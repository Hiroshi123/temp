2016-12-12 13:45:00 [program started on Mon Dec 12 13:45:00 2016] 
2016-12-12 13:45:00 [command line arguments] 
2016-12-12 13:45:00 stcWeights false 
2016-12-12 13:45:00 LR 0.015625 
2016-12-12 13:45:00 batchSize 300 
2016-12-12 13:45:00 network ./Models/Cifar10_Custom 
2016-12-12 13:45:00 stcNeurons true 
2016-12-12 13:45:00 constBatchSize false 
2016-12-12 13:45:00 chartFileName chart1 
2016-12-12 13:45:00 dp_prepro false 
2016-12-12 13:45:00 nGPU 3 
2016-12-12 13:45:00 dataset Caltech256 
2016-12-12 13:45:00 type cuda 
2016-12-12 13:45:00 momentum 0 
2016-12-12 13:45:00 threads 8 
2016-12-12 13:45:00 weightDecay 0 
2016-12-12 13:45:00 runningVal false 
2016-12-12 13:45:00 convLayerN 6 
2016-12-12 13:45:00 LRDecay 0 
2016-12-12 13:45:00 numHid 1024 
2016-12-12 13:45:00 save /dev/shm/clone/temp/th/Results/Caltech256/model6-20-v2 
2016-12-12 13:45:00 augment false 
2016-12-12 13:45:00 epoch -1 
2016-12-12 13:45:00 modelsFolder ./Models/ 
2016-12-12 13:45:00 format rgb 
2016-12-12 13:45:00 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-12 13:45:00 imageFileExtension svg 
2016-12-12 13:45:00 channel 2 
2016-12-12 13:45:00 devid 14 
2016-12-12 13:45:00 visualize 1 
2016-12-12 13:45:00 LRDecayPerEpoch 0.0001 
2016-12-12 13:45:00 optimization adam 
2016-12-12 13:45:00 SBN true 
2016-12-12 13:45:00 normalization simple 
2016-12-12 13:45:00 title model1 
2016-12-12 13:45:00 load  
2016-12-12 13:45:00 whiten true 
2016-12-12 13:45:00 [----------------------] 
2016-12-12 13:45:11 ==> Network 
2016-12-12 13:45:11 DataParallelTable: 3 x nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 256, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(512 -> 1024, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(16384)
  (29): BinaryLinear(16384 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-12 13:45:11 ==>36396029 Parameters 
2016-12-12 13:45:11 ==> Loss 
2016-12-12 13:45:11 SqrtHingeEmbeddingCriterion 
2016-12-12 13:45:11 
==> Starting Training
 
2016-12-12 13:45:11 Epoch 1 
2016-12-12 13:50:52 Training Error = 0.99163684779895 
2016-12-12 13:50:52 Training Loss = 0.44315123127918 
2016-12-12 13:50:59 Valid Error = 1 
2016-12-12 13:50:59 Valid Loss = 0.071501613702884 
2016-12-12 13:51:05 Test Error = 1 
2016-12-12 13:51:05 Test Loss = 0.071852977228395 
2016-12-12 13:51:05 -------------------LR------------------- 
2016-12-12 13:51:05 0.015625 
2016-12-12 13:51:05 Epoch 2 
2016-12-12 13:56:43 Training Error = 0.97615877506865 
2016-12-12 13:56:43 Training Loss = 0.036321495782911 
2016-12-12 13:56:50 Valid Error = 0.93934855859229 
2016-12-12 13:56:50 Valid Loss = 0.01827313600219 
2016-12-12 13:56:56 Test Error = 0.9514988211519 
2016-12-12 13:56:56 Test Loss = 0.018393513596397 
2016-12-12 13:56:56 -------------------LR------------------- 
2016-12-12 13:56:56 0.015625 
2016-12-12 13:56:56 Epoch 3 
2016-12-12 14:02:32 Training Error = 0.96767079970042 
2016-12-12 14:02:32 Training Loss = 0.017664680174124 
2016-12-12 14:02:39 Valid Error = 0.93785099213778 
2016-12-12 14:02:39 Valid Loss = 0.016128828161271 
2016-12-12 14:02:47 Test Error = 0.9484674974739 
2016-12-12 14:02:47 Test Loss = 0.016173859461037 
2016-12-12 14:02:47 -------------------LR------------------- 
2016-12-12 14:02:47 0.015625 
2016-12-12 14:02:47 Epoch 4 
2016-12-12 14:08:28 Training Error = 0.96821170009154 
2016-12-12 14:08:28 Training Loss = 0.016621554819051 
2016-12-12 14:08:34 Valid Error = 0.93710220891052 
2016-12-12 14:08:34 Valid Loss = 0.015830683493547 
2016-12-12 14:08:40 Test Error = 0.9477938699899 
2016-12-12 14:08:40 Test Loss = 0.015884382841424 
2016-12-12 14:08:40 -------------------LR------------------- 
2016-12-12 14:08:40 0.015625 
2016-12-12 14:08:40 Epoch 5 
2016-12-12 14:14:14 Training Error = 0.95830906216194 
2016-12-12 14:14:14 Training Loss = 0.016264710823547 
2016-12-12 14:14:21 Valid Error = 0.95058030700112 
2016-12-12 14:14:21 Valid Loss = 0.015963414515202 
2016-12-12 14:14:27 Test Error = 0.95991916470192 
2016-12-12 14:14:27 Test Loss = 0.016045316098311 
2016-12-12 14:14:27 -------------------LR------------------- 
2016-12-12 14:14:27 0.015625 
2016-12-12 14:14:27 Epoch 6 
2016-12-12 14:20:07 Training Error = 0.95339935091953 
2016-12-12 14:20:07 Training Loss = 0.016064109424653 
2016-12-12 14:20:14 Valid Error = 0.93934855859229 
2016-12-12 14:20:14 Valid Loss = 0.015813716148309 
2016-12-12 14:20:20 Test Error = 0.9514988211519 
2016-12-12 14:20:20 Test Loss = 0.015863115929954 
2016-12-12 14:20:20 -------------------LR------------------- 
2016-12-12 14:20:20 0.015625 
2016-12-12 14:20:20 Epoch 7 
2016-12-12 14:25:56 Training Error = 0.94270616626446 
2016-12-12 14:25:56 Training Loss = 0.015900784224856 
2016-12-12 14:26:03 Valid Error = 0.93859977536503 
2016-12-12 14:26:03 Valid Loss = 0.015715529209903 
2016-12-12 14:26:09 Test Error = 0.9494779386999 
2016-12-12 14:26:09 Test Loss = 0.015771381794651 
2016-12-12 14:26:09 -------------------LR------------------- 
2016-12-12 14:26:09 0.015625 
2016-12-12 14:26:09 Epoch 8 
2016-12-12 14:31:44 Training Error = 0.94008487975368 
2016-12-12 14:31:44 Training Loss = 0.015804480416589 
2016-12-12 14:31:50 Valid Error = 0.93785099213778 
2016-12-12 14:31:50 Valid Loss = 0.015737036957612 
2016-12-12 14:31:56 Test Error = 0.9481306837319 
2016-12-12 14:31:56 Test Loss = 0.015789783775177 
2016-12-12 14:31:56 -------------------LR------------------- 
2016-12-12 14:31:56 0.015625 
2016-12-12 14:31:56 Epoch 9 
2016-12-12 14:37:26 Training Error = 0.92843471748356 
2016-12-12 14:37:26 Training Loss = 0.015703319473749 
2016-12-12 14:37:33 Valid Error = 0.93934855859229 
2016-12-12 14:37:33 Valid Loss = 0.015700390650123 
2016-12-12 14:37:39 Test Error = 0.9514988211519 
2016-12-12 14:37:39 Test Loss = 0.015729190160686 
2016-12-12 14:37:39 -------------------LR------------------- 
2016-12-12 14:37:39 0.015625 
2016-12-12 14:37:39 Epoch 10 
2016-12-12 14:43:16 Training Error = 0.9251060996921 
2016-12-12 14:43:16 Training Loss = 0.015647030739901 
2016-12-12 14:43:23 Valid Error = 0.9382253837514 
2016-12-12 14:43:23 Valid Loss = 0.01565540865443 
2016-12-12 14:43:29 Test Error = 0.9504883799259 
2016-12-12 14:43:29 Test Loss = 0.015688581267074 
2016-12-12 14:43:29 -------------------LR------------------- 
2016-12-12 14:43:29 0.015625 
2016-12-12 14:43:29 Epoch 11 
2016-12-12 14:49:01 Training Error = 0.90704834817342 
2016-12-12 14:49:01 Training Loss = 0.015523073031633 
2016-12-12 14:49:08 Valid Error = 0.97791089479596 
2016-12-12 14:49:08 Valid Loss = 0.015810472543569 
2016-12-12 14:49:14 Test Error = 0.97574941057595 
2016-12-12 14:49:14 Test Loss = 0.015834684477323 
2016-12-12 14:49:14 -------------------LR------------------- 
2016-12-12 14:49:14 0.015625 
2016-12-12 14:49:14 Epoch 12 
2016-12-12 14:55:01 Training Error = 0.90276275276691 
2016-12-12 14:55:01 Training Loss = 0.015382154654342 
2016-12-12 14:55:08 Valid Error = 0.95207787345563 
2016-12-12 14:55:08 Valid Loss = 0.016237310170028 
2016-12-12 14:55:14 Test Error = 0.96295048837993 
2016-12-12 14:55:14 Test Loss = 0.016404264233938 
2016-12-12 14:55:14 -------------------LR------------------- 
2016-12-12 14:55:14 0.015625 
2016-12-12 14:55:14 Epoch 13 
2016-12-12 15:00:50 Training Error = 0.89464924690022 
2016-12-12 15:00:50 Training Loss = 0.015176900642141 
2016-12-12 15:00:57 Valid Error = 0.98090602770498 
2016-12-12 15:00:57 Valid Loss = 0.016145788820834 
2016-12-12 15:01:03 Test Error = 0.98113843044796 
2016-12-12 15:01:03 Test Loss = 0.016025803707117 
2016-12-12 15:01:03 -------------------LR------------------- 
2016-12-12 15:01:03 0.015625 
2016-12-12 15:01:03 Epoch 14 
2016-12-12 15:06:32 Training Error = 0.8848714321378 
2016-12-12 15:06:32 Training Loss = 0.015022224533424 
2016-12-12 15:06:39 Valid Error = 0.97603893672782 
2016-12-12 15:06:39 Valid Loss = 0.016223928198404 
2016-12-12 15:06:45 Test Error = 0.97473896934995 
2016-12-12 15:06:45 Test Loss = 0.016187046783008 
2016-12-12 15:06:45 -------------------LR------------------- 
2016-12-12 15:06:45 0.015625 
2016-12-12 15:06:45 Epoch 15 
2016-12-12 15:12:17 Training Error = 0.8669801115087 
2016-12-12 15:12:17 Training Loss = 0.014889425384439 
2016-12-12 15:12:23 Valid Error = 0.9797828528641 
2016-12-12 15:12:23 Valid Loss = 0.016240386801048 
2016-12-12 15:12:29 Test Error = 0.98214887167396 
2016-12-12 15:12:29 Test Loss = 0.01618439908484 
2016-12-12 15:12:29 -------------------LR------------------- 
2016-12-12 15:12:29 0.015625 
2016-12-12 15:12:29 Epoch 16 
2016-12-12 15:17:59 Training Error = 0.84767412831822 
2016-12-12 15:17:59 Training Loss = 0.014730077064219 
2016-12-12 15:18:06 Valid Error = 0.95731935604642 
2016-12-12 15:18:06 Valid Loss = 0.01721560072745 
2016-12-12 15:18:12 Test Error = 0.96934994947794 
2016-12-12 15:18:12 Test Loss = 0.017467987094507 
2016-12-12 15:18:12 -------------------LR------------------- 
2016-12-12 15:18:12 0.015625 
2016-12-12 15:18:12 Epoch 17 
2016-12-12 15:23:50 Training Error = 0.82583007406175 
2016-12-12 15:23:50 Training Loss = 0.014526186037244 
2016-12-12 15:23:57 Valid Error = 0.96143766379633 
2016-12-12 15:23:57 Valid Loss = 0.016372448430925 
2016-12-12 15:24:03 Test Error = 0.96194004715392 
2016-12-12 15:24:03 Test Loss = 0.016361077200022 
2016-12-12 15:24:03 -------------------LR------------------- 
2016-12-12 15:24:03 0.015625 
2016-12-12 15:24:03 Epoch 18 
2016-12-12 15:29:40 Training Error = 0.79999167845552 
2016-12-12 15:29:40 Training Loss = 0.014287891705365 
2016-12-12 15:29:47 Valid Error = 0.93373268438787 
2016-12-12 15:29:47 Valid Loss = 0.017085433295867 
2016-12-12 15:29:53 Test Error = 0.93768945772988 
2016-12-12 15:29:53 Test Loss = 0.01706724217108 
2016-12-12 15:29:53 -------------------LR------------------- 
2016-12-12 15:29:53 0.015625 
2016-12-12 15:29:53 Epoch 19 
2016-12-12 15:35:26 Training Error = 0.754972122826 
2016-12-12 15:35:26 Training Loss = 0.014002060863649 
2016-12-12 15:35:32 Valid Error = 0.8292774241857 
2016-12-12 15:35:32 Valid Loss = 0.014738415801568 
2016-12-12 15:35:38 Test Error = 0.82889861906366 
2016-12-12 15:35:38 Test Loss = 0.014842319931622 
2016-12-12 15:35:38 -------------------LR------------------- 
2016-12-12 15:35:38 0.015625 
2016-12-12 15:35:38 Epoch 20 
2016-12-12 15:41:14 Training Error = 0.71864858117667 
2016-12-12 15:41:14 Training Loss = 0.013783147972866 
2016-12-12 15:41:21 Valid Error = 0.81505054286784 
2016-12-12 15:41:21 Valid Loss = 0.01497214940143 
2016-12-12 15:41:27 Test Error = 0.80868979454362 
2016-12-12 15:41:27 Test Loss = 0.014902830964688 
2016-12-12 15:41:27 -------------------LR------------------- 
2016-12-12 15:41:27 0.015625 
2016-12-12 15:41:27 Epoch 21 
2016-12-12 15:46:55 Training Error = 0.68631938087709 
2016-12-12 15:46:55 Training Loss = 0.013555551682356 
2016-12-12 15:47:02 Valid Error = 0.81916885061775 
2016-12-12 15:47:02 Valid Loss = 0.016024773166106 
2016-12-12 15:47:08 Test Error = 0.80363758841361 
2016-12-12 15:47:08 Test Loss = 0.015816598156383 
2016-12-12 15:47:08 -------------------LR------------------- 
2016-12-12 15:47:08 0.015625 
2016-12-12 15:47:08 Epoch 22 
2016-12-12 15:52:41 Training Error = 0.64425397353749 
2016-12-12 15:52:41 Training Loss = 0.013349647977786 
2016-12-12 15:52:48 Valid Error = 0.76787719955073 
2016-12-12 15:52:48 Valid Loss = 0.01453994162071 
2016-12-12 15:52:54 Test Error = 0.73795890872348 
2016-12-12 15:52:54 Test Loss = 0.014410973168128 
2016-12-12 15:52:54 -------------------LR------------------- 
2016-12-12 15:52:54 0.015625 
2016-12-12 15:52:54 Epoch 23 
2016-12-12 15:58:35 Training Error = 0.60564200715653 
2016-12-12 15:58:35 Training Loss = 0.013126655790351 
2016-12-12 15:58:42 Valid Error = 0.62972669412205 
2016-12-12 15:58:42 Valid Loss = 0.013467786243913 
2016-12-12 15:58:48 Test Error = 0.62681037386325 
2016-12-12 15:58:48 Test Loss = 0.013439126823227 
2016-12-12 15:58:48 -------------------LR------------------- 
2016-12-12 15:58:48 0.015625 
2016-12-12 15:58:48 Epoch 24 
2016-12-12 16:04:25 Training Error = 0.57164849796122 
2016-12-12 16:04:25 Training Loss = 0.012973254267988 
2016-12-12 16:04:32 Valid Error = 0.65555971546237 
2016-12-12 16:04:32 Valid Loss = 0.013621228404938 
2016-12-12 16:04:38 Test Error = 0.6513977770293 
2016-12-12 16:04:38 Test Loss = 0.013625618125659 
2016-12-12 16:04:38 -------------------LR------------------- 
2016-12-12 16:04:38 0.015625 
2016-12-12 16:04:38 Epoch 25 
2016-12-12 16:10:10 Training Error = 0.5148539568944 
2016-12-12 16:10:10 Training Loss = 0.012729984088603 
2016-12-12 16:10:17 Valid Error = 0.60688880569075 
2016-12-12 16:10:17 Valid Loss = 0.012934680600939 
2016-12-12 16:10:23 Test Error = 0.60929605927922 
2016-12-12 16:10:23 Test Loss = 0.012957440058159 
2016-12-12 16:10:23 -------------------LR------------------- 
2016-12-12 16:10:23 0.015625 
2016-12-12 16:10:23 Epoch 26 
2016-12-12 16:16:00 Training Error = 0.48364816509944 
2016-12-12 16:16:00 Training Loss = 0.012571178074385 
2016-12-12 16:16:07 Valid Error = 0.61100711344066 
2016-12-12 16:16:07 Valid Loss = 0.01340373527868 
2016-12-12 16:16:13 Test Error = 0.59649713708319 
2016-12-12 16:16:13 Test Loss = 0.013259563140495 
2016-12-12 16:16:13 -------------------LR------------------- 
2016-12-12 16:16:13 0.015625 
2016-12-12 16:16:13 Epoch 27 
2016-12-12 16:21:47 Training Error = 0.45256719647167 
2016-12-12 16:21:47 Training Loss = 0.012429442645979 
2016-12-12 16:21:54 Valid Error = 0.50018719580681 
2016-12-12 16:21:54 Valid Loss = 0.011729762613182 
2016-12-12 16:22:00 Test Error = 0.49275850454699 
2016-12-12 16:22:00 Test Loss = 0.011705399079727 
2016-12-12 16:22:00 -------------------LR------------------- 
2016-12-12 16:22:00 0.015625 
2016-12-12 16:22:00 Epoch 28 
2016-12-12 16:27:37 Training Error = 0.42177748190064 
2016-12-12 16:27:37 Training Loss = 0.012254812124402 
2016-12-12 16:27:44 Valid Error = 0.42044178210408 
2016-12-12 16:27:44 Valid Loss = 0.011071348748124 
2016-12-12 16:27:50 Test Error = 0.41832266756484 
2016-12-12 16:27:50 Test Loss = 0.011052895735184 
2016-12-12 16:27:50 -------------------LR------------------- 
2016-12-12 16:27:50 0.015625 
2016-12-12 16:27:50 Epoch 29 
2016-12-12 16:33:27 Training Error = 0.38969792793542 
2016-12-12 16:33:27 Training Loss = 0.012082663009539 
2016-12-12 16:33:34 Valid Error = 0.50505428678398 
2016-12-12 16:33:34 Valid Loss = 0.011975707145852 
2016-12-12 16:33:40 Test Error = 0.48736948467497 
2016-12-12 16:33:40 Test Loss = 0.011779938772886 
2016-12-12 16:33:40 -------------------LR------------------- 
2016-12-12 16:33:40 0.015625 
2016-12-12 16:33:40 Epoch 30 
2016-12-12 16:39:07 Training Error = 0.36876924357161 
2016-12-12 16:39:07 Training Loss = 0.011974059971683 
2016-12-12 16:39:14 Valid Error = 0.51815799326095 
2016-12-12 16:39:14 Valid Loss = 0.012452832202268 
2016-12-12 16:39:20 Test Error = 0.49545301448299 
2016-12-12 16:39:20 Test Loss = 0.012207907765977 
2016-12-12 16:39:20 -------------------LR------------------- 
2016-12-12 16:39:20 0.015625 
2016-12-12 16:39:20 Epoch 31 
2016-12-12 16:44:57 Training Error = 0.34576017308813 
2016-12-12 16:44:57 Training Loss = 0.011819321634517 
2016-12-12 16:45:03 Valid Error = 0.46836390864845 
2016-12-12 16:45:03 Valid Loss = 0.011697235715129 
2016-12-12 16:45:09 Test Error = 0.45267766924891 
2016-12-12 16:45:09 Test Loss = 0.011610777061639 
2016-12-12 16:45:09 -------------------LR------------------- 
2016-12-12 16:45:09 0.015625 
2016-12-12 16:45:09 Epoch 32 
2016-12-12 16:50:46 Training Error = 0.32112840143131 
2016-12-12 16:50:46 Training Loss = 0.011686665209432 
2016-12-12 16:50:53 Valid Error = 0.49419692998877 
2016-12-12 16:50:53 Valid Loss = 0.013955805394738 
2016-12-12 16:50:59 Test Error = 0.47019198383294 
2016-12-12 16:50:59 Test Loss = 0.013667008591375 
2016-12-12 16:50:59 -------------------LR------------------- 
2016-12-12 16:50:59 0.015625 
2016-12-12 16:50:59 Epoch 33 
2016-12-12 16:56:37 Training Error = 0.30111508696014 
2016-12-12 16:56:37 Training Loss = 0.011514241167955 
2016-12-12 16:56:44 Valid Error = 0.3964807188319 
2016-12-12 16:56:44 Valid Loss = 0.010746620250945 
2016-12-12 16:56:50 Test Error = 0.38363085213877 
2016-12-12 16:56:50 Test Loss = 0.010587231953679 
2016-12-12 16:56:50 -------------------LR------------------- 
2016-12-12 16:56:50 0.015625 
2016-12-12 16:56:50 Epoch 34 
2016-12-12 17:02:23 Training Error = 0.28309894316385 
2016-12-12 17:02:23 Training Loss = 0.011430831838275 
2016-12-12 17:02:30 Valid Error = 0.54923249719206 
2016-12-12 17:02:30 Valid Loss = 0.013987909102165 
2016-12-12 17:02:36 Test Error = 0.52778713371506 
2016-12-12 17:02:36 Test Loss = 0.013639987699956 
2016-12-12 17:02:36 -------------------LR------------------- 
2016-12-12 17:02:36 0.015625 
2016-12-12 17:02:36 Epoch 35 
2016-12-12 17:08:14 Training Error = 0.27269701256553 
2016-12-12 17:08:14 Training Loss = 0.011345590043338 
2016-12-12 17:08:21 Valid Error = 0.32834144515163 
2016-12-12 17:08:21 Valid Loss = 0.0098757536169479 
2016-12-12 17:08:27 Test Error = 0.31727854496463 
2016-12-12 17:08:27 Test Loss = 0.0097650844963721 
2016-12-12 17:08:27 -------------------LR------------------- 
2016-12-12 17:08:27 0.015625 
2016-12-12 17:08:27 Epoch 36 
2016-12-12 17:13:59 Training Error = 0.23986851959724 
2016-12-12 17:13:59 Training Loss = 0.011118143328955 
2016-12-12 17:14:06 Valid Error = 0.25870460501685 
2016-12-12 17:14:06 Valid Loss = 0.0088707112033542 
2016-12-12 17:14:12 Test Error = 0.25934658134052 
2016-12-12 17:14:12 Test Loss = 0.0088197747710345 
2016-12-12 17:14:12 -------------------LR------------------- 
2016-12-12 17:14:12 0.015625 
2016-12-12 17:14:12 Epoch 37 
2016-12-12 17:19:46 Training Error = 0.23246234501123 
2016-12-12 17:19:46 Training Loss = 0.011074057712164 
2016-12-12 17:19:53 Valid Error = 0.31636091351554 
2016-12-12 17:19:53 Valid Loss = 0.010017117718282 
2016-12-12 17:19:59 Test Error = 0.31391040754463 
2016-12-12 17:19:59 Test Loss = 0.0098463364598424 
2016-12-12 17:19:59 -------------------LR------------------- 
2016-12-12 17:19:59 0.015625 
2016-12-12 17:19:59 Epoch 38 
2016-12-12 17:25:37 Training Error = 0.22181076807856 
2016-12-12 17:25:37 Training Loss = 0.010965012360123 
2016-12-12 17:25:44 Valid Error = 0.33433171096967 
2016-12-12 17:25:44 Valid Loss = 0.010318918143042 
2016-12-12 17:25:50 Test Error = 0.31929942741664 
2016-12-12 17:25:50 Test Loss = 0.010110216453202 
2016-12-12 17:25:50 -------------------LR------------------- 
2016-12-12 17:25:50 0.015625 
2016-12-12 17:25:50 Epoch 39 
2016-12-12 17:31:32 Training Error = 0.21311475409836 
2016-12-12 17:31:32 Training Loss = 0.010845963109254 
2016-12-12 17:31:39 Valid Error = 0.5511044552602 
2016-12-12 17:31:39 Valid Loss = 0.01375230179054 
2016-12-12 17:31:45 Test Error = 0.53384978107107 
2016-12-12 17:31:45 Test Loss = 0.013455983536023 
2016-12-12 17:31:45 -------------------LR------------------- 
2016-12-12 17:31:45 0.015625 
2016-12-12 17:31:45 Epoch 40 
2016-12-12 17:37:21 Training Error = 0.20641591079304 
2016-12-12 17:37:21 Training Loss = 0.010752639656582 
2016-12-12 17:37:28 Valid Error = 0.24560089853987 
2016-12-12 17:37:28 Valid Loss = 0.008476614371713 
2016-12-12 17:37:34 Test Error = 0.23846412933648 
2016-12-12 17:37:34 Test Loss = 0.0083328218172894 
2016-12-12 17:37:34 -------------------LR------------------- 
2016-12-12 17:37:34 0.015625 
2016-12-12 17:37:34 Epoch 41 
2016-12-12 17:43:07 Training Error = 0.20038279104602 
2016-12-12 17:43:07 Training Loss = 0.010660896624833 
2016-12-12 17:43:13 Valid Error = 0.44327967053538 
2016-12-12 17:43:13 Valid Loss = 0.011543924708205 
2016-12-12 17:43:19 Test Error = 0.41529134388683 
2016-12-12 17:43:19 Test Loss = 0.011256767967912 
2016-12-12 17:43:19 -------------------LR------------------- 
2016-12-12 17:43:19 0.015625 
2016-12-12 17:43:19 Epoch 42 
2016-12-12 17:48:52 Training Error = 0.19231089290172 
2016-12-12 17:48:52 Training Loss = 0.010528677770607 
2016-12-12 17:48:59 Valid Error = 0.23174840883564 
2016-12-12 17:48:59 Valid Loss = 0.008342935677142 
2016-12-12 17:49:05 Test Error = 0.22027618726844 
2016-12-12 17:49:05 Test Loss = 0.0082428291300595 
2016-12-12 17:49:05 -------------------LR------------------- 
2016-12-12 17:49:05 0.015625 
2016-12-12 17:49:05 Epoch 43 
2016-12-12 17:54:41 Training Error = 0.18835815927436 
2016-12-12 17:54:41 Training Loss = 0.010465958229629 
2016-12-12 17:54:48 Valid Error = 0.27929614376638 
2016-12-12 17:54:48 Valid Loss = 0.0089602152070623 
2016-12-12 17:54:54 Test Error = 0.27652408218255 
2016-12-12 17:54:54 Test Loss = 0.0088497809573895 
2016-12-12 17:54:54 -------------------LR------------------- 
2016-12-12 17:54:54 0.015625 
2016-12-12 17:54:54 Epoch 44 
2016-12-12 18:00:30 Training Error = 0.18640259632188 
2016-12-12 18:00:30 Training Loss = 0.010359248036005 
2016-12-12 18:00:37 Valid Error = 0.37588918008237 
2016-12-12 18:00:37 Valid Loss = 0.010813689467437 
2016-12-12 18:00:43 Test Error = 0.36443246884473 
2016-12-12 18:00:43 Test Loss = 0.010647662793813 
2016-12-12 18:00:43 -------------------LR------------------- 
2016-12-12 18:00:43 0.015625 
2016-12-12 18:00:43 Epoch 45 
2016-12-12 18:06:27 Training Error = 0.18336523258717 
2016-12-12 18:06:27 Training Loss = 0.010280506108449 
2016-12-12 18:06:34 Valid Error = 0.311868214152 
2016-12-12 18:06:34 Valid Loss = 0.0096727862069091 
2016-12-12 18:06:40 Test Error = 0.31087908386662 
2016-12-12 18:06:40 Test Loss = 0.0095043776726924 
2016-12-12 18:06:40 -------------------LR------------------- 
2016-12-12 18:06:40 0.015625 
2016-12-12 18:06:40 Epoch 46 
2016-12-12 18:12:10 Training Error = 0.17500208038612 
2016-12-12 18:12:10 Training Loss = 0.010160723817187 
2016-12-12 18:12:17 Valid Error = 0.18569824035942 
2016-12-12 18:12:17 Valid Loss = 0.0065760798205456 
2016-12-12 18:12:23 Test Error = 0.18895250926238 
2016-12-12 18:12:23 Test Loss = 0.0066202692628715 
2016-12-12 18:12:23 -------------------LR------------------- 
2016-12-12 18:12:23 0.015625 
2016-12-12 18:12:23 Epoch 47 
2016-12-12 18:18:00 Training Error = 0.17541815761005 
2016-12-12 18:18:00 Training Loss = 0.0101514150585 
2016-12-12 18:18:07 Valid Error = 0.20628977910895 
2016-12-12 18:18:07 Valid Loss = 0.0072708054656709 
2016-12-12 18:18:13 Test Error = 0.2007409902324 
2016-12-12 18:18:13 Test Loss = 0.0071986336454919 
2016-12-12 18:18:13 -------------------LR------------------- 
2016-12-12 18:18:13 0.015625 
2016-12-12 18:18:13 Epoch 48 
2016-12-12 18:23:44 Training Error = 0.1751269035533 
2016-12-12 18:23:44 Training Loss = 0.010059091450111 
2016-12-12 18:23:51 Valid Error = 0.27068513665294 
2016-12-12 18:23:51 Valid Loss = 0.008922134211034 
2016-12-12 18:23:57 Test Error = 0.26709329740653 
2016-12-12 18:23:57 Test Loss = 0.0087207518852043 
2016-12-12 18:23:57 -------------------LR------------------- 
2016-12-12 18:23:57 0.015625 
2016-12-12 18:23:57 Epoch 49 
2016-12-12 18:29:36 Training Error = 0.16822002163602 
2016-12-12 18:29:36 Training Loss = 0.0099289337188187 
2016-12-12 18:29:43 Valid Error = 0.19692998876825 
2016-12-12 18:29:43 Valid Loss = 0.0071084268409847 
2016-12-12 18:29:49 Test Error = 0.2007409902324 
2016-12-12 18:29:49 Test Loss = 0.007080661323281 
2016-12-12 18:29:49 -------------------LR------------------- 
2016-12-12 18:29:49 0.015625 
2016-12-12 18:29:49 Epoch 50 
2016-12-12 18:35:17 Training Error = 0.16963468419739 
2016-12-12 18:35:17 Training Loss = 0.0099199585002655 
2016-12-12 18:35:24 Valid Error = 0.43017596405841 
2016-12-12 18:35:24 Valid Loss = 0.011443699283216 
2016-12-12 18:35:30 Test Error = 0.41394408891883 
2016-12-12 18:35:30 Test Loss = 0.011171489144275 
2016-12-12 18:35:30 -------------------LR------------------- 
2016-12-12 18:35:30 0.0078125 
2016-12-12 18:35:30 Epoch 51 
2016-12-12 18:41:04 Training Error = 0.16380960306233 
2016-12-12 18:41:04 Training Loss = 0.0096719031812591 
2016-12-12 18:41:11 Valid Error = 0.42905278921752 
2016-12-12 18:41:11 Valid Loss = 0.011431229942781 
2016-12-12 18:41:17 Test Error = 0.41057595149882 
2016-12-12 18:41:17 Test Loss = 0.011138626587647 
2016-12-12 18:41:17 -------------------LR------------------- 
2016-12-12 18:41:17 0.0078125 
2016-12-12 18:41:17 Epoch 52 
2016-12-12 18:46:47 Training Error = 0.16048098527087 
2016-12-12 18:46:47 Training Loss = 0.0096018755615277 
2016-12-12 18:46:54 Valid Error = 0.22276301010857 
2016-12-12 18:46:54 Valid Loss = 0.0075328066276763 
2016-12-12 18:47:00 Test Error = 0.22162344223644 
2016-12-12 18:47:00 Test Loss = 0.0073611479371532 
2016-12-12 18:47:00 -------------------LR------------------- 
2016-12-12 18:47:00 0.0078125 
2016-12-12 18:47:00 Epoch 53 
2016-12-12 18:52:30 Training Error = 0.15935757676625 
2016-12-12 18:52:30 Training Loss = 0.0096036738538646 
2016-12-12 18:52:37 Valid Error = 0.19093972295021 
2016-12-12 18:52:37 Valid Loss = 0.0061060433669961 
2016-12-12 18:52:43 Test Error = 0.19063657797238 
2016-12-12 18:52:43 Test Loss = 0.0060342672861552 
2016-12-12 18:52:43 -------------------LR------------------- 
2016-12-12 18:52:43 0.0078125 
2016-12-12 18:52:43 Epoch 54 
2016-12-12 18:58:23 Training Error = 0.16006490804693 
2016-12-12 18:58:23 Training Loss = 0.0095799667777962 
2016-12-12 18:58:30 Valid Error = 0.2029202545863 
2016-12-12 18:58:30 Valid Loss = 0.0063474395998683 
2016-12-12 18:58:36 Test Error = 0.20613001010441 
2016-12-12 18:58:36 Test Loss = 0.0063442987687404 
2016-12-12 18:58:36 -------------------LR------------------- 
2016-12-12 18:58:36 0.0078125 
2016-12-12 18:58:36 Epoch 55 
2016-12-12 19:04:16 Training Error = 0.15669468253308 
2016-12-12 19:04:16 Training Loss = 0.0095440929694814 
2016-12-12 19:04:22 Valid Error = 0.23811306626732 
2016-12-12 19:04:22 Valid Loss = 0.0066064001945023 
2016-12-12 19:04:28 Test Error = 0.23307510946447 
2016-12-12 19:04:28 Test Loss = 0.0065219864644586 
2016-12-12 19:04:28 -------------------LR------------------- 
2016-12-12 19:04:28 0.0078125 
2016-12-12 19:04:28 Epoch 56 
2016-12-12 19:10:00 Training Error = 0.15607056669718 
2016-12-12 19:10:00 Training Loss = 0.009501376382883 
2016-12-12 19:10:07 Valid Error = 0.17409210033695 
2016-12-12 19:10:07 Valid Loss = 0.0054561980902757 
2016-12-12 19:10:13 Test Error = 0.17009093971034 
2016-12-12 19:10:13 Test Loss = 0.0054211751144887 
2016-12-12 19:10:13 -------------------LR------------------- 
2016-12-12 19:10:13 0.0078125 
2016-12-12 19:10:13 Epoch 57 
2016-12-12 19:15:45 Training Error = 0.15652825164351 
2016-12-12 19:15:45 Training Loss = 0.0095107243002978 
2016-12-12 19:15:52 Valid Error = 0.27031074503931 
2016-12-12 19:15:52 Valid Loss = 0.0083526889723426 
2016-12-12 19:15:58 Test Error = 0.25261030650051 
2016-12-12 19:15:58 Test Loss = 0.008121916264612 
2016-12-12 19:15:58 -------------------LR------------------- 
2016-12-12 19:15:58 0.0078125 
2016-12-12 19:15:58 Epoch 58 
2016-12-12 19:21:32 Training Error = 0.15444786552384 
2016-12-12 19:21:32 Training Loss = 0.0094669021398655 
2016-12-12 19:21:39 Valid Error = 0.19468363908648 
2016-12-12 19:21:39 Valid Loss = 0.0063017914299471 
2016-12-12 19:21:45 Test Error = 0.18827888177838 
2016-12-12 19:21:45 Test Loss = 0.0062169913577707 
2016-12-12 19:21:45 -------------------LR------------------- 
2016-12-12 19:21:45 0.0078125 
2016-12-12 19:21:45 Epoch 59 
2016-12-12 19:27:12 Training Error = 0.15207622534742 
2016-12-12 19:27:12 Training Loss = 0.0093651371511624 
2016-12-12 19:27:19 Valid Error = 0.21827031074504 
2016-12-12 19:27:19 Valid Loss = 0.0067291662119702 
2016-12-12 19:27:25 Test Error = 0.21791849107444 
2016-12-12 19:27:25 Test Loss = 0.006660255955585 
2016-12-12 19:27:25 -------------------LR------------------- 
2016-12-12 19:27:25 0.0078125 
2016-12-12 19:27:25 Epoch 60 
2016-12-12 19:33:09 Training Error = 0.15240908712657 
2016-12-12 19:33:09 Training Loss = 0.0093874266124969 
2016-12-12 19:33:16 Valid Error = 0.18607263197304 
2016-12-12 19:33:16 Valid Loss = 0.0056914603917608 
2016-12-12 19:33:22 Test Error = 0.18558437184237 
2016-12-12 19:33:22 Test Loss = 0.0056352419840999 
2016-12-12 19:33:22 -------------------LR------------------- 
2016-12-12 19:33:22 0.0078125 
2016-12-12 19:33:22 Epoch 61 
2016-12-12 19:39:00 Training Error = 0.15120246317717 
2016-12-12 19:39:00 Training Loss = 0.009403006455155 
2016-12-12 19:39:06 Valid Error = 0.18906776488207 
2016-12-12 19:39:06 Valid Loss = 0.0055854399853031 
2016-12-12 19:39:12 Test Error = 0.18962613674638 
2016-12-12 19:39:12 Test Loss = 0.0055829771897783 
2016-12-12 19:39:12 -------------------LR------------------- 
2016-12-12 19:39:12 0.0078125 
2016-12-12 19:39:12 Epoch 62 
2016-12-12 19:44:38 Training Error = 0.15116085545477 
2016-12-12 19:44:38 Training Loss = 0.0093947086845104 
2016-12-12 19:44:45 Valid Error = 0.25159116435792 
2016-12-12 19:44:45 Valid Loss = 0.008109093411028 
2016-12-12 19:44:51 Test Error = 0.2505894240485 
2016-12-12 19:44:51 Test Loss = 0.0080023589591833 
2016-12-12 19:44:51 -------------------LR------------------- 
2016-12-12 19:44:51 0.0078125 
2016-12-12 19:44:51 Epoch 63 
2016-12-12 19:50:22 Training Error = 0.14828992260964 
2016-12-12 19:50:22 Training Loss = 0.0092712543313781 
2016-12-12 19:50:29 Valid Error = 0.24971920628978 
2016-12-12 19:50:29 Valid Loss = 0.0083153800644085 
2016-12-12 19:50:35 Test Error = 0.2509262377905 
2016-12-12 19:50:35 Test Loss = 0.0082246143231231 
2016-12-12 19:50:35 -------------------LR------------------- 
2016-12-12 19:50:35 0.0078125 
2016-12-12 19:50:35 Epoch 64 
2016-12-12 19:56:08 Training Error = 0.14987101606058 
2016-12-12 19:56:08 Training Loss = 0.0092943284502705 
2016-12-12 19:56:15 Valid Error = 0.18157993260951 
2016-12-12 19:56:15 Valid Loss = 0.0054608888309534 
2016-12-12 19:56:21 Test Error = 0.17682721455035 
2016-12-12 19:56:21 Test Loss = 0.0054534330039793 
2016-12-12 19:56:21 -------------------LR------------------- 
2016-12-12 19:56:21 0.0078125 
2016-12-12 19:56:21 Epoch 65 
2016-12-12 20:01:53 Training Error = 0.14741616043938 
2016-12-12 20:01:53 Training Loss = 0.0092507776994441 
2016-12-12 20:02:00 Valid Error = 0.18757019842756 
2016-12-12 20:02:00 Valid Loss = 0.0060828508031764 
2016-12-12 20:02:06 Test Error = 0.19198383294038 
2016-12-12 20:02:06 Test Loss = 0.0060290722059497 
2016-12-12 20:02:06 -------------------LR------------------- 
2016-12-12 20:02:06 0.0078125 
2016-12-12 20:02:06 Epoch 66 
2016-12-12 20:07:45 Training Error = 0.14795706083049 
2016-12-12 20:07:45 Training Loss = 0.0092090194685997 
2016-12-12 20:07:52 Valid Error = 0.43242231374017 
2016-12-12 20:07:52 Valid Loss = 0.011407662465983 
2016-12-12 20:07:58 Test Error = 0.41966992253284 
2016-12-12 20:07:58 Test Loss = 0.011258699048065 
2016-12-12 20:07:58 -------------------LR------------------- 
2016-12-12 20:07:58 0.0078125 
2016-12-12 20:07:58 Epoch 67 
2016-12-12 20:13:31 Training Error = 0.14616792876758 
2016-12-12 20:13:31 Training Loss = 0.0092579552916903 
2016-12-12 20:13:37 Valid Error = 0.28453762635717 
2016-12-12 20:13:37 Valid Loss = 0.0087564956815555 
2016-12-12 20:13:43 Test Error = 0.27820815089256 
2016-12-12 20:13:43 Test Loss = 0.0085706225197989 
2016-12-12 20:13:43 -------------------LR------------------- 
2016-12-12 20:13:43 0.0078125 
2016-12-12 20:13:43 Epoch 68 
2016-12-12 20:19:17 Training Error = 0.14654239826912 
2016-12-12 20:19:17 Training Loss = 0.0091248231393935 
2016-12-12 20:19:24 Valid Error = 0.23099962560839 
2016-12-12 20:19:24 Valid Loss = 0.0069150355078527 
2016-12-12 20:19:30 Test Error = 0.22196025597844 
2016-12-12 20:19:30 Test Loss = 0.0068128607829209 
2016-12-12 20:19:30 -------------------LR------------------- 
2016-12-12 20:19:30 0.0078125 
2016-12-12 20:19:30 Epoch 69 
2016-12-12 20:24:56 Training Error = 0.14591828243322 
2016-12-12 20:24:56 Training Loss = 0.0091556563591513 
2016-12-12 20:25:02 Valid Error = 0.17184575065519 
2016-12-12 20:25:02 Valid Loss = 0.0051474467642171 
2016-12-12 20:25:08 Test Error = 0.16908049848434 
2016-12-12 20:25:08 Test Loss = 0.0050547680636776 
2016-12-12 20:25:08 -------------------LR------------------- 
2016-12-12 20:25:08 0.0078125 
2016-12-12 20:25:08 Epoch 70 
2016-12-12 20:30:41 Training Error = 0.14562702837647 
2016-12-12 20:30:41 Training Loss = 0.0091305093121708 
2016-12-12 20:30:48 Valid Error = 0.18831898165481 
2016-12-12 20:30:48 Valid Loss = 0.006248751013934 
2016-12-12 20:30:54 Test Error = 0.18895250926238 
2016-12-12 20:30:54 Test Loss = 0.0061541009390537 
2016-12-12 20:30:54 -------------------LR------------------- 
2016-12-12 20:30:54 0.0078125 
2016-12-12 20:30:54 Epoch 71 
2016-12-12 20:36:29 Training Error = 0.14500291254057 
2016-12-12 20:36:29 Training Loss = 0.0091201144515342 
2016-12-12 20:36:36 Valid Error = 0.16473230999626 
2016-12-12 20:36:36 Valid Loss = 0.0053605807730504 
2016-12-12 20:36:42 Test Error = 0.16470191983833 
2016-12-12 20:36:42 Test Loss = 0.0053961817671532 
2016-12-12 20:36:42 -------------------LR------------------- 
2016-12-12 20:36:42 0.0078125 
2016-12-12 20:36:42 Epoch 72 
2016-12-12 20:42:17 Training Error = 0.14462844303903 
2016-12-12 20:42:17 Training Loss = 0.0090893693458676 
2016-12-12 20:42:24 Valid Error = 0.2594533882441 
2016-12-12 20:42:24 Valid Loss = 0.007735767366434 
2016-12-12 20:42:30 Test Error = 0.24722128662849 
2016-12-12 20:42:30 Test Loss = 0.0075711295836295 
2016-12-12 20:42:30 -------------------LR------------------- 
2016-12-12 20:42:30 0.0078125 
2016-12-12 20:42:30 Epoch 73 
2016-12-12 20:48:05 Training Error = 0.14267288008654 
2016-12-12 20:48:05 Training Loss = 0.0091010983305352 
2016-12-12 20:48:12 Valid Error = 0.21265443654062 
2016-12-12 20:48:12 Valid Loss = 0.0069304090418706 
2016-12-12 20:48:18 Test Error = 0.20613001010441 
2016-12-12 20:48:18 Test Loss = 0.0068072707680168 
2016-12-12 20:48:18 -------------------LR------------------- 
2016-12-12 20:48:18 0.0078125 
2016-12-12 20:48:18 Epoch 74 
2016-12-12 20:53:51 Training Error = 0.14217358741782 
2016-12-12 20:53:51 Training Loss = 0.0090241409966556 
2016-12-12 20:53:58 Valid Error = 0.21527517783602 
2016-12-12 20:53:58 Valid Loss = 0.0067248449104117 
2016-12-12 20:54:04 Test Error = 0.21219265746042 
2016-12-12 20:54:04 Test Loss = 0.0066232371130267 
2016-12-12 20:54:04 -------------------LR------------------- 
2016-12-12 20:54:04 0.0078125 
2016-12-12 20:54:04 Epoch 75 
2016-12-12 20:59:40 Training Error = 0.14088374802363 
2016-12-12 20:59:40 Training Loss = 0.0089908322527717 
2016-12-12 20:59:46 Valid Error = 0.16847622613253 
2016-12-12 20:59:46 Valid Loss = 0.0049792855518137 
2016-12-12 20:59:52 Test Error = 0.16672280229033 
2016-12-12 20:59:52 Test Loss = 0.0049853555610687 
2016-12-12 20:59:52 -------------------LR------------------- 
2016-12-12 20:59:52 0.0078125 
2016-12-12 20:59:52 Epoch 76 
2016-12-12 21:05:40 Training Error = 0.14362985770159 
2016-12-12 21:05:40 Training Loss = 0.0091001175789135 
2016-12-12 21:05:47 Valid Error = 0.1666042680644 
2016-12-12 21:05:47 Valid Loss = 0.0049661227923235 
2016-12-12 21:05:53 Test Error = 0.16604917480633 
2016-12-12 21:05:53 Test Loss = 0.0050045784143954 
2016-12-12 21:05:53 -------------------LR------------------- 
2016-12-12 21:05:53 0.0078125 
2016-12-12 21:05:53 Epoch 77 
2016-12-12 21:11:30 Training Error = 0.14221519514022 
2016-12-12 21:11:30 Training Loss = 0.0090207186765496 
2016-12-12 21:11:37 Valid Error = 0.22276301010857 
2016-12-12 21:11:37 Valid Loss = 0.0072388520207216 
2016-12-12 21:11:43 Test Error = 0.22162344223644 
2016-12-12 21:11:43 Test Loss = 0.0071106976391174 
2016-12-12 21:11:43 -------------------LR------------------- 
2016-12-12 21:11:43 0.0078125 
2016-12-12 21:11:43 Epoch 78 
2016-12-12 21:17:15 Training Error = 0.14009320129816 
2016-12-12 21:17:15 Training Loss = 0.0089700869358992 
2016-12-12 21:17:22 Valid Error = 0.16922500935979 
2016-12-12 21:17:22 Valid Loss = 0.0054463250471495 
2016-12-12 21:17:28 Test Error = 0.16807005725834 
2016-12-12 21:17:28 Test Loss = 0.0053745426855239 
2016-12-12 21:17:28 -------------------LR------------------- 
2016-12-12 21:17:28 0.0078125 
2016-12-12 21:17:28 Epoch 79 
2016-12-12 21:23:00 Training Error = 0.14059249396688 
2016-12-12 21:23:00 Training Loss = 0.0088664280774102 
2016-12-12 21:23:07 Valid Error = 0.16211156870086 
2016-12-12 21:23:07 Valid Loss = 0.0049460880848413 
2016-12-12 21:23:13 Test Error = 0.15964971370832 
2016-12-12 21:23:13 Test Loss = 0.0049002331167181 
2016-12-12 21:23:13 -------------------LR------------------- 
2016-12-12 21:23:13 0.0078125 
2016-12-12 21:23:13 Epoch 80 
2016-12-12 21:28:47 Training Error = 0.13901140051594 
2016-12-12 21:28:47 Training Loss = 0.0089583218071647 
2016-12-12 21:28:53 Valid Error = 0.17858479970049 
2016-12-12 21:28:53 Valid Loss = 0.0055064071349703 
2016-12-12 21:28:59 Test Error = 0.17649040080835 
2016-12-12 21:28:59 Test Loss = 0.0054710131749035 
2016-12-12 21:28:59 -------------------LR------------------- 
2016-12-12 21:28:59 0.0078125 
2016-12-12 21:29:00 Epoch 81 
2016-12-12 21:34:41 Training Error = 0.13813763834568 
2016-12-12 21:34:41 Training Loss = 0.0089231189953372 
2016-12-12 21:34:48 Valid Error = 0.14938225383751 
2016-12-12 21:34:48 Valid Loss = 0.0051008228312766 
2016-12-12 21:34:54 Test Error = 0.15594476254631 
2016-12-12 21:34:54 Test Loss = 0.0051651729951984 
2016-12-12 21:34:54 -------------------LR------------------- 
2016-12-12 21:34:54 0.0078125 
2016-12-12 21:34:54 Epoch 82 
2016-12-12 21:40:30 Training Error = 0.13976033951901 
2016-12-12 21:40:30 Training Loss = 0.0089213924624241 
2016-12-12 21:40:37 Valid Error = 0.16735305129165 
2016-12-12 21:40:37 Valid Loss = 0.0051536683319786 
2016-12-12 21:40:43 Test Error = 0.16402829235433 
2016-12-12 21:40:43 Test Loss = 0.0051064576798418 
2016-12-12 21:40:43 -------------------LR------------------- 
2016-12-12 21:40:43 0.0078125 
2016-12-12 21:40:43 Epoch 83 
2016-12-12 21:46:22 Training Error = 0.13663976033952 
2016-12-12 21:46:22 Training Loss = 0.008824630004136 
2016-12-12 21:46:28 Valid Error = 0.15087982029203 
2016-12-12 21:46:28 Valid Loss = 0.0045482676718003 
2016-12-12 21:46:34 Test Error = 0.1512293701583 
2016-12-12 21:46:34 Test Loss = 0.0045476543282015 
2016-12-12 21:46:34 -------------------LR------------------- 
2016-12-12 21:46:34 0.0078125 
2016-12-12 21:46:34 Epoch 84 
2016-12-12 21:52:01 Training Error = 0.13626529083798 
2016-12-12 21:52:01 Training Loss = 0.0087907993304465 
2016-12-12 21:52:08 Valid Error = 0.16136278547361 
2016-12-12 21:52:08 Valid Loss = 0.0046402855188387 
2016-12-12 21:52:14 Test Error = 0.15762883125632 
2016-12-12 21:52:14 Test Loss = 0.0046542060426991 
2016-12-12 21:52:14 -------------------LR------------------- 
2016-12-12 21:52:14 0.0078125 
2016-12-12 21:52:14 Epoch 85 
2016-12-12 21:57:53 Training Error = 0.1355163518349 
2016-12-12 21:57:53 Training Loss = 0.0088537060185556 
2016-12-12 21:58:00 Valid Error = 0.21003369524523 
2016-12-12 21:58:00 Valid Loss = 0.006371252445299 
2016-12-12 21:58:06 Test Error = 0.20276187268441 
2016-12-12 21:58:06 Test Loss = 0.0062844469390898 
2016-12-12 21:58:06 -------------------LR------------------- 
2016-12-12 21:58:06 0.0078125 
2016-12-12 21:58:06 Epoch 86 
2016-12-12 22:03:41 Training Error = 0.13559956727969 
2016-12-12 22:03:41 Training Loss = 0.0088324734187536 
2016-12-12 22:03:48 Valid Error = 0.36053912392362 
2016-12-12 22:03:48 Valid Loss = 0.010356053014413 
2016-12-12 22:03:54 Test Error = 0.34186594813068 
2016-12-12 22:03:54 Test Loss = 0.010159309771856 
2016-12-12 22:03:54 -------------------LR------------------- 
2016-12-12 22:03:54 0.0078125 
2016-12-12 22:03:54 Epoch 87 
2016-12-12 22:09:36 Training Error = 0.13451776649746 
2016-12-12 22:09:36 Training Loss = 0.0088379678496923 
2016-12-12 22:09:43 Valid Error = 0.19318607263197 
2016-12-12 22:09:43 Valid Loss = 0.0060210598582303 
2016-12-12 22:09:49 Test Error = 0.19164701919838 
2016-12-12 22:09:49 Test Loss = 0.0059891141495013 
2016-12-12 22:09:49 -------------------LR------------------- 
2016-12-12 22:09:49 0.0078125 
2016-12-12 22:09:49 Epoch 88 
2016-12-12 22:15:16 Training Error = 0.13526670550054 
2016-12-12 22:15:16 Training Loss = 0.0088076798203745 
2016-12-12 22:15:23 Valid Error = 0.16211156870086 
2016-12-12 22:15:23 Valid Loss = 0.004641467347538 
2016-12-12 22:15:29 Test Error = 0.15863927248232 
2016-12-12 22:15:29 Test Loss = 0.0046183656220684 
2016-12-12 22:15:29 -------------------LR------------------- 
2016-12-12 22:15:29 0.0078125 
2016-12-12 22:15:29 Epoch 89 
2016-12-12 22:21:04 Training Error = 0.1343097278855 
2016-12-12 22:21:04 Training Loss = 0.0087705988239222 
2016-12-12 22:21:10 Valid Error = 0.15275177836016 
2016-12-12 22:21:10 Valid Loss = 0.0046678881785954 
2016-12-12 22:21:16 Test Error = 0.15493432132031 
2016-12-12 22:21:16 Test Loss = 0.0047695170723801 
2016-12-12 22:21:16 -------------------LR------------------- 
2016-12-12 22:21:16 0.0078125 
2016-12-12 22:21:16 Epoch 90 
2016-12-12 22:26:48 Training Error = 0.13347757343763 
2016-12-12 22:26:48 Training Loss = 0.0087500684008838 
2016-12-12 22:26:54 Valid Error = 0.17259453388244 
2016-12-12 22:26:54 Valid Loss = 0.0051118588156958 
2016-12-12 22:27:01 Test Error = 0.17076456719434 
2016-12-12 22:27:01 Test Loss = 0.0051098707416956 
2016-12-12 22:27:01 -------------------LR------------------- 
2016-12-12 22:27:01 0.0078125 
2016-12-12 22:27:01 Epoch 91 
2016-12-12 22:32:26 Training Error = 0.13335275027045 
2016-12-12 22:32:26 Training Loss = 0.0087147543586033 
2016-12-12 22:32:33 Valid Error = 0.16697865967802 
2016-12-12 22:32:33 Valid Loss = 0.0050482928637864 
2016-12-12 22:32:39 Test Error = 0.16234422364432 
2016-12-12 22:32:39 Test Loss = 0.0050123564692834 
2016-12-12 22:32:39 -------------------LR------------------- 
2016-12-12 22:32:39 0.0078125 
2016-12-12 22:32:39 Epoch 92 
2016-12-12 22:38:18 Training Error = 0.13397686610635 
2016-12-12 22:38:18 Training Loss = 0.0087107150932687 
2016-12-12 22:38:25 Valid Error = 0.16997379258705 
2016-12-12 22:38:25 Valid Loss = 0.0057056247086475 
2016-12-12 22:38:31 Test Error = 0.16739642977433 
2016-12-12 22:38:31 Test Loss = 0.0056323461675006 
2016-12-12 22:38:31 -------------------LR------------------- 
2016-12-12 22:38:31 0.0078125 
2016-12-12 22:38:31 Epoch 93 
2016-12-12 22:44:08 Training Error = 0.13277024215694 
2016-12-12 22:44:08 Training Loss = 0.0087244850139969 
2016-12-12 22:44:15 Valid Error = 0.15162860351928 
2016-12-12 22:44:15 Valid Loss = 0.0044954879620858 
2016-12-12 22:44:21 Test Error = 0.15257662512631 
2016-12-12 22:44:21 Test Loss = 0.0045464027907331 
2016-12-12 22:44:21 -------------------LR------------------- 
2016-12-12 22:44:21 0.0078125 
2016-12-12 22:44:21 Epoch 94 
2016-12-12 22:49:50 Training Error = 0.13156361820754 
2016-12-12 22:49:50 Training Loss = 0.008701913112282 
2016-12-12 22:49:57 Valid Error = 0.20217147135904 
2016-12-12 22:49:57 Valid Loss = 0.0055495108240119 
2016-12-12 22:50:03 Test Error = 0.1977096665544 
2016-12-12 22:50:03 Test Loss = 0.0055739861137686 
2016-12-12 22:50:03 -------------------LR------------------- 
2016-12-12 22:50:03 0.0078125 
2016-12-12 22:50:03 Epoch 95 
2016-12-12 22:55:45 Training Error = 0.13252059582258 
2016-12-12 22:55:45 Training Loss = 0.0086911387027296 
2016-12-12 22:55:52 Valid Error = 0.19767877199551 
2016-12-12 22:55:52 Valid Loss = 0.0061823593767023 
2016-12-12 22:55:58 Test Error = 0.19636241158639 
2016-12-12 22:55:58 Test Loss = 0.0060578657118245 
2016-12-12 22:55:58 -------------------LR------------------- 
2016-12-12 22:55:58 0.0078125 
2016-12-12 22:55:58 Epoch 96 
2016-12-12 23:01:27 Training Error = 0.13197969543147 
2016-12-12 23:01:27 Training Loss = 0.0086488677346816 
2016-12-12 23:01:34 Valid Error = 0.15537251965556 
2016-12-12 23:01:34 Valid Loss = 0.0049001933047041 
2016-12-12 23:01:40 Test Error = 0.15796564499832 
2016-12-12 23:01:40 Test Loss = 0.0048943081889489 
2016-12-12 23:01:40 -------------------LR------------------- 
2016-12-12 23:01:40 0.0078125 
2016-12-12 23:01:40 Epoch 97 
2016-12-12 23:07:25 Training Error = 0.13139718731797 
2016-12-12 23:07:25 Training Loss = 0.0086979208972161 
2016-12-12 23:07:32 Valid Error = 0.20142268813179 
2016-12-12 23:07:32 Valid Loss = 0.0053569322708775 
2016-12-12 23:07:38 Test Error = 0.19568878410239 
2016-12-12 23:07:38 Test Loss = 0.0051428920702565 
2016-12-12 23:07:38 -------------------LR------------------- 
2016-12-12 23:07:38 0.0078125 
2016-12-12 23:07:38 Epoch 98 
2016-12-12 23:13:07 Training Error = 0.13131397187318 
2016-12-12 23:13:07 Training Loss = 0.008643295189659 
2016-12-12 23:13:14 Valid Error = 0.15761886933733 
2016-12-12 23:13:14 Valid Loss = 0.0046466272046618 
2016-12-12 23:13:20 Test Error = 0.15628157628831 
2016-12-12 23:13:20 Test Loss = 0.0046659535376669 
2016-12-12 23:13:20 -------------------LR------------------- 
2016-12-12 23:13:20 0.0078125 
2016-12-12 23:13:20 Epoch 99 
2016-12-12 23:18:58 Training Error = 0.13127236415079 
2016-12-12 23:18:58 Training Loss = 0.0085894733739862 
2016-12-12 23:19:05 Valid Error = 0.18494945713216 
2016-12-12 23:19:05 Valid Loss = 0.0054442502906682 
2016-12-12 23:19:11 Test Error = 0.18120579319636 
2016-12-12 23:19:11 Test Loss = 0.0053763677523685 
2016-12-12 23:19:11 -------------------LR------------------- 
2016-12-12 23:19:11 0.0078125 
2016-12-12 23:19:11 Epoch 100 
2016-12-12 23:24:39 Training Error = 0.13231255721062 
2016-12-12 23:24:39 Training Loss = 0.0086513144842346 
2016-12-12 23:24:45 Valid Error = 0.15799326095095 
2016-12-12 23:24:45 Valid Loss = 0.0045383044101796 
2016-12-12 23:24:51 Test Error = 0.1515661839003 
2016-12-12 23:24:51 Test Loss = 0.0045103440379895 
2016-12-12 23:24:51 -------------------LR------------------- 
2016-12-12 23:24:51 0.00390625 
2016-12-12 23:24:51 Epoch 101 
2016-12-12 23:30:29 Training Error = 0.13052342514771 
2016-12-12 23:30:29 Training Loss = 0.0084334400199508 
2016-12-12 23:30:35 Valid Error = 0.16697865967802 
2016-12-12 23:30:35 Valid Loss = 0.0049198781434995 
2016-12-12 23:30:41 Test Error = 0.16503873358033 
2016-12-12 23:30:41 Test Loss = 0.0048992204942853 
2016-12-12 23:30:41 -------------------LR------------------- 
2016-12-12 23:30:41 0.00390625 
2016-12-12 23:30:41 Epoch 102 
2016-12-12 23:36:12 Training Error = 0.13010734792377 
2016-12-12 23:36:12 Training Loss = 0.0084602373899857 
2016-12-12 23:36:19 Valid Error = 0.14676151254212 
2016-12-12 23:36:19 Valid Loss = 0.0041914703010372 
2016-12-12 23:36:25 Test Error = 0.14550353654429 
2016-12-12 23:36:25 Test Loss = 0.0042021716550913 
2016-12-12 23:36:25 -------------------LR------------------- 
2016-12-12 23:36:25 0.00390625 
2016-12-12 23:36:25 Epoch 103 
2016-12-12 23:42:09 Training Error = 0.12960805525506 
2016-12-12 23:42:09 Training Loss = 0.0084798764383138 
2016-12-12 23:42:15 Valid Error = 0.18083114938225 
2016-12-12 23:42:15 Valid Loss = 0.0052089924649996 
2016-12-12 23:42:21 Test Error = 0.16705961603233 
2016-12-12 23:42:21 Test Loss = 0.0050837409607404 
2016-12-12 23:42:21 -------------------LR------------------- 
2016-12-12 23:42:21 0.00390625 
2016-12-12 23:42:21 Epoch 104 
2016-12-12 23:47:47 Training Error = 0.12969127069984 
2016-12-12 23:47:47 Training Loss = 0.008470980773674 
2016-12-12 23:47:54 Valid Error = 0.16435791838263 
2016-12-12 23:47:54 Valid Loss = 0.0049770408158726 
2016-12-12 23:48:00 Test Error = 0.15661839003031 
2016-12-12 23:48:00 Test Loss = 0.0048679235283428 
2016-12-12 23:48:00 -------------------LR------------------- 
2016-12-12 23:48:00 0.00390625 
2016-12-12 23:48:00 Epoch 105 
2016-12-12 23:53:35 Training Error = 0.13089789464925 
2016-12-12 23:53:35 Training Loss = 0.0084689245099472 
2016-12-12 23:53:42 Valid Error = 0.15013103706477 
2016-12-12 23:53:42 Valid Loss = 0.0042950231318249 
2016-12-12 23:53:48 Test Error = 0.1478612327383 
2016-12-12 23:53:48 Test Loss = 0.0042997634571449 
2016-12-12 23:53:48 -------------------LR------------------- 
2016-12-12 23:53:48 0.00390625 
2016-12-12 23:53:48 Epoch 106 
2016-12-12 23:59:19 Training Error = 0.12919197803112 
2016-12-12 23:59:19 Training Loss = 0.0084553430889786 
2016-12-12 23:59:25 Valid Error = 0.14264320479221 
2016-12-12 23:59:25 Valid Loss = 0.0043534397505449 
2016-12-12 23:59:31 Test Error = 0.14449309531829 
2016-12-12 23:59:31 Test Loss = 0.0043756301476141 
2016-12-12 23:59:31 -------------------LR------------------- 
2016-12-12 23:59:31 0.00390625 
2016-12-12 23:59:32 Epoch 107 
2016-12-13 00:05:02 Training Error = 0.12898393941916 
2016-12-13 00:05:02 Training Loss = 0.0084707958526295 
2016-12-13 00:05:09 Valid Error = 0.15574691126919 
2016-12-13 00:05:09 Valid Loss = 0.0043218834319707 
2016-12-13 00:05:15 Test Error = 0.1502189289323 
2016-12-13 00:05:15 Test Loss = 0.0043139056818986 
2016-12-13 00:05:15 -------------------LR------------------- 
2016-12-13 00:05:15 0.00390625 
2016-12-13 00:05:15 Epoch 108 
2016-12-13 00:10:54 Training Error = 0.12827660813847 
2016-12-13 00:10:54 Training Loss = 0.0084710329253428 
2016-12-13 00:11:01 Valid Error = 0.15424934481468 
2016-12-13 00:11:01 Valid Loss = 0.0043961098017356 
2016-12-13 00:11:07 Test Error = 0.15426069383631 
2016-12-13 00:11:07 Test Loss = 0.0044377612879195 
2016-12-13 00:11:07 -------------------LR------------------- 
2016-12-13 00:11:07 0.00390625 
2016-12-13 00:11:07 Epoch 109 
2016-12-13 00:16:44 Training Error = 0.12923358575352 
2016-12-13 00:16:44 Training Loss = 0.0084195226256239 
2016-12-13 00:16:51 Valid Error = 0.24260576563085 
2016-12-13 00:16:51 Valid Loss = 0.0072931406210301 
2016-12-13 00:16:57 Test Error = 0.23172785449646 
2016-12-13 00:16:57 Test Loss = 0.0069887306499409 
2016-12-13 00:16:57 -------------------LR------------------- 
2016-12-13 00:16:57 0.00390625 
2016-12-13 00:16:57 Epoch 110 
2016-12-13 00:22:22 Training Error = 0.12890072397437 
2016-12-13 00:22:22 Training Loss = 0.008492246182469 
2016-12-13 00:22:29 Valid Error = 0.28416323474354 
2016-12-13 00:22:29 Valid Loss = 0.0090900355239798 
2016-12-13 00:22:35 Test Error = 0.27551364095655 
2016-12-13 00:22:35 Test Loss = 0.0087515208601931 
2016-12-13 00:22:35 -------------------LR------------------- 
2016-12-13 00:22:35 0.00390625 
2016-12-13 00:22:35 Epoch 111 
2016-12-13 00:28:11 Training Error = 0.1305650328701 
2016-12-13 00:28:11 Training Loss = 0.0084743736213096 
2016-12-13 00:28:18 Valid Error = 0.17821040808686 
2016-12-13 00:28:18 Valid Loss = 0.0052247527803926 
2016-12-13 00:28:24 Test Error = 0.17076456719434 
2016-12-13 00:28:24 Test Loss = 0.0051965186710721 
2016-12-13 00:28:24 -------------------LR------------------- 
2016-12-13 00:28:24 0.00390625 
2016-12-13 00:28:24 Epoch 112 
2016-12-13 00:33:57 Training Error = 0.12885911625198 
2016-12-13 00:33:57 Training Loss = 0.0083900075222953 
2016-12-13 00:34:03 Valid Error = 0.14713590415575 
2016-12-13 00:34:03 Valid Loss = 0.0043357262628831 
2016-12-13 00:34:09 Test Error = 0.14617716402829 
2016-12-13 00:34:09 Test Loss = 0.0043456681905035 
2016-12-13 00:34:09 -------------------LR------------------- 
2016-12-13 00:34:09 0.00390625 
2016-12-13 00:34:09 Epoch 113 
2016-12-13 00:39:51 Training Error = 0.12923358575352 
2016-12-13 00:39:51 Training Loss = 0.0084293672853875 
2016-12-13 00:39:58 Valid Error = 0.3212280044927 
2016-12-13 00:39:58 Valid Loss = 0.0097777617070365 
2016-12-13 00:40:04 Test Error = 0.31896261367464 
2016-12-13 00:40:04 Test Loss = 0.0096290614848681 
2016-12-13 00:40:04 -------------------LR------------------- 
2016-12-13 00:40:04 0.00390625 
2016-12-13 00:40:04 Epoch 114 
2016-12-13 00:45:43 Training Error = 0.12915037030873 
2016-12-13 00:45:43 Training Loss = 0.0084135053667969 
2016-12-13 00:45:50 Valid Error = 0.14451516286035 
2016-12-13 00:45:50 Valid Loss = 0.0042790722447809 
2016-12-13 00:45:56 Test Error = 0.13977770293028 
2016-12-13 00:45:56 Test Loss = 0.0042156950166982 
2016-12-13 00:45:56 -------------------LR------------------- 
2016-12-13 00:45:56 0.00390625 
2016-12-13 00:45:56 Epoch 115 
2016-12-13 00:51:28 Training Error = 0.12940001664309 
2016-12-13 00:51:28 Training Loss = 0.0083884225304197 
2016-12-13 00:51:34 Valid Error = 0.14900786222389 
2016-12-13 00:51:34 Valid Loss = 0.0042900931671327 
2016-12-13 00:51:41 Test Error = 0.14280902660829 
2016-12-13 00:51:41 Test Loss = 0.0042560076792925 
2016-12-13 00:51:41 -------------------LR------------------- 
2016-12-13 00:51:41 0.00390625 
2016-12-13 00:51:41 Epoch 116 
2016-12-13 00:57:14 Training Error = 0.12860946991762 
2016-12-13 00:57:14 Training Loss = 0.0084219049872747 
2016-12-13 00:57:21 Valid Error = 0.15499812804193 
2016-12-13 00:57:21 Valid Loss = 0.004447873969519 
2016-12-13 00:57:27 Test Error = 0.1519029976423 
2016-12-13 00:57:27 Test Loss = 0.004428894754356 
2016-12-13 00:57:27 -------------------LR------------------- 
2016-12-13 00:57:27 0.00390625 
2016-12-13 00:57:27 Epoch 117 
2016-12-13 01:02:56 Training Error = 0.1287342930848 
2016-12-13 01:02:56 Training Loss = 0.0084573702927737 
2016-12-13 01:03:03 Valid Error = 0.15612130288282 
2016-12-13 01:03:03 Valid Loss = 0.0050755250466363 
2016-12-13 01:03:09 Test Error = 0.16032334119232 
2016-12-13 01:03:09 Test Loss = 0.0050723703581961 
2016-12-13 01:03:09 -------------------LR------------------- 
2016-12-13 01:03:09 0.00390625 
2016-12-13 01:03:09 Epoch 118 
2016-12-13 01:08:46 Training Error = 0.12852625447283 
2016-12-13 01:08:46 Training Loss = 0.0084003990837812 
2016-12-13 01:08:53 Valid Error = 0.17633845001872 
2016-12-13 01:08:53 Valid Loss = 0.0056433858071626 
2016-12-13 01:08:59 Test Error = 0.17817446951836 
2016-12-13 01:08:59 Test Loss = 0.0056225455882804 
2016-12-13 01:08:59 -------------------LR------------------- 
2016-12-13 01:08:59 0.00390625 
2016-12-13 01:08:59 Epoch 119 
2016-12-13 01:14:29 Training Error = 0.12877590080719 
2016-12-13 01:14:29 Training Loss = 0.0083614180891418 
2016-12-13 01:14:36 Valid Error = 0.196181205541 
2016-12-13 01:14:36 Valid Loss = 0.0051674639509995 
2016-12-13 01:14:42 Test Error = 0.19400471539239 
2016-12-13 01:14:42 Test Loss = 0.0051077153564174 
2016-12-13 01:14:42 -------------------LR------------------- 
2016-12-13 01:14:42 0.00390625 
2016-12-13 01:14:42 Epoch 120 
