2016-12-10 01:58:09 [program started on Sat Dec 10 01:58:09 2016] 
2016-12-10 01:58:09 [command line arguments] 
2016-12-10 01:58:09 stcWeights false 
2016-12-10 01:58:09 LR 0.015625 
2016-12-10 01:58:09 batchSize 100 
2016-12-10 01:58:09 network ./Models/Cifar10_Custom 
2016-12-10 01:58:09 stcNeurons true 
2016-12-10 01:58:09 constBatchSize false 
2016-12-10 01:58:09 chartFileName chart1 
2016-12-10 01:58:09 dp_prepro false 
2016-12-10 01:58:09 nGPU 1 
2016-12-10 01:58:09 dataset Caltech256 
2016-12-10 01:58:09 type cuda 
2016-12-10 01:58:09 momentum 0 
2016-12-10 01:58:09 threads 8 
2016-12-10 01:58:09 weightDecay 0 
2016-12-10 01:58:09 runningVal false 
2016-12-10 01:58:09 convLayerN 6 
2016-12-10 01:58:09 LRDecay 0 
2016-12-10 01:58:09 numHid 2048 
2016-12-10 01:58:09 save /dev/shm/clone/temp/th/Results/Caltech256/model6-10-2048 
2016-12-10 01:58:09 augment false 
2016-12-10 01:58:09 epoch -1 
2016-12-10 01:58:09 modelsFolder ./Models/ 
2016-12-10 01:58:09 format rgb 
2016-12-10 01:58:09 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 01:58:09 imageFileExtension svg 
2016-12-10 01:58:09 channel 1 
2016-12-10 01:58:09 devid 14 
2016-12-10 01:58:09 visualize 1 
2016-12-10 01:58:09 LRDecayPerEpoch 0.0001 
2016-12-10 01:58:09 optimization adam 
2016-12-10 01:58:09 SBN true 
2016-12-10 01:58:09 normalization simple 
2016-12-10 01:58:09 title model1 
2016-12-10 01:58:09 load  
2016-12-10 01:58:09 whiten true 
2016-12-10 01:58:09 [----------------------] 
2016-12-10 01:58:11 ==> Network 
2016-12-10 01:58:11 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 2048)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(2048 -> 2048)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(2048 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-10 01:58:11 ==>26086781 Parameters 
2016-12-10 01:58:11 ==> Loss 
2016-12-10 01:58:11 SqrtHingeEmbeddingCriterion 
2016-12-10 01:58:11 
==> Starting Training
 
2016-12-10 01:58:11 Epoch 1 
2016-12-10 02:03:59 Training Error = 0.96550719813597 
2016-12-10 02:03:59 Training Loss = 0.1639195671337 
2016-12-10 02:04:05 Valid Error = 0.96143766379633 
2016-12-10 02:04:05 Valid Loss = 0.016385865514512 
2016-12-10 02:04:11 Test Error = 0.97541259683395 
2016-12-10 02:04:11 Test Loss = 0.016229101742304 
2016-12-10 02:04:11 -------------------LR------------------- 
2016-12-10 02:04:11 0.015625 
2016-12-10 02:04:11 Epoch 2 
2016-12-10 02:09:43 Training Error = 0.93842057085795 
2016-12-10 02:09:43 Training Loss = 0.015805751794896 
2016-12-10 02:09:49 Valid Error = 0.95919131411456 
2016-12-10 02:09:49 Valid Loss = 0.015851139926732 
2016-12-10 02:09:56 Test Error = 0.97238127315594 
2016-12-10 02:09:56 Test Loss = 0.015805907649259 
2016-12-10 02:09:56 -------------------LR------------------- 
2016-12-10 02:09:56 0.015625 
2016-12-10 02:09:56 Epoch 3 
2016-12-10 02:15:18 Training Error = 0.93105600399434 
2016-12-10 02:15:18 Training Loss = 0.015536898943967 
2016-12-10 02:15:24 Valid Error = 0.95731935604642 
2016-12-10 02:15:24 Valid Loss = 0.015568836326599 
2016-12-10 02:15:31 Test Error = 0.96934994947794 
2016-12-10 02:15:31 Test Loss = 0.015594851203262 
2016-12-10 02:15:31 -------------------LR------------------- 
2016-12-10 02:15:31 0.015625 
2016-12-10 02:15:31 Epoch 4 
2016-12-10 02:20:56 Training Error = 0.91536989265208 
2016-12-10 02:20:56 Training Loss = 0.015357343008384 
2016-12-10 02:21:02 Valid Error = 0.98128041931861 
2016-12-10 02:21:02 Valid Loss = 0.015800121373353 
2016-12-10 02:21:08 Test Error = 0.98181205793196 
2016-12-10 02:21:08 Test Loss = 0.015766716334842 
2016-12-10 02:21:08 -------------------LR------------------- 
2016-12-10 02:21:08 0.015625 
2016-12-10 02:21:08 Epoch 5 
2016-12-10 02:26:31 Training Error = 0.90446866938504 
2016-12-10 02:26:31 Training Loss = 0.01502886175279 
2016-12-10 02:26:37 Valid Error = 0.96967427929614 
2016-12-10 02:26:37 Valid Loss = 0.015686360427991 
2016-12-10 02:26:44 Test Error = 0.96092960592792 
2016-12-10 02:26:44 Test Loss = 0.015652303866413 
2016-12-10 02:26:44 -------------------LR------------------- 
2016-12-10 02:26:44 0.015625 
2016-12-10 02:26:44 Epoch 6 
2016-12-10 02:32:08 Training Error = 0.88283265374053 
2016-12-10 02:32:08 Training Loss = 0.014804141066411 
2016-12-10 02:32:14 Valid Error = 0.93934855859229 
2016-12-10 02:32:14 Valid Loss = 0.015778718824306 
2016-12-10 02:32:20 Test Error = 0.94577298753789 
2016-12-10 02:32:20 Test Loss = 0.015967456566349 
2016-12-10 02:32:20 -------------------LR------------------- 
2016-12-10 02:32:20 0.015625 
2016-12-10 02:32:21 Epoch 7 
2016-12-10 02:37:40 Training Error = 0.85466422568029 
2016-12-10 02:37:40 Training Loss = 0.01459378850046 
2016-12-10 02:37:46 Valid Error = 0.96929988768252 
2016-12-10 02:37:46 Valid Loss = 0.01576721382065 
2016-12-10 02:37:52 Test Error = 0.96867632199394 
2016-12-10 02:37:52 Test Loss = 0.015827050985336 
2016-12-10 02:37:52 -------------------LR------------------- 
2016-12-10 02:37:52 0.015625 
2016-12-10 02:37:52 Epoch 8 
2016-12-10 02:43:15 Training Error = 0.80648248314887 
2016-12-10 02:43:15 Training Loss = 0.014271183052127 
2016-12-10 02:43:21 Valid Error = 0.87832272557095 
2016-12-10 02:43:21 Valid Loss = 0.015407039778703 
2016-12-10 02:43:28 Test Error = 0.89558773997979 
2016-12-10 02:43:28 Test Loss = 0.015589757073372 
2016-12-10 02:43:28 -------------------LR------------------- 
2016-12-10 02:43:28 0.015625 
2016-12-10 02:43:28 Epoch 9 
2016-12-10 02:48:53 Training Error = 0.72451527003412 
2016-12-10 02:48:53 Training Loss = 0.013728802768643 
2016-12-10 02:48:59 Valid Error = 0.78659678023212 
2016-12-10 02:48:59 Valid Loss = 0.01440146944653 
2016-12-10 02:49:06 Test Error = 0.78073425395756 
2016-12-10 02:49:06 Test Loss = 0.01448448428282 
2016-12-10 02:49:06 -------------------LR------------------- 
2016-12-10 02:49:06 0.015625 
2016-12-10 02:49:06 Epoch 10 
2016-12-10 02:54:22 Training Error = 0.63447615877507 
2016-12-10 02:54:22 Training Loss = 0.013153254010339 
2016-12-10 02:54:28 Valid Error = 0.66005241482591 
2016-12-10 02:54:28 Valid Loss = 0.013183439258955 
2016-12-10 02:54:35 Test Error = 0.65308184573931 
2016-12-10 02:54:35 Test Loss = 0.013284698400184 
2016-12-10 02:54:35 -------------------LR------------------- 
2016-12-10 02:54:35 0.015625 
2016-12-10 02:54:36 Epoch 11 
2016-12-10 02:59:39 Training Error = 0.57102438212532 
2016-12-10 02:59:39 Training Loss = 0.012847761248626 
2016-12-10 02:59:45 Valid Error = 0.64395357543991 
2016-12-10 02:59:45 Valid Loss = 0.013401162696909 
2016-12-10 02:59:52 Test Error = 0.64735601212529 
2016-12-10 02:59:52 Test Loss = 0.01351243803865 
2016-12-10 02:59:52 -------------------LR------------------- 
2016-12-10 02:59:52 0.015625 
2016-12-10 02:59:52 Epoch 12 
2016-12-10 03:04:53 Training Error = 0.56574020138138 
2016-12-10 03:04:53 Training Loss = 0.012839204153867 
2016-12-10 03:04:59 Valid Error = 0.63609135155373 
2016-12-10 03:04:59 Valid Loss = 0.013200905103166 
2016-12-10 03:05:06 Test Error = 0.63388346244527 
2016-12-10 03:05:06 Test Loss = 0.01331075174372 
2016-12-10 03:05:06 -------------------LR------------------- 
2016-12-10 03:05:06 0.015625 
2016-12-10 03:05:06 Epoch 13 
2016-12-10 03:10:06 Training Error = 0.56736290255471 
2016-12-10 03:10:06 Training Loss = 0.012856209177688 
2016-12-10 03:10:12 Valid Error = 0.64507675028079 
2016-12-10 03:10:12 Valid Loss = 0.013279962681797 
2016-12-10 03:10:19 Test Error = 0.63590434489727 
2016-12-10 03:10:19 Test Loss = 0.013312474451032 
2016-12-10 03:10:19 -------------------LR------------------- 
2016-12-10 03:10:19 0.015625 
2016-12-10 03:10:19 Epoch 14 
2016-12-10 03:15:17 Training Error = 0.57131563618208 
2016-12-10 03:15:17 Training Loss = 0.012855970799922 
2016-12-10 03:15:23 Valid Error = 0.65406214900786 
2016-12-10 03:15:23 Valid Loss = 0.013371623991788 
2016-12-10 03:15:30 Test Error = 0.65712361064331 
2016-12-10 03:15:30 Test Loss = 0.01354047909493 
2016-12-10 03:15:30 -------------------LR------------------- 
2016-12-10 03:15:30 0.015625 
2016-12-10 03:15:30 Epoch 15 
2016-12-10 03:20:31 Training Error = 0.56881917283848 
2016-12-10 03:20:31 Training Loss = 0.012841103308789 
2016-12-10 03:20:37 Valid Error = 0.64732309996256 
2016-12-10 03:20:37 Valid Loss = 0.013257162562082 
2016-12-10 03:20:44 Test Error = 0.63893566857528 
2016-12-10 03:20:44 Test Loss = 0.013304223250656 
2016-12-10 03:20:44 -------------------LR------------------- 
2016-12-10 03:20:44 0.015625 
2016-12-10 03:20:44 Epoch 16 
2016-12-10 03:25:44 Training Error = 0.56936007322959 
2016-12-10 03:25:44 Training Loss = 0.012868503780674 
2016-12-10 03:25:50 Valid Error = 0.63908648446275 
2016-12-10 03:25:50 Valid Loss = 0.013490495088081 
2016-12-10 03:25:56 Test Error = 0.64365106096329 
2016-12-10 03:25:56 Test Loss = 0.013656417557316 
2016-12-10 03:25:56 -------------------LR------------------- 
2016-12-10 03:25:56 0.015625 
2016-12-10 03:25:56 Epoch 17 
2016-12-10 03:31:02 Training Error = 0.56678039444121 
2016-12-10 03:31:02 Training Loss = 0.012837994404366 
2016-12-10 03:31:08 Valid Error = 0.65031823287158 
2016-12-10 03:31:08 Valid Loss = 0.013461686486839 
2016-12-10 03:31:15 Test Error = 0.65341865948131 
2016-12-10 03:31:15 Test Loss = 0.013609214363123 
2016-12-10 03:31:15 -------------------LR------------------- 
2016-12-10 03:31:15 0.015625 
2016-12-10 03:31:15 Epoch 18 
2016-12-10 03:36:18 Training Error = 0.57069152034618 
2016-12-10 03:36:18 Training Loss = 0.012836231837979 
2016-12-10 03:36:24 Valid Error = 0.64507675028079 
2016-12-10 03:36:24 Valid Loss = 0.01319280530024 
2016-12-10 03:36:30 Test Error = 0.63960929605928 
2016-12-10 03:36:30 Test Loss = 0.013240418121636 
2016-12-10 03:36:30 -------------------LR------------------- 
2016-12-10 03:36:30 0.015625 
2016-12-10 03:36:30 Epoch 19 
2016-12-10 03:41:31 Training Error = 0.56877756511609 
2016-12-10 03:41:31 Training Loss = 0.012843954564038 
2016-12-10 03:41:37 Valid Error = 0.64994384125796 
2016-12-10 03:41:37 Valid Loss = 0.013385464593564 
2016-12-10 03:41:44 Test Error = 0.65375547322331 
2016-12-10 03:41:44 Test Loss = 0.013511612500148 
2016-12-10 03:41:44 -------------------LR------------------- 
2016-12-10 03:41:44 0.015625 
2016-12-10 03:41:44 Epoch 20 
2016-12-10 03:46:47 Training Error = 0.56536573187984 
2016-12-10 03:46:47 Training Loss = 0.012836688648647 
2016-12-10 03:46:53 Valid Error = 0.64170722575814 
2016-12-10 03:46:53 Valid Loss = 0.01327338422292 
2016-12-10 03:47:00 Test Error = 0.63994610980128 
2016-12-10 03:47:00 Test Loss = 0.013348609629894 
2016-12-10 03:47:00 -------------------LR------------------- 
2016-12-10 03:47:00 0.015625 
2016-12-10 03:47:00 Epoch 21 
2016-12-10 03:52:06 Training Error = 0.5699009736207 
2016-12-10 03:52:06 Training Loss = 0.012855534663657 
2016-12-10 03:52:12 Valid Error = 0.64095844253089 
2016-12-10 03:52:12 Valid Loss = 0.013169793584242 
2016-12-10 03:52:19 Test Error = 0.63826204109128 
2016-12-10 03:52:19 Test Loss = 0.013252884288375 
2016-12-10 03:52:19 -------------------LR------------------- 
2016-12-10 03:52:19 0.015625 
2016-12-10 03:52:19 Epoch 22 
2016-12-10 03:56:56 Training Error = 0.56827827244737 
2016-12-10 03:56:56 Training Loss = 0.012850056286556 
2016-12-10 03:57:02 Valid Error = 0.63796330962186 
2016-12-10 03:57:02 Valid Loss = 0.013183545999153 
2016-12-10 03:57:08 Test Error = 0.63422027618727 
2016-12-10 03:57:08 Test Loss = 0.01323576840423 
2016-12-10 03:57:08 -------------------LR------------------- 
2016-12-10 03:57:08 0.015625 
2016-12-10 03:57:08 Epoch 23 
2016-12-10 04:01:37 Training Error = 0.56894399600566 
2016-12-10 04:01:37 Training Loss = 0.01284380883894 
2016-12-10 04:01:43 Valid Error = 0.63983526769 
2016-12-10 04:01:43 Valid Loss = 0.013228104649829 
2016-12-10 04:01:50 Test Error = 0.64398787470529 
2016-12-10 04:01:50 Test Loss = 0.013320423050122 
2016-12-10 04:01:50 -------------------LR------------------- 
2016-12-10 04:01:50 0.015625 
2016-12-10 04:01:50 Epoch 24 
2016-12-10 04:06:22 Training Error = 0.57069152034618 
2016-12-10 04:06:22 Training Loss = 0.01285364447836 
2016-12-10 04:06:28 Valid Error = 0.64507675028079 
2016-12-10 04:06:28 Valid Loss = 0.013233349385629 
2016-12-10 04:06:35 Test Error = 0.63590434489727 
2016-12-10 04:06:35 Test Loss = 0.013285695544199 
2016-12-10 04:06:35 -------------------LR------------------- 
2016-12-10 04:06:35 0.015625 
2016-12-10 04:06:35 Epoch 25 
2016-12-10 04:11:09 Training Error = 0.56956811184156 
2016-12-10 04:11:09 Training Loss = 0.012847372983365 
2016-12-10 04:11:15 Valid Error = 0.64020965930363 
2016-12-10 04:11:15 Valid Loss = 0.013299521754619 
2016-12-10 04:11:22 Test Error = 0.63725159986527 
2016-12-10 04:11:22 Test Loss = 0.013368901256414 
2016-12-10 04:11:22 -------------------LR------------------- 
2016-12-10 04:11:22 0.015625 
2016-12-10 04:11:22 Epoch 26 
2016-12-10 04:15:54 Training Error = 0.57035865856703 
2016-12-10 04:15:54 Training Loss = 0.012844031472506 
2016-12-10 04:16:00 Valid Error = 0.64994384125796 
2016-12-10 04:16:00 Valid Loss = 0.013196899035742 
2016-12-10 04:16:07 Test Error = 0.64398787470529 
2016-12-10 04:16:07 Test Loss = 0.013272229386063 
2016-12-10 04:16:07 -------------------LR------------------- 
2016-12-10 04:16:07 0.015625 
2016-12-10 04:16:07 Epoch 27 
2016-12-10 04:20:41 Training Error = 0.56856952650412 
2016-12-10 04:20:41 Training Loss = 0.01284601123092 
2016-12-10 04:20:47 Valid Error = 0.64807188318982 
2016-12-10 04:20:47 Valid Loss = 0.013204541533538 
2016-12-10 04:20:54 Test Error = 0.63960929605928 
2016-12-10 04:20:54 Test Loss = 0.013250960202049 
2016-12-10 04:20:54 -------------------LR------------------- 
2016-12-10 04:20:54 0.015625 
2016-12-10 04:20:54 Epoch 28 
2016-12-10 04:25:24 Training Error = 0.57023383539985 
2016-12-10 04:25:24 Training Loss = 0.012846093387552 
2016-12-10 04:25:30 Valid Error = 0.6491950580307 
2016-12-10 04:25:30 Valid Loss = 0.013161402034681 
2016-12-10 04:25:36 Test Error = 0.64331424722129 
2016-12-10 04:25:36 Test Loss = 0.013245471725037 
2016-12-10 04:25:36 -------------------LR------------------- 
2016-12-10 04:25:36 0.015625 
2016-12-10 04:25:36 Epoch 29 
2016-12-10 04:30:13 Training Error = 0.57031705084464 
2016-12-10 04:30:13 Training Loss = 0.012850458387089 
2016-12-10 04:30:19 Valid Error = 0.63871209284912 
2016-12-10 04:30:19 Valid Loss = 0.013174476891747 
2016-12-10 04:30:25 Test Error = 0.64028292354328 
2016-12-10 04:30:25 Test Loss = 0.013252172857922 
2016-12-10 04:30:25 -------------------LR------------------- 
2016-12-10 04:30:25 0.015625 
2016-12-10 04:30:26 Epoch 30 
2016-12-10 04:35:03 Training Error = 0.56815344928019 
2016-12-10 04:35:03 Training Loss = 0.0128441525441 
2016-12-10 04:35:09 Valid Error = 0.64956944964433 
2016-12-10 04:35:09 Valid Loss = 0.01337661309125 
2016-12-10 04:35:16 Test Error = 0.65308184573931 
2016-12-10 04:35:16 Test Loss = 0.013521889560675 
2016-12-10 04:35:16 -------------------LR------------------- 
2016-12-10 04:35:16 0.015625 
2016-12-10 04:35:16 Epoch 31 
2016-12-10 04:39:52 Training Error = 0.56815344928019 
2016-12-10 04:39:52 Training Loss = 0.012849748593531 
2016-12-10 04:39:58 Valid Error = 0.64470235866717 
2016-12-10 04:39:58 Valid Loss = 0.013426342408601 
2016-12-10 04:40:05 Test Error = 0.65510272819131 
2016-12-10 04:40:05 Test Loss = 0.013582506840308 
2016-12-10 04:40:05 -------------------LR------------------- 
2016-12-10 04:40:05 0.015625 
2016-12-10 04:40:05 Epoch 32 
2016-12-10 04:44:37 Training Error = 0.5686943496713 
2016-12-10 04:44:37 Training Loss = 0.012837725127967 
2016-12-10 04:44:43 Valid Error = 0.63983526769 
2016-12-10 04:44:43 Valid Loss = 0.013255136099003 
2016-12-10 04:44:50 Test Error = 0.63455708992927 
2016-12-10 04:44:50 Test Loss = 0.013325936887047 
2016-12-10 04:44:50 -------------------LR------------------- 
2016-12-10 04:44:50 0.015625 
2016-12-10 04:44:50 Epoch 33 
2016-12-10 04:49:25 Training Error = 0.56952650411916 
2016-12-10 04:49:25 Training Loss = 0.012847534067664 
2016-12-10 04:49:31 Valid Error = 0.655934107076 
2016-12-10 04:49:31 Valid Loss = 0.013208919564126 
2016-12-10 04:49:38 Test Error = 0.65746042438531 
2016-12-10 04:49:38 Test Loss = 0.013313079071406 
2016-12-10 04:49:38 -------------------LR------------------- 
2016-12-10 04:49:38 0.015625 
2016-12-10 04:49:38 Epoch 34 
2016-12-10 04:54:11 Training Error = 0.57160689023883 
2016-12-10 04:54:11 Training Loss = 0.012849474949382 
2016-12-10 04:54:17 Valid Error = 0.63833770123549 
2016-12-10 04:54:17 Valid Loss = 0.013177973270948 
2016-12-10 04:54:24 Test Error = 0.64095655102728 
2016-12-10 04:54:24 Test Loss = 0.013273104791622 
2016-12-10 04:54:24 -------------------LR------------------- 
2016-12-10 04:54:24 0.015625 
2016-12-10 04:54:24 Epoch 35 
2016-12-10 04:58:59 Training Error = 0.56919364234002 
2016-12-10 04:58:59 Training Loss = 0.012855795066244 
2016-12-10 04:59:05 Valid Error = 0.63796330962186 
2016-12-10 04:59:05 Valid Loss = 0.013386960592606 
2016-12-10 04:59:11 Test Error = 0.64466150218929 
2016-12-10 04:59:11 Test Loss = 0.013553247125237 
2016-12-10 04:59:11 -------------------LR------------------- 
2016-12-10 04:59:11 0.015625 
2016-12-10 04:59:11 Epoch 36 
2016-12-10 05:03:40 Training Error = 0.5686943496713 
2016-12-10 05:03:40 Training Loss = 0.012842489659529 
2016-12-10 05:03:46 Valid Error = 0.6491950580307 
2016-12-10 05:03:46 Valid Loss = 0.013124057894673 
2016-12-10 05:03:52 Test Error = 0.64466150218929 
2016-12-10 05:03:52 Test Loss = 0.013215588278887 
2016-12-10 05:03:52 -------------------LR------------------- 
2016-12-10 05:03:52 0.015625 
2016-12-10 05:03:52 Epoch 37 
2016-12-10 05:08:32 Training Error = 0.57006740451028 
2016-12-10 05:08:32 Training Loss = 0.012851410212105 
2016-12-10 05:08:38 Valid Error = 0.62785473605391 
2016-12-10 05:08:38 Valid Loss = 0.013173985933533 
2016-12-10 05:08:45 Test Error = 0.62209498147524 
2016-12-10 05:08:45 Test Loss = 0.01320368009269 
2016-12-10 05:08:45 -------------------LR------------------- 
2016-12-10 05:08:45 0.015625 
2016-12-10 05:08:45 Epoch 38 
2016-12-10 05:13:17 Training Error = 0.57002579678788 
2016-12-10 05:13:17 Training Loss = 0.012852161386019 
2016-12-10 05:13:23 Valid Error = 0.64694870834893 
2016-12-10 05:13:23 Valid Loss = 0.013175181596305 
2016-12-10 05:13:30 Test Error = 0.64297743347929 
2016-12-10 05:13:30 Test Loss = 0.013280690761406 
2016-12-10 05:13:30 -------------------LR------------------- 
2016-12-10 05:13:30 0.015625 
2016-12-10 05:13:30 Epoch 39 
2016-12-10 05:18:03 Training Error = 0.56782058750104 
2016-12-10 05:18:03 Training Loss = 0.012842664232076 
2016-12-10 05:18:09 Valid Error = 0.64769749157619 
2016-12-10 05:18:09 Valid Loss = 0.013398331178702 
2016-12-10 05:18:16 Test Error = 0.64735601212529 
2016-12-10 05:18:16 Test Loss = 0.013503591021948 
2016-12-10 05:18:16 -------------------LR------------------- 
2016-12-10 05:18:16 0.015625 
2016-12-10 05:18:16 Epoch 40 
2016-12-10 05:22:55 Training Error = 0.57040026628942 
2016-12-10 05:22:55 Training Loss = 0.012848213235272 
2016-12-10 05:23:01 Valid Error = 0.63758891800824 
2016-12-10 05:23:01 Valid Loss = 0.013327133742915 
2016-12-10 05:23:07 Test Error = 0.63691478612327 
2016-12-10 05:23:07 Test Loss = 0.013434336424186 
2016-12-10 05:23:07 -------------------LR------------------- 
2016-12-10 05:23:07 0.015625 
2016-12-10 05:23:08 Epoch 41 
2016-12-10 05:27:38 Training Error = 0.57077473579096 
2016-12-10 05:27:38 Training Loss = 0.012852016558132 
2016-12-10 05:27:44 Valid Error = 0.6518157993261 
2016-12-10 05:27:44 Valid Loss = 0.01320265769621 
2016-12-10 05:27:51 Test Error = 0.64668238464129 
2016-12-10 05:27:51 Test Loss = 0.013297040614159 
2016-12-10 05:27:51 -------------------LR------------------- 
2016-12-10 05:27:51 0.015625 
2016-12-10 05:27:51 Epoch 42 
2016-12-10 05:32:21 Training Error = 0.57094116668054 
2016-12-10 05:32:21 Training Loss = 0.012869872043337 
2016-12-10 05:32:27 Valid Error = 0.64357918382628 
2016-12-10 05:32:27 Valid Loss = 0.013200565646886 
2016-12-10 05:32:33 Test Error = 0.63590434489727 
2016-12-10 05:32:33 Test Loss = 0.013264355220724 
2016-12-10 05:32:33 -------------------LR------------------- 
2016-12-10 05:32:33 0.015625 
2016-12-10 05:32:34 Epoch 43 
2016-12-10 05:37:08 Training Error = 0.56653074810685 
2016-12-10 05:37:08 Training Loss = 0.012851391986152 
2016-12-10 05:37:14 Valid Error = 0.63983526769 
2016-12-10 05:37:14 Valid Loss = 0.013251505380278 
2016-12-10 05:37:21 Test Error = 0.63590434489727 
2016-12-10 05:37:21 Test Loss = 0.013342170244574 
2016-12-10 05:37:21 -------------------LR------------------- 
2016-12-10 05:37:21 0.015625 
2016-12-10 05:37:21 Epoch 44 
2016-12-10 05:41:56 Training Error = 0.56632270949488 
2016-12-10 05:41:56 Training Loss = 0.012841629051324 
2016-12-10 05:42:03 Valid Error = 0.63721452639461 
2016-12-10 05:42:03 Valid Loss = 0.013209129952404 
2016-12-10 05:42:09 Test Error = 0.62748400134725 
2016-12-10 05:42:09 Test Loss = 0.013226301212063 
2016-12-10 05:42:09 -------------------LR------------------- 
2016-12-10 05:42:09 0.015625 
2016-12-10 05:42:09 Epoch 45 
2016-12-10 05:47:04 Training Error = 0.57148206707165 
2016-12-10 05:47:04 Training Loss = 0.012849693732084 
2016-12-10 05:47:10 Valid Error = 0.63758891800824 
2016-12-10 05:47:10 Valid Loss = 0.013251838200334 
2016-12-10 05:47:17 Test Error = 0.63422027618727 
2016-12-10 05:47:17 Test Loss = 0.013337953186469 
2016-12-10 05:47:17 -------------------LR------------------- 
2016-12-10 05:47:17 0.015625 
2016-12-10 05:47:17 Epoch 46 
2016-12-10 05:52:41 Training Error = 0.5705250894566 
2016-12-10 05:52:41 Training Loss = 0.0128613812411 
2016-12-10 05:52:47 Valid Error = 0.64807188318982 
2016-12-10 05:52:47 Valid Loss = 0.013311628173096 
2016-12-10 05:52:54 Test Error = 0.65476591444931 
2016-12-10 05:52:54 Test Loss = 0.013417243164155 
2016-12-10 05:52:54 -------------------LR------------------- 
2016-12-10 05:52:54 0.015625 
2016-12-10 05:52:54 Epoch 47 
2016-12-10 05:58:03 Training Error = 0.56898560372805 
2016-12-10 05:58:03 Training Loss = 0.012846206260542 
2016-12-10 05:58:09 Valid Error = 0.63272182703107 
2016-12-10 05:58:09 Valid Loss = 0.013192848986322 
2016-12-10 05:58:16 Test Error = 0.62916807005726 
2016-12-10 05:58:16 Test Loss = 0.013216281069248 
2016-12-10 05:58:16 -------------------LR------------------- 
2016-12-10 05:58:16 0.015625 
2016-12-10 05:58:16 Epoch 48 
2016-12-10 06:03:47 Training Error = 0.56944328867438 
2016-12-10 06:03:47 Training Loss = 0.012849911070749 
2016-12-10 06:03:53 Valid Error = 0.64956944964433 
2016-12-10 06:03:53 Valid Loss = 0.013371351206149 
2016-12-10 06:04:00 Test Error = 0.65476591444931 
2016-12-10 06:04:00 Test Loss = 0.013507513018405 
2016-12-10 06:04:00 -------------------LR------------------- 
2016-12-10 06:04:00 0.015625 
2016-12-10 06:04:00 Epoch 49 
2016-12-10 06:10:08 Training Error = 0.5692768577848 
2016-12-10 06:10:08 Training Loss = 0.012845648612915 
2016-12-10 06:10:14 Valid Error = 0.65705728191689 
2016-12-10 06:10:14 Valid Loss = 0.013364557929019 
2016-12-10 06:10:21 Test Error = 0.66554395419333 
2016-12-10 06:10:21 Test Loss = 0.01349342226717 
2016-12-10 06:10:21 -------------------LR------------------- 
2016-12-10 06:10:21 0.015625 
2016-12-10 06:10:21 Epoch 50 
2016-12-10 06:16:13 Training Error = 0.56948489639677 
2016-12-10 06:16:13 Training Loss = 0.012847204283656 
2016-12-10 06:16:19 Valid Error = 0.65368775739423 
2016-12-10 06:16:19 Valid Loss = 0.013448343927119 
2016-12-10 06:16:26 Test Error = 0.65644998315931 
2016-12-10 06:16:26 Test Loss = 0.013574971297231 
2016-12-10 06:16:26 -------------------LR------------------- 
2016-12-10 06:16:26 0.0078125 
2016-12-10 06:16:26 Epoch 51 
2016-12-10 06:22:04 Training Error = 0.56985936589831 
2016-12-10 06:22:04 Training Loss = 0.012859837312237 
2016-12-10 06:22:10 Valid Error = 0.64657431673531 
2016-12-10 06:22:10 Valid Loss = 0.013293968464369 
2016-12-10 06:22:17 Test Error = 0.6503873358033 
2016-12-10 06:22:17 Test Loss = 0.013417944387971 
2016-12-10 06:22:17 -------------------LR------------------- 
2016-12-10 06:22:17 0.0078125 
2016-12-10 06:22:17 Epoch 52 
2016-12-10 06:28:10 Training Error = 0.56915203461763 
2016-12-10 06:28:10 Training Loss = 0.012859782603562 
2016-12-10 06:28:16 Valid Error = 0.6518157993261 
2016-12-10 06:28:16 Valid Loss = 0.013538129371992 
2016-12-10 06:28:23 Test Error = 0.65543954193331 
2016-12-10 06:28:23 Test Loss = 0.013662442913021 
2016-12-10 06:28:23 -------------------LR------------------- 
2016-12-10 06:28:23 0.0078125 
2016-12-10 06:28:23 Epoch 53 
2016-12-10 06:34:25 Training Error = 0.57210618290755 
2016-12-10 06:34:25 Training Loss = 0.012846896700464 
2016-12-10 06:34:31 Valid Error = 0.64133283414452 
2016-12-10 06:34:31 Valid Loss = 0.01326648332971 
2016-12-10 06:34:38 Test Error = 0.65375547322331 
2016-12-10 06:34:38 Test Loss = 0.013395788100715 
2016-12-10 06:34:38 -------------------LR------------------- 
2016-12-10 06:34:38 0.0078125 
2016-12-10 06:34:38 Epoch 54 
2016-12-10 06:40:42 Training Error = 0.56844470333694 
2016-12-10 06:40:42 Training Loss = 0.012859970412705 
2016-12-10 06:40:48 Valid Error = 0.64020965930363 
2016-12-10 06:40:48 Valid Loss = 0.013190910372989 
2016-12-10 06:40:55 Test Error = 0.63118895250926 
2016-12-10 06:40:55 Test Loss = 0.01324927662037 
2016-12-10 06:40:55 -------------------LR------------------- 
2016-12-10 06:40:55 0.0078125 
2016-12-10 06:40:55 Epoch 55 
2016-12-10 06:46:57 Training Error = 0.56998418906549 
2016-12-10 06:46:57 Training Loss = 0.012866758421657 
2016-12-10 06:47:03 Valid Error = 0.63534256832647 
2016-12-10 06:47:03 Valid Loss = 0.013294708091198 
2016-12-10 06:47:10 Test Error = 0.63388346244527 
2016-12-10 06:47:10 Test Loss = 0.013397852312359 
2016-12-10 06:47:10 -------------------LR------------------- 
2016-12-10 06:47:10 0.0078125 
2016-12-10 06:47:10 Epoch 56 
2016-12-10 06:53:48 Training Error = 0.56769576433386 
2016-12-10 06:53:48 Training Loss = 0.012846633519343 
2016-12-10 06:53:54 Valid Error = 0.64657431673531 
2016-12-10 06:53:54 Valid Loss = 0.013367856559982 
2016-12-10 06:54:01 Test Error = 0.6503873358033 
2016-12-10 06:54:01 Test Loss = 0.013480688126204 
2016-12-10 06:54:01 -------------------LR------------------- 
2016-12-10 06:54:01 0.0078125 
2016-12-10 06:54:01 Epoch 57 
2016-12-10 07:01:17 Training Error = 0.56944328867438 
2016-12-10 07:01:17 Training Loss = 0.012846339517289 
2016-12-10 07:01:24 Valid Error = 0.64545114189442 
2016-12-10 07:01:24 Valid Loss = 0.013188960531765 
2016-12-10 07:01:30 Test Error = 0.64028292354328 
2016-12-10 07:01:30 Test Loss = 0.013282597050581 
2016-12-10 07:01:30 -------------------LR------------------- 
2016-12-10 07:01:30 0.0078125 
2016-12-10 07:01:30 Epoch 58 
2016-12-10 07:08:42 Training Error = 0.5699009736207 
2016-12-10 07:08:42 Training Loss = 0.012857725548176 
2016-12-10 07:08:48 Valid Error = 0.63758891800824 
2016-12-10 07:08:48 Valid Loss = 0.013434240105107 
2016-12-10 07:08:54 Test Error = 0.64264061973729 
2016-12-10 07:08:54 Test Loss = 0.013583228670499 
2016-12-10 07:08:54 -------------------LR------------------- 
2016-12-10 07:08:54 0.0078125 
2016-12-10 07:08:55 Epoch 59 
2016-12-10 07:16:07 Training Error = 0.56886078056087 
2016-12-10 07:16:07 Training Loss = 0.012854128643219 
2016-12-10 07:16:13 Valid Error = 0.6518157993261 
2016-12-10 07:16:13 Valid Loss = 0.013189105060982 
2016-12-10 07:16:19 Test Error = 0.65476591444931 
2016-12-10 07:16:19 Test Loss = 0.013311997958811 
2016-12-10 07:16:19 -------------------LR------------------- 
2016-12-10 07:16:19 0.0078125 
2016-12-10 07:16:19 Epoch 60 
2016-12-10 07:23:42 Training Error = 0.57031705084464 
2016-12-10 07:23:42 Training Loss = 0.012842085868419 
2016-12-10 07:23:48 Valid Error = 0.64208161737177 
2016-12-10 07:23:48 Valid Loss = 0.01347397305726 
2016-12-10 07:23:55 Test Error = 0.64634557089929 
2016-12-10 07:23:55 Test Loss = 0.013599118498441 
2016-12-10 07:23:55 -------------------LR------------------- 
2016-12-10 07:23:55 0.0078125 
2016-12-10 07:23:55 Epoch 61 
2016-12-10 07:31:20 Training Error = 0.570566697179 
2016-12-10 07:31:20 Training Loss = 0.01285016962911 
2016-12-10 07:31:26 Valid Error = 0.63234743541745 
2016-12-10 07:31:26 Valid Loss = 0.013171507197742 
2016-12-10 07:31:32 Test Error = 0.62647356012125 
2016-12-10 07:31:32 Test Loss = 0.013194536130153 
2016-12-10 07:31:32 -------------------LR------------------- 
2016-12-10 07:31:32 0.0078125 
2016-12-10 07:31:32 Epoch 62 
2016-12-10 07:38:42 Training Error = 0.5674461179995 
2016-12-10 07:38:42 Training Loss = 0.012859946591856 
2016-12-10 07:38:49 Valid Error = 0.64694870834893 
2016-12-10 07:38:49 Valid Loss = 0.013180519938448 
2016-12-10 07:38:55 Test Error = 0.63994610980128 
2016-12-10 07:38:55 Test Loss = 0.013214978261494 
2016-12-10 07:38:55 -------------------LR------------------- 
2016-12-10 07:38:55 0.0078125 
2016-12-10 07:38:55 Epoch 63 
2016-12-10 07:46:11 Training Error = 0.56948489639677 
2016-12-10 07:46:11 Training Loss = 0.012846144811322 
2016-12-10 07:46:17 Valid Error = 0.64470235866717 
2016-12-10 07:46:17 Valid Loss = 0.013206833547336 
2016-12-10 07:46:24 Test Error = 0.64129336476928 
2016-12-10 07:46:24 Test Loss = 0.013307283944913 
2016-12-10 07:46:24 -------------------LR------------------- 
2016-12-10 07:46:24 0.0078125 
2016-12-10 07:46:24 Epoch 64 
2016-12-10 07:53:48 Training Error = 0.56748772572189 
2016-12-10 07:53:48 Training Loss = 0.012835973941389 
2016-12-10 07:53:54 Valid Error = 0.64133283414452 
2016-12-10 07:53:54 Valid Loss = 0.013266901265113 
2016-12-10 07:54:01 Test Error = 0.63826204109128 
2016-12-10 07:54:01 Test Loss = 0.013360749136269 
2016-12-10 07:54:01 -------------------LR------------------- 
2016-12-10 07:54:01 0.0078125 
2016-12-10 07:54:01 Epoch 65 
2016-12-10 08:00:12 Training Error = 0.56940168095198 
2016-12-10 08:00:12 Training Loss = 0.0128510987817 
2016-12-10 08:00:18 Valid Error = 0.64058405091726 
2016-12-10 08:00:18 Valid Loss = 0.013259641594411 
2016-12-10 08:00:25 Test Error = 0.63388346244527 
2016-12-10 08:00:25 Test Loss = 0.01330028451506 
2016-12-10 08:00:25 -------------------LR------------------- 
2016-12-10 08:00:25 0.0078125 
2016-12-10 08:00:25 Epoch 66 
2016-12-10 08:06:31 Training Error = 0.57010901223267 
2016-12-10 08:06:31 Training Loss = 0.012848383122985 
2016-12-10 08:06:37 Valid Error = 0.63684013478098 
2016-12-10 08:06:37 Valid Loss = 0.013237338384909 
2016-12-10 08:06:44 Test Error = 0.62849444257326 
2016-12-10 08:06:44 Test Loss = 0.013267398664759 
2016-12-10 08:06:44 -------------------LR------------------- 
2016-12-10 08:06:44 0.0078125 
2016-12-10 08:06:44 Epoch 67 
2016-12-10 08:12:48 Training Error = 0.57048348173421 
2016-12-10 08:12:48 Training Loss = 0.012846053053236 
2016-12-10 08:12:54 Valid Error = 0.63796330962186 
2016-12-10 08:12:54 Valid Loss = 0.013452269494587 
2016-12-10 08:13:01 Test Error = 0.64466150218929 
2016-12-10 08:13:01 Test Loss = 0.013602665242871 
2016-12-10 08:13:01 -------------------LR------------------- 
2016-12-10 08:13:01 0.0078125 
2016-12-10 08:13:01 Epoch 68 
2016-12-10 08:19:09 Training Error = 0.56669717899642 
2016-12-10 08:19:09 Training Loss = 0.012829532445926 
2016-12-10 08:19:15 Valid Error = 0.65368775739423 
2016-12-10 08:19:15 Valid Loss = 0.013333672588591 
2016-12-10 08:19:22 Test Error = 0.65779723812732 
2016-12-10 08:19:22 Test Loss = 0.013446389399047 
2016-12-10 08:19:22 -------------------LR------------------- 
2016-12-10 08:19:22 0.0078125 
2016-12-10 08:19:22 Epoch 69 
2016-12-10 08:25:35 Training Error = 0.56678039444121 
2016-12-10 08:25:35 Training Loss = 0.012845801696805 
2016-12-10 08:25:41 Valid Error = 0.64208161737177 
2016-12-10 08:25:41 Valid Loss = 0.013254793029321 
2016-12-10 08:25:48 Test Error = 0.63624115863927 
2016-12-10 08:25:48 Test Loss = 0.013339436135523 
2016-12-10 08:25:48 -------------------LR------------------- 
2016-12-10 08:25:48 0.0078125 
2016-12-10 08:25:48 Epoch 70 
2016-12-10 08:32:04 Training Error = 0.57285512191063 
2016-12-10 08:32:04 Training Loss = 0.012848923013202 
2016-12-10 08:32:10 Valid Error = 0.65293897416698 
2016-12-10 08:32:10 Valid Loss = 0.013343922915775 
2016-12-10 08:32:17 Test Error = 0.65746042438531 
2016-12-10 08:32:17 Test Loss = 0.013476930140699 
2016-12-10 08:32:17 -------------------LR------------------- 
2016-12-10 08:32:17 0.0078125 
2016-12-10 08:32:17 Epoch 71 
2016-12-10 08:38:21 Training Error = 0.56827827244737 
2016-12-10 08:38:21 Training Loss = 0.012848956729367 
2016-12-10 08:38:27 Valid Error = 0.63758891800824 
2016-12-10 08:38:27 Valid Loss = 0.013257753173531 
2016-12-10 08:38:33 Test Error = 0.62782081508926 
2016-12-10 08:38:33 Test Loss = 0.013289404304391 
2016-12-10 08:38:33 -------------------LR------------------- 
2016-12-10 08:38:33 0.0078125 
2016-12-10 08:38:33 Epoch 72 
2016-12-10 08:44:43 Training Error = 0.56719647166514 
2016-12-10 08:44:43 Training Loss = 0.012833551312299 
2016-12-10 08:44:49 Valid Error = 0.6357169599401 
2016-12-10 08:44:49 Valid Loss = 0.013250494494828 
2016-12-10 08:44:55 Test Error = 0.63388346244527 
2016-12-10 08:44:55 Test Loss = 0.013320798309086 
2016-12-10 08:44:55 -------------------LR------------------- 
2016-12-10 08:44:55 0.0078125 
2016-12-10 08:44:55 Epoch 73 
2016-12-10 08:51:01 Training Error = 0.56790380294583 
2016-12-10 08:51:01 Training Loss = 0.012828442603822 
2016-12-10 08:51:07 Valid Error = 0.64170722575814 
2016-12-10 08:51:07 Valid Loss = 0.013396513287211 
2016-12-10 08:51:14 Test Error = 0.64668238464129 
2016-12-10 08:51:14 Test Loss = 0.013530492350029 
2016-12-10 08:51:14 -------------------LR------------------- 
2016-12-10 08:51:14 0.0078125 
2016-12-10 08:51:14 Epoch 74 
2016-12-10 08:57:21 Training Error = 0.57081634351336 
2016-12-10 08:57:21 Training Loss = 0.012848398469772 
2016-12-10 08:57:27 Valid Error = 0.64769749157619 
2016-12-10 08:57:27 Valid Loss = 0.013422953308362 
2016-12-10 08:57:34 Test Error = 0.6503873358033 
2016-12-10 08:57:34 Test Loss = 0.013546350147377 
2016-12-10 08:57:34 -------------------LR------------------- 
2016-12-10 08:57:34 0.0078125 
2016-12-10 08:57:34 Epoch 75 
2016-12-10 09:03:39 Training Error = 0.56503287010069 
2016-12-10 09:03:39 Training Loss = 0.01282737731196 
2016-12-10 09:03:45 Valid Error = 0.64208161737177 
2016-12-10 09:03:45 Valid Loss = 0.013119754010622 
2016-12-10 09:03:51 Test Error = 0.63624115863927 
2016-12-10 09:03:51 Test Loss = 0.013200340364223 
2016-12-10 09:03:51 -------------------LR------------------- 
2016-12-10 09:03:51 0.0078125 
2016-12-10 09:03:51 Epoch 76 
2016-12-10 09:09:44 Training Error = 0.56802862611301 
2016-12-10 09:09:44 Training Loss = 0.012841897747012 
2016-12-10 09:09:50 Valid Error = 0.63534256832647 
2016-12-10 09:09:50 Valid Loss = 0.013176944116841 
2016-12-10 09:09:57 Test Error = 0.63253620747727 
2016-12-10 09:09:57 Test Loss = 0.013220132472017 
2016-12-10 09:09:57 -------------------LR------------------- 
2016-12-10 09:09:57 0.0078125 
2016-12-10 09:09:57 Epoch 77 
2016-12-10 09:15:55 Training Error = 0.56965132728634 
2016-12-10 09:15:55 Training Loss = 0.012862468196444 
2016-12-10 09:16:01 Valid Error = 0.63758891800824 
2016-12-10 09:16:01 Valid Loss = 0.013291407328277 
2016-12-10 09:16:08 Test Error = 0.64365106096329 
2016-12-10 09:16:08 Test Loss = 0.01343347568568 
2016-12-10 09:16:08 -------------------LR------------------- 
2016-12-10 09:16:08 0.0078125 
2016-12-10 09:16:08 Epoch 78 
2016-12-10 09:22:17 Training Error = 0.57081634351336 
2016-12-10 09:22:17 Training Loss = 0.0128490460187 
2016-12-10 09:22:23 Valid Error = 0.63347061025833 
2016-12-10 09:22:23 Valid Loss = 0.013169748329315 
2016-12-10 09:22:30 Test Error = 0.62445267766925 
2016-12-10 09:22:30 Test Loss = 0.0132191477952 
2016-12-10 09:22:30 -------------------LR------------------- 
2016-12-10 09:22:30 0.0078125 
2016-12-10 09:22:30 Epoch 79 
2016-12-10 09:28:33 Training Error = 0.56936007322959 
2016-12-10 09:28:33 Training Loss = 0.012861254271985 
2016-12-10 09:28:39 Valid Error = 0.64395357543991 
2016-12-10 09:28:39 Valid Loss = 0.013170720027331 
2016-12-10 09:28:45 Test Error = 0.63927248231728 
2016-12-10 09:28:45 Test Loss = 0.013242678614757 
2016-12-10 09:28:45 -------------------LR------------------- 
2016-12-10 09:28:45 0.0078125 
2016-12-10 09:28:45 Epoch 80 
2016-12-10 09:34:52 Training Error = 0.56831988016976 
2016-12-10 09:34:52 Training Loss = 0.012846711792103 
2016-12-10 09:34:58 Valid Error = 0.64769749157619 
2016-12-10 09:34:58 Valid Loss = 0.013127500497985 
2016-12-10 09:35:04 Test Error = 0.64230380599528 
2016-12-10 09:35:04 Test Loss = 0.013175912591505 
2016-12-10 09:35:04 -------------------LR------------------- 
2016-12-10 09:35:04 0.0078125 
2016-12-10 09:35:04 Epoch 81 
2016-12-10 09:41:07 Training Error = 0.57123242073729 
2016-12-10 09:41:07 Training Loss = 0.012853043967342 
2016-12-10 09:41:13 Valid Error = 0.6289779108948 
2016-12-10 09:41:13 Valid Loss = 0.013187538299066 
2016-12-10 09:41:20 Test Error = 0.62478949141125 
2016-12-10 09:41:20 Test Loss = 0.013194537368547 
2016-12-10 09:41:20 -------------------LR------------------- 
2016-12-10 09:41:20 0.0078125 
2016-12-10 09:41:20 Epoch 82 
2016-12-10 09:47:25 Training Error = 0.57181492885079 
2016-12-10 09:47:25 Training Loss = 0.012851290826998 
2016-12-10 09:47:31 Valid Error = 0.64769749157619 
2016-12-10 09:47:31 Valid Loss = 0.013231734144941 
2016-12-10 09:47:38 Test Error = 0.63927248231728 
2016-12-10 09:47:38 Test Loss = 0.013301475136531 
2016-12-10 09:47:38 -------------------LR------------------- 
2016-12-10 09:47:38 0.0078125 
2016-12-10 09:47:38 Epoch 83 
2016-12-10 09:53:36 Training Error = 0.56877756511609 
2016-12-10 09:53:36 Training Loss = 0.012858643833314 
2016-12-10 09:53:42 Valid Error = 0.64133283414452 
2016-12-10 09:53:42 Valid Loss = 0.013240320618443 
2016-12-10 09:53:48 Test Error = 0.63994610980128 
2016-12-10 09:53:48 Test Loss = 0.013338625916227 
2016-12-10 09:53:48 -------------------LR------------------- 
2016-12-10 09:53:48 0.0078125 
2016-12-10 09:53:48 Epoch 84 
2016-12-10 09:59:55 Training Error = 0.5692768577848 
2016-12-10 09:59:55 Training Loss = 0.01284727978314 
2016-12-10 10:00:01 Valid Error = 0.65481093223512 
2016-12-10 10:00:01 Valid Loss = 0.013198291859293 
2016-12-10 10:00:08 Test Error = 0.6524082182553 
2016-12-10 10:00:08 Test Loss = 0.013304560742636 
2016-12-10 10:00:08 -------------------LR------------------- 
2016-12-10 10:00:08 0.0078125 
2016-12-10 10:00:08 Epoch 85 
2016-12-10 10:06:06 Training Error = 0.56936007322959 
2016-12-10 10:06:06 Training Loss = 0.012849008038338 
2016-12-10 10:06:12 Valid Error = 0.64694870834893 
2016-12-10 10:06:12 Valid Loss = 0.013371297846039 
2016-12-10 10:06:19 Test Error = 0.6503873358033 
2016-12-10 10:06:19 Test Loss = 0.013480934618738 
2016-12-10 10:06:19 -------------------LR------------------- 
2016-12-10 10:06:19 0.0078125 
2016-12-10 10:06:19 Epoch 86 
2016-12-10 10:12:28 Training Error = 0.56736290255471 
2016-12-10 10:12:28 Training Loss = 0.012844631899688 
2016-12-10 10:12:34 Valid Error = 0.64657431673531 
2016-12-10 10:12:34 Valid Loss = 0.013258113970608 
2016-12-10 10:12:40 Test Error = 0.6503873358033 
2016-12-10 10:12:40 Test Loss = 0.013373721845084 
2016-12-10 10:12:40 -------------------LR------------------- 
2016-12-10 10:12:40 0.0078125 
2016-12-10 10:12:40 Epoch 87 
2016-12-10 10:18:48 Training Error = 0.5711908130149 
2016-12-10 10:18:48 Training Loss = 0.012838600618214 
2016-12-10 10:18:54 Valid Error = 0.6518157993261 
2016-12-10 10:18:54 Valid Loss = 0.013195568700698 
2016-12-10 10:19:01 Test Error = 0.64533512967329 
2016-12-10 10:19:01 Test Loss = 0.013286474947592 
2016-12-10 10:19:01 -------------------LR------------------- 
2016-12-10 10:19:01 0.0078125 
2016-12-10 10:19:01 Epoch 88 
2016-12-10 10:25:20 Training Error = 0.56852791878173 
2016-12-10 10:25:20 Training Loss = 0.012849363553292 
2016-12-10 10:25:26 Valid Error = 0.64320479221265 
2016-12-10 10:25:26 Valid Loss = 0.013246702912911 
2016-12-10 10:25:33 Test Error = 0.63893566857528 
2016-12-10 10:25:33 Test Loss = 0.0132963006671 
2016-12-10 10:25:33 -------------------LR------------------- 
2016-12-10 10:25:33 0.0078125 
2016-12-10 10:25:33 Epoch 89 
2016-12-10 10:31:48 Training Error = 0.56902721145045 
2016-12-10 10:31:48 Training Loss = 0.01283688906168 
2016-12-10 10:31:54 Valid Error = 0.61812055409959 
2016-12-10 10:31:54 Valid Loss = 0.013247389812661 
2016-12-10 10:32:01 Test Error = 0.61333782418323 
2016-12-10 10:32:01 Test Loss = 0.013252218453618 
2016-12-10 10:32:01 -------------------LR------------------- 
2016-12-10 10:32:01 0.0078125 
2016-12-10 10:32:01 Epoch 90 
2016-12-10 10:38:13 Training Error = 0.57131563618208 
2016-12-10 10:38:13 Training Loss = 0.012853242686585 
2016-12-10 10:38:19 Valid Error = 0.64020965930363 
2016-12-10 10:38:19 Valid Loss = 0.013353287885774 
2016-12-10 10:38:26 Test Error = 0.62849444257326 
2016-12-10 10:38:26 Test Loss = 0.013386020866727 
2016-12-10 10:38:26 -------------------LR------------------- 
2016-12-10 10:38:26 0.0078125 
2016-12-10 10:38:26 Epoch 91 
2016-12-10 10:44:34 Training Error = 0.5692768577848 
2016-12-10 10:44:34 Training Loss = 0.012855653153744 
2016-12-10 10:44:40 Valid Error = 0.6424560089854 
2016-12-10 10:44:40 Valid Loss = 0.013362132229956 
2016-12-10 10:44:47 Test Error = 0.64701919838329 
2016-12-10 10:44:47 Test Loss = 0.013474986200747 
2016-12-10 10:44:47 -------------------LR------------------- 
2016-12-10 10:44:47 0.0078125 
2016-12-10 10:44:47 Epoch 92 
2016-12-10 10:51:05 Training Error = 0.57002579678788 
2016-12-10 10:51:05 Training Loss = 0.012845077114095 
2016-12-10 10:51:11 Valid Error = 0.63758891800824 
2016-12-10 10:51:11 Valid Loss = 0.013312174278769 
2016-12-10 10:51:18 Test Error = 0.64095655102728 
2016-12-10 10:51:18 Test Loss = 0.01343267525155 
2016-12-10 10:51:18 -------------------LR------------------- 
2016-12-10 10:51:18 0.0078125 
2016-12-10 10:51:18 Epoch 93 
2016-12-10 10:57:28 Training Error = 0.57169010568361 
2016-12-10 10:57:28 Training Loss = 0.012855390537414 
2016-12-10 10:57:34 Valid Error = 0.64283040059903 
2016-12-10 10:57:34 Valid Loss = 0.013175449588006 
2016-12-10 10:57:41 Test Error = 0.63691478612327 
2016-12-10 10:57:41 Test Loss = 0.013223059738808 
2016-12-10 10:57:41 -------------------LR------------------- 
2016-12-10 10:57:41 0.0078125 
2016-12-10 10:57:41 Epoch 94 
2016-12-10 11:03:53 Training Error = 0.56811184155779 
2016-12-10 11:03:53 Training Loss = 0.0128426249549 
2016-12-10 11:03:59 Valid Error = 0.63646574316735 
2016-12-10 11:03:59 Valid Loss = 0.013272291796195 
2016-12-10 11:04:06 Test Error = 0.63859885483328 
2016-12-10 11:04:06 Test Loss = 0.013364150520824 
2016-12-10 11:04:06 -------------------LR------------------- 
2016-12-10 11:04:06 0.0078125 
2016-12-10 11:04:06 Epoch 95 
2016-12-10 11:10:29 Training Error = 0.56648914038446 
2016-12-10 11:10:29 Training Loss = 0.012839680692217 
2016-12-10 11:10:35 Valid Error = 0.65930363159865 
2016-12-10 11:10:35 Valid Loss = 0.013283938908063 
2016-12-10 11:10:42 Test Error = 0.66049174806332 
2016-12-10 11:10:42 Test Loss = 0.013398687146913 
2016-12-10 11:10:42 -------------------LR------------------- 
2016-12-10 11:10:42 0.0078125 
2016-12-10 11:10:42 Epoch 96 
2016-12-10 11:16:58 Training Error = 0.56823666472497 
2016-12-10 11:16:58 Training Loss = 0.012839748431697 
2016-12-10 11:17:04 Valid Error = 0.65668289030326 
2016-12-10 11:17:04 Valid Loss = 0.013231900375173 
2016-12-10 11:17:10 Test Error = 0.65577635567531 
2016-12-10 11:17:10 Test Loss = 0.013358943717272 
2016-12-10 11:17:10 -------------------LR------------------- 
2016-12-10 11:17:10 0.0078125 
2016-12-10 11:17:11 Epoch 97 
2016-12-10 11:23:19 Training Error = 0.56911042689523 
2016-12-10 11:23:19 Training Loss = 0.01284385497555 
2016-12-10 11:23:25 Valid Error = 0.63908648446275 
2016-12-10 11:23:25 Valid Loss = 0.013383767766027 
2016-12-10 11:23:32 Test Error = 0.6480296396093 
2016-12-10 11:23:32 Test Loss = 0.013570599600541 
2016-12-10 11:23:32 -------------------LR------------------- 
2016-12-10 11:23:32 0.0078125 
2016-12-10 11:23:32 Epoch 98 
2016-12-10 11:29:15 Training Error = 0.56965132728634 
2016-12-10 11:29:15 Training Loss = 0.012844908273005 
2016-12-10 11:29:21 Valid Error = 0.65219019093972 
2016-12-10 11:29:21 Valid Loss = 0.013308725637929 
2016-12-10 11:29:28 Test Error = 0.65813405186932 
2016-12-10 11:29:28 Test Loss = 0.013429875260722 
2016-12-10 11:29:28 -------------------LR------------------- 
2016-12-10 11:29:28 0.0078125 
2016-12-10 11:29:28 Epoch 99 
2016-12-10 11:35:10 Training Error = 0.5699009736207 
2016-12-10 11:35:10 Training Loss = 0.012861064567643 
2016-12-10 11:35:16 Valid Error = 0.64320479221265 
2016-12-10 11:35:16 Valid Loss = 0.013388577595046 
2016-12-10 11:35:23 Test Error = 0.6500505220613 
2016-12-10 11:35:23 Test Loss = 0.01351251564586 
2016-12-10 11:35:23 -------------------LR------------------- 
2016-12-10 11:35:23 0.0078125 
2016-12-10 11:35:23 Epoch 100 
2016-12-10 11:41:01 Training Error = 0.57010901223267 
2016-12-10 11:41:01 Training Loss = 0.01285034142692 
2016-12-10 11:41:07 Valid Error = 0.6491950580307 
2016-12-10 11:41:07 Valid Loss = 0.013310138128551 
2016-12-10 11:41:14 Test Error = 0.6507241495453 
2016-12-10 11:41:14 Test Loss = 0.013412648719498 
2016-12-10 11:41:14 -------------------LR------------------- 
2016-12-10 11:41:14 0.00390625 
2016-12-10 11:41:14 Epoch 101 
2016-12-10 11:46:50 Training Error = 0.57193975201797 
2016-12-10 11:46:50 Training Loss = 0.012871095297882 
2016-12-10 11:46:56 Valid Error = 0.63908648446275 
2016-12-10 11:46:56 Valid Loss = 0.013299856458787 
2016-12-10 11:47:03 Test Error = 0.64365106096329 
2016-12-10 11:47:03 Test Loss = 0.013426944944774 
2016-12-10 11:47:03 -------------------LR------------------- 
2016-12-10 11:47:03 0.00390625 
2016-12-10 11:47:03 Epoch 102 
2016-12-10 11:52:41 Training Error = 0.570566697179 
2016-12-10 11:52:41 Training Loss = 0.0128612815568 
2016-12-10 11:52:47 Valid Error = 0.64395357543991 
2016-12-10 11:52:47 Valid Loss = 0.013247952801062 
2016-12-10 11:52:54 Test Error = 0.64061973728528 
2016-12-10 11:52:54 Test Loss = 0.013353470145512 
2016-12-10 11:52:54 -------------------LR------------------- 
2016-12-10 11:52:54 0.00390625 
2016-12-10 11:52:54 Epoch 103 
2016-12-10 11:58:29 Training Error = 0.57210618290755 
2016-12-10 11:58:29 Training Loss = 0.012854697854247 
2016-12-10 11:58:35 Valid Error = 0.65031823287158 
2016-12-10 11:58:35 Valid Loss = 0.013361646242354 
2016-12-10 11:58:41 Test Error = 0.65341865948131 
2016-12-10 11:58:41 Test Loss = 0.013491744865323 
2016-12-10 11:58:41 -------------------LR------------------- 
2016-12-10 11:58:41 0.00390625 
2016-12-10 11:58:41 Epoch 104 
2016-12-10 12:04:13 Training Error = 0.56836148789215 
2016-12-10 12:04:13 Training Loss = 0.012849181541184 
2016-12-10 12:04:19 Valid Error = 0.63871209284912 
2016-12-10 12:04:19 Valid Loss = 0.0132381280862 
2016-12-10 12:04:26 Test Error = 0.63455708992927 
2016-12-10 12:04:26 Test Loss = 0.013275440091979 
2016-12-10 12:04:26 -------------------LR------------------- 
2016-12-10 12:04:26 0.00390625 
2016-12-10 12:04:26 Epoch 105 
2016-12-10 12:10:14 Training Error = 0.56711325622035 
2016-12-10 12:10:14 Training Loss = 0.012848625449034 
2016-12-10 12:10:20 Valid Error = 0.64994384125796 
2016-12-10 12:10:20 Valid Loss = 0.013442615096571 
2016-12-10 12:10:27 Test Error = 0.65341865948131 
2016-12-10 12:10:27 Test Loss = 0.01356910958651 
2016-12-10 12:10:27 -------------------LR------------------- 
2016-12-10 12:10:27 0.00390625 
2016-12-10 12:10:27 Epoch 106 
2016-12-10 12:16:02 Training Error = 0.56698843305317 
2016-12-10 12:16:02 Training Loss = 0.012830995191609 
2016-12-10 12:16:08 Valid Error = 0.64956944964433 
2016-12-10 12:16:08 Valid Loss = 0.013271103486333 
2016-12-10 12:16:15 Test Error = 0.6510609632873 
2016-12-10 12:16:15 Test Loss = 0.013352870829074 
2016-12-10 12:16:15 -------------------LR------------------- 
2016-12-10 12:16:15 0.00390625 
2016-12-10 12:16:15 Epoch 107 
2016-12-10 12:21:55 Training Error = 0.56586502454856 
2016-12-10 12:21:55 Training Loss = 0.012839166859376 
2016-12-10 12:22:01 Valid Error = 0.65144140771247 
2016-12-10 12:22:01 Valid Loss = 0.013268733951076 
2016-12-10 12:22:08 Test Error = 0.64634557089929 
2016-12-10 12:22:08 Test Loss = 0.01337022563952 
2016-12-10 12:22:08 -------------------LR------------------- 
2016-12-10 12:22:08 0.00390625 
2016-12-10 12:22:08 Epoch 108 
2016-12-10 12:27:50 Training Error = 0.57110759757011 
2016-12-10 12:27:50 Training Loss = 0.012861771295379 
2016-12-10 12:27:56 Valid Error = 0.63684013478098 
2016-12-10 12:27:56 Valid Loss = 0.013289329062072 
2016-12-10 12:28:02 Test Error = 0.63523071741327 
2016-12-10 12:28:02 Test Loss = 0.013384895460427 
2016-12-10 12:28:02 -------------------LR------------------- 
2016-12-10 12:28:02 0.00390625 
2016-12-10 12:28:02 Epoch 109 
2016-12-10 12:33:41 Training Error = 0.57173171340601 
2016-12-10 12:33:41 Training Loss = 0.012860093921359 
2016-12-10 12:33:47 Valid Error = 0.64170722575814 
2016-12-10 12:33:47 Valid Loss = 0.013250971690525 
2016-12-10 12:33:54 Test Error = 0.63691478612327 
2016-12-10 12:33:54 Test Loss = 0.013362138350656 
2016-12-10 12:33:54 -------------------LR------------------- 
2016-12-10 12:33:54 0.00390625 
2016-12-10 12:33:54 Epoch 110 
2016-12-10 12:39:28 Training Error = 0.56898560372805 
2016-12-10 12:39:28 Training Loss = 0.012843844681945 
2016-12-10 12:39:35 Valid Error = 0.63234743541745 
2016-12-10 12:39:35 Valid Loss = 0.013172723902277 
2016-12-10 12:39:41 Test Error = 0.63051532502526 
2016-12-10 12:39:41 Test Loss = 0.013242416171679 
2016-12-10 12:39:41 -------------------LR------------------- 
2016-12-10 12:39:41 0.00390625 
2016-12-10 12:39:41 Epoch 111 
2016-12-10 12:45:21 Training Error = 0.56827827244737 
2016-12-10 12:45:21 Training Loss = 0.012835856028946 
2016-12-10 12:45:27 Valid Error = 0.64395357543991 
2016-12-10 12:45:27 Valid Loss = 0.01337187744685 
2016-12-10 12:45:34 Test Error = 0.6490400808353 
2016-12-10 12:45:34 Test Loss = 0.013505309683953 
2016-12-10 12:45:34 -------------------LR------------------- 
2016-12-10 12:45:34 0.00390625 
2016-12-10 12:45:34 Epoch 112 
