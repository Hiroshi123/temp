2016-12-10 01:58:09 [program started on Sat Dec 10 01:58:09 2016] 
2016-12-10 01:58:09 [command line arguments] 
2016-12-10 01:58:09 stcWeights false 
2016-12-10 01:58:09 LR 0.015625 
2016-12-10 01:58:09 batchSize 100 
2016-12-10 01:58:09 network ./Models/Cifar10_Custom 
2016-12-10 01:58:09 stcNeurons true 
2016-12-10 01:58:09 constBatchSize false 
2016-12-10 01:58:09 chartFileName chart1 
2016-12-10 01:58:09 dp_prepro false 
2016-12-10 01:58:09 nGPU 1 
2016-12-10 01:58:09 dataset Caltech256 
2016-12-10 01:58:09 type cuda 
2016-12-10 01:58:09 momentum 0 
2016-12-10 01:58:09 threads 8 
2016-12-10 01:58:09 weightDecay 0 
2016-12-10 01:58:09 runningVal false 
2016-12-10 01:58:09 convLayerN 6 
2016-12-10 01:58:09 LRDecay 0 
2016-12-10 01:58:09 numHid 2048 
2016-12-10 01:58:09 save /dev/shm/clone/temp/th/Results/Caltech256/model6-10-2048 
2016-12-10 01:58:09 augment false 
2016-12-10 01:58:09 epoch -1 
2016-12-10 01:58:09 modelsFolder ./Models/ 
2016-12-10 01:58:09 format rgb 
2016-12-10 01:58:09 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 01:58:09 imageFileExtension svg 
2016-12-10 01:58:09 channel 1 
2016-12-10 01:58:09 devid 14 
2016-12-10 01:58:09 visualize 1 
2016-12-10 01:58:09 LRDecayPerEpoch 0.0001 
2016-12-10 01:58:09 optimization adam 
2016-12-10 01:58:09 SBN true 
2016-12-10 01:58:09 normalization simple 
2016-12-10 01:58:09 title model1 
2016-12-10 01:58:09 load  
2016-12-10 01:58:09 whiten true 
2016-12-10 01:58:09 [----------------------] 
2016-12-10 01:58:11 ==> Network 
2016-12-10 01:58:11 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 2048)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(2048 -> 2048)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(2048 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-10 01:58:11 ==>26086781 Parameters 
2016-12-10 01:58:11 ==> Loss 
2016-12-10 01:58:11 SqrtHingeEmbeddingCriterion 
2016-12-10 01:58:11 
==> Starting Training
 
2016-12-10 01:58:11 Epoch 1 
2016-12-10 02:03:59 Training Error = 0.96550719813597 
2016-12-10 02:03:59 Training Loss = 0.1639195671337 
2016-12-10 02:04:05 Valid Error = 0.96143766379633 
2016-12-10 02:04:05 Valid Loss = 0.016385865514512 
2016-12-10 02:04:11 Test Error = 0.97541259683395 
2016-12-10 02:04:11 Test Loss = 0.016229101742304 
2016-12-10 02:04:11 -------------------LR------------------- 
2016-12-10 02:04:11 0.015625 
2016-12-10 02:04:11 Epoch 2 
2016-12-10 02:09:43 Training Error = 0.93842057085795 
2016-12-10 02:09:43 Training Loss = 0.015805751794896 
2016-12-10 02:09:49 Valid Error = 0.95919131411456 
2016-12-10 02:09:49 Valid Loss = 0.015851139926732 
2016-12-10 02:09:56 Test Error = 0.97238127315594 
2016-12-10 02:09:56 Test Loss = 0.015805907649259 
2016-12-10 02:09:56 -------------------LR------------------- 
2016-12-10 02:09:56 0.015625 
2016-12-10 02:09:56 Epoch 3 
2016-12-10 02:15:18 Training Error = 0.93105600399434 
2016-12-10 02:15:18 Training Loss = 0.015536898943967 
2016-12-10 02:15:24 Valid Error = 0.95731935604642 
2016-12-10 02:15:24 Valid Loss = 0.015568836326599 
2016-12-10 02:15:31 Test Error = 0.96934994947794 
2016-12-10 02:15:31 Test Loss = 0.015594851203262 
2016-12-10 02:15:31 -------------------LR------------------- 
2016-12-10 02:15:31 0.015625 
2016-12-10 02:15:31 Epoch 4 
2016-12-10 02:20:56 Training Error = 0.91536989265208 
2016-12-10 02:20:56 Training Loss = 0.015357343008384 
2016-12-10 02:21:02 Valid Error = 0.98128041931861 
2016-12-10 02:21:02 Valid Loss = 0.015800121373353 
2016-12-10 02:21:08 Test Error = 0.98181205793196 
2016-12-10 02:21:08 Test Loss = 0.015766716334842 
2016-12-10 02:21:08 -------------------LR------------------- 
2016-12-10 02:21:08 0.015625 
2016-12-10 02:21:08 Epoch 5 
2016-12-10 02:26:31 Training Error = 0.90446866938504 
2016-12-10 02:26:31 Training Loss = 0.01502886175279 
2016-12-10 02:26:37 Valid Error = 0.96967427929614 
2016-12-10 02:26:37 Valid Loss = 0.015686360427991 
2016-12-10 02:26:44 Test Error = 0.96092960592792 
2016-12-10 02:26:44 Test Loss = 0.015652303866413 
2016-12-10 02:26:44 -------------------LR------------------- 
2016-12-10 02:26:44 0.015625 
2016-12-10 02:26:44 Epoch 6 
2016-12-10 02:32:08 Training Error = 0.88283265374053 
2016-12-10 02:32:08 Training Loss = 0.014804141066411 
2016-12-10 02:32:14 Valid Error = 0.93934855859229 
2016-12-10 02:32:14 Valid Loss = 0.015778718824306 
2016-12-10 02:32:20 Test Error = 0.94577298753789 
2016-12-10 02:32:20 Test Loss = 0.015967456566349 
2016-12-10 02:32:20 -------------------LR------------------- 
2016-12-10 02:32:20 0.015625 
2016-12-10 02:32:21 Epoch 7 
2016-12-10 02:37:40 Training Error = 0.85466422568029 
2016-12-10 02:37:40 Training Loss = 0.01459378850046 
2016-12-10 02:37:46 Valid Error = 0.96929988768252 
2016-12-10 02:37:46 Valid Loss = 0.01576721382065 
2016-12-10 02:37:52 Test Error = 0.96867632199394 
2016-12-10 02:37:52 Test Loss = 0.015827050985336 
2016-12-10 02:37:52 -------------------LR------------------- 
2016-12-10 02:37:52 0.015625 
2016-12-10 02:37:52 Epoch 8 
2016-12-10 02:43:15 Training Error = 0.80648248314887 
2016-12-10 02:43:15 Training Loss = 0.014271183052127 
2016-12-10 02:43:21 Valid Error = 0.87832272557095 
2016-12-10 02:43:21 Valid Loss = 0.015407039778703 
2016-12-10 02:43:28 Test Error = 0.89558773997979 
2016-12-10 02:43:28 Test Loss = 0.015589757073372 
2016-12-10 02:43:28 -------------------LR------------------- 
2016-12-10 02:43:28 0.015625 
2016-12-10 02:43:28 Epoch 9 
2016-12-10 02:48:53 Training Error = 0.72451527003412 
2016-12-10 02:48:53 Training Loss = 0.013728802768643 
2016-12-10 02:48:59 Valid Error = 0.78659678023212 
2016-12-10 02:48:59 Valid Loss = 0.01440146944653 
2016-12-10 02:49:06 Test Error = 0.78073425395756 
2016-12-10 02:49:06 Test Loss = 0.01448448428282 
2016-12-10 02:49:06 -------------------LR------------------- 
2016-12-10 02:49:06 0.015625 
2016-12-10 02:49:06 Epoch 10 
2016-12-10 02:54:22 Training Error = 0.63447615877507 
2016-12-10 02:54:22 Training Loss = 0.013153254010339 
2016-12-10 02:54:28 Valid Error = 0.66005241482591 
2016-12-10 02:54:28 Valid Loss = 0.013183439258955 
2016-12-10 02:54:35 Test Error = 0.65308184573931 
2016-12-10 02:54:35 Test Loss = 0.013284698400184 
2016-12-10 02:54:35 -------------------LR------------------- 
2016-12-10 02:54:35 0.015625 
2016-12-10 02:54:36 Epoch 11 
2016-12-10 02:59:39 Training Error = 0.57102438212532 
2016-12-10 02:59:39 Training Loss = 0.012847761248626 
2016-12-10 02:59:45 Valid Error = 0.64395357543991 
2016-12-10 02:59:45 Valid Loss = 0.013401162696909 
2016-12-10 02:59:52 Test Error = 0.64735601212529 
2016-12-10 02:59:52 Test Loss = 0.01351243803865 
2016-12-10 02:59:52 -------------------LR------------------- 
2016-12-10 02:59:52 0.015625 
2016-12-10 02:59:52 Epoch 12 
2016-12-10 03:04:53 Training Error = 0.56574020138138 
2016-12-10 03:04:53 Training Loss = 0.012839204153867 
2016-12-10 03:04:59 Valid Error = 0.63609135155373 
2016-12-10 03:04:59 Valid Loss = 0.013200905103166 
2016-12-10 03:05:06 Test Error = 0.63388346244527 
2016-12-10 03:05:06 Test Loss = 0.01331075174372 
2016-12-10 03:05:06 -------------------LR------------------- 
2016-12-10 03:05:06 0.015625 
2016-12-10 03:05:06 Epoch 13 
2016-12-10 03:10:06 Training Error = 0.56736290255471 
2016-12-10 03:10:06 Training Loss = 0.012856209177688 
2016-12-10 03:10:12 Valid Error = 0.64507675028079 
2016-12-10 03:10:12 Valid Loss = 0.013279962681797 
2016-12-10 03:10:19 Test Error = 0.63590434489727 
2016-12-10 03:10:19 Test Loss = 0.013312474451032 
2016-12-10 03:10:19 -------------------LR------------------- 
2016-12-10 03:10:19 0.015625 
2016-12-10 03:10:19 Epoch 14 
2016-12-10 03:15:17 Training Error = 0.57131563618208 
2016-12-10 03:15:17 Training Loss = 0.012855970799922 
2016-12-10 03:15:23 Valid Error = 0.65406214900786 
2016-12-10 03:15:23 Valid Loss = 0.013371623991788 
2016-12-10 03:15:30 Test Error = 0.65712361064331 
2016-12-10 03:15:30 Test Loss = 0.01354047909493 
2016-12-10 03:15:30 -------------------LR------------------- 
2016-12-10 03:15:30 0.015625 
2016-12-10 03:15:30 Epoch 15 
2016-12-10 03:20:31 Training Error = 0.56881917283848 
2016-12-10 03:20:31 Training Loss = 0.012841103308789 
2016-12-10 03:20:37 Valid Error = 0.64732309996256 
2016-12-10 03:20:37 Valid Loss = 0.013257162562082 
2016-12-10 03:20:44 Test Error = 0.63893566857528 
2016-12-10 03:20:44 Test Loss = 0.013304223250656 
2016-12-10 03:20:44 -------------------LR------------------- 
2016-12-10 03:20:44 0.015625 
2016-12-10 03:20:44 Epoch 16 
2016-12-10 03:25:44 Training Error = 0.56936007322959 
2016-12-10 03:25:44 Training Loss = 0.012868503780674 
2016-12-10 03:25:50 Valid Error = 0.63908648446275 
2016-12-10 03:25:50 Valid Loss = 0.013490495088081 
2016-12-10 03:25:56 Test Error = 0.64365106096329 
2016-12-10 03:25:56 Test Loss = 0.013656417557316 
2016-12-10 03:25:56 -------------------LR------------------- 
2016-12-10 03:25:56 0.015625 
2016-12-10 03:25:56 Epoch 17 
2016-12-10 03:31:02 Training Error = 0.56678039444121 
2016-12-10 03:31:02 Training Loss = 0.012837994404366 
2016-12-10 03:31:08 Valid Error = 0.65031823287158 
2016-12-10 03:31:08 Valid Loss = 0.013461686486839 
2016-12-10 03:31:15 Test Error = 0.65341865948131 
2016-12-10 03:31:15 Test Loss = 0.013609214363123 
2016-12-10 03:31:15 -------------------LR------------------- 
2016-12-10 03:31:15 0.015625 
2016-12-10 03:31:15 Epoch 18 
2016-12-10 03:36:18 Training Error = 0.57069152034618 
2016-12-10 03:36:18 Training Loss = 0.012836231837979 
2016-12-10 03:36:24 Valid Error = 0.64507675028079 
2016-12-10 03:36:24 Valid Loss = 0.01319280530024 
2016-12-10 03:36:30 Test Error = 0.63960929605928 
2016-12-10 03:36:30 Test Loss = 0.013240418121636 
2016-12-10 03:36:30 -------------------LR------------------- 
2016-12-10 03:36:30 0.015625 
2016-12-10 03:36:30 Epoch 19 
2016-12-10 03:41:31 Training Error = 0.56877756511609 
2016-12-10 03:41:31 Training Loss = 0.012843954564038 
2016-12-10 03:41:37 Valid Error = 0.64994384125796 
2016-12-10 03:41:37 Valid Loss = 0.013385464593564 
2016-12-10 03:41:44 Test Error = 0.65375547322331 
2016-12-10 03:41:44 Test Loss = 0.013511612500148 
2016-12-10 03:41:44 -------------------LR------------------- 
2016-12-10 03:41:44 0.015625 
2016-12-10 03:41:44 Epoch 20 
2016-12-10 03:46:47 Training Error = 0.56536573187984 
2016-12-10 03:46:47 Training Loss = 0.012836688648647 
2016-12-10 03:46:53 Valid Error = 0.64170722575814 
2016-12-10 03:46:53 Valid Loss = 0.01327338422292 
2016-12-10 03:47:00 Test Error = 0.63994610980128 
2016-12-10 03:47:00 Test Loss = 0.013348609629894 
2016-12-10 03:47:00 -------------------LR------------------- 
2016-12-10 03:47:00 0.015625 
2016-12-10 03:47:00 Epoch 21 
2016-12-10 03:52:06 Training Error = 0.5699009736207 
2016-12-10 03:52:06 Training Loss = 0.012855534663657 
2016-12-10 03:52:12 Valid Error = 0.64095844253089 
2016-12-10 03:52:12 Valid Loss = 0.013169793584242 
2016-12-10 03:52:19 Test Error = 0.63826204109128 
2016-12-10 03:52:19 Test Loss = 0.013252884288375 
2016-12-10 03:52:19 -------------------LR------------------- 
2016-12-10 03:52:19 0.015625 
2016-12-10 03:52:19 Epoch 22 
2016-12-10 03:56:56 Training Error = 0.56827827244737 
2016-12-10 03:56:56 Training Loss = 0.012850056286556 
2016-12-10 03:57:02 Valid Error = 0.63796330962186 
2016-12-10 03:57:02 Valid Loss = 0.013183545999153 
2016-12-10 03:57:08 Test Error = 0.63422027618727 
2016-12-10 03:57:08 Test Loss = 0.01323576840423 
2016-12-10 03:57:08 -------------------LR------------------- 
2016-12-10 03:57:08 0.015625 
2016-12-10 03:57:08 Epoch 23 
2016-12-10 04:01:37 Training Error = 0.56894399600566 
2016-12-10 04:01:37 Training Loss = 0.01284380883894 
2016-12-10 04:01:43 Valid Error = 0.63983526769 
2016-12-10 04:01:43 Valid Loss = 0.013228104649829 
2016-12-10 04:01:50 Test Error = 0.64398787470529 
2016-12-10 04:01:50 Test Loss = 0.013320423050122 
2016-12-10 04:01:50 -------------------LR------------------- 
2016-12-10 04:01:50 0.015625 
2016-12-10 04:01:50 Epoch 24 
2016-12-10 04:06:22 Training Error = 0.57069152034618 
2016-12-10 04:06:22 Training Loss = 0.01285364447836 
2016-12-10 04:06:28 Valid Error = 0.64507675028079 
2016-12-10 04:06:28 Valid Loss = 0.013233349385629 
2016-12-10 04:06:35 Test Error = 0.63590434489727 
2016-12-10 04:06:35 Test Loss = 0.013285695544199 
2016-12-10 04:06:35 -------------------LR------------------- 
2016-12-10 04:06:35 0.015625 
2016-12-10 04:06:35 Epoch 25 
2016-12-10 04:11:09 Training Error = 0.56956811184156 
2016-12-10 04:11:09 Training Loss = 0.012847372983365 
2016-12-10 04:11:15 Valid Error = 0.64020965930363 
2016-12-10 04:11:15 Valid Loss = 0.013299521754619 
2016-12-10 04:11:22 Test Error = 0.63725159986527 
2016-12-10 04:11:22 Test Loss = 0.013368901256414 
2016-12-10 04:11:22 -------------------LR------------------- 
2016-12-10 04:11:22 0.015625 
2016-12-10 04:11:22 Epoch 26 
2016-12-10 04:15:54 Training Error = 0.57035865856703 
2016-12-10 04:15:54 Training Loss = 0.012844031472506 
2016-12-10 04:16:00 Valid Error = 0.64994384125796 
2016-12-10 04:16:00 Valid Loss = 0.013196899035742 
2016-12-10 04:16:07 Test Error = 0.64398787470529 
2016-12-10 04:16:07 Test Loss = 0.013272229386063 
2016-12-10 04:16:07 -------------------LR------------------- 
2016-12-10 04:16:07 0.015625 
2016-12-10 04:16:07 Epoch 27 
2016-12-10 04:20:41 Training Error = 0.56856952650412 
2016-12-10 04:20:41 Training Loss = 0.01284601123092 
2016-12-10 04:20:47 Valid Error = 0.64807188318982 
2016-12-10 04:20:47 Valid Loss = 0.013204541533538 
2016-12-10 04:20:54 Test Error = 0.63960929605928 
2016-12-10 04:20:54 Test Loss = 0.013250960202049 
2016-12-10 04:20:54 -------------------LR------------------- 
2016-12-10 04:20:54 0.015625 
2016-12-10 04:20:54 Epoch 28 
