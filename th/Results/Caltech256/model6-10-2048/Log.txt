2016-12-10 01:58:09 [program started on Sat Dec 10 01:58:09 2016] 
2016-12-10 01:58:09 [command line arguments] 
2016-12-10 01:58:09 stcWeights false 
2016-12-10 01:58:09 LR 0.015625 
2016-12-10 01:58:09 batchSize 100 
2016-12-10 01:58:09 network ./Models/Cifar10_Custom 
2016-12-10 01:58:09 stcNeurons true 
2016-12-10 01:58:09 constBatchSize false 
2016-12-10 01:58:09 chartFileName chart1 
2016-12-10 01:58:09 dp_prepro false 
2016-12-10 01:58:09 nGPU 1 
2016-12-10 01:58:09 dataset Caltech256 
2016-12-10 01:58:09 type cuda 
2016-12-10 01:58:09 momentum 0 
2016-12-10 01:58:09 threads 8 
2016-12-10 01:58:09 weightDecay 0 
2016-12-10 01:58:09 runningVal false 
2016-12-10 01:58:09 convLayerN 6 
2016-12-10 01:58:09 LRDecay 0 
2016-12-10 01:58:09 numHid 2048 
2016-12-10 01:58:09 save /dev/shm/clone/temp/th/Results/Caltech256/model6-10-2048 
2016-12-10 01:58:09 augment false 
2016-12-10 01:58:09 epoch -1 
2016-12-10 01:58:09 modelsFolder ./Models/ 
2016-12-10 01:58:09 format rgb 
2016-12-10 01:58:09 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 01:58:09 imageFileExtension svg 
2016-12-10 01:58:09 channel 1 
2016-12-10 01:58:09 devid 14 
2016-12-10 01:58:09 visualize 1 
2016-12-10 01:58:09 LRDecayPerEpoch 0.0001 
2016-12-10 01:58:09 optimization adam 
2016-12-10 01:58:09 SBN true 
2016-12-10 01:58:09 normalization simple 
2016-12-10 01:58:09 title model1 
2016-12-10 01:58:09 load  
2016-12-10 01:58:09 whiten true 
2016-12-10 01:58:09 [----------------------] 
2016-12-10 01:58:11 ==> Network 
2016-12-10 01:58:11 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 2048)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(2048 -> 2048)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(2048 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-10 01:58:11 ==>26086781 Parameters 
2016-12-10 01:58:11 ==> Loss 
2016-12-10 01:58:11 SqrtHingeEmbeddingCriterion 
2016-12-10 01:58:11 
==> Starting Training
 
2016-12-10 01:58:11 Epoch 1 
2016-12-10 02:03:59 Training Error = 0.96550719813597 
2016-12-10 02:03:59 Training Loss = 0.1639195671337 
2016-12-10 02:04:05 Valid Error = 0.96143766379633 
2016-12-10 02:04:05 Valid Loss = 0.016385865514512 
2016-12-10 02:04:11 Test Error = 0.97541259683395 
2016-12-10 02:04:11 Test Loss = 0.016229101742304 
2016-12-10 02:04:11 -------------------LR------------------- 
2016-12-10 02:04:11 0.015625 
2016-12-10 02:04:11 Epoch 2 
2016-12-10 02:09:43 Training Error = 0.93842057085795 
2016-12-10 02:09:43 Training Loss = 0.015805751794896 
2016-12-10 02:09:49 Valid Error = 0.95919131411456 
2016-12-10 02:09:49 Valid Loss = 0.015851139926732 
2016-12-10 02:09:56 Test Error = 0.97238127315594 
2016-12-10 02:09:56 Test Loss = 0.015805907649259 
2016-12-10 02:09:56 -------------------LR------------------- 
2016-12-10 02:09:56 0.015625 
2016-12-10 02:09:56 Epoch 3 
2016-12-10 02:15:18 Training Error = 0.93105600399434 
2016-12-10 02:15:18 Training Loss = 0.015536898943967 
2016-12-10 02:15:24 Valid Error = 0.95731935604642 
2016-12-10 02:15:24 Valid Loss = 0.015568836326599 
2016-12-10 02:15:31 Test Error = 0.96934994947794 
2016-12-10 02:15:31 Test Loss = 0.015594851203262 
2016-12-10 02:15:31 -------------------LR------------------- 
2016-12-10 02:15:31 0.015625 
2016-12-10 02:15:31 Epoch 4 
2016-12-10 02:20:56 Training Error = 0.91536989265208 
2016-12-10 02:20:56 Training Loss = 0.015357343008384 
2016-12-10 02:21:02 Valid Error = 0.98128041931861 
2016-12-10 02:21:02 Valid Loss = 0.015800121373353 
2016-12-10 02:21:08 Test Error = 0.98181205793196 
2016-12-10 02:21:08 Test Loss = 0.015766716334842 
2016-12-10 02:21:08 -------------------LR------------------- 
2016-12-10 02:21:08 0.015625 
2016-12-10 02:21:08 Epoch 5 
2016-12-10 02:26:31 Training Error = 0.90446866938504 
2016-12-10 02:26:31 Training Loss = 0.01502886175279 
2016-12-10 02:26:37 Valid Error = 0.96967427929614 
2016-12-10 02:26:37 Valid Loss = 0.015686360427991 
2016-12-10 02:26:44 Test Error = 0.96092960592792 
2016-12-10 02:26:44 Test Loss = 0.015652303866413 
2016-12-10 02:26:44 -------------------LR------------------- 
2016-12-10 02:26:44 0.015625 
2016-12-10 02:26:44 Epoch 6 
2016-12-10 02:32:08 Training Error = 0.88283265374053 
2016-12-10 02:32:08 Training Loss = 0.014804141066411 
2016-12-10 02:32:14 Valid Error = 0.93934855859229 
2016-12-10 02:32:14 Valid Loss = 0.015778718824306 
2016-12-10 02:32:20 Test Error = 0.94577298753789 
2016-12-10 02:32:20 Test Loss = 0.015967456566349 
2016-12-10 02:32:20 -------------------LR------------------- 
2016-12-10 02:32:20 0.015625 
2016-12-10 02:32:21 Epoch 7 
2016-12-10 02:37:40 Training Error = 0.85466422568029 
2016-12-10 02:37:40 Training Loss = 0.01459378850046 
2016-12-10 02:37:46 Valid Error = 0.96929988768252 
2016-12-10 02:37:46 Valid Loss = 0.01576721382065 
2016-12-10 02:37:52 Test Error = 0.96867632199394 
2016-12-10 02:37:52 Test Loss = 0.015827050985336 
2016-12-10 02:37:52 -------------------LR------------------- 
2016-12-10 02:37:52 0.015625 
2016-12-10 02:37:52 Epoch 8 
2016-12-10 02:43:15 Training Error = 0.80648248314887 
2016-12-10 02:43:15 Training Loss = 0.014271183052127 
2016-12-10 02:43:21 Valid Error = 0.87832272557095 
2016-12-10 02:43:21 Valid Loss = 0.015407039778703 
2016-12-10 02:43:28 Test Error = 0.89558773997979 
2016-12-10 02:43:28 Test Loss = 0.015589757073372 
2016-12-10 02:43:28 -------------------LR------------------- 
2016-12-10 02:43:28 0.015625 
2016-12-10 02:43:28 Epoch 9 
2016-12-10 02:48:53 Training Error = 0.72451527003412 
2016-12-10 02:48:53 Training Loss = 0.013728802768643 
2016-12-10 02:48:59 Valid Error = 0.78659678023212 
2016-12-10 02:48:59 Valid Loss = 0.01440146944653 
2016-12-10 02:49:06 Test Error = 0.78073425395756 
2016-12-10 02:49:06 Test Loss = 0.01448448428282 
2016-12-10 02:49:06 -------------------LR------------------- 
2016-12-10 02:49:06 0.015625 
2016-12-10 02:49:06 Epoch 10 
2016-12-10 02:54:22 Training Error = 0.63447615877507 
2016-12-10 02:54:22 Training Loss = 0.013153254010339 
2016-12-10 02:54:28 Valid Error = 0.66005241482591 
2016-12-10 02:54:28 Valid Loss = 0.013183439258955 
2016-12-10 02:54:35 Test Error = 0.65308184573931 
2016-12-10 02:54:35 Test Loss = 0.013284698400184 
2016-12-10 02:54:35 -------------------LR------------------- 
2016-12-10 02:54:35 0.015625 
2016-12-10 02:54:36 Epoch 11 
2016-12-10 02:59:39 Training Error = 0.57102438212532 
2016-12-10 02:59:39 Training Loss = 0.012847761248626 
2016-12-10 02:59:45 Valid Error = 0.64395357543991 
2016-12-10 02:59:45 Valid Loss = 0.013401162696909 
2016-12-10 02:59:52 Test Error = 0.64735601212529 
2016-12-10 02:59:52 Test Loss = 0.01351243803865 
2016-12-10 02:59:52 -------------------LR------------------- 
2016-12-10 02:59:52 0.015625 
2016-12-10 02:59:52 Epoch 12 
2016-12-10 03:04:53 Training Error = 0.56574020138138 
2016-12-10 03:04:53 Training Loss = 0.012839204153867 
2016-12-10 03:04:59 Valid Error = 0.63609135155373 
2016-12-10 03:04:59 Valid Loss = 0.013200905103166 
2016-12-10 03:05:06 Test Error = 0.63388346244527 
2016-12-10 03:05:06 Test Loss = 0.01331075174372 
2016-12-10 03:05:06 -------------------LR------------------- 
2016-12-10 03:05:06 0.015625 
2016-12-10 03:05:06 Epoch 13 
2016-12-10 03:10:06 Training Error = 0.56736290255471 
2016-12-10 03:10:06 Training Loss = 0.012856209177688 
2016-12-10 03:10:12 Valid Error = 0.64507675028079 
2016-12-10 03:10:12 Valid Loss = 0.013279962681797 
2016-12-10 03:10:19 Test Error = 0.63590434489727 
2016-12-10 03:10:19 Test Loss = 0.013312474451032 
2016-12-10 03:10:19 -------------------LR------------------- 
2016-12-10 03:10:19 0.015625 
2016-12-10 03:10:19 Epoch 14 
2016-12-10 03:15:17 Training Error = 0.57131563618208 
2016-12-10 03:15:17 Training Loss = 0.012855970799922 
2016-12-10 03:15:23 Valid Error = 0.65406214900786 
2016-12-10 03:15:23 Valid Loss = 0.013371623991788 
2016-12-10 03:15:30 Test Error = 0.65712361064331 
2016-12-10 03:15:30 Test Loss = 0.01354047909493 
2016-12-10 03:15:30 -------------------LR------------------- 
2016-12-10 03:15:30 0.015625 
2016-12-10 03:15:30 Epoch 15 
2016-12-10 03:20:31 Training Error = 0.56881917283848 
2016-12-10 03:20:31 Training Loss = 0.012841103308789 
2016-12-10 03:20:37 Valid Error = 0.64732309996256 
2016-12-10 03:20:37 Valid Loss = 0.013257162562082 
2016-12-10 03:20:44 Test Error = 0.63893566857528 
2016-12-10 03:20:44 Test Loss = 0.013304223250656 
2016-12-10 03:20:44 -------------------LR------------------- 
2016-12-10 03:20:44 0.015625 
2016-12-10 03:20:44 Epoch 16 
2016-12-10 03:25:44 Training Error = 0.56936007322959 
2016-12-10 03:25:44 Training Loss = 0.012868503780674 
2016-12-10 03:25:50 Valid Error = 0.63908648446275 
2016-12-10 03:25:50 Valid Loss = 0.013490495088081 
2016-12-10 03:25:56 Test Error = 0.64365106096329 
2016-12-10 03:25:56 Test Loss = 0.013656417557316 
2016-12-10 03:25:56 -------------------LR------------------- 
2016-12-10 03:25:56 0.015625 
2016-12-10 03:25:56 Epoch 17 
2016-12-10 03:31:02 Training Error = 0.56678039444121 
2016-12-10 03:31:02 Training Loss = 0.012837994404366 
2016-12-10 03:31:08 Valid Error = 0.65031823287158 
2016-12-10 03:31:08 Valid Loss = 0.013461686486839 
2016-12-10 03:31:15 Test Error = 0.65341865948131 
2016-12-10 03:31:15 Test Loss = 0.013609214363123 
2016-12-10 03:31:15 -------------------LR------------------- 
2016-12-10 03:31:15 0.015625 
2016-12-10 03:31:15 Epoch 18 
2016-12-10 03:36:18 Training Error = 0.57069152034618 
2016-12-10 03:36:18 Training Loss = 0.012836231837979 
2016-12-10 03:36:24 Valid Error = 0.64507675028079 
2016-12-10 03:36:24 Valid Loss = 0.01319280530024 
2016-12-10 03:36:30 Test Error = 0.63960929605928 
2016-12-10 03:36:30 Test Loss = 0.013240418121636 
2016-12-10 03:36:30 -------------------LR------------------- 
2016-12-10 03:36:30 0.015625 
2016-12-10 03:36:30 Epoch 19 
2016-12-10 03:41:31 Training Error = 0.56877756511609 
2016-12-10 03:41:31 Training Loss = 0.012843954564038 
2016-12-10 03:41:37 Valid Error = 0.64994384125796 
2016-12-10 03:41:37 Valid Loss = 0.013385464593564 
2016-12-10 03:41:44 Test Error = 0.65375547322331 
2016-12-10 03:41:44 Test Loss = 0.013511612500148 
2016-12-10 03:41:44 -------------------LR------------------- 
2016-12-10 03:41:44 0.015625 
2016-12-10 03:41:44 Epoch 20 
2016-12-10 03:46:47 Training Error = 0.56536573187984 
2016-12-10 03:46:47 Training Loss = 0.012836688648647 
2016-12-10 03:46:53 Valid Error = 0.64170722575814 
2016-12-10 03:46:53 Valid Loss = 0.01327338422292 
2016-12-10 03:47:00 Test Error = 0.63994610980128 
2016-12-10 03:47:00 Test Loss = 0.013348609629894 
2016-12-10 03:47:00 -------------------LR------------------- 
2016-12-10 03:47:00 0.015625 
2016-12-10 03:47:00 Epoch 21 
2016-12-10 03:52:06 Training Error = 0.5699009736207 
2016-12-10 03:52:06 Training Loss = 0.012855534663657 
2016-12-10 03:52:12 Valid Error = 0.64095844253089 
2016-12-10 03:52:12 Valid Loss = 0.013169793584242 
2016-12-10 03:52:19 Test Error = 0.63826204109128 
2016-12-10 03:52:19 Test Loss = 0.013252884288375 
2016-12-10 03:52:19 -------------------LR------------------- 
2016-12-10 03:52:19 0.015625 
2016-12-10 03:52:19 Epoch 22 
2016-12-10 03:56:56 Training Error = 0.56827827244737 
2016-12-10 03:56:56 Training Loss = 0.012850056286556 
2016-12-10 03:57:02 Valid Error = 0.63796330962186 
2016-12-10 03:57:02 Valid Loss = 0.013183545999153 
2016-12-10 03:57:08 Test Error = 0.63422027618727 
2016-12-10 03:57:08 Test Loss = 0.01323576840423 
2016-12-10 03:57:08 -------------------LR------------------- 
2016-12-10 03:57:08 0.015625 
2016-12-10 03:57:08 Epoch 23 
2016-12-10 04:01:37 Training Error = 0.56894399600566 
2016-12-10 04:01:37 Training Loss = 0.01284380883894 
2016-12-10 04:01:43 Valid Error = 0.63983526769 
2016-12-10 04:01:43 Valid Loss = 0.013228104649829 
2016-12-10 04:01:50 Test Error = 0.64398787470529 
2016-12-10 04:01:50 Test Loss = 0.013320423050122 
2016-12-10 04:01:50 -------------------LR------------------- 
2016-12-10 04:01:50 0.015625 
2016-12-10 04:01:50 Epoch 24 
2016-12-10 04:06:22 Training Error = 0.57069152034618 
2016-12-10 04:06:22 Training Loss = 0.01285364447836 
2016-12-10 04:06:28 Valid Error = 0.64507675028079 
2016-12-10 04:06:28 Valid Loss = 0.013233349385629 
2016-12-10 04:06:35 Test Error = 0.63590434489727 
2016-12-10 04:06:35 Test Loss = 0.013285695544199 
2016-12-10 04:06:35 -------------------LR------------------- 
2016-12-10 04:06:35 0.015625 
2016-12-10 04:06:35 Epoch 25 
2016-12-10 04:11:09 Training Error = 0.56956811184156 
2016-12-10 04:11:09 Training Loss = 0.012847372983365 
2016-12-10 04:11:15 Valid Error = 0.64020965930363 
2016-12-10 04:11:15 Valid Loss = 0.013299521754619 
2016-12-10 04:11:22 Test Error = 0.63725159986527 
2016-12-10 04:11:22 Test Loss = 0.013368901256414 
2016-12-10 04:11:22 -------------------LR------------------- 
2016-12-10 04:11:22 0.015625 
2016-12-10 04:11:22 Epoch 26 
2016-12-10 04:15:54 Training Error = 0.57035865856703 
2016-12-10 04:15:54 Training Loss = 0.012844031472506 
2016-12-10 04:16:00 Valid Error = 0.64994384125796 
2016-12-10 04:16:00 Valid Loss = 0.013196899035742 
2016-12-10 04:16:07 Test Error = 0.64398787470529 
2016-12-10 04:16:07 Test Loss = 0.013272229386063 
2016-12-10 04:16:07 -------------------LR------------------- 
2016-12-10 04:16:07 0.015625 
2016-12-10 04:16:07 Epoch 27 
2016-12-10 04:20:41 Training Error = 0.56856952650412 
2016-12-10 04:20:41 Training Loss = 0.01284601123092 
2016-12-10 04:20:47 Valid Error = 0.64807188318982 
2016-12-10 04:20:47 Valid Loss = 0.013204541533538 
2016-12-10 04:20:54 Test Error = 0.63960929605928 
2016-12-10 04:20:54 Test Loss = 0.013250960202049 
2016-12-10 04:20:54 -------------------LR------------------- 
2016-12-10 04:20:54 0.015625 
2016-12-10 04:20:54 Epoch 28 
2016-12-10 04:25:24 Training Error = 0.57023383539985 
2016-12-10 04:25:24 Training Loss = 0.012846093387552 
2016-12-10 04:25:30 Valid Error = 0.6491950580307 
2016-12-10 04:25:30 Valid Loss = 0.013161402034681 
2016-12-10 04:25:36 Test Error = 0.64331424722129 
2016-12-10 04:25:36 Test Loss = 0.013245471725037 
2016-12-10 04:25:36 -------------------LR------------------- 
2016-12-10 04:25:36 0.015625 
2016-12-10 04:25:36 Epoch 29 
2016-12-10 04:30:13 Training Error = 0.57031705084464 
2016-12-10 04:30:13 Training Loss = 0.012850458387089 
2016-12-10 04:30:19 Valid Error = 0.63871209284912 
2016-12-10 04:30:19 Valid Loss = 0.013174476891747 
2016-12-10 04:30:25 Test Error = 0.64028292354328 
2016-12-10 04:30:25 Test Loss = 0.013252172857922 
2016-12-10 04:30:25 -------------------LR------------------- 
2016-12-10 04:30:25 0.015625 
2016-12-10 04:30:26 Epoch 30 
2016-12-10 04:35:03 Training Error = 0.56815344928019 
2016-12-10 04:35:03 Training Loss = 0.0128441525441 
2016-12-10 04:35:09 Valid Error = 0.64956944964433 
2016-12-10 04:35:09 Valid Loss = 0.01337661309125 
2016-12-10 04:35:16 Test Error = 0.65308184573931 
2016-12-10 04:35:16 Test Loss = 0.013521889560675 
2016-12-10 04:35:16 -------------------LR------------------- 
2016-12-10 04:35:16 0.015625 
2016-12-10 04:35:16 Epoch 31 
2016-12-10 04:39:52 Training Error = 0.56815344928019 
2016-12-10 04:39:52 Training Loss = 0.012849748593531 
2016-12-10 04:39:58 Valid Error = 0.64470235866717 
2016-12-10 04:39:58 Valid Loss = 0.013426342408601 
2016-12-10 04:40:05 Test Error = 0.65510272819131 
2016-12-10 04:40:05 Test Loss = 0.013582506840308 
2016-12-10 04:40:05 -------------------LR------------------- 
2016-12-10 04:40:05 0.015625 
2016-12-10 04:40:05 Epoch 32 
2016-12-10 04:44:37 Training Error = 0.5686943496713 
2016-12-10 04:44:37 Training Loss = 0.012837725127967 
2016-12-10 04:44:43 Valid Error = 0.63983526769 
2016-12-10 04:44:43 Valid Loss = 0.013255136099003 
2016-12-10 04:44:50 Test Error = 0.63455708992927 
2016-12-10 04:44:50 Test Loss = 0.013325936887047 
2016-12-10 04:44:50 -------------------LR------------------- 
2016-12-10 04:44:50 0.015625 
2016-12-10 04:44:50 Epoch 33 
2016-12-10 04:49:25 Training Error = 0.56952650411916 
2016-12-10 04:49:25 Training Loss = 0.012847534067664 
2016-12-10 04:49:31 Valid Error = 0.655934107076 
2016-12-10 04:49:31 Valid Loss = 0.013208919564126 
2016-12-10 04:49:38 Test Error = 0.65746042438531 
2016-12-10 04:49:38 Test Loss = 0.013313079071406 
2016-12-10 04:49:38 -------------------LR------------------- 
2016-12-10 04:49:38 0.015625 
2016-12-10 04:49:38 Epoch 34 
2016-12-10 04:54:11 Training Error = 0.57160689023883 
2016-12-10 04:54:11 Training Loss = 0.012849474949382 
2016-12-10 04:54:17 Valid Error = 0.63833770123549 
2016-12-10 04:54:17 Valid Loss = 0.013177973270948 
2016-12-10 04:54:24 Test Error = 0.64095655102728 
2016-12-10 04:54:24 Test Loss = 0.013273104791622 
2016-12-10 04:54:24 -------------------LR------------------- 
2016-12-10 04:54:24 0.015625 
2016-12-10 04:54:24 Epoch 35 
2016-12-10 04:58:59 Training Error = 0.56919364234002 
2016-12-10 04:58:59 Training Loss = 0.012855795066244 
2016-12-10 04:59:05 Valid Error = 0.63796330962186 
2016-12-10 04:59:05 Valid Loss = 0.013386960592606 
2016-12-10 04:59:11 Test Error = 0.64466150218929 
2016-12-10 04:59:11 Test Loss = 0.013553247125237 
2016-12-10 04:59:11 -------------------LR------------------- 
2016-12-10 04:59:11 0.015625 
2016-12-10 04:59:11 Epoch 36 
2016-12-10 05:03:40 Training Error = 0.5686943496713 
2016-12-10 05:03:40 Training Loss = 0.012842489659529 
2016-12-10 05:03:46 Valid Error = 0.6491950580307 
2016-12-10 05:03:46 Valid Loss = 0.013124057894673 
2016-12-10 05:03:52 Test Error = 0.64466150218929 
2016-12-10 05:03:52 Test Loss = 0.013215588278887 
2016-12-10 05:03:52 -------------------LR------------------- 
2016-12-10 05:03:52 0.015625 
2016-12-10 05:03:52 Epoch 37 
2016-12-10 05:08:32 Training Error = 0.57006740451028 
2016-12-10 05:08:32 Training Loss = 0.012851410212105 
2016-12-10 05:08:38 Valid Error = 0.62785473605391 
2016-12-10 05:08:38 Valid Loss = 0.013173985933533 
2016-12-10 05:08:45 Test Error = 0.62209498147524 
2016-12-10 05:08:45 Test Loss = 0.01320368009269 
2016-12-10 05:08:45 -------------------LR------------------- 
2016-12-10 05:08:45 0.015625 
2016-12-10 05:08:45 Epoch 38 
2016-12-10 05:13:17 Training Error = 0.57002579678788 
2016-12-10 05:13:17 Training Loss = 0.012852161386019 
2016-12-10 05:13:23 Valid Error = 0.64694870834893 
2016-12-10 05:13:23 Valid Loss = 0.013175181596305 
2016-12-10 05:13:30 Test Error = 0.64297743347929 
2016-12-10 05:13:30 Test Loss = 0.013280690761406 
2016-12-10 05:13:30 -------------------LR------------------- 
2016-12-10 05:13:30 0.015625 
2016-12-10 05:13:30 Epoch 39 
2016-12-10 05:18:03 Training Error = 0.56782058750104 
2016-12-10 05:18:03 Training Loss = 0.012842664232076 
2016-12-10 05:18:09 Valid Error = 0.64769749157619 
2016-12-10 05:18:09 Valid Loss = 0.013398331178702 
2016-12-10 05:18:16 Test Error = 0.64735601212529 
2016-12-10 05:18:16 Test Loss = 0.013503591021948 
2016-12-10 05:18:16 -------------------LR------------------- 
2016-12-10 05:18:16 0.015625 
2016-12-10 05:18:16 Epoch 40 
2016-12-10 05:22:55 Training Error = 0.57040026628942 
2016-12-10 05:22:55 Training Loss = 0.012848213235272 
2016-12-10 05:23:01 Valid Error = 0.63758891800824 
2016-12-10 05:23:01 Valid Loss = 0.013327133742915 
2016-12-10 05:23:07 Test Error = 0.63691478612327 
2016-12-10 05:23:07 Test Loss = 0.013434336424186 
2016-12-10 05:23:07 -------------------LR------------------- 
2016-12-10 05:23:07 0.015625 
2016-12-10 05:23:08 Epoch 41 
2016-12-10 05:27:38 Training Error = 0.57077473579096 
2016-12-10 05:27:38 Training Loss = 0.012852016558132 
2016-12-10 05:27:44 Valid Error = 0.6518157993261 
2016-12-10 05:27:44 Valid Loss = 0.01320265769621 
2016-12-10 05:27:51 Test Error = 0.64668238464129 
2016-12-10 05:27:51 Test Loss = 0.013297040614159 
2016-12-10 05:27:51 -------------------LR------------------- 
2016-12-10 05:27:51 0.015625 
2016-12-10 05:27:51 Epoch 42 
2016-12-10 05:32:21 Training Error = 0.57094116668054 
2016-12-10 05:32:21 Training Loss = 0.012869872043337 
2016-12-10 05:32:27 Valid Error = 0.64357918382628 
2016-12-10 05:32:27 Valid Loss = 0.013200565646886 
2016-12-10 05:32:33 Test Error = 0.63590434489727 
2016-12-10 05:32:33 Test Loss = 0.013264355220724 
2016-12-10 05:32:33 -------------------LR------------------- 
2016-12-10 05:32:33 0.015625 
2016-12-10 05:32:34 Epoch 43 
2016-12-10 05:37:08 Training Error = 0.56653074810685 
2016-12-10 05:37:08 Training Loss = 0.012851391986152 
2016-12-10 05:37:14 Valid Error = 0.63983526769 
2016-12-10 05:37:14 Valid Loss = 0.013251505380278 
2016-12-10 05:37:21 Test Error = 0.63590434489727 
2016-12-10 05:37:21 Test Loss = 0.013342170244574 
2016-12-10 05:37:21 -------------------LR------------------- 
2016-12-10 05:37:21 0.015625 
2016-12-10 05:37:21 Epoch 44 
2016-12-10 05:41:56 Training Error = 0.56632270949488 
2016-12-10 05:41:56 Training Loss = 0.012841629051324 
2016-12-10 05:42:03 Valid Error = 0.63721452639461 
2016-12-10 05:42:03 Valid Loss = 0.013209129952404 
2016-12-10 05:42:09 Test Error = 0.62748400134725 
2016-12-10 05:42:09 Test Loss = 0.013226301212063 
2016-12-10 05:42:09 -------------------LR------------------- 
2016-12-10 05:42:09 0.015625 
2016-12-10 05:42:09 Epoch 45 
2016-12-10 05:47:04 Training Error = 0.57148206707165 
2016-12-10 05:47:04 Training Loss = 0.012849693732084 
2016-12-10 05:47:10 Valid Error = 0.63758891800824 
2016-12-10 05:47:10 Valid Loss = 0.013251838200334 
2016-12-10 05:47:17 Test Error = 0.63422027618727 
2016-12-10 05:47:17 Test Loss = 0.013337953186469 
2016-12-10 05:47:17 -------------------LR------------------- 
2016-12-10 05:47:17 0.015625 
2016-12-10 05:47:17 Epoch 46 
2016-12-10 05:52:41 Training Error = 0.5705250894566 
2016-12-10 05:52:41 Training Loss = 0.0128613812411 
2016-12-10 05:52:47 Valid Error = 0.64807188318982 
2016-12-10 05:52:47 Valid Loss = 0.013311628173096 
2016-12-10 05:52:54 Test Error = 0.65476591444931 
2016-12-10 05:52:54 Test Loss = 0.013417243164155 
2016-12-10 05:52:54 -------------------LR------------------- 
2016-12-10 05:52:54 0.015625 
2016-12-10 05:52:54 Epoch 47 
2016-12-10 05:58:03 Training Error = 0.56898560372805 
2016-12-10 05:58:03 Training Loss = 0.012846206260542 
2016-12-10 05:58:09 Valid Error = 0.63272182703107 
2016-12-10 05:58:09 Valid Loss = 0.013192848986322 
2016-12-10 05:58:16 Test Error = 0.62916807005726 
2016-12-10 05:58:16 Test Loss = 0.013216281069248 
2016-12-10 05:58:16 -------------------LR------------------- 
2016-12-10 05:58:16 0.015625 
2016-12-10 05:58:16 Epoch 48 
2016-12-10 06:03:47 Training Error = 0.56944328867438 
2016-12-10 06:03:47 Training Loss = 0.012849911070749 
2016-12-10 06:03:53 Valid Error = 0.64956944964433 
2016-12-10 06:03:53 Valid Loss = 0.013371351206149 
2016-12-10 06:04:00 Test Error = 0.65476591444931 
2016-12-10 06:04:00 Test Loss = 0.013507513018405 
2016-12-10 06:04:00 -------------------LR------------------- 
2016-12-10 06:04:00 0.015625 
2016-12-10 06:04:00 Epoch 49 
2016-12-10 06:10:08 Training Error = 0.5692768577848 
2016-12-10 06:10:08 Training Loss = 0.012845648612915 
2016-12-10 06:10:14 Valid Error = 0.65705728191689 
2016-12-10 06:10:14 Valid Loss = 0.013364557929019 
2016-12-10 06:10:21 Test Error = 0.66554395419333 
2016-12-10 06:10:21 Test Loss = 0.01349342226717 
2016-12-10 06:10:21 -------------------LR------------------- 
2016-12-10 06:10:21 0.015625 
2016-12-10 06:10:21 Epoch 50 
2016-12-10 06:16:13 Training Error = 0.56948489639677 
2016-12-10 06:16:13 Training Loss = 0.012847204283656 
2016-12-10 06:16:19 Valid Error = 0.65368775739423 
2016-12-10 06:16:19 Valid Loss = 0.013448343927119 
2016-12-10 06:16:26 Test Error = 0.65644998315931 
2016-12-10 06:16:26 Test Loss = 0.013574971297231 
2016-12-10 06:16:26 -------------------LR------------------- 
2016-12-10 06:16:26 0.0078125 
2016-12-10 06:16:26 Epoch 51 
2016-12-10 06:22:04 Training Error = 0.56985936589831 
2016-12-10 06:22:04 Training Loss = 0.012859837312237 
2016-12-10 06:22:10 Valid Error = 0.64657431673531 
2016-12-10 06:22:10 Valid Loss = 0.013293968464369 
2016-12-10 06:22:17 Test Error = 0.6503873358033 
2016-12-10 06:22:17 Test Loss = 0.013417944387971 
2016-12-10 06:22:17 -------------------LR------------------- 
2016-12-10 06:22:17 0.0078125 
2016-12-10 06:22:17 Epoch 52 
2016-12-10 06:28:10 Training Error = 0.56915203461763 
2016-12-10 06:28:10 Training Loss = 0.012859782603562 
2016-12-10 06:28:16 Valid Error = 0.6518157993261 
2016-12-10 06:28:16 Valid Loss = 0.013538129371992 
2016-12-10 06:28:23 Test Error = 0.65543954193331 
2016-12-10 06:28:23 Test Loss = 0.013662442913021 
2016-12-10 06:28:23 -------------------LR------------------- 
2016-12-10 06:28:23 0.0078125 
2016-12-10 06:28:23 Epoch 53 
2016-12-10 06:34:25 Training Error = 0.57210618290755 
2016-12-10 06:34:25 Training Loss = 0.012846896700464 
2016-12-10 06:34:31 Valid Error = 0.64133283414452 
2016-12-10 06:34:31 Valid Loss = 0.01326648332971 
2016-12-10 06:34:38 Test Error = 0.65375547322331 
2016-12-10 06:34:38 Test Loss = 0.013395788100715 
2016-12-10 06:34:38 -------------------LR------------------- 
2016-12-10 06:34:38 0.0078125 
2016-12-10 06:34:38 Epoch 54 
2016-12-10 06:40:42 Training Error = 0.56844470333694 
2016-12-10 06:40:42 Training Loss = 0.012859970412705 
2016-12-10 06:40:48 Valid Error = 0.64020965930363 
2016-12-10 06:40:48 Valid Loss = 0.013190910372989 
2016-12-10 06:40:55 Test Error = 0.63118895250926 
2016-12-10 06:40:55 Test Loss = 0.01324927662037 
2016-12-10 06:40:55 -------------------LR------------------- 
2016-12-10 06:40:55 0.0078125 
2016-12-10 06:40:55 Epoch 55 
2016-12-10 06:46:57 Training Error = 0.56998418906549 
2016-12-10 06:46:57 Training Loss = 0.012866758421657 
2016-12-10 06:47:03 Valid Error = 0.63534256832647 
2016-12-10 06:47:03 Valid Loss = 0.013294708091198 
2016-12-10 06:47:10 Test Error = 0.63388346244527 
2016-12-10 06:47:10 Test Loss = 0.013397852312359 
2016-12-10 06:47:10 -------------------LR------------------- 
2016-12-10 06:47:10 0.0078125 
2016-12-10 06:47:10 Epoch 56 
