2016-12-10 06:07:05 [program started on Sat Dec 10 06:07:05 2016] 
2016-12-10 06:07:05 [command line arguments] 
2016-12-10 06:07:05 stcWeights false 
2016-12-10 06:07:05 LR 0.015625 
2016-12-10 06:07:05 batchSize 100 
2016-12-10 06:07:05 network ./Models/Cifar10_Custom 
2016-12-10 06:07:05 stcNeurons true 
2016-12-10 06:07:05 constBatchSize false 
2016-12-10 06:07:05 chartFileName chart1 
2016-12-10 06:07:05 dp_prepro false 
2016-12-10 06:07:05 nGPU 1 
2016-12-10 06:07:05 dataset Caltech256 
2016-12-10 06:07:05 type cuda 
2016-12-10 06:07:05 momentum 0 
2016-12-10 06:07:05 threads 8 
2016-12-10 06:07:05 weightDecay 0 
2016-12-10 06:07:05 runningVal false 
2016-12-10 06:07:05 convLayerN 6 
2016-12-10 06:07:05 LRDecay 0 
2016-12-10 06:07:05 numHid 1024 
2016-12-10 06:07:05 save /dev/shm/clone/temp/th/Results/Caltech256/model6-17 
2016-12-10 06:07:05 augment false 
2016-12-10 06:07:05 epoch -1 
2016-12-10 06:07:05 modelsFolder ./Models/ 
2016-12-10 06:07:05 format rgb 
2016-12-10 06:07:05 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 06:07:05 imageFileExtension svg 
2016-12-10 06:07:05 channel 1.7 
2016-12-10 06:07:05 devid 4 
2016-12-10 06:07:05 visualize 1 
2016-12-10 06:07:05 LRDecayPerEpoch 0.0001 
2016-12-10 06:07:05 optimization adam 
2016-12-10 06:07:05 SBN true 
2016-12-10 06:07:05 normalization simple 
2016-12-10 06:07:05 title model1 
2016-12-10 06:07:05 load  
2016-12-10 06:07:05 whiten true 
2016-12-10 06:07:05 [----------------------] 
2016-12-10 06:07:07 ==> Network 
2016-12-10 06:07:07 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 217, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(217 -> 217, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(217 -> 435, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(435 -> 435, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(435 -> 870, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(870 -> 870, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(13920)
  (29): BinaryLinear(13920 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-10 06:07:07 ==>28780207 Parameters 
2016-12-10 06:07:07 ==> Loss 
2016-12-10 06:07:07 SqrtHingeEmbeddingCriterion 
2016-12-10 06:07:07 
==> Starting Training
 
2016-12-10 06:07:07 Epoch 1 
2016-12-10 06:15:51 Training Error = 0.97607555962387 
2016-12-10 06:15:51 Training Loss = 0.1630096918805 
2016-12-10 06:16:04 Valid Error = 0.93934855859229 
2016-12-10 06:16:04 Valid Loss = 0.015700860621736 
2016-12-10 06:16:18 Test Error = 0.9514988211519 
2016-12-10 06:16:18 Test Loss = 0.015723109269384 
2016-12-10 06:16:18 -------------------LR------------------- 
2016-12-10 06:16:18 0.015625 
2016-12-10 06:16:18 Epoch 2 
2016-12-10 06:24:35 Training Error = 0.95215111924773 
2016-12-10 06:24:35 Training Loss = 0.015752236210966 
2016-12-10 06:24:48 Valid Error = 0.95731935604642 
2016-12-10 06:24:48 Valid Loss = 0.015519333314475 
2016-12-10 06:25:02 Test Error = 0.96934994947794 
2016-12-10 06:25:02 Test Loss = 0.015534639187931 
2016-12-10 06:25:02 -------------------LR------------------- 
2016-12-10 06:25:02 0.015625 
2016-12-10 06:25:02 Epoch 3 
2016-12-10 06:33:44 Training Error = 0.94079221103437 
2016-12-10 06:33:44 Training Loss = 0.015564311773494 
2016-12-10 06:33:57 Valid Error = 0.93934855859229 
2016-12-10 06:33:57 Valid Loss = 0.015517890852842 
2016-12-10 06:34:11 Test Error = 0.9514988211519 
2016-12-10 06:34:11 Test Loss = 0.015534243400641 
2016-12-10 06:34:11 -------------------LR------------------- 
2016-12-10 06:34:11 0.015625 
2016-12-10 06:34:11 Epoch 4 
2016-12-10 06:42:49 Training Error = 0.93047349588084 
2016-12-10 06:42:49 Training Loss = 0.015450664581004 
2016-12-10 06:43:02 Valid Error = 0.95657057281917 
2016-12-10 06:43:02 Valid Loss = 0.015548826961944 
2016-12-10 06:43:16 Test Error = 0.96766588076794 
2016-12-10 06:43:16 Test Loss = 0.01558853787748 
2016-12-10 06:43:16 -------------------LR------------------- 
2016-12-10 06:43:16 0.015625 
2016-12-10 06:43:16 Epoch 5 
