2016-12-10 06:07:05 [program started on Sat Dec 10 06:07:05 2016] 
2016-12-10 06:07:05 [command line arguments] 
2016-12-10 06:07:05 stcWeights false 
2016-12-10 06:07:05 LR 0.015625 
2016-12-10 06:07:05 batchSize 100 
2016-12-10 06:07:05 network ./Models/Cifar10_Custom 
2016-12-10 06:07:05 stcNeurons true 
2016-12-10 06:07:05 constBatchSize false 
2016-12-10 06:07:05 chartFileName chart1 
2016-12-10 06:07:05 dp_prepro false 
2016-12-10 06:07:05 nGPU 1 
2016-12-10 06:07:05 dataset Caltech256 
2016-12-10 06:07:05 type cuda 
2016-12-10 06:07:05 momentum 0 
2016-12-10 06:07:05 threads 8 
2016-12-10 06:07:05 weightDecay 0 
2016-12-10 06:07:05 runningVal false 
2016-12-10 06:07:05 convLayerN 6 
2016-12-10 06:07:05 LRDecay 0 
2016-12-10 06:07:05 numHid 1024 
2016-12-10 06:07:05 save /dev/shm/clone/temp/th/Results/Caltech256/model6-17 
2016-12-10 06:07:05 augment false 
2016-12-10 06:07:05 epoch -1 
2016-12-10 06:07:05 modelsFolder ./Models/ 
2016-12-10 06:07:05 format rgb 
2016-12-10 06:07:05 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 06:07:05 imageFileExtension svg 
2016-12-10 06:07:05 channel 1.7 
2016-12-10 06:07:05 devid 4 
2016-12-10 06:07:05 visualize 1 
2016-12-10 06:07:05 LRDecayPerEpoch 0.0001 
2016-12-10 06:07:05 optimization adam 
2016-12-10 06:07:05 SBN true 
2016-12-10 06:07:05 normalization simple 
2016-12-10 06:07:05 title model1 
2016-12-10 06:07:05 load  
2016-12-10 06:07:05 whiten true 
2016-12-10 06:07:05 [----------------------] 
2016-12-10 06:07:07 ==> Network 
2016-12-10 06:07:07 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 217, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(217 -> 217, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(217 -> 435, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(435 -> 435, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(435 -> 870, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(870 -> 870, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(13920)
  (29): BinaryLinear(13920 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-10 06:07:07 ==>28780207 Parameters 
2016-12-10 06:07:07 ==> Loss 
2016-12-10 06:07:07 SqrtHingeEmbeddingCriterion 
2016-12-10 06:07:07 
==> Starting Training
 
2016-12-10 06:07:07 Epoch 1 
2016-12-10 06:15:51 Training Error = 0.97607555962387 
2016-12-10 06:15:51 Training Loss = 0.1630096918805 
2016-12-10 06:16:04 Valid Error = 0.93934855859229 
2016-12-10 06:16:04 Valid Loss = 0.015700860621736 
2016-12-10 06:16:18 Test Error = 0.9514988211519 
2016-12-10 06:16:18 Test Loss = 0.015723109269384 
2016-12-10 06:16:18 -------------------LR------------------- 
2016-12-10 06:16:18 0.015625 
2016-12-10 06:16:18 Epoch 2 
2016-12-10 06:24:35 Training Error = 0.95215111924773 
2016-12-10 06:24:35 Training Loss = 0.015752236210966 
2016-12-10 06:24:48 Valid Error = 0.95731935604642 
2016-12-10 06:24:48 Valid Loss = 0.015519333314475 
2016-12-10 06:25:02 Test Error = 0.96934994947794 
2016-12-10 06:25:02 Test Loss = 0.015534639187931 
2016-12-10 06:25:02 -------------------LR------------------- 
2016-12-10 06:25:02 0.015625 
2016-12-10 06:25:02 Epoch 3 
2016-12-10 06:33:44 Training Error = 0.94079221103437 
2016-12-10 06:33:44 Training Loss = 0.015564311773494 
2016-12-10 06:33:57 Valid Error = 0.93934855859229 
2016-12-10 06:33:57 Valid Loss = 0.015517890852842 
2016-12-10 06:34:11 Test Error = 0.9514988211519 
2016-12-10 06:34:11 Test Loss = 0.015534243400641 
2016-12-10 06:34:11 -------------------LR------------------- 
2016-12-10 06:34:11 0.015625 
2016-12-10 06:34:11 Epoch 4 
2016-12-10 06:42:49 Training Error = 0.93047349588084 
2016-12-10 06:42:49 Training Loss = 0.015450664581004 
2016-12-10 06:43:02 Valid Error = 0.95657057281917 
2016-12-10 06:43:02 Valid Loss = 0.015548826961944 
2016-12-10 06:43:16 Test Error = 0.96766588076794 
2016-12-10 06:43:16 Test Loss = 0.01558853787748 
2016-12-10 06:43:16 -------------------LR------------------- 
2016-12-10 06:43:16 0.015625 
2016-12-10 06:43:16 Epoch 5 
2016-12-10 06:52:12 Training Error = 0.91649330115669 
2016-12-10 06:52:12 Training Loss = 0.015312218607094 
2016-12-10 06:52:25 Valid Error = 0.95919131411456 
2016-12-10 06:52:25 Valid Loss = 0.015665222947085 
2016-12-10 06:52:39 Test Error = 0.96934994947794 
2016-12-10 06:52:39 Test Loss = 0.015736799498292 
2016-12-10 06:52:39 -------------------LR------------------- 
2016-12-10 06:52:39 0.015625 
2016-12-10 06:52:39 Epoch 6 
2016-12-10 07:01:58 Training Error = 0.90363651493717 
2016-12-10 07:01:58 Training Loss = 0.015097875527241 
2016-12-10 07:02:11 Valid Error = 0.97304380381879 
2016-12-10 07:02:11 Valid Loss = 0.015635515651285 
2016-12-10 07:02:25 Test Error = 0.97036039070394 
2016-12-10 07:02:25 Test Loss = 0.015634624905924 
2016-12-10 07:02:25 -------------------LR------------------- 
2016-12-10 07:02:25 0.015625 
2016-12-10 07:02:25 Epoch 7 
2016-12-10 07:11:48 Training Error = 0.86989265207623 
2016-12-10 07:11:48 Training Loss = 0.014767303652578 
2016-12-10 07:12:00 Valid Error = 0.96031448895545 
2016-12-10 07:12:00 Valid Loss = 0.015486061154016 
2016-12-10 07:12:14 Test Error = 0.96092960592792 
2016-12-10 07:12:14 Test Loss = 0.015447982600477 
2016-12-10 07:12:14 -------------------LR------------------- 
2016-12-10 07:12:14 0.015625 
2016-12-10 07:12:14 Epoch 8 
2016-12-10 07:21:39 Training Error = 0.82553882000499 
2016-12-10 07:21:39 Training Loss = 0.014393375714195 
2016-12-10 07:21:52 Valid Error = 0.84612504679895 
2016-12-10 07:21:52 Valid Loss = 0.014952687560466 
2016-12-10 07:22:06 Test Error = 0.85719097339171 
2016-12-10 07:22:06 Test Loss = 0.015058625342935 
2016-12-10 07:22:06 -------------------LR------------------- 
2016-12-10 07:22:06 0.015625 
2016-12-10 07:22:06 Epoch 9 
2016-12-10 07:31:31 Training Error = 0.76129649662977 
2016-12-10 07:31:31 Training Loss = 0.013931149392434 
2016-12-10 07:31:44 Valid Error = 0.79445900411831 
2016-12-10 07:31:44 Valid Loss = 0.014559287435805 
2016-12-10 07:31:58 Test Error = 0.7982485685416 
2016-12-10 07:31:58 Test Loss = 0.014688851661317 
2016-12-10 07:31:58 -------------------LR------------------- 
2016-12-10 07:31:58 0.015625 
2016-12-10 07:31:58 Epoch 10 
2016-12-10 07:41:27 Training Error = 0.68710992760256 
2016-12-10 07:41:27 Training Loss = 0.013452420736344 
2016-12-10 07:41:41 Valid Error = 0.68738300262074 
2016-12-10 07:41:41 Valid Loss = 0.013513374366773 
2016-12-10 07:41:56 Test Error = 0.69282586729539 
2016-12-10 07:41:56 Test Loss = 0.013561916494772 
2016-12-10 07:41:56 -------------------LR------------------- 
2016-12-10 07:41:56 0.015625 
2016-12-10 07:41:56 Epoch 11 
2016-12-10 07:51:17 Training Error = 0.64899725389032 
2016-12-10 07:51:17 Training Loss = 0.013332803884674 
2016-12-10 07:51:30 Valid Error = 0.68663421939349 
2016-12-10 07:51:30 Valid Loss = 0.013491300729419 
2016-12-10 07:51:44 Test Error = 0.69484674974739 
2016-12-10 07:51:44 Test Loss = 0.013553654004309 
2016-12-10 07:51:44 -------------------LR------------------- 
2016-12-10 07:51:44 0.015625 
2016-12-10 07:51:44 Epoch 12 
2016-12-10 08:00:41 Training Error = 0.64970458517101 
2016-12-10 08:00:41 Training Loss = 0.013340618577823 
2016-12-10 08:00:54 Valid Error = 0.66491950580307 
2016-12-10 08:00:54 Valid Loss = 0.013476954744538 
2016-12-10 08:01:08 Test Error = 0.67430111148535 
2016-12-10 08:01:08 Test Loss = 0.013542502196156 
2016-12-10 08:01:08 -------------------LR------------------- 
2016-12-10 08:01:08 0.015625 
2016-12-10 08:01:08 Epoch 13 
2016-12-10 08:09:48 Training Error = 0.65095281684281 
2016-12-10 08:09:48 Training Loss = 0.013333163423127 
2016-12-10 08:10:00 Valid Error = 0.66866342193935 
2016-12-10 08:10:00 Valid Loss = 0.013336671846567 
2016-12-10 08:10:14 Test Error = 0.67160660154934 
2016-12-10 08:10:14 Test Loss = 0.013417938065915 
2016-12-10 08:10:14 -------------------LR------------------- 
2016-12-10 08:10:14 0.015625 
2016-12-10 08:10:14 Epoch 14 
2016-12-10 08:18:56 Training Error = 0.65174336356828 
2016-12-10 08:18:56 Training Loss = 0.013336733756013 
2016-12-10 08:19:08 Valid Error = 0.66491950580307 
2016-12-10 08:19:08 Valid Loss = 0.013439725731467 
2016-12-10 08:19:22 Test Error = 0.67261704277535 
2016-12-10 08:19:22 Test Loss = 0.013524280681865 
2016-12-10 08:19:22 -------------------LR------------------- 
2016-12-10 08:19:22 0.015625 
2016-12-10 08:19:22 Epoch 15 
2016-12-10 08:28:05 Training Error = 0.65141050178913 
2016-12-10 08:28:05 Training Loss = 0.013334719390505 
2016-12-10 08:28:17 Valid Error = 0.66154998128042 
2016-12-10 08:28:17 Valid Loss = 0.013422776197969 
2016-12-10 08:28:31 Test Error = 0.66419669922533 
2016-12-10 08:28:31 Test Loss = 0.013496644577109 
2016-12-10 08:28:31 -------------------LR------------------- 
2016-12-10 08:28:31 0.015625 
2016-12-10 08:28:31 Epoch 16 
2016-12-10 08:37:11 Training Error = 0.64999583922776 
2016-12-10 08:37:11 Training Loss = 0.013335225664897 
2016-12-10 08:37:24 Valid Error = 0.66754024709847 
2016-12-10 08:37:24 Valid Loss = 0.013369082479067 
2016-12-10 08:37:38 Test Error = 0.67632199393735 
2016-12-10 08:37:38 Test Loss = 0.013447180058995 
2016-12-10 08:37:38 -------------------LR------------------- 
2016-12-10 08:37:38 0.015625 
2016-12-10 08:37:38 Epoch 17 
2016-12-10 08:46:22 Training Error = 0.6479154531081 
2016-12-10 08:46:22 Training Loss = 0.013317253742104 
2016-12-10 08:46:35 Valid Error = 0.66754024709847 
2016-12-10 08:46:35 Valid Loss = 0.013428779487883 
2016-12-10 08:46:49 Test Error = 0.67295385651735 
2016-12-10 08:46:49 Test Loss = 0.01349548042791 
2016-12-10 08:46:49 -------------------LR------------------- 
2016-12-10 08:46:49 0.015625 
2016-12-10 08:46:49 Epoch 18 
2016-12-10 08:55:29 Training Error = 0.64908046933511 
2016-12-10 08:55:29 Training Loss = 0.013335881174506 
2016-12-10 08:55:42 Valid Error = 0.66417072257581 
2016-12-10 08:55:42 Valid Loss = 0.013380419076209 
2016-12-10 08:55:56 Test Error = 0.66655439541933 
2016-12-10 08:55:56 Test Loss = 0.013457779502164 
2016-12-10 08:55:56 -------------------LR------------------- 
2016-12-10 08:55:56 0.015625 
2016-12-10 08:55:56 Epoch 19 
2016-12-10 09:04:36 Training Error = 0.65049513189648 
2016-12-10 09:04:36 Training Loss = 0.013344218090431 
2016-12-10 09:04:49 Valid Error = 0.67016098839386 
2016-12-10 09:04:49 Valid Loss = 0.013431550469119 
2016-12-10 09:05:03 Test Error = 0.67632199393735 
2016-12-10 09:05:03 Test Loss = 0.013483708151748 
2016-12-10 09:05:03 -------------------LR------------------- 
2016-12-10 09:05:03 0.015625 
2016-12-10 09:05:03 Epoch 20 
2016-12-10 09:13:50 Training Error = 0.64766580677374 
2016-12-10 09:13:50 Training Loss = 0.013311737120575 
2016-12-10 09:14:03 Valid Error = 0.67390490453014 
2016-12-10 09:14:03 Valid Loss = 0.013389994813432 
2016-12-10 09:14:17 Test Error = 0.67632199393735 
2016-12-10 09:14:17 Test Loss = 0.013476439719143 
2016-12-10 09:14:17 -------------------LR------------------- 
2016-12-10 09:14:17 0.015625 
2016-12-10 09:14:17 Epoch 21 
2016-12-10 09:22:55 Training Error = 0.64933011566947 
2016-12-10 09:22:55 Training Loss = 0.013322850529985 
2016-12-10 09:23:07 Valid Error = 0.66604268064395 
2016-12-10 09:23:07 Valid Loss = 0.013399882130424 
2016-12-10 09:23:21 Test Error = 0.66621758167733 
2016-12-10 09:23:21 Test Loss = 0.013475252110983 
2016-12-10 09:23:21 -------------------LR------------------- 
2016-12-10 09:23:21 0.015625 
2016-12-10 09:23:21 Epoch 22 
2016-12-10 09:32:02 Training Error = 0.64953815428143 
2016-12-10 09:32:02 Training Loss = 0.013324506151867 
2016-12-10 09:32:15 Valid Error = 0.67502807937102 
2016-12-10 09:32:15 Valid Loss = 0.013437397646078 
2016-12-10 09:32:29 Test Error = 0.67766924890536 
2016-12-10 09:32:29 Test Loss = 0.013518189216015 
2016-12-10 09:32:29 -------------------LR------------------- 
2016-12-10 09:32:29 0.015625 
2016-12-10 09:32:29 Epoch 23 
2016-12-10 09:41:10 Training Error = 0.64899725389032 
2016-12-10 09:41:10 Training Loss = 0.013335337769788 
2016-12-10 09:41:23 Valid Error = 0.6585548483714 
2016-12-10 09:41:23 Valid Loss = 0.013430472080223 
2016-12-10 09:41:37 Test Error = 0.66453351296733 
2016-12-10 09:41:37 Test Loss = 0.013496092714536 
2016-12-10 09:41:37 -------------------LR------------------- 
2016-12-10 09:41:37 0.015625 
2016-12-10 09:41:37 Epoch 24 
2016-12-10 09:50:20 Training Error = 0.64704169093784 
2016-12-10 09:50:20 Training Loss = 0.013323771675886 
2016-12-10 09:50:33 Valid Error = 0.66491950580307 
2016-12-10 09:50:33 Valid Loss = 0.013347312798876 
2016-12-10 09:50:47 Test Error = 0.66891209161334 
2016-12-10 09:50:47 Test Loss = 0.013438091202122 
2016-12-10 09:50:47 -------------------LR------------------- 
2016-12-10 09:50:47 0.015625 
2016-12-10 09:50:47 Epoch 25 
2016-12-10 09:59:33 Training Error = 0.65061995506366 
2016-12-10 09:59:33 Training Loss = 0.013337945189519 
2016-12-10 09:59:45 Valid Error = 0.66304754773493 
2016-12-10 09:59:45 Valid Loss = 0.013461177112011 
2016-12-10 10:00:00 Test Error = 0.67059616032334 
2016-12-10 10:00:00 Test Loss = 0.013526165843175 
2016-12-10 10:00:00 -------------------LR------------------- 
2016-12-10 10:00:00 0.015625 
2016-12-10 10:00:00 Epoch 26 
2016-12-10 10:08:42 Training Error = 0.64957976200383 
2016-12-10 10:08:42 Training Loss = 0.013342017005344 
2016-12-10 10:08:55 Valid Error = 0.6787719955073 
2016-12-10 10:08:55 Valid Loss = 0.01342230885797 
2016-12-10 10:09:09 Test Error = 0.68305826877737 
2016-12-10 10:09:09 Test Loss = 0.013494717293042 
2016-12-10 10:09:09 -------------------LR------------------- 
2016-12-10 10:09:09 0.015625 
2016-12-10 10:09:09 Epoch 27 
2016-12-10 10:17:53 Training Error = 0.64887243072314 
2016-12-10 10:17:53 Training Loss = 0.013337991003203 
2016-12-10 10:18:06 Valid Error = 0.66754024709847 
2016-12-10 10:18:06 Valid Loss = 0.013470508282217 
2016-12-10 10:18:20 Test Error = 0.67261704277535 
2016-12-10 10:18:20 Test Loss = 0.013527610900364 
2016-12-10 10:18:20 -------------------LR------------------- 
2016-12-10 10:18:20 0.015625 
2016-12-10 10:18:20 Epoch 28 
2016-12-10 10:27:09 Training Error = 0.65032870100691 
2016-12-10 10:27:09 Training Loss = 0.013329868328718 
2016-12-10 10:27:21 Valid Error = 0.68326469487083 
2016-12-10 10:27:21 Valid Loss = 0.013383161105903 
2016-12-10 10:27:35 Test Error = 0.68912091613338 
2016-12-10 10:27:35 Test Loss = 0.013476514315933 
2016-12-10 10:27:35 -------------------LR------------------- 
2016-12-10 10:27:35 0.015625 
2016-12-10 10:27:35 Epoch 29 
2016-12-10 10:36:27 Training Error = 0.65128567862195 
2016-12-10 10:36:27 Training Loss = 0.013332363717461 
2016-12-10 10:36:40 Valid Error = 0.66304754773493 
2016-12-10 10:36:40 Valid Loss = 0.013384283526114 
2016-12-10 10:36:54 Test Error = 0.66554395419333 
2016-12-10 10:36:54 Test Loss = 0.013455565398537 
2016-12-10 10:36:54 -------------------LR------------------- 
2016-12-10 10:36:54 0.015625 
2016-12-10 10:36:54 Epoch 30 
2016-12-10 10:45:48 Training Error = 0.64824831488724 
2016-12-10 10:45:48 Training Loss = 0.013318415129422 
2016-12-10 10:46:01 Valid Error = 0.6652938974167 
2016-12-10 10:46:01 Valid Loss = 0.013419355208895 
2016-12-10 10:46:15 Test Error = 0.67194341529134 
2016-12-10 10:46:15 Test Loss = 0.013507275387156 
2016-12-10 10:46:15 -------------------LR------------------- 
2016-12-10 10:46:15 0.015625 
2016-12-10 10:46:15 Epoch 31 
2016-12-10 10:55:01 Training Error = 0.64799866855288 
2016-12-10 10:55:01 Training Loss = 0.013329178964485 
2016-12-10 10:55:14 Valid Error = 0.67465368775739 
2016-12-10 10:55:14 Valid Loss = 0.013426513655643 
2016-12-10 10:55:28 Test Error = 0.67665880767935 
2016-12-10 10:55:28 Test Loss = 0.01349560221146 
2016-12-10 10:55:28 -------------------LR------------------- 
2016-12-10 10:55:28 0.015625 
2016-12-10 10:55:28 Epoch 32 
2016-12-10 11:04:11 Training Error = 0.65116085545477 
2016-12-10 11:04:11 Training Loss = 0.013330843867671 
2016-12-10 11:04:23 Valid Error = 0.68401347809809 
2016-12-10 11:04:23 Valid Loss = 0.013429210359865 
2016-12-10 11:04:37 Test Error = 0.68272145503537 
2016-12-10 11:04:37 Test Loss = 0.01350933673812 
2016-12-10 11:04:37 -------------------LR------------------- 
2016-12-10 11:04:37 0.015625 
2016-12-10 11:04:37 Epoch 33 
2016-12-10 11:13:26 Training Error = 0.64949654655904 
2016-12-10 11:13:26 Training Loss = 0.013332730336474 
2016-12-10 11:13:38 Valid Error = 0.66417072257581 
2016-12-10 11:13:38 Valid Loss = 0.013392119125542 
2016-12-10 11:13:52 Test Error = 0.66756483664534 
2016-12-10 11:13:52 Test Loss = 0.013467751863882 
2016-12-10 11:13:52 -------------------LR------------------- 
2016-12-10 11:13:52 0.015625 
2016-12-10 11:13:52 Epoch 34 
2016-12-10 11:22:40 Training Error = 0.64620953648997 
2016-12-10 11:22:40 Training Loss = 0.013321166370581 
2016-12-10 11:22:53 Valid Error = 0.66604268064395 
2016-12-10 11:22:53 Valid Loss = 0.013335392210901 
2016-12-10 11:23:07 Test Error = 0.67059616032334 
2016-12-10 11:23:07 Test Loss = 0.013410053379427 
2016-12-10 11:23:07 -------------------LR------------------- 
2016-12-10 11:23:07 0.015625 
2016-12-10 11:23:07 Epoch 35 
2016-12-10 11:31:35 Training Error = 0.64675043688109 
2016-12-10 11:31:35 Training Loss = 0.013319688023248 
2016-12-10 11:31:48 Valid Error = 0.67016098839386 
2016-12-10 11:31:48 Valid Loss = 0.013501433490557 
2016-12-10 11:32:02 Test Error = 0.67598518019535 
2016-12-10 11:32:02 Test Loss = 0.013548355047326 
2016-12-10 11:32:02 -------------------LR------------------- 
2016-12-10 11:32:02 0.015625 
2016-12-10 11:32:02 Epoch 36 
