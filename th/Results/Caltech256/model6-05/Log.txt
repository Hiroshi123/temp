2016-12-09 22:47:08 [program started on Fri Dec  9 22:47:08 2016] 
2016-12-09 22:47:08 [command line arguments] 
2016-12-09 22:47:08 stcWeights false 
2016-12-09 22:47:08 LR 0.015625 
2016-12-09 22:47:08 batchSize 300 
2016-12-09 22:47:08 network ./Models/Cifar10_Custom 
2016-12-09 22:47:08 stcNeurons true 
2016-12-09 22:47:08 constBatchSize false 
2016-12-09 22:47:08 chartFileName chart1 
2016-12-09 22:47:08 dp_prepro false 
2016-12-09 22:47:08 nGPU 1 
2016-12-09 22:47:08 dataset Caltech256 
2016-12-09 22:47:08 type cuda 
2016-12-09 22:47:08 momentum 0 
2016-12-09 22:47:08 threads 8 
2016-12-09 22:47:08 weightDecay 0 
2016-12-09 22:47:08 runningVal false 
2016-12-09 22:47:08 convLayerN 6 
2016-12-09 22:47:08 LRDecay 0 
2016-12-09 22:47:08 numHid 1024 
2016-12-09 22:47:08 save /dev/shm/clone/temp/th/Results/Caltech256/model6-05 
2016-12-09 22:47:08 augment false 
2016-12-09 22:47:08 epoch -1 
2016-12-09 22:47:08 modelsFolder ./Models/ 
2016-12-09 22:47:08 format rgb 
2016-12-09 22:47:08 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 22:47:08 imageFileExtension svg 
2016-12-09 22:47:08 channel 0.5 
2016-12-09 22:47:08 devid 8 
2016-12-09 22:47:08 visualize 1 
2016-12-09 22:47:08 LRDecayPerEpoch 0.0001 
2016-12-09 22:47:08 optimization adam 
2016-12-09 22:47:08 SBN true 
2016-12-09 22:47:08 normalization simple 
2016-12-09 22:47:08 title model1 
2016-12-09 22:47:08 load  
2016-12-09 22:47:08 whiten true 
2016-12-09 22:47:08 [----------------------] 
2016-12-09 22:47:09 ==> Network 
2016-12-09 22:47:09 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 64, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(64 -> 64, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(64 -> 128, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(4096)
  (29): BinaryLinear(4096 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-09 22:47:09 ==>6658109 Parameters 
2016-12-09 22:47:09 ==> Loss 
2016-12-09 22:47:09 SqrtHingeEmbeddingCriterion 
2016-12-09 22:47:09 
==> Starting Training
 
2016-12-09 22:47:09 Epoch 1 
2016-12-09 22:48:39 Training Error = 0.98864109178664 
2016-12-09 22:48:39 Training Loss = 0.43620780496398 
2016-12-09 22:48:42 Valid Error = 0.98914264320479 
2016-12-09 22:48:42 Valid Loss = 0.069305768246229 
2016-12-09 22:48:45 Test Error = 0.99090602896598 
2016-12-09 22:48:45 Test Loss = 0.069416916847187 
2016-12-09 22:48:45 -------------------LR------------------- 
2016-12-09 22:48:45 0.015625 
2016-12-09 22:48:45 Epoch 2 
2016-12-09 22:50:03 Training Error = 0.9801947241408 
2016-12-09 22:50:03 Training Loss = 0.035211425658415 
2016-12-09 22:50:06 Valid Error = 0.96929988768252 
2016-12-09 22:50:06 Valid Loss = 0.018034575807327 
2016-12-09 22:50:09 Test Error = 0.97069720444594 
2016-12-09 22:50:09 Test Loss = 0.018078729804611 
2016-12-09 22:50:09 -------------------LR------------------- 
2016-12-09 22:50:09 0.015625 
2016-12-09 22:50:09 Epoch 3 
2016-12-09 22:51:34 Training Error = 0.96800366147957 
2016-12-09 22:51:34 Training Loss = 0.017381502633475 
2016-12-09 22:51:37 Valid Error = 0.96405840509173 
2016-12-09 22:51:37 Valid Loss = 0.015886769178133 
2016-12-09 22:51:40 Test Error = 0.96396092960593 
2016-12-09 22:51:40 Test Loss = 0.015934271383342 
2016-12-09 22:51:40 -------------------LR------------------- 
2016-12-09 22:51:40 0.015625 
2016-12-09 22:51:40 Epoch 4 
2016-12-09 22:53:09 Training Error = 0.96725472247649 
2016-12-09 22:53:09 Training Loss = 0.016563171888197 
2016-12-09 22:53:12 Valid Error = 0.96405840509173 
2016-12-09 22:53:12 Valid Loss = 0.015846189610362 
2016-12-09 22:53:15 Test Error = 0.96396092960593 
2016-12-09 22:53:15 Test Loss = 0.015884936247603 
2016-12-09 22:53:15 -------------------LR------------------- 
2016-12-09 22:53:15 0.015625 
2016-12-09 22:53:15 Epoch 5 
2016-12-09 22:54:37 Training Error = 0.96013980194724 
2016-12-09 22:54:37 Training Loss = 0.016278297561745 
2016-12-09 22:54:39 Valid Error = 0.96405840509173 
2016-12-09 22:54:39 Valid Loss = 0.015664743533972 
2016-12-09 22:54:42 Test Error = 0.96396092960593 
2016-12-09 22:54:42 Test Loss = 0.015695666141168 
2016-12-09 22:54:42 -------------------LR------------------- 
2016-12-09 22:54:42 0.015625 
2016-12-09 22:54:42 Epoch 6 
2016-12-09 22:56:19 Training Error = 0.95410668220022 
2016-12-09 22:56:19 Training Loss = 0.016133010662551 
2016-12-09 22:56:22 Valid Error = 0.96405840509173 
2016-12-09 22:56:22 Valid Loss = 0.01565570286074 
2016-12-09 22:56:25 Test Error = 0.96396092960593 
2016-12-09 22:56:25 Test Loss = 0.015686439083613 
2016-12-09 22:56:25 -------------------LR------------------- 
2016-12-09 22:56:25 0.015625 
2016-12-09 22:56:25 Epoch 7 
2016-12-09 22:57:55 Training Error = 0.94724140800533 
2016-12-09 22:57:55 Training Loss = 0.015950178229516 
2016-12-09 22:57:58 Valid Error = 0.96405840509173 
2016-12-09 22:57:58 Valid Loss = 0.015629747509865 
2016-12-09 22:58:01 Test Error = 0.96396092960593 
2016-12-09 22:58:01 Test Loss = 0.015657034592645 
2016-12-09 22:58:01 -------------------LR------------------- 
2016-12-09 22:58:01 0.015625 
2016-12-09 22:58:01 Epoch 8 
2016-12-09 22:59:26 Training Error = 0.94191561953899 
2016-12-09 22:59:26 Training Loss = 0.015845497379443 
2016-12-09 22:59:29 Valid Error = 0.9341070760015 
2016-12-09 22:59:29 Valid Loss = 0.015568005611952 
2016-12-09 22:59:32 Test Error = 0.94476254631189 
2016-12-09 22:59:32 Test Loss = 0.015588102431244 
2016-12-09 22:59:32 -------------------LR------------------- 
2016-12-09 22:59:32 0.015625 
2016-12-09 22:59:32 Epoch 9 
2016-12-09 23:01:14 Training Error = 0.93559124573521 
2016-12-09 23:01:14 Training Loss = 0.015736206934519 
2016-12-09 23:01:17 Valid Error = 0.98876825159116 
2016-12-09 23:01:17 Valid Loss = 0.015670933413148 
2016-12-09 23:01:20 Test Error = 0.99090602896598 
2016-12-09 23:01:20 Test Loss = 0.015695128461735 
2016-12-09 23:01:20 -------------------LR------------------- 
2016-12-09 23:01:20 0.015625 
2016-12-09 23:01:20 Epoch 10 
2016-12-09 23:03:09 Training Error = 0.92726970125655 
2016-12-09 23:03:09 Training Loss = 0.015694423716693 
2016-12-09 23:03:12 Valid Error = 0.95881692250094 
2016-12-09 23:03:12 Valid Loss = 0.015646564482712 
2016-12-09 23:03:15 Test Error = 0.96160323341192 
2016-12-09 23:03:15 Test Loss = 0.01567161523466 
2016-12-09 23:03:15 -------------------LR------------------- 
2016-12-09 23:03:15 0.015625 
2016-12-09 23:03:15 Epoch 11 
2016-12-09 23:05:08 Training Error = 0.92489806108014 
2016-12-09 23:05:08 Training Loss = 0.015649917892171 
2016-12-09 23:05:10 Valid Error = 0.96405840509173 
2016-12-09 23:05:10 Valid Loss = 0.015635745522159 
2016-12-09 23:05:13 Test Error = 0.96396092960593 
2016-12-09 23:05:13 Test Loss = 0.015643314063326 
2016-12-09 23:05:13 -------------------LR------------------- 
2016-12-09 23:05:13 0.015625 
2016-12-09 23:05:13 Epoch 12 
2016-12-09 23:06:48 Training Error = 0.92535574602646 
2016-12-09 23:06:48 Training Loss = 0.015676698119833 
2016-12-09 23:06:51 Valid Error = 0.96405840509173 
2016-12-09 23:06:51 Valid Loss = 0.015647681458113 
2016-12-09 23:06:54 Test Error = 0.96396092960593 
2016-12-09 23:06:54 Test Loss = 0.015654638277401 
2016-12-09 23:06:54 -------------------LR------------------- 
2016-12-09 23:06:54 0.015625 
2016-12-09 23:06:54 Epoch 13 
2016-12-09 23:08:32 Training Error = 0.92373304485312 
2016-12-09 23:08:32 Training Loss = 0.015671291323235 
2016-12-09 23:08:35 Valid Error = 0.96405840509173 
2016-12-09 23:08:35 Valid Loss = 0.015680656354249 
2016-12-09 23:08:38 Test Error = 0.96396092960593 
2016-12-09 23:08:38 Test Loss = 0.015697450268323 
2016-12-09 23:08:38 -------------------LR------------------- 
2016-12-09 23:08:38 0.015625 
2016-12-09 23:08:38 Epoch 14 
2016-12-09 23:10:49 Training Error = 0.9238994757427 
2016-12-09 23:10:49 Training Loss = 0.015686081780654 
2016-12-09 23:10:52 Valid Error = 0.96405840509173 
2016-12-09 23:10:52 Valid Loss = 0.015646071208306 
2016-12-09 23:10:55 Test Error = 0.96396092960593 
2016-12-09 23:10:55 Test Loss = 0.015653141273669 
2016-12-09 23:10:55 -------------------LR------------------- 
2016-12-09 23:10:55 0.015625 
2016-12-09 23:10:55 Epoch 15 
2016-12-09 23:13:06 Training Error = 0.92244320545893 
2016-12-09 23:13:06 Training Loss = 0.015652122665189 
2016-12-09 23:13:09 Valid Error = 0.96405840509173 
2016-12-09 23:13:09 Valid Loss = 0.015696391237714 
2016-12-09 23:13:12 Test Error = 0.96396092960593 
2016-12-09 23:13:12 Test Loss = 0.015708724736603 
2016-12-09 23:13:12 -------------------LR------------------- 
2016-12-09 23:13:12 0.015625 
2016-12-09 23:13:12 Epoch 16 
2016-12-09 23:15:13 Training Error = 0.92394108346509 
2016-12-09 23:15:13 Training Loss = 0.015663784969525 
2016-12-09 23:15:16 Valid Error = 0.96405840509173 
2016-12-09 23:15:16 Valid Loss = 0.015663174513035 
2016-12-09 23:15:18 Test Error = 0.96396092960593 
2016-12-09 23:15:18 Test Loss = 0.015673591974691 
2016-12-09 23:15:18 -------------------LR------------------- 
2016-12-09 23:15:18 0.015625 
2016-12-09 23:15:19 Epoch 17 
2016-12-09 23:17:22 Training Error = 0.92352500624116 
2016-12-09 23:17:22 Training Loss = 0.015690591588654 
2016-12-09 23:17:25 Valid Error = 0.96405840509173 
2016-12-09 23:17:25 Valid Loss = 0.015644245429733 
2016-12-09 23:17:28 Test Error = 0.96396092960593 
2016-12-09 23:17:28 Test Loss = 0.015658263511499 
2016-12-09 23:17:28 -------------------LR------------------- 
2016-12-09 23:17:28 0.015625 
2016-12-09 23:17:28 Epoch 18 
2016-12-09 23:19:41 Training Error = 0.92360822168594 
2016-12-09 23:19:41 Training Loss = 0.01566925811677 
2016-12-09 23:19:43 Valid Error = 0.96405840509173 
2016-12-09 23:19:43 Valid Loss = 0.01567987917519 
2016-12-09 23:19:46 Test Error = 0.96396092960593 
2016-12-09 23:19:46 Test Loss = 0.015693221956994 
2016-12-09 23:19:46 -------------------LR------------------- 
2016-12-09 23:19:46 0.015625 
2016-12-09 23:19:46 Epoch 19 
2016-12-09 23:21:53 Training Error = 0.92285928268287 
2016-12-09 23:21:53 Training Loss = 0.015643645987757 
2016-12-09 23:21:56 Valid Error = 0.96405840509173 
2016-12-09 23:21:56 Valid Loss = 0.015638469357752 
2016-12-09 23:21:59 Test Error = 0.96396092960593 
2016-12-09 23:21:59 Test Loss = 0.015652597430955 
2016-12-09 23:21:59 -------------------LR------------------- 
2016-12-09 23:21:59 0.015625 
2016-12-09 23:21:59 Epoch 20 
2016-12-09 23:24:16 Training Error = 0.9263543313639 
2016-12-09 23:24:16 Training Loss = 0.015653020616183 
2016-12-09 23:24:18 Valid Error = 0.96405840509173 
2016-12-09 23:24:18 Valid Loss = 0.015605778009054 
2016-12-09 23:24:21 Test Error = 0.96396092960593 
2016-12-09 23:24:21 Test Loss = 0.015623152545293 
2016-12-09 23:24:21 -------------------LR------------------- 
2016-12-09 23:24:21 0.015625 
2016-12-09 23:24:21 Epoch 21 
2016-12-09 23:26:26 Training Error = 0.92285928268287 
2016-12-09 23:26:26 Training Loss = 0.015648815236237 
2016-12-09 23:26:29 Valid Error = 0.96405840509173 
2016-12-09 23:26:29 Valid Loss = 0.015631327561935 
2016-12-09 23:26:32 Test Error = 0.96396092960593 
2016-12-09 23:26:32 Test Loss = 0.015640764525623 
2016-12-09 23:26:32 -------------------LR------------------- 
2016-12-09 23:26:32 0.015625 
2016-12-09 23:26:32 Epoch 22 
2016-12-09 23:28:41 Training Error = 0.92269285179329 
2016-12-09 23:28:41 Training Loss = 0.015681313968816 
2016-12-09 23:28:44 Valid Error = 0.95881692250094 
2016-12-09 23:28:44 Valid Loss = 0.015619813858474 
2016-12-09 23:28:47 Test Error = 0.96160323341192 
2016-12-09 23:28:47 Test Loss = 0.015637278922736 
2016-12-09 23:28:47 -------------------LR------------------- 
2016-12-09 23:28:47 0.015625 
2016-12-09 23:28:47 Epoch 23 
2016-12-09 23:30:54 Training Error = 0.92419072979945 
2016-12-09 23:30:54 Training Loss = 0.015668033241616 
2016-12-09 23:30:57 Valid Error = 0.96405840509173 
2016-12-09 23:30:57 Valid Loss = 0.01568427672641 
2016-12-09 23:31:00 Test Error = 0.96396092960593 
2016-12-09 23:31:00 Test Loss = 0.015697408913249 
2016-12-09 23:31:00 -------------------LR------------------- 
2016-12-09 23:31:00 0.015625 
2016-12-09 23:31:00 Epoch 24 
2016-12-09 23:33:07 Training Error = 0.92402429890988 
2016-12-09 23:33:07 Training Loss = 0.015662058487021 
2016-12-09 23:33:10 Valid Error = 0.96405840509173 
2016-12-09 23:33:10 Valid Loss = 0.01567746749039 
2016-12-09 23:33:12 Test Error = 0.96396092960593 
2016-12-09 23:33:12 Test Loss = 0.015689760576568 
2016-12-09 23:33:12 -------------------LR------------------- 
2016-12-09 23:33:12 0.015625 
2016-12-09 23:33:13 Epoch 25 
2016-12-09 23:35:17 Training Error = 0.92564700008322 
2016-12-09 23:35:17 Training Loss = 0.015656792852528 
2016-12-09 23:35:19 Valid Error = 0.96405840509173 
2016-12-09 23:35:19 Valid Loss = 0.015616073575318 
2016-12-09 23:35:22 Test Error = 0.96396092960593 
2016-12-09 23:35:22 Test Loss = 0.015633044562613 
2016-12-09 23:35:22 -------------------LR------------------- 
2016-12-09 23:35:22 0.015625 
2016-12-09 23:35:22 Epoch 26 
2016-12-09 23:37:33 Training Error = 0.92406590663227 
2016-12-09 23:37:33 Training Loss = 0.015650547902766 
2016-12-09 23:37:35 Valid Error = 0.96405840509173 
2016-12-09 23:37:35 Valid Loss = 0.015615597617325 
2016-12-09 23:37:38 Test Error = 0.96396092960593 
2016-12-09 23:37:38 Test Loss = 0.015626229786696 
2016-12-09 23:37:38 -------------------LR------------------- 
2016-12-09 23:37:38 0.015625 
2016-12-09 23:37:38 Epoch 27 
2016-12-09 23:39:47 Training Error = 0.92456519930099 
2016-12-09 23:39:47 Training Loss = 0.015652622627889 
2016-12-09 23:39:50 Valid Error = 0.96405840509173 
2016-12-09 23:39:50 Valid Loss = 0.015684823111986 
2016-12-09 23:39:53 Test Error = 0.96396092960593 
2016-12-09 23:39:53 Test Loss = 0.015691781988811 
2016-12-09 23:39:53 -------------------LR------------------- 
2016-12-09 23:39:53 0.015625 
2016-12-09 23:39:53 Epoch 28 
2016-12-09 23:41:59 Training Error = 0.92281767496047 
2016-12-09 23:41:59 Training Loss = 0.015638216923631 
2016-12-09 23:42:02 Valid Error = 0.96405840509173 
2016-12-09 23:42:02 Valid Loss = 0.015620937620302 
2016-12-09 23:42:05 Test Error = 0.96396092960593 
2016-12-09 23:42:05 Test Loss = 0.015636235203027 
2016-12-09 23:42:05 -------------------LR------------------- 
2016-12-09 23:42:05 0.015625 
2016-12-09 23:42:05 Epoch 29 
2016-12-09 23:44:07 Training Error = 0.92331696762919 
2016-12-09 23:44:07 Training Loss = 0.015654331060667 
2016-12-09 23:44:10 Valid Error = 0.96405840509173 
2016-12-09 23:44:10 Valid Loss = 0.015616896500119 
2016-12-09 23:44:13 Test Error = 0.96396092960593 
2016-12-09 23:44:13 Test Loss = 0.015638437827561 
2016-12-09 23:44:13 -------------------LR------------------- 
2016-12-09 23:44:13 0.015625 
2016-12-09 23:44:13 Epoch 30 
2016-12-09 23:46:29 Training Error = 0.92290089040526 
2016-12-09 23:46:29 Training Loss = 0.01568973940454 
2016-12-09 23:46:32 Valid Error = 0.96405840509173 
2016-12-09 23:46:32 Valid Loss = 0.015637952520252 
2016-12-09 23:46:35 Test Error = 0.96396092960593 
2016-12-09 23:46:35 Test Loss = 0.01564816550657 
2016-12-09 23:46:35 -------------------LR------------------- 
2016-12-09 23:46:35 0.015625 
2016-12-09 23:46:35 Epoch 31 
2016-12-09 23:48:40 Training Error = 0.92136140467671 
2016-12-09 23:48:40 Training Loss = 0.015645325906117 
2016-12-09 23:48:43 Valid Error = 0.96405840509173 
2016-12-09 23:48:43 Valid Loss = 0.015641356882782 
2016-12-09 23:48:46 Test Error = 0.96396092960593 
2016-12-09 23:48:46 Test Loss = 0.01565814683984 
2016-12-09 23:48:46 -------------------LR------------------- 
2016-12-09 23:48:46 0.015625 
2016-12-09 23:48:46 Epoch 32 
2016-12-09 23:50:53 Training Error = 0.92294249812765 
2016-12-09 23:50:53 Training Loss = 0.015647171458468 
2016-12-09 23:50:56 Valid Error = 0.95881692250094 
2016-12-09 23:50:56 Valid Loss = 0.015626818248929 
2016-12-09 23:50:59 Test Error = 0.96160323341192 
2016-12-09 23:50:59 Test Loss = 0.01564203224348 
2016-12-09 23:50:59 -------------------LR------------------- 
2016-12-09 23:50:59 0.015625 
2016-12-09 23:50:59 Epoch 33 
2016-12-09 23:53:00 Training Error = 0.92439876841142 
2016-12-09 23:53:00 Training Loss = 0.015642231878443 
2016-12-09 23:53:02 Valid Error = 0.96405840509173 
2016-12-09 23:53:02 Valid Loss = 0.015626923568418 
2016-12-09 23:53:05 Test Error = 0.96396092960593 
2016-12-09 23:53:05 Test Loss = 0.01563734487161 
2016-12-09 23:53:05 -------------------LR------------------- 
2016-12-09 23:53:05 0.015625 
2016-12-09 23:53:05 Epoch 34 
2016-12-09 23:55:23 Training Error = 0.92277606723808 
2016-12-09 23:55:23 Training Loss = 0.01567506767193 
2016-12-09 23:55:26 Valid Error = 0.96405840509173 
2016-12-09 23:55:26 Valid Loss = 0.01565142113348 
2016-12-09 23:55:29 Test Error = 0.96396092960593 
2016-12-09 23:55:29 Test Loss = 0.015664767147965 
2016-12-09 23:55:29 -------------------LR------------------- 
2016-12-09 23:55:29 0.015625 
2016-12-09 23:55:29 Epoch 35 
2016-12-09 23:57:57 Training Error = 0.92252642090372 
2016-12-09 23:57:57 Training Loss = 0.015652045534361 
2016-12-09 23:57:59 Valid Error = 0.96405840509173 
2016-12-09 23:57:59 Valid Loss = 0.015637140979875 
2016-12-09 23:58:02 Test Error = 0.96396092960593 
2016-12-09 23:58:02 Test Loss = 0.015647584288517 
2016-12-09 23:58:02 -------------------LR------------------- 
2016-12-09 23:58:02 0.015625 
2016-12-09 23:58:02 Epoch 36 
2016-12-10 00:00:31 Training Error = 0.92402429890988 
2016-12-10 00:00:31 Training Loss = 0.01565654010769 
2016-12-10 00:00:33 Valid Error = 0.96405840509173 
2016-12-10 00:00:33 Valid Loss = 0.015615798590568 
2016-12-10 00:00:36 Test Error = 0.96396092960593 
2016-12-10 00:00:36 Test Loss = 0.015631754110617 
2016-12-10 00:00:36 -------------------LR------------------- 
2016-12-10 00:00:36 0.015625 
2016-12-10 00:00:36 Epoch 37 
2016-12-10 00:02:48 Training Error = 0.92431555296663 
2016-12-10 00:02:48 Training Loss = 0.015662980451011 
2016-12-10 00:02:50 Valid Error = 0.96405840509173 
2016-12-10 00:02:50 Valid Loss = 0.01562459740778 
2016-12-10 00:02:53 Test Error = 0.96396092960593 
2016-12-10 00:02:53 Test Loss = 0.0156402178077 
2016-12-10 00:02:53 -------------------LR------------------- 
2016-12-10 00:02:53 0.015625 
2016-12-10 00:02:53 Epoch 38 
2016-12-10 00:05:06 Training Error = 0.92277606723808 
2016-12-10 00:05:06 Training Loss = 0.015646789465319 
2016-12-10 00:05:09 Valid Error = 0.96405840509173 
2016-12-10 00:05:09 Valid Loss = 0.015626684200471 
2016-12-10 00:05:12 Test Error = 0.96396092960593 
2016-12-10 00:05:12 Test Loss = 0.015643564106225 
2016-12-10 00:05:12 -------------------LR------------------- 
2016-12-10 00:05:12 0.015625 
2016-12-10 00:05:12 Epoch 39 
2016-12-10 00:07:14 Training Error = 0.92722809353416 
2016-12-10 00:07:14 Training Loss = 0.015654132626084 
2016-12-10 00:07:17 Valid Error = 0.95881692250094 
2016-12-10 00:07:17 Valid Loss = 0.015616963923434 
2016-12-10 00:07:20 Test Error = 0.96160323341192 
2016-12-10 00:07:20 Test Loss = 0.015633483491355 
2016-12-10 00:07:20 -------------------LR------------------- 
2016-12-10 00:07:20 0.015625 
2016-12-10 00:07:20 Epoch 40 
2016-12-10 00:09:30 Training Error = 0.92302571357244 
2016-12-10 00:09:30 Training Loss = 0.015648893120006 
2016-12-10 00:09:33 Valid Error = 0.96405840509173 
2016-12-10 00:09:33 Valid Loss = 0.015624623566896 
2016-12-10 00:09:36 Test Error = 0.96396092960593 
2016-12-10 00:09:36 Test Loss = 0.01564551044094 
2016-12-10 00:09:36 -------------------LR------------------- 
2016-12-10 00:09:36 0.015625 
2016-12-10 00:09:36 Epoch 41 
2016-12-10 00:11:39 Training Error = 0.92277606723808 
2016-12-10 00:11:39 Training Loss = 0.015641838034946 
2016-12-10 00:11:42 Valid Error = 0.96405840509173 
2016-12-10 00:11:42 Valid Loss = 0.015610021657607 
2016-12-10 00:11:45 Test Error = 0.96396092960593 
2016-12-10 00:11:45 Test Loss = 0.015627122264026 
2016-12-10 00:11:45 -------------------LR------------------- 
2016-12-10 00:11:45 0.015625 
2016-12-10 00:11:45 Epoch 42 
2016-12-10 00:13:47 Training Error = 0.92169426645585 
2016-12-10 00:13:47 Training Loss = 0.015672104317334 
2016-12-10 00:13:50 Valid Error = 0.96405840509173 
2016-12-10 00:13:50 Valid Loss = 0.015679533495272 
2016-12-10 00:13:53 Test Error = 0.96396092960593 
2016-12-10 00:13:53 Test Loss = 0.0156928969469 
2016-12-10 00:13:53 -------------------LR------------------- 
2016-12-10 00:13:53 0.015625 
2016-12-10 00:13:53 Epoch 43 
2016-12-10 00:15:53 Training Error = 0.92281767496047 
2016-12-10 00:15:53 Training Loss = 0.015656547232094 
2016-12-10 00:15:55 Valid Error = 0.96405840509173 
2016-12-10 00:15:55 Valid Loss = 0.015665781951554 
2016-12-10 00:15:58 Test Error = 0.96396092960593 
2016-12-10 00:15:58 Test Loss = 0.015681024178968 
2016-12-10 00:15:58 -------------------LR------------------- 
2016-12-10 00:15:58 0.015625 
2016-12-10 00:15:58 Epoch 44 
2016-12-10 00:17:59 Training Error = 0.92090371973038 
2016-12-10 00:17:59 Training Loss = 0.015643379374783 
2016-12-10 00:18:02 Valid Error = 0.96405840509173 
2016-12-10 00:18:02 Valid Loss = 0.015615495297525 
2016-12-10 00:18:05 Test Error = 0.96396092960593 
2016-12-10 00:18:05 Test Loss = 0.015631886552324 
2016-12-10 00:18:05 -------------------LR------------------- 
2016-12-10 00:18:05 0.015625 
2016-12-10 00:18:05 Epoch 45 
2016-12-10 00:20:07 Training Error = 0.92460680702338 
2016-12-10 00:20:07 Training Loss = 0.015683753724911 
2016-12-10 00:20:10 Valid Error = 0.96405840509173 
2016-12-10 00:20:10 Valid Loss = 0.015639820287922 
2016-12-10 00:20:13 Test Error = 0.96396092960593 
2016-12-10 00:20:13 Test Loss = 0.015652851392491 
2016-12-10 00:20:13 -------------------LR------------------- 
2016-12-10 00:20:13 0.015625 
2016-12-10 00:20:13 Epoch 46 
2016-12-10 00:22:08 Training Error = 0.922027128235 
2016-12-10 00:22:08 Training Loss = 0.015671735663032 
2016-12-10 00:22:10 Valid Error = 0.96405840509173 
2016-12-10 00:22:10 Valid Loss = 0.015697478453064 
2016-12-10 00:22:13 Test Error = 0.96396092960593 
2016-12-10 00:22:13 Test Loss = 0.015708053207815 
2016-12-10 00:22:13 -------------------LR------------------- 
2016-12-10 00:22:13 0.015625 
2016-12-10 00:22:13 Epoch 47 
2016-12-10 00:24:15 Training Error = 0.9226512440709 
2016-12-10 00:24:15 Training Loss = 0.015684901851068 
2016-12-10 00:24:18 Valid Error = 0.96405840509173 
2016-12-10 00:24:18 Valid Loss = 0.015672701915662 
2016-12-10 00:24:21 Test Error = 0.96396092960593 
2016-12-10 00:24:21 Test Loss = 0.015685675169691 
2016-12-10 00:24:21 -------------------LR------------------- 
2016-12-10 00:24:21 0.015625 
2016-12-10 00:24:21 Epoch 48 
2016-12-10 00:26:23 Training Error = 0.92419072979945 
2016-12-10 00:26:23 Training Loss = 0.015644770938742 
2016-12-10 00:26:26 Valid Error = 0.96405840509173 
2016-12-10 00:26:26 Valid Loss = 0.015653285025433 
2016-12-10 00:26:29 Test Error = 0.96396092960593 
2016-12-10 00:26:29 Test Loss = 0.01566695868868 
2016-12-10 00:26:29 -------------------LR------------------- 
2016-12-10 00:26:29 0.015625 
2016-12-10 00:26:29 Epoch 49 
2016-12-10 00:28:32 Training Error = 0.92298410585005 
2016-12-10 00:28:32 Training Loss = 0.015660031136635 
2016-12-10 00:28:35 Valid Error = 0.96405840509173 
2016-12-10 00:28:35 Valid Loss = 0.015672496073568 
2016-12-10 00:28:38 Test Error = 0.96396092960593 
2016-12-10 00:28:38 Test Loss = 0.01569050014761 
2016-12-10 00:28:38 -------------------LR------------------- 
2016-12-10 00:28:38 0.015625 
2016-12-10 00:28:38 Epoch 50 
2016-12-10 00:30:48 Training Error = 0.92285928268287 
2016-12-10 00:30:48 Training Loss = 0.015677721530098 
2016-12-10 00:30:51 Valid Error = 0.95881692250094 
2016-12-10 00:30:51 Valid Loss = 0.015697494254259 
2016-12-10 00:30:54 Test Error = 0.96160323341192 
2016-12-10 00:30:54 Test Loss = 0.015714159230275 
2016-12-10 00:30:54 -------------------LR------------------- 
2016-12-10 00:30:54 0.0078125 
2016-12-10 00:30:54 Epoch 51 
2016-12-10 00:32:57 Training Error = 0.92373304485312 
2016-12-10 00:32:57 Training Loss = 0.015682833164828 
2016-12-10 00:33:00 Valid Error = 0.96405840509173 
2016-12-10 00:33:00 Valid Loss = 0.01567379312907 
2016-12-10 00:33:03 Test Error = 0.96396092960593 
2016-12-10 00:33:03 Test Loss = 0.015690408927509 
2016-12-10 00:33:03 -------------------LR------------------- 
2016-12-10 00:33:03 0.0078125 
2016-12-10 00:33:03 Epoch 52 
2016-12-10 00:35:06 Training Error = 0.92410751435466 
2016-12-10 00:35:06 Training Loss = 0.01565243211034 
2016-12-10 00:35:09 Valid Error = 0.96405840509173 
2016-12-10 00:35:09 Valid Loss = 0.015647390579266 
2016-12-10 00:35:11 Test Error = 0.96396092960593 
2016-12-10 00:35:11 Test Loss = 0.015666583843812 
2016-12-10 00:35:11 -------------------LR------------------- 
2016-12-10 00:35:11 0.0078125 
2016-12-10 00:35:11 Epoch 53 
2016-12-10 00:37:15 Training Error = 0.92364982940834 
2016-12-10 00:37:15 Training Loss = 0.015642309587231 
2016-12-10 00:37:18 Valid Error = 0.96405840509173 
2016-12-10 00:37:18 Valid Loss = 0.015637096379708 
2016-12-10 00:37:21 Test Error = 0.96396092960593 
2016-12-10 00:37:21 Test Loss = 0.015645483988665 
2016-12-10 00:37:21 -------------------LR------------------- 
2016-12-10 00:37:21 0.0078125 
2016-12-10 00:37:21 Epoch 54 
2016-12-10 00:39:19 Training Error = 0.92381626029791 
2016-12-10 00:39:19 Training Loss = 0.015649424815738 
2016-12-10 00:39:22 Valid Error = 0.96405840509173 
2016-12-10 00:39:22 Valid Loss = 0.015620558834552 
2016-12-10 00:39:24 Test Error = 0.96396092960593 
2016-12-10 00:39:24 Test Loss = 0.015635966821552 
2016-12-10 00:39:24 -------------------LR------------------- 
2016-12-10 00:39:24 0.0078125 
2016-12-10 00:39:25 Epoch 55 
2016-12-10 00:41:25 Training Error = 0.92206873595739 
2016-12-10 00:41:25 Training Loss = 0.015640830445423 
2016-12-10 00:41:28 Valid Error = 0.96405840509173 
2016-12-10 00:41:28 Valid Loss = 0.015656684876981 
2016-12-10 00:41:31 Test Error = 0.96396092960593 
2016-12-10 00:41:31 Test Loss = 0.01567174739104 
2016-12-10 00:41:31 -------------------LR------------------- 
2016-12-10 00:41:31 0.0078125 
2016-12-10 00:41:31 Epoch 56 
2016-12-10 00:43:34 Training Error = 0.92410751435466 
2016-12-10 00:43:34 Training Loss = 0.015685004819159 
2016-12-10 00:43:36 Valid Error = 0.96405840509173 
2016-12-10 00:43:36 Valid Loss = 0.0156326400202 
2016-12-10 00:43:39 Test Error = 0.96396092960593 
2016-12-10 00:43:39 Test Loss = 0.015646674515446 
2016-12-10 00:43:39 -------------------LR------------------- 
2016-12-10 00:43:39 0.0078125 
2016-12-10 00:43:39 Epoch 57 
2016-12-10 00:45:42 Training Error = 0.92427394524424 
2016-12-10 00:45:42 Training Loss = 0.015651389410994 
2016-12-10 00:45:45 Valid Error = 0.96405840509173 
2016-12-10 00:45:45 Valid Loss = 0.015661122612905 
2016-12-10 00:45:48 Test Error = 0.96396092960593 
2016-12-10 00:45:48 Test Loss = 0.01568134525441 
2016-12-10 00:45:48 -------------------LR------------------- 
2016-12-10 00:45:48 0.0078125 
2016-12-10 00:45:48 Epoch 58 
2016-12-10 00:47:48 Training Error = 0.92431555296663 
2016-12-10 00:47:48 Training Loss = 0.015668771417595 
2016-12-10 00:47:51 Valid Error = 0.96405840509173 
2016-12-10 00:47:51 Valid Loss = 0.015624785027339 
2016-12-10 00:47:54 Test Error = 0.96396092960593 
2016-12-10 00:47:54 Test Loss = 0.015640807128776 
2016-12-10 00:47:54 -------------------LR------------------- 
2016-12-10 00:47:54 0.0078125 
2016-12-10 00:47:54 Epoch 59 
2016-12-10 00:49:54 Training Error = 0.92523092285928 
2016-12-10 00:49:54 Training Loss = 0.015663137463408 
2016-12-10 00:49:56 Valid Error = 0.96405840509173 
2016-12-10 00:49:56 Valid Loss = 0.015655972879812 
2016-12-10 00:49:59 Test Error = 0.96396092960593 
2016-12-10 00:49:59 Test Loss = 0.015673487587475 
2016-12-10 00:49:59 -------------------LR------------------- 
2016-12-10 00:49:59 0.0078125 
2016-12-10 00:49:59 Epoch 60 
2016-12-10 00:52:07 Training Error = 0.92556378463843 
2016-12-10 00:52:07 Training Loss = 0.015677257548651 
2016-12-10 00:52:10 Valid Error = 0.96405840509173 
2016-12-10 00:52:10 Valid Loss = 0.015705570094199 
2016-12-10 00:52:13 Test Error = 0.96396092960593 
2016-12-10 00:52:13 Test Loss = 0.015717944186453 
2016-12-10 00:52:13 -------------------LR------------------- 
2016-12-10 00:52:13 0.0078125 
2016-12-10 00:52:13 Epoch 61 
2016-12-10 00:54:15 Training Error = 0.92597986186236 
2016-12-10 00:54:15 Training Loss = 0.015655588148024 
2016-12-10 00:54:18 Valid Error = 0.96405840509173 
2016-12-10 00:54:18 Valid Loss = 0.0156348057397 
2016-12-10 00:54:20 Test Error = 0.96396092960593 
2016-12-10 00:54:20 Test Loss = 0.015648270558163 
2016-12-10 00:54:20 -------------------LR------------------- 
2016-12-10 00:54:20 0.0078125 
2016-12-10 00:54:20 Epoch 62 
2016-12-10 00:56:20 Training Error = 0.92456519930099 
2016-12-10 00:56:20 Training Loss = 0.015708978758216 
2016-12-10 00:56:24 Valid Error = 0.95881692250094 
2016-12-10 00:56:24 Valid Loss = 0.015625187398425 
2016-12-10 00:56:27 Test Error = 0.96160323341192 
2016-12-10 00:56:27 Test Loss = 0.015640454233845 
2016-12-10 00:56:27 -------------------LR------------------- 
2016-12-10 00:56:27 0.0078125 
2016-12-10 00:56:27 Epoch 63 
2016-12-10 00:58:29 Training Error = 0.92269285179329 
2016-12-10 00:58:29 Training Loss = 0.015650001610002 
2016-12-10 00:58:32 Valid Error = 0.96405840509173 
2016-12-10 00:58:32 Valid Loss = 0.015654882748515 
2016-12-10 00:58:35 Test Error = 0.96396092960593 
2016-12-10 00:58:35 Test Loss = 0.015668488625919 
2016-12-10 00:58:35 -------------------LR------------------- 
2016-12-10 00:58:35 0.0078125 
2016-12-10 00:58:35 Epoch 64 
2016-12-10 01:00:34 Training Error = 0.92348339851877 
2016-12-10 01:00:34 Training Loss = 0.015642316830704 
2016-12-10 01:00:36 Valid Error = 0.95881692250094 
2016-12-10 01:00:36 Valid Loss = 0.015617922837821 
2016-12-10 01:00:39 Test Error = 0.96160323341192 
2016-12-10 01:00:39 Test Loss = 0.015633270873623 
2016-12-10 01:00:39 -------------------LR------------------- 
2016-12-10 01:00:39 0.0078125 
2016-12-10 01:00:39 Epoch 65 
2016-12-10 01:02:45 Training Error = 0.92331696762919 
2016-12-10 01:02:45 Training Loss = 0.015681451808304 
2016-12-10 01:02:48 Valid Error = 0.96405840509173 
2016-12-10 01:02:48 Valid Loss = 0.01568564537535 
2016-12-10 01:02:51 Test Error = 0.96396092960593 
2016-12-10 01:02:51 Test Loss = 0.015697436316413 
2016-12-10 01:02:51 -------------------LR------------------- 
2016-12-10 01:02:51 0.0078125 
2016-12-10 01:02:51 Epoch 66 
2016-12-10 01:04:42 Training Error = 0.92223516684697 
2016-12-10 01:04:42 Training Loss = 0.015671734403688 
2016-12-10 01:04:45 Valid Error = 0.96405840509173 
2016-12-10 01:04:45 Valid Loss = 0.01567083923536 
2016-12-10 01:04:48 Test Error = 0.96396092960593 
2016-12-10 01:04:48 Test Loss = 0.01569062210047 
2016-12-10 01:04:48 -------------------LR------------------- 
2016-12-10 01:04:48 0.0078125 
2016-12-10 01:04:48 Epoch 67 
2016-12-10 01:06:39 Training Error = 0.92473163019056 
2016-12-10 01:06:39 Training Loss = 0.015662313029473 
2016-12-10 01:06:42 Valid Error = 0.96405840509173 
2016-12-10 01:06:42 Valid Loss = 0.015673899440386 
2016-12-10 01:06:45 Test Error = 0.96396092960593 
2016-12-10 01:06:45 Test Loss = 0.015689899823983 
2016-12-10 01:06:45 -------------------LR------------------- 
2016-12-10 01:06:45 0.0078125 
2016-12-10 01:06:45 Epoch 68 
2016-12-10 01:08:33 Training Error = 0.92240159773654 
2016-12-10 01:08:33 Training Loss = 0.015662773207104 
2016-12-10 01:08:36 Valid Error = 0.96405840509173 
2016-12-10 01:08:36 Valid Loss = 0.015658920940322 
2016-12-10 01:08:39 Test Error = 0.96396092960593 
2016-12-10 01:08:39 Test Loss = 0.015674611843278 
2016-12-10 01:08:39 -------------------LR------------------- 
2016-12-10 01:08:39 0.0078125 
2016-12-10 01:08:39 Epoch 69 
2016-12-10 01:10:34 Training Error = 0.92456519930099 
2016-12-10 01:10:34 Training Loss = 0.015654151105151 
2016-12-10 01:10:37 Valid Error = 0.96405840509173 
2016-12-10 01:10:37 Valid Loss = 0.015678237483282 
2016-12-10 01:10:40 Test Error = 0.96396092960593 
2016-12-10 01:10:40 Test Loss = 0.015692654883045 
2016-12-10 01:10:40 -------------------LR------------------- 
2016-12-10 01:10:40 0.0078125 
2016-12-10 01:10:40 Epoch 70 
2016-12-10 01:12:36 Training Error = 0.92394108346509 
2016-12-10 01:12:36 Training Loss = 0.015647887461651 
2016-12-10 01:12:39 Valid Error = 0.96405840509173 
2016-12-10 01:12:39 Valid Loss = 0.01564360227885 
2016-12-10 01:12:42 Test Error = 0.96396092960593 
2016-12-10 01:12:42 Test Loss = 0.015649668185977 
2016-12-10 01:12:42 -------------------LR------------------- 
2016-12-10 01:12:42 0.0078125 
2016-12-10 01:12:42 Epoch 71 
2016-12-10 01:14:34 Training Error = 0.92227677456936 
2016-12-10 01:14:34 Training Loss = 0.015648010858808 
2016-12-10 01:14:36 Valid Error = 0.96405840509173 
2016-12-10 01:14:36 Valid Loss = 0.015676055778745 
2016-12-10 01:14:39 Test Error = 0.96396092960593 
2016-12-10 01:14:39 Test Loss = 0.015689150125349 
2016-12-10 01:14:39 -------------------LR------------------- 
2016-12-10 01:14:39 0.0078125 
2016-12-10 01:14:39 Epoch 72 
2016-12-10 01:16:30 Training Error = 0.92419072979945 
2016-12-10 01:16:30 Training Loss = 0.015650635209162 
2016-12-10 01:16:34 Valid Error = 0.96405840509173 
2016-12-10 01:16:34 Valid Loss = 0.015676260683968 
2016-12-10 01:16:36 Test Error = 0.96396092960593 
2016-12-10 01:16:36 Test Loss = 0.015692115475639 
2016-12-10 01:16:36 -------------------LR------------------- 
2016-12-10 01:16:36 0.0078125 
2016-12-10 01:16:36 Epoch 73 
2016-12-10 01:18:27 Training Error = 0.92177748190064 
2016-12-10 01:18:27 Training Loss = 0.015655298317581 
2016-12-10 01:18:30 Valid Error = 0.95881692250094 
2016-12-10 01:18:30 Valid Loss = 0.015672801873657 
2016-12-10 01:18:32 Test Error = 0.96160323341192 
2016-12-10 01:18:32 Test Loss = 0.015691167233973 
2016-12-10 01:18:32 -------------------LR------------------- 
2016-12-10 01:18:32 0.0078125 
2016-12-10 01:18:32 Epoch 74 
2016-12-10 01:20:25 Training Error = 0.92419072979945 
2016-12-10 01:20:25 Training Loss = 0.015644896967282 
2016-12-10 01:20:27 Valid Error = 0.96405840509173 
2016-12-10 01:20:27 Valid Loss = 0.015624117261345 
2016-12-10 01:20:30 Test Error = 0.96396092960593 
2016-12-10 01:20:30 Test Loss = 0.015640659345307 
2016-12-10 01:20:30 -------------------LR------------------- 
2016-12-10 01:20:30 0.0078125 
2016-12-10 01:20:30 Epoch 75 
2016-12-10 01:22:23 Training Error = 0.92485645335774 
2016-12-10 01:22:23 Training Loss = 0.015650830111093 
2016-12-10 01:22:25 Valid Error = 0.96405840509173 
2016-12-10 01:22:25 Valid Loss = 0.015598756227602 
2016-12-10 01:22:28 Test Error = 0.96396092960593 
2016-12-10 01:22:28 Test Loss = 0.015617075336611 
2016-12-10 01:22:28 -------------------LR------------------- 
2016-12-10 01:22:28 0.0078125 
2016-12-10 01:22:28 Epoch 76 
2016-12-10 01:24:19 Training Error = 0.92485645335774 
2016-12-10 01:24:19 Training Loss = 0.015685562411833 
2016-12-10 01:24:21 Valid Error = 0.96405840509173 
2016-12-10 01:24:21 Valid Loss = 0.015634750851616 
2016-12-10 01:24:24 Test Error = 0.96396092960593 
2016-12-10 01:24:24 Test Loss = 0.015648598334318 
2016-12-10 01:24:24 -------------------LR------------------- 
2016-12-10 01:24:24 0.0078125 
2016-12-10 01:24:24 Epoch 77 
2016-12-10 01:26:16 Training Error = 0.92219355912457 
2016-12-10 01:26:16 Training Loss = 0.015648127894063 
2016-12-10 01:26:18 Valid Error = 0.95881692250094 
2016-12-10 01:26:18 Valid Loss = 0.015610590496686 
2016-12-10 01:26:21 Test Error = 0.96160323341192 
2016-12-10 01:26:21 Test Loss = 0.015630834650104 
2016-12-10 01:26:21 -------------------LR------------------- 
2016-12-10 01:26:21 0.0078125 
2016-12-10 01:26:21 Epoch 78 
2016-12-10 01:28:15 Training Error = 0.92419072979945 
2016-12-10 01:28:15 Training Loss = 0.015645069201023 
2016-12-10 01:28:18 Valid Error = 0.96405840509173 
2016-12-10 01:28:18 Valid Loss = 0.015678919496651 
2016-12-10 01:28:21 Test Error = 0.96396092960593 
2016-12-10 01:28:21 Test Loss = 0.015693414763251 
2016-12-10 01:28:21 -------------------LR------------------- 
2016-12-10 01:28:21 0.0078125 
2016-12-10 01:28:21 Epoch 79 
2016-12-10 01:30:12 Training Error = 0.92481484563535 
2016-12-10 01:30:12 Training Loss = 0.015668020818524 
2016-12-10 01:30:14 Valid Error = 0.96405840509173 
2016-12-10 01:30:14 Valid Loss = 0.015680934182325 
2016-12-10 01:30:17 Test Error = 0.96396092960593 
2016-12-10 01:30:17 Test Loss = 0.015696392758052 
2016-12-10 01:30:17 -------------------LR------------------- 
2016-12-10 01:30:17 0.0078125 
2016-12-10 01:30:17 Epoch 80 
2016-12-10 01:32:34 Training Error = 0.92568860780561 
2016-12-10 01:32:34 Training Loss = 0.015656692037518 
2016-12-10 01:32:36 Valid Error = 0.96405840509173 
2016-12-10 01:32:36 Valid Loss = 0.015654820480608 
2016-12-10 01:32:39 Test Error = 0.96396092960593 
2016-12-10 01:32:39 Test Loss = 0.015669613702702 
2016-12-10 01:32:39 -------------------LR------------------- 
2016-12-10 01:32:39 0.0078125 
2016-12-10 01:32:39 Epoch 81 
2016-12-10 01:34:36 Training Error = 0.92460680702338 
2016-12-10 01:34:36 Training Loss = 0.015640516663112 
2016-12-10 01:34:39 Valid Error = 0.96405840509173 
2016-12-10 01:34:39 Valid Loss = 0.015697125197052 
2016-12-10 01:34:42 Test Error = 0.96396092960593 
2016-12-10 01:34:42 Test Loss = 0.015721623414204 
2016-12-10 01:34:42 -------------------LR------------------- 
2016-12-10 01:34:42 0.0078125 
2016-12-10 01:34:42 Epoch 82 
2016-12-10 01:36:34 Training Error = 0.9238994757427 
2016-12-10 01:36:34 Training Loss = 0.015675725225277 
2016-12-10 01:36:37 Valid Error = 0.96405840509173 
2016-12-10 01:36:37 Valid Loss = 0.015658864525242 
2016-12-10 01:36:39 Test Error = 0.96396092960593 
2016-12-10 01:36:39 Test Loss = 0.015678850879545 
2016-12-10 01:36:39 -------------------LR------------------- 
2016-12-10 01:36:39 0.0078125 
2016-12-10 01:36:40 Epoch 83 
2016-12-10 01:38:30 Training Error = 0.92410751435466 
2016-12-10 01:38:30 Training Loss = 0.015696386385127 
2016-12-10 01:38:33 Valid Error = 0.96405840509173 
2016-12-10 01:38:33 Valid Loss = 0.015656256656888 
2016-12-10 01:38:36 Test Error = 0.96396092960593 
2016-12-10 01:38:36 Test Loss = 0.015664209075134 
2016-12-10 01:38:36 -------------------LR------------------- 
2016-12-10 01:38:36 0.0078125 
2016-12-10 01:38:36 Epoch 84 
2016-12-10 01:40:24 Training Error = 0.9251060996921 
2016-12-10 01:40:24 Training Loss = 0.015684268573189 
2016-12-10 01:40:26 Valid Error = 0.96405840509173 
2016-12-10 01:40:26 Valid Loss = 0.015657155279171 
2016-12-10 01:40:29 Test Error = 0.96396092960593 
2016-12-10 01:40:29 Test Loss = 0.01566199043319 
2016-12-10 01:40:29 -------------------LR------------------- 
2016-12-10 01:40:29 0.0078125 
2016-12-10 01:40:29 Epoch 85 
2016-12-10 01:42:19 Training Error = 0.92340018307398 
2016-12-10 01:42:19 Training Loss = 0.015665546869229 
2016-12-10 01:42:22 Valid Error = 0.96405840509173 
2016-12-10 01:42:22 Valid Loss = 0.015671137989943 
2016-12-10 01:42:25 Test Error = 0.96396092960593 
2016-12-10 01:42:25 Test Loss = 0.01568553679783 
2016-12-10 01:42:25 -------------------LR------------------- 
2016-12-10 01:42:25 0.0078125 
2016-12-10 01:42:25 Epoch 86 
2016-12-10 01:44:15 Training Error = 0.92398269118748 
2016-12-10 01:44:15 Training Loss = 0.015648286400754 
2016-12-10 01:44:17 Valid Error = 0.96405840509173 
2016-12-10 01:44:17 Valid Loss = 0.015617809931115 
2016-12-10 01:44:20 Test Error = 0.96396092960593 
2016-12-10 01:44:20 Test Loss = 0.015634288712302 
2016-12-10 01:44:20 -------------------LR------------------- 
2016-12-10 01:44:20 0.0078125 
2016-12-10 01:44:20 Epoch 87 
2016-12-10 01:46:10 Training Error = 0.92123658150953 
2016-12-10 01:46:10 Training Loss = 0.015684351028779 
2016-12-10 01:46:13 Valid Error = 0.96405840509173 
2016-12-10 01:46:13 Valid Loss = 0.015680835031007 
2016-12-10 01:46:16 Test Error = 0.96396092960593 
2016-12-10 01:46:16 Test Loss = 0.015697513129625 
2016-12-10 01:46:16 -------------------LR------------------- 
2016-12-10 01:46:16 0.0078125 
2016-12-10 01:46:16 Epoch 88 
2016-12-10 01:48:06 Training Error = 0.92161105101107 
2016-12-10 01:48:06 Training Loss = 0.015639666446668 
2016-12-10 01:48:09 Valid Error = 0.96405840509173 
2016-12-10 01:48:09 Valid Loss = 0.015635833231481 
2016-12-10 01:48:12 Test Error = 0.96396092960593 
2016-12-10 01:48:12 Test Loss = 0.015655433927765 
2016-12-10 01:48:12 -------------------LR------------------- 
2016-12-10 01:48:12 0.0078125 
2016-12-10 01:48:12 Epoch 89 
2016-12-10 01:50:00 Training Error = 0.92481484563535 
2016-12-10 01:50:00 Training Loss = 0.015640982140881 
2016-12-10 01:50:03 Valid Error = 0.96405840509173 
2016-12-10 01:50:03 Valid Loss = 0.015664439397614 
2016-12-10 01:50:06 Test Error = 0.96396092960593 
2016-12-10 01:50:06 Test Loss = 0.015676778732653 
2016-12-10 01:50:06 -------------------LR------------------- 
2016-12-10 01:50:06 0.0078125 
2016-12-10 01:50:06 Epoch 90 
2016-12-10 01:52:02 Training Error = 0.92298410585005 
2016-12-10 01:52:02 Training Loss = 0.015644163999314 
2016-12-10 01:52:05 Valid Error = 0.96405840509173 
2016-12-10 01:52:05 Valid Loss = 0.01561523749834 
2016-12-10 01:52:08 Test Error = 0.96396092960593 
2016-12-10 01:52:08 Test Loss = 0.015628492568757 
2016-12-10 01:52:08 -------------------LR------------------- 
2016-12-10 01:52:08 0.0078125 
2016-12-10 01:52:08 Epoch 91 
2016-12-10 01:53:54 Training Error = 0.92369143713073 
2016-12-10 01:53:54 Training Loss = 0.015693888628236 
2016-12-10 01:53:57 Valid Error = 0.96405840509173 
2016-12-10 01:53:57 Valid Loss = 0.015677663404398 
2016-12-10 01:54:00 Test Error = 0.96396092960593 
2016-12-10 01:54:00 Test Loss = 0.01568991791401 
2016-12-10 01:54:00 -------------------LR------------------- 
2016-12-10 01:54:00 0.0078125 
2016-12-10 01:54:00 Epoch 92 
2016-12-10 01:55:52 Training Error = 0.92556378463843 
2016-12-10 01:55:52 Training Loss = 0.015707096684603 
2016-12-10 01:55:57 Valid Error = 0.96405840509173 
2016-12-10 01:55:57 Valid Loss = 0.01561215662523 
2016-12-10 01:56:00 Test Error = 0.96396092960593 
2016-12-10 01:56:00 Test Loss = 0.015628379282453 
2016-12-10 01:56:00 -------------------LR------------------- 
2016-12-10 01:56:00 0.0078125 
2016-12-10 01:56:00 Epoch 93 
2016-12-10 01:58:19 Training Error = 0.92406590663227 
2016-12-10 01:58:19 Training Loss = 0.015655685426905 
2016-12-10 01:58:22 Valid Error = 0.96405840509173 
2016-12-10 01:58:22 Valid Loss = 0.01565740358534 
2016-12-10 01:58:25 Test Error = 0.96396092960593 
2016-12-10 01:58:25 Test Loss = 0.015672977152822 
2016-12-10 01:58:25 -------------------LR------------------- 
2016-12-10 01:58:25 0.0078125 
2016-12-10 01:58:25 Epoch 94 
2016-12-10 02:00:29 Training Error = 0.92410751435466 
2016-12-10 02:00:29 Training Loss = 0.015662470806978 
2016-12-10 02:00:32 Valid Error = 0.96405840509173 
2016-12-10 02:00:32 Valid Loss = 0.015653004807421 
2016-12-10 02:00:34 Test Error = 0.96396092960593 
2016-12-10 02:00:34 Test Loss = 0.015669945035645 
2016-12-10 02:00:34 -------------------LR------------------- 
2016-12-10 02:00:34 0.0078125 
2016-12-10 02:00:34 Epoch 95 
2016-12-10 02:02:39 Training Error = 0.92344179079637 
2016-12-10 02:02:39 Training Loss = 0.015661776798133 
2016-12-10 02:02:42 Valid Error = 0.96405840509173 
2016-12-10 02:02:42 Valid Loss = 0.015667962329947 
2016-12-10 02:02:45 Test Error = 0.96396092960593 
2016-12-10 02:02:45 Test Loss = 0.015688770750263 
2016-12-10 02:02:45 -------------------LR------------------- 
2016-12-10 02:02:45 0.0078125 
2016-12-10 02:02:45 Epoch 96 
2016-12-10 02:04:47 Training Error = 0.92360822168594 
2016-12-10 02:04:47 Training Loss = 0.015647419937412 
2016-12-10 02:04:50 Valid Error = 0.95881692250094 
2016-12-10 02:04:50 Valid Loss = 0.01560293711626 
2016-12-10 02:04:53 Test Error = 0.96160323341192 
2016-12-10 02:04:53 Test Loss = 0.015620593177189 
2016-12-10 02:04:53 -------------------LR------------------- 
2016-12-10 02:04:53 0.0078125 
2016-12-10 02:04:53 Epoch 97 
2016-12-10 02:06:48 Training Error = 0.92373304485312 
2016-12-10 02:06:48 Training Loss = 0.015647192582824 
2016-12-10 02:06:51 Valid Error = 0.96405840509173 
2016-12-10 02:06:51 Valid Loss = 0.015665087028076 
2016-12-10 02:06:54 Test Error = 0.96396092960593 
2016-12-10 02:06:54 Test Loss = 0.015691590328009 
2016-12-10 02:06:54 -------------------LR------------------- 
2016-12-10 02:06:54 0.0078125 
2016-12-10 02:06:54 Epoch 98 
2016-12-10 02:08:54 Training Error = 0.92335857535159 
2016-12-10 02:08:54 Training Loss = 0.015640279881262 
2016-12-10 02:08:57 Valid Error = 0.96405840509173 
2016-12-10 02:08:57 Valid Loss = 0.015633416783163 
2016-12-10 02:09:00 Test Error = 0.96396092960593 
2016-12-10 02:09:00 Test Loss = 0.015649519453399 
2016-12-10 02:09:00 -------------------LR------------------- 
2016-12-10 02:09:00 0.0078125 
2016-12-10 02:09:00 Epoch 99 
2016-12-10 02:10:53 Training Error = 0.92302571357244 
2016-12-10 02:10:53 Training Loss = 0.015647906758554 
2016-12-10 02:10:55 Valid Error = 0.96405840509173 
2016-12-10 02:10:55 Valid Loss = 0.015664545775009 
2016-12-10 02:10:58 Test Error = 0.96396092960593 
2016-12-10 02:10:58 Test Loss = 0.015677758618816 
2016-12-10 02:10:58 -------------------LR------------------- 
2016-12-10 02:10:58 0.0078125 
2016-12-10 02:10:58 Epoch 100 
2016-12-10 02:13:00 Training Error = 0.92614629275193 
2016-12-10 02:13:00 Training Loss = 0.015668592247757 
2016-12-10 02:13:02 Valid Error = 0.96405840509173 
2016-12-10 02:13:02 Valid Loss = 0.015612920330225 
2016-12-10 02:13:05 Test Error = 0.96396092960593 
2016-12-10 02:13:05 Test Loss = 0.015631250601498 
2016-12-10 02:13:05 -------------------LR------------------- 
2016-12-10 02:13:05 0.00390625 
2016-12-10 02:13:05 Epoch 101 
2016-12-10 02:14:58 Training Error = 0.92348339851877 
2016-12-10 02:14:58 Training Loss = 0.015702669860323 
2016-12-10 02:15:01 Valid Error = 0.96405840509173 
2016-12-10 02:15:01 Valid Loss = 0.015709507663956 
2016-12-10 02:15:04 Test Error = 0.96396092960593 
2016-12-10 02:15:04 Test Loss = 0.015723304848896 
2016-12-10 02:15:04 -------------------LR------------------- 
2016-12-10 02:15:04 0.00390625 
2016-12-10 02:15:04 Epoch 102 
2016-12-10 02:17:00 Training Error = 0.92252642090372 
2016-12-10 02:17:00 Training Loss = 0.015641062284921 
2016-12-10 02:17:04 Valid Error = 0.96405840509173 
2016-12-10 02:17:04 Valid Loss = 0.015641737470307 
2016-12-10 02:17:07 Test Error = 0.96396092960593 
2016-12-10 02:17:07 Test Loss = 0.015660257449988 
2016-12-10 02:17:07 -------------------LR------------------- 
2016-12-10 02:17:07 0.00390625 
2016-12-10 02:17:07 Epoch 103 
2016-12-10 02:19:03 Training Error = 0.92273445951569 
2016-12-10 02:19:03 Training Loss = 0.015664339021435 
2016-12-10 02:19:06 Valid Error = 0.96405840509173 
2016-12-10 02:19:06 Valid Loss = 0.015661551340688 
2016-12-10 02:19:09 Test Error = 0.96396092960593 
2016-12-10 02:19:09 Test Loss = 0.01567478827799 
2016-12-10 02:19:09 -------------------LR------------------- 
2016-12-10 02:19:09 0.00390625 
2016-12-10 02:19:09 Epoch 104 
