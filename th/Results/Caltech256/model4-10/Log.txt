2016-12-09 22:36:37 [program started on Fri Dec  9 22:36:37 2016] 
2016-12-09 22:36:37 [command line arguments] 
2016-12-09 22:36:37 stcWeights false 
2016-12-09 22:36:37 LR 0.015625 
2016-12-09 22:36:37 batchSize 300 
2016-12-09 22:36:37 network ./Models/Cifar10_Custom 
2016-12-09 22:36:37 stcNeurons true 
2016-12-09 22:36:37 constBatchSize false 
2016-12-09 22:36:37 chartFileName chart1 
2016-12-09 22:36:37 dp_prepro false 
2016-12-09 22:36:37 nGPU 1 
2016-12-09 22:36:37 dataset Caltech256 
2016-12-09 22:36:37 type cuda 
2016-12-09 22:36:37 momentum 0 
2016-12-09 22:36:37 threads 8 
2016-12-09 22:36:37 weightDecay 0 
2016-12-09 22:36:37 runningVal false 
2016-12-09 22:36:37 convLayerN 4 
2016-12-09 22:36:37 LRDecay 0 
2016-12-09 22:36:37 numHid 1024 
2016-12-09 22:36:37 save /dev/shm/clone/temp/th/Results/Caltech256/model4-10 
2016-12-09 22:36:37 augment false 
2016-12-09 22:36:37 epoch -1 
2016-12-09 22:36:37 modelsFolder ./Models/ 
2016-12-09 22:36:37 format rgb 
2016-12-09 22:36:37 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 22:36:37 imageFileExtension svg 
2016-12-09 22:36:37 channel 1 
2016-12-09 22:36:37 devid 4 
2016-12-09 22:36:37 visualize 1 
2016-12-09 22:36:37 LRDecayPerEpoch 0.0001 
2016-12-09 22:36:37 optimization adam 
2016-12-09 22:36:37 SBN true 
2016-12-09 22:36:37 normalization simple 
2016-12-09 22:36:37 title model1 
2016-12-09 22:36:37 load  
2016-12-09 22:36:37 whiten true 
2016-12-09 22:36:37 [----------------------] 
2016-12-09 22:36:38 ==> Network 
2016-12-09 22:36:38 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): nn.View(16384)
  (20): BinaryLinear(16384 -> 1024)
  (21): BatchNormalizationShiftPow2
  (22): nn.HardTanh
  (23): BinarizedNeurons
  (24): BinaryLinear(1024 -> 1024)
  (25): BatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): BinaryLinear(1024 -> 255)
  (29): nn.BatchNormalization
} 
2016-12-09 22:36:38 ==>19131773 Parameters 
2016-12-09 22:36:38 ==> Loss 
2016-12-09 22:36:38 SqrtHingeEmbeddingCriterion 
2016-12-09 22:36:38 
==> Starting Training
 
2016-12-09 22:36:38 Epoch 1 
2016-12-09 22:38:51 Training Error = 0.99092951651827 
2016-12-09 22:38:51 Training Loss = 0.43822194210382 
2016-12-09 22:38:56 Valid Error = 0.99363534256833 
2016-12-09 22:38:56 Valid Loss = 0.075254018198245 
2016-12-09 22:39:01 Test Error = 0.99292691141799 
2016-12-09 22:39:01 Test Loss = 0.075680424203545 
2016-12-09 22:39:01 -------------------LR------------------- 
2016-12-09 22:39:01 0.015625 
2016-12-09 22:39:01 Epoch 2 
2016-12-09 22:41:23 Training Error = 0.98048597819755 
2016-12-09 22:41:23 Training Loss = 0.035877536151379 
2016-12-09 22:41:28 Valid Error = 0.93934855859229 
2016-12-09 22:41:28 Valid Loss = 0.018402059682441 
2016-12-09 22:41:33 Test Error = 0.9514988211519 
2016-12-09 22:41:33 Test Loss = 0.018527469969701 
2016-12-09 22:41:33 -------------------LR------------------- 
2016-12-09 22:41:33 0.015625 
2016-12-09 22:41:33 Epoch 3 
2016-12-09 22:43:54 Training Error = 0.96567362902555 
2016-12-09 22:43:54 Training Loss = 0.017266254534032 
2016-12-09 22:43:59 Valid Error = 0.97154623736428 
2016-12-09 22:43:59 Valid Loss = 0.018205437913595 
2016-12-09 22:44:04 Test Error = 0.97238127315594 
2016-12-09 22:44:04 Test Loss = 0.020220002234322 
2016-12-09 22:44:04 -------------------LR------------------- 
2016-12-09 22:44:04 0.015625 
2016-12-09 22:44:04 Epoch 4 
2016-12-09 22:46:24 Training Error = 0.96330198884913 
2016-12-09 22:46:24 Training Loss = 0.016301149696295 
2016-12-09 22:46:29 Valid Error = 0.95394983152377 
2016-12-09 22:46:29 Valid Loss = 0.016835896952847 
2016-12-09 22:46:34 Test Error = 0.9518356348939 
2016-12-09 22:46:34 Test Loss = 0.01773113593246 
2016-12-09 22:46:34 -------------------LR------------------- 
2016-12-09 22:46:34 0.015625 
2016-12-09 22:46:34 Epoch 5 
2016-12-09 22:49:01 Training Error = 0.94749105433969 
2016-12-09 22:49:01 Training Loss = 0.016054475724831 
2016-12-09 22:49:06 Valid Error = 0.93036315986522 
2016-12-09 22:49:06 Valid Loss = 0.015756090710848 
2016-12-09 22:49:11 Test Error = 0.94173122263388 
2016-12-09 22:49:11 Test Loss = 0.015806463936401 
2016-12-09 22:49:11 -------------------LR------------------- 
2016-12-09 22:49:11 0.015625 
2016-12-09 22:49:11 Epoch 6 
2016-12-09 22:51:29 Training Error = 0.93396854456187 
2016-12-09 22:51:29 Training Loss = 0.015905155400448 
2016-12-09 22:51:34 Valid Error = 0.9341070760015 
2016-12-09 22:51:34 Valid Loss = 0.016297078947416 
2016-12-09 22:51:39 Test Error = 0.94476254631189 
2016-12-09 22:51:39 Test Loss = 0.016834095372764 
2016-12-09 22:51:39 -------------------LR------------------- 
2016-12-09 22:51:39 0.015625 
2016-12-09 22:51:39 Epoch 7 
2016-12-09 22:54:01 Training Error = 0.918324040942 
2016-12-09 22:54:01 Training Loss = 0.015795046813094 
2016-12-09 22:54:06 Valid Error = 0.91838262822913 
2016-12-09 22:54:06 Valid Loss = 0.015809113876362 
2016-12-09 22:54:11 Test Error = 0.92960592792186 
2016-12-09 22:54:11 Test Loss = 0.015855179341004 
2016-12-09 22:54:11 -------------------LR------------------- 
2016-12-09 22:54:11 0.015625 
2016-12-09 22:54:11 Epoch 8 
2016-12-09 22:56:39 Training Error = 0.90821336440043 
2016-12-09 22:56:39 Training Loss = 0.015652551880981 
2016-12-09 22:56:44 Valid Error = 0.96967427929614 
2016-12-09 22:56:44 Valid Loss = 0.016565698074898 
2016-12-09 22:56:49 Test Error = 0.96699225328393 
2016-12-09 22:56:49 Test Loss = 0.016758726488303 
2016-12-09 22:56:49 -------------------LR------------------- 
2016-12-09 22:56:49 0.015625 
2016-12-09 22:56:49 Epoch 9 
2016-12-09 22:59:12 Training Error = 0.90846301073479 
2016-12-09 22:59:12 Training Loss = 0.015453009456432 
2016-12-09 22:59:17 Valid Error = 0.91838262822913 
2016-12-09 22:59:17 Valid Loss = 0.015710544633706 
2016-12-09 22:59:23 Test Error = 0.92960592792186 
2016-12-09 22:59:23 Test Loss = 0.015821668157599 
2016-12-09 22:59:23 -------------------LR------------------- 
2016-12-09 22:59:23 0.015625 
2016-12-09 22:59:23 Epoch 10 
2016-12-09 23:02:04 Training Error = 0.90604976283598 
2016-12-09 23:02:04 Training Loss = 0.015275290513392 
2016-12-09 23:02:09 Valid Error = 0.95095469861475 
2016-12-09 23:02:09 Valid Loss = 0.016806317134272 
2016-12-09 23:02:14 Test Error = 0.9488043112159 
2016-12-09 23:02:14 Test Loss = 0.017336478457421 
2016-12-09 23:02:14 -------------------LR------------------- 
2016-12-09 23:02:14 0.015625 
2016-12-09 23:02:14 Epoch 11 
2016-12-09 23:04:57 Training Error = 0.89839394191562 
2016-12-09 23:04:57 Training Loss = 0.015185759651387 
2016-12-09 23:05:02 Valid Error = 0.95394983152377 
2016-12-09 23:05:02 Valid Loss = 0.016111678724145 
2016-12-09 23:05:07 Test Error = 0.9518356348939 
2016-12-09 23:05:07 Test Loss = 0.016072746770726 
2016-12-09 23:05:07 -------------------LR------------------- 
2016-12-09 23:05:07 0.015625 
2016-12-09 23:05:07 Epoch 12 
2016-12-09 23:07:35 Training Error = 0.8985187650828 
2016-12-09 23:07:35 Training Loss = 0.015218122805619 
2016-12-09 23:07:40 Valid Error = 0.95394983152377 
2016-12-09 23:07:40 Valid Loss = 0.01610219033448 
2016-12-09 23:07:45 Test Error = 0.9518356348939 
2016-12-09 23:07:45 Test Loss = 0.016048816169186 
2016-12-09 23:07:45 -------------------LR------------------- 
2016-12-09 23:07:45 0.015625 
2016-12-09 23:07:45 Epoch 13 
2016-12-09 23:10:32 Training Error = 0.89897645002913 
2016-12-09 23:10:32 Training Loss = 0.015206453163656 
2016-12-09 23:10:37 Valid Error = 0.95394983152377 
2016-12-09 23:10:37 Valid Loss = 0.016093915384572 
2016-12-09 23:10:43 Test Error = 0.9518356348939 
2016-12-09 23:10:43 Test Loss = 0.016047994417718 
2016-12-09 23:10:43 -------------------LR------------------- 
2016-12-09 23:10:43 0.015625 
2016-12-09 23:10:43 Epoch 14 
2016-12-09 23:13:35 Training Error = 0.89818590330365 
2016-12-09 23:13:35 Training Loss = 0.015193747398341 
2016-12-09 23:13:40 Valid Error = 0.95394983152377 
2016-12-09 23:13:40 Valid Loss = 0.016083751160176 
2016-12-09 23:13:45 Test Error = 0.9518356348939 
2016-12-09 23:13:45 Test Loss = 0.016031647133518 
2016-12-09 23:13:45 -------------------LR------------------- 
2016-12-09 23:13:45 0.015625 
2016-12-09 23:13:45 Epoch 15 
2016-12-09 23:16:34 Training Error = 0.89747857202297 
2016-12-09 23:16:34 Training Loss = 0.015184716162886 
2016-12-09 23:16:39 Valid Error = 0.95394983152377 
2016-12-09 23:16:39 Valid Loss = 0.016090152438557 
2016-12-09 23:16:45 Test Error = 0.9518356348939 
2016-12-09 23:16:45 Test Loss = 0.016035222805711 
2016-12-09 23:16:45 -------------------LR------------------- 
2016-12-09 23:16:45 0.015625 
2016-12-09 23:16:45 Epoch 16 
2016-12-09 23:19:34 Training Error = 0.89752017974536 
2016-12-09 23:19:34 Training Loss = 0.015198281078542 
2016-12-09 23:19:39 Valid Error = 0.95394983152377 
2016-12-09 23:19:39 Valid Loss = 0.016116213362112 
2016-12-09 23:19:45 Test Error = 0.9518356348939 
2016-12-09 23:19:45 Test Loss = 0.016112080784262 
2016-12-09 23:19:45 -------------------LR------------------- 
2016-12-09 23:19:45 0.015625 
2016-12-09 23:19:45 Epoch 17 
2016-12-09 23:22:36 Training Error = 0.89864358824998 
2016-12-09 23:22:36 Training Loss = 0.015203965118807 
2016-12-09 23:22:41 Valid Error = 0.95394983152377 
2016-12-09 23:22:41 Valid Loss = 0.016120087874949 
2016-12-09 23:22:47 Test Error = 0.9518356348939 
2016-12-09 23:22:47 Test Loss = 0.016051449390468 
2016-12-09 23:22:47 -------------------LR------------------- 
2016-12-09 23:22:47 0.015625 
2016-12-09 23:22:47 Epoch 18 
2016-12-09 23:25:36 Training Error = 0.89839394191562 
2016-12-09 23:25:36 Training Loss = 0.015190436499024 
2016-12-09 23:25:41 Valid Error = 0.95394983152377 
2016-12-09 23:25:41 Valid Loss = 0.016126587259828 
2016-12-09 23:25:47 Test Error = 0.9518356348939 
2016-12-09 23:25:47 Test Loss = 0.016074766682783 
2016-12-09 23:25:47 -------------------LR------------------- 
2016-12-09 23:25:47 0.015625 
2016-12-09 23:25:47 Epoch 19 
2016-12-09 23:28:39 Training Error = 0.89868519597237 
2016-12-09 23:28:39 Training Loss = 0.015189624550757 
2016-12-09 23:28:44 Valid Error = 0.95394983152377 
2016-12-09 23:28:44 Valid Loss = 0.016133285843652 
2016-12-09 23:28:49 Test Error = 0.9518356348939 
2016-12-09 23:28:49 Test Loss = 0.016086226701378 
2016-12-09 23:28:49 -------------------LR------------------- 
2016-12-09 23:28:49 0.015625 
2016-12-09 23:28:49 Epoch 20 
2016-12-09 23:31:50 Training Error = 0.89876841141716 
2016-12-09 23:31:50 Training Loss = 0.01521096826542 
2016-12-09 23:31:55 Valid Error = 0.95394983152377 
2016-12-09 23:31:55 Valid Loss = 0.016088950594543 
2016-12-09 23:32:00 Test Error = 0.9518356348939 
2016-12-09 23:32:00 Test Loss = 0.016041002329755 
2016-12-09 23:32:00 -------------------LR------------------- 
2016-12-09 23:32:00 0.015625 
2016-12-09 23:32:00 Epoch 21 
2016-12-09 23:34:50 Training Error = 0.89818590330365 
2016-12-09 23:34:50 Training Loss = 0.015208597814665 
2016-12-09 23:34:55 Valid Error = 0.95394983152377 
2016-12-09 23:34:55 Valid Loss = 0.016109521320684 
2016-12-09 23:35:01 Test Error = 0.9518356348939 
2016-12-09 23:35:01 Test Loss = 0.016062318029014 
2016-12-09 23:35:01 -------------------LR------------------- 
2016-12-09 23:35:01 0.015625 
2016-12-09 23:35:01 Epoch 22 
2016-12-09 23:37:50 Training Error = 0.89747857202297 
2016-12-09 23:37:50 Training Loss = 0.015203012955768 
2016-12-09 23:37:55 Valid Error = 0.95394983152377 
2016-12-09 23:37:55 Valid Loss = 0.016129248174583 
2016-12-09 23:38:00 Test Error = 0.9518356348939 
2016-12-09 23:38:00 Test Loss = 0.016071201551044 
2016-12-09 23:38:00 -------------------LR------------------- 
2016-12-09 23:38:00 0.015625 
2016-12-09 23:38:00 Epoch 23 
2016-12-09 23:40:50 Training Error = 0.89864358824998 
2016-12-09 23:40:50 Training Loss = 0.015198065466531 
2016-12-09 23:40:55 Valid Error = 0.95394983152377 
2016-12-09 23:40:55 Valid Loss = 0.016068559555958 
2016-12-09 23:41:00 Test Error = 0.9518356348939 
2016-12-09 23:41:00 Test Loss = 0.016009167006211 
2016-12-09 23:41:00 -------------------LR------------------- 
2016-12-09 23:41:00 0.015625 
2016-12-09 23:41:00 Epoch 24 
2016-12-09 23:43:52 Training Error = 0.89743696430057 
2016-12-09 23:43:52 Training Loss = 0.01519698150057 
2016-12-09 23:43:57 Valid Error = 0.95394983152377 
2016-12-09 23:43:57 Valid Loss = 0.016112889315343 
2016-12-09 23:44:02 Test Error = 0.9518356348939 
2016-12-09 23:44:02 Test Loss = 0.016092729038157 
2016-12-09 23:44:02 -------------------LR------------------- 
2016-12-09 23:44:02 0.015625 
2016-12-09 23:44:02 Epoch 25 
2016-12-09 23:46:53 Training Error = 0.89810268785887 
2016-12-09 23:46:53 Training Loss = 0.015203995709825 
2016-12-09 23:46:58 Valid Error = 0.95095469861475 
2016-12-09 23:46:58 Valid Loss = 0.016348392480858 
2016-12-09 23:47:04 Test Error = 0.9488043112159 
2016-12-09 23:47:04 Test Loss = 0.016638389873804 
2016-12-09 23:47:04 -------------------LR------------------- 
2016-12-09 23:47:04 0.015625 
2016-12-09 23:47:04 Epoch 26 
2016-12-09 23:49:55 Training Error = 0.89968378130981 
2016-12-09 23:49:55 Training Loss = 0.015189846830888 
2016-12-09 23:50:00 Valid Error = 0.95095469861475 
2016-12-09 23:50:00 Valid Loss = 0.016074221983252 
2016-12-09 23:50:05 Test Error = 0.9488043112159 
2016-12-09 23:50:05 Test Loss = 0.016013033293362 
2016-12-09 23:50:05 -------------------LR------------------- 
2016-12-09 23:50:05 0.015625 
2016-12-09 23:50:05 Epoch 27 
2016-12-09 23:52:54 Training Error = 0.89885162686195 
2016-12-09 23:52:54 Training Loss = 0.015186053358361 
2016-12-09 23:52:59 Valid Error = 0.95394983152377 
2016-12-09 23:52:59 Valid Loss = 0.016118327736235 
2016-12-09 23:53:05 Test Error = 0.9518356348939 
2016-12-09 23:53:05 Test Loss = 0.016082373165514 
2016-12-09 23:53:05 -------------------LR------------------- 
2016-12-09 23:53:05 0.015625 
2016-12-09 23:53:05 Epoch 28 
2016-12-09 23:56:04 Training Error = 0.89856037280519 
2016-12-09 23:56:04 Training Loss = 0.015197029775707 
2016-12-09 23:56:09 Valid Error = 0.95919131411456 
2016-12-09 23:56:09 Valid Loss = 0.016093052771635 
2016-12-09 23:56:15 Test Error = 0.95857190973392 
2016-12-09 23:56:15 Test Loss = 0.016103653351467 
2016-12-09 23:56:15 -------------------LR------------------- 
2016-12-09 23:56:15 0.015625 
2016-12-09 23:56:15 Epoch 29 
2016-12-09 23:59:22 Training Error = 0.8985187650828 
2016-12-09 23:59:22 Training Loss = 0.015205244733846 
2016-12-09 23:59:27 Valid Error = 0.95394983152377 
2016-12-09 23:59:27 Valid Loss = 0.016113998025081 
2016-12-09 23:59:32 Test Error = 0.9518356348939 
2016-12-09 23:59:32 Test Loss = 0.0160659571907 
2016-12-09 23:59:32 -------------------LR------------------- 
2016-12-09 23:59:32 0.015625 
2016-12-09 23:59:32 Epoch 30 
2016-12-10 00:02:42 Training Error = 0.89935091953066 
2016-12-10 00:02:42 Training Loss = 0.015205628173199 
2016-12-10 00:02:47 Valid Error = 0.95394983152377 
2016-12-10 00:02:47 Valid Loss = 0.016134361190442 
2016-12-10 00:02:52 Test Error = 0.9518356348939 
2016-12-10 00:02:52 Test Loss = 0.016105104770063 
2016-12-10 00:02:52 -------------------LR------------------- 
2016-12-10 00:02:52 0.015625 
2016-12-10 00:02:52 Epoch 31 
2016-12-10 00:05:47 Training Error = 0.89885162686195 
2016-12-10 00:05:47 Training Loss = 0.015197426289407 
2016-12-10 00:05:52 Valid Error = 0.95919131411456 
2016-12-10 00:05:52 Valid Loss = 0.01610768875503 
2016-12-10 00:05:57 Test Error = 0.95857190973392 
2016-12-10 00:05:57 Test Loss = 0.016059122010708 
2016-12-10 00:05:57 -------------------LR------------------- 
2016-12-10 00:05:57 0.015625 
2016-12-10 00:05:57 Epoch 32 
2016-12-10 00:08:43 Training Error = 0.89847715736041 
2016-12-10 00:08:43 Training Loss = 0.015195142628216 
2016-12-10 00:08:48 Valid Error = 0.94721078247847 
2016-12-10 00:08:48 Valid Loss = 0.016041107356587 
2016-12-10 00:08:54 Test Error = 0.94577298753789 
2016-12-10 00:08:54 Test Loss = 0.01598481912571 
2016-12-10 00:08:54 -------------------LR------------------- 
2016-12-10 00:08:54 0.015625 
2016-12-10 00:08:54 Epoch 33 
2016-12-10 00:11:42 Training Error = 0.89735374885579 
2016-12-10 00:11:42 Training Loss = 0.015201313150379 
2016-12-10 00:11:47 Valid Error = 0.95394983152377 
2016-12-10 00:11:47 Valid Loss = 0.01613069173461 
2016-12-10 00:11:52 Test Error = 0.9518356348939 
2016-12-10 00:11:52 Test Loss = 0.016075595842051 
2016-12-10 00:11:52 -------------------LR------------------- 
2016-12-10 00:11:52 0.015625 
2016-12-10 00:11:52 Epoch 34 
2016-12-10 00:14:39 Training Error = 0.89722892568861 
2016-12-10 00:14:39 Training Loss = 0.015205203336864 
2016-12-10 00:14:44 Valid Error = 0.95394983152377 
2016-12-10 00:14:44 Valid Loss = 0.016108165227256 
2016-12-10 00:14:49 Test Error = 0.9518356348939 
2016-12-10 00:14:49 Test Loss = 0.01607289421904 
2016-12-10 00:14:49 -------------------LR------------------- 
2016-12-10 00:14:49 0.015625 
2016-12-10 00:14:49 Epoch 35 
2016-12-10 00:17:37 Training Error = 0.89847715736041 
2016-12-10 00:17:37 Training Loss = 0.015191348697667 
2016-12-10 00:17:42 Valid Error = 0.95394983152377 
2016-12-10 00:17:42 Valid Loss = 0.016091697805462 
2016-12-10 00:17:48 Test Error = 0.9518356348939 
2016-12-10 00:17:48 Test Loss = 0.016059555263182 
2016-12-10 00:17:48 -------------------LR------------------- 
2016-12-10 00:17:48 0.015625 
2016-12-10 00:17:48 Epoch 36 
2016-12-10 00:20:35 Training Error = 0.89872680369477 
2016-12-10 00:20:35 Training Loss = 0.015179179792639 
2016-12-10 00:20:40 Valid Error = 0.95919131411456 
2016-12-10 00:20:40 Valid Loss = 0.016059237297352 
2016-12-10 00:20:45 Test Error = 0.95857190973392 
2016-12-10 00:20:45 Test Loss = 0.016043957922013 
2016-12-10 00:20:45 -------------------LR------------------- 
2016-12-10 00:20:45 0.015625 
2016-12-10 00:20:45 Epoch 37 
2016-12-10 00:23:31 Training Error = 0.89868519597237 
2016-12-10 00:23:31 Training Loss = 0.015197171321959 
2016-12-10 00:23:36 Valid Error = 0.95394983152377 
2016-12-10 00:23:36 Valid Loss = 0.016134084061094 
2016-12-10 00:23:42 Test Error = 0.9518356348939 
2016-12-10 00:23:42 Test Loss = 0.016112857441166 
2016-12-10 00:23:42 -------------------LR------------------- 
2016-12-10 00:23:42 0.015625 
2016-12-10 00:23:42 Epoch 38 
2016-12-10 00:26:28 Training Error = 0.89881001913955 
2016-12-10 00:26:28 Training Loss = 0.015185366089192 
2016-12-10 00:26:33 Valid Error = 0.95394983152377 
2016-12-10 00:26:33 Valid Loss = 0.016152575185946 
2016-12-10 00:26:39 Test Error = 0.9518356348939 
2016-12-10 00:26:39 Test Loss = 0.016110538330048 
2016-12-10 00:26:39 -------------------LR------------------- 
2016-12-10 00:26:39 0.015625 
2016-12-10 00:26:39 Epoch 39 
2016-12-10 00:29:28 Training Error = 0.89910127319631 
2016-12-10 00:29:28 Training Loss = 0.015179887462773 
2016-12-10 00:29:33 Valid Error = 0.95394983152377 
2016-12-10 00:29:33 Valid Loss = 0.016079724806181 
2016-12-10 00:29:38 Test Error = 0.9518356348939 
2016-12-10 00:29:38 Test Loss = 0.016077493338556 
2016-12-10 00:29:38 -------------------LR------------------- 
2016-12-10 00:29:38 0.015625 
2016-12-10 00:29:38 Epoch 40 
2016-12-10 00:32:35 Training Error = 0.89810268785887 
2016-12-10 00:32:35 Training Loss = 0.01518849662567 
2016-12-10 00:32:40 Valid Error = 0.95095469861475 
2016-12-10 00:32:40 Valid Loss = 0.016349183460447 
2016-12-10 00:32:45 Test Error = 0.9488043112159 
2016-12-10 00:32:45 Test Loss = 0.016493541302683 
2016-12-10 00:32:45 -------------------LR------------------- 
2016-12-10 00:32:45 0.015625 
2016-12-10 00:32:46 Epoch 41 
2016-12-10 00:35:33 Training Error = 0.89930931180827 
2016-12-10 00:35:33 Training Loss = 0.015178925449504 
2016-12-10 00:35:38 Valid Error = 0.95394983152377 
2016-12-10 00:35:38 Valid Loss = 0.016129125082021 
2016-12-10 00:35:43 Test Error = 0.9518356348939 
2016-12-10 00:35:43 Test Loss = 0.016066024319436 
2016-12-10 00:35:43 -------------------LR------------------- 
2016-12-10 00:35:43 0.015625 
2016-12-10 00:35:43 Epoch 42 
2016-12-10 00:38:30 Training Error = 0.89797786469169 
2016-12-10 00:38:30 Training Loss = 0.015194834811492 
2016-12-10 00:38:35 Valid Error = 0.95095469861475 
2016-12-10 00:38:35 Valid Loss = 0.016098747729684 
2016-12-10 00:38:41 Test Error = 0.9488043112159 
2016-12-10 00:38:41 Test Loss = 0.016038544779746 
2016-12-10 00:38:41 -------------------LR------------------- 
2016-12-10 00:38:41 0.015625 
2016-12-10 00:38:41 Epoch 43 
2016-12-10 00:41:26 Training Error = 0.8997253890322 
2016-12-10 00:41:26 Training Loss = 0.015188793503456 
2016-12-10 00:41:31 Valid Error = 0.95919131411456 
2016-12-10 00:41:31 Valid Loss = 0.016084608810705 
2016-12-10 00:41:37 Test Error = 0.95857190973392 
2016-12-10 00:41:37 Test Loss = 0.01606326510624 
2016-12-10 00:41:37 -------------------LR------------------- 
2016-12-10 00:41:37 0.015625 
2016-12-10 00:41:37 Epoch 44 
2016-12-10 00:44:26 Training Error = 0.89839394191562 
2016-12-10 00:44:26 Training Loss = 0.015205142234786 
2016-12-10 00:44:31 Valid Error = 0.95394983152377 
2016-12-10 00:44:31 Valid Loss = 0.016159764845931 
2016-12-10 00:44:36 Test Error = 0.9518356348939 
2016-12-10 00:44:36 Test Loss = 0.01614726660021 
2016-12-10 00:44:36 -------------------LR------------------- 
2016-12-10 00:44:36 0.015625 
2016-12-10 00:44:36 Epoch 45 
2016-12-10 00:47:25 Training Error = 0.89856037280519 
2016-12-10 00:47:25 Training Loss = 0.015193173622794 
2016-12-10 00:47:30 Valid Error = 0.95394983152377 
2016-12-10 00:47:30 Valid Loss = 0.016125372211296 
2016-12-10 00:47:36 Test Error = 0.9518356348939 
2016-12-10 00:47:36 Test Loss = 0.016099112440837 
2016-12-10 00:47:36 -------------------LR------------------- 
2016-12-10 00:47:36 0.015625 
2016-12-10 00:47:36 Epoch 46 
2016-12-10 00:50:22 Training Error = 0.89826911874844 
2016-12-10 00:50:22 Training Loss = 0.015178410830382 
2016-12-10 00:50:27 Valid Error = 0.95394983152377 
2016-12-10 00:50:27 Valid Loss = 0.016102187587982 
2016-12-10 00:50:33 Test Error = 0.9518356348939 
2016-12-10 00:50:33 Test Loss = 0.016076406105142 
2016-12-10 00:50:33 -------------------LR------------------- 
2016-12-10 00:50:33 0.015625 
2016-12-10 00:50:33 Epoch 47 
2016-12-10 00:53:20 Training Error = 0.89835233419323 
2016-12-10 00:53:20 Training Loss = 0.015173777869735 
2016-12-10 00:53:25 Valid Error = 0.95919131411456 
2016-12-10 00:53:25 Valid Loss = 0.016116677475751 
2016-12-10 00:53:30 Test Error = 0.95857190973392 
2016-12-10 00:53:30 Test Loss = 0.016076169929326 
2016-12-10 00:53:30 -------------------LR------------------- 
2016-12-10 00:53:30 0.015625 
2016-12-10 00:53:30 Epoch 48 
2016-12-10 00:56:18 Training Error = 0.89814429558126 
2016-12-10 00:56:18 Training Loss = 0.015179957330718 
2016-12-10 00:56:23 Valid Error = 0.95394983152377 
2016-12-10 00:56:23 Valid Loss = 0.016077975595885 
2016-12-10 00:56:28 Test Error = 0.9518356348939 
2016-12-10 00:56:28 Test Loss = 0.016047120370315 
2016-12-10 00:56:28 -------------------LR------------------- 
2016-12-10 00:56:28 0.015625 
2016-12-10 00:56:28 Epoch 49 
2016-12-10 00:59:15 Training Error = 0.89881001913955 
2016-12-10 00:59:15 Training Loss = 0.015218786518944 
2016-12-10 00:59:20 Valid Error = 0.95095469861475 
2016-12-10 00:59:20 Valid Loss = 0.016066780453455 
2016-12-10 00:59:26 Test Error = 0.9488043112159 
2016-12-10 00:59:26 Test Loss = 0.016025407386274 
2016-12-10 00:59:26 -------------------LR------------------- 
2016-12-10 00:59:26 0.015625 
2016-12-10 00:59:26 Epoch 50 
2016-12-10 01:02:22 Training Error = 0.89847715736041 
2016-12-10 01:02:22 Training Loss = 0.015183699217079 
2016-12-10 01:02:27 Valid Error = 0.95095469861475 
2016-12-10 01:02:27 Valid Loss = 0.016050710452117 
2016-12-10 01:02:32 Test Error = 0.9488043112159 
2016-12-10 01:02:32 Test Loss = 0.015986868114922 
2016-12-10 01:02:32 -------------------LR------------------- 
2016-12-10 01:02:32 0.0078125 
2016-12-10 01:02:33 Epoch 51 
2016-12-10 01:05:17 Training Error = 0.89856037280519 
2016-12-10 01:05:17 Training Loss = 0.015212302706387 
2016-12-10 01:05:22 Valid Error = 0.95394983152377 
2016-12-10 01:05:22 Valid Loss = 0.016113893384038 
2016-12-10 01:05:27 Test Error = 0.9518356348939 
2016-12-10 01:05:27 Test Loss = 0.016065970178671 
2016-12-10 01:05:27 -------------------LR------------------- 
2016-12-10 01:05:27 0.0078125 
2016-12-10 01:05:27 Epoch 52 
2016-12-10 01:08:07 Training Error = 0.89831072647083 
2016-12-10 01:08:07 Training Loss = 0.015191719274735 
2016-12-10 01:08:12 Valid Error = 0.95394983152377 
2016-12-10 01:08:12 Valid Loss = 0.016096590981771 
2016-12-10 01:08:17 Test Error = 0.9518356348939 
2016-12-10 01:08:17 Test Loss = 0.016067174566603 
2016-12-10 01:08:17 -------------------LR------------------- 
2016-12-10 01:08:17 0.0078125 
2016-12-10 01:08:17 Epoch 53 
2016-12-10 01:10:58 Training Error = 0.89785304152451 
2016-12-10 01:10:58 Training Loss = 0.015192192959243 
2016-12-10 01:11:03 Valid Error = 0.95394983152377 
2016-12-10 01:11:03 Valid Loss = 0.016137135101533 
2016-12-10 01:11:08 Test Error = 0.9518356348939 
2016-12-10 01:11:08 Test Loss = 0.01607847253009 
2016-12-10 01:11:08 -------------------LR------------------- 
2016-12-10 01:11:08 0.0078125 
2016-12-10 01:11:08 Epoch 54 
2016-12-10 01:13:51 Training Error = 0.89826911874844 
2016-12-10 01:13:51 Training Loss = 0.015192081322045 
2016-12-10 01:13:56 Valid Error = 0.95394983152377 
2016-12-10 01:13:56 Valid Loss = 0.016099898579648 
2016-12-10 01:14:01 Test Error = 0.9518356348939 
2016-12-10 01:14:01 Test Loss = 0.016046736052148 
2016-12-10 01:14:01 -------------------LR------------------- 
2016-12-10 01:14:01 0.0078125 
2016-12-10 01:14:01 Epoch 55 
2016-12-10 01:16:43 Training Error = 0.89860198052759 
2016-12-10 01:16:43 Training Loss = 0.015205107662074 
2016-12-10 01:16:48 Valid Error = 0.94721078247847 
2016-12-10 01:16:48 Valid Loss = 0.016039565103863 
2016-12-10 01:16:53 Test Error = 0.94577298753789 
2016-12-10 01:16:53 Test Loss = 0.015982222021011 
2016-12-10 01:16:53 -------------------LR------------------- 
2016-12-10 01:16:53 0.0078125 
2016-12-10 01:16:53 Epoch 56 
2016-12-10 01:19:34 Training Error = 0.89905966547391 
2016-12-10 01:19:34 Training Loss = 0.015196057147969 
2016-12-10 01:19:39 Valid Error = 0.94721078247847 
2016-12-10 01:19:39 Valid Loss = 0.016325363548248 
2016-12-10 01:19:44 Test Error = 0.94509936005389 
2016-12-10 01:19:44 Test Loss = 0.016334027444403 
2016-12-10 01:19:44 -------------------LR------------------- 
2016-12-10 01:19:44 0.0078125 
2016-12-10 01:19:44 Epoch 57 
2016-12-10 01:22:25 Training Error = 0.89806108013647 
2016-12-10 01:22:25 Training Loss = 0.015191375728511 
2016-12-10 01:22:30 Valid Error = 0.95919131411456 
2016-12-10 01:22:30 Valid Loss = 0.01611210137208 
2016-12-10 01:22:35 Test Error = 0.95857190973392 
2016-12-10 01:22:35 Test Loss = 0.016082495604199 
2016-12-10 01:22:35 -------------------LR------------------- 
2016-12-10 01:22:35 0.0078125 
2016-12-10 01:22:35 Epoch 58 
2016-12-10 01:25:16 Training Error = 0.89960056586502 
2016-12-10 01:25:16 Training Loss = 0.015193739045302 
2016-12-10 01:25:20 Valid Error = 0.95394983152377 
2016-12-10 01:25:20 Valid Loss = 0.016099713249274 
2016-12-10 01:25:26 Test Error = 0.9518356348939 
2016-12-10 01:25:26 Test Loss = 0.016037333239087 
2016-12-10 01:25:26 -------------------LR------------------- 
2016-12-10 01:25:26 0.0078125 
2016-12-10 01:25:26 Epoch 59 
2016-12-10 01:28:05 Training Error = 0.89685445618707 
2016-12-10 01:28:05 Training Loss = 0.015193889703618 
2016-12-10 01:28:10 Valid Error = 0.95394983152377 
2016-12-10 01:28:10 Valid Loss = 0.016121622114547 
2016-12-10 01:28:15 Test Error = 0.9518356348939 
2016-12-10 01:28:15 Test Loss = 0.016073609161284 
2016-12-10 01:28:15 -------------------LR------------------- 
2016-12-10 01:28:15 0.0078125 
2016-12-10 01:28:15 Epoch 60 
2016-12-10 01:31:06 Training Error = 0.89881001913955 
2016-12-10 01:31:06 Training Loss = 0.015193659221094 
2016-12-10 01:31:11 Valid Error = 0.95394983152377 
2016-12-10 01:31:11 Valid Loss = 0.01613534447787 
2016-12-10 01:31:16 Test Error = 0.9518356348939 
2016-12-10 01:31:16 Test Loss = 0.016082564290068 
2016-12-10 01:31:16 -------------------LR------------------- 
2016-12-10 01:31:16 0.0078125 
2016-12-10 01:31:16 Epoch 61 
2016-12-10 01:34:13 Training Error = 0.89872680369477 
2016-12-10 01:34:13 Training Loss = 0.015178660347626 
2016-12-10 01:34:18 Valid Error = 0.95095469861475 
2016-12-10 01:34:18 Valid Loss = 0.016095581574481 
2016-12-10 01:34:23 Test Error = 0.9488043112159 
2016-12-10 01:34:23 Test Loss = 0.016037424718413 
2016-12-10 01:34:23 -------------------LR------------------- 
2016-12-10 01:34:23 0.0078125 
2016-12-10 01:34:23 Epoch 62 
2016-12-10 01:37:01 Training Error = 0.89856037280519 
2016-12-10 01:37:01 Training Loss = 0.015186794101118 
2016-12-10 01:37:06 Valid Error = 0.95394983152377 
2016-12-10 01:37:06 Valid Loss = 0.016101905546603 
2016-12-10 01:37:12 Test Error = 0.9518356348939 
2016-12-10 01:37:12 Test Loss = 0.016049838810953 
2016-12-10 01:37:12 -------------------LR------------------- 
2016-12-10 01:37:12 0.0078125 
2016-12-10 01:37:12 Epoch 63 
2016-12-10 01:39:51 Training Error = 0.89922609636349 
2016-12-10 01:39:51 Training Loss = 0.015202424416609 
2016-12-10 01:39:56 Valid Error = 0.95394983152377 
2016-12-10 01:39:56 Valid Loss = 0.016126520526736 
2016-12-10 01:40:01 Test Error = 0.9518356348939 
2016-12-10 01:40:01 Test Loss = 0.016084887952758 
2016-12-10 01:40:01 -------------------LR------------------- 
2016-12-10 01:40:01 0.0078125 
2016-12-10 01:40:01 Epoch 64 
2016-12-10 01:42:40 Training Error = 0.89793625696929 
2016-12-10 01:42:40 Training Loss = 0.015194309087721 
2016-12-10 01:42:45 Valid Error = 0.95394983152377 
2016-12-10 01:42:45 Valid Loss = 0.016087556154169 
2016-12-10 01:42:50 Test Error = 0.9518356348939 
2016-12-10 01:42:50 Test Loss = 0.016019950739793 
2016-12-10 01:42:50 -------------------LR------------------- 
2016-12-10 01:42:50 0.0078125 
2016-12-10 01:42:50 Epoch 65 
2016-12-10 01:45:29 Training Error = 0.8997669967546 
2016-12-10 01:45:29 Training Loss = 0.01519157139584 
2016-12-10 01:45:34 Valid Error = 0.95394983152377 
2016-12-10 01:45:34 Valid Loss = 0.016121225668254 
2016-12-10 01:45:39 Test Error = 0.9518356348939 
2016-12-10 01:45:39 Test Loss = 0.01609318930644 
2016-12-10 01:45:39 -------------------LR------------------- 
2016-12-10 01:45:39 0.0078125 
2016-12-10 01:45:39 Epoch 66 
2016-12-10 01:48:18 Training Error = 0.89735374885579 
2016-12-10 01:48:18 Training Loss = 0.015190529316751 
2016-12-10 01:48:23 Valid Error = 0.95394983152377 
2016-12-10 01:48:23 Valid Loss = 0.016113848946777 
2016-12-10 01:48:28 Test Error = 0.9518356348939 
2016-12-10 01:48:28 Test Loss = 0.016071840019976 
2016-12-10 01:48:28 -------------------LR------------------- 
2016-12-10 01:48:28 0.0078125 
2016-12-10 01:48:28 Epoch 67 
2016-12-10 01:51:09 Training Error = 0.8985187650828 
2016-12-10 01:51:09 Training Loss = 0.015217269655051 
2016-12-10 01:51:14 Valid Error = 0.94346686634219 
2016-12-10 01:51:14 Valid Loss = 0.016062517317722 
2016-12-10 01:51:20 Test Error = 0.94206803637588 
2016-12-10 01:51:20 Test Loss = 0.016002356069441 
2016-12-10 01:51:20 -------------------LR------------------- 
2016-12-10 01:51:20 0.0078125 
2016-12-10 01:51:20 Epoch 68 
2016-12-10 01:53:58 Training Error = 0.89760339519015 
2016-12-10 01:53:58 Training Loss = 0.01518963944126 
2016-12-10 01:54:03 Valid Error = 0.95394983152377 
2016-12-10 01:54:03 Valid Loss = 0.016109402794715 
2016-12-10 01:54:08 Test Error = 0.9518356348939 
2016-12-10 01:54:08 Test Loss = 0.016063253221017 
2016-12-10 01:54:08 -------------------LR------------------- 
2016-12-10 01:54:08 0.0078125 
2016-12-10 01:54:08 Epoch 69 
2016-12-10 01:57:01 Training Error = 0.89810268785887 
2016-12-10 01:57:01 Training Loss = 0.015198144461315 
2016-12-10 01:57:05 Valid Error = 0.95394983152377 
2016-12-10 01:57:05 Valid Loss = 0.01613879167412 
2016-12-10 01:57:11 Test Error = 0.9518356348939 
2016-12-10 01:57:11 Test Loss = 0.01609161415837 
2016-12-10 01:57:11 -------------------LR------------------- 
2016-12-10 01:57:11 0.0078125 
2016-12-10 01:57:11 Epoch 70 
2016-12-10 02:00:16 Training Error = 0.89756178746775 
2016-12-10 02:00:16 Training Loss = 0.015209975750941 
2016-12-10 02:00:21 Valid Error = 0.95394983152377 
2016-12-10 02:00:21 Valid Loss = 0.016093513341259 
2016-12-10 02:00:26 Test Error = 0.9518356348939 
2016-12-10 02:00:26 Test Loss = 0.016067688438218 
2016-12-10 02:00:26 -------------------LR------------------- 
2016-12-10 02:00:26 0.0078125 
2016-12-10 02:00:26 Epoch 71 
2016-12-10 02:03:16 Training Error = 0.89831072647083 
2016-12-10 02:03:16 Training Loss = 0.015210967779296 
2016-12-10 02:03:21 Valid Error = 0.95394983152377 
2016-12-10 02:03:21 Valid Loss = 0.016136971289753 
2016-12-10 02:03:26 Test Error = 0.9518356348939 
2016-12-10 02:03:26 Test Loss = 0.01607438405581 
2016-12-10 02:03:26 -------------------LR------------------- 
2016-12-10 02:03:26 0.0078125 
2016-12-10 02:03:26 Epoch 72 
2016-12-10 02:06:13 Training Error = 0.90005825081135 
2016-12-10 02:06:13 Training Loss = 0.015214672518055 
2016-12-10 02:06:18 Valid Error = 0.95394983152377 
2016-12-10 02:06:18 Valid Loss = 0.016120609316333 
2016-12-10 02:06:23 Test Error = 0.9518356348939 
2016-12-10 02:06:23 Test Loss = 0.016129783357094 
2016-12-10 02:06:23 -------------------LR------------------- 
2016-12-10 02:06:23 0.0078125 
2016-12-10 02:06:23 Epoch 73 
2016-12-10 02:09:07 Training Error = 0.89793625696929 
2016-12-10 02:09:07 Training Loss = 0.015196990905814 
2016-12-10 02:09:12 Valid Error = 0.95394983152377 
2016-12-10 02:09:12 Valid Loss = 0.016138028128105 
2016-12-10 02:09:17 Test Error = 0.9518356348939 
2016-12-10 02:09:17 Test Loss = 0.016110322236203 
2016-12-10 02:09:17 -------------------LR------------------- 
2016-12-10 02:09:17 0.0078125 
2016-12-10 02:09:17 Epoch 74 
2016-12-10 02:12:02 Training Error = 0.89901805775152 
2016-12-10 02:12:02 Training Loss = 0.015184371419315 
2016-12-10 02:12:06 Valid Error = 0.95394983152377 
2016-12-10 02:12:06 Valid Loss = 0.016115019524681 
2016-12-10 02:12:12 Test Error = 0.9518356348939 
2016-12-10 02:12:12 Test Loss = 0.016109161676368 
2016-12-10 02:12:12 -------------------LR------------------- 
2016-12-10 02:12:12 0.0078125 
2016-12-10 02:12:12 Epoch 75 
2016-12-10 02:14:54 Training Error = 0.89885162686195 
2016-12-10 02:14:54 Training Loss = 0.015180033101386 
2016-12-10 02:14:59 Valid Error = 0.95394983152377 
2016-12-10 02:14:59 Valid Loss = 0.0161095871084 
2016-12-10 02:15:05 Test Error = 0.9518356348939 
2016-12-10 02:15:05 Test Loss = 0.016059680892062 
2016-12-10 02:15:05 -------------------LR------------------- 
2016-12-10 02:15:05 0.0078125 
2016-12-10 02:15:05 Epoch 76 
2016-12-10 02:17:47 Training Error = 0.89822751102605 
2016-12-10 02:17:47 Training Loss = 0.015192660039944 
2016-12-10 02:17:52 Valid Error = 0.95394983152377 
2016-12-10 02:17:52 Valid Loss = 0.016118350946039 
2016-12-10 02:17:58 Test Error = 0.9518356348939 
2016-12-10 02:17:58 Test Loss = 0.016073045554551 
2016-12-10 02:17:58 -------------------LR------------------- 
2016-12-10 02:17:58 0.0078125 
2016-12-10 02:17:58 Epoch 77 
2016-12-10 02:20:41 Training Error = 0.89814429558126 
2016-12-10 02:20:41 Training Loss = 0.015198061044487 
2016-12-10 02:20:46 Valid Error = 0.95095469861475 
2016-12-10 02:20:46 Valid Loss = 0.0163307977964 
2016-12-10 02:20:52 Test Error = 0.9488043112159 
2016-12-10 02:20:52 Test Loss = 0.01639577278074 
2016-12-10 02:20:52 -------------------LR------------------- 
2016-12-10 02:20:52 0.0078125 
2016-12-10 02:20:52 Epoch 78 
2016-12-10 02:23:34 Training Error = 0.89806108013647 
2016-12-10 02:23:34 Training Loss = 0.015192003521711 
2016-12-10 02:23:39 Valid Error = 0.95394983152377 
2016-12-10 02:23:39 Valid Loss = 0.016125084122781 
2016-12-10 02:23:45 Test Error = 0.9518356348939 
2016-12-10 02:23:45 Test Loss = 0.01606443561215 
2016-12-10 02:23:45 -------------------LR------------------- 
2016-12-10 02:23:45 0.0078125 
2016-12-10 02:23:45 Epoch 79 
2016-12-10 02:26:27 Training Error = 0.89810268785887 
2016-12-10 02:26:27 Training Loss = 0.015184301099431 
2016-12-10 02:26:32 Valid Error = 0.95394983152377 
2016-12-10 02:26:32 Valid Loss = 0.016053889389853 
2016-12-10 02:26:38 Test Error = 0.9518356348939 
2016-12-10 02:26:38 Test Loss = 0.015991034031199 
2016-12-10 02:26:38 -------------------LR------------------- 
2016-12-10 02:26:38 0.0078125 
2016-12-10 02:26:38 Epoch 80 
2016-12-10 02:29:32 Training Error = 0.89901805775152 
2016-12-10 02:29:32 Training Loss = 0.015184241657358 
2016-12-10 02:29:37 Valid Error = 0.95394983152377 
2016-12-10 02:29:37 Valid Loss = 0.016157688155354 
2016-12-10 02:29:42 Test Error = 0.9518356348939 
2016-12-10 02:29:42 Test Loss = 0.016100941650693 
2016-12-10 02:29:42 -------------------LR------------------- 
2016-12-10 02:29:42 0.0078125 
2016-12-10 02:29:42 Epoch 81 
2016-12-10 02:32:23 Training Error = 0.89822751102605 
2016-12-10 02:32:23 Training Loss = 0.015199025744182 
2016-12-10 02:32:28 Valid Error = 0.95394983152377 
2016-12-10 02:32:28 Valid Loss = 0.016116881262879 
2016-12-10 02:32:33 Test Error = 0.9518356348939 
2016-12-10 02:32:33 Test Loss = 0.016063796496044 
2016-12-10 02:32:33 -------------------LR------------------- 
2016-12-10 02:32:33 0.0078125 
2016-12-10 02:32:33 Epoch 82 
2016-12-10 02:35:16 Training Error = 0.89839394191562 
2016-12-10 02:35:16 Training Loss = 0.015195540729495 
2016-12-10 02:35:21 Valid Error = 0.95394983152377 
2016-12-10 02:35:21 Valid Loss = 0.016121355253489 
2016-12-10 02:35:26 Test Error = 0.9518356348939 
2016-12-10 02:35:26 Test Loss = 0.016080915383138 
2016-12-10 02:35:26 -------------------LR------------------- 
2016-12-10 02:35:26 0.0078125 
2016-12-10 02:35:26 Epoch 83 
2016-12-10 02:38:09 Training Error = 0.89872680369477 
2016-12-10 02:38:09 Training Loss = 0.015192539696848 
2016-12-10 02:38:14 Valid Error = 0.95919131411456 
2016-12-10 02:38:14 Valid Loss = 0.016111822206738 
2016-12-10 02:38:19 Test Error = 0.95857190973392 
2016-12-10 02:38:19 Test Loss = 0.016088738888656 
2016-12-10 02:38:19 -------------------LR------------------- 
2016-12-10 02:38:19 0.0078125 
2016-12-10 02:38:19 Epoch 84 
2016-12-10 02:41:04 Training Error = 0.89918448864109 
2016-12-10 02:41:04 Training Loss = 0.015202383459687 
2016-12-10 02:41:09 Valid Error = 0.95394983152377 
2016-12-10 02:41:09 Valid Loss = 0.016091971366587 
2016-12-10 02:41:14 Test Error = 0.9518356348939 
2016-12-10 02:41:14 Test Loss = 0.016020771149458 
2016-12-10 02:41:14 -------------------LR------------------- 
2016-12-10 02:41:14 0.0078125 
2016-12-10 02:41:14 Epoch 85 
2016-12-10 02:43:55 Training Error = 0.89943413497545 
2016-12-10 02:43:55 Training Loss = 0.015192424345353 
2016-12-10 02:44:00 Valid Error = 0.95394983152377 
2016-12-10 02:44:00 Valid Loss = 0.016103702641349 
2016-12-10 02:44:05 Test Error = 0.9518356348939 
2016-12-10 02:44:05 Test Loss = 0.016060689592003 
2016-12-10 02:44:05 -------------------LR------------------- 
2016-12-10 02:44:05 0.0078125 
2016-12-10 02:44:05 Epoch 86 
2016-12-10 02:46:48 Training Error = 0.90022468170092 
2016-12-10 02:46:48 Training Loss = 0.01519596011128 
2016-12-10 02:46:53 Valid Error = 0.95394983152377 
2016-12-10 02:46:53 Valid Loss = 0.016121806493002 
2016-12-10 02:46:58 Test Error = 0.9518356348939 
2016-12-10 02:46:58 Test Loss = 0.016093271376532 
2016-12-10 02:46:58 -------------------LR------------------- 
2016-12-10 02:46:58 0.0078125 
2016-12-10 02:46:58 Epoch 87 
2016-12-10 02:49:40 Training Error = 0.89818590330365 
2016-12-10 02:49:40 Training Loss = 0.015208258023875 
2016-12-10 02:49:45 Valid Error = 0.95394983152377 
2016-12-10 02:49:45 Valid Loss = 0.016103394757507 
2016-12-10 02:49:51 Test Error = 0.9518356348939 
2016-12-10 02:49:51 Test Loss = 0.016078176011077 
2016-12-10 02:49:51 -------------------LR------------------- 
2016-12-10 02:49:51 0.0078125 
2016-12-10 02:49:51 Epoch 88 
2016-12-10 02:52:35 Training Error = 0.89697927935425 
2016-12-10 02:52:35 Training Loss = 0.015182111581653 
2016-12-10 02:52:40 Valid Error = 0.95095469861475 
2016-12-10 02:52:40 Valid Loss = 0.016348705972842 
2016-12-10 02:52:45 Test Error = 0.9488043112159 
2016-12-10 02:52:45 Test Loss = 0.016338609186317 
2016-12-10 02:52:45 -------------------LR------------------- 
2016-12-10 02:52:45 0.0078125 
2016-12-10 02:52:45 Epoch 89 
2016-12-10 02:55:22 Training Error = 0.89985021219938 
2016-12-10 02:55:22 Training Loss = 0.015194579956449 
2016-12-10 02:55:27 Valid Error = 0.95394983152377 
2016-12-10 02:55:27 Valid Loss = 0.01611736120192 
2016-12-10 02:55:33 Test Error = 0.9518356348939 
2016-12-10 02:55:33 Test Loss = 0.016055235242961 
2016-12-10 02:55:33 -------------------LR------------------- 
2016-12-10 02:55:33 0.0078125 
2016-12-10 02:55:33 Epoch 90 
2016-12-10 02:58:19 Training Error = 0.89868519597237 
2016-12-10 02:58:19 Training Loss = 0.015193807945636 
2016-12-10 02:58:24 Valid Error = 0.95394983152377 
2016-12-10 02:58:24 Valid Loss = 0.016079861737873 
2016-12-10 02:58:29 Test Error = 0.9518356348939 
2016-12-10 02:58:29 Test Loss = 0.016056311414503 
2016-12-10 02:58:29 -------------------LR------------------- 
2016-12-10 02:58:29 0.0078125 
2016-12-10 02:58:30 Epoch 91 
2016-12-10 03:01:07 Training Error = 0.89835233419323 
2016-12-10 03:01:07 Training Loss = 0.015193182025083 
2016-12-10 03:01:12 Valid Error = 0.95394983152377 
2016-12-10 03:01:12 Valid Loss = 0.016060816192073 
2016-12-10 03:01:18 Test Error = 0.9518356348939 
2016-12-10 03:01:18 Test Loss = 0.01601206759164 
2016-12-10 03:01:18 -------------------LR------------------- 
2016-12-10 03:01:18 0.0078125 
2016-12-10 03:01:18 Epoch 92 
2016-12-10 03:03:56 Training Error = 0.8985187650828 
2016-12-10 03:03:56 Training Loss = 0.015207596927737 
2016-12-10 03:04:01 Valid Error = 0.95095469861475 
2016-12-10 03:04:01 Valid Loss = 0.016135282735972 
2016-12-10 03:04:07 Test Error = 0.9488043112159 
2016-12-10 03:04:07 Test Loss = 0.016125838937469 
2016-12-10 03:04:07 -------------------LR------------------- 
2016-12-10 03:04:07 0.0078125 
2016-12-10 03:04:07 Epoch 93 
2016-12-10 03:06:43 Training Error = 0.89989181992178 
2016-12-10 03:06:43 Training Loss = 0.015216287468814 
2016-12-10 03:06:48 Valid Error = 0.95095469861475 
2016-12-10 03:06:48 Valid Loss = 0.016251383156703 
2016-12-10 03:06:53 Test Error = 0.9488043112159 
2016-12-10 03:06:53 Test Loss = 0.016331976387911 
2016-12-10 03:06:53 -------------------LR------------------- 
2016-12-10 03:06:53 0.0078125 
2016-12-10 03:06:53 Epoch 94 
2016-12-10 03:09:33 Training Error = 0.89706249479903 
2016-12-10 03:09:33 Training Loss = 0.015189954307644 
2016-12-10 03:09:38 Valid Error = 0.95394983152377 
2016-12-10 03:09:38 Valid Loss = 0.016093285659994 
2016-12-10 03:09:43 Test Error = 0.9518356348939 
2016-12-10 03:09:43 Test Loss = 0.016030504280508 
2016-12-10 03:09:43 -------------------LR------------------- 
2016-12-10 03:09:43 0.0078125 
2016-12-10 03:09:44 Epoch 95 
2016-12-10 03:12:20 Training Error = 0.89835233419323 
2016-12-10 03:12:20 Training Loss = 0.015178983436683 
2016-12-10 03:12:24 Valid Error = 0.95394983152377 
2016-12-10 03:12:24 Valid Loss = 0.016096078289533 
2016-12-10 03:12:30 Test Error = 0.9518356348939 
2016-12-10 03:12:30 Test Loss = 0.016048582640199 
2016-12-10 03:12:30 -------------------LR------------------- 
2016-12-10 03:12:30 0.0078125 
2016-12-10 03:12:30 Epoch 96 
2016-12-10 03:15:07 Training Error = 0.89876841141716 
2016-12-10 03:15:07 Training Loss = 0.015191450369622 
2016-12-10 03:15:12 Valid Error = 0.95095469861475 
2016-12-10 03:15:12 Valid Loss = 0.016071641384258 
2016-12-10 03:15:17 Test Error = 0.9488043112159 
2016-12-10 03:15:17 Test Loss = 0.016005810413406 
2016-12-10 03:15:17 -------------------LR------------------- 
2016-12-10 03:15:17 0.0078125 
2016-12-10 03:15:17 Epoch 97 
2016-12-10 03:17:55 Training Error = 0.89835233419323 
2016-12-10 03:17:55 Training Loss = 0.015190880596338 
2016-12-10 03:18:00 Valid Error = 0.95394983152377 
2016-12-10 03:18:00 Valid Loss = 0.016102760399604 
2016-12-10 03:18:05 Test Error = 0.9518356348939 
2016-12-10 03:18:05 Test Loss = 0.016054454881564 
2016-12-10 03:18:05 -------------------LR------------------- 
2016-12-10 03:18:05 0.0078125 
2016-12-10 03:18:05 Epoch 98 
2016-12-10 03:20:42 Training Error = 0.89893484230673 
2016-12-10 03:20:42 Training Loss = 0.015200382097211 
2016-12-10 03:20:47 Valid Error = 0.95394983152377 
2016-12-10 03:20:47 Valid Loss = 0.016098363608611 
2016-12-10 03:20:53 Test Error = 0.9518356348939 
2016-12-10 03:20:53 Test Loss = 0.016036507997268 
2016-12-10 03:20:53 -------------------LR------------------- 
2016-12-10 03:20:53 0.0078125 
2016-12-10 03:20:53 Epoch 99 
2016-12-10 03:23:31 Training Error = 0.89893484230673 
2016-12-10 03:23:31 Training Loss = 0.015209379377893 
2016-12-10 03:23:35 Valid Error = 0.95394983152377 
2016-12-10 03:23:35 Valid Loss = 0.016109281936381 
2016-12-10 03:23:41 Test Error = 0.9518356348939 
2016-12-10 03:23:41 Test Loss = 0.01607966196065 
2016-12-10 03:23:41 -------------------LR------------------- 
2016-12-10 03:23:41 0.0078125 
2016-12-10 03:23:41 Epoch 100 
2016-12-10 03:26:26 Training Error = 0.89822751102605 
2016-12-10 03:26:26 Training Loss = 0.015211245100315 
2016-12-10 03:26:31 Valid Error = 0.95095469861475 
2016-12-10 03:26:31 Valid Loss = 0.016054632597522 
2016-12-10 03:26:37 Test Error = 0.9488043112159 
2016-12-10 03:26:37 Test Loss = 0.016002912116517 
2016-12-10 03:26:37 -------------------LR------------------- 
2016-12-10 03:26:37 0.00390625 
2016-12-10 03:26:37 Epoch 101 
2016-12-10 03:29:19 Training Error = 0.89960056586502 
2016-12-10 03:29:19 Training Loss = 0.015214161318311 
2016-12-10 03:29:24 Valid Error = 0.95095469861475 
2016-12-10 03:29:24 Valid Loss = 0.016188057679714 
2016-12-10 03:29:29 Test Error = 0.9488043112159 
2016-12-10 03:29:29 Test Loss = 0.016252719385595 
2016-12-10 03:29:29 -------------------LR------------------- 
2016-12-10 03:29:29 0.00390625 
2016-12-10 03:29:29 Epoch 102 
2016-12-10 03:32:07 Training Error = 0.89843554963801 
2016-12-10 03:32:07 Training Loss = 0.01518795872042 
2016-12-10 03:32:12 Valid Error = 0.95394983152377 
2016-12-10 03:32:12 Valid Loss = 0.016122868613685 
2016-12-10 03:32:17 Test Error = 0.9518356348939 
2016-12-10 03:32:17 Test Loss = 0.016052860152178 
2016-12-10 03:32:17 -------------------LR------------------- 
2016-12-10 03:32:17 0.00390625 
2016-12-10 03:32:17 Epoch 103 
2016-12-10 03:34:57 Training Error = 0.8991428809187 
2016-12-10 03:34:57 Training Loss = 0.015207308350264 
2016-12-10 03:35:01 Valid Error = 0.95394983152377 
2016-12-10 03:35:01 Valid Loss = 0.016125151023358 
2016-12-10 03:35:07 Test Error = 0.9518356348939 
2016-12-10 03:35:07 Test Loss = 0.016097294450642 
2016-12-10 03:35:07 -------------------LR------------------- 
2016-12-10 03:35:07 0.00390625 
2016-12-10 03:35:07 Epoch 104 
2016-12-10 03:37:46 Training Error = 0.89843554963801 
2016-12-10 03:37:46 Training Loss = 0.015186981065735 
2016-12-10 03:37:51 Valid Error = 0.95394983152377 
2016-12-10 03:37:51 Valid Loss = 0.016083949471972 
2016-12-10 03:37:57 Test Error = 0.9518356348939 
2016-12-10 03:37:57 Test Loss = 0.016053589320387 
2016-12-10 03:37:57 -------------------LR------------------- 
2016-12-10 03:37:57 0.00390625 
2016-12-10 03:37:57 Epoch 105 
2016-12-10 03:40:35 Training Error = 0.89806108013647 
2016-12-10 03:40:35 Training Loss = 0.015199072517783 
2016-12-10 03:40:40 Valid Error = 0.95095469861475 
2016-12-10 03:40:40 Valid Loss = 0.016159200185481 
2016-12-10 03:40:46 Test Error = 0.9488043112159 
2016-12-10 03:40:46 Test Loss = 0.016185644451169 
2016-12-10 03:40:46 -------------------LR------------------- 
2016-12-10 03:40:46 0.00390625 
2016-12-10 03:40:46 Epoch 106 
2016-12-10 03:43:25 Training Error = 0.89776982607972 
2016-12-10 03:43:25 Training Loss = 0.015182226268566 
2016-12-10 03:43:30 Valid Error = 0.95394983152377 
2016-12-10 03:43:30 Valid Loss = 0.016127531393634 
2016-12-10 03:43:35 Test Error = 0.9518356348939 
2016-12-10 03:43:35 Test Loss = 0.016114615231717 
2016-12-10 03:43:35 -------------------LR------------------- 
2016-12-10 03:43:35 0.00390625 
2016-12-10 03:43:35 Epoch 107 
2016-12-10 03:46:15 Training Error = 0.89847715736041 
2016-12-10 03:46:15 Training Loss = 0.015197555445303 
2016-12-10 03:46:20 Valid Error = 0.95095469861475 
2016-12-10 03:46:20 Valid Loss = 0.016328865179848 
2016-12-10 03:46:25 Test Error = 0.9488043112159 
2016-12-10 03:46:25 Test Loss = 0.016316662407538 
2016-12-10 03:46:25 -------------------LR------------------- 
2016-12-10 03:46:25 0.00390625 
2016-12-10 03:46:25 Epoch 108 
2016-12-10 03:49:04 Training Error = 0.89831072647083 
2016-12-10 03:49:04 Training Loss = 0.015187636379379 
2016-12-10 03:49:09 Valid Error = 0.95919131411456 
2016-12-10 03:49:09 Valid Loss = 0.016096299170633 
2016-12-10 03:49:14 Test Error = 0.95857190973392 
2016-12-10 03:49:14 Test Loss = 0.01606651587808 
2016-12-10 03:49:14 -------------------LR------------------- 
2016-12-10 03:49:14 0.00390625 
2016-12-10 03:49:14 Epoch 109 
2016-12-10 03:51:54 Training Error = 0.89955895814263 
2016-12-10 03:51:54 Training Loss = 0.015193463759744 
2016-12-10 03:51:59 Valid Error = 0.95095469861475 
2016-12-10 03:51:59 Valid Loss = 0.016119737511985 
2016-12-10 03:52:04 Test Error = 0.9488043112159 
2016-12-10 03:52:04 Test Loss = 0.016060813281734 
2016-12-10 03:52:04 -------------------LR------------------- 
2016-12-10 03:52:04 0.00390625 
2016-12-10 03:52:04 Epoch 110 
2016-12-10 03:54:47 Training Error = 0.89964217358742 
2016-12-10 03:54:47 Training Loss = 0.015201220511978 
2016-12-10 03:54:52 Valid Error = 0.95394983152377 
2016-12-10 03:54:52 Valid Loss = 0.016101380209223 
2016-12-10 03:54:57 Test Error = 0.9518356348939 
2016-12-10 03:54:57 Test Loss = 0.016089688970408 
2016-12-10 03:54:57 -------------------LR------------------- 
2016-12-10 03:54:57 0.00390625 
2016-12-10 03:54:57 Epoch 111 
2016-12-10 03:57:31 Training Error = 0.89835233419323 
2016-12-10 03:57:31 Training Loss = 0.01519992345646 
2016-12-10 03:57:36 Valid Error = 0.95394983152377 
2016-12-10 03:57:36 Valid Loss = 0.016109327742312 
2016-12-10 03:57:41 Test Error = 0.9518356348939 
2016-12-10 03:57:41 Test Loss = 0.016059649176382 
2016-12-10 03:57:41 -------------------LR------------------- 
2016-12-10 03:57:41 0.00390625 
2016-12-10 03:57:41 Epoch 112 
2016-12-10 04:00:14 Training Error = 0.89939252725306 
2016-12-10 04:00:14 Training Loss = 0.015200143703157 
2016-12-10 04:00:19 Valid Error = 0.95394983152377 
2016-12-10 04:00:19 Valid Loss = 0.016107083302087 
2016-12-10 04:00:24 Test Error = 0.9518356348939 
2016-12-10 04:00:24 Test Loss = 0.016046902305287 
2016-12-10 04:00:24 -------------------LR------------------- 
2016-12-10 04:00:24 0.00390625 
2016-12-10 04:00:24 Epoch 113 
2016-12-10 04:02:55 Training Error = 0.89822751102605 
2016-12-10 04:02:55 Training Loss = 0.015186850000689 
2016-12-10 04:03:00 Valid Error = 0.95394983152377 
2016-12-10 04:03:00 Valid Loss = 0.016076355083021 
2016-12-10 04:03:06 Test Error = 0.9518356348939 
2016-12-10 04:03:06 Test Loss = 0.016017738284263 
2016-12-10 04:03:06 -------------------LR------------------- 
2016-12-10 04:03:06 0.00390625 
2016-12-10 04:03:06 Epoch 114 
2016-12-10 04:05:39 Training Error = 0.89864358824998 
2016-12-10 04:05:39 Training Loss = 0.015179478157477 
2016-12-10 04:05:44 Valid Error = 0.95394983152377 
2016-12-10 04:05:44 Valid Loss = 0.016060809970909 
2016-12-10 04:05:49 Test Error = 0.9518356348939 
2016-12-10 04:05:49 Test Loss = 0.016025741606289 
2016-12-10 04:05:49 -------------------LR------------------- 
2016-12-10 04:05:49 0.00390625 
2016-12-10 04:05:49 Epoch 115 
2016-12-10 04:08:24 Training Error = 0.89818590330365 
2016-12-10 04:08:24 Training Loss = 0.015187289496053 
2016-12-10 04:08:29 Valid Error = 0.95394983152377 
2016-12-10 04:08:29 Valid Loss = 0.016092979846819 
2016-12-10 04:08:34 Test Error = 0.9518356348939 
2016-12-10 04:08:34 Test Loss = 0.0160844977163 
2016-12-10 04:08:34 -------------------LR------------------- 
2016-12-10 04:08:34 0.00390625 
2016-12-10 04:08:34 Epoch 116 
2016-12-10 04:11:06 Training Error = 0.89889323458434 
2016-12-10 04:11:06 Training Loss = 0.015205768106378 
2016-12-10 04:11:11 Valid Error = 0.95919131411456 
2016-12-10 04:11:11 Valid Loss = 0.016161492941299 
2016-12-10 04:11:16 Test Error = 0.95857190973392 
2016-12-10 04:11:16 Test Loss = 0.01612850622407 
2016-12-10 04:11:16 -------------------LR------------------- 
2016-12-10 04:11:16 0.00390625 
2016-12-10 04:11:16 Epoch 117 
2016-12-10 04:13:50 Training Error = 0.89810268785887 
2016-12-10 04:13:50 Training Loss = 0.015194132859249 
2016-12-10 04:13:55 Valid Error = 0.95095469861475 
2016-12-10 04:13:55 Valid Loss = 0.016026849864534 
2016-12-10 04:14:00 Test Error = 0.9488043112159 
2016-12-10 04:14:00 Test Loss = 0.015968516229583 
2016-12-10 04:14:00 -------------------LR------------------- 
2016-12-10 04:14:00 0.00390625 
2016-12-10 04:14:00 Epoch 118 
2016-12-10 04:16:33 Training Error = 0.89810268785887 
2016-12-10 04:16:33 Training Loss = 0.015193323134462 
2016-12-10 04:16:38 Valid Error = 0.95394983152377 
2016-12-10 04:16:38 Valid Loss = 0.016135898084943 
2016-12-10 04:16:43 Test Error = 0.9518356348939 
2016-12-10 04:16:43 Test Loss = 0.016123478226289 
2016-12-10 04:16:43 -------------------LR------------------- 
2016-12-10 04:16:43 0.00390625 
2016-12-10 04:16:43 Epoch 119 
2016-12-10 04:19:16 Training Error = 0.89847715736041 
2016-12-10 04:19:16 Training Loss = 0.01519247727285 
2016-12-10 04:19:21 Valid Error = 0.95394983152377 
2016-12-10 04:19:21 Valid Loss = 0.016121282268484 
2016-12-10 04:19:27 Test Error = 0.9518356348939 
2016-12-10 04:19:27 Test Loss = 0.016097320191678 
2016-12-10 04:19:27 -------------------LR------------------- 
2016-12-10 04:19:27 0.00390625 
2016-12-10 04:19:27 Epoch 120 
2016-12-10 04:22:08 Training Error = 0.89760339519015 
2016-12-10 04:22:08 Training Loss = 0.015184761289809 
2016-12-10 04:22:13 Valid Error = 0.95394983152377 
2016-12-10 04:22:13 Valid Loss = 0.016108808709838 
2016-12-10 04:22:19 Test Error = 0.9518356348939 
2016-12-10 04:22:19 Test Loss = 0.016070942012304 
2016-12-10 04:22:19 -------------------LR------------------- 
2016-12-10 04:22:19 0.00390625 
2016-12-10 04:22:19 Epoch 121 
2016-12-10 04:24:50 Training Error = 0.89818590330365 
2016-12-10 04:24:50 Training Loss = 0.015191907758561 
2016-12-10 04:24:55 Valid Error = 0.94721078247847 
2016-12-10 04:24:55 Valid Loss = 0.016073852822675 
2016-12-10 04:25:01 Test Error = 0.94509936005389 
2016-12-10 04:25:01 Test Loss = 0.016036318936434 
2016-12-10 04:25:01 -------------------LR------------------- 
2016-12-10 04:25:01 0.00390625 
2016-12-10 04:25:01 Epoch 122 
