2016-12-09 22:31:26 [program started on Fri Dec  9 22:31:26 2016] 
2016-12-09 22:31:26 [command line arguments] 
2016-12-09 22:31:26 stcWeights false 
2016-12-09 22:31:26 LR 0.015625 
2016-12-09 22:31:26 batchSize 64 
2016-12-09 22:31:26 network ./Models/Cifar10_Custom 
2016-12-09 22:31:26 stcNeurons true 
2016-12-09 22:31:26 constBatchSize false 
2016-12-09 22:31:26 chartFileName chart1 
2016-12-09 22:31:26 dp_prepro false 
2016-12-09 22:31:26 nGPU 1 
2016-12-09 22:31:26 dataset Caltech256 
2016-12-09 22:31:26 type cuda 
2016-12-09 22:31:26 momentum 0 
2016-12-09 22:31:26 threads 8 
2016-12-09 22:31:26 weightDecay 0 
2016-12-09 22:31:26 runningVal false 
2016-12-09 22:31:26 convLayerN 8 
2016-12-09 22:31:26 LRDecay 0 
2016-12-09 22:31:26 numHid 1024 
2016-12-09 22:31:26 save /dev/shm/clone/temp/th/Results/Caltech256/model8-10 
2016-12-09 22:31:26 augment false 
2016-12-09 22:31:26 epoch -1 
2016-12-09 22:31:26 modelsFolder ./Models/ 
2016-12-09 22:31:26 format rgb 
2016-12-09 22:31:26 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 22:31:26 imageFileExtension svg 
2016-12-09 22:31:26 channel 1 
2016-12-09 22:31:26 devid 2 
2016-12-09 22:31:26 visualize 1 
2016-12-09 22:31:26 LRDecayPerEpoch 0.0001 
2016-12-09 22:31:26 optimization adam 
2016-12-09 22:31:26 SBN true 
2016-12-09 22:31:26 normalization simple 
2016-12-09 22:31:26 title model1 
2016-12-09 22:31:26 load  
2016-12-09 22:31:26 whiten true 
2016-12-09 22:31:26 [----------------------] 
2016-12-09 22:31:27 ==> Network 
2016-12-09 22:31:27 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> (43) -> (44) -> (45) -> (46) -> (47) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (29): SpatialBatchNormalizationShiftPow2
  (30): nn.HardTanh
  (31): BinarizedNeurons
  (32): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (33): cudnn.SpatialMaxPooling(2x2, 2,2)
  (34): SpatialBatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): nn.View(2048)
  (38): BinaryLinear(2048 -> 1024)
  (39): BatchNormalizationShiftPow2
  (40): nn.HardTanh
  (41): BinarizedNeurons
  (42): BinaryLinear(1024 -> 1024)
  (43): BatchNormalizationShiftPow2
  (44): nn.HardTanh
  (45): BinarizedNeurons
  (46): BinaryLinear(1024 -> 255)
  (47): nn.BatchNormalization
} 
2016-12-09 22:31:27 ==>12715389 Parameters 
2016-12-09 22:31:27 ==> Loss 
2016-12-09 22:31:27 SqrtHingeEmbeddingCriterion 
2016-12-09 22:31:27 
==> Starting Training
 
2016-12-09 22:31:27 Epoch 1 
2016-12-09 22:35:27 Training Error = 0.9777398685196 
2016-12-09 22:35:27 Training Loss = 0.11456806473406 
2016-12-09 22:35:33 Valid Error = 0.93934855859229 
2016-12-09 22:35:33 Valid Loss = 0.015823210743378 
2016-12-09 22:35:40 Test Error = 0.9514988211519 
2016-12-09 22:35:40 Test Loss = 0.015795717435924 
2016-12-09 22:35:40 -------------------LR------------------- 
2016-12-09 22:35:40 0.015625 
2016-12-09 22:35:40 Epoch 2 
2016-12-09 22:39:50 Training Error = 0.95190147291337 
2016-12-09 22:39:50 Training Loss = 0.015912737107025 
2016-12-09 22:39:56 Valid Error = 0.93448146761513 
2016-12-09 22:39:56 Valid Loss = 0.01566687137191 
2016-12-09 22:40:03 Test Error = 0.94610980127989 
2016-12-09 22:40:03 Test Loss = 0.015662412621152 
2016-12-09 22:40:03 -------------------LR------------------- 
2016-12-09 22:40:03 0.015625 
2016-12-09 22:40:03 Epoch 3 
2016-12-09 22:44:26 Training Error = 0.93896147124906 
2016-12-09 22:44:26 Training Loss = 0.015616043930759 
2016-12-09 22:44:32 Valid Error = 0.93448146761513 
2016-12-09 22:44:32 Valid Loss = 0.015603233391644 
2016-12-09 22:44:39 Test Error = 0.94610980127989 
2016-12-09 22:44:39 Test Loss = 0.015601027142967 
2016-12-09 22:44:39 -------------------LR------------------- 
2016-12-09 22:44:39 0.015625 
2016-12-09 22:44:39 Epoch 4 
2016-12-09 22:49:18 Training Error = 0.93513356078888 
2016-12-09 22:49:18 Training Loss = 0.015505969651641 
2016-12-09 22:49:24 Valid Error = 0.93223511793336 
2016-12-09 22:49:24 Valid Loss = 0.015517007124036 
2016-12-09 22:49:31 Test Error = 0.94375210508589 
2016-12-09 22:49:31 Test Loss = 0.015533567567045 
2016-12-09 22:49:31 -------------------LR------------------- 
2016-12-09 22:49:31 0.015625 
2016-12-09 22:49:31 Epoch 5 
2016-12-09 22:54:09 Training Error = 0.93550803029042 
2016-12-09 22:54:09 Training Loss = 0.015456921847344 
2016-12-09 22:54:16 Valid Error = 0.9314863347061 
2016-12-09 22:54:16 Valid Loss = 0.015518673662657 
2016-12-09 22:54:23 Test Error = 0.94173122263388 
2016-12-09 22:54:23 Test Loss = 0.015518709925945 
2016-12-09 22:54:23 -------------------LR------------------- 
2016-12-09 22:54:23 0.015625 
2016-12-09 22:54:23 Epoch 6 
2016-12-09 22:59:23 Training Error = 0.92868436381792 
2016-12-09 22:59:23 Training Loss = 0.015421080867944 
2016-12-09 22:59:29 Valid Error = 0.92699363534257 
2016-12-09 22:59:29 Valid Loss = 0.015507387389305 
2016-12-09 22:59:36 Test Error = 0.93566857527787 
2016-12-09 22:59:36 Test Loss = 0.015516641313651 
2016-12-09 22:59:36 -------------------LR------------------- 
2016-12-09 22:59:36 0.015625 
2016-12-09 22:59:36 Epoch 7 
2016-12-09 23:05:40 Training Error = 0.92710327036698 
2016-12-09 23:05:40 Training Loss = 0.015385299721081 
2016-12-09 23:05:46 Valid Error = 0.9273680269562 
2016-12-09 23:05:46 Valid Loss = 0.015523506895631 
2016-12-09 23:05:53 Test Error = 0.93768945772988 
2016-12-09 23:05:53 Test Loss = 0.015530766852756 
2016-12-09 23:05:53 -------------------LR------------------- 
2016-12-09 23:05:53 0.015625 
2016-12-09 23:05:53 Epoch 8 
2016-12-09 23:12:54 Training Error = 0.92589664641758 
2016-12-09 23:12:54 Training Loss = 0.015354882375563 
2016-12-09 23:13:01 Valid Error = 0.96218644702359 
2016-12-09 23:13:01 Valid Loss = 0.015624603057245 
2016-12-09 23:13:08 Test Error = 0.97541259683395 
2016-12-09 23:13:08 Test Loss = 0.015619921909057 
2016-12-09 23:13:08 -------------------LR------------------- 
2016-12-09 23:13:08 0.015625 
2016-12-09 23:13:08 Epoch 9 
2016-12-09 23:21:26 Training Error = 0.92431555296663 
2016-12-09 23:21:26 Training Loss = 0.01530292849941 
2016-12-09 23:21:32 Valid Error = 0.96218644702359 
2016-12-09 23:21:32 Valid Loss = 0.015694154889184 
2016-12-09 23:21:40 Test Error = 0.97473896934995 
2016-12-09 23:21:40 Test Loss = 0.015728117347211 
2016-12-09 23:21:40 -------------------LR------------------- 
2016-12-09 23:21:40 0.015625 
2016-12-09 23:21:40 Epoch 10 
2016-12-09 23:30:11 Training Error = 0.91874011816593 
2016-12-09 23:30:11 Training Loss = 0.015260703623691 
2016-12-09 23:30:18 Valid Error = 0.97229502059154 
2016-12-09 23:30:18 Valid Loss = 0.015724110363668 
2016-12-09 23:30:25 Test Error = 0.97002357696194 
2016-12-09 23:30:25 Test Loss = 0.015683745100541 
2016-12-09 23:30:25 -------------------LR------------------- 
2016-12-09 23:30:25 0.015625 
2016-12-09 23:30:25 Epoch 11 
2016-12-09 23:38:54 Training Error = 0.90517600066572 
2016-12-09 23:38:54 Training Loss = 0.01521512299082 
2016-12-09 23:39:01 Valid Error = 0.97753650318233 
2016-12-09 23:39:01 Valid Loss = 0.015680908055102 
2016-12-09 23:39:08 Test Error = 0.97844392051196 
2016-12-09 23:39:08 Test Loss = 0.015657820024041 
2016-12-09 23:39:08 -------------------LR------------------- 
2016-12-09 23:39:08 0.015625 
2016-12-09 23:39:08 Epoch 12 
2016-12-09 23:47:35 Training Error = 0.90492635433136 
2016-12-09 23:47:35 Training Loss = 0.01521005242622 
2016-12-09 23:47:41 Valid Error = 0.97416697865968 
2016-12-09 23:47:41 Valid Loss = 0.015683578961294 
2016-12-09 23:47:48 Test Error = 0.97473896934995 
2016-12-09 23:47:48 Test Loss = 0.015672523799319 
2016-12-09 23:47:48 -------------------LR------------------- 
2016-12-09 23:47:48 0.015625 
2016-12-09 23:47:48 Epoch 13 
2016-12-09 23:56:23 Training Error = 0.90713156361821 
2016-12-09 23:56:23 Training Loss = 0.015218807167678 
2016-12-09 23:56:30 Valid Error = 0.97566454511419 
2016-12-09 23:56:30 Valid Loss = 0.015701620221211 
2016-12-09 23:56:37 Test Error = 0.97372852812395 
2016-12-09 23:56:37 Test Loss = 0.01566134560879 
2016-12-09 23:56:37 -------------------LR------------------- 
2016-12-09 23:56:37 0.015625 
2016-12-09 23:56:37 Epoch 14 
2016-12-10 00:05:57 Training Error = 0.90617458600316 
2016-12-10 00:05:57 Training Loss = 0.015216495394897 
2016-12-10 00:06:03 Valid Error = 0.97753650318233 
2016-12-10 00:06:03 Valid Loss = 0.015663779479333 
2016-12-10 00:06:10 Test Error = 0.97844392051196 
2016-12-10 00:06:10 Test Loss = 0.015641348684834 
2016-12-10 00:06:10 -------------------LR------------------- 
2016-12-10 00:06:10 0.015625 
2016-12-10 00:06:10 Epoch 15 
2016-12-10 00:14:13 Training Error = 0.90600815511359 
2016-12-10 00:14:13 Training Loss = 0.015213465097185 
2016-12-10 00:14:20 Valid Error = 0.97416697865968 
2016-12-10 00:14:20 Valid Loss = 0.015638688785407 
2016-12-10 00:14:27 Test Error = 0.97473896934995 
2016-12-10 00:14:27 Test Loss = 0.01562432073403 
2016-12-10 00:14:27 -------------------LR------------------- 
2016-12-10 00:14:27 0.015625 
2016-12-10 00:14:27 Epoch 16 
2016-12-10 00:22:20 Training Error = 0.90767246400932 
2016-12-10 00:22:20 Training Loss = 0.015216021486849 
2016-12-10 00:22:27 Valid Error = 0.97753650318233 
2016-12-10 00:22:27 Valid Loss = 0.015660358752227 
2016-12-10 00:22:34 Test Error = 0.97844392051196 
2016-12-10 00:22:34 Test Loss = 0.015648418472666 
2016-12-10 00:22:34 -------------------LR------------------- 
2016-12-10 00:22:34 0.015625 
2016-12-10 00:22:34 Epoch 17 
2016-12-10 00:30:38 Training Error = 0.90525921611051 
2016-12-10 00:30:38 Training Loss = 0.015212097771256 
2016-12-10 00:30:44 Valid Error = 0.97753650318233 
2016-12-10 00:30:44 Valid Loss = 0.015652422428766 
2016-12-10 00:30:51 Test Error = 0.97844392051196 
2016-12-10 00:30:51 Test Loss = 0.015637529574487 
2016-12-10 00:30:51 -------------------LR------------------- 
2016-12-10 00:30:51 0.015625 
2016-12-10 00:30:51 Epoch 18 
2016-12-10 00:38:58 Training Error = 0.90446866938504 
2016-12-10 00:38:58 Training Loss = 0.015211042841887 
2016-12-10 00:39:05 Valid Error = 0.97454137027331 
2016-12-10 00:39:05 Valid Loss = 0.015664307759052 
2016-12-10 00:39:12 Test Error = 0.97642303805995 
2016-12-10 00:39:12 Test Loss = 0.015649919184437 
2016-12-10 00:39:12 -------------------LR------------------- 
2016-12-10 00:39:12 0.015625 
2016-12-10 00:39:12 Epoch 19 
2016-12-10 00:47:12 Training Error = 0.9059665473912 
2016-12-10 00:47:12 Training Loss = 0.015218996718464 
2016-12-10 00:47:19 Valid Error = 0.97117184575066 
2016-12-10 00:47:19 Valid Loss = 0.015632703088451 
2016-12-10 00:47:26 Test Error = 0.97036039070394 
2016-12-10 00:47:26 Test Loss = 0.01561605786024 
2016-12-10 00:47:26 -------------------LR------------------- 
2016-12-10 00:47:26 0.015625 
2016-12-10 00:47:26 Epoch 20 
2016-12-10 00:55:29 Training Error = 0.90521760838812 
2016-12-10 00:55:29 Training Loss = 0.015213735564688 
2016-12-10 00:55:36 Valid Error = 0.97229502059154 
2016-12-10 00:55:36 Valid Loss = 0.01568036359615 
2016-12-10 00:55:43 Test Error = 0.97002357696194 
2016-12-10 00:55:43 Test Loss = 0.015650281708789 
2016-12-10 00:55:43 -------------------LR------------------- 
2016-12-10 00:55:43 0.015625 
2016-12-10 00:55:43 Epoch 21 
2016-12-10 01:03:32 Training Error = 0.90758924856453 
2016-12-10 01:03:32 Training Loss = 0.015217064403868 
2016-12-10 01:03:39 Valid Error = 0.97753650318233 
2016-12-10 01:03:39 Valid Loss = 0.015684310353162 
2016-12-10 01:03:46 Test Error = 0.97844392051196 
2016-12-10 01:03:46 Test Loss = 0.015656368181613 
2016-12-10 01:03:46 -------------------LR------------------- 
2016-12-10 01:03:46 0.015625 
2016-12-10 01:03:46 Epoch 22 
2016-12-10 01:10:49 Training Error = 0.90646584005992 
2016-12-10 01:10:49 Training Loss = 0.015212310822499 
2016-12-10 01:10:55 Valid Error = 0.97416697865968 
2016-12-10 01:10:55 Valid Loss = 0.015672067846391 
2016-12-10 01:11:02 Test Error = 0.97473896934995 
2016-12-10 01:11:02 Test Loss = 0.015648617313562 
2016-12-10 01:11:02 -------------------LR------------------- 
2016-12-10 01:11:02 0.015625 
2016-12-10 01:11:02 Epoch 23 
2016-12-10 01:18:11 Training Error = 0.90667387867188 
2016-12-10 01:18:11 Training Loss = 0.01521583315583 
2016-12-10 01:18:17 Valid Error = 0.97753650318233 
2016-12-10 01:18:17 Valid Loss = 0.015671011967106 
2016-12-10 01:18:24 Test Error = 0.97844392051196 
2016-12-10 01:18:24 Test Loss = 0.015653819609743 
2016-12-10 01:18:24 -------------------LR------------------- 
2016-12-10 01:18:24 0.015625 
2016-12-10 01:18:24 Epoch 24 
2016-12-10 01:25:30 Training Error = 0.90692352500624 
2016-12-10 01:25:30 Training Loss = 0.0152158335259 
2016-12-10 01:25:36 Valid Error = 0.97753650318233 
2016-12-10 01:25:36 Valid Loss = 0.015685546781105 
2016-12-10 01:25:43 Test Error = 0.97844392051196 
2016-12-10 01:25:43 Test Loss = 0.015661607664329 
2016-12-10 01:25:43 -------------------LR------------------- 
2016-12-10 01:25:43 0.015625 
2016-12-10 01:25:43 Epoch 25 
2016-12-10 01:33:10 Training Error = 0.90575850877923 
2016-12-10 01:33:10 Training Loss = 0.015212494128759 
2016-12-10 01:33:17 Valid Error = 0.97753650318233 
2016-12-10 01:33:17 Valid Loss = 0.015707495689657 
2016-12-10 01:33:24 Test Error = 0.97844392051196 
2016-12-10 01:33:24 Test Loss = 0.015678881587513 
2016-12-10 01:33:24 -------------------LR------------------- 
2016-12-10 01:33:24 0.015625 
2016-12-10 01:33:24 Epoch 26 
2016-12-10 01:40:19 Training Error = 0.90738120995257 
2016-12-10 01:40:19 Training Loss = 0.015213625546879 
2016-12-10 01:40:26 Valid Error = 0.97753650318233 
2016-12-10 01:40:26 Valid Loss = 0.015704686213945 
2016-12-10 01:40:33 Test Error = 0.97844392051196 
2016-12-10 01:40:33 Test Loss = 0.015675608272497 
2016-12-10 01:40:33 -------------------LR------------------- 
2016-12-10 01:40:33 0.015625 
2016-12-10 01:40:33 Epoch 27 
2016-12-10 01:47:31 Training Error = 0.90525921611051 
2016-12-10 01:47:31 Training Loss = 0.015213247663905 
2016-12-10 01:47:37 Valid Error = 0.97753650318233 
2016-12-10 01:47:37 Valid Loss = 0.015673008018989 
2016-12-10 01:47:44 Test Error = 0.97844392051196 
2016-12-10 01:47:44 Test Loss = 0.015663572877161 
2016-12-10 01:47:44 -------------------LR------------------- 
2016-12-10 01:47:44 0.015625 
2016-12-10 01:47:44 Epoch 28 
2016-12-10 01:54:36 Training Error = 0.90604976283598 
2016-12-10 01:54:36 Training Loss = 0.015220327047504 
2016-12-10 01:54:42 Valid Error = 0.97416697865968 
2016-12-10 01:54:42 Valid Loss = 0.015634875396822 
2016-12-10 01:54:49 Test Error = 0.97473896934995 
2016-12-10 01:54:49 Test Loss = 0.015614753967432 
2016-12-10 01:54:49 -------------------LR------------------- 
2016-12-10 01:54:49 0.015625 
2016-12-10 01:54:49 Epoch 29 
2016-12-10 02:03:08 Training Error = 0.90708995589581 
2016-12-10 02:03:08 Training Loss = 0.015216287600546 
2016-12-10 02:03:14 Valid Error = 0.97753650318233 
2016-12-10 02:03:14 Valid Loss = 0.015636328979061 
2016-12-10 02:03:21 Test Error = 0.97844392051196 
2016-12-10 02:03:21 Test Loss = 0.015620941680921 
2016-12-10 02:03:21 -------------------LR------------------- 
2016-12-10 02:03:21 0.015625 
2016-12-10 02:03:21 Epoch 30 
2016-12-10 02:10:58 Training Error = 0.90688191728385 
2016-12-10 02:10:58 Training Loss = 0.015216633187542 
2016-12-10 02:11:04 Valid Error = 0.97753650318233 
2016-12-10 02:11:04 Valid Loss = 0.015662352288582 
2016-12-10 02:11:11 Test Error = 0.97844392051196 
2016-12-10 02:11:11 Test Loss = 0.015662185744539 
2016-12-10 02:11:11 -------------------LR------------------- 
2016-12-10 02:11:11 0.015625 
2016-12-10 02:11:11 Epoch 31 
2016-12-10 02:18:32 Training Error = 0.90671548639427 
2016-12-10 02:18:32 Training Loss = 0.015212915275529 
2016-12-10 02:18:38 Valid Error = 0.97753650318233 
2016-12-10 02:18:38 Valid Loss = 0.015683438064757 
2016-12-10 02:18:45 Test Error = 0.97844392051196 
2016-12-10 02:18:45 Test Loss = 0.015660380448209 
2016-12-10 02:18:45 -------------------LR------------------- 
2016-12-10 02:18:45 0.015625 
2016-12-10 02:18:45 Epoch 32 
2016-12-10 02:26:11 Training Error = 0.90796371806607 
2016-12-10 02:26:11 Training Loss = 0.015213181938334 
2016-12-10 02:26:17 Valid Error = 0.97416697865968 
2016-12-10 02:26:17 Valid Loss = 0.015669656827201 
2016-12-10 02:26:24 Test Error = 0.97473896934995 
2016-12-10 02:26:24 Test Loss = 0.015649699254488 
2016-12-10 02:26:24 -------------------LR------------------- 
2016-12-10 02:26:24 0.015625 
2016-12-10 02:26:24 Epoch 33 
2016-12-10 02:33:47 Training Error = 0.90484313888658 
2016-12-10 02:33:47 Training Loss = 0.015212780231201 
2016-12-10 02:33:53 Valid Error = 0.97566454511419 
2016-12-10 02:33:53 Valid Loss = 0.015699667899532 
2016-12-10 02:34:00 Test Error = 0.97372852812395 
2016-12-10 02:34:00 Test Loss = 0.015657539562628 
2016-12-10 02:34:00 -------------------LR------------------- 
2016-12-10 02:34:00 0.015625 
2016-12-10 02:34:00 Epoch 34 
2016-12-10 02:41:21 Training Error = 0.90733960223017 
2016-12-10 02:41:21 Training Loss = 0.015216406599788 
2016-12-10 02:41:27 Valid Error = 0.97229502059154 
2016-12-10 02:41:27 Valid Loss = 0.015684954262363 
2016-12-10 02:41:35 Test Error = 0.97002357696194 
2016-12-10 02:41:35 Test Loss = 0.015650698843627 
2016-12-10 02:41:35 -------------------LR------------------- 
2016-12-10 02:41:35 0.015625 
2016-12-10 02:41:35 Epoch 35 
2016-12-10 02:48:56 Training Error = 0.9071731713406 
2016-12-10 02:48:56 Training Loss = 0.015222149999008 
2016-12-10 02:49:02 Valid Error = 0.97753650318233 
2016-12-10 02:49:02 Valid Loss = 0.015683551698773 
2016-12-10 02:49:09 Test Error = 0.97844392051196 
2016-12-10 02:49:09 Test Loss = 0.015675123979412 
2016-12-10 02:49:09 -------------------LR------------------- 
2016-12-10 02:49:09 0.015625 
2016-12-10 02:49:09 Epoch 36 
2016-12-10 02:56:12 Training Error = 0.90550886244487 
2016-12-10 02:56:12 Training Loss = 0.015210771322976 
2016-12-10 02:56:18 Valid Error = 0.97753650318233 
2016-12-10 02:56:18 Valid Loss = 0.01569637485901 
2016-12-10 02:56:25 Test Error = 0.97844392051196 
2016-12-10 02:56:25 Test Loss = 0.015662373816117 
2016-12-10 02:56:25 -------------------LR------------------- 
2016-12-10 02:56:25 0.015625 
2016-12-10 02:56:25 Epoch 37 
2016-12-10 03:03:13 Training Error = 0.9059249396688 
2016-12-10 03:03:13 Training Loss = 0.015216266216361 
2016-12-10 03:03:19 Valid Error = 0.97229502059154 
2016-12-10 03:03:19 Valid Loss = 0.015669171491908 
2016-12-10 03:03:26 Test Error = 0.97002357696194 
2016-12-10 03:03:26 Test Loss = 0.015638710397554 
2016-12-10 03:03:26 -------------------LR------------------- 
2016-12-10 03:03:26 0.015625 
2016-12-10 03:03:26 Epoch 38 
2016-12-10 03:10:11 Training Error = 0.9059249396688 
2016-12-10 03:10:11 Training Loss = 0.01520982265645 
2016-12-10 03:10:17 Valid Error = 0.97753650318233 
2016-12-10 03:10:17 Valid Loss = 0.015684578909759 
2016-12-10 03:10:24 Test Error = 0.97844392051196 
2016-12-10 03:10:24 Test Loss = 0.015653038298631 
2016-12-10 03:10:24 -------------------LR------------------- 
2016-12-10 03:10:24 0.015625 
2016-12-10 03:10:24 Epoch 39 
2016-12-10 03:17:09 Training Error = 0.90604976283598 
2016-12-10 03:17:09 Training Loss = 0.015214298089685 
2016-12-10 03:17:15 Valid Error = 0.97229502059154 
2016-12-10 03:17:15 Valid Loss = 0.015712432221245 
2016-12-10 03:17:22 Test Error = 0.97002357696194 
2016-12-10 03:17:22 Test Loss = 0.01566829235871 
2016-12-10 03:17:22 -------------------LR------------------- 
2016-12-10 03:17:22 0.015625 
2016-12-10 03:17:22 Epoch 40 
2016-12-10 03:24:09 Training Error = 0.90625780144795 
2016-12-10 03:24:09 Training Loss = 0.015216771718426 
2016-12-10 03:24:15 Valid Error = 0.97229502059154 
2016-12-10 03:24:15 Valid Loss = 0.015668738073768 
2016-12-10 03:24:22 Test Error = 0.97002357696194 
2016-12-10 03:24:22 Test Loss = 0.015640062862105 
2016-12-10 03:24:22 -------------------LR------------------- 
2016-12-10 03:24:22 0.015625 
2016-12-10 03:24:22 Epoch 41 
2016-12-10 03:31:11 Training Error = 0.90763085628693 
2016-12-10 03:31:11 Training Loss = 0.015220713584846 
2016-12-10 03:31:18 Valid Error = 0.97753650318233 
2016-12-10 03:31:18 Valid Loss = 0.015650051067381 
2016-12-10 03:31:25 Test Error = 0.97844392051196 
2016-12-10 03:31:25 Test Loss = 0.015629123288291 
2016-12-10 03:31:25 -------------------LR------------------- 
2016-12-10 03:31:25 0.015625 
2016-12-10 03:31:25 Epoch 42 
2016-12-10 03:38:15 Training Error = 0.90613297828077 
2016-12-10 03:38:15 Training Loss = 0.015214121268276 
2016-12-10 03:38:21 Valid Error = 0.97416697865968 
2016-12-10 03:38:21 Valid Loss = 0.015621963360456 
2016-12-10 03:38:28 Test Error = 0.97473896934995 
2016-12-10 03:38:28 Test Loss = 0.015607017333278 
2016-12-10 03:38:28 -------------------LR------------------- 
2016-12-10 03:38:28 0.015625 
2016-12-10 03:38:28 Epoch 43 
2016-12-10 03:45:13 Training Error = 0.90758924856453 
2016-12-10 03:45:13 Training Loss = 0.015217390509394 
2016-12-10 03:45:20 Valid Error = 0.97753650318233 
2016-12-10 03:45:20 Valid Loss = 0.015658961999785 
2016-12-10 03:45:27 Test Error = 0.97844392051196 
2016-12-10 03:45:27 Test Loss = 0.0156337351801 
2016-12-10 03:45:27 -------------------LR------------------- 
2016-12-10 03:45:27 0.015625 
2016-12-10 03:45:27 Epoch 44 
2016-12-10 03:52:12 Training Error = 0.90542564700008 
2016-12-10 03:52:12 Training Loss = 0.01521386089344 
2016-12-10 03:52:19 Valid Error = 0.97753650318233 
2016-12-10 03:52:19 Valid Loss = 0.01568138822293 
2016-12-10 03:52:26 Test Error = 0.97844392051196 
2016-12-10 03:52:26 Test Loss = 0.015655535263074 
2016-12-10 03:52:26 -------------------LR------------------- 
2016-12-10 03:52:26 0.015625 
2016-12-10 03:52:26 Epoch 45 
2016-12-10 03:58:26 Training Error = 0.9059249396688 
2016-12-10 03:58:26 Training Loss = 0.015217425002827 
2016-12-10 03:58:33 Valid Error = 0.97753650318233 
2016-12-10 03:58:33 Valid Loss = 0.015690016760257 
2016-12-10 03:58:40 Test Error = 0.97844392051196 
2016-12-10 03:58:40 Test Loss = 0.015661045083216 
2016-12-10 03:58:40 -------------------LR------------------- 
2016-12-10 03:58:40 0.015625 
2016-12-10 03:58:40 Epoch 46 
2016-12-10 04:04:39 Training Error = 0.90475992344179 
2016-12-10 04:04:39 Training Loss = 0.015212071786065 
2016-12-10 04:04:45 Valid Error = 0.97229502059154 
2016-12-10 04:04:45 Valid Loss = 0.015693076066546 
2016-12-10 04:04:52 Test Error = 0.97002357696194 
2016-12-10 04:04:52 Test Loss = 0.015655622556302 
2016-12-10 04:04:52 -------------------LR------------------- 
2016-12-10 04:04:52 0.015625 
2016-12-10 04:04:53 Epoch 47 
2016-12-10 04:10:54 Training Error = 0.90763085628693 
2016-12-10 04:10:54 Training Loss = 0.015213377717556 
2016-12-10 04:11:00 Valid Error = 0.97416697865968 
2016-12-10 04:11:00 Valid Loss = 0.01565751316252 
2016-12-10 04:11:07 Test Error = 0.97473896934995 
2016-12-10 04:11:07 Test Loss = 0.015632630074875 
2016-12-10 04:11:07 -------------------LR------------------- 
2016-12-10 04:11:07 0.015625 
2016-12-10 04:11:07 Epoch 48 
2016-12-10 04:17:02 Training Error = 0.9053424315553 
2016-12-10 04:17:02 Training Loss = 0.015210353890215 
2016-12-10 04:17:09 Valid Error = 0.97753650318233 
2016-12-10 04:17:09 Valid Loss = 0.015647121563447 
2016-12-10 04:17:16 Test Error = 0.97844392051196 
2016-12-10 04:17:16 Test Loss = 0.01562951981151 
2016-12-10 04:17:16 -------------------LR------------------- 
2016-12-10 04:17:16 0.015625 
2016-12-10 04:17:16 Epoch 49 
2016-12-10 04:23:13 Training Error = 0.90509278522094 
2016-12-10 04:23:13 Training Loss = 0.015208210485892 
2016-12-10 04:23:20 Valid Error = 0.97416697865968 
2016-12-10 04:23:20 Valid Loss = 0.015646700773151 
2016-12-10 04:23:27 Test Error = 0.97473896934995 
2016-12-10 04:23:27 Test Loss = 0.015621923102903 
2016-12-10 04:23:27 -------------------LR------------------- 
2016-12-10 04:23:27 0.015625 
2016-12-10 04:23:27 Epoch 50 
2016-12-10 04:29:32 Training Error = 0.90617458600316 
2016-12-10 04:29:32 Training Loss = 0.015205398372423 
2016-12-10 04:29:38 Valid Error = 0.97753650318233 
2016-12-10 04:29:38 Valid Loss = 0.015634977720675 
2016-12-10 04:29:45 Test Error = 0.97844392051196 
2016-12-10 04:29:45 Test Loss = 0.015622392396605 
2016-12-10 04:29:45 -------------------LR------------------- 
2016-12-10 04:29:45 0.0078125 
2016-12-10 04:29:45 Epoch 51 
2016-12-10 04:35:42 Training Error = 0.90563368561205 
2016-12-10 04:35:42 Training Loss = 0.015224400647956 
2016-12-10 04:35:48 Valid Error = 0.97753650318233 
2016-12-10 04:35:48 Valid Loss = 0.015665069083376 
2016-12-10 04:35:55 Test Error = 0.97844392051196 
2016-12-10 04:35:55 Test Loss = 0.015639814658517 
2016-12-10 04:35:55 -------------------LR------------------- 
2016-12-10 04:35:55 0.0078125 
2016-12-10 04:35:55 Epoch 52 
2016-12-10 04:41:53 Training Error = 0.90638262461513 
2016-12-10 04:41:53 Training Loss = 0.015215897970853 
2016-12-10 04:41:59 Valid Error = 0.97416697865968 
2016-12-10 04:41:59 Valid Loss = 0.01567000015005 
2016-12-10 04:42:06 Test Error = 0.97473896934995 
2016-12-10 04:42:06 Test Loss = 0.015639057233426 
2016-12-10 04:42:06 -------------------LR------------------- 
2016-12-10 04:42:06 0.0078125 
2016-12-10 04:42:06 Epoch 53 
2016-12-10 04:48:09 Training Error = 0.90621619372556 
2016-12-10 04:48:09 Training Loss = 0.01521840454634 
2016-12-10 04:48:16 Valid Error = 0.97229502059154 
2016-12-10 04:48:16 Valid Loss = 0.015676783624455 
2016-12-10 04:48:23 Test Error = 0.97002357696194 
2016-12-10 04:48:23 Test Loss = 0.015645026830419 
2016-12-10 04:48:23 -------------------LR------------------- 
2016-12-10 04:48:23 0.0078125 
2016-12-10 04:48:23 Epoch 54 
2016-12-10 04:54:20 Training Error = 0.90621619372556 
2016-12-10 04:54:20 Training Loss = 0.015212778601723 
2016-12-10 04:54:26 Valid Error = 0.97566454511419 
2016-12-10 04:54:26 Valid Loss = 0.015703384136939 
2016-12-10 04:54:33 Test Error = 0.97372852812395 
2016-12-10 04:54:33 Test Loss = 0.015661012772078 
2016-12-10 04:54:33 -------------------LR------------------- 
2016-12-10 04:54:33 0.0078125 
2016-12-10 04:54:33 Epoch 55 
2016-12-10 05:00:33 Training Error = 0.90688191728385 
2016-12-10 05:00:33 Training Loss = 0.015221932117402 
2016-12-10 05:00:39 Valid Error = 0.97229502059154 
2016-12-10 05:00:39 Valid Loss = 0.015698051749138 
2016-12-10 05:00:46 Test Error = 0.97002357696194 
2016-12-10 05:00:46 Test Loss = 0.015664874428155 
2016-12-10 05:00:46 -------------------LR------------------- 
2016-12-10 05:00:46 0.0078125 
2016-12-10 05:00:46 Epoch 56 
2016-12-10 05:06:42 Training Error = 0.90521760838812 
2016-12-10 05:06:42 Training Loss = 0.015213690091883 
2016-12-10 05:06:48 Valid Error = 0.97753650318233 
2016-12-10 05:06:48 Valid Loss = 0.015668052932367 
2016-12-10 05:06:55 Test Error = 0.97844392051196 
2016-12-10 05:06:55 Test Loss = 0.015641636991282 
2016-12-10 05:06:55 -------------------LR------------------- 
2016-12-10 05:06:55 0.0078125 
2016-12-10 05:06:55 Epoch 57 
2016-12-10 05:12:49 Training Error = 0.90480153116418 
2016-12-10 05:12:49 Training Loss = 0.01521247804257 
2016-12-10 05:12:55 Valid Error = 0.97266941220517 
2016-12-10 05:12:55 Valid Loss = 0.015703864463912 
2016-12-10 05:13:03 Test Error = 0.97170764567194 
2016-12-10 05:13:03 Test Loss = 0.015663478714454 
2016-12-10 05:13:03 -------------------LR------------------- 
2016-12-10 05:13:03 0.0078125 
2016-12-10 05:13:03 Epoch 58 
2016-12-10 05:19:03 Training Error = 0.90725638678539 
2016-12-10 05:19:03 Training Loss = 0.015206113378766 
2016-12-10 05:19:09 Valid Error = 0.97229502059154 
2016-12-10 05:19:09 Valid Loss = 0.015708775710919 
2016-12-10 05:19:16 Test Error = 0.97002357696194 
2016-12-10 05:19:16 Test Loss = 0.015670113013295 
2016-12-10 05:19:16 -------------------LR------------------- 
2016-12-10 05:19:16 0.0078125 
2016-12-10 05:19:16 Epoch 59 
2016-12-10 05:25:13 Training Error = 0.90750603311975 
2016-12-10 05:25:13 Training Loss = 0.015216994750438 
2016-12-10 05:25:19 Valid Error = 0.97229502059154 
2016-12-10 05:25:19 Valid Loss = 0.015652440690614 
2016-12-10 05:25:26 Test Error = 0.97002357696194 
2016-12-10 05:25:26 Test Loss = 0.015622298490917 
2016-12-10 05:25:26 -------------------LR------------------- 
2016-12-10 05:25:26 0.0078125 
2016-12-10 05:25:26 Epoch 60 
2016-12-10 05:31:27 Training Error = 0.90459349255222 
2016-12-10 05:31:27 Training Loss = 0.015209984637912 
2016-12-10 05:31:33 Valid Error = 0.97416697865968 
2016-12-10 05:31:33 Valid Loss = 0.015664498898881 
2016-12-10 05:31:40 Test Error = 0.97473896934995 
2016-12-10 05:31:40 Test Loss = 0.015646893456323 
2016-12-10 05:31:40 -------------------LR------------------- 
2016-12-10 05:31:40 0.0078125 
2016-12-10 05:31:40 Epoch 61 
2016-12-10 05:37:36 Training Error = 0.90659066322709 
2016-12-10 05:37:36 Training Loss = 0.015214707062181 
2016-12-10 05:37:43 Valid Error = 0.97566454511419 
2016-12-10 05:37:43 Valid Loss = 0.015672051764729 
2016-12-10 05:37:50 Test Error = 0.97372852812395 
2016-12-10 05:37:50 Test Loss = 0.01564035666541 
2016-12-10 05:37:50 -------------------LR------------------- 
2016-12-10 05:37:50 0.0078125 
2016-12-10 05:37:50 Epoch 62 
2016-12-10 05:43:46 Training Error = 0.90675709411667 
2016-12-10 05:43:46 Training Loss = 0.015214935612768 
2016-12-10 05:43:53 Valid Error = 0.97416697865968 
2016-12-10 05:43:53 Valid Loss = 0.01562063735681 
2016-12-10 05:44:00 Test Error = 0.97473896934995 
2016-12-10 05:44:00 Test Loss = 0.015605977023001 
2016-12-10 05:44:00 -------------------LR------------------- 
2016-12-10 05:44:00 0.0078125 
2016-12-10 05:44:00 Epoch 63 
2016-12-10 05:51:01 Training Error = 0.90588333194641 
2016-12-10 05:51:01 Training Loss = 0.015210981116874 
2016-12-10 05:51:08 Valid Error = 0.97416697865968 
2016-12-10 05:51:08 Valid Loss = 0.015652437606713 
2016-12-10 05:51:15 Test Error = 0.97473896934995 
2016-12-10 05:51:15 Test Loss = 0.015626045084616 
2016-12-10 05:51:15 -------------------LR------------------- 
2016-12-10 05:51:15 0.0078125 
2016-12-10 05:51:15 Epoch 64 
2016-12-10 05:58:10 Training Error = 0.9053424315553 
2016-12-10 05:58:10 Training Loss = 0.015214075122325 
2016-12-10 05:58:16 Valid Error = 0.97416697865968 
2016-12-10 05:58:16 Valid Loss = 0.015651925968504 
2016-12-10 05:58:24 Test Error = 0.97473896934995 
2016-12-10 05:58:24 Test Loss = 0.015634099192454 
2016-12-10 05:58:24 -------------------LR------------------- 
2016-12-10 05:58:24 0.0078125 
2016-12-10 05:58:24 Epoch 65 
2016-12-10 06:06:21 Training Error = 0.90521760838812 
2016-12-10 06:06:21 Training Loss = 0.015216637789134 
2016-12-10 06:06:28 Valid Error = 0.97229502059154 
2016-12-10 06:06:28 Valid Loss = 0.015671521726367 
2016-12-10 06:06:35 Test Error = 0.97002357696194 
2016-12-10 06:06:35 Test Loss = 0.015643978174597 
2016-12-10 06:06:35 -------------------LR------------------- 
2016-12-10 06:06:35 0.0078125 
2016-12-10 06:06:35 Epoch 66 
2016-12-10 06:14:28 Training Error = 0.90646584005992 
2016-12-10 06:14:28 Training Loss = 0.015219704496889 
2016-12-10 06:14:34 Valid Error = 0.97229502059154 
2016-12-10 06:14:34 Valid Loss = 0.015676918782786 
2016-12-10 06:14:41 Test Error = 0.97002357696194 
2016-12-10 06:14:41 Test Loss = 0.015644934509812 
2016-12-10 06:14:41 -------------------LR------------------- 
2016-12-10 06:14:41 0.0078125 
2016-12-10 06:14:41 Epoch 67 
2016-12-10 06:22:18 Training Error = 0.90509278522094 
2016-12-10 06:22:18 Training Loss = 0.01521471603557 
2016-12-10 06:22:24 Valid Error = 0.97753650318233 
2016-12-10 06:22:24 Valid Loss = 0.015662079148524 
2016-12-10 06:22:31 Test Error = 0.97844392051196 
2016-12-10 06:22:31 Test Loss = 0.015636608010787 
2016-12-10 06:22:31 -------------------LR------------------- 
2016-12-10 06:22:31 0.0078125 
2016-12-10 06:22:31 Epoch 68 
2016-12-10 06:30:44 Training Error = 0.90517600066572 
2016-12-10 06:30:44 Training Loss = 0.015213642959615 
2016-12-10 06:30:50 Valid Error = 0.97229502059154 
2016-12-10 06:30:50 Valid Loss = 0.015634752927909 
2016-12-10 06:30:57 Test Error = 0.97002357696194 
2016-12-10 06:30:57 Test Loss = 0.015614338669918 
2016-12-10 06:30:57 -------------------LR------------------- 
2016-12-10 06:30:57 0.0078125 
2016-12-10 06:30:57 Epoch 69 
2016-12-10 06:39:27 Training Error = 0.90758924856453 
2016-12-10 06:39:27 Training Loss = 0.015219980521876 
2016-12-10 06:39:33 Valid Error = 0.97753650318233 
2016-12-10 06:39:33 Valid Loss = 0.015692204662436 
2016-12-10 06:39:40 Test Error = 0.97844392051196 
2016-12-10 06:39:40 Test Loss = 0.015657467957084 
2016-12-10 06:39:40 -------------------LR------------------- 
2016-12-10 06:39:40 0.0078125 
2016-12-10 06:39:41 Epoch 70 
2016-12-10 06:47:58 Training Error = 0.90629940917034 
2016-12-10 06:47:58 Training Loss = 0.015217336482857 
2016-12-10 06:48:05 Valid Error = 0.97753650318233 
2016-12-10 06:48:05 Valid Loss = 0.01566837131166 
2016-12-10 06:48:12 Test Error = 0.97844392051196 
2016-12-10 06:48:12 Test Loss = 0.015645541735774 
2016-12-10 06:48:12 -------------------LR------------------- 
2016-12-10 06:48:12 0.0078125 
2016-12-10 06:48:12 Epoch 71 
