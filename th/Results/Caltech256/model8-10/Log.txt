2016-12-09 22:31:26 [program started on Fri Dec  9 22:31:26 2016] 
2016-12-09 22:31:26 [command line arguments] 
2016-12-09 22:31:26 stcWeights false 
2016-12-09 22:31:26 LR 0.015625 
2016-12-09 22:31:26 batchSize 64 
2016-12-09 22:31:26 network ./Models/Cifar10_Custom 
2016-12-09 22:31:26 stcNeurons true 
2016-12-09 22:31:26 constBatchSize false 
2016-12-09 22:31:26 chartFileName chart1 
2016-12-09 22:31:26 dp_prepro false 
2016-12-09 22:31:26 nGPU 1 
2016-12-09 22:31:26 dataset Caltech256 
2016-12-09 22:31:26 type cuda 
2016-12-09 22:31:26 momentum 0 
2016-12-09 22:31:26 threads 8 
2016-12-09 22:31:26 weightDecay 0 
2016-12-09 22:31:26 runningVal false 
2016-12-09 22:31:26 convLayerN 8 
2016-12-09 22:31:26 LRDecay 0 
2016-12-09 22:31:26 numHid 1024 
2016-12-09 22:31:26 save /dev/shm/clone/temp/th/Results/Caltech256/model8-10 
2016-12-09 22:31:26 augment false 
2016-12-09 22:31:26 epoch -1 
2016-12-09 22:31:26 modelsFolder ./Models/ 
2016-12-09 22:31:26 format rgb 
2016-12-09 22:31:26 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 22:31:26 imageFileExtension svg 
2016-12-09 22:31:26 channel 1 
2016-12-09 22:31:26 devid 2 
2016-12-09 22:31:26 visualize 1 
2016-12-09 22:31:26 LRDecayPerEpoch 0.0001 
2016-12-09 22:31:26 optimization adam 
2016-12-09 22:31:26 SBN true 
2016-12-09 22:31:26 normalization simple 
2016-12-09 22:31:26 title model1 
2016-12-09 22:31:26 load  
2016-12-09 22:31:26 whiten true 
2016-12-09 22:31:26 [----------------------] 
2016-12-09 22:31:27 ==> Network 
2016-12-09 22:31:27 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> (43) -> (44) -> (45) -> (46) -> (47) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (29): SpatialBatchNormalizationShiftPow2
  (30): nn.HardTanh
  (31): BinarizedNeurons
  (32): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (33): cudnn.SpatialMaxPooling(2x2, 2,2)
  (34): SpatialBatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): nn.View(2048)
  (38): BinaryLinear(2048 -> 1024)
  (39): BatchNormalizationShiftPow2
  (40): nn.HardTanh
  (41): BinarizedNeurons
  (42): BinaryLinear(1024 -> 1024)
  (43): BatchNormalizationShiftPow2
  (44): nn.HardTanh
  (45): BinarizedNeurons
  (46): BinaryLinear(1024 -> 255)
  (47): nn.BatchNormalization
} 
2016-12-09 22:31:27 ==>12715389 Parameters 
2016-12-09 22:31:27 ==> Loss 
2016-12-09 22:31:27 SqrtHingeEmbeddingCriterion 
2016-12-09 22:31:27 
==> Starting Training
 
2016-12-09 22:31:27 Epoch 1 
2016-12-09 22:35:27 Training Error = 0.9777398685196 
2016-12-09 22:35:27 Training Loss = 0.11456806473406 
2016-12-09 22:35:33 Valid Error = 0.93934855859229 
2016-12-09 22:35:33 Valid Loss = 0.015823210743378 
2016-12-09 22:35:40 Test Error = 0.9514988211519 
2016-12-09 22:35:40 Test Loss = 0.015795717435924 
2016-12-09 22:35:40 -------------------LR------------------- 
2016-12-09 22:35:40 0.015625 
2016-12-09 22:35:40 Epoch 2 
2016-12-09 22:39:50 Training Error = 0.95190147291337 
2016-12-09 22:39:50 Training Loss = 0.015912737107025 
2016-12-09 22:39:56 Valid Error = 0.93448146761513 
2016-12-09 22:39:56 Valid Loss = 0.01566687137191 
2016-12-09 22:40:03 Test Error = 0.94610980127989 
2016-12-09 22:40:03 Test Loss = 0.015662412621152 
2016-12-09 22:40:03 -------------------LR------------------- 
2016-12-09 22:40:03 0.015625 
2016-12-09 22:40:03 Epoch 3 
2016-12-09 22:44:26 Training Error = 0.93896147124906 
2016-12-09 22:44:26 Training Loss = 0.015616043930759 
2016-12-09 22:44:32 Valid Error = 0.93448146761513 
2016-12-09 22:44:32 Valid Loss = 0.015603233391644 
2016-12-09 22:44:39 Test Error = 0.94610980127989 
2016-12-09 22:44:39 Test Loss = 0.015601027142967 
2016-12-09 22:44:39 -------------------LR------------------- 
2016-12-09 22:44:39 0.015625 
2016-12-09 22:44:39 Epoch 4 
2016-12-09 22:49:18 Training Error = 0.93513356078888 
2016-12-09 22:49:18 Training Loss = 0.015505969651641 
2016-12-09 22:49:24 Valid Error = 0.93223511793336 
2016-12-09 22:49:24 Valid Loss = 0.015517007124036 
2016-12-09 22:49:31 Test Error = 0.94375210508589 
2016-12-09 22:49:31 Test Loss = 0.015533567567045 
2016-12-09 22:49:31 -------------------LR------------------- 
2016-12-09 22:49:31 0.015625 
2016-12-09 22:49:31 Epoch 5 
2016-12-09 22:54:09 Training Error = 0.93550803029042 
2016-12-09 22:54:09 Training Loss = 0.015456921847344 
2016-12-09 22:54:16 Valid Error = 0.9314863347061 
2016-12-09 22:54:16 Valid Loss = 0.015518673662657 
2016-12-09 22:54:23 Test Error = 0.94173122263388 
2016-12-09 22:54:23 Test Loss = 0.015518709925945 
2016-12-09 22:54:23 -------------------LR------------------- 
2016-12-09 22:54:23 0.015625 
2016-12-09 22:54:23 Epoch 6 
2016-12-09 22:59:23 Training Error = 0.92868436381792 
2016-12-09 22:59:23 Training Loss = 0.015421080867944 
2016-12-09 22:59:29 Valid Error = 0.92699363534257 
2016-12-09 22:59:29 Valid Loss = 0.015507387389305 
2016-12-09 22:59:36 Test Error = 0.93566857527787 
2016-12-09 22:59:36 Test Loss = 0.015516641313651 
2016-12-09 22:59:36 -------------------LR------------------- 
2016-12-09 22:59:36 0.015625 
2016-12-09 22:59:36 Epoch 7 
2016-12-09 23:05:40 Training Error = 0.92710327036698 
2016-12-09 23:05:40 Training Loss = 0.015385299721081 
2016-12-09 23:05:46 Valid Error = 0.9273680269562 
2016-12-09 23:05:46 Valid Loss = 0.015523506895631 
2016-12-09 23:05:53 Test Error = 0.93768945772988 
2016-12-09 23:05:53 Test Loss = 0.015530766852756 
2016-12-09 23:05:53 -------------------LR------------------- 
2016-12-09 23:05:53 0.015625 
2016-12-09 23:05:53 Epoch 8 
2016-12-09 23:12:54 Training Error = 0.92589664641758 
2016-12-09 23:12:54 Training Loss = 0.015354882375563 
2016-12-09 23:13:01 Valid Error = 0.96218644702359 
2016-12-09 23:13:01 Valid Loss = 0.015624603057245 
2016-12-09 23:13:08 Test Error = 0.97541259683395 
2016-12-09 23:13:08 Test Loss = 0.015619921909057 
2016-12-09 23:13:08 -------------------LR------------------- 
2016-12-09 23:13:08 0.015625 
2016-12-09 23:13:08 Epoch 9 
2016-12-09 23:21:26 Training Error = 0.92431555296663 
2016-12-09 23:21:26 Training Loss = 0.01530292849941 
2016-12-09 23:21:32 Valid Error = 0.96218644702359 
2016-12-09 23:21:32 Valid Loss = 0.015694154889184 
2016-12-09 23:21:40 Test Error = 0.97473896934995 
2016-12-09 23:21:40 Test Loss = 0.015728117347211 
2016-12-09 23:21:40 -------------------LR------------------- 
2016-12-09 23:21:40 0.015625 
2016-12-09 23:21:40 Epoch 10 
2016-12-09 23:30:11 Training Error = 0.91874011816593 
2016-12-09 23:30:11 Training Loss = 0.015260703623691 
2016-12-09 23:30:18 Valid Error = 0.97229502059154 
2016-12-09 23:30:18 Valid Loss = 0.015724110363668 
2016-12-09 23:30:25 Test Error = 0.97002357696194 
2016-12-09 23:30:25 Test Loss = 0.015683745100541 
2016-12-09 23:30:25 -------------------LR------------------- 
2016-12-09 23:30:25 0.015625 
2016-12-09 23:30:25 Epoch 11 
2016-12-09 23:38:54 Training Error = 0.90517600066572 
2016-12-09 23:38:54 Training Loss = 0.01521512299082 
2016-12-09 23:39:01 Valid Error = 0.97753650318233 
2016-12-09 23:39:01 Valid Loss = 0.015680908055102 
2016-12-09 23:39:08 Test Error = 0.97844392051196 
2016-12-09 23:39:08 Test Loss = 0.015657820024041 
2016-12-09 23:39:08 -------------------LR------------------- 
2016-12-09 23:39:08 0.015625 
2016-12-09 23:39:08 Epoch 12 
2016-12-09 23:47:35 Training Error = 0.90492635433136 
2016-12-09 23:47:35 Training Loss = 0.01521005242622 
2016-12-09 23:47:41 Valid Error = 0.97416697865968 
2016-12-09 23:47:41 Valid Loss = 0.015683578961294 
2016-12-09 23:47:48 Test Error = 0.97473896934995 
2016-12-09 23:47:48 Test Loss = 0.015672523799319 
2016-12-09 23:47:48 -------------------LR------------------- 
2016-12-09 23:47:48 0.015625 
2016-12-09 23:47:48 Epoch 13 
2016-12-09 23:56:23 Training Error = 0.90713156361821 
2016-12-09 23:56:23 Training Loss = 0.015218807167678 
2016-12-09 23:56:30 Valid Error = 0.97566454511419 
2016-12-09 23:56:30 Valid Loss = 0.015701620221211 
2016-12-09 23:56:37 Test Error = 0.97372852812395 
2016-12-09 23:56:37 Test Loss = 0.01566134560879 
2016-12-09 23:56:37 -------------------LR------------------- 
2016-12-09 23:56:37 0.015625 
2016-12-09 23:56:37 Epoch 14 
2016-12-10 00:05:57 Training Error = 0.90617458600316 
2016-12-10 00:05:57 Training Loss = 0.015216495394897 
2016-12-10 00:06:03 Valid Error = 0.97753650318233 
2016-12-10 00:06:03 Valid Loss = 0.015663779479333 
2016-12-10 00:06:10 Test Error = 0.97844392051196 
2016-12-10 00:06:10 Test Loss = 0.015641348684834 
2016-12-10 00:06:10 -------------------LR------------------- 
2016-12-10 00:06:10 0.015625 
2016-12-10 00:06:10 Epoch 15 
2016-12-10 00:14:13 Training Error = 0.90600815511359 
2016-12-10 00:14:13 Training Loss = 0.015213465097185 
2016-12-10 00:14:20 Valid Error = 0.97416697865968 
2016-12-10 00:14:20 Valid Loss = 0.015638688785407 
2016-12-10 00:14:27 Test Error = 0.97473896934995 
2016-12-10 00:14:27 Test Loss = 0.01562432073403 
2016-12-10 00:14:27 -------------------LR------------------- 
2016-12-10 00:14:27 0.015625 
2016-12-10 00:14:27 Epoch 16 
2016-12-10 00:22:20 Training Error = 0.90767246400932 
2016-12-10 00:22:20 Training Loss = 0.015216021486849 
2016-12-10 00:22:27 Valid Error = 0.97753650318233 
2016-12-10 00:22:27 Valid Loss = 0.015660358752227 
2016-12-10 00:22:34 Test Error = 0.97844392051196 
2016-12-10 00:22:34 Test Loss = 0.015648418472666 
2016-12-10 00:22:34 -------------------LR------------------- 
2016-12-10 00:22:34 0.015625 
2016-12-10 00:22:34 Epoch 17 
2016-12-10 00:30:38 Training Error = 0.90525921611051 
2016-12-10 00:30:38 Training Loss = 0.015212097771256 
2016-12-10 00:30:44 Valid Error = 0.97753650318233 
2016-12-10 00:30:44 Valid Loss = 0.015652422428766 
2016-12-10 00:30:51 Test Error = 0.97844392051196 
2016-12-10 00:30:51 Test Loss = 0.015637529574487 
2016-12-10 00:30:51 -------------------LR------------------- 
2016-12-10 00:30:51 0.015625 
2016-12-10 00:30:51 Epoch 18 
2016-12-10 00:38:58 Training Error = 0.90446866938504 
2016-12-10 00:38:58 Training Loss = 0.015211042841887 
2016-12-10 00:39:05 Valid Error = 0.97454137027331 
2016-12-10 00:39:05 Valid Loss = 0.015664307759052 
2016-12-10 00:39:12 Test Error = 0.97642303805995 
2016-12-10 00:39:12 Test Loss = 0.015649919184437 
2016-12-10 00:39:12 -------------------LR------------------- 
2016-12-10 00:39:12 0.015625 
2016-12-10 00:39:12 Epoch 19 
2016-12-10 00:47:12 Training Error = 0.9059665473912 
2016-12-10 00:47:12 Training Loss = 0.015218996718464 
2016-12-10 00:47:19 Valid Error = 0.97117184575066 
2016-12-10 00:47:19 Valid Loss = 0.015632703088451 
2016-12-10 00:47:26 Test Error = 0.97036039070394 
2016-12-10 00:47:26 Test Loss = 0.01561605786024 
2016-12-10 00:47:26 -------------------LR------------------- 
2016-12-10 00:47:26 0.015625 
2016-12-10 00:47:26 Epoch 20 
2016-12-10 00:55:29 Training Error = 0.90521760838812 
2016-12-10 00:55:29 Training Loss = 0.015213735564688 
2016-12-10 00:55:36 Valid Error = 0.97229502059154 
2016-12-10 00:55:36 Valid Loss = 0.01568036359615 
2016-12-10 00:55:43 Test Error = 0.97002357696194 
2016-12-10 00:55:43 Test Loss = 0.015650281708789 
2016-12-10 00:55:43 -------------------LR------------------- 
2016-12-10 00:55:43 0.015625 
2016-12-10 00:55:43 Epoch 21 
2016-12-10 01:03:32 Training Error = 0.90758924856453 
2016-12-10 01:03:32 Training Loss = 0.015217064403868 
2016-12-10 01:03:39 Valid Error = 0.97753650318233 
2016-12-10 01:03:39 Valid Loss = 0.015684310353162 
2016-12-10 01:03:46 Test Error = 0.97844392051196 
2016-12-10 01:03:46 Test Loss = 0.015656368181613 
2016-12-10 01:03:46 -------------------LR------------------- 
2016-12-10 01:03:46 0.015625 
2016-12-10 01:03:46 Epoch 22 
2016-12-10 01:10:49 Training Error = 0.90646584005992 
2016-12-10 01:10:49 Training Loss = 0.015212310822499 
2016-12-10 01:10:55 Valid Error = 0.97416697865968 
2016-12-10 01:10:55 Valid Loss = 0.015672067846391 
2016-12-10 01:11:02 Test Error = 0.97473896934995 
2016-12-10 01:11:02 Test Loss = 0.015648617313562 
2016-12-10 01:11:02 -------------------LR------------------- 
2016-12-10 01:11:02 0.015625 
2016-12-10 01:11:02 Epoch 23 
2016-12-10 01:18:11 Training Error = 0.90667387867188 
2016-12-10 01:18:11 Training Loss = 0.01521583315583 
2016-12-10 01:18:17 Valid Error = 0.97753650318233 
2016-12-10 01:18:17 Valid Loss = 0.015671011967106 
2016-12-10 01:18:24 Test Error = 0.97844392051196 
2016-12-10 01:18:24 Test Loss = 0.015653819609743 
2016-12-10 01:18:24 -------------------LR------------------- 
2016-12-10 01:18:24 0.015625 
2016-12-10 01:18:24 Epoch 24 
2016-12-10 01:25:30 Training Error = 0.90692352500624 
2016-12-10 01:25:30 Training Loss = 0.0152158335259 
2016-12-10 01:25:36 Valid Error = 0.97753650318233 
2016-12-10 01:25:36 Valid Loss = 0.015685546781105 
2016-12-10 01:25:43 Test Error = 0.97844392051196 
2016-12-10 01:25:43 Test Loss = 0.015661607664329 
2016-12-10 01:25:43 -------------------LR------------------- 
2016-12-10 01:25:43 0.015625 
2016-12-10 01:25:43 Epoch 25 
2016-12-10 01:33:10 Training Error = 0.90575850877923 
2016-12-10 01:33:10 Training Loss = 0.015212494128759 
2016-12-10 01:33:17 Valid Error = 0.97753650318233 
2016-12-10 01:33:17 Valid Loss = 0.015707495689657 
2016-12-10 01:33:24 Test Error = 0.97844392051196 
2016-12-10 01:33:24 Test Loss = 0.015678881587513 
2016-12-10 01:33:24 -------------------LR------------------- 
2016-12-10 01:33:24 0.015625 
2016-12-10 01:33:24 Epoch 26 
2016-12-10 01:40:19 Training Error = 0.90738120995257 
2016-12-10 01:40:19 Training Loss = 0.015213625546879 
2016-12-10 01:40:26 Valid Error = 0.97753650318233 
2016-12-10 01:40:26 Valid Loss = 0.015704686213945 
2016-12-10 01:40:33 Test Error = 0.97844392051196 
2016-12-10 01:40:33 Test Loss = 0.015675608272497 
2016-12-10 01:40:33 -------------------LR------------------- 
2016-12-10 01:40:33 0.015625 
2016-12-10 01:40:33 Epoch 27 
2016-12-10 01:47:31 Training Error = 0.90525921611051 
2016-12-10 01:47:31 Training Loss = 0.015213247663905 
2016-12-10 01:47:37 Valid Error = 0.97753650318233 
2016-12-10 01:47:37 Valid Loss = 0.015673008018989 
2016-12-10 01:47:44 Test Error = 0.97844392051196 
2016-12-10 01:47:44 Test Loss = 0.015663572877161 
2016-12-10 01:47:44 -------------------LR------------------- 
2016-12-10 01:47:44 0.015625 
2016-12-10 01:47:44 Epoch 28 
2016-12-10 01:54:36 Training Error = 0.90604976283598 
2016-12-10 01:54:36 Training Loss = 0.015220327047504 
2016-12-10 01:54:42 Valid Error = 0.97416697865968 
2016-12-10 01:54:42 Valid Loss = 0.015634875396822 
2016-12-10 01:54:49 Test Error = 0.97473896934995 
2016-12-10 01:54:49 Test Loss = 0.015614753967432 
2016-12-10 01:54:49 -------------------LR------------------- 
2016-12-10 01:54:49 0.015625 
2016-12-10 01:54:49 Epoch 29 
2016-12-10 02:03:08 Training Error = 0.90708995589581 
2016-12-10 02:03:08 Training Loss = 0.015216287600546 
2016-12-10 02:03:14 Valid Error = 0.97753650318233 
2016-12-10 02:03:14 Valid Loss = 0.015636328979061 
2016-12-10 02:03:21 Test Error = 0.97844392051196 
2016-12-10 02:03:21 Test Loss = 0.015620941680921 
2016-12-10 02:03:21 -------------------LR------------------- 
2016-12-10 02:03:21 0.015625 
2016-12-10 02:03:21 Epoch 30 
2016-12-10 02:10:58 Training Error = 0.90688191728385 
2016-12-10 02:10:58 Training Loss = 0.015216633187542 
2016-12-10 02:11:04 Valid Error = 0.97753650318233 
2016-12-10 02:11:04 Valid Loss = 0.015662352288582 
2016-12-10 02:11:11 Test Error = 0.97844392051196 
2016-12-10 02:11:11 Test Loss = 0.015662185744539 
2016-12-10 02:11:11 -------------------LR------------------- 
2016-12-10 02:11:11 0.015625 
2016-12-10 02:11:11 Epoch 31 
2016-12-10 02:18:32 Training Error = 0.90671548639427 
2016-12-10 02:18:32 Training Loss = 0.015212915275529 
2016-12-10 02:18:38 Valid Error = 0.97753650318233 
2016-12-10 02:18:38 Valid Loss = 0.015683438064757 
2016-12-10 02:18:45 Test Error = 0.97844392051196 
2016-12-10 02:18:45 Test Loss = 0.015660380448209 
2016-12-10 02:18:45 -------------------LR------------------- 
2016-12-10 02:18:45 0.015625 
2016-12-10 02:18:45 Epoch 32 
