2016-12-11 13:20:13 [program started on Sun Dec 11 13:20:13 2016] 
2016-12-11 13:20:13 [command line arguments] 
2016-12-11 13:20:13 stcWeights false 
2016-12-11 13:20:13 LR 0.015625 
2016-12-11 13:20:13 batchSize 100 
2016-12-11 13:20:13 network ./Models/Cifar10_Custom 
2016-12-11 13:20:13 stcNeurons true 
2016-12-11 13:20:13 constBatchSize false 
2016-12-11 13:20:13 chartFileName chart1 
2016-12-11 13:20:13 dp_prepro false 
2016-12-11 13:20:13 nGPU 1 
2016-12-11 13:20:13 dataset Caltech256 
2016-12-11 13:20:13 type cuda 
2016-12-11 13:20:13 momentum 0 
2016-12-11 13:20:13 threads 8 
2016-12-11 13:20:13 weightDecay 0 
2016-12-11 13:20:13 runningVal false 
2016-12-11 13:20:13 convLayerN 10 
2016-12-11 13:20:13 LRDecay 0 
2016-12-11 13:20:13 numHid 1024 
2016-12-11 13:20:13 save /dev/shm/clone/temp/th/Results/Caltech256/model10-10 
2016-12-11 13:20:13 augment false 
2016-12-11 13:20:13 epoch -1 
2016-12-11 13:20:13 modelsFolder ./Models/ 
2016-12-11 13:20:13 format rgb 
2016-12-11 13:20:13 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-11 13:20:13 imageFileExtension svg 
2016-12-11 13:20:13 channel 1 
2016-12-11 13:20:13 devid 2 
2016-12-11 13:20:13 visualize 1 
2016-12-11 13:20:13 LRDecayPerEpoch 0.0001 
2016-12-11 13:20:13 optimization adam 
2016-12-11 13:20:13 SBN true 
2016-12-11 13:20:13 normalization simple 
2016-12-11 13:20:13 title model1 
2016-12-11 13:20:13 load  
2016-12-11 13:20:13 whiten true 
2016-12-11 13:20:13 [----------------------] 
2016-12-11 13:20:15 ==> Network 
2016-12-11 13:20:15 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> (43) -> (44) -> (45) -> (46) -> (47) -> (48) -> (49) -> (50) -> (51) -> (52) -> (53) -> (54) -> (55) -> (56) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (29): SpatialBatchNormalizationShiftPow2
  (30): nn.HardTanh
  (31): BinarizedNeurons
  (32): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (33): cudnn.SpatialMaxPooling(2x2, 2,2)
  (34): SpatialBatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (38): SpatialBatchNormalizationShiftPow2
  (39): nn.HardTanh
  (40): BinarizedNeurons
  (41): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (42): cudnn.SpatialMaxPooling(2x2, 2,2)
  (43): SpatialBatchNormalizationShiftPow2
  (44): nn.HardTanh
  (45): BinarizedNeurons
  (46): nn.View(512)
  (47): BinaryLinear(512 -> 1024)
  (48): BatchNormalizationShiftPow2
  (49): nn.HardTanh
  (50): BinarizedNeurons
  (51): BinaryLinear(1024 -> 1024)
  (52): BatchNormalizationShiftPow2
  (53): nn.HardTanh
  (54): BinarizedNeurons
  (55): BinaryLinear(1024 -> 255)
  (56): nn.BatchNormalization
} 
2016-12-11 13:20:15 ==>15864189 Parameters 
2016-12-11 13:20:15 ==> Loss 
2016-12-11 13:20:15 SqrtHingeEmbeddingCriterion 
2016-12-11 13:20:15 
==> Starting Training
 
2016-12-11 13:20:15 Epoch 1 
2016-12-11 13:25:39 Training Error = 0.97233086460847 
2016-12-11 13:25:39 Training Loss = 0.1656419887141 
2016-12-11 13:25:45 Valid Error = 0.93223511793336 
2016-12-11 13:25:45 Valid Loss = 0.015766950679074 
2016-12-11 13:25:52 Test Error = 0.94307847760189 
2016-12-11 13:25:52 Test Loss = 0.015760391199217 
2016-12-11 13:25:52 -------------------LR------------------- 
2016-12-11 13:25:52 0.015625 
2016-12-11 13:25:52 Epoch 2 
2016-12-11 13:31:23 Training Error = 0.95801780810518 
2016-12-11 13:31:23 Training Loss = 0.016146928219857 
2016-12-11 13:31:30 Valid Error = 0.93448146761513 
2016-12-11 13:31:30 Valid Loss = 0.015620840991024 
2016-12-11 13:31:37 Test Error = 0.94543617379589 
2016-12-11 13:31:37 Test Loss = 0.015663339876011 
2016-12-11 13:31:37 -------------------LR------------------- 
2016-12-11 13:31:37 0.015625 
2016-12-11 13:31:37 Epoch 3 
2016-12-11 13:37:00 Training Error = 0.93971041025214 
2016-12-11 13:37:00 Training Loss = 0.015767518213292 
2016-12-11 13:37:06 Valid Error = 0.93036315986522 
2016-12-11 13:37:06 Valid Loss = 0.015512051610634 
2016-12-11 13:37:13 Test Error = 0.93836308521388 
2016-12-11 13:37:13 Test Loss = 0.015511978542266 
2016-12-11 13:37:13 -------------------LR------------------- 
2016-12-11 13:37:13 0.015625 
2016-12-11 13:37:13 Epoch 4 
2016-12-11 13:42:27 Training Error = 0.93205458933178 
2016-12-11 13:42:27 Training Loss = 0.015596765054403 
2016-12-11 13:42:33 Valid Error = 0.93934855859229 
2016-12-11 13:42:33 Valid Loss = 0.015554515790357 
2016-12-11 13:42:40 Test Error = 0.9514988211519 
2016-12-11 13:42:40 Test Loss = 0.015568694098226 
2016-12-11 13:42:40 -------------------LR------------------- 
2016-12-11 13:42:40 0.015625 
2016-12-11 13:42:40 Epoch 5 
2016-12-11 13:48:30 Training Error = 0.93097278854955 
2016-12-11 13:48:30 Training Loss = 0.015514851359013 
2016-12-11 13:48:36 Valid Error = 0.93223511793336 
2016-12-11 13:48:36 Valid Loss = 0.015503700847942 
2016-12-11 13:48:43 Test Error = 0.94307847760189 
2016-12-11 13:48:43 Test Loss = 0.015513664126651 
2016-12-11 13:48:43 -------------------LR------------------- 
2016-12-11 13:48:43 0.015625 
2016-12-11 13:48:43 Epoch 6 
2016-12-11 13:54:54 Training Error = 0.9307231422152 
2016-12-11 13:54:54 Training Loss = 0.015456302833806 
2016-12-11 13:55:00 Valid Error = 0.93223511793336 
2016-12-11 13:55:00 Valid Loss = 0.015519749046127 
2016-12-11 13:55:07 Test Error = 0.94307847760189 
2016-12-11 13:55:07 Test Loss = 0.015546230871257 
2016-12-11 13:55:07 -------------------LR------------------- 
2016-12-11 13:55:07 0.015625 
2016-12-11 13:55:07 Epoch 7 
2016-12-11 14:00:16 Training Error = 0.92989098776733 
2016-12-11 14:00:16 Training Loss = 0.015425429428902 
2016-12-11 14:00:23 Valid Error = 0.93223511793336 
2016-12-11 14:00:23 Valid Loss = 0.015502737448015 
2016-12-11 14:00:30 Test Error = 0.94307847760189 
2016-12-11 14:00:30 Test Loss = 0.015525721975885 
2016-12-11 14:00:30 -------------------LR------------------- 
2016-12-11 14:00:30 0.015625 
2016-12-11 14:00:30 Epoch 8 
2016-12-11 14:05:18 Training Error = 0.92756095531331 
2016-12-11 14:05:18 Training Loss = 0.015370174259915 
2016-12-11 14:05:25 Valid Error = 0.96443279670535 
2016-12-11 14:05:25 Valid Loss = 0.015620535485616 
2016-12-11 14:05:32 Test Error = 0.97777029302796 
2016-12-11 14:05:32 Test Loss = 0.015646574311231 
2016-12-11 14:05:32 -------------------LR------------------- 
2016-12-11 14:05:32 0.015625 
2016-12-11 14:05:32 Epoch 9 
2016-12-11 14:10:21 Training Error = 0.92044603478406 
2016-12-11 14:10:21 Training Loss = 0.015308037107225 
2016-12-11 14:10:27 Valid Error = 0.95731935604642 
2016-12-11 14:10:27 Valid Loss = 0.015707433217886 
2016-12-11 14:10:34 Test Error = 0.96934994947794 
2016-12-11 14:10:34 Test Loss = 0.015713173636873 
2016-12-11 14:10:34 -------------------LR------------------- 
2016-12-11 14:10:34 0.015625 
2016-12-11 14:10:34 Epoch 10 
2016-12-11 14:15:23 Training Error = 0.91116751269036 
2016-12-11 14:15:23 Training Loss = 0.015268501529629 
2016-12-11 14:15:29 Valid Error = 0.95320104829652 
2016-12-11 14:15:29 Valid Loss = 0.015650433890309 
2016-12-11 14:15:36 Test Error = 0.96362411586393 
2016-12-11 14:15:36 Test Loss = 0.01570324961937 
2016-12-11 14:15:36 -------------------LR------------------- 
2016-12-11 14:15:36 0.015625 
2016-12-11 14:15:36 Epoch 11 
2016-12-11 14:20:23 Training Error = 0.90559207788966 
2016-12-11 14:20:23 Training Loss = 0.015231853572722 
2016-12-11 14:20:29 Valid Error = 0.95731935604642 
2016-12-11 14:20:29 Valid Loss = 0.015676367053777 
2016-12-11 14:20:36 Test Error = 0.96934994947794 
2016-12-11 14:20:36 Test Loss = 0.015736487128607 
2016-12-11 14:20:36 -------------------LR------------------- 
2016-12-11 14:20:36 0.015625 
2016-12-11 14:20:36 Epoch 12 
2016-12-11 14:25:23 Training Error = 0.90488474660897 
2016-12-11 14:25:23 Training Loss = 0.01522181587161 
2016-12-11 14:25:30 Valid Error = 0.95320104829652 
2016-12-11 14:25:30 Valid Loss = 0.015691159135248 
2016-12-11 14:25:37 Test Error = 0.96362411586393 
2016-12-11 14:25:37 Test Loss = 0.015747871373921 
2016-12-11 14:25:37 -------------------LR------------------- 
2016-12-11 14:25:37 0.015625 
2016-12-11 14:25:37 Epoch 13 
2016-12-11 14:30:20 Training Error = 0.90363651493717 
2016-12-11 14:30:20 Training Loss = 0.015228135230159 
2016-12-11 14:30:27 Valid Error = 0.95544739797829 
2016-12-11 14:30:27 Valid Loss = 0.01566149529579 
2016-12-11 14:30:34 Test Error = 0.96463455708993 
2016-12-11 14:30:34 Test Loss = 0.015711559179808 
2016-12-11 14:30:34 -------------------LR------------------- 
2016-12-11 14:30:34 0.015625 
2016-12-11 14:30:34 Epoch 14 
2016-12-11 14:35:22 Training Error = 0.90326204543563 
2016-12-11 14:35:22 Training Loss = 0.01522290629355 
2016-12-11 14:35:28 Valid Error = 0.95731935604642 
2016-12-11 14:35:28 Valid Loss = 0.01566838184277 
2016-12-11 14:35:35 Test Error = 0.96934994947794 
2016-12-11 14:35:35 Test Loss = 0.015726140638205 
2016-12-11 14:35:35 -------------------LR------------------- 
2016-12-11 14:35:35 0.015625 
2016-12-11 14:35:35 Epoch 15 
2016-12-11 14:40:20 Training Error = 0.90197220604144 
2016-12-11 14:40:20 Training Loss = 0.015220852351746 
2016-12-11 14:40:27 Valid Error = 0.9502059153875 
2016-12-11 14:40:27 Valid Loss = 0.015752455035169 
2016-12-11 14:40:34 Test Error = 0.95756146850792 
2016-12-11 14:40:34 Test Loss = 0.015790318863914 
2016-12-11 14:40:34 -------------------LR------------------- 
2016-12-11 14:40:34 0.015625 
2016-12-11 14:40:34 Epoch 16 
2016-12-11 14:45:20 Training Error = 0.90301239910127 
2016-12-11 14:45:20 Training Loss = 0.015217646658109 
2016-12-11 14:45:26 Valid Error = 0.95544739797829 
2016-12-11 14:45:26 Valid Loss = 0.015731668600524 
2016-12-11 14:45:33 Test Error = 0.96463455708993 
2016-12-11 14:45:33 Test Loss = 0.015776441302692 
2016-12-11 14:45:33 -------------------LR------------------- 
2016-12-11 14:45:33 0.015625 
2016-12-11 14:45:33 Epoch 17 
2016-12-11 14:50:19 Training Error = 0.9047183157194 
2016-12-11 14:50:19 Training Loss = 0.015228559492074 
2016-12-11 14:50:26 Valid Error = 0.95731935604642 
2016-12-11 14:50:26 Valid Loss = 0.015670349727281 
2016-12-11 14:50:33 Test Error = 0.96934994947794 
2016-12-11 14:50:33 Test Loss = 0.01572510389274 
2016-12-11 14:50:33 -------------------LR------------------- 
2016-12-11 14:50:33 0.015625 
2016-12-11 14:50:33 Epoch 18 
2016-12-11 14:55:19 Training Error = 0.90280436048931 
2016-12-11 14:55:19 Training Loss = 0.015220340369704 
2016-12-11 14:55:26 Valid Error = 0.95170348184201 
2016-12-11 14:55:26 Valid Loss = 0.015661662292652 
2016-12-11 14:55:33 Test Error = 0.96631862579993 
2016-12-11 14:55:33 Test Loss = 0.015719356675115 
2016-12-11 14:55:33 -------------------LR------------------- 
2016-12-11 14:55:33 0.015625 
2016-12-11 14:55:33 Epoch 19 
2016-12-11 15:00:20 Training Error = 0.90238828326537 
2016-12-11 15:00:20 Training Loss = 0.015228449872294 
2016-12-11 15:00:26 Valid Error = 0.95320104829652 
2016-12-11 15:00:26 Valid Loss = 0.015674473582375 
2016-12-11 15:00:33 Test Error = 0.96362411586393 
2016-12-11 15:00:33 Test Loss = 0.015734457407 
2016-12-11 15:00:33 -------------------LR------------------- 
2016-12-11 15:00:33 0.015625 
2016-12-11 15:00:33 Epoch 20 
2016-12-11 15:05:20 Training Error = 0.90371973038196 
2016-12-11 15:05:20 Training Loss = 0.015219132277771 
2016-12-11 15:05:27 Valid Error = 0.95731935604642 
2016-12-11 15:05:27 Valid Loss = 0.015672371392052 
2016-12-11 15:05:34 Test Error = 0.96934994947794 
2016-12-11 15:05:34 Test Loss = 0.01573243582804 
2016-12-11 15:05:34 -------------------LR------------------- 
2016-12-11 15:05:34 0.015625 
2016-12-11 15:05:34 Epoch 21 
2016-12-11 15:10:20 Training Error = 0.90301239910127 
2016-12-11 15:10:20 Training Loss = 0.015220979323928 
2016-12-11 15:10:26 Valid Error = 0.95544739797829 
2016-12-11 15:10:26 Valid Loss = 0.015722688465965 
2016-12-11 15:10:33 Test Error = 0.96463455708993 
2016-12-11 15:10:33 Test Loss = 0.015765112457319 
2016-12-11 15:10:33 -------------------LR------------------- 
2016-12-11 15:10:33 0.015625 
2016-12-11 15:10:33 Epoch 22 
2016-12-11 15:15:22 Training Error = 0.90384455354914 
2016-12-11 15:15:22 Training Loss = 0.015222037957765 
2016-12-11 15:15:28 Valid Error = 0.95207787345563 
2016-12-11 15:15:28 Valid Loss = 0.015662471484963 
2016-12-11 15:15:35 Test Error = 0.96227686089592 
2016-12-11 15:15:35 Test Loss = 0.015718170157343 
2016-12-11 15:15:35 -------------------LR------------------- 
2016-12-11 15:15:35 0.015625 
2016-12-11 15:15:35 Epoch 23 
2016-12-11 15:20:24 Training Error = 0.90380294582675 
2016-12-11 15:20:24 Training Loss = 0.01522121834185 
2016-12-11 15:20:30 Valid Error = 0.94795956570573 
2016-12-11 15:20:30 Valid Loss = 0.015681131138424 
2016-12-11 15:20:37 Test Error = 0.95655102728191 
2016-12-11 15:20:37 Test Loss = 0.015742061388428 
2016-12-11 15:20:37 -------------------LR------------------- 
2016-12-11 15:20:37 0.015625 
2016-12-11 15:20:37 Epoch 24 
2016-12-11 15:25:25 Training Error = 0.90371973038196 
2016-12-11 15:25:25 Training Loss = 0.015225778862774 
2016-12-11 15:25:31 Valid Error = 0.95544739797829 
2016-12-11 15:25:31 Valid Loss = 0.015696038187013 
2016-12-11 15:25:38 Test Error = 0.96463455708993 
2016-12-11 15:25:38 Test Loss = 0.015731889756783 
2016-12-11 15:25:38 -------------------LR------------------- 
2016-12-11 15:25:38 0.015625 
2016-12-11 15:25:38 Epoch 25 
2016-12-11 15:30:28 Training Error = 0.90230506782059 
2016-12-11 15:30:28 Training Loss = 0.015218746459647 
2016-12-11 15:30:34 Valid Error = 0.9502059153875 
2016-12-11 15:30:34 Valid Loss = 0.015686733593541 
2016-12-11 15:30:41 Test Error = 0.95756146850792 
2016-12-11 15:30:41 Test Loss = 0.015750597780876 
2016-12-11 15:30:41 -------------------LR------------------- 
2016-12-11 15:30:41 0.015625 
2016-12-11 15:30:41 Epoch 26 
2016-12-11 15:35:31 Training Error = 0.90338686860281 
2016-12-11 15:35:31 Training Loss = 0.015224232609897 
2016-12-11 15:35:37 Valid Error = 0.9475851740921 
2016-12-11 15:35:37 Valid Loss = 0.015684924933456 
2016-12-11 15:35:44 Test Error = 0.96059279218592 
2016-12-11 15:35:44 Test Loss = 0.015749430062765 
2016-12-11 15:35:44 -------------------LR------------------- 
2016-12-11 15:35:44 0.015625 
2016-12-11 15:35:44 Epoch 27 
2016-12-11 15:40:32 Training Error = 0.90459349255222 
2016-12-11 15:40:32 Training Loss = 0.015228055539505 
2016-12-11 15:40:39 Valid Error = 0.9502059153875 
2016-12-11 15:40:39 Valid Loss = 0.015703953507906 
2016-12-11 15:40:46 Test Error = 0.95756146850792 
2016-12-11 15:40:46 Test Loss = 0.015768463817559 
2016-12-11 15:40:46 -------------------LR------------------- 
2016-12-11 15:40:46 0.015625 
2016-12-11 15:40:46 Epoch 28 
2016-12-11 15:45:36 Training Error = 0.90292918365649 
2016-12-11 15:45:36 Training Loss = 0.015220419443425 
2016-12-11 15:45:42 Valid Error = 0.95207787345563 
2016-12-11 15:45:42 Valid Loss = 0.01565248955527 
2016-12-11 15:45:49 Test Error = 0.96227686089592 
2016-12-11 15:45:49 Test Loss = 0.015708940273819 
2016-12-11 15:45:49 -------------------LR------------------- 
2016-12-11 15:45:49 0.015625 
2016-12-11 15:45:49 Epoch 29 
2016-12-11 15:50:34 Training Error = 0.90172255970708 
2016-12-11 15:50:34 Training Loss = 0.015223739172643 
2016-12-11 15:50:40 Valid Error = 0.94795956570573 
2016-12-11 15:50:40 Valid Loss = 0.015670273799015 
2016-12-11 15:50:47 Test Error = 0.95655102728191 
2016-12-11 15:50:47 Test Loss = 0.015726587924088 
2016-12-11 15:50:47 -------------------LR------------------- 
2016-12-11 15:50:47 0.015625 
2016-12-11 15:50:47 Epoch 30 
2016-12-11 15:55:36 Training Error = 0.90342847632521 
2016-12-11 15:55:36 Training Loss = 0.015231137955838 
2016-12-11 15:55:43 Valid Error = 0.95207787345563 
2016-12-11 15:55:43 Valid Loss = 0.015687617197713 
2016-12-11 15:55:50 Test Error = 0.96227686089592 
2016-12-11 15:55:50 Test Loss = 0.01574287205868 
2016-12-11 15:55:50 -------------------LR------------------- 
2016-12-11 15:55:50 0.015625 
2016-12-11 15:55:50 Epoch 31 
2016-12-11 16:00:40 Training Error = 0.9034700840476 
2016-12-11 16:00:40 Training Loss = 0.015228328281624 
2016-12-11 16:00:47 Valid Error = 0.9502059153875 
2016-12-11 16:00:47 Valid Loss = 0.015652767112997 
2016-12-11 16:00:54 Test Error = 0.95756146850792 
2016-12-11 16:00:54 Test Loss = 0.015700094352708 
2016-12-11 16:00:54 -------------------LR------------------- 
2016-12-11 16:00:54 0.015625 
2016-12-11 16:00:54 Epoch 32 
2016-12-11 16:05:41 Training Error = 0.90322043771324 
2016-12-11 16:05:41 Training Loss = 0.015226044074924 
2016-12-11 16:05:47 Valid Error = 0.95132909022838 
2016-12-11 16:05:47 Valid Loss = 0.015729474703578 
2016-12-11 16:05:54 Test Error = 0.95890872347592 
2016-12-11 16:05:54 Test Loss = 0.015784372680467 
2016-12-11 16:05:54 -------------------LR------------------- 
2016-12-11 16:05:54 0.015625 
2016-12-11 16:05:54 Epoch 33 
2016-12-11 16:10:42 Training Error = 0.90276275276691 
2016-12-11 16:10:42 Training Loss = 0.015225434069218 
2016-12-11 16:10:48 Valid Error = 0.95544739797829 
2016-12-11 16:10:48 Valid Loss = 0.015711484519012 
2016-12-11 16:10:55 Test Error = 0.96463455708993 
2016-12-11 16:10:55 Test Loss = 0.015751889784187 
2016-12-11 16:10:55 -------------------LR------------------- 
2016-12-11 16:10:55 0.015625 
2016-12-11 16:10:55 Epoch 34 
2016-12-11 16:15:46 Training Error = 0.90359490721478 
2016-12-11 16:15:46 Training Loss = 0.015225492026721 
2016-12-11 16:15:52 Valid Error = 0.95731935604642 
2016-12-11 16:15:52 Valid Loss = 0.015651794633991 
2016-12-11 16:15:59 Test Error = 0.96934994947794 
2016-12-11 16:15:59 Test Loss = 0.015707601138671 
2016-12-11 16:15:59 -------------------LR------------------- 
2016-12-11 16:15:59 0.015625 
2016-12-11 16:15:59 Epoch 35 
2016-12-11 16:20:45 Training Error = 0.90326204543563 
2016-12-11 16:20:45 Training Loss = 0.015224651983672 
2016-12-11 16:20:51 Valid Error = 0.95544739797829 
2016-12-11 16:20:51 Valid Loss = 0.015686811384071 
2016-12-11 16:20:58 Test Error = 0.96463455708993 
2016-12-11 16:20:58 Test Loss = 0.015744664556054 
2016-12-11 16:20:58 -------------------LR------------------- 
2016-12-11 16:20:58 0.015625 
2016-12-11 16:20:58 Epoch 36 
2016-12-11 16:25:44 Training Error = 0.90297079137888 
2016-12-11 16:25:44 Training Loss = 0.015218731212177 
2016-12-11 16:25:51 Valid Error = 0.94795956570573 
2016-12-11 16:25:51 Valid Loss = 0.015651607431919 
2016-12-11 16:25:58 Test Error = 0.95655102728191 
2016-12-11 16:25:58 Test Loss = 0.015706658765571 
2016-12-11 16:25:58 -------------------LR------------------- 
2016-12-11 16:25:58 0.015625 
2016-12-11 16:25:58 Epoch 37 
2016-12-11 16:30:47 Training Error = 0.90380294582675 
2016-12-11 16:30:47 Training Loss = 0.015225611094452 
2016-12-11 16:30:54 Valid Error = 0.9502059153875 
2016-12-11 16:30:54 Valid Loss = 0.015714936728929 
2016-12-11 16:31:01 Test Error = 0.95756146850792 
2016-12-11 16:31:01 Test Loss = 0.015754961313528 
2016-12-11 16:31:01 -------------------LR------------------- 
2016-12-11 16:31:01 0.015625 
2016-12-11 16:31:01 Epoch 38 
2016-12-11 16:35:46 Training Error = 0.90276275276691 
2016-12-11 16:35:46 Training Loss = 0.015219885888307 
2016-12-11 16:35:52 Valid Error = 0.95731935604642 
2016-12-11 16:35:52 Valid Loss = 0.015694583417463 
2016-12-11 16:35:59 Test Error = 0.96934994947794 
2016-12-11 16:35:59 Test Loss = 0.015751598731422 
2016-12-11 16:35:59 -------------------LR------------------- 
2016-12-11 16:35:59 0.015625 
2016-12-11 16:35:59 Epoch 39 
2016-12-11 16:40:50 Training Error = 0.90297079137888 
2016-12-11 16:40:50 Training Loss = 0.015226834562675 
2016-12-11 16:40:56 Valid Error = 0.9502059153875 
2016-12-11 16:40:56 Valid Loss = 0.015777454075507 
2016-12-11 16:41:03 Test Error = 0.95756146850792 
2016-12-11 16:41:03 Test Loss = 0.015816744810399 
2016-12-11 16:41:03 -------------------LR------------------- 
2016-12-11 16:41:03 0.015625 
2016-12-11 16:41:03 Epoch 40 
2016-12-11 16:45:52 Training Error = 0.90392776899393 
2016-12-11 16:45:52 Training Loss = 0.015228046968463 
2016-12-11 16:45:58 Valid Error = 0.95544739797829 
2016-12-11 16:45:58 Valid Loss = 0.015706177134261 
2016-12-11 16:46:05 Test Error = 0.96463455708993 
2016-12-11 16:46:05 Test Loss = 0.015741463709307 
2016-12-11 16:46:05 -------------------LR------------------- 
2016-12-11 16:46:05 0.015625 
2016-12-11 16:46:05 Epoch 41 
2016-12-11 16:50:50 Training Error = 0.90126487476076 
2016-12-11 16:50:50 Training Loss = 0.015215392174892 
2016-12-11 16:50:57 Valid Error = 0.95731935604642 
2016-12-11 16:50:57 Valid Loss = 0.01567043159194 
2016-12-11 16:51:04 Test Error = 0.96934994947794 
2016-12-11 16:51:04 Test Loss = 0.015727547838797 
2016-12-11 16:51:04 -------------------LR------------------- 
2016-12-11 16:51:04 0.015625 
2016-12-11 16:51:04 Epoch 42 
2016-12-11 16:55:53 Training Error = 0.90263792959973 
2016-12-11 16:55:53 Training Loss = 0.015221507777667 
2016-12-11 16:55:59 Valid Error = 0.95170348184201 
2016-12-11 16:55:59 Valid Loss = 0.015667082439522 
2016-12-11 16:56:06 Test Error = 0.96631862579993 
2016-12-11 16:56:06 Test Loss = 0.01572975877706 
2016-12-11 16:56:06 -------------------LR------------------- 
2016-12-11 16:56:06 0.015625 
2016-12-11 16:56:06 Epoch 43 
2016-12-11 17:00:51 Training Error = 0.90384455354914 
2016-12-11 17:00:51 Training Loss = 0.015223244742513 
2016-12-11 17:00:57 Valid Error = 0.95544739797829 
2016-12-11 17:00:57 Valid Loss = 0.01573229668947 
2016-12-11 17:01:04 Test Error = 0.96463455708993 
2016-12-11 17:01:04 Test Loss = 0.015772859274425 
2016-12-11 17:01:04 -------------------LR------------------- 
2016-12-11 17:01:04 0.015625 
2016-12-11 17:01:04 Epoch 44 
2016-12-11 17:05:49 Training Error = 0.90272114504452 
2016-12-11 17:05:49 Training Loss = 0.015221253101571 
2016-12-11 17:05:55 Valid Error = 0.95207787345563 
2016-12-11 17:05:55 Valid Loss = 0.015672058079873 
2016-12-11 17:06:02 Test Error = 0.96227686089592 
2016-12-11 17:06:02 Test Loss = 0.015727615778205 
2016-12-11 17:06:02 -------------------LR------------------- 
2016-12-11 17:06:02 0.015625 
2016-12-11 17:06:02 Epoch 45 
2016-12-11 17:10:50 Training Error = 0.90272114504452 
2016-12-11 17:10:50 Training Loss = 0.015222403550893 
2016-12-11 17:10:57 Valid Error = 0.95320104829652 
2016-12-11 17:10:57 Valid Loss = 0.015669010348744 
2016-12-11 17:11:03 Test Error = 0.96362411586393 
2016-12-11 17:11:03 Test Loss = 0.015724331454882 
2016-12-11 17:11:03 -------------------LR------------------- 
2016-12-11 17:11:03 0.015625 
2016-12-11 17:11:04 Epoch 46 
2016-12-11 17:15:48 Training Error = 0.90334526088042 
2016-12-11 17:15:48 Training Loss = 0.015222204967189 
2016-12-11 17:15:54 Valid Error = 0.95207787345563 
2016-12-11 17:15:54 Valid Loss = 0.015655815979714 
2016-12-11 17:16:01 Test Error = 0.96227686089592 
2016-12-11 17:16:01 Test Loss = 0.015710957406237 
2016-12-11 17:16:01 -------------------LR------------------- 
2016-12-11 17:16:01 0.015625 
2016-12-11 17:16:01 Epoch 47 
2016-12-11 17:20:49 Training Error = 0.90263792959973 
2016-12-11 17:20:49 Training Loss = 0.015217436224447 
2016-12-11 17:20:55 Valid Error = 0.95207787345563 
2016-12-11 17:20:55 Valid Loss = 0.015668878417115 
2016-12-11 17:21:02 Test Error = 0.96227686089592 
2016-12-11 17:21:02 Test Loss = 0.015720671441874 
2016-12-11 17:21:02 -------------------LR------------------- 
2016-12-11 17:21:02 0.015625 
2016-12-11 17:21:02 Epoch 48 
2016-12-11 17:25:48 Training Error = 0.90193059831905 
2016-12-11 17:25:48 Training Loss = 0.015218352818863 
2016-12-11 17:25:54 Valid Error = 0.95207787345563 
2016-12-11 17:25:54 Valid Loss = 0.015642051508475 
2016-12-11 17:26:01 Test Error = 0.96227686089592 
2016-12-11 17:26:01 Test Loss = 0.015692294045286 
2016-12-11 17:26:01 -------------------LR------------------- 
2016-12-11 17:26:01 0.015625 
2016-12-11 17:26:01 Epoch 49 
2016-12-11 17:30:48 Training Error = 0.90342847632521 
2016-12-11 17:30:48 Training Loss = 0.015217320296296 
2016-12-11 17:30:55 Valid Error = 0.94646199925122 
2016-12-11 17:30:55 Valid Loss = 0.015696972195897 
2016-12-11 17:31:02 Test Error = 0.95924553721792 
2016-12-11 17:31:02 Test Loss = 0.015758209411211 
2016-12-11 17:31:02 -------------------LR------------------- 
2016-12-11 17:31:02 0.015625 
2016-12-11 17:31:02 Epoch 50 
2016-12-11 17:35:51 Training Error = 0.90238828326537 
2016-12-11 17:35:51 Training Loss = 0.015217512144859 
2016-12-11 17:35:57 Valid Error = 0.95731935604642 
2016-12-11 17:35:57 Valid Loss = 0.015655047897655 
2016-12-11 17:36:04 Test Error = 0.96934994947794 
2016-12-11 17:36:04 Test Loss = 0.015705171256658 
2016-12-11 17:36:04 -------------------LR------------------- 
2016-12-11 17:36:04 0.0078125 
2016-12-11 17:36:04 Epoch 51 
2016-12-11 17:40:50 Training Error = 0.90292918365649 
2016-12-11 17:40:50 Training Loss = 0.015218034780968 
2016-12-11 17:40:56 Valid Error = 0.9502059153875 
2016-12-11 17:40:56 Valid Loss = 0.015714628562165 
2016-12-11 17:41:03 Test Error = 0.95756146850792 
2016-12-11 17:41:03 Test Loss = 0.015766549471882 
2016-12-11 17:41:03 -------------------LR------------------- 
2016-12-11 17:41:03 0.0078125 
2016-12-11 17:41:03 Epoch 52 
2016-12-11 17:45:51 Training Error = 0.90205542148623 
2016-12-11 17:45:51 Training Loss = 0.015214014255858 
2016-12-11 17:45:57 Valid Error = 0.9502059153875 
2016-12-11 17:45:57 Valid Loss = 0.015684480731592 
2016-12-11 17:46:04 Test Error = 0.95756146850792 
2016-12-11 17:46:04 Test Loss = 0.015744302416439 
2016-12-11 17:46:04 -------------------LR------------------- 
2016-12-11 17:46:04 0.0078125 
2016-12-11 17:46:04 Epoch 53 
2016-12-11 17:50:50 Training Error = 0.90384455354914 
2016-12-11 17:50:50 Training Loss = 0.015227190250994 
2016-12-11 17:50:56 Valid Error = 0.95731935604642 
2016-12-11 17:50:56 Valid Loss = 0.015644507612432 
2016-12-11 17:51:03 Test Error = 0.96934994947794 
2016-12-11 17:51:03 Test Loss = 0.015698583339739 
2016-12-11 17:51:03 -------------------LR------------------- 
2016-12-11 17:51:03 0.0078125 
2016-12-11 17:51:03 Epoch 54 
2016-12-11 17:55:50 Training Error = 0.9034700840476 
2016-12-11 17:55:50 Training Loss = 0.015223328618203 
2016-12-11 17:55:56 Valid Error = 0.95132909022838 
2016-12-11 17:55:56 Valid Loss = 0.0156545334105 
2016-12-11 17:56:03 Test Error = 0.95890872347592 
2016-12-11 17:56:03 Test Loss = 0.015707520519306 
2016-12-11 17:56:03 -------------------LR------------------- 
2016-12-11 17:56:03 0.0078125 
2016-12-11 17:56:03 Epoch 55 
2016-12-11 18:00:48 Training Error = 0.90255471415495 
2016-12-11 18:00:48 Training Loss = 0.015219011310752 
2016-12-11 18:00:54 Valid Error = 0.95544739797829 
2016-12-11 18:00:54 Valid Loss = 0.015713233165906 
2016-12-11 18:01:01 Test Error = 0.96463455708993 
2016-12-11 18:01:01 Test Loss = 0.015759647177945 
2016-12-11 18:01:01 -------------------LR------------------- 
2016-12-11 18:01:01 0.0078125 
2016-12-11 18:01:01 Epoch 56 
2016-12-11 18:05:51 Training Error = 0.90376133810435 
2016-12-11 18:05:51 Training Loss = 0.015227230629127 
2016-12-11 18:05:57 Valid Error = 0.95731935604642 
2016-12-11 18:05:57 Valid Loss = 0.01566034249753 
2016-12-11 18:06:04 Test Error = 0.96934994947794 
2016-12-11 18:06:04 Test Loss = 0.015713161134986 
2016-12-11 18:06:04 -------------------LR------------------- 
2016-12-11 18:06:04 0.0078125 
2016-12-11 18:06:04 Epoch 57 
2016-12-11 18:10:50 Training Error = 0.90276275276691 
2016-12-11 18:10:50 Training Loss = 0.015219561965598 
2016-12-11 18:10:57 Valid Error = 0.94795956570573 
2016-12-11 18:10:57 Valid Loss = 0.015706626634491 
2016-12-11 18:11:04 Test Error = 0.95655102728191 
2016-12-11 18:11:04 Test Loss = 0.015762765847795 
2016-12-11 18:11:04 -------------------LR------------------- 
2016-12-11 18:11:04 0.0078125 
2016-12-11 18:11:04 Epoch 58 
2016-12-11 18:15:49 Training Error = 0.90392776899393 
2016-12-11 18:15:49 Training Loss = 0.015221699327403 
2016-12-11 18:15:56 Valid Error = 0.95544739797829 
2016-12-11 18:15:56 Valid Loss = 0.015726983925195 
2016-12-11 18:16:03 Test Error = 0.96463455708993 
2016-12-11 18:16:03 Test Loss = 0.015773111468083 
2016-12-11 18:16:03 -------------------LR------------------- 
2016-12-11 18:16:03 0.0078125 
2016-12-11 18:16:03 Epoch 59 
2016-12-11 18:20:52 Training Error = 0.90438545394025 
2016-12-11 18:20:52 Training Loss = 0.015228646445125 
2016-12-11 18:20:59 Valid Error = 0.95207787345563 
2016-12-11 18:20:59 Valid Loss = 0.015689054687485 
2016-12-11 18:21:06 Test Error = 0.96227686089592 
2016-12-11 18:21:06 Test Loss = 0.01574926018765 
2016-12-11 18:21:06 -------------------LR------------------- 
2016-12-11 18:21:06 0.0078125 
2016-12-11 18:21:06 Epoch 60 
2016-12-11 18:25:53 Training Error = 0.90334526088042 
2016-12-11 18:25:53 Training Loss = 0.015224440714872 
2016-12-11 18:25:59 Valid Error = 0.95544739797829 
2016-12-11 18:25:59 Valid Loss = 0.015744915875804 
2016-12-11 18:26:06 Test Error = 0.96463455708993 
2016-12-11 18:26:06 Test Loss = 0.015786370474391 
2016-12-11 18:26:06 -------------------LR------------------- 
2016-12-11 18:26:06 0.0078125 
2016-12-11 18:26:06 Epoch 61 
2016-12-11 18:30:54 Training Error = 0.90297079137888 
2016-12-11 18:30:54 Training Loss = 0.015223256731223 
2016-12-11 18:31:00 Valid Error = 0.95731935604642 
2016-12-11 18:31:00 Valid Loss = 0.015675619292423 
2016-12-11 18:31:07 Test Error = 0.96934994947794 
2016-12-11 18:31:07 Test Loss = 0.015734387991579 
2016-12-11 18:31:07 -------------------LR------------------- 
2016-12-11 18:31:07 0.0078125 
2016-12-11 18:31:07 Epoch 62 
2016-12-11 18:35:56 Training Error = 0.90218024465341 
2016-12-11 18:35:56 Training Loss = 0.015221133956431 
2016-12-11 18:36:03 Valid Error = 0.94608760763759 
2016-12-11 18:36:03 Valid Loss = 0.015720781901286 
2016-12-11 18:36:10 Test Error = 0.9518356348939 
2016-12-11 18:36:10 Test Loss = 0.015760096525507 
2016-12-11 18:36:10 -------------------LR------------------- 
2016-12-11 18:36:10 0.0078125 
2016-12-11 18:36:10 Epoch 63 
2016-12-11 18:40:55 Training Error = 0.90326204543563 
2016-12-11 18:40:55 Training Loss = 0.015225102536212 
2016-12-11 18:41:01 Valid Error = 0.95731935604642 
2016-12-11 18:41:01 Valid Loss = 0.015658899005815 
2016-12-11 18:41:08 Test Error = 0.96934994947794 
2016-12-11 18:41:08 Test Loss = 0.015718907803948 
2016-12-11 18:41:08 -------------------LR------------------- 
2016-12-11 18:41:08 0.0078125 
2016-12-11 18:41:08 Epoch 64 
2016-12-11 18:46:00 Training Error = 0.90238828326537 
2016-12-11 18:46:00 Training Loss = 0.015220094450139 
2016-12-11 18:46:07 Valid Error = 0.95731935604642 
2016-12-11 18:46:07 Valid Loss = 0.015655032053124 
2016-12-11 18:46:14 Test Error = 0.96934994947794 
2016-12-11 18:46:14 Test Loss = 0.015708163867548 
2016-12-11 18:46:14 -------------------LR------------------- 
2016-12-11 18:46:14 0.0078125 
2016-12-11 18:46:14 Epoch 65 
2016-12-11 18:51:01 Training Error = 0.90297079137888 
2016-12-11 18:51:01 Training Loss = 0.015219583682683 
2016-12-11 18:51:07 Valid Error = 0.95207787345563 
2016-12-11 18:51:07 Valid Loss = 0.015709795985194 
2016-12-11 18:51:14 Test Error = 0.96227686089592 
2016-12-11 18:51:14 Test Loss = 0.015770572236764 
2016-12-11 18:51:14 -------------------LR------------------- 
2016-12-11 18:51:14 0.0078125 
2016-12-11 18:51:14 Epoch 66 
2016-12-11 18:56:02 Training Error = 0.90455188482982 
2016-12-11 18:56:02 Training Loss = 0.015226013332861 
2016-12-11 18:56:08 Valid Error = 0.95207787345563 
2016-12-11 18:56:08 Valid Loss = 0.015649209366517 
2016-12-11 18:56:15 Test Error = 0.96227686089592 
2016-12-11 18:56:15 Test Loss = 0.015702722684834 
2016-12-11 18:56:15 -------------------LR------------------- 
2016-12-11 18:56:15 0.0078125 
2016-12-11 18:56:15 Epoch 67 
2016-12-11 19:01:01 Training Error = 0.90330365315803 
2016-12-11 19:01:01 Training Loss = 0.015223737868087 
2016-12-11 19:01:08 Valid Error = 0.94608760763759 
2016-12-11 19:01:08 Valid Loss = 0.015656638491295 
2016-12-11 19:01:15 Test Error = 0.9518356348939 
2016-12-11 19:01:15 Test Loss = 0.015710926340574 
2016-12-11 19:01:15 -------------------LR------------------- 
2016-12-11 19:01:15 0.0078125 
2016-12-11 19:01:15 Epoch 68 
2016-12-11 19:06:02 Training Error = 0.90371973038196 
2016-12-11 19:06:02 Training Loss = 0.015223643877271 
2016-12-11 19:06:08 Valid Error = 0.94795956570573 
2016-12-11 19:06:08 Valid Loss = 0.015662625325496 
2016-12-11 19:06:15 Test Error = 0.95655102728191 
2016-12-11 19:06:15 Test Loss = 0.015716552613542 
2016-12-11 19:06:15 -------------------LR------------------- 
2016-12-11 19:06:15 0.0078125 
2016-12-11 19:06:15 Epoch 69 
2016-12-11 19:10:59 Training Error = 0.9028459682117 
2016-12-11 19:10:59 Training Loss = 0.01522068480163 
2016-12-11 19:11:06 Valid Error = 0.94795956570573 
2016-12-11 19:11:06 Valid Loss = 0.01567484765627 
2016-12-11 19:11:13 Test Error = 0.95655102728191 
2016-12-11 19:11:13 Test Loss = 0.01573347823705 
2016-12-11 19:11:13 -------------------LR------------------- 
2016-12-11 19:11:13 0.0078125 
2016-12-11 19:11:13 Epoch 70 
2016-12-11 19:16:01 Training Error = 0.90367812265957 
2016-12-11 19:16:01 Training Loss = 0.015222542537783 
2016-12-11 19:16:08 Valid Error = 0.95207787345563 
2016-12-11 19:16:08 Valid Loss = 0.015657952207061 
2016-12-11 19:16:15 Test Error = 0.96227686089592 
2016-12-11 19:16:15 Test Loss = 0.015712414196954 
2016-12-11 19:16:15 -------------------LR------------------- 
2016-12-11 19:16:15 0.0078125 
2016-12-11 19:16:15 Epoch 71 
2016-12-11 19:21:02 Training Error = 0.9028459682117 
2016-12-11 19:21:02 Training Loss = 0.015227356954581 
2016-12-11 19:21:09 Valid Error = 0.9502059153875 
2016-12-11 19:21:09 Valid Loss = 0.015724396031948 
2016-12-11 19:21:16 Test Error = 0.95756146850792 
2016-12-11 19:21:16 Test Loss = 0.015768504533102 
2016-12-11 19:21:16 -------------------LR------------------- 
2016-12-11 19:21:16 0.0078125 
2016-12-11 19:21:16 Epoch 72 
2016-12-11 19:26:02 Training Error = 0.90201381376383 
2016-12-11 19:26:02 Training Loss = 0.015218981413466 
2016-12-11 19:26:08 Valid Error = 0.95544739797829 
2016-12-11 19:26:08 Valid Loss = 0.015680467242585 
2016-12-11 19:26:15 Test Error = 0.96463455708993 
2016-12-11 19:26:15 Test Loss = 0.015741193698841 
2016-12-11 19:26:15 -------------------LR------------------- 
2016-12-11 19:26:15 0.0078125 
2016-12-11 19:26:15 Epoch 73 
2016-12-11 19:31:06 Training Error = 0.90263792959973 
2016-12-11 19:31:06 Training Loss = 0.015220030452713 
2016-12-11 19:31:13 Valid Error = 0.95731935604642 
2016-12-11 19:31:13 Valid Loss = 0.015670507053236 
2016-12-11 19:31:20 Test Error = 0.96934994947794 
2016-12-11 19:31:20 Test Loss = 0.015723019175319 
2016-12-11 19:31:20 -------------------LR------------------- 
2016-12-11 19:31:20 0.0078125 
2016-12-11 19:31:20 Epoch 74 
2016-12-11 19:36:06 Training Error = 0.90330365315803 
2016-12-11 19:36:06 Training Loss = 0.015224122229759 
2016-12-11 19:36:12 Valid Error = 0.95731935604642 
2016-12-11 19:36:12 Valid Loss = 0.015682961266662 
2016-12-11 19:36:19 Test Error = 0.96934994947794 
2016-12-11 19:36:19 Test Loss = 0.015744840228843 
2016-12-11 19:36:19 -------------------LR------------------- 
2016-12-11 19:36:19 0.0078125 
2016-12-11 19:36:19 Epoch 75 
2016-12-11 19:41:08 Training Error = 0.90276275276691 
2016-12-11 19:41:08 Training Loss = 0.015222891293642 
2016-12-11 19:41:15 Valid Error = 0.94608760763759 
2016-12-11 19:41:15 Valid Loss = 0.015661575356245 
2016-12-11 19:41:22 Test Error = 0.9518356348939 
2016-12-11 19:41:22 Test Loss = 0.015711668606009 
2016-12-11 19:41:22 -------------------LR------------------- 
2016-12-11 19:41:22 0.0078125 
2016-12-11 19:41:22 Epoch 76 
2016-12-11 19:46:09 Training Error = 0.90297079137888 
2016-12-11 19:46:09 Training Loss = 0.015223125668355 
2016-12-11 19:46:16 Valid Error = 0.95731935604642 
2016-12-11 19:46:16 Valid Loss = 0.015697860476016 
2016-12-11 19:46:23 Test Error = 0.96934994947794 
2016-12-11 19:46:23 Test Loss = 0.015759496196152 
2016-12-11 19:46:23 -------------------LR------------------- 
2016-12-11 19:46:23 0.0078125 
2016-12-11 19:46:23 Epoch 77 
2016-12-11 19:51:10 Training Error = 0.90288757593409 
2016-12-11 19:51:10 Training Loss = 0.015220844318183 
2016-12-11 19:51:16 Valid Error = 0.95207787345563 
2016-12-11 19:51:16 Valid Loss = 0.015673020080138 
2016-12-11 19:51:23 Test Error = 0.96227686089592 
2016-12-11 19:51:23 Test Loss = 0.015733991385053 
2016-12-11 19:51:23 -------------------LR------------------- 
2016-12-11 19:51:23 0.0078125 
2016-12-11 19:51:23 Epoch 78 
2016-12-11 19:56:11 Training Error = 0.9034700840476 
2016-12-11 19:56:11 Training Loss = 0.015227628242 
2016-12-11 19:56:17 Valid Error = 0.95544739797829 
2016-12-11 19:56:17 Valid Loss = 0.01567421900983 
2016-12-11 19:56:24 Test Error = 0.96463455708993 
2016-12-11 19:56:24 Test Loss = 0.015739087229732 
2016-12-11 19:56:24 -------------------LR------------------- 
2016-12-11 19:56:24 0.0078125 
2016-12-11 19:56:24 Epoch 79 
2016-12-11 20:01:07 Training Error = 0.90338686860281 
2016-12-11 20:01:07 Training Loss = 0.015223861564859 
2016-12-11 20:01:13 Valid Error = 0.95544739797829 
2016-12-11 20:01:13 Valid Loss = 0.015725675513414 
2016-12-11 20:01:20 Test Error = 0.96463455708993 
2016-12-11 20:01:20 Test Loss = 0.01576665805572 
2016-12-11 20:01:20 -------------------LR------------------- 
2016-12-11 20:01:20 0.0078125 
2016-12-11 20:01:20 Epoch 80 
2016-12-11 20:06:09 Training Error = 0.90367812265957 
2016-12-11 20:06:09 Training Loss = 0.015224451965716 
2016-12-11 20:06:15 Valid Error = 0.95731935604642 
2016-12-11 20:06:15 Valid Loss = 0.015654627091133 
2016-12-11 20:06:22 Test Error = 0.96934994947794 
2016-12-11 20:06:22 Test Loss = 0.015704542154578 
2016-12-11 20:06:22 -------------------LR------------------- 
2016-12-11 20:06:22 0.0078125 
2016-12-11 20:06:22 Epoch 81 
2016-12-11 20:11:08 Training Error = 0.90168095198469 
2016-12-11 20:11:08 Training Loss = 0.015222442573351 
2016-12-11 20:11:15 Valid Error = 0.95544739797829 
2016-12-11 20:11:15 Valid Loss = 0.015671598841935 
2016-12-11 20:11:22 Test Error = 0.96463455708993 
2016-12-11 20:11:22 Test Loss = 0.015731285039857 
2016-12-11 20:11:22 -------------------LR------------------- 
2016-12-11 20:11:22 0.0078125 
2016-12-11 20:11:22 Epoch 82 
2016-12-11 20:16:06 Training Error = 0.90292918365649 
2016-12-11 20:16:06 Training Loss = 0.015226466558192 
2016-12-11 20:16:12 Valid Error = 0.94795956570573 
2016-12-11 20:16:12 Valid Loss = 0.015675087541096 
2016-12-11 20:16:19 Test Error = 0.95655102728191 
2016-12-11 20:16:19 Test Loss = 0.01573353694747 
2016-12-11 20:16:19 -------------------LR------------------- 
2016-12-11 20:16:19 0.0078125 
2016-12-11 20:16:19 Epoch 83 
2016-12-11 20:21:06 Training Error = 0.90084879753682 
2016-12-11 20:21:06 Training Loss = 0.015214641504718 
2016-12-11 20:21:13 Valid Error = 0.95207787345563 
2016-12-11 20:21:13 Valid Loss = 0.015672128429466 
2016-12-11 20:21:20 Test Error = 0.96227686089592 
2016-12-11 20:21:20 Test Loss = 0.015722795086046 
2016-12-11 20:21:20 -------------------LR------------------- 
2016-12-11 20:21:20 0.0078125 
2016-12-11 20:21:20 Epoch 84 
2016-12-11 20:26:06 Training Error = 0.90384455354914 
2016-12-11 20:26:06 Training Loss = 0.015220383704849 
2016-12-11 20:26:13 Valid Error = 0.95544739797829 
2016-12-11 20:26:13 Valid Loss = 0.015750305288778 
2016-12-11 20:26:20 Test Error = 0.96463455708993 
2016-12-11 20:26:20 Test Loss = 0.015787640309169 
2016-12-11 20:26:20 -------------------LR------------------- 
2016-12-11 20:26:20 0.0078125 
2016-12-11 20:26:20 Epoch 85 
2016-12-11 20:31:07 Training Error = 0.90255471415495 
2016-12-11 20:31:07 Training Loss = 0.015226413701777 
2016-12-11 20:31:13 Valid Error = 0.95132909022838 
2016-12-11 20:31:13 Valid Loss = 0.015666172588865 
2016-12-11 20:31:20 Test Error = 0.95890872347592 
2016-12-11 20:31:20 Test Loss = 0.015720829330232 
2016-12-11 20:31:20 -------------------LR------------------- 
2016-12-11 20:31:20 0.0078125 
2016-12-11 20:31:20 Epoch 86 
2016-12-11 20:36:07 Training Error = 0.90434384621786 
2016-12-11 20:36:07 Training Loss = 0.01522252471567 
2016-12-11 20:36:13 Valid Error = 0.95731935604642 
2016-12-11 20:36:13 Valid Loss = 0.015665987485662 
2016-12-11 20:36:20 Test Error = 0.96934994947794 
2016-12-11 20:36:20 Test Loss = 0.015723583924826 
2016-12-11 20:36:20 -------------------LR------------------- 
2016-12-11 20:36:20 0.0078125 
2016-12-11 20:36:20 Epoch 87 
2016-12-11 20:41:10 Training Error = 0.90367812265957 
2016-12-11 20:41:10 Training Loss = 0.015222702727062 
2016-12-11 20:41:16 Valid Error = 0.95544739797829 
2016-12-11 20:41:16 Valid Loss = 0.015733438774879 
2016-12-11 20:41:23 Test Error = 0.96463455708993 
2016-12-11 20:41:23 Test Loss = 0.015769774190966 
2016-12-11 20:41:23 -------------------LR------------------- 
2016-12-11 20:41:23 0.0078125 
2016-12-11 20:41:23 Epoch 88 
2016-12-11 20:46:09 Training Error = 0.90434384621786 
2016-12-11 20:46:09 Training Loss = 0.015228742192681 
2016-12-11 20:46:16 Valid Error = 0.95731935604642 
2016-12-11 20:46:16 Valid Loss = 0.015691421576993 
2016-12-11 20:46:23 Test Error = 0.96934994947794 
2016-12-11 20:46:23 Test Loss = 0.015752029465486 
2016-12-11 20:46:23 -------------------LR------------------- 
2016-12-11 20:46:23 0.0078125 
2016-12-11 20:46:23 Epoch 89 
2016-12-11 20:51:07 Training Error = 0.90421902305068 
2016-12-11 20:51:07 Training Loss = 0.015228856857755 
2016-12-11 20:51:13 Valid Error = 0.95207787345563 
2016-12-11 20:51:13 Valid Loss = 0.015658368284571 
2016-12-11 20:51:20 Test Error = 0.96227686089592 
2016-12-11 20:51:20 Test Loss = 0.015715356918816 
2016-12-11 20:51:20 -------------------LR------------------- 
2016-12-11 20:51:20 0.0078125 
2016-12-11 20:51:20 Epoch 90 
2016-12-11 20:56:10 Training Error = 0.90388616127153 
2016-12-11 20:56:10 Training Loss = 0.015227078544977 
2016-12-11 20:56:16 Valid Error = 0.95731935604642 
2016-12-11 20:56:16 Valid Loss = 0.015669938198363 
2016-12-11 20:56:23 Test Error = 0.96934994947794 
2016-12-11 20:56:23 Test Loss = 0.015727583283358 
2016-12-11 20:56:23 -------------------LR------------------- 
2016-12-11 20:56:23 0.0078125 
2016-12-11 20:56:23 Epoch 91 
2016-12-11 21:01:10 Training Error = 0.90438545394025 
2016-12-11 21:01:10 Training Loss = 0.015225249226873 
2016-12-11 21:01:17 Valid Error = 0.95544739797829 
2016-12-11 21:01:17 Valid Loss = 0.015714459025683 
2016-12-11 21:01:24 Test Error = 0.96463455708993 
2016-12-11 21:01:24 Test Loss = 0.015750688871091 
2016-12-11 21:01:24 -------------------LR------------------- 
2016-12-11 21:01:24 0.0078125 
2016-12-11 21:01:24 Epoch 92 
2016-12-11 21:06:14 Training Error = 0.90405259216111 
2016-12-11 21:06:14 Training Loss = 0.015225814713228 
2016-12-11 21:06:20 Valid Error = 0.95207787345563 
2016-12-11 21:06:20 Valid Loss = 0.015690223460753 
2016-12-11 21:06:27 Test Error = 0.96227686089592 
2016-12-11 21:06:27 Test Loss = 0.015745328228535 
2016-12-11 21:06:27 -------------------LR------------------- 
2016-12-11 21:06:27 0.0078125 
2016-12-11 21:06:27 Epoch 93 
2016-12-11 21:11:11 Training Error = 0.90392776899393 
2016-12-11 21:11:11 Training Loss = 0.015221527772189 
2016-12-11 21:11:18 Valid Error = 0.95544739797829 
2016-12-11 21:11:18 Valid Loss = 0.015716280167862 
2016-12-11 21:11:25 Test Error = 0.96463455708993 
2016-12-11 21:11:25 Test Loss = 0.015760709085019 
2016-12-11 21:11:25 -------------------LR------------------- 
2016-12-11 21:11:25 0.0078125 
2016-12-11 21:11:25 Epoch 94 
2016-12-11 21:16:08 Training Error = 0.904676707997 
2016-12-11 21:16:08 Training Loss = 0.015225988701119 
2016-12-11 21:16:14 Valid Error = 0.95731935604642 
2016-12-11 21:16:14 Valid Loss = 0.01564746035566 
2016-12-11 21:16:21 Test Error = 0.96934994947794 
2016-12-11 21:16:21 Test Loss = 0.015703718325084 
2016-12-11 21:16:21 -------------------LR------------------- 
2016-12-11 21:16:21 0.0078125 
2016-12-11 21:16:21 Epoch 95 
2016-12-11 21:21:08 Training Error = 0.90338686860281 
2016-12-11 21:21:08 Training Loss = 0.015219330590983 
2016-12-11 21:21:14 Valid Error = 0.95731935604642 
2016-12-11 21:21:14 Valid Loss = 0.015668631500887 
2016-12-11 21:21:21 Test Error = 0.96934994947794 
2016-12-11 21:21:21 Test Loss = 0.015724949646719 
2016-12-11 21:21:21 -------------------LR------------------- 
2016-12-11 21:21:21 0.0078125 
2016-12-11 21:21:21 Epoch 96 
2016-12-11 21:26:05 Training Error = 0.90230506782059 
2016-12-11 21:26:05 Training Loss = 0.015218507243968 
2016-12-11 21:26:11 Valid Error = 0.95132909022838 
2016-12-11 21:26:11 Valid Loss = 0.015714259520688 
2016-12-11 21:26:18 Test Error = 0.95890872347592 
2016-12-11 21:26:18 Test Loss = 0.015762214203184 
2016-12-11 21:26:18 -------------------LR------------------- 
2016-12-11 21:26:18 0.0078125 
2016-12-11 21:26:18 Epoch 97 
2016-12-11 21:31:05 Training Error = 0.90330365315803 
2016-12-11 21:31:05 Training Loss = 0.015231336126209 
2016-12-11 21:31:12 Valid Error = 0.95731935604642 
2016-12-11 21:31:12 Valid Loss = 0.01570818014144 
2016-12-11 21:31:19 Test Error = 0.96934994947794 
2016-12-11 21:31:19 Test Loss = 0.015771406260754 
2016-12-11 21:31:19 -------------------LR------------------- 
2016-12-11 21:31:19 0.0078125 
2016-12-11 21:31:19 Epoch 98 
2016-12-11 21:36:02 Training Error = 0.90392776899393 
2016-12-11 21:36:02 Training Loss = 0.015226755242414 
2016-12-11 21:36:08 Valid Error = 0.95207787345563 
2016-12-11 21:36:08 Valid Loss = 0.015666594698285 
2016-12-11 21:36:15 Test Error = 0.96227686089592 
2016-12-11 21:36:15 Test Loss = 0.015715936651625 
2016-12-11 21:36:15 -------------------LR------------------- 
2016-12-11 21:36:15 0.0078125 
2016-12-11 21:36:15 Epoch 99 
2016-12-11 21:41:02 Training Error = 0.90413580760589 
2016-12-11 21:41:02 Training Loss = 0.015226364609469 
2016-12-11 21:41:08 Valid Error = 0.95544739797829 
2016-12-11 21:41:08 Valid Loss = 0.015666830092579 
2016-12-11 21:41:15 Test Error = 0.96463455708993 
2016-12-11 21:41:15 Test Loss = 0.01572681977385 
2016-12-11 21:41:15 -------------------LR------------------- 
2016-12-11 21:41:15 0.0078125 
2016-12-11 21:41:15 Epoch 100 
2016-12-11 21:46:03 Training Error = 0.90205542148623 
2016-12-11 21:46:03 Training Loss = 0.015216121275203 
2016-12-11 21:46:09 Valid Error = 0.95207787345563 
2016-12-11 21:46:09 Valid Loss = 0.015667886056281 
2016-12-11 21:46:16 Test Error = 0.96227686089592 
2016-12-11 21:46:16 Test Loss = 0.015722408681531 
2016-12-11 21:46:16 -------------------LR------------------- 
2016-12-11 21:46:16 0.00390625 
2016-12-11 21:46:16 Epoch 101 
2016-12-11 21:51:02 Training Error = 0.90205542148623 
2016-12-11 21:51:02 Training Loss = 0.015218274215144 
2016-12-11 21:51:08 Valid Error = 0.95731935604642 
2016-12-11 21:51:08 Valid Loss = 0.015653592953928 
2016-12-11 21:51:15 Test Error = 0.96934994947794 
2016-12-11 21:51:15 Test Loss = 0.015713632962125 
2016-12-11 21:51:15 -------------------LR------------------- 
2016-12-11 21:51:15 0.00390625 
2016-12-11 21:51:15 Epoch 102 
2016-12-11 21:56:03 Training Error = 0.90334526088042 
2016-12-11 21:56:03 Training Loss = 0.015222503115721 
2016-12-11 21:56:09 Valid Error = 0.95320104829652 
2016-12-11 21:56:09 Valid Loss = 0.015645870985633 
2016-12-11 21:56:16 Test Error = 0.96362411586393 
2016-12-11 21:56:16 Test Loss = 0.015699726800466 
2016-12-11 21:56:16 -------------------LR------------------- 
2016-12-11 21:56:16 0.00390625 
2016-12-11 21:56:16 Epoch 103 
2016-12-11 22:01:00 Training Error = 0.90430223849546 
2016-12-11 22:01:00 Training Loss = 0.015228915986613 
2016-12-11 22:01:07 Valid Error = 0.94795956570573 
2016-12-11 22:01:07 Valid Loss = 0.015650590904742 
2016-12-11 22:01:14 Test Error = 0.95655102728191 
2016-12-11 22:01:14 Test Loss = 0.015711175041058 
2016-12-11 22:01:14 -------------------LR------------------- 
2016-12-11 22:01:14 0.00390625 
2016-12-11 22:01:14 Epoch 104 
2016-12-11 22:06:06 Training Error = 0.90417741532828 
2016-12-11 22:06:06 Training Loss = 0.015225710386451 
2016-12-11 22:06:13 Valid Error = 0.95731935604642 
2016-12-11 22:06:13 Valid Loss = 0.015656193708839 
2016-12-11 22:06:20 Test Error = 0.96934994947794 
2016-12-11 22:06:20 Test Loss = 0.0157123030762 
2016-12-11 22:06:20 -------------------LR------------------- 
2016-12-11 22:06:20 0.00390625 
2016-12-11 22:06:20 Epoch 105 
2016-12-11 22:11:06 Training Error = 0.90384455354914 
2016-12-11 22:11:06 Training Loss = 0.015224573888805 
2016-12-11 22:11:13 Valid Error = 0.95207787345563 
2016-12-11 22:11:13 Valid Loss = 0.01567075246492 
2016-12-11 22:11:20 Test Error = 0.96227686089592 
2016-12-11 22:11:20 Test Loss = 0.015725263118934 
2016-12-11 22:11:20 -------------------LR------------------- 
2016-12-11 22:11:20 0.00390625 
2016-12-11 22:11:20 Epoch 106 
2016-12-11 22:16:07 Training Error = 0.90363651493717 
2016-12-11 22:16:07 Training Loss = 0.015219080349092 
2016-12-11 22:16:14 Valid Error = 0.95320104829652 
2016-12-11 22:16:14 Valid Loss = 0.015678177139744 
2016-12-11 22:16:21 Test Error = 0.96362411586393 
2016-12-11 22:16:21 Test Loss = 0.015738087135424 
2016-12-11 22:16:21 -------------------LR------------------- 
2016-12-11 22:16:21 0.00390625 
2016-12-11 22:16:21 Epoch 107 
2016-12-11 22:21:05 Training Error = 0.90292918365649 
2016-12-11 22:21:05 Training Loss = 0.015225989591174 
2016-12-11 22:21:12 Valid Error = 0.95320104829652 
2016-12-11 22:21:12 Valid Loss = 0.015664759456471 
2016-12-11 22:21:19 Test Error = 0.96362411586393 
2016-12-11 22:21:19 Test Loss = 0.015720332336859 
2016-12-11 22:21:19 -------------------LR------------------- 
2016-12-11 22:21:19 0.00390625 
2016-12-11 22:21:19 Epoch 108 
2016-12-11 22:26:03 Training Error = 0.9034700840476 
2016-12-11 22:26:03 Training Loss = 0.015226661813906 
2016-12-11 22:26:09 Valid Error = 0.95207787345563 
2016-12-11 22:26:09 Valid Loss = 0.015672085788449 
2016-12-11 22:26:16 Test Error = 0.96227686089592 
2016-12-11 22:26:16 Test Loss = 0.015731508202357 
2016-12-11 22:26:16 -------------------LR------------------- 
2016-12-11 22:26:16 0.00390625 
2016-12-11 22:26:16 Epoch 109 
2016-12-11 22:31:02 Training Error = 0.90242989098777 
2016-12-11 22:31:02 Training Loss = 0.015215476694096 
2016-12-11 22:31:09 Valid Error = 0.95731935604642 
2016-12-11 22:31:09 Valid Loss = 0.015681956135935 
2016-12-11 22:31:16 Test Error = 0.96934994947794 
2016-12-11 22:31:16 Test Loss = 0.01573753326841 
2016-12-11 22:31:16 -------------------LR------------------- 
2016-12-11 22:31:16 0.00390625 
2016-12-11 22:31:16 Epoch 110 
2016-12-11 22:36:04 Training Error = 0.90267953732213 
2016-12-11 22:36:04 Training Loss = 0.015224998486061 
2016-12-11 22:36:11 Valid Error = 0.95132909022838 
2016-12-11 22:36:11 Valid Loss = 0.015710402986181 
2016-12-11 22:36:18 Test Error = 0.95890872347592 
2016-12-11 22:36:18 Test Loss = 0.015752640206143 
2016-12-11 22:36:18 -------------------LR------------------- 
2016-12-11 22:36:18 0.00390625 
2016-12-11 22:36:18 Epoch 111 
2016-12-11 22:41:05 Training Error = 0.90326204543563 
2016-12-11 22:41:05 Training Loss = 0.015221861937676 
2016-12-11 22:41:11 Valid Error = 0.95207787345563 
2016-12-11 22:41:11 Valid Loss = 0.015661668399477 
2016-12-11 22:41:18 Test Error = 0.96227686089592 
2016-12-11 22:41:18 Test Loss = 0.015717376862772 
2016-12-11 22:41:18 -------------------LR------------------- 
2016-12-11 22:41:18 0.00390625 
2016-12-11 22:41:18 Epoch 112 
2016-12-11 22:46:04 Training Error = 0.90334526088042 
2016-12-11 22:46:04 Training Loss = 0.015220624072019 
2016-12-11 22:46:10 Valid Error = 0.95731935604642 
2016-12-11 22:46:10 Valid Loss = 0.015689097478956 
2016-12-11 22:46:17 Test Error = 0.96934994947794 
2016-12-11 22:46:17 Test Loss = 0.015747238764212 
2016-12-11 22:46:17 -------------------LR------------------- 
2016-12-11 22:46:17 0.00390625 
2016-12-11 22:46:17 Epoch 113 
2016-12-11 22:51:01 Training Error = 0.90259632187734 
2016-12-11 22:51:01 Training Loss = 0.015227682830326 
2016-12-11 22:51:08 Valid Error = 0.9502059153875 
2016-12-11 22:51:08 Valid Loss = 0.015698587756222 
2016-12-11 22:51:15 Test Error = 0.95756146850792 
2016-12-11 22:51:15 Test Loss = 0.01573664757585 
2016-12-11 22:51:15 -------------------LR------------------- 
2016-12-11 22:51:15 0.00390625 
2016-12-11 22:51:15 Epoch 114 
2016-12-11 22:56:02 Training Error = 0.90338686860281 
2016-12-11 22:56:02 Training Loss = 0.01521997962645 
2016-12-11 22:56:08 Valid Error = 0.95207787345563 
2016-12-11 22:56:08 Valid Loss = 0.015653984657205 
2016-12-11 22:56:15 Test Error = 0.96227686089592 
2016-12-11 22:56:15 Test Loss = 0.015707170088359 
2016-12-11 22:56:15 -------------------LR------------------- 
2016-12-11 22:56:15 0.00390625 
2016-12-11 22:56:15 Epoch 115 
2016-12-11 23:01:02 Training Error = 0.90230506782059 
2016-12-11 23:01:02 Training Loss = 0.015212447276143 
2016-12-11 23:01:08 Valid Error = 0.95207787345563 
2016-12-11 23:01:08 Valid Loss = 0.015684116930422 
2016-12-11 23:01:15 Test Error = 0.96227686089592 
2016-12-11 23:01:15 Test Loss = 0.01574624680041 
2016-12-11 23:01:15 -------------------LR------------------- 
2016-12-11 23:01:15 0.00390625 
2016-12-11 23:01:15 Epoch 116 
2016-12-11 23:06:01 Training Error = 0.90272114504452 
2016-12-11 23:06:01 Training Loss = 0.015222689375667 
2016-12-11 23:06:08 Valid Error = 0.95731935604642 
2016-12-11 23:06:08 Valid Loss = 0.015675248533518 
2016-12-11 23:06:15 Test Error = 0.96934994947794 
2016-12-11 23:06:15 Test Loss = 0.015733797963677 
2016-12-11 23:06:15 -------------------LR------------------- 
2016-12-11 23:06:15 0.00390625 
2016-12-11 23:06:15 Epoch 117 
2016-12-11 23:10:59 Training Error = 0.90334526088042 
2016-12-11 23:10:59 Training Loss = 0.015219187892566 
2016-12-11 23:11:06 Valid Error = 0.95207787345563 
2016-12-11 23:11:06 Valid Loss = 0.015675335790811 
2016-12-11 23:11:13 Test Error = 0.96227686089592 
2016-12-11 23:11:13 Test Loss = 0.015732368662774 
2016-12-11 23:11:13 -------------------LR------------------- 
2016-12-11 23:11:13 0.00390625 
2016-12-11 23:11:13 Epoch 118 
2016-12-11 23:16:03 Training Error = 0.90238828326537 
2016-12-11 23:16:03 Training Loss = 0.015218029408512 
2016-12-11 23:16:09 Valid Error = 0.95544739797829 
2016-12-11 23:16:09 Valid Loss = 0.015673041511458 
2016-12-11 23:16:16 Test Error = 0.96463455708993 
2016-12-11 23:16:16 Test Loss = 0.015731285823249 
2016-12-11 23:16:16 -------------------LR------------------- 
2016-12-11 23:16:16 0.00390625 
2016-12-11 23:16:16 Epoch 119 
2016-12-11 23:21:01 Training Error = 0.90396937671632 
2016-12-11 23:21:01 Training Loss = 0.015227726690098 
2016-12-11 23:21:08 Valid Error = 0.95320104829652 
2016-12-11 23:21:08 Valid Loss = 0.015696662191217 
2016-12-11 23:21:15 Test Error = 0.96362411586393 
2016-12-11 23:21:15 Test Loss = 0.015758464236601 
2016-12-11 23:21:15 -------------------LR------------------- 
2016-12-11 23:21:15 0.00390625 
2016-12-11 23:21:15 Epoch 120 
2016-12-11 23:26:07 Training Error = 0.90480153116418 
2016-12-11 23:26:07 Training Loss = 0.015229784766986 
2016-12-11 23:26:13 Valid Error = 0.95731935604642 
2016-12-11 23:26:13 Valid Loss = 0.015682014206329 
2016-12-11 23:26:20 Test Error = 0.96934994947794 
2016-12-11 23:26:20 Test Loss = 0.015742351651442 
2016-12-11 23:26:20 -------------------LR------------------- 
2016-12-11 23:26:20 0.00390625 
2016-12-11 23:26:20 Epoch 121 
2016-12-11 23:31:48 Training Error = 0.90317882999085 
2016-12-11 23:31:48 Training Loss = 0.015223739862603 
2016-12-11 23:31:54 Valid Error = 0.95731935604642 
2016-12-11 23:31:54 Valid Loss = 0.015678567051928 
2016-12-11 23:32:01 Test Error = 0.96934994947794 
2016-12-11 23:32:01 Test Loss = 0.015732229228344 
2016-12-11 23:32:01 -------------------LR------------------- 
2016-12-11 23:32:01 0.00390625 
2016-12-11 23:32:01 Epoch 122 
2016-12-11 23:38:06 Training Error = 0.90193059831905 
2016-12-11 23:38:06 Training Loss = 0.01521806112797 
2016-12-11 23:38:12 Valid Error = 0.95731935604642 
2016-12-11 23:38:12 Valid Loss = 0.015673638420765 
2016-12-11 23:38:19 Test Error = 0.96934994947794 
2016-12-11 23:38:19 Test Loss = 0.015732790921179 
2016-12-11 23:38:19 -------------------LR------------------- 
2016-12-11 23:38:19 0.00390625 
2016-12-11 23:38:19 Epoch 123 
2016-12-11 23:44:29 Training Error = 0.90251310643255 
2016-12-11 23:44:29 Training Loss = 0.015223592028921 
2016-12-11 23:44:35 Valid Error = 0.9502059153875 
2016-12-11 23:44:35 Valid Loss = 0.015729787398957 
2016-12-11 23:44:42 Test Error = 0.95756146850792 
2016-12-11 23:44:42 Test Loss = 0.015759840823064 
2016-12-11 23:44:42 -------------------LR------------------- 
2016-12-11 23:44:42 0.00390625 
2016-12-11 23:44:42 Epoch 124 
2016-12-11 23:50:35 Training Error = 0.90338686860281 
2016-12-11 23:50:35 Training Loss = 0.015218815702755 
2016-12-11 23:50:41 Valid Error = 0.95544739797829 
2016-12-11 23:50:41 Valid Loss = 0.01571983443891 
2016-12-11 23:50:48 Test Error = 0.96463455708993 
2016-12-11 23:50:48 Test Loss = 0.015766429819965 
2016-12-11 23:50:48 -------------------LR------------------- 
2016-12-11 23:50:48 0.00390625 
2016-12-11 23:50:48 Epoch 125 
2016-12-11 23:56:39 Training Error = 0.90371973038196 
2016-12-11 23:56:39 Training Loss = 0.015228151979066 
2016-12-11 23:56:46 Valid Error = 0.95731935604642 
2016-12-11 23:56:46 Valid Loss = 0.015647827165918 
2016-12-11 23:56:53 Test Error = 0.96934994947794 
2016-12-11 23:56:53 Test Loss = 0.015714233823955 
2016-12-11 23:56:53 -------------------LR------------------- 
2016-12-11 23:56:53 0.00390625 
2016-12-11 23:56:53 Epoch 126 
2016-12-12 00:02:43 Training Error = 0.90475992344179 
2016-12-12 00:02:43 Training Loss = 0.015222549154328 
2016-12-12 00:02:50 Valid Error = 0.94795956570573 
2016-12-12 00:02:50 Valid Loss = 0.015627500233285 
2016-12-12 00:02:57 Test Error = 0.95655102728191 
2016-12-12 00:02:57 Test Loss = 0.015685240069996 
2016-12-12 00:02:57 -------------------LR------------------- 
2016-12-12 00:02:57 0.00390625 
2016-12-12 00:02:57 Epoch 127 
2016-12-12 00:08:34 Training Error = 0.90492635433136 
2016-12-12 00:08:34 Training Loss = 0.015222793407999 
2016-12-12 00:08:40 Valid Error = 0.95544739797829 
2016-12-12 00:08:40 Valid Loss = 0.015653806360033 
2016-12-12 00:08:47 Test Error = 0.96463455708993 
2016-12-12 00:08:47 Test Loss = 0.015712030481987 
2016-12-12 00:08:47 -------------------LR------------------- 
2016-12-12 00:08:47 0.00390625 
2016-12-12 00:08:47 Epoch 128 
2016-12-12 00:14:36 Training Error = 0.90451027710743 
2016-12-12 00:14:36 Training Loss = 0.015226163840794 
2016-12-12 00:14:43 Valid Error = 0.95544739797829 
2016-12-12 00:14:43 Valid Loss = 0.015768728448566 
2016-12-12 00:14:50 Test Error = 0.96463455708993 
2016-12-12 00:14:50 Test Loss = 0.015801818786372 
2016-12-12 00:14:50 -------------------LR------------------- 
2016-12-12 00:14:50 0.00390625 
2016-12-12 00:14:50 Epoch 129 
2016-12-12 00:20:33 Training Error = 0.90309561454606 
2016-12-12 00:20:33 Training Loss = 0.015219877505091 
2016-12-12 00:20:39 Valid Error = 0.95731935604642 
2016-12-12 00:20:39 Valid Loss = 0.015683477753424 
2016-12-12 00:20:46 Test Error = 0.96934994947794 
2016-12-12 00:20:46 Test Loss = 0.015742559251336 
2016-12-12 00:20:46 -------------------LR------------------- 
2016-12-12 00:20:46 0.00390625 
2016-12-12 00:20:46 Epoch 130 
2016-12-12 00:26:28 Training Error = 0.90351169176999 
2016-12-12 00:26:28 Training Loss = 0.015222318739873 
2016-12-12 00:26:34 Valid Error = 0.95731935604642 
2016-12-12 00:26:34 Valid Loss = 0.015697564087145 
2016-12-12 00:26:41 Test Error = 0.96934994947794 
2016-12-12 00:26:41 Test Loss = 0.015757053604119 
2016-12-12 00:26:41 -------------------LR------------------- 
2016-12-12 00:26:41 0.00390625 
2016-12-12 00:26:41 Epoch 131 
2016-12-12 00:32:25 Training Error = 0.90367812265957 
2016-12-12 00:32:25 Training Loss = 0.015222750899813 
2016-12-12 00:32:31 Valid Error = 0.9502059153875 
2016-12-12 00:32:31 Valid Loss = 0.015720064175245 
2016-12-12 00:32:38 Test Error = 0.95756146850792 
2016-12-12 00:32:38 Test Loss = 0.015764369898185 
2016-12-12 00:32:38 -------------------LR------------------- 
2016-12-12 00:32:38 0.00390625 
2016-12-12 00:32:38 Epoch 132 
2016-12-12 00:38:27 Training Error = 0.90242989098777 
2016-12-12 00:38:27 Training Loss = 0.015220301508198 
2016-12-12 00:38:33 Valid Error = 0.9502059153875 
2016-12-12 00:38:33 Valid Loss = 0.015743959262555 
2016-12-12 00:38:40 Test Error = 0.95756146850792 
2016-12-12 00:38:40 Test Loss = 0.01576772208749 
2016-12-12 00:38:40 -------------------LR------------------- 
2016-12-12 00:38:40 0.00390625 
2016-12-12 00:38:40 Epoch 133 
2016-12-12 00:44:22 Training Error = 0.90297079137888 
2016-12-12 00:44:22 Training Loss = 0.015218955927307 
2016-12-12 00:44:28 Valid Error = 0.95207787345563 
2016-12-12 00:44:28 Valid Loss = 0.015652336679893 
2016-12-12 00:44:35 Test Error = 0.96227686089592 
2016-12-12 00:44:35 Test Loss = 0.015705082522399 
2016-12-12 00:44:35 -------------------LR------------------- 
2016-12-12 00:44:35 0.00390625 
2016-12-12 00:44:35 Epoch 134 
2016-12-12 00:50:22 Training Error = 0.9022218523758 
2016-12-12 00:50:22 Training Loss = 0.015220176937438 
2016-12-12 00:50:28 Valid Error = 0.95544739797829 
2016-12-12 00:50:28 Valid Loss = 0.015711484597048 
2016-12-12 00:50:35 Test Error = 0.96463455708993 
2016-12-12 00:50:35 Test Loss = 0.015756117458837 
2016-12-12 00:50:35 -------------------LR------------------- 
2016-12-12 00:50:35 0.00390625 
2016-12-12 00:50:35 Epoch 135 
2016-12-12 00:56:22 Training Error = 0.90371973038196 
2016-12-12 00:56:22 Training Loss = 0.015220835079674 
2016-12-12 00:56:28 Valid Error = 0.95731935604642 
2016-12-12 00:56:28 Valid Loss = 0.015673669358179 
2016-12-12 00:56:35 Test Error = 0.96934994947794 
2016-12-12 00:56:35 Test Loss = 0.015730023255221 
2016-12-12 00:56:35 -------------------LR------------------- 
2016-12-12 00:56:35 0.00390625 
2016-12-12 00:56:35 Epoch 136 
2016-12-12 01:02:17 Training Error = 0.90367812265957 
2016-12-12 01:02:17 Training Loss = 0.0152201148615 
2016-12-12 01:02:24 Valid Error = 0.95207787345563 
2016-12-12 01:02:24 Valid Loss = 0.015683296442171 
2016-12-12 01:02:31 Test Error = 0.96227686089592 
2016-12-12 01:02:31 Test Loss = 0.015748484881019 
2016-12-12 01:02:31 -------------------LR------------------- 
2016-12-12 01:02:31 0.00390625 
2016-12-12 01:02:31 Epoch 137 
2016-12-12 01:08:24 Training Error = 0.90363651493717 
2016-12-12 01:08:24 Training Loss = 0.015225831898544 
2016-12-12 01:08:31 Valid Error = 0.95731935604642 
2016-12-12 01:08:31 Valid Loss = 0.01566236932145 
2016-12-12 01:08:38 Test Error = 0.96934994947794 
2016-12-12 01:08:38 Test Loss = 0.01571927457858 
2016-12-12 01:08:38 -------------------LR------------------- 
2016-12-12 01:08:38 0.00390625 
2016-12-12 01:08:38 Epoch 138 
2016-12-12 01:14:22 Training Error = 0.90334526088042 
2016-12-12 01:14:22 Training Loss = 0.015227599511979 
2016-12-12 01:14:28 Valid Error = 0.9502059153875 
2016-12-12 01:14:28 Valid Loss = 0.015676830384572 
2016-12-12 01:14:35 Test Error = 0.95756146850792 
2016-12-12 01:14:35 Test Loss = 0.015734300174263 
2016-12-12 01:14:35 -------------------LR------------------- 
2016-12-12 01:14:35 0.00390625 
2016-12-12 01:14:35 Epoch 139 
2016-12-12 01:20:15 Training Error = 0.90305400682367 
2016-12-12 01:20:15 Training Loss = 0.015220542940102 
2016-12-12 01:20:21 Valid Error = 0.95731935604642 
2016-12-12 01:20:21 Valid Loss = 0.015659507154876 
2016-12-12 01:20:28 Test Error = 0.96934994947794 
2016-12-12 01:20:28 Test Loss = 0.01571179178521 
2016-12-12 01:20:28 -------------------LR------------------- 
2016-12-12 01:20:28 0.00390625 
2016-12-12 01:20:28 Epoch 140 
2016-12-12 01:26:17 Training Error = 0.90371973038196 
2016-12-12 01:26:17 Training Loss = 0.015231154447105 
2016-12-12 01:26:24 Valid Error = 0.95731935604642 
2016-12-12 01:26:24 Valid Loss = 0.015677907270173 
2016-12-12 01:26:31 Test Error = 0.96934994947794 
2016-12-12 01:26:31 Test Loss = 0.015740205464675 
2016-12-12 01:26:31 -------------------LR------------------- 
2016-12-12 01:26:31 0.00390625 
2016-12-12 01:26:31 Epoch 141 
2016-12-12 01:32:16 Training Error = 0.90367812265957 
2016-12-12 01:32:16 Training Loss = 0.015224467532168 
2016-12-12 01:32:23 Valid Error = 0.9502059153875 
2016-12-12 01:32:23 Valid Loss = 0.015686800686203 
2016-12-12 01:32:30 Test Error = 0.95756146850792 
2016-12-12 01:32:30 Test Loss = 0.015749854072382 
2016-12-12 01:32:30 -------------------LR------------------- 
2016-12-12 01:32:30 0.00390625 
2016-12-12 01:32:30 Epoch 142 
2016-12-12 01:37:59 Training Error = 0.90301239910127 
2016-12-12 01:37:59 Training Loss = 0.015219626827374 
2016-12-12 01:38:06 Valid Error = 0.95207787345563 
2016-12-12 01:38:06 Valid Loss = 0.015669474278236 
2016-12-12 01:38:13 Test Error = 0.96227686089592 
2016-12-12 01:38:13 Test Loss = 0.015724317616893 
2016-12-12 01:38:13 -------------------LR------------------- 
2016-12-12 01:38:13 0.00390625 
2016-12-12 01:38:13 Epoch 143 
2016-12-12 01:43:55 Training Error = 0.90405259216111 
2016-12-12 01:43:55 Training Loss = 0.015223102629773 
2016-12-12 01:44:01 Valid Error = 0.95207787345563 
2016-12-12 01:44:01 Valid Loss = 0.015685004412071 
2016-12-12 01:44:08 Test Error = 0.96227686089592 
2016-12-12 01:44:08 Test Loss = 0.015741345248955 
2016-12-12 01:44:08 -------------------LR------------------- 
2016-12-12 01:44:08 0.00390625 
2016-12-12 01:44:08 Epoch 144 
2016-12-12 01:50:03 Training Error = 0.90251310643255 
2016-12-12 01:50:03 Training Loss = 0.015220661131216 
2016-12-12 01:50:09 Valid Error = 0.95207787345563 
2016-12-12 01:50:09 Valid Loss = 0.015669974386698 
2016-12-12 01:50:16 Test Error = 0.96227686089592 
2016-12-12 01:50:16 Test Loss = 0.015724792712306 
2016-12-12 01:50:16 -------------------LR------------------- 
2016-12-12 01:50:16 0.00390625 
2016-12-12 01:50:16 Epoch 145 
2016-12-12 01:55:58 Training Error = 0.90330365315803 
2016-12-12 01:55:58 Training Loss = 0.015223555524437 
2016-12-12 01:56:04 Valid Error = 0.95320104829652 
2016-12-12 01:56:04 Valid Loss = 0.015689373290539 
2016-12-12 01:56:11 Test Error = 0.96362411586393 
2016-12-12 01:56:11 Test Loss = 0.01574948732897 
2016-12-12 01:56:11 -------------------LR------------------- 
2016-12-12 01:56:11 0.00390625 
2016-12-12 01:56:11 Epoch 146 
2016-12-12 02:02:04 Training Error = 0.90376133810435 
2016-12-12 02:02:04 Training Loss = 0.015225745265644 
2016-12-12 02:02:11 Valid Error = 0.95320104829652 
2016-12-12 02:02:11 Valid Loss = 0.015675725165479 
2016-12-12 02:02:18 Test Error = 0.96362411586393 
2016-12-12 02:02:18 Test Loss = 0.015738301619334 
2016-12-12 02:02:18 -------------------LR------------------- 
2016-12-12 02:02:18 0.00390625 
2016-12-12 02:02:18 Epoch 147 
2016-12-12 02:08:03 Training Error = 0.9022218523758 
2016-12-12 02:08:03 Training Loss = 0.015217958545663 
2016-12-12 02:08:09 Valid Error = 0.95731935604642 
2016-12-12 02:08:09 Valid Loss = 0.015652623206824 
2016-12-12 02:08:16 Test Error = 0.96934994947794 
2016-12-12 02:08:16 Test Loss = 0.015707926296427 
2016-12-12 02:08:16 -------------------LR------------------- 
2016-12-12 02:08:16 0.00390625 
2016-12-12 02:08:16 Epoch 148 
2016-12-12 02:13:52 Training Error = 0.90438545394025 
2016-12-12 02:13:52 Training Loss = 0.015226672011992 
2016-12-12 02:13:58 Valid Error = 0.95731935604642 
2016-12-12 02:13:58 Valid Loss = 0.01569003242303 
2016-12-12 02:14:05 Test Error = 0.96934994947794 
2016-12-12 02:14:05 Test Loss = 0.015752557963337 
2016-12-12 02:14:05 -------------------LR------------------- 
2016-12-12 02:14:05 0.00390625 
2016-12-12 02:14:05 Epoch 149 
2016-12-12 02:19:53 Training Error = 0.90459349255222 
2016-12-12 02:19:53 Training Loss = 0.015234810657353 
2016-12-12 02:20:00 Valid Error = 0.9502059153875 
2016-12-12 02:20:00 Valid Loss = 0.015690445910976 
2016-12-12 02:20:07 Test Error = 0.95756146850792 
2016-12-12 02:20:07 Test Loss = 0.015750780449842 
2016-12-12 02:20:07 -------------------LR------------------- 
2016-12-12 02:20:07 0.00390625 
2016-12-12 02:20:07 Epoch 150 
2016-12-12 02:25:59 Training Error = 0.90313722226845 
2016-12-12 02:25:59 Training Loss = 0.015217936351858 
2016-12-12 02:26:06 Valid Error = 0.9502059153875 
2016-12-12 02:26:06 Valid Loss = 0.01568004776518 
2016-12-12 02:26:13 Test Error = 0.95756146850792 
2016-12-12 02:26:13 Test Loss = 0.015740000937642 
2016-12-12 02:26:13 -------------------LR------------------- 
2016-12-12 02:26:13 0.001953125 
2016-12-12 02:26:13 Epoch 151 
2016-12-12 02:31:46 Training Error = 0.90218024465341 
2016-12-12 02:31:46 Training Loss = 0.015218180899098 
2016-12-12 02:31:52 Valid Error = 0.95207787345563 
2016-12-12 02:31:52 Valid Loss = 0.015667156920055 
2016-12-12 02:31:59 Test Error = 0.96227686089592 
2016-12-12 02:31:59 Test Loss = 0.015729751880903 
2016-12-12 02:31:59 -------------------LR------------------- 
2016-12-12 02:31:59 0.001953125 
2016-12-12 02:31:59 Epoch 152 
2016-12-12 02:37:46 Training Error = 0.9022218523758 
2016-12-12 02:37:46 Training Loss = 0.015221452466957 
2016-12-12 02:37:52 Valid Error = 0.95544739797829 
2016-12-12 02:37:52 Valid Loss = 0.015678818047279 
2016-12-12 02:37:59 Test Error = 0.96463455708993 
2016-12-12 02:37:59 Test Loss = 0.015737140490962 
2016-12-12 02:37:59 -------------------LR------------------- 
2016-12-12 02:37:59 0.001953125 
2016-12-12 02:37:59 Epoch 153 
2016-12-12 02:43:46 Training Error = 0.90355329949239 
2016-12-12 02:43:46 Training Loss = 0.015223455974507 
2016-12-12 02:43:53 Valid Error = 0.94795956570573 
2016-12-12 02:43:53 Valid Loss = 0.015678111670242 
2016-12-12 02:44:00 Test Error = 0.95655102728191 
2016-12-12 02:44:00 Test Loss = 0.015734945153463 
2016-12-12 02:44:00 -------------------LR------------------- 
2016-12-12 02:44:00 0.001953125 
2016-12-12 02:44:00 Epoch 154 
2016-12-12 02:49:40 Training Error = 0.90213863693101 
2016-12-12 02:49:40 Training Loss = 0.015222907489441 
2016-12-12 02:49:46 Valid Error = 0.95207787345563 
2016-12-12 02:49:46 Valid Loss = 0.015674837613909 
2016-12-12 02:49:53 Test Error = 0.96227686089592 
2016-12-12 02:49:53 Test Loss = 0.015730081930953 
2016-12-12 02:49:53 -------------------LR------------------- 
2016-12-12 02:49:53 0.001953125 
2016-12-12 02:49:53 Epoch 155 
2016-12-12 02:55:43 Training Error = 0.90338686860281 
2016-12-12 02:55:43 Training Loss = 0.015219818390254 
2016-12-12 02:55:49 Valid Error = 0.95544739797829 
2016-12-12 02:55:49 Valid Loss = 0.015667697267882 
2016-12-12 02:55:56 Test Error = 0.96463455708993 
2016-12-12 02:55:56 Test Loss = 0.015724562226975 
2016-12-12 02:55:56 -------------------LR------------------- 
2016-12-12 02:55:56 0.001953125 
2016-12-12 02:55:56 Epoch 156 
2016-12-12 03:01:40 Training Error = 0.90276275276691 
2016-12-12 03:01:40 Training Loss = 0.015218769003106 
2016-12-12 03:01:47 Valid Error = 0.95207787345563 
2016-12-12 03:01:47 Valid Loss = 0.015669768901609 
2016-12-12 03:01:54 Test Error = 0.96227686089592 
2016-12-12 03:01:54 Test Loss = 0.015728309543903 
2016-12-12 03:01:54 -------------------LR------------------- 
2016-12-12 03:01:54 0.001953125 
2016-12-12 03:01:54 Epoch 157 
2016-12-12 03:07:33 Training Error = 0.90413580760589 
2016-12-12 03:07:33 Training Loss = 0.015223087088734 
2016-12-12 03:07:39 Valid Error = 0.95731935604642 
2016-12-12 03:07:39 Valid Loss = 0.015676349222124 
2016-12-12 03:07:46 Test Error = 0.96934994947794 
2016-12-12 03:07:46 Test Loss = 0.015731954691552 
2016-12-12 03:07:46 -------------------LR------------------- 
2016-12-12 03:07:46 0.001953125 
2016-12-12 03:07:46 Epoch 158 
2016-12-12 03:13:30 Training Error = 0.90267953732213 
2016-12-12 03:13:30 Training Loss = 0.015224247102267 
2016-12-12 03:13:37 Valid Error = 0.95731935604642 
2016-12-12 03:13:37 Valid Loss = 0.015668164190854 
2016-12-12 03:13:44 Test Error = 0.96934994947794 
2016-12-12 03:13:44 Test Loss = 0.015723392184128 
2016-12-12 03:13:44 -------------------LR------------------- 
2016-12-12 03:13:44 0.001953125 
2016-12-12 03:13:44 Epoch 159 
2016-12-12 03:19:28 Training Error = 0.90413580760589 
2016-12-12 03:19:28 Training Loss = 0.015220087491827 
2016-12-12 03:19:35 Valid Error = 0.95731935604642 
2016-12-12 03:19:35 Valid Loss = 0.0156717738391 
2016-12-12 03:19:42 Test Error = 0.96934994947794 
2016-12-12 03:19:42 Test Loss = 0.015727802749754 
2016-12-12 03:19:42 -------------------LR------------------- 
2016-12-12 03:19:42 0.001953125 
2016-12-12 03:19:42 Epoch 160 
2016-12-12 03:25:25 Training Error = 0.90242989098777 
2016-12-12 03:25:25 Training Loss = 0.015220316045552 
2016-12-12 03:25:31 Valid Error = 0.95731935604642 
2016-12-12 03:25:31 Valid Loss = 0.015680074525457 
2016-12-12 03:25:38 Test Error = 0.96934994947794 
2016-12-12 03:25:38 Test Loss = 0.015736817882842 
2016-12-12 03:25:38 -------------------LR------------------- 
2016-12-12 03:25:38 0.001953125 
2016-12-12 03:25:38 Epoch 161 
2016-12-12 03:31:22 Training Error = 0.90172255970708 
2016-12-12 03:31:22 Training Loss = 0.01522499451368 
2016-12-12 03:31:28 Valid Error = 0.95731935604642 
2016-12-12 03:31:28 Valid Loss = 0.015665715606495 
2016-12-12 03:31:35 Test Error = 0.96934994947794 
2016-12-12 03:31:35 Test Loss = 0.015722455258346 
2016-12-12 03:31:35 -------------------LR------------------- 
2016-12-12 03:31:35 0.001953125 
2016-12-12 03:31:35 Epoch 162 
2016-12-12 03:37:23 Training Error = 0.90338686860281 
2016-12-12 03:37:23 Training Loss = 0.015223455990573 
2016-12-12 03:37:29 Valid Error = 0.95544739797829 
2016-12-12 03:37:29 Valid Loss = 0.015669543499109 
2016-12-12 03:37:36 Test Error = 0.96463455708993 
2016-12-12 03:37:36 Test Loss = 0.015725925124034 
2016-12-12 03:37:36 -------------------LR------------------- 
2016-12-12 03:37:36 0.001953125 
2016-12-12 03:37:36 Epoch 163 
2016-12-12 03:43:14 Training Error = 0.904676707997 
2016-12-12 03:43:14 Training Loss = 0.015227921108921 
2016-12-12 03:43:21 Valid Error = 0.95731935604642 
2016-12-12 03:43:21 Valid Loss = 0.015686843609399 
2016-12-12 03:43:28 Test Error = 0.96934994947794 
2016-12-12 03:43:28 Test Loss = 0.015750185702513 
2016-12-12 03:43:28 -------------------LR------------------- 
2016-12-12 03:43:28 0.001953125 
2016-12-12 03:43:28 Epoch 164 
2016-12-12 03:49:19 Training Error = 0.90184738287426 
2016-12-12 03:49:19 Training Loss = 0.015217980574428 
2016-12-12 03:49:25 Valid Error = 0.94795956570573 
2016-12-12 03:49:25 Valid Loss = 0.015668996156089 
2016-12-12 03:49:32 Test Error = 0.95655102728191 
2016-12-12 03:49:32 Test Loss = 0.015728531441413 
2016-12-12 03:49:32 -------------------LR------------------- 
2016-12-12 03:49:32 0.001953125 
2016-12-12 03:49:32 Epoch 165 
2016-12-12 03:55:21 Training Error = 0.90426063077307 
2016-12-12 03:55:21 Training Loss = 0.01522329390259 
2016-12-12 03:55:28 Valid Error = 0.95207787345563 
2016-12-12 03:55:28 Valid Loss = 0.015692700696369 
2016-12-12 03:55:35 Test Error = 0.96227686089592 
2016-12-12 03:55:35 Test Loss = 0.015755120775606 
2016-12-12 03:55:35 -------------------LR------------------- 
2016-12-12 03:55:35 0.001953125 
2016-12-12 03:55:35 Epoch 166 
2016-12-12 04:01:13 Training Error = 0.90292918365649 
2016-12-12 04:01:13 Training Loss = 0.01522051980454 
2016-12-12 04:01:19 Valid Error = 0.95544739797829 
2016-12-12 04:01:19 Valid Loss = 0.015689981649361 
2016-12-12 04:01:26 Test Error = 0.96463455708993 
2016-12-12 04:01:26 Test Loss = 0.015741860566749 
2016-12-12 04:01:26 -------------------LR------------------- 
2016-12-12 04:01:26 0.001953125 
2016-12-12 04:01:26 Epoch 167 
2016-12-12 04:07:13 Training Error = 0.90247149871016 
2016-12-12 04:07:13 Training Loss = 0.015220302308282 
2016-12-12 04:07:19 Valid Error = 0.95207787345563 
2016-12-12 04:07:19 Valid Loss = 0.015662681266429 
2016-12-12 04:07:26 Test Error = 0.96227686089592 
2016-12-12 04:07:26 Test Loss = 0.015719336562479 
2016-12-12 04:07:26 -------------------LR------------------- 
2016-12-12 04:07:26 0.001953125 
2016-12-12 04:07:26 Epoch 168 
2016-12-12 04:13:13 Training Error = 0.90130648248315 
2016-12-12 04:13:13 Training Loss = 0.015219085927776 
2016-12-12 04:13:19 Valid Error = 0.9502059153875 
2016-12-12 04:13:19 Valid Loss = 0.015675294196108 
2016-12-12 04:13:26 Test Error = 0.95756146850792 
2016-12-12 04:13:26 Test Loss = 0.015736875097591 
2016-12-12 04:13:26 -------------------LR------------------- 
2016-12-12 04:13:26 0.001953125 
2016-12-12 04:13:26 Epoch 169 
2016-12-12 04:19:03 Training Error = 0.90201381376383 
2016-12-12 04:19:03 Training Loss = 0.015218384014278 
2016-12-12 04:19:10 Valid Error = 0.95544739797829 
2016-12-12 04:19:10 Valid Loss = 0.015723315808882 
2016-12-12 04:19:17 Test Error = 0.96463455708993 
2016-12-12 04:19:17 Test Loss = 0.015758458059083 
2016-12-12 04:19:17 -------------------LR------------------- 
2016-12-12 04:19:17 0.001953125 
2016-12-12 04:19:17 Epoch 170 
2016-12-12 04:25:04 Training Error = 0.90317882999085 
2016-12-12 04:25:04 Training Loss = 0.01522703646064 
2016-12-12 04:25:11 Valid Error = 0.95207787345563 
2016-12-12 04:25:11 Valid Loss = 0.015669179654862 
2016-12-12 04:25:18 Test Error = 0.96227686089592 
2016-12-12 04:25:18 Test Loss = 0.015737212158851 
2016-12-12 04:25:18 -------------------LR------------------- 
2016-12-12 04:25:18 0.001953125 
2016-12-12 04:25:18 Epoch 171 
2016-12-12 04:31:06 Training Error = 0.90334526088042 
2016-12-12 04:31:06 Training Loss = 0.015222957664302 
2016-12-12 04:31:12 Valid Error = 0.95207787345563 
2016-12-12 04:31:12 Valid Loss = 0.015670755474007 
2016-12-12 04:31:19 Test Error = 0.96227686089592 
2016-12-12 04:31:19 Test Loss = 0.015724612250712 
2016-12-12 04:31:19 -------------------LR------------------- 
2016-12-12 04:31:19 0.001953125 
2016-12-12 04:31:19 Epoch 172 
2016-12-12 04:36:58 Training Error = 0.90330365315803 
2016-12-12 04:36:58 Training Loss = 0.015219616222381 
2016-12-12 04:37:05 Valid Error = 0.95320104829652 
2016-12-12 04:37:05 Valid Loss = 0.015669951420868 
2016-12-12 04:37:12 Test Error = 0.96362411586393 
2016-12-12 04:37:12 Test Loss = 0.015727797261966 
2016-12-12 04:37:12 -------------------LR------------------- 
2016-12-12 04:37:12 0.001953125 
2016-12-12 04:37:12 Epoch 173 
2016-12-12 04:43:02 Training Error = 0.90434384621786 
2016-12-12 04:43:02 Training Loss = 0.015226641777321 
2016-12-12 04:43:08 Valid Error = 0.95544739797829 
2016-12-12 04:43:08 Valid Loss = 0.015772447256141 
2016-12-12 04:43:15 Test Error = 0.96463455708993 
2016-12-12 04:43:15 Test Loss = 0.01580646191693 
2016-12-12 04:43:15 -------------------LR------------------- 
2016-12-12 04:43:15 0.001953125 
2016-12-12 04:43:15 Epoch 174 
2016-12-12 04:49:02 Training Error = 0.90371973038196 
2016-12-12 04:49:02 Training Loss = 0.015226467473367 
2016-12-12 04:49:08 Valid Error = 0.95207787345563 
2016-12-12 04:49:08 Valid Loss = 0.015669577613545 
2016-12-12 04:49:15 Test Error = 0.96227686089592 
2016-12-12 04:49:15 Test Loss = 0.015722981127932 
2016-12-12 04:49:15 -------------------LR------------------- 
2016-12-12 04:49:15 0.001953125 
2016-12-12 04:49:15 Epoch 175 
2016-12-12 04:54:52 Training Error = 0.90446866938504 
2016-12-12 04:54:52 Training Loss = 0.015220294871789 
2016-12-12 04:54:58 Valid Error = 0.95544739797829 
2016-12-12 04:54:58 Valid Loss = 0.015705385543238 
2016-12-12 04:55:05 Test Error = 0.96463455708993 
2016-12-12 04:55:05 Test Loss = 0.015753137658565 
2016-12-12 04:55:05 -------------------LR------------------- 
2016-12-12 04:55:05 0.001953125 
2016-12-12 04:55:05 Epoch 176 
2016-12-12 05:00:50 Training Error = 0.90309561454606 
2016-12-12 05:00:50 Training Loss = 0.015219637544536 
2016-12-12 05:00:56 Valid Error = 0.95544739797829 
2016-12-12 05:00:56 Valid Loss = 0.015660320963202 
2016-12-12 05:01:03 Test Error = 0.96463455708993 
2016-12-12 05:01:03 Test Loss = 0.015719078108049 
2016-12-12 05:01:03 -------------------LR------------------- 
2016-12-12 05:01:03 0.001953125 
2016-12-12 05:01:03 Epoch 177 
2016-12-12 05:06:45 Training Error = 0.90280436048931 
2016-12-12 05:06:45 Training Loss = 0.015216885640583 
2016-12-12 05:06:52 Valid Error = 0.95731935604642 
2016-12-12 05:06:52 Valid Loss = 0.015676089870625 
2016-12-12 05:06:59 Test Error = 0.96934994947794 
2016-12-12 05:06:59 Test Loss = 0.015738187217008 
2016-12-12 05:06:59 -------------------LR------------------- 
2016-12-12 05:06:59 0.001953125 
2016-12-12 05:06:59 Epoch 178 
2016-12-12 05:12:28 Training Error = 0.90317882999085 
2016-12-12 05:12:28 Training Loss = 0.015217624522433 
2016-12-12 05:12:34 Valid Error = 0.9502059153875 
2016-12-12 05:12:34 Valid Loss = 0.015688048487971 
2016-12-12 05:12:41 Test Error = 0.95756146850792 
2016-12-12 05:12:41 Test Loss = 0.015729213367783 
2016-12-12 05:12:41 -------------------LR------------------- 
2016-12-12 05:12:41 0.001953125 
2016-12-12 05:12:41 Epoch 179 
2016-12-12 05:17:55 Training Error = 0.90251310643255 
2016-12-12 05:17:55 Training Loss = 0.015222881195895 
2016-12-12 05:18:02 Valid Error = 0.95731935604642 
2016-12-12 05:18:02 Valid Loss = 0.015670869971658 
2016-12-12 05:18:09 Test Error = 0.96934994947794 
2016-12-12 05:18:09 Test Loss = 0.015726749716106 
2016-12-12 05:18:09 -------------------LR------------------- 
2016-12-12 05:18:09 0.001953125 
2016-12-12 05:18:09 Epoch 180 
2016-12-12 05:23:31 Training Error = 0.90317882999085 
2016-12-12 05:23:31 Training Loss = 0.015224495189859 
2016-12-12 05:23:37 Valid Error = 0.95207787345563 
2016-12-12 05:23:37 Valid Loss = 0.01567965401048 
2016-12-12 05:23:44 Test Error = 0.96227686089592 
2016-12-12 05:23:44 Test Loss = 0.015737070651758 
2016-12-12 05:23:44 -------------------LR------------------- 
2016-12-12 05:23:44 0.001953125 
2016-12-12 05:23:44 Epoch 181 
2016-12-12 05:28:50 Training Error = 0.90242989098777 
2016-12-12 05:28:50 Training Loss = 0.015217932816179 
2016-12-12 05:28:56 Valid Error = 0.95207787345563 
2016-12-12 05:28:56 Valid Loss = 0.015658588887514 
2016-12-12 05:29:03 Test Error = 0.96227686089592 
2016-12-12 05:29:03 Test Loss = 0.015711831734128 
2016-12-12 05:29:03 -------------------LR------------------- 
2016-12-12 05:29:03 0.001953125 
2016-12-12 05:29:03 Epoch 182 
2016-12-12 05:34:22 Training Error = 0.90242989098777 
2016-12-12 05:34:22 Training Loss = 0.01522466383363 
2016-12-12 05:34:28 Valid Error = 0.95544739797829 
2016-12-12 05:34:28 Valid Loss = 0.01576648287585 
2016-12-12 05:34:35 Test Error = 0.96463455708993 
2016-12-12 05:34:35 Test Loss = 0.015803759053346 
2016-12-12 05:34:35 -------------------LR------------------- 
2016-12-12 05:34:35 0.001953125 
2016-12-12 05:34:35 Epoch 183 
2016-12-12 05:39:54 Training Error = 0.90413580760589 
2016-12-12 05:39:54 Training Loss = 0.01521674265327 
2016-12-12 05:40:01 Valid Error = 0.95207787345563 
2016-12-12 05:40:01 Valid Loss = 0.015649434029855 
2016-12-12 05:40:08 Test Error = 0.96227686089592 
2016-12-12 05:40:08 Test Loss = 0.015700074488098 
2016-12-12 05:40:08 -------------------LR------------------- 
2016-12-12 05:40:08 0.001953125 
2016-12-12 05:40:08 Epoch 184 
2016-12-12 05:45:11 Training Error = 0.90338686860281 
2016-12-12 05:45:11 Training Loss = 0.01522528640642 
2016-12-12 05:45:18 Valid Error = 0.95731935604642 
2016-12-12 05:45:18 Valid Loss = 0.015669407716846 
2016-12-12 05:45:25 Test Error = 0.96934994947794 
2016-12-12 05:45:25 Test Loss = 0.015729143272458 
2016-12-12 05:45:25 -------------------LR------------------- 
2016-12-12 05:45:25 0.001953125 
2016-12-12 05:45:25 Epoch 185 
2016-12-12 05:50:43 Training Error = 0.90326204543563 
2016-12-12 05:50:43 Training Loss = 0.015225625202992 
2016-12-12 05:50:49 Valid Error = 0.95320104829652 
2016-12-12 05:50:49 Valid Loss = 0.01565645206709 
2016-12-12 05:50:56 Test Error = 0.96362411586393 
2016-12-12 05:50:56 Test Loss = 0.015709889363271 
2016-12-12 05:50:56 -------------------LR------------------- 
2016-12-12 05:50:56 0.001953125 
2016-12-12 05:50:56 Epoch 186 
2016-12-12 05:56:13 Training Error = 0.90317882999085 
2016-12-12 05:56:13 Training Loss = 0.015222579662705 
2016-12-12 05:56:19 Valid Error = 0.94608760763759 
2016-12-12 05:56:19 Valid Loss = 0.015688734820864 
2016-12-12 05:56:26 Test Error = 0.9518356348939 
2016-12-12 05:56:26 Test Loss = 0.015755169984153 
2016-12-12 05:56:26 -------------------LR------------------- 
2016-12-12 05:56:26 0.001953125 
2016-12-12 05:56:26 Epoch 187 
2016-12-12 06:01:41 Training Error = 0.90388616127153 
2016-12-12 06:01:41 Training Loss = 0.015220580697731 
2016-12-12 06:01:48 Valid Error = 0.95544739797829 
2016-12-12 06:01:48 Valid Loss = 0.015666344505773 
2016-12-12 06:01:55 Test Error = 0.96463455708993 
2016-12-12 06:01:55 Test Loss = 0.015718732175676 
2016-12-12 06:01:55 -------------------LR------------------- 
2016-12-12 06:01:55 0.001953125 
2016-12-12 06:01:55 Epoch 188 
2016-12-12 06:07:08 Training Error = 0.90380294582675 
2016-12-12 06:07:08 Training Loss = 0.015223238863833 
2016-12-12 06:07:14 Valid Error = 0.95544739797829 
2016-12-12 06:07:14 Valid Loss = 0.015668233683294 
2016-12-12 06:07:21 Test Error = 0.96463455708993 
2016-12-12 06:07:21 Test Loss = 0.015723815482045 
2016-12-12 06:07:21 -------------------LR------------------- 
2016-12-12 06:07:21 0.001953125 
2016-12-12 06:07:21 Epoch 189 
2016-12-12 06:12:29 Training Error = 0.90434384621786 
2016-12-12 06:12:29 Training Loss = 0.015225307877549 
2016-12-12 06:12:35 Valid Error = 0.9502059153875 
2016-12-12 06:12:35 Valid Loss = 0.015666240538056 
2016-12-12 06:12:42 Test Error = 0.95756146850792 
2016-12-12 06:12:42 Test Loss = 0.015730875549866 
2016-12-12 06:12:42 -------------------LR------------------- 
2016-12-12 06:12:42 0.001953125 
2016-12-12 06:12:42 Epoch 190 
2016-12-12 06:18:02 Training Error = 0.90355329949239 
2016-12-12 06:18:02 Training Loss = 0.015220827297032 
2016-12-12 06:18:09 Valid Error = 0.95544739797829 
2016-12-12 06:18:09 Valid Loss = 0.015732461996998 
2016-12-12 06:18:16 Test Error = 0.96463455708993 
2016-12-12 06:18:16 Test Loss = 0.015767568591328 
2016-12-12 06:18:16 -------------------LR------------------- 
2016-12-12 06:18:16 0.001953125 
2016-12-12 06:18:16 Epoch 191 
2016-12-12 06:23:32 Training Error = 0.90317882999085 
2016-12-12 06:23:32 Training Loss = 0.015221925202203 
2016-12-12 06:23:38 Valid Error = 0.95731935604642 
2016-12-12 06:23:38 Valid Loss = 0.015688313872004 
2016-12-12 06:23:45 Test Error = 0.96934994947794 
2016-12-12 06:23:45 Test Loss = 0.015742250454032 
2016-12-12 06:23:45 -------------------LR------------------- 
2016-12-12 06:23:45 0.001953125 
2016-12-12 06:23:45 Epoch 192 
2016-12-12 06:28:57 Training Error = 0.90351169176999 
2016-12-12 06:28:57 Training Loss = 0.015216690105321 
2016-12-12 06:29:03 Valid Error = 0.95544739797829 
2016-12-12 06:29:03 Valid Loss = 0.015726512564756 
2016-12-12 06:29:10 Test Error = 0.96463455708993 
2016-12-12 06:29:10 Test Loss = 0.015758624672282 
2016-12-12 06:29:10 -------------------LR------------------- 
2016-12-12 06:29:10 0.001953125 
2016-12-12 06:29:10 Epoch 193 
2016-12-12 06:34:25 Training Error = 0.90197220604144 
2016-12-12 06:34:25 Training Loss = 0.015225858767543 
2016-12-12 06:34:31 Valid Error = 0.9475851740921 
2016-12-12 06:34:31 Valid Loss = 0.015680026427504 
2016-12-12 06:34:38 Test Error = 0.96059279218592 
2016-12-12 06:34:38 Test Loss = 0.015744040987434 
2016-12-12 06:34:38 -------------------LR------------------- 
2016-12-12 06:34:38 0.001953125 
2016-12-12 06:34:38 Epoch 194 
2016-12-12 06:39:58 Training Error = 0.90342847632521 
2016-12-12 06:39:58 Training Loss = 0.01522756396006 
2016-12-12 06:40:04 Valid Error = 0.95170348184201 
2016-12-12 06:40:04 Valid Loss = 0.015640094841242 
2016-12-12 06:40:11 Test Error = 0.96631862579993 
2016-12-12 06:40:11 Test Loss = 0.01569673905065 
2016-12-12 06:40:11 -------------------LR------------------- 
2016-12-12 06:40:11 0.001953125 
2016-12-12 06:40:11 Epoch 195 
2016-12-12 06:45:20 Training Error = 0.90330365315803 
2016-12-12 06:45:20 Training Loss = 0.015230060960657 
2016-12-12 06:45:27 Valid Error = 0.95731935604642 
2016-12-12 06:45:27 Valid Loss = 0.015669607158164 
2016-12-12 06:45:34 Test Error = 0.96934994947794 
2016-12-12 06:45:34 Test Loss = 0.015728640935258 
2016-12-12 06:45:34 -------------------LR------------------- 
2016-12-12 06:45:34 0.001953125 
2016-12-12 06:45:34 Epoch 196 
2016-12-12 06:50:51 Training Error = 0.90238828326537 
2016-12-12 06:50:51 Training Loss = 0.015218065343969 
2016-12-12 06:50:58 Valid Error = 0.95544739797829 
2016-12-12 06:50:58 Valid Loss = 0.01573614364484 
2016-12-12 06:51:05 Test Error = 0.96463455708993 
2016-12-12 06:51:05 Test Loss = 0.015784200549417 
2016-12-12 06:51:05 -------------------LR------------------- 
2016-12-12 06:51:05 0.001953125 
2016-12-12 06:51:05 Epoch 197 
2016-12-12 06:56:16 Training Error = 0.9059665473912 
2016-12-12 06:56:16 Training Loss = 0.015228701921168 
2016-12-12 06:56:23 Valid Error = 0.95731935604642 
2016-12-12 06:56:23 Valid Loss = 0.015650797157709 
2016-12-12 06:56:30 Test Error = 0.96934994947794 
2016-12-12 06:56:30 Test Loss = 0.015707144842918 
2016-12-12 06:56:30 -------------------LR------------------- 
2016-12-12 06:56:30 0.001953125 
2016-12-12 06:56:30 Epoch 198 
2016-12-12 07:01:45 Training Error = 0.90313722226845 
2016-12-12 07:01:45 Training Loss = 0.01521935911536 
2016-12-12 07:01:52 Valid Error = 0.95731935604642 
2016-12-12 07:01:52 Valid Loss = 0.015666877799101 
2016-12-12 07:01:59 Test Error = 0.96934994947794 
2016-12-12 07:01:59 Test Loss = 0.015723167552552 
2016-12-12 07:01:59 -------------------LR------------------- 
2016-12-12 07:01:59 0.001953125 
2016-12-12 07:01:59 Epoch 199 
2016-12-12 07:07:18 Training Error = 0.90305400682367 
2016-12-12 07:07:18 Training Loss = 0.015225186983849 
2016-12-12 07:07:25 Valid Error = 0.95731935604642 
2016-12-12 07:07:25 Valid Loss = 0.015662261586755 
2016-12-12 07:07:32 Test Error = 0.96934994947794 
2016-12-12 07:07:32 Test Loss = 0.015715591751248 
2016-12-12 07:07:32 -------------------LR------------------- 
2016-12-12 07:07:32 0.001953125 
2016-12-12 07:07:32 Epoch 200 
2016-12-12 07:12:46 Training Error = 0.90280436048931 
2016-12-12 07:12:46 Training Loss = 0.015223078918172 
2016-12-12 07:12:53 Valid Error = 0.95544739797829 
2016-12-12 07:12:53 Valid Loss = 0.015756189318942 
2016-12-12 07:13:00 Test Error = 0.96463455708993 
2016-12-12 07:13:00 Test Loss = 0.015784184522557 
2016-12-12 07:13:00 -------------------LR------------------- 
2016-12-12 07:13:00 0.0009765625 
2016-12-12 07:13:00 Epoch 201 
2016-12-12 07:18:20 Training Error = 0.90438545394025 
2016-12-12 07:18:20 Training Loss = 0.015225747372329 
2016-12-12 07:18:26 Valid Error = 0.95320104829652 
2016-12-12 07:18:26 Valid Loss = 0.015677240649924 
2016-12-12 07:18:33 Test Error = 0.96362411586393 
2016-12-12 07:18:33 Test Loss = 0.015733924267772 
2016-12-12 07:18:33 -------------------LR------------------- 
2016-12-12 07:18:33 0.0009765625 
2016-12-12 07:18:33 Epoch 202 
2016-12-12 07:23:51 Training Error = 0.90451027710743 
2016-12-12 07:23:51 Training Loss = 0.01522292432452 
2016-12-12 07:23:57 Valid Error = 0.95731935604642 
2016-12-12 07:23:57 Valid Loss = 0.015672939472803 
2016-12-12 07:24:04 Test Error = 0.96934994947794 
2016-12-12 07:24:04 Test Loss = 0.015728965054659 
2016-12-12 07:24:04 -------------------LR------------------- 
2016-12-12 07:24:04 0.0009765625 
2016-12-12 07:24:04 Epoch 203 
2016-12-12 07:29:10 Training Error = 0.90326204543563 
2016-12-12 07:29:10 Training Loss = 0.015225906873693 
2016-12-12 07:29:17 Valid Error = 0.94608760763759 
2016-12-12 07:29:17 Valid Loss = 0.015660131850171 
2016-12-12 07:29:24 Test Error = 0.9518356348939 
2016-12-12 07:29:24 Test Loss = 0.015714610049006 
2016-12-12 07:29:24 -------------------LR------------------- 
2016-12-12 07:29:24 0.0009765625 
2016-12-12 07:29:24 Epoch 204 
2016-12-12 07:34:43 Training Error = 0.90251310643255 
2016-12-12 07:34:43 Training Loss = 0.015221625024102 
2016-12-12 07:34:49 Valid Error = 0.95207787345563 
2016-12-12 07:34:49 Valid Loss = 0.015697468978756 
2016-12-12 07:34:56 Test Error = 0.96227686089592 
2016-12-12 07:34:56 Test Loss = 0.015756908202616 
2016-12-12 07:34:56 -------------------LR------------------- 
2016-12-12 07:34:56 0.0009765625 
2016-12-12 07:34:56 Epoch 205 
2016-12-12 07:40:10 Training Error = 0.90267953732213 
2016-12-12 07:40:10 Training Loss = 0.015224633619698 
2016-12-12 07:40:16 Valid Error = 0.95731935604642 
2016-12-12 07:40:16 Valid Loss = 0.015683245609819 
2016-12-12 07:40:23 Test Error = 0.96934994947794 
2016-12-12 07:40:23 Test Loss = 0.015741400647161 
2016-12-12 07:40:23 -------------------LR------------------- 
2016-12-12 07:40:23 0.0009765625 
2016-12-12 07:40:23 Epoch 206 
2016-12-12 07:45:41 Training Error = 0.90230506782059 
2016-12-12 07:45:41 Training Loss = 0.015225373256356 
2016-12-12 07:45:47 Valid Error = 0.95731935604642 
2016-12-12 07:45:47 Valid Loss = 0.015674811014699 
2016-12-12 07:45:54 Test Error = 0.96934994947794 
2016-12-12 07:45:54 Test Loss = 0.01573155824286 
2016-12-12 07:45:54 -------------------LR------------------- 
2016-12-12 07:45:54 0.0009765625 
2016-12-12 07:45:54 Epoch 207 
2016-12-12 07:51:08 Training Error = 0.90309561454606 
2016-12-12 07:51:08 Training Loss = 0.015223217336034 
2016-12-12 07:51:14 Valid Error = 0.95320104829652 
2016-12-12 07:51:14 Valid Loss = 0.015663866841268 
2016-12-12 07:51:21 Test Error = 0.96362411586393 
2016-12-12 07:51:21 Test Loss = 0.015718705713233 
2016-12-12 07:51:21 -------------------LR------------------- 
2016-12-12 07:51:21 0.0009765625 
2016-12-12 07:51:21 Epoch 208 
2016-12-12 07:56:31 Training Error = 0.90421902305068 
2016-12-12 07:56:31 Training Loss = 0.015222670816857 
2016-12-12 07:56:37 Valid Error = 0.95731935604642 
2016-12-12 07:56:37 Valid Loss = 0.015667761272171 
2016-12-12 07:56:44 Test Error = 0.96934994947794 
2016-12-12 07:56:44 Test Loss = 0.015725346783986 
2016-12-12 07:56:44 -------------------LR------------------- 
2016-12-12 07:56:44 0.0009765625 
2016-12-12 07:56:44 Epoch 209 
2016-12-12 08:02:01 Training Error = 0.90380294582675 
2016-12-12 08:02:01 Training Loss = 0.01522416981917 
2016-12-12 08:02:08 Valid Error = 0.9502059153875 
2016-12-12 08:02:08 Valid Loss = 0.015696302232564 
2016-12-12 08:02:15 Test Error = 0.95756146850792 
2016-12-12 08:02:15 Test Loss = 0.015742680018502 
2016-12-12 08:02:15 -------------------LR------------------- 
2016-12-12 08:02:15 0.0009765625 
2016-12-12 08:02:15 Epoch 210 
2016-12-12 08:07:34 Training Error = 0.90309561454606 
2016-12-12 08:07:34 Training Loss = 0.015226640117269 
2016-12-12 08:07:40 Valid Error = 0.95320104829652 
2016-12-12 08:07:40 Valid Loss = 0.015656718956915 
2016-12-12 08:07:47 Test Error = 0.96362411586393 
2016-12-12 08:07:47 Test Loss = 0.015713032393994 
2016-12-12 08:07:47 -------------------LR------------------- 
2016-12-12 08:07:47 0.0009765625 
2016-12-12 08:07:47 Epoch 211 
2016-12-12 08:12:55 Training Error = 0.90330365315803 
2016-12-12 08:12:55 Training Loss = 0.015217088132112 
2016-12-12 08:13:02 Valid Error = 0.95731935604642 
2016-12-12 08:13:02 Valid Loss = 0.015669808003514 
2016-12-12 08:13:09 Test Error = 0.96934994947794 
2016-12-12 08:13:09 Test Loss = 0.015727534299711 
2016-12-12 08:13:09 -------------------LR------------------- 
2016-12-12 08:13:09 0.0009765625 
2016-12-12 08:13:09 Epoch 212 
2016-12-12 08:18:21 Training Error = 0.90338686860281 
2016-12-12 08:18:21 Training Loss = 0.01522628944591 
2016-12-12 08:18:28 Valid Error = 0.95207787345563 
2016-12-12 08:18:28 Valid Loss = 0.015670509041606 
2016-12-12 08:18:35 Test Error = 0.96227686089592 
2016-12-12 08:18:35 Test Loss = 0.015726647458949 
2016-12-12 08:18:35 -------------------LR------------------- 
2016-12-12 08:18:35 0.0009765625 
2016-12-12 08:18:35 Epoch 213 
2016-12-12 08:23:53 Training Error = 0.90267953732213 
2016-12-12 08:23:53 Training Loss = 0.015220811960177 
2016-12-12 08:24:00 Valid Error = 0.95731935604642 
2016-12-12 08:24:00 Valid Loss = 0.015668543579972 
2016-12-12 08:24:07 Test Error = 0.96934994947794 
2016-12-12 08:24:07 Test Loss = 0.015719272070572 
2016-12-12 08:24:07 -------------------LR------------------- 
2016-12-12 08:24:07 0.0009765625 
2016-12-12 08:24:07 Epoch 214 
2016-12-12 08:29:15 Training Error = 0.90305400682367 
2016-12-12 08:29:15 Training Loss = 0.015223906032216 
2016-12-12 08:29:21 Valid Error = 0.9502059153875 
2016-12-12 08:29:21 Valid Loss = 0.015702035496209 
2016-12-12 08:29:28 Test Error = 0.95756146850792 
2016-12-12 08:29:28 Test Loss = 0.015767528474748 
2016-12-12 08:29:28 -------------------LR------------------- 
2016-12-12 08:29:28 0.0009765625 
2016-12-12 08:29:28 Epoch 215 
2016-12-12 08:34:47 Training Error = 0.9028459682117 
2016-12-12 08:34:47 Training Loss = 0.015224116222552 
2016-12-12 08:34:53 Valid Error = 0.9502059153875 
2016-12-12 08:34:53 Valid Loss = 0.015715928933066 
2016-12-12 08:35:00 Test Error = 0.95756146850792 
2016-12-12 08:35:00 Test Loss = 0.015772695819074 
2016-12-12 08:35:00 -------------------LR------------------- 
2016-12-12 08:35:00 0.0009765625 
2016-12-12 08:35:00 Epoch 216 
2016-12-12 08:40:15 Training Error = 0.90405259216111 
2016-12-12 08:40:15 Training Loss = 0.015222515872967 
2016-12-12 08:40:22 Valid Error = 0.95544739797829 
2016-12-12 08:40:22 Valid Loss = 0.015751743090696 
2016-12-12 08:40:29 Test Error = 0.96463455708993 
2016-12-12 08:40:29 Test Loss = 0.015791647526476 
2016-12-12 08:40:29 -------------------LR------------------- 
2016-12-12 08:40:29 0.0009765625 
2016-12-12 08:40:29 Epoch 217 
2016-12-12 08:45:46 Training Error = 0.90459349255222 
2016-12-12 08:45:46 Training Loss = 0.015226717447688 
2016-12-12 08:45:52 Valid Error = 0.95544739797829 
2016-12-12 08:45:52 Valid Loss = 0.015674614601822 
2016-12-12 08:45:59 Test Error = 0.96463455708993 
2016-12-12 08:45:59 Test Loss = 0.015727124156412 
2016-12-12 08:45:59 -------------------LR------------------- 
2016-12-12 08:45:59 0.0009765625 
2016-12-12 08:45:59 Epoch 218 
2016-12-12 08:51:20 Training Error = 0.90330365315803 
2016-12-12 08:51:20 Training Loss = 0.015231586589518 
2016-12-12 08:51:27 Valid Error = 0.9502059153875 
2016-12-12 08:51:27 Valid Loss = 0.015663739061805 
2016-12-12 08:51:34 Test Error = 0.95756146850792 
2016-12-12 08:51:34 Test Loss = 0.015715582551746 
2016-12-12 08:51:34 -------------------LR------------------- 
2016-12-12 08:51:34 0.0009765625 
2016-12-12 08:51:34 Epoch 219 
2016-12-12 08:56:42 Training Error = 0.90280436048931 
2016-12-12 08:56:42 Training Loss = 0.015225168872842 
2016-12-12 08:56:48 Valid Error = 0.95544739797829 
2016-12-12 08:56:48 Valid Loss = 0.015737889216472 
2016-12-12 08:56:55 Test Error = 0.96463455708993 
2016-12-12 08:56:55 Test Loss = 0.015790098578282 
2016-12-12 08:56:55 -------------------LR------------------- 
2016-12-12 08:56:55 0.0009765625 
2016-12-12 08:56:55 Epoch 220 
2016-12-12 09:02:15 Training Error = 0.90242989098777 
2016-12-12 09:02:15 Training Loss = 0.015218292365294 
2016-12-12 09:02:21 Valid Error = 0.94795956570573 
2016-12-12 09:02:21 Valid Loss = 0.01568689787286 
2016-12-12 09:02:28 Test Error = 0.95655102728191 
2016-12-12 09:02:28 Test Loss = 0.015746684143292 
2016-12-12 09:02:28 -------------------LR------------------- 
2016-12-12 09:02:28 0.0009765625 
2016-12-12 09:02:28 Epoch 221 
2016-12-12 09:07:43 Training Error = 0.90355329949239 
2016-12-12 09:07:43 Training Loss = 0.015229839094167 
2016-12-12 09:07:49 Valid Error = 0.9502059153875 
2016-12-12 09:07:49 Valid Loss = 0.015760423011971 
2016-12-12 09:07:56 Test Error = 0.95756146850792 
2016-12-12 09:07:56 Test Loss = 0.015797757389596 
2016-12-12 09:07:56 -------------------LR------------------- 
2016-12-12 09:07:56 0.0009765625 
2016-12-12 09:07:56 Epoch 222 
2016-12-12 09:13:07 Training Error = 0.90197220604144 
2016-12-12 09:13:07 Training Loss = 0.01522086770788 
2016-12-12 09:13:13 Valid Error = 0.94608760763759 
2016-12-12 09:13:13 Valid Loss = 0.015709953668868 
2016-12-12 09:13:20 Test Error = 0.9518356348939 
2016-12-12 09:13:20 Test Loss = 0.015774424578446 
2016-12-12 09:13:20 -------------------LR------------------- 
2016-12-12 09:13:20 0.0009765625 
2016-12-12 09:13:20 Epoch 223 
2016-12-12 09:18:43 Training Error = 0.90359490721478 
2016-12-12 09:18:43 Training Loss = 0.015218891283737 
2016-12-12 09:18:50 Valid Error = 0.95731935604642 
2016-12-12 09:18:50 Valid Loss = 0.015670507949719 
2016-12-12 09:18:57 Test Error = 0.96934994947794 
2016-12-12 09:18:57 Test Loss = 0.015725158925556 
2016-12-12 09:18:57 -------------------LR------------------- 
2016-12-12 09:18:57 0.0009765625 
2016-12-12 09:18:57 Epoch 224 
2016-12-12 09:24:10 Training Error = 0.90376133810435 
2016-12-12 09:24:10 Training Loss = 0.015218198239523 
2016-12-12 09:24:16 Valid Error = 0.94646199925122 
2016-12-12 09:24:16 Valid Loss = 0.015656136644804 
2016-12-12 09:24:23 Test Error = 0.95924553721792 
2016-12-12 09:24:23 Test Loss = 0.015713715621198 
2016-12-12 09:24:23 -------------------LR------------------- 
2016-12-12 09:24:23 0.0009765625 
2016-12-12 09:24:23 Epoch 225 
2016-12-12 09:29:44 Training Error = 0.9022218523758 
2016-12-12 09:29:44 Training Loss = 0.015223432640603 
2016-12-12 09:29:50 Valid Error = 0.95731935604642 
2016-12-12 09:29:50 Valid Loss = 0.015676472600953 
2016-12-12 09:29:57 Test Error = 0.96934994947794 
2016-12-12 09:29:57 Test Loss = 0.015733453955962 
2016-12-12 09:29:57 -------------------LR------------------- 
2016-12-12 09:29:57 0.0009765625 
2016-12-12 09:29:57 Epoch 226 
2016-12-12 09:35:12 Training Error = 0.90305400682367 
2016-12-12 09:35:12 Training Loss = 0.015227939973569 
2016-12-12 09:35:18 Valid Error = 0.95544739797829 
2016-12-12 09:35:18 Valid Loss = 0.015737282479561 
2016-12-12 09:35:25 Test Error = 0.96463455708993 
2016-12-12 09:35:25 Test Loss = 0.015784442853264 
2016-12-12 09:35:25 -------------------LR------------------- 
2016-12-12 09:35:25 0.0009765625 
2016-12-12 09:35:25 Epoch 227 
2016-12-12 09:40:41 Training Error = 0.90363651493717 
2016-12-12 09:40:41 Training Loss = 0.015221704490709 
2016-12-12 09:40:47 Valid Error = 0.95207787345563 
2016-12-12 09:40:47 Valid Loss = 0.015677265186472 
2016-12-12 09:40:54 Test Error = 0.96227686089592 
2016-12-12 09:40:54 Test Loss = 0.015729450516278 
2016-12-12 09:40:54 -------------------LR------------------- 
2016-12-12 09:40:54 0.0009765625 
2016-12-12 09:40:54 Epoch 228 
2016-12-12 09:46:09 Training Error = 0.90251310643255 
2016-12-12 09:46:09 Training Loss = 0.015222449407517 
2016-12-12 09:46:16 Valid Error = 0.95320104829652 
2016-12-12 09:46:16 Valid Loss = 0.015669224640719 
2016-12-12 09:46:23 Test Error = 0.96362411586393 
2016-12-12 09:46:23 Test Loss = 0.015726515257737 
2016-12-12 09:46:23 -------------------LR------------------- 
2016-12-12 09:46:23 0.0009765625 
2016-12-12 09:46:23 Epoch 229 
2016-12-12 09:51:38 Training Error = 0.90230506782059 
2016-12-12 09:51:38 Training Loss = 0.015220915123194 
2016-12-12 09:51:44 Valid Error = 0.95544739797829 
2016-12-12 09:51:44 Valid Loss = 0.015742897408032 
2016-12-12 09:51:51 Test Error = 0.96463455708993 
2016-12-12 09:51:51 Test Loss = 0.01577849953281 
2016-12-12 09:51:51 -------------------LR------------------- 
2016-12-12 09:51:51 0.0009765625 
2016-12-12 09:51:51 Epoch 230 
2016-12-12 09:57:08 Training Error = 0.90355329949239 
2016-12-12 09:57:08 Training Loss = 0.015223739734367 
2016-12-12 09:57:14 Valid Error = 0.95731935604642 
2016-12-12 09:57:14 Valid Loss = 0.015675315335884 
2016-12-12 09:57:21 Test Error = 0.96934994947794 
2016-12-12 09:57:21 Test Loss = 0.015736675873338 
2016-12-12 09:57:21 -------------------LR------------------- 
2016-12-12 09:57:21 0.0009765625 
2016-12-12 09:57:21 Epoch 231 
2016-12-12 10:02:39 Training Error = 0.90292918365649 
2016-12-12 10:02:39 Training Loss = 0.015219823219389 
2016-12-12 10:02:45 Valid Error = 0.95731935604642 
2016-12-12 10:02:45 Valid Loss = 0.015679636643301 
2016-12-12 10:02:52 Test Error = 0.96934994947794 
2016-12-12 10:02:52 Test Loss = 0.015736880748417 
2016-12-12 10:02:52 -------------------LR------------------- 
2016-12-12 10:02:52 0.0009765625 
2016-12-12 10:02:52 Epoch 232 
2016-12-12 10:08:10 Training Error = 0.90309561454606 
2016-12-12 10:08:10 Training Loss = 0.015219231671715 
2016-12-12 10:08:16 Valid Error = 0.95320104829652 
2016-12-12 10:08:16 Valid Loss = 0.01564869743334 
2016-12-12 10:08:23 Test Error = 0.96362411586393 
2016-12-12 10:08:23 Test Loss = 0.015702932016861 
2016-12-12 10:08:23 -------------------LR------------------- 
2016-12-12 10:08:23 0.0009765625 
2016-12-12 10:08:23 Epoch 233 
2016-12-12 10:13:37 Training Error = 0.9022218523758 
2016-12-12 10:13:37 Training Loss = 0.015223631986418 
2016-12-12 10:13:43 Valid Error = 0.95207787345563 
2016-12-12 10:13:43 Valid Loss = 0.015679832342612 
2016-12-12 10:13:50 Test Error = 0.96227686089592 
2016-12-12 10:13:50 Test Loss = 0.015737753787036 
2016-12-12 10:13:50 -------------------LR------------------- 
2016-12-12 10:13:50 0.0009765625 
2016-12-12 10:13:50 Epoch 234 
2016-12-12 10:19:07 Training Error = 0.9040941998835 
2016-12-12 10:19:07 Training Loss = 0.015226302460211 
2016-12-12 10:19:13 Valid Error = 0.95320104829652 
2016-12-12 10:19:13 Valid Loss = 0.015677743719403 
2016-12-12 10:19:20 Test Error = 0.96362411586393 
2016-12-12 10:19:20 Test Loss = 0.015738728582713 
2016-12-12 10:19:20 -------------------LR------------------- 
2016-12-12 10:19:20 0.0009765625 
2016-12-12 10:19:20 Epoch 235 
2016-12-12 10:24:29 Training Error = 0.90338686860281 
2016-12-12 10:24:29 Training Loss = 0.015228097128719 
2016-12-12 10:24:36 Valid Error = 0.94608760763759 
2016-12-12 10:24:36 Valid Loss = 0.015712800439777 
2016-12-12 10:24:43 Test Error = 0.9518356348939 
2016-12-12 10:24:43 Test Loss = 0.015752589753998 
2016-12-12 10:24:43 -------------------LR------------------- 
2016-12-12 10:24:43 0.0009765625 
2016-12-12 10:24:43 Epoch 236 
2016-12-12 10:29:55 Training Error = 0.9040941998835 
2016-12-12 10:29:55 Training Loss = 0.015230656469027 
2016-12-12 10:30:01 Valid Error = 0.95320104829652 
2016-12-12 10:30:01 Valid Loss = 0.015685309862541 
2016-12-12 10:30:08 Test Error = 0.96362411586393 
2016-12-12 10:30:08 Test Loss = 0.015738860474616 
2016-12-12 10:30:08 -------------------LR------------------- 
2016-12-12 10:30:08 0.0009765625 
2016-12-12 10:30:08 Epoch 237 
2016-12-12 10:35:26 Training Error = 0.90351169176999 
2016-12-12 10:35:26 Training Loss = 0.015224969558575 
2016-12-12 10:35:32 Valid Error = 0.95731935604642 
2016-12-12 10:35:32 Valid Loss = 0.015654207377123 
2016-12-12 10:35:39 Test Error = 0.96934994947794 
2016-12-12 10:35:39 Test Loss = 0.015705770907267 
2016-12-12 10:35:39 -------------------LR------------------- 
2016-12-12 10:35:39 0.0009765625 
2016-12-12 10:35:40 Epoch 238 
2016-12-12 10:40:49 Training Error = 0.90342847632521 
2016-12-12 10:40:49 Training Loss = 0.015222304812148 
2016-12-12 10:40:55 Valid Error = 0.9502059153875 
2016-12-12 10:40:55 Valid Loss = 0.01568530666679 
2016-12-12 10:41:02 Test Error = 0.95756146850792 
2016-12-12 10:41:02 Test Loss = 0.015743144526278 
2016-12-12 10:41:02 -------------------LR------------------- 
2016-12-12 10:41:02 0.0009765625 
2016-12-12 10:41:02 Epoch 239 
2016-12-12 10:46:17 Training Error = 0.90421902305068 
2016-12-12 10:46:17 Training Loss = 0.01522764144442 
2016-12-12 10:46:23 Valid Error = 0.95731935604642 
2016-12-12 10:46:23 Valid Loss = 0.015658462620087 
2016-12-12 10:46:30 Test Error = 0.96934994947794 
2016-12-12 10:46:30 Test Loss = 0.015714608644104 
2016-12-12 10:46:30 -------------------LR------------------- 
2016-12-12 10:46:30 0.0009765625 
2016-12-12 10:46:30 Epoch 240 
2016-12-12 10:51:48 Training Error = 0.90247149871016 
2016-12-12 10:51:48 Training Loss = 0.015217103242583 
2016-12-12 10:51:54 Valid Error = 0.95731935604642 
2016-12-12 10:51:54 Valid Loss = 0.015671673554705 
2016-12-12 10:52:01 Test Error = 0.96934994947794 
2016-12-12 10:52:01 Test Loss = 0.015725659231143 
2016-12-12 10:52:01 -------------------LR------------------- 
2016-12-12 10:52:01 0.0009765625 
2016-12-12 10:52:02 Epoch 241 
2016-12-12 10:57:00 Training Error = 0.90371973038196 
2016-12-12 10:57:00 Training Loss = 0.015222525504947 
2016-12-12 10:57:07 Valid Error = 0.95207787345563 
2016-12-12 10:57:07 Valid Loss = 0.015656873187006 
2016-12-12 10:57:14 Test Error = 0.96227686089592 
2016-12-12 10:57:14 Test Loss = 0.015714836669413 
2016-12-12 10:57:14 -------------------LR------------------- 
2016-12-12 10:57:14 0.0009765625 
2016-12-12 10:57:14 Epoch 242 
2016-12-12 11:01:52 Training Error = 0.9028459682117 
2016-12-12 11:01:52 Training Loss = 0.015216302567263 
2016-12-12 11:01:59 Valid Error = 0.95132909022838 
2016-12-12 11:01:59 Valid Loss = 0.015696415554673 
2016-12-12 11:02:06 Test Error = 0.95890872347592 
2016-12-12 11:02:06 Test Loss = 0.015744914590905 
2016-12-12 11:02:06 -------------------LR------------------- 
2016-12-12 11:02:06 0.0009765625 
2016-12-12 11:02:06 Epoch 243 
2016-12-12 11:06:41 Training Error = 0.90521760838812 
2016-12-12 11:06:41 Training Loss = 0.015226770324843 
2016-12-12 11:06:48 Valid Error = 0.95320104829652 
2016-12-12 11:06:48 Valid Loss = 0.015667314068711 
2016-12-12 11:06:55 Test Error = 0.96362411586393 
2016-12-12 11:06:55 Test Loss = 0.015724258263572 
2016-12-12 11:06:55 -------------------LR------------------- 
2016-12-12 11:06:55 0.0009765625 
2016-12-12 11:06:55 Epoch 244 
2016-12-12 11:11:34 Training Error = 0.90151452109512 
2016-12-12 11:11:34 Training Loss = 0.015214130278944 
2016-12-12 11:11:40 Valid Error = 0.95544739797829 
2016-12-12 11:11:40 Valid Loss = 0.015743231741996 
2016-12-12 11:11:47 Test Error = 0.96463455708993 
2016-12-12 11:11:47 Test Loss = 0.015783396703632 
2016-12-12 11:11:47 -------------------LR------------------- 
2016-12-12 11:11:47 0.0009765625 
2016-12-12 11:11:47 Epoch 245 
2016-12-12 11:16:26 Training Error = 0.90334526088042 
2016-12-12 11:16:26 Training Loss = 0.015223985570097 
2016-12-12 11:16:32 Valid Error = 0.95731935604642 
2016-12-12 11:16:32 Valid Loss = 0.0156596739426 
2016-12-12 11:16:39 Test Error = 0.96934994947794 
2016-12-12 11:16:39 Test Loss = 0.015714706017062 
2016-12-12 11:16:39 -------------------LR------------------- 
2016-12-12 11:16:39 0.0009765625 
2016-12-12 11:16:39 Epoch 246 
2016-12-12 11:21:20 Training Error = 0.90446866938504 
2016-12-12 11:21:20 Training Loss = 0.015226589544848 
2016-12-12 11:21:26 Valid Error = 0.95544739797829 
2016-12-12 11:21:26 Valid Loss = 0.015734765906056 
2016-12-12 11:21:33 Test Error = 0.96463455708993 
2016-12-12 11:21:33 Test Loss = 0.015782451377349 
2016-12-12 11:21:33 -------------------LR------------------- 
2016-12-12 11:21:33 0.0009765625 
2016-12-12 11:21:33 Epoch 247 
2016-12-12 11:26:10 Training Error = 0.9028459682117 
2016-12-12 11:26:10 Training Loss = 0.015221039055697 
2016-12-12 11:26:17 Valid Error = 0.95731935604642 
2016-12-12 11:26:17 Valid Loss = 0.015656614633352 
2016-12-12 11:26:24 Test Error = 0.96934994947794 
2016-12-12 11:26:24 Test Loss = 0.015708856278066 
2016-12-12 11:26:24 -------------------LR------------------- 
2016-12-12 11:26:24 0.0009765625 
2016-12-12 11:26:24 Epoch 248 
2016-12-12 11:30:59 Training Error = 0.90351169176999 
2016-12-12 11:30:59 Training Loss = 0.015225233545038 
2016-12-12 11:31:06 Valid Error = 0.95207787345563 
2016-12-12 11:31:06 Valid Loss = 0.015686505350512 
2016-12-12 11:31:13 Test Error = 0.96227686089592 
2016-12-12 11:31:13 Test Loss = 0.015745594640025 
2016-12-12 11:31:13 -------------------LR------------------- 
2016-12-12 11:31:13 0.0009765625 
2016-12-12 11:31:13 Epoch 249 
2016-12-12 11:35:50 Training Error = 0.90209702920862 
2016-12-12 11:35:50 Training Loss = 0.015221724519992 
2016-12-12 11:35:57 Valid Error = 0.95320104829652 
2016-12-12 11:35:57 Valid Loss = 0.015670509949327 
2016-12-12 11:36:04 Test Error = 0.96362411586393 
2016-12-12 11:36:04 Test Loss = 0.015725878777901 
2016-12-12 11:36:04 -------------------LR------------------- 
2016-12-12 11:36:04 0.0009765625 
2016-12-12 11:36:04 Epoch 250 
2016-12-12 11:40:42 Training Error = 0.90396937671632 
2016-12-12 11:40:42 Training Loss = 0.015222592431928 
2016-12-12 11:40:48 Valid Error = 0.95132909022838 
2016-12-12 11:40:48 Valid Loss = 0.015677375505112 
2016-12-12 11:40:55 Test Error = 0.95890872347592 
2016-12-12 11:40:55 Test Loss = 0.015738630722377 
2016-12-12 11:40:55 -------------------LR------------------- 
2016-12-12 11:40:55 0.00048828125 
2016-12-12 11:40:55 Epoch 251 
2016-12-12 11:45:34 Training Error = 0.90542564700008 
2016-12-12 11:45:34 Training Loss = 0.015223512063978 
2016-12-12 11:45:40 Valid Error = 0.95731935604642 
2016-12-12 11:45:40 Valid Loss = 0.015669779783019 
2016-12-12 11:45:47 Test Error = 0.96934994947794 
2016-12-12 11:45:47 Test Loss = 0.015727538132259 
2016-12-12 11:45:47 -------------------LR------------------- 
2016-12-12 11:45:47 0.00048828125 
2016-12-12 11:45:47 Epoch 252 
2016-12-12 11:50:24 Training Error = 0.90317882999085 
2016-12-12 11:50:24 Training Loss = 0.015215627542043 
2016-12-12 11:50:31 Valid Error = 0.95207787345563 
2016-12-12 11:50:31 Valid Loss = 0.015642588208564 
2016-12-12 11:50:38 Test Error = 0.96227686089592 
2016-12-12 11:50:38 Test Loss = 0.015687519663415 
2016-12-12 11:50:38 -------------------LR------------------- 
2016-12-12 11:50:38 0.00048828125 
2016-12-12 11:50:38 Epoch 253 
2016-12-12 11:55:17 Training Error = 0.90401098443871 
2016-12-12 11:55:17 Training Loss = 0.015226950421888 
2016-12-12 11:55:24 Valid Error = 0.95544739797829 
2016-12-12 11:55:24 Valid Loss = 0.015685647053265 
2016-12-12 11:55:31 Test Error = 0.96463455708993 
2016-12-12 11:55:31 Test Loss = 0.015751495046815 
2016-12-12 11:55:31 -------------------LR------------------- 
2016-12-12 11:55:31 0.00048828125 
2016-12-12 11:55:31 Epoch 254 
2016-12-12 12:00:07 Training Error = 0.90371973038196 
2016-12-12 12:00:07 Training Loss = 0.015224322669228 
2016-12-12 12:00:13 Valid Error = 0.95207787345563 
2016-12-12 12:00:13 Valid Loss = 0.015690392764998 
2016-12-12 12:00:20 Test Error = 0.96227686089592 
2016-12-12 12:00:20 Test Loss = 0.015751843211998 
2016-12-12 12:00:20 -------------------LR------------------- 
2016-12-12 12:00:20 0.00048828125 
2016-12-12 12:00:20 Epoch 255 
2016-12-12 12:04:57 Training Error = 0.90305400682367 
2016-12-12 12:04:57 Training Loss = 0.015219645911686 
2016-12-12 12:05:04 Valid Error = 0.95731935604642 
2016-12-12 12:05:04 Valid Loss = 0.015644602027233 
2016-12-12 12:05:11 Test Error = 0.96934994947794 
2016-12-12 12:05:11 Test Loss = 0.015699115127834 
2016-12-12 12:05:11 -------------------LR------------------- 
2016-12-12 12:05:11 0.00048828125 
2016-12-12 12:05:11 Epoch 256 
2016-12-12 12:10:08 Training Error = 0.90446866938504 
2016-12-12 12:10:08 Training Loss = 0.015231953732866 
2016-12-12 12:10:14 Valid Error = 0.95731935604642 
2016-12-12 12:10:14 Valid Loss = 0.015667095449767 
2016-12-12 12:10:21 Test Error = 0.96934994947794 
2016-12-12 12:10:21 Test Loss = 0.015722868268684 
2016-12-12 12:10:21 -------------------LR------------------- 
2016-12-12 12:10:21 0.00048828125 
2016-12-12 12:10:21 Epoch 257 
2016-12-12 12:15:59 Training Error = 0.90396937671632 
2016-12-12 12:15:59 Training Loss = 0.015215766740127 
2016-12-12 12:16:10 Valid Error = 0.95320104829652 
2016-12-12 12:16:10 Valid Loss = 0.015656632709727 
2016-12-12 12:16:22 Test Error = 0.96362411586393 
2016-12-12 12:16:22 Test Loss = 0.01571484477737 
2016-12-12 12:16:22 -------------------LR------------------- 
2016-12-12 12:16:22 0.00048828125 
2016-12-12 12:16:22 Epoch 258 
2016-12-12 12:24:02 Training Error = 0.90438545394025 
2016-12-12 12:24:02 Training Loss = 0.01522942279717 
2016-12-12 12:24:13 Valid Error = 0.95207787345563 
2016-12-12 12:24:13 Valid Loss = 0.015667512780855 
2016-12-12 12:24:24 Test Error = 0.96227686089592 
2016-12-12 12:24:24 Test Loss = 0.015722472290027 
2016-12-12 12:24:24 -------------------LR------------------- 
2016-12-12 12:24:24 0.00048828125 
2016-12-12 12:24:25 Epoch 259 
2016-12-12 12:32:06 Training Error = 0.90342847632521 
2016-12-12 12:32:06 Training Loss = 0.015213840254529 
2016-12-12 12:32:17 Valid Error = 0.95544739797829 
2016-12-12 12:32:17 Valid Loss = 0.015754272412243 
2016-12-12 12:32:28 Test Error = 0.96463455708993 
2016-12-12 12:32:28 Test Loss = 0.01578760555087 
2016-12-12 12:32:28 -------------------LR------------------- 
2016-12-12 12:32:28 0.00048828125 
2016-12-12 12:32:28 Epoch 260 
2016-12-12 12:40:10 Training Error = 0.90396937671632 
2016-12-12 12:40:10 Training Loss = 0.015225747913898 
2016-12-12 12:40:22 Valid Error = 0.95731935604642 
2016-12-12 12:40:22 Valid Loss = 0.015703079070837 
2016-12-12 12:40:35 Test Error = 0.96934994947794 
2016-12-12 12:40:35 Test Loss = 0.015761200681952 
2016-12-12 12:40:35 -------------------LR------------------- 
2016-12-12 12:40:35 0.00048828125 
2016-12-12 12:40:35 Epoch 261 
2016-12-12 12:48:15 Training Error = 0.90355329949239 
2016-12-12 12:48:15 Training Loss = 0.01522355164962 
2016-12-12 12:48:26 Valid Error = 0.95544739797829 
2016-12-12 12:48:26 Valid Loss = 0.015729196050843 
2016-12-12 12:48:37 Test Error = 0.96463455708993 
2016-12-12 12:48:37 Test Loss = 0.015774951753493 
2016-12-12 12:48:37 -------------------LR------------------- 
2016-12-12 12:48:37 0.00048828125 
2016-12-12 12:48:37 Epoch 262 
2016-12-12 12:56:31 Training Error = 0.90405259216111 
2016-12-12 12:56:31 Training Loss = 0.015222712523791 
2016-12-12 12:56:41 Valid Error = 0.9502059153875 
2016-12-12 12:56:41 Valid Loss = 0.015746840054256 
2016-12-12 12:56:53 Test Error = 0.95756146850792 
2016-12-12 12:56:53 Test Loss = 0.015782955696443 
2016-12-12 12:56:53 -------------------LR------------------- 
2016-12-12 12:56:53 0.00048828125 
2016-12-12 12:56:53 Epoch 263 
2016-12-12 13:04:39 Training Error = 0.90205542148623 
2016-12-12 13:04:39 Training Loss = 0.015224008628251 
2016-12-12 13:04:50 Valid Error = 0.95207787345563 
2016-12-12 13:04:50 Valid Loss = 0.015671286353822 
2016-12-12 13:05:01 Test Error = 0.96227686089592 
2016-12-12 13:05:01 Test Loss = 0.015725228269866 
2016-12-12 13:05:01 -------------------LR------------------- 
2016-12-12 13:05:01 0.00048828125 
2016-12-12 13:05:01 Epoch 264 
2016-12-12 13:12:44 Training Error = 0.90430223849546 
2016-12-12 13:12:44 Training Loss = 0.015230096652204 
2016-12-12 13:12:53 Valid Error = 0.95207787345563 
2016-12-12 13:12:53 Valid Loss = 0.015660141330045 
2016-12-12 13:13:04 Test Error = 0.96227686089592 
2016-12-12 13:13:04 Test Loss = 0.015713047429329 
2016-12-12 13:13:04 -------------------LR------------------- 
2016-12-12 13:13:04 0.00048828125 
2016-12-12 13:13:04 Epoch 265 
2016-12-12 13:20:52 Training Error = 0.90280436048931 
2016-12-12 13:20:52 Training Loss = 0.015217070084784 
2016-12-12 13:21:02 Valid Error = 0.95207787345563 
2016-12-12 13:21:02 Valid Loss = 0.015668507232443 
2016-12-12 13:21:14 Test Error = 0.96227686089592 
2016-12-12 13:21:14 Test Loss = 0.015719351927936 
2016-12-12 13:21:14 -------------------LR------------------- 
2016-12-12 13:21:14 0.00048828125 
2016-12-12 13:21:14 Epoch 266 
2016-12-12 13:29:03 Training Error = 0.90334526088042 
2016-12-12 13:29:03 Training Loss = 0.015221890226613 
2016-12-12 13:29:13 Valid Error = 0.9502059153875 
2016-12-12 13:29:13 Valid Loss = 0.015697430858862 
2016-12-12 13:29:24 Test Error = 0.95756146850792 
2016-12-12 13:29:24 Test Loss = 0.015740877026573 
2016-12-12 13:29:24 -------------------LR------------------- 
2016-12-12 13:29:24 0.00048828125 
2016-12-12 13:29:24 Epoch 267 
2016-12-12 13:37:08 Training Error = 0.90351169176999 
2016-12-12 13:37:08 Training Loss = 0.015228330465133 
2016-12-12 13:37:16 Valid Error = 0.95731935604642 
2016-12-12 13:37:16 Valid Loss = 0.015664608144945 
2016-12-12 13:37:33 Test Error = 0.96934994947794 
2016-12-12 13:37:33 Test Loss = 0.01571779688721 
2016-12-12 13:37:33 -------------------LR------------------- 
2016-12-12 13:37:33 0.00048828125 
2016-12-12 13:37:33 Epoch 268 
2016-12-12 13:45:27 Training Error = 0.90272114504452 
2016-12-12 13:45:27 Training Loss = 0.01522329697148 
2016-12-12 13:45:36 Valid Error = 0.95544739797829 
2016-12-12 13:45:36 Valid Loss = 0.015716260013219 
2016-12-12 13:45:47 Test Error = 0.96463455708993 
2016-12-12 13:45:47 Test Loss = 0.01576663720421 
2016-12-12 13:45:47 -------------------LR------------------- 
2016-12-12 13:45:47 0.00048828125 
2016-12-12 13:45:47 Epoch 269 
2016-12-12 13:53:57 Training Error = 0.90367812265957 
2016-12-12 13:53:57 Training Loss = 0.015224475906913 
2016-12-12 13:54:07 Valid Error = 0.95544739797829 
2016-12-12 13:54:07 Valid Loss = 0.015724245465827 
2016-12-12 13:54:17 Test Error = 0.96463455708993 
2016-12-12 13:54:17 Test Loss = 0.01577355755373 
2016-12-12 13:54:17 -------------------LR------------------- 
2016-12-12 13:54:17 0.00048828125 
2016-12-12 13:54:17 Epoch 270 
2016-12-12 14:02:24 Training Error = 0.90371973038196 
2016-12-12 14:02:24 Training Loss = 0.015223719877428 
2016-12-12 14:02:34 Valid Error = 0.94795956570573 
2016-12-12 14:02:34 Valid Loss = 0.015655284874529 
2016-12-12 14:02:44 Test Error = 0.95655102728191 
2016-12-12 14:02:44 Test Loss = 0.015712374589144 
2016-12-12 14:02:44 -------------------LR------------------- 
2016-12-12 14:02:44 0.00048828125 
2016-12-12 14:02:44 Epoch 271 
2016-12-12 14:10:55 Training Error = 0.90326204543563 
2016-12-12 14:10:55 Training Loss = 0.01522378085241 
2016-12-12 14:11:04 Valid Error = 0.95207787345563 
2016-12-12 14:11:04 Valid Loss = 0.015695607603454 
2016-12-12 14:11:15 Test Error = 0.96227686089592 
2016-12-12 14:11:15 Test Loss = 0.015756391981175 
2016-12-12 14:11:15 -------------------LR------------------- 
2016-12-12 14:11:15 0.00048828125 
2016-12-12 14:11:15 Epoch 272 
2016-12-12 14:19:25 Training Error = 0.90405259216111 
2016-12-12 14:19:25 Training Loss = 0.015224212781877 
2016-12-12 14:19:34 Valid Error = 0.95207787345563 
2016-12-12 14:19:34 Valid Loss = 0.015663049391446 
2016-12-12 14:19:45 Test Error = 0.96227686089592 
2016-12-12 14:19:45 Test Loss = 0.015717248022917 
2016-12-12 14:19:45 -------------------LR------------------- 
2016-12-12 14:19:45 0.00048828125 
2016-12-12 14:19:45 Epoch 273 
2016-12-12 14:27:54 Training Error = 0.90276275276691 
2016-12-12 14:27:54 Training Loss = 0.015222934451039 
2016-12-12 14:28:04 Valid Error = 0.94608760763759 
2016-12-12 14:28:04 Valid Loss = 0.015700958515092 
2016-12-12 14:28:14 Test Error = 0.9518356348939 
2016-12-12 14:28:14 Test Loss = 0.015747379210402 
2016-12-12 14:28:14 -------------------LR------------------- 
2016-12-12 14:28:14 0.00048828125 
2016-12-12 14:28:14 Epoch 274 
2016-12-12 14:36:29 Training Error = 0.90305400682367 
2016-12-12 14:36:29 Training Loss = 0.01521972855205 
2016-12-12 14:36:38 Valid Error = 0.95320104829652 
2016-12-12 14:36:38 Valid Loss = 0.015671847821448 
2016-12-12 14:36:48 Test Error = 0.96362411586393 
2016-12-12 14:36:48 Test Loss = 0.015727871966292 
2016-12-12 14:36:48 -------------------LR------------------- 
2016-12-12 14:36:48 0.00048828125 
2016-12-12 14:36:48 Epoch 275 
2016-12-12 14:44:57 Training Error = 0.90371973038196 
2016-12-12 14:44:57 Training Loss = 0.015225758488219 
2016-12-12 14:45:06 Valid Error = 0.9502059153875 
2016-12-12 14:45:06 Valid Loss = 0.015743591400365 
2016-12-12 14:45:17 Test Error = 0.95756146850792 
2016-12-12 14:45:17 Test Loss = 0.015779572562886 
2016-12-12 14:45:17 -------------------LR------------------- 
2016-12-12 14:45:17 0.00048828125 
2016-12-12 14:45:17 Epoch 276 
2016-12-12 14:53:26 Training Error = 0.90267953732213 
2016-12-12 14:53:26 Training Loss = 0.015218476090617 
2016-12-12 14:53:35 Valid Error = 0.95207787345563 
2016-12-12 14:53:35 Valid Loss = 0.015652997170219 
2016-12-12 14:53:46 Test Error = 0.96227686089592 
2016-12-12 14:53:46 Test Loss = 0.015706696760346 
2016-12-12 14:53:46 -------------------LR------------------- 
2016-12-12 14:53:46 0.00048828125 
2016-12-12 14:53:46 Epoch 277 
2016-12-12 15:01:54 Training Error = 0.90301239910127 
2016-12-12 15:01:54 Training Loss = 0.015221188731414 
2016-12-12 15:02:03 Valid Error = 0.95207787345563 
2016-12-12 15:02:03 Valid Loss = 0.015644167693552 
2016-12-12 15:02:13 Test Error = 0.96227686089592 
2016-12-12 15:02:13 Test Loss = 0.015703105995097 
2016-12-12 15:02:13 -------------------LR------------------- 
2016-12-12 15:02:13 0.00048828125 
2016-12-12 15:02:13 Epoch 278 
2016-12-12 15:10:19 Training Error = 0.90338686860281 
2016-12-12 15:10:19 Training Loss = 0.015223393642974 
2016-12-12 15:10:29 Valid Error = 0.94646199925122 
2016-12-12 15:10:29 Valid Loss = 0.015669709098181 
2016-12-12 15:10:40 Test Error = 0.95924553721792 
2016-12-12 15:10:40 Test Loss = 0.015727318078464 
2016-12-12 15:10:40 -------------------LR------------------- 
2016-12-12 15:10:40 0.00048828125 
2016-12-12 15:10:40 Epoch 279 
2016-12-12 15:18:50 Training Error = 0.90292918365649 
2016-12-12 15:18:50 Training Loss = 0.015223015842347 
2016-12-12 15:18:59 Valid Error = 0.95320104829652 
2016-12-12 15:18:59 Valid Loss = 0.015689769681624 
2016-12-12 15:19:10 Test Error = 0.96362411586393 
2016-12-12 15:19:10 Test Loss = 0.015754601592309 
2016-12-12 15:19:10 -------------------LR------------------- 
2016-12-12 15:19:10 0.00048828125 
2016-12-12 15:19:10 Epoch 280 
2016-12-12 15:27:24 Training Error = 0.90442706166264 
2016-12-12 15:27:24 Training Loss = 0.015223501233185 
2016-12-12 15:27:33 Valid Error = 0.9502059153875 
2016-12-12 15:27:33 Valid Loss = 0.01567023827243 
2016-12-12 15:27:44 Test Error = 0.95756146850792 
2016-12-12 15:27:44 Test Loss = 0.015728884045044 
2016-12-12 15:27:44 -------------------LR------------------- 
2016-12-12 15:27:44 0.00048828125 
2016-12-12 15:27:44 Epoch 281 
2016-12-12 15:35:55 Training Error = 0.90263792959973 
2016-12-12 15:35:55 Training Loss = 0.015219965654617 
2016-12-12 15:36:04 Valid Error = 0.95544739797829 
2016-12-12 15:36:04 Valid Loss = 0.015658814477927 
2016-12-12 15:36:15 Test Error = 0.96463455708993 
2016-12-12 15:36:15 Test Loss = 0.015718357663102 
2016-12-12 15:36:15 -------------------LR------------------- 
2016-12-12 15:36:15 0.00048828125 
2016-12-12 15:36:15 Epoch 282 
2016-12-12 15:44:22 Training Error = 0.90251310643255 
2016-12-12 15:44:22 Training Loss = 0.015221220830613 
2016-12-12 15:44:31 Valid Error = 0.95320104829652 
2016-12-12 15:44:31 Valid Loss = 0.015694563723547 
2016-12-12 15:44:42 Test Error = 0.96362411586393 
2016-12-12 15:44:42 Test Loss = 0.015757473889881 
2016-12-12 15:44:42 -------------------LR------------------- 
2016-12-12 15:44:42 0.00048828125 
2016-12-12 15:44:42 Epoch 283 
2016-12-12 15:52:45 Training Error = 0.90513439294333 
2016-12-12 15:52:45 Training Loss = 0.015234607464764 
2016-12-12 15:52:55 Valid Error = 0.95731935604642 
2016-12-12 15:52:55 Valid Loss = 0.015695393123566 
2016-12-12 15:53:05 Test Error = 0.96934994947794 
2016-12-12 15:53:05 Test Loss = 0.015752835785169 
2016-12-12 15:53:05 -------------------LR------------------- 
2016-12-12 15:53:05 0.00048828125 
2016-12-12 15:53:05 Epoch 284 
2016-12-12 16:01:13 Training Error = 0.90367812265957 
2016-12-12 16:01:13 Training Loss = 0.015228713191291 
2016-12-12 16:01:22 Valid Error = 0.95207787345563 
2016-12-12 16:01:22 Valid Loss = 0.015677532161826 
2016-12-12 16:01:32 Test Error = 0.96227686089592 
2016-12-12 16:01:32 Test Loss = 0.015734691985624 
2016-12-12 16:01:32 -------------------LR------------------- 
2016-12-12 16:01:32 0.00048828125 
2016-12-12 16:01:32 Epoch 285 
2016-12-12 16:09:42 Training Error = 0.90355329949239 
2016-12-12 16:09:42 Training Loss = 0.015223454813669 
2016-12-12 16:09:52 Valid Error = 0.95544739797829 
2016-12-12 16:09:52 Valid Loss = 0.015688856847476 
2016-12-12 16:10:02 Test Error = 0.96463455708993 
2016-12-12 16:10:02 Test Loss = 0.015750879979294 
2016-12-12 16:10:02 -------------------LR------------------- 
2016-12-12 16:10:02 0.00048828125 
2016-12-12 16:10:02 Epoch 286 
2016-12-12 16:18:11 Training Error = 0.90380294582675 
2016-12-12 16:18:11 Training Loss = 0.015229649142556 
2016-12-12 16:18:20 Valid Error = 0.95320104829652 
2016-12-12 16:18:20 Valid Loss = 0.01567752495375 
2016-12-12 16:18:31 Test Error = 0.96362411586393 
2016-12-12 16:18:31 Test Loss = 0.015733133298515 
2016-12-12 16:18:31 -------------------LR------------------- 
2016-12-12 16:18:31 0.00048828125 
2016-12-12 16:18:31 Epoch 287 
2016-12-12 16:26:42 Training Error = 0.90334526088042 
2016-12-12 16:26:42 Training Loss = 0.015224857676416 
2016-12-12 16:26:52 Valid Error = 0.95544739797829 
2016-12-12 16:26:52 Valid Loss = 0.015734304072937 
2016-12-12 16:27:03 Test Error = 0.96463455708993 
2016-12-12 16:27:03 Test Loss = 0.01577972545257 
2016-12-12 16:27:03 -------------------LR------------------- 
2016-12-12 16:27:03 0.00048828125 
2016-12-12 16:27:03 Epoch 288 
2016-12-12 16:35:08 Training Error = 0.90288757593409 
2016-12-12 16:35:08 Training Loss = 0.015219604345549 
2016-12-12 16:35:18 Valid Error = 0.95544739797829 
2016-12-12 16:35:18 Valid Loss = 0.015683078021752 
2016-12-12 16:35:29 Test Error = 0.96463455708993 
2016-12-12 16:35:29 Test Loss = 0.015744287523908 
2016-12-12 16:35:29 -------------------LR------------------- 
2016-12-12 16:35:29 0.00048828125 
2016-12-12 16:35:29 Epoch 289 
2016-12-12 16:43:37 Training Error = 0.90251310643255 
2016-12-12 16:43:37 Training Loss = 0.015226299934059 
2016-12-12 16:43:46 Valid Error = 0.94795956570573 
2016-12-12 16:43:46 Valid Loss = 0.015690808293131 
2016-12-12 16:43:57 Test Error = 0.95655102728191 
2016-12-12 16:43:57 Test Loss = 0.015752934369348 
2016-12-12 16:43:57 -------------------LR------------------- 
2016-12-12 16:43:57 0.00048828125 
2016-12-12 16:43:57 Epoch 290 
2016-12-12 16:52:10 Training Error = 0.90326204543563 
2016-12-12 16:52:10 Training Loss = 0.01522522691009 
2016-12-12 16:52:19 Valid Error = 0.95207787345563 
2016-12-12 16:52:19 Valid Loss = 0.015674369256938 
2016-12-12 16:52:30 Test Error = 0.96227686089592 
2016-12-12 16:52:30 Test Loss = 0.015731348833939 
2016-12-12 16:52:30 -------------------LR------------------- 
2016-12-12 16:52:30 0.00048828125 
2016-12-12 16:52:30 Epoch 291 
2016-12-12 17:00:35 Training Error = 0.90263792959973 
2016-12-12 17:00:35 Training Loss = 0.0152205759758 
2016-12-12 17:00:44 Valid Error = 0.95544739797829 
2016-12-12 17:00:44 Valid Loss = 0.015669282271611 
2016-12-12 17:00:59 Test Error = 0.96463455708993 
2016-12-12 17:00:59 Test Loss = 0.015729375724652 
2016-12-12 17:00:59 -------------------LR------------------- 
2016-12-12 17:00:59 0.00048828125 
2016-12-12 17:00:59 Epoch 292 
2016-12-12 17:09:03 Training Error = 0.90342847632521 
2016-12-12 17:09:03 Training Loss = 0.01522507205909 
2016-12-12 17:09:13 Valid Error = 0.95320104829652 
2016-12-12 17:09:13 Valid Loss = 0.015672626293598 
2016-12-12 17:09:23 Test Error = 0.96362411586393 
2016-12-12 17:09:23 Test Loss = 0.015732978831641 
2016-12-12 17:09:23 -------------------LR------------------- 
2016-12-12 17:09:23 0.00048828125 
2016-12-12 17:09:23 Epoch 293 
2016-12-12 17:17:27 Training Error = 0.90280436048931 
2016-12-12 17:17:27 Training Loss = 0.015219015729182 
2016-12-12 17:17:37 Valid Error = 0.95544739797829 
2016-12-12 17:17:37 Valid Loss = 0.015723623522411 
2016-12-12 17:17:48 Test Error = 0.96463455708993 
2016-12-12 17:17:48 Test Loss = 0.015762196488709 
2016-12-12 17:17:48 -------------------LR------------------- 
2016-12-12 17:17:48 0.00048828125 
2016-12-12 17:17:48 Epoch 294 
2016-12-12 17:25:49 Training Error = 0.90255471415495 
2016-12-12 17:25:49 Training Loss = 0.015220610155102 
2016-12-12 17:25:59 Valid Error = 0.95320104829652 
2016-12-12 17:25:59 Valid Loss = 0.015659567204275 
2016-12-12 17:26:09 Test Error = 0.96362411586393 
2016-12-12 17:26:09 Test Loss = 0.015709648729696 
2016-12-12 17:26:09 -------------------LR------------------- 
2016-12-12 17:26:09 0.00048828125 
2016-12-12 17:26:09 Epoch 295 
2016-12-12 17:34:21 Training Error = 0.9040941998835 
2016-12-12 17:34:21 Training Loss = 0.015219582518632 
2016-12-12 17:34:31 Valid Error = 0.95320104829652 
2016-12-12 17:34:31 Valid Loss = 0.015657135570068 
2016-12-12 17:34:41 Test Error = 0.96362411586393 
2016-12-12 17:34:41 Test Loss = 0.015712840991514 
2016-12-12 17:34:41 -------------------LR------------------- 
2016-12-12 17:34:41 0.00048828125 
2016-12-12 17:34:41 Epoch 296 
2016-12-12 17:42:53 Training Error = 0.90334526088042 
2016-12-12 17:42:53 Training Loss = 0.015218295967574 
2016-12-12 17:43:02 Valid Error = 0.95207787345563 
2016-12-12 17:43:02 Valid Loss = 0.015695979408672 
2016-12-12 17:43:13 Test Error = 0.96227686089592 
2016-12-12 17:43:13 Test Loss = 0.015754642210145 
2016-12-12 17:43:13 -------------------LR------------------- 
2016-12-12 17:43:13 0.00048828125 
2016-12-12 17:43:13 Epoch 297 
2016-12-12 17:51:16 Training Error = 0.90288757593409 
2016-12-12 17:51:16 Training Loss = 0.015225801806422 
2016-12-12 17:51:25 Valid Error = 0.95731935604642 
2016-12-12 17:51:25 Valid Loss = 0.015667866078313 
2016-12-12 17:51:36 Test Error = 0.96934994947794 
2016-12-12 17:51:36 Test Loss = 0.015723933777046 
2016-12-12 17:51:36 -------------------LR------------------- 
2016-12-12 17:51:36 0.00048828125 
2016-12-12 17:51:36 Epoch 298 
2016-12-12 17:59:43 Training Error = 0.90338686860281 
2016-12-12 17:59:43 Training Loss = 0.015221915213559 
2016-12-12 17:59:53 Valid Error = 0.95731935604642 
2016-12-12 17:59:53 Valid Loss = 0.015698684054512 
2016-12-12 18:00:03 Test Error = 0.96934994947794 
2016-12-12 18:00:03 Test Loss = 0.015756585871429 
2016-12-12 18:00:03 -------------------LR------------------- 
2016-12-12 18:00:03 0.00048828125 
2016-12-12 18:00:03 Epoch 299 
2016-12-12 18:08:15 Training Error = 0.90280436048931 
2016-12-12 18:08:15 Training Loss = 0.015219217038549 
2016-12-12 18:08:24 Valid Error = 0.9502059153875 
2016-12-12 18:08:24 Valid Loss = 0.015745785360988 
2016-12-12 18:08:35 Test Error = 0.95756146850792 
2016-12-12 18:08:35 Test Loss = 0.015776277683725 
2016-12-12 18:08:35 -------------------LR------------------- 
2016-12-12 18:08:35 0.00048828125 
2016-12-12 18:08:35 Epoch 300 
2016-12-12 18:16:48 Training Error = 0.9028459682117 
2016-12-12 18:16:48 Training Loss = 0.015217970159598 
2016-12-12 18:16:57 Valid Error = 0.95731935604642 
2016-12-12 18:16:57 Valid Loss = 0.015673119089103 
2016-12-12 18:17:08 Test Error = 0.96934994947794 
2016-12-12 18:17:08 Test Loss = 0.015731557633491 
2016-12-12 18:17:08 -------------------LR------------------- 
2016-12-12 18:17:08 0.000244140625 
2016-12-12 18:17:08 Epoch 301 
2016-12-12 18:25:14 Training Error = 0.9022218523758 
2016-12-12 18:25:14 Training Loss = 0.015221615193489 
2016-12-12 18:25:23 Valid Error = 0.94795956570573 
2016-12-12 18:25:23 Valid Loss = 0.015664484566343 
2016-12-12 18:25:34 Test Error = 0.95655102728191 
2016-12-12 18:25:34 Test Loss = 0.01572343741559 
2016-12-12 18:25:34 -------------------LR------------------- 
2016-12-12 18:25:34 0.000244140625 
2016-12-12 18:25:34 Epoch 302 
2016-12-12 18:33:48 Training Error = 0.90197220604144 
2016-12-12 18:33:48 Training Loss = 0.015214624371397 
2016-12-12 18:33:57 Valid Error = 0.95320104829652 
2016-12-12 18:33:57 Valid Loss = 0.015670738100585 
2016-12-12 18:34:08 Test Error = 0.96362411586393 
2016-12-12 18:34:08 Test Loss = 0.015728525348305 
2016-12-12 18:34:08 -------------------LR------------------- 
2016-12-12 18:34:08 0.000244140625 
2016-12-12 18:34:08 Epoch 303 
2016-12-12 18:42:16 Training Error = 0.90371973038196 
2016-12-12 18:42:16 Training Loss = 0.015226532344782 
2016-12-12 18:42:25 Valid Error = 0.95544739797829 
2016-12-12 18:42:25 Valid Loss = 0.015698942183024 
2016-12-12 18:42:36 Test Error = 0.96463455708993 
2016-12-12 18:42:36 Test Loss = 0.015731735652408 
2016-12-12 18:42:36 -------------------LR------------------- 
2016-12-12 18:42:36 0.000244140625 
2016-12-12 18:42:36 Epoch 304 
2016-12-12 18:50:43 Training Error = 0.90288757593409 
2016-12-12 18:50:43 Training Loss = 0.015219820650881 
2016-12-12 18:50:53 Valid Error = 0.95544739797829 
2016-12-12 18:50:53 Valid Loss = 0.015700039400567 
2016-12-12 18:51:04 Test Error = 0.96463455708993 
2016-12-12 18:51:04 Test Loss = 0.015745415837139 
2016-12-12 18:51:04 -------------------LR------------------- 
2016-12-12 18:51:04 0.000244140625 
2016-12-12 18:51:04 Epoch 305 
2016-12-12 18:59:09 Training Error = 0.90371973038196 
2016-12-12 18:59:09 Training Loss = 0.015222826158891 
2016-12-12 18:59:19 Valid Error = 0.95544739797829 
2016-12-12 18:59:19 Valid Loss = 0.015679293754664 
2016-12-12 18:59:27 Test Error = 0.96463455708993 
2016-12-12 18:59:27 Test Loss = 0.015741728827478 
2016-12-12 18:59:27 -------------------LR------------------- 
2016-12-12 18:59:27 0.000244140625 
2016-12-12 18:59:27 Epoch 306 
2016-12-12 19:07:36 Training Error = 0.90442706166264 
2016-12-12 19:07:36 Training Loss = 0.015221785284364 
2016-12-12 19:07:45 Valid Error = 0.9502059153875 
2016-12-12 19:07:45 Valid Loss = 0.015673547666812 
2016-12-12 19:07:56 Test Error = 0.95756146850792 
2016-12-12 19:07:56 Test Loss = 0.015727656395462 
2016-12-12 19:07:56 -------------------LR------------------- 
2016-12-12 19:07:56 0.000244140625 
2016-12-12 19:07:56 Epoch 307 
2016-12-12 19:16:03 Training Error = 0.90259632187734 
2016-12-12 19:16:03 Training Loss = 0.015220656651443 
2016-12-12 19:16:12 Valid Error = 0.95544739797829 
2016-12-12 19:16:12 Valid Loss = 0.015661682245649 
2016-12-12 19:16:23 Test Error = 0.96463455708993 
2016-12-12 19:16:23 Test Loss = 0.015710697097684 
2016-12-12 19:16:23 -------------------LR------------------- 
2016-12-12 19:16:23 0.000244140625 
2016-12-12 19:16:23 Epoch 308 
2016-12-12 19:24:37 Training Error = 0.90238828326537 
2016-12-12 19:24:37 Training Loss = 0.01521891916197 
2016-12-12 19:24:47 Valid Error = 0.95544739797829 
2016-12-12 19:24:47 Valid Loss = 0.015709583627275 
2016-12-12 19:24:57 Test Error = 0.96463455708993 
2016-12-12 19:24:57 Test Loss = 0.015759493131386 
2016-12-12 19:24:57 -------------------LR------------------- 
2016-12-12 19:24:57 0.000244140625 
2016-12-12 19:24:57 Epoch 309 
2016-12-12 19:33:09 Training Error = 0.90388616127153 
2016-12-12 19:33:09 Training Loss = 0.015223676706448 
2016-12-12 19:33:20 Valid Error = 0.95731935604642 
2016-12-12 19:33:20 Valid Loss = 0.015705262289268 
2016-12-12 19:33:31 Test Error = 0.96934994947794 
2016-12-12 19:33:31 Test Loss = 0.015761516082871 
2016-12-12 19:33:31 -------------------LR------------------- 
2016-12-12 19:33:31 0.000244140625 
2016-12-12 19:33:31 Epoch 310 
2016-12-12 19:41:46 Training Error = 0.90384455354914 
2016-12-12 19:41:46 Training Loss = 0.015227065238567 
2016-12-12 19:41:56 Valid Error = 0.95544739797829 
2016-12-12 19:41:56 Valid Loss = 0.015695465861701 
2016-12-12 19:42:06 Test Error = 0.96463455708993 
2016-12-12 19:42:06 Test Loss = 0.015746391307516 
2016-12-12 19:42:06 -------------------LR------------------- 
2016-12-12 19:42:06 0.000244140625 
2016-12-12 19:42:06 Epoch 311 
2016-12-12 19:50:11 Training Error = 0.90484313888658 
2016-12-12 19:50:11 Training Loss = 0.015229064427004 
2016-12-12 19:50:21 Valid Error = 0.95544739797829 
2016-12-12 19:50:21 Valid Loss = 0.015677464874385 
2016-12-12 19:50:31 Test Error = 0.96463455708993 
2016-12-12 19:50:31 Test Loss = 0.015736767443995 
2016-12-12 19:50:31 -------------------LR------------------- 
2016-12-12 19:50:31 0.000244140625 
2016-12-12 19:50:31 Epoch 312 
2016-12-12 19:58:39 Training Error = 0.90338686860281 
2016-12-12 19:58:39 Training Loss = 0.015222823044725 
2016-12-12 19:58:48 Valid Error = 0.94795956570573 
2016-12-12 19:58:48 Valid Loss = 0.015693018898003 
2016-12-12 19:58:58 Test Error = 0.95655102728191 
2016-12-12 19:58:58 Test Loss = 0.015752893363575 
2016-12-12 19:58:58 -------------------LR------------------- 
2016-12-12 19:58:58 0.000244140625 
2016-12-12 19:58:58 Epoch 313 
2016-12-12 20:07:10 Training Error = 0.90380294582675 
2016-12-12 20:07:10 Training Loss = 0.015223233637139 
2016-12-12 20:07:20 Valid Error = 0.95544739797829 
2016-12-12 20:07:20 Valid Loss = 0.015692874301362 
2016-12-12 20:07:31 Test Error = 0.96463455708993 
2016-12-12 20:07:31 Test Loss = 0.015745711456122 
2016-12-12 20:07:31 -------------------LR------------------- 
2016-12-12 20:07:31 0.000244140625 
2016-12-12 20:07:31 Epoch 314 
2016-12-12 20:15:36 Training Error = 0.90413580760589 
2016-12-12 20:15:36 Training Loss = 0.015232049037001 
2016-12-12 20:15:45 Valid Error = 0.95207787345563 
2016-12-12 20:15:45 Valid Loss = 0.015689444776343 
2016-12-12 20:15:56 Test Error = 0.96227686089592 
2016-12-12 20:15:56 Test Loss = 0.015750762673505 
2016-12-12 20:15:56 -------------------LR------------------- 
2016-12-12 20:15:56 0.000244140625 
2016-12-12 20:15:56 Epoch 315 
2016-12-12 20:23:57 Training Error = 0.90259632187734 
2016-12-12 20:23:57 Training Loss = 0.015221593386143 
2016-12-12 20:24:06 Valid Error = 0.9502059153875 
2016-12-12 20:24:06 Valid Loss = 0.015712514241849 
2016-12-12 20:24:16 Test Error = 0.95756146850792 
2016-12-12 20:24:16 Test Loss = 0.015747199775022 
2016-12-12 20:24:16 -------------------LR------------------- 
2016-12-12 20:24:16 0.000244140625 
2016-12-12 20:24:16 Epoch 316 
2016-12-12 20:32:32 Training Error = 0.90326204543563 
2016-12-12 20:32:32 Training Loss = 0.015225256211183 
2016-12-12 20:32:41 Valid Error = 0.95544739797829 
2016-12-12 20:32:41 Valid Loss = 0.015708247598688 
2016-12-12 20:32:51 Test Error = 0.96463455708993 
2016-12-12 20:32:51 Test Loss = 0.015743597102222 
2016-12-12 20:32:51 -------------------LR------------------- 
2016-12-12 20:32:51 0.000244140625 
2016-12-12 20:32:51 Epoch 317 
2016-12-12 20:40:58 Training Error = 0.90426063077307 
2016-12-12 20:40:58 Training Loss = 0.015223493916164 
2016-12-12 20:41:07 Valid Error = 0.95731935604642 
2016-12-12 20:41:07 Valid Loss = 0.015673631713372 
2016-12-12 20:41:17 Test Error = 0.96934994947794 
2016-12-12 20:41:17 Test Loss = 0.015732925781296 
2016-12-12 20:41:17 -------------------LR------------------- 
2016-12-12 20:41:17 0.000244140625 
2016-12-12 20:41:17 Epoch 318 
2016-12-12 20:49:26 Training Error = 0.9040941998835 
2016-12-12 20:49:26 Training Loss = 0.015229418263064 
2016-12-12 20:49:35 Valid Error = 0.95544739797829 
2016-12-12 20:49:35 Valid Loss = 0.015710629325744 
2016-12-12 20:49:46 Test Error = 0.96463455708993 
2016-12-12 20:49:46 Test Loss = 0.01575343377996 
2016-12-12 20:49:46 -------------------LR------------------- 
2016-12-12 20:49:46 0.000244140625 
2016-12-12 20:49:46 Epoch 319 
2016-12-12 20:57:59 Training Error = 0.90188899059665 
2016-12-12 20:57:59 Training Loss = 0.015221762327571 
2016-12-12 20:58:08 Valid Error = 0.95544739797829 
2016-12-12 20:58:08 Valid Loss = 0.015749817519448 
2016-12-12 20:58:17 Test Error = 0.96463455708993 
2016-12-12 20:58:17 Test Loss = 0.01578907568179 
2016-12-12 20:58:17 -------------------LR------------------- 
2016-12-12 20:58:17 0.000244140625 
2016-12-12 20:58:17 Epoch 320 
2016-12-12 21:06:35 Training Error = 0.90313722226845 
2016-12-12 21:06:35 Training Loss = 0.015218921268656 
2016-12-12 21:06:45 Valid Error = 0.95731935604642 
2016-12-12 21:06:45 Valid Loss = 0.015657714919914 
2016-12-12 21:06:55 Test Error = 0.96934994947794 
2016-12-12 21:06:55 Test Loss = 0.015713358664687 
2016-12-12 21:06:55 -------------------LR------------------- 
2016-12-12 21:06:55 0.000244140625 
2016-12-12 21:06:55 Epoch 321 
2016-12-12 21:15:06 Training Error = 0.90209702920862 
2016-12-12 21:15:06 Training Loss = 0.015217410376951 
2016-12-12 21:15:15 Valid Error = 0.9502059153875 
2016-12-12 21:15:15 Valid Loss = 0.015660840916034 
2016-12-12 21:15:25 Test Error = 0.95756146850792 
2016-12-12 21:15:25 Test Loss = 0.015710293122075 
2016-12-12 21:15:25 -------------------LR------------------- 
2016-12-12 21:15:25 0.000244140625 
2016-12-12 21:15:25 Epoch 322 
2016-12-12 21:23:28 Training Error = 0.904676707997 
2016-12-12 21:23:28 Training Loss = 0.015227119516674 
2016-12-12 21:23:38 Valid Error = 0.95207787345563 
2016-12-12 21:23:38 Valid Loss = 0.015665465550079 
2016-12-12 21:23:49 Test Error = 0.96227686089592 
2016-12-12 21:23:49 Test Loss = 0.015721367749692 
2016-12-12 21:23:49 -------------------LR------------------- 
2016-12-12 21:23:49 0.000244140625 
2016-12-12 21:23:49 Epoch 323 
2016-12-12 21:31:56 Training Error = 0.90313722226845 
2016-12-12 21:31:56 Training Loss = 0.015221023252053 
2016-12-12 21:32:05 Valid Error = 0.9502059153875 
2016-12-12 21:32:05 Valid Loss = 0.015743799828366 
2016-12-12 21:32:15 Test Error = 0.95756146850792 
2016-12-12 21:32:15 Test Loss = 0.015781214204503 
2016-12-12 21:32:15 -------------------LR------------------- 
2016-12-12 21:32:15 0.000244140625 
2016-12-12 21:32:16 Epoch 324 
2016-12-12 21:40:20 Training Error = 0.9034700840476 
2016-12-12 21:40:20 Training Loss = 0.015221459706277 
2016-12-12 21:40:29 Valid Error = 0.95207787345563 
2016-12-12 21:40:29 Valid Loss = 0.015681373458613 
2016-12-12 21:40:41 Test Error = 0.96227686089592 
2016-12-12 21:40:41 Test Loss = 0.015743342383788 
2016-12-12 21:40:41 -------------------LR------------------- 
2016-12-12 21:40:41 0.000244140625 
2016-12-12 21:40:41 Epoch 325 
2016-12-12 21:48:46 Training Error = 0.90218024465341 
2016-12-12 21:48:46 Training Loss = 0.015217409105695 
2016-12-12 21:48:56 Valid Error = 0.95207787345563 
2016-12-12 21:48:56 Valid Loss = 0.015666660721534 
2016-12-12 21:49:08 Test Error = 0.96227686089592 
2016-12-12 21:49:08 Test Loss = 0.015724771619708 
2016-12-12 21:49:08 -------------------LR------------------- 
2016-12-12 21:49:08 0.000244140625 
2016-12-12 21:49:08 Epoch 326 
2016-12-12 21:57:13 Training Error = 0.90342847632521 
2016-12-12 21:57:13 Training Loss = 0.015227574845184 
2016-12-12 21:57:23 Valid Error = 0.95544739797829 
2016-12-12 21:57:23 Valid Loss = 0.015744729515901 
2016-12-12 21:57:33 Test Error = 0.96463455708993 
2016-12-12 21:57:33 Test Loss = 0.015778230430615 
2016-12-12 21:57:33 -------------------LR------------------- 
2016-12-12 21:57:33 0.000244140625 
2016-12-12 21:57:33 Epoch 327 
2016-12-12 22:05:39 Training Error = 0.90442706166264 
2016-12-12 22:05:39 Training Loss = 0.015225226404743 
2016-12-12 22:05:49 Valid Error = 0.95544739797829 
2016-12-12 22:05:49 Valid Loss = 0.015703065755313 
2016-12-12 22:05:59 Test Error = 0.96463455708993 
2016-12-12 22:05:59 Test Loss = 0.01576270652685 
2016-12-12 22:05:59 -------------------LR------------------- 
2016-12-12 22:05:59 0.000244140625 
2016-12-12 22:05:59 Epoch 328 
2016-12-12 22:14:09 Training Error = 0.90438545394025 
2016-12-12 22:14:09 Training Loss = 0.015226819411601 
2016-12-12 22:14:19 Valid Error = 0.95207787345563 
2016-12-12 22:14:19 Valid Loss = 0.01568981955881 
2016-12-12 22:14:30 Test Error = 0.96227686089592 
2016-12-12 22:14:30 Test Loss = 0.01574455524317 
2016-12-12 22:14:30 -------------------LR------------------- 
2016-12-12 22:14:30 0.000244140625 
2016-12-12 22:14:30 Epoch 329 
2016-12-12 22:22:32 Training Error = 0.90259632187734 
2016-12-12 22:22:32 Training Loss = 0.015220197326599 
2016-12-12 22:22:41 Valid Error = 0.95320104829652 
2016-12-12 22:22:41 Valid Loss = 0.015663281609342 
2016-12-12 22:22:51 Test Error = 0.96362411586393 
2016-12-12 22:22:51 Test Loss = 0.015719831781513 
2016-12-12 22:22:51 -------------------LR------------------- 
2016-12-12 22:22:51 0.000244140625 
2016-12-12 22:22:51 Epoch 330 
2016-12-12 22:31:00 Training Error = 0.90234667554298 
2016-12-12 22:31:00 Training Loss = 0.015216506048456 
2016-12-12 22:31:15 Valid Error = 0.95731935604642 
2016-12-12 22:31:15 Valid Loss = 0.015688767882745 
2016-12-12 22:31:26 Test Error = 0.96934994947794 
2016-12-12 22:31:26 Test Loss = 0.01574222123035 
2016-12-12 22:31:26 -------------------LR------------------- 
2016-12-12 22:31:26 0.000244140625 
2016-12-12 22:31:26 Epoch 331 
2016-12-12 22:39:30 Training Error = 0.90430223849546 
2016-12-12 22:39:30 Training Loss = 0.015227824468098 
2016-12-12 22:39:40 Valid Error = 0.95320104829652 
2016-12-12 22:39:40 Valid Loss = 0.015691043153031 
2016-12-12 22:39:51 Test Error = 0.96362411586393 
2016-12-12 22:39:51 Test Loss = 0.015753236498286 
2016-12-12 22:39:51 -------------------LR------------------- 
2016-12-12 22:39:51 0.000244140625 
2016-12-12 22:39:51 Epoch 332 
2016-12-12 22:48:03 Training Error = 0.90263792959973 
2016-12-12 22:48:03 Training Loss = 0.015220430448606 
2016-12-12 22:48:13 Valid Error = 0.95207787345563 
2016-12-12 22:48:13 Valid Loss = 0.015667365797546 
2016-12-12 22:48:24 Test Error = 0.96227686089592 
2016-12-12 22:48:24 Test Loss = 0.015724925881917 
2016-12-12 22:48:24 -------------------LR------------------- 
2016-12-12 22:48:24 0.000244140625 
2016-12-12 22:48:24 Epoch 333 
2016-12-12 22:56:28 Training Error = 0.90342847632521 
2016-12-12 22:56:28 Training Loss = 0.015218947805236 
2016-12-12 22:56:38 Valid Error = 0.95544739797829 
2016-12-12 22:56:38 Valid Loss = 0.015716746674431 
2016-12-12 22:56:48 Test Error = 0.96463455708993 
2016-12-12 22:56:48 Test Loss = 0.015782359191542 
2016-12-12 22:56:48 -------------------LR------------------- 
2016-12-12 22:56:48 0.000244140625 
2016-12-12 22:56:48 Epoch 334 
2016-12-12 23:04:56 Training Error = 0.90147291337272 
2016-12-12 23:04:56 Training Loss = 0.015216912501111 
2016-12-12 23:05:05 Valid Error = 0.94795956570573 
2016-12-12 23:05:05 Valid Loss = 0.015675309202215 
2016-12-12 23:05:16 Test Error = 0.95655102728191 
2016-12-12 23:05:16 Test Loss = 0.015737729263703 
2016-12-12 23:05:16 -------------------LR------------------- 
2016-12-12 23:05:16 0.000244140625 
2016-12-12 23:05:16 Epoch 335 
2016-12-12 23:13:21 Training Error = 0.90272114504452 
2016-12-12 23:13:21 Training Loss = 0.015228732627594 
2016-12-12 23:13:30 Valid Error = 0.95207787345563 
2016-12-12 23:13:30 Valid Loss = 0.015665630717141 
2016-12-12 23:13:40 Test Error = 0.96227686089592 
2016-12-12 23:13:40 Test Loss = 0.015724588972133 
2016-12-12 23:13:40 -------------------LR------------------- 
2016-12-12 23:13:40 0.000244140625 
2016-12-12 23:13:40 Epoch 336 
2016-12-12 23:21:50 Training Error = 0.90317882999085 
2016-12-12 23:21:50 Training Loss = 0.015221770272041 
2016-12-12 23:22:00 Valid Error = 0.95544739797829 
2016-12-12 23:22:00 Valid Loss = 0.015725974740317 
2016-12-12 23:22:11 Test Error = 0.96463455708993 
2016-12-12 23:22:11 Test Loss = 0.015772078584073 
2016-12-12 23:22:11 -------------------LR------------------- 
2016-12-12 23:22:11 0.000244140625 
2016-12-12 23:22:11 Epoch 337 
2016-12-12 23:30:22 Training Error = 0.90288757593409 
2016-12-12 23:30:22 Training Loss = 0.015220686949794 
2016-12-12 23:30:32 Valid Error = 0.95544739797829 
2016-12-12 23:30:32 Valid Loss = 0.015706724135792 
2016-12-12 23:30:43 Test Error = 0.96463455708993 
2016-12-12 23:30:43 Test Loss = 0.015755037601403 
2016-12-12 23:30:43 -------------------LR------------------- 
2016-12-12 23:30:43 0.000244140625 
2016-12-12 23:30:43 Epoch 338 
2016-12-12 23:38:49 Training Error = 0.90234667554298 
2016-12-12 23:38:49 Training Loss = 0.015220048744535 
2016-12-12 23:38:58 Valid Error = 0.95207787345563 
2016-12-12 23:38:58 Valid Loss = 0.015661250471565 
2016-12-12 23:39:09 Test Error = 0.96227686089592 
2016-12-12 23:39:09 Test Loss = 0.015714554682019 
2016-12-12 23:39:09 -------------------LR------------------- 
2016-12-12 23:39:09 0.000244140625 
2016-12-12 23:39:09 Epoch 339 
2016-12-12 23:47:13 Training Error = 0.90218024465341 
2016-12-12 23:47:13 Training Loss = 0.015222811623289 
2016-12-12 23:47:23 Valid Error = 0.95544739797829 
2016-12-12 23:47:23 Valid Loss = 0.015737500155823 
2016-12-12 23:47:33 Test Error = 0.96463455708993 
2016-12-12 23:47:33 Test Loss = 0.015764240311361 
2016-12-12 23:47:33 -------------------LR------------------- 
2016-12-12 23:47:33 0.000244140625 
2016-12-12 23:47:33 Epoch 340 
2016-12-12 23:55:42 Training Error = 0.90392776899393 
2016-12-12 23:55:42 Training Loss = 0.015222872214149 
2016-12-12 23:55:51 Valid Error = 0.95132909022838 
2016-12-12 23:55:51 Valid Loss = 0.015678562572008 
2016-12-12 23:56:02 Test Error = 0.95890872347592 
2016-12-12 23:56:02 Test Loss = 0.015737919885683 
2016-12-12 23:56:02 -------------------LR------------------- 
2016-12-12 23:56:02 0.000244140625 
2016-12-12 23:56:02 Epoch 341 
2016-12-13 00:04:16 Training Error = 0.90351169176999 
2016-12-13 00:04:16 Training Loss = 0.015226089292708 
2016-12-13 00:04:26 Valid Error = 0.95731935604642 
2016-12-13 00:04:26 Valid Loss = 0.015688317537222 
2016-12-13 00:04:38 Test Error = 0.96934994947794 
2016-12-13 00:04:38 Test Loss = 0.015746394927883 
2016-12-13 00:04:38 -------------------LR------------------- 
2016-12-13 00:04:38 0.000244140625 
2016-12-13 00:04:38 Epoch 342 
2016-12-13 00:12:44 Training Error = 0.90297079137888 
2016-12-13 00:12:44 Training Loss = 0.015218937446198 
2016-12-13 00:12:53 Valid Error = 0.95544739797829 
2016-12-13 00:12:53 Valid Loss = 0.015680738499333 
2016-12-13 00:13:04 Test Error = 0.96463455708993 
2016-12-13 00:13:04 Test Loss = 0.015741649937356 
2016-12-13 00:13:04 -------------------LR------------------- 
2016-12-13 00:13:04 0.000244140625 
2016-12-13 00:13:04 Epoch 343 
2016-12-13 00:21:10 Training Error = 0.90367812265957 
2016-12-13 00:21:10 Training Loss = 0.015225386139794 
2016-12-13 00:21:19 Valid Error = 0.9502059153875 
2016-12-13 00:21:19 Valid Loss = 0.015686868704065 
2016-12-13 00:21:30 Test Error = 0.95756146850792 
2016-12-13 00:21:30 Test Loss = 0.015749252154274 
2016-12-13 00:21:30 -------------------LR------------------- 
2016-12-13 00:21:30 0.000244140625 
2016-12-13 00:21:30 Epoch 344 
2016-12-13 00:29:30 Training Error = 0.90309561454606 
2016-12-13 00:29:30 Training Loss = 0.015218612059443 
2016-12-13 00:29:42 Valid Error = 0.94608760763759 
2016-12-13 00:29:42 Valid Loss = 0.015735691905898 
2016-12-13 00:29:53 Test Error = 0.9518356348939 
2016-12-13 00:29:53 Test Loss = 0.01578492255074 
2016-12-13 00:29:53 -------------------LR------------------- 
2016-12-13 00:29:53 0.000244140625 
2016-12-13 00:29:53 Epoch 345 
2016-12-13 00:37:56 Training Error = 0.90276275276691 
2016-12-13 00:37:56 Training Loss = 0.015221337884257 
2016-12-13 00:38:06 Valid Error = 0.95731935604642 
2016-12-13 00:38:06 Valid Loss = 0.015689211516503 
2016-12-13 00:38:17 Test Error = 0.96934994947794 
2016-12-13 00:38:17 Test Loss = 0.015745425890566 
2016-12-13 00:38:17 -------------------LR------------------- 
2016-12-13 00:38:17 0.000244140625 
2016-12-13 00:38:17 Epoch 346 
2016-12-13 00:46:20 Training Error = 0.90226346009819 
2016-12-13 00:46:20 Training Loss = 0.015219103938591 
2016-12-13 00:46:29 Valid Error = 0.95731935604642 
2016-12-13 00:46:29 Valid Loss = 0.015682346805385 
2016-12-13 00:46:39 Test Error = 0.96934994947794 
2016-12-13 00:46:39 Test Loss = 0.015735699736933 
2016-12-13 00:46:39 -------------------LR------------------- 
2016-12-13 00:46:39 0.000244140625 
2016-12-13 00:46:39 Epoch 347 
2016-12-13 00:54:42 Training Error = 0.90588333194641 
2016-12-13 00:54:42 Training Loss = 0.01523499875466 
2016-12-13 00:54:51 Valid Error = 0.9502059153875 
2016-12-13 00:54:51 Valid Loss = 0.015756788548118 
2016-12-13 00:55:02 Test Error = 0.95756146850792 
2016-12-13 00:55:02 Test Loss = 0.015794903171312 
2016-12-13 00:55:02 -------------------LR------------------- 
2016-12-13 00:55:02 0.000244140625 
2016-12-13 00:55:02 Epoch 348 
2016-12-13 01:03:13 Training Error = 0.90184738287426 
2016-12-13 01:03:13 Training Loss = 0.015223470828215 
2016-12-13 01:03:23 Valid Error = 0.94795956570573 
2016-12-13 01:03:23 Valid Loss = 0.015684594576857 
2016-12-13 01:03:33 Test Error = 0.95655102728191 
2016-12-13 01:03:33 Test Loss = 0.015744203740913 
2016-12-13 01:03:33 -------------------LR------------------- 
2016-12-13 01:03:33 0.000244140625 
2016-12-13 01:03:33 Epoch 349 
2016-12-13 01:11:38 Training Error = 0.90359490721478 
2016-12-13 01:11:38 Training Loss = 0.01523025731353 
2016-12-13 01:11:48 Valid Error = 0.95544739797829 
2016-12-13 01:11:48 Valid Loss = 0.015700284182339 
2016-12-13 01:11:58 Test Error = 0.96463455708993 
2016-12-13 01:11:58 Test Loss = 0.015758027287438 
2016-12-13 01:11:58 -------------------LR------------------- 
2016-12-13 01:11:58 0.000244140625 
2016-12-13 01:11:58 Epoch 350 
2016-12-13 01:20:04 Training Error = 0.90309561454606 
2016-12-13 01:20:04 Training Loss = 0.015219925997116 
2016-12-13 01:20:14 Valid Error = 0.95731935604642 
2016-12-13 01:20:14 Valid Loss = 0.015665727361289 
2016-12-13 01:20:24 Test Error = 0.96934994947794 
2016-12-13 01:20:24 Test Loss = 0.015720358302673 
2016-12-13 01:20:24 -------------------LR------------------- 
2016-12-13 01:20:24 0.0001220703125 
2016-12-13 01:20:24 Epoch 351 
2016-12-13 01:28:27 Training Error = 0.90396937671632 
2016-12-13 01:28:27 Training Loss = 0.015225897454661 
2016-12-13 01:28:41 Valid Error = 0.95320104829652 
2016-12-13 01:28:41 Valid Loss = 0.015653787865383 
2016-12-13 01:28:53 Test Error = 0.96362411586393 
2016-12-13 01:28:53 Test Loss = 0.015706921206915 
2016-12-13 01:28:53 -------------------LR------------------- 
2016-12-13 01:28:53 0.0001220703125 
2016-12-13 01:28:53 Epoch 352 
2016-12-13 01:36:53 Training Error = 0.90338686860281 
2016-12-13 01:36:53 Training Loss = 0.015223758043717 
2016-12-13 01:37:03 Valid Error = 0.95731935604642 
2016-12-13 01:37:03 Valid Loss = 0.015660101665653 
2016-12-13 01:37:13 Test Error = 0.96934994947794 
2016-12-13 01:37:13 Test Loss = 0.0157170813837 
2016-12-13 01:37:13 -------------------LR------------------- 
2016-12-13 01:37:13 0.0001220703125 
2016-12-13 01:37:13 Epoch 353 
2016-12-13 01:45:21 Training Error = 0.90263792959973 
2016-12-13 01:45:21 Training Loss = 0.015220565018817 
2016-12-13 01:45:31 Valid Error = 0.95731935604642 
2016-12-13 01:45:31 Valid Loss = 0.015664449393107 
2016-12-13 01:45:41 Test Error = 0.96934994947794 
2016-12-13 01:45:41 Test Loss = 0.015715996268582 
2016-12-13 01:45:41 -------------------LR------------------- 
2016-12-13 01:45:41 0.0001220703125 
2016-12-13 01:45:42 Epoch 354 
2016-12-13 01:53:55 Training Error = 0.90421902305068 
2016-12-13 01:53:55 Training Loss = 0.015227751494475 
2016-12-13 01:54:04 Valid Error = 0.95544739797829 
2016-12-13 01:54:04 Valid Loss = 0.015735558374833 
2016-12-13 01:54:14 Test Error = 0.96463455708993 
2016-12-13 01:54:14 Test Loss = 0.015764847049495 
2016-12-13 01:54:14 -------------------LR------------------- 
2016-12-13 01:54:14 0.0001220703125 
2016-12-13 01:54:15 Epoch 355 
2016-12-13 02:02:22 Training Error = 0.90292918365649 
2016-12-13 02:02:22 Training Loss = 0.015221839048944 
2016-12-13 02:02:32 Valid Error = 0.95544739797829 
2016-12-13 02:02:32 Valid Loss = 0.015676727146028 
2016-12-13 02:02:42 Test Error = 0.96463455708993 
2016-12-13 02:02:42 Test Loss = 0.015740079662413 
2016-12-13 02:02:42 -------------------LR------------------- 
2016-12-13 02:02:42 0.0001220703125 
2016-12-13 02:02:42 Epoch 356 
2016-12-13 02:10:47 Training Error = 0.90363651493717 
2016-12-13 02:10:47 Training Loss = 0.015215553358508 
2016-12-13 02:10:57 Valid Error = 0.95544739797829 
2016-12-13 02:10:57 Valid Loss = 0.01570727563285 
2016-12-13 02:11:07 Test Error = 0.96463455708993 
2016-12-13 02:11:07 Test Loss = 0.01577379470685 
2016-12-13 02:11:07 -------------------LR------------------- 
2016-12-13 02:11:07 0.0001220703125 
2016-12-13 02:11:07 Epoch 357 
2016-12-13 02:19:14 Training Error = 0.90267953732213 
2016-12-13 02:19:14 Training Loss = 0.0152219957338 
2016-12-13 02:19:24 Valid Error = 0.95731935604642 
2016-12-13 02:19:24 Valid Loss = 0.015677853750868 
2016-12-13 02:19:35 Test Error = 0.96934994947794 
2016-12-13 02:19:35 Test Loss = 0.015735569244729 
2016-12-13 02:19:35 -------------------LR------------------- 
2016-12-13 02:19:35 0.0001220703125 
2016-12-13 02:19:35 Epoch 358 
2016-12-13 02:27:36 Training Error = 0.90280436048931 
2016-12-13 02:27:36 Training Loss = 0.015224703744097 
2016-12-13 02:27:46 Valid Error = 0.95544739797829 
2016-12-13 02:27:46 Valid Loss = 0.01572160535867 
2016-12-13 02:27:55 Test Error = 0.96463455708993 
2016-12-13 02:27:55 Test Loss = 0.015773544340142 
2016-12-13 02:27:55 -------------------LR------------------- 
2016-12-13 02:27:55 0.0001220703125 
2016-12-13 02:27:55 Epoch 359 
2016-12-13 02:36:06 Training Error = 0.90430223849546 
2016-12-13 02:36:06 Training Loss = 0.015218778927779 
2016-12-13 02:36:15 Valid Error = 0.95320104829652 
2016-12-13 02:36:15 Valid Loss = 0.015664581804817 
2016-12-13 02:36:26 Test Error = 0.96362411586393 
2016-12-13 02:36:26 Test Loss = 0.015721344796611 
2016-12-13 02:36:26 -------------------LR------------------- 
2016-12-13 02:36:26 0.0001220703125 
2016-12-13 02:36:26 Epoch 360 
2016-12-13 02:44:37 Training Error = 0.90455188482982 
2016-12-13 02:44:37 Training Loss = 0.015221983725227 
2016-12-13 02:44:47 Valid Error = 0.95544739797829 
2016-12-13 02:44:47 Valid Loss = 0.015712946666445 
2016-12-13 02:44:57 Test Error = 0.96463455708993 
2016-12-13 02:44:57 Test Loss = 0.01577193526564 
2016-12-13 02:44:57 -------------------LR------------------- 
2016-12-13 02:44:57 0.0001220703125 
2016-12-13 02:44:57 Epoch 361 
2016-12-13 02:53:01 Training Error = 0.90338686860281 
2016-12-13 02:53:01 Training Loss = 0.015221746462293 
2016-12-13 02:53:11 Valid Error = 0.9502059153875 
2016-12-13 02:53:11 Valid Loss = 0.015751804021595 
2016-12-13 02:53:22 Test Error = 0.95756146850792 
2016-12-13 02:53:22 Test Loss = 0.01578818038965 
2016-12-13 02:53:22 -------------------LR------------------- 
2016-12-13 02:53:22 0.0001220703125 
2016-12-13 02:53:22 Epoch 362 
2016-12-13 03:01:34 Training Error = 0.90330365315803 
2016-12-13 03:01:34 Training Loss = 0.015223746282267 
2016-12-13 03:01:43 Valid Error = 0.9502059153875 
2016-12-13 03:01:43 Valid Loss = 0.015745836984318 
2016-12-13 03:01:54 Test Error = 0.95756146850792 
2016-12-13 03:01:54 Test Loss = 0.015779936221875 
2016-12-13 03:01:54 -------------------LR------------------- 
2016-12-13 03:01:54 0.0001220703125 
2016-12-13 03:01:54 Epoch 363 
2016-12-13 03:09:57 Training Error = 0.90384455354914 
2016-12-13 03:09:57 Training Loss = 0.015228664290314 
2016-12-13 03:10:06 Valid Error = 0.95731935604642 
2016-12-13 03:10:06 Valid Loss = 0.01568450208113 
2016-12-13 03:10:16 Test Error = 0.96934994947794 
2016-12-13 03:10:16 Test Loss = 0.015740044514442 
2016-12-13 03:10:16 -------------------LR------------------- 
2016-12-13 03:10:16 0.0001220703125 
2016-12-13 03:10:16 Epoch 364 
2016-12-13 03:18:20 Training Error = 0.90388616127153 
2016-12-13 03:18:20 Training Loss = 0.015224844591132 
2016-12-13 03:18:29 Valid Error = 0.95207787345563 
2016-12-13 03:18:29 Valid Loss = 0.01568684434107 
2016-12-13 03:18:40 Test Error = 0.96227686089592 
2016-12-13 03:18:40 Test Loss = 0.015743126399582 
2016-12-13 03:18:40 -------------------LR------------------- 
2016-12-13 03:18:40 0.0001220703125 
2016-12-13 03:18:40 Epoch 365 
2016-12-13 03:26:48 Training Error = 0.90359490721478 
2016-12-13 03:26:48 Training Loss = 0.015230739365862 
2016-12-13 03:26:57 Valid Error = 0.95544739797829 
2016-12-13 03:26:57 Valid Loss = 0.015711205236366 
2016-12-13 03:27:08 Test Error = 0.96463455708993 
2016-12-13 03:27:08 Test Loss = 0.01575633781905 
2016-12-13 03:27:08 -------------------LR------------------- 
2016-12-13 03:27:08 0.0001220703125 
2016-12-13 03:27:08 Epoch 366 
2016-12-13 03:35:16 Training Error = 0.90267953732213 
2016-12-13 03:35:16 Training Loss = 0.015218191640212 
2016-12-13 03:35:26 Valid Error = 0.9502059153875 
2016-12-13 03:35:26 Valid Loss = 0.015725389123203 
2016-12-13 03:35:37 Test Error = 0.95756146850792 
2016-12-13 03:35:37 Test Loss = 0.015762300757245 
2016-12-13 03:35:37 -------------------LR------------------- 
2016-12-13 03:35:37 0.0001220703125 
2016-12-13 03:35:37 Epoch 367 
2016-12-13 03:43:40 Training Error = 0.90309561454606 
2016-12-13 03:43:40 Training Loss = 0.015220759905307 
2016-12-13 03:43:50 Valid Error = 0.95731935604642 
2016-12-13 03:43:50 Valid Loss = 0.015674443555178 
2016-12-13 03:44:00 Test Error = 0.96934994947794 
2016-12-13 03:44:00 Test Loss = 0.015732249009701 
2016-12-13 03:44:00 -------------------LR------------------- 
2016-12-13 03:44:00 0.0001220703125 
2016-12-13 03:44:00 Epoch 368 
2016-12-13 03:52:06 Training Error = 0.90317882999085 
2016-12-13 03:52:06 Training Loss = 0.015220631302576 
2016-12-13 03:52:16 Valid Error = 0.95544739797829 
2016-12-13 03:52:16 Valid Loss = 0.015723452292224 
2016-12-13 03:52:27 Test Error = 0.96463455708993 
2016-12-13 03:52:27 Test Loss = 0.015775362385328 
2016-12-13 03:52:27 -------------------LR------------------- 
2016-12-13 03:52:27 0.0001220703125 
2016-12-13 03:52:27 Epoch 369 
2016-12-13 04:00:39 Training Error = 0.90193059831905 
2016-12-13 04:00:39 Training Loss = 0.015216063688678 
2016-12-13 04:00:48 Valid Error = 0.95544739797829 
2016-12-13 04:00:48 Valid Loss = 0.015680054972632 
2016-12-13 04:00:59 Test Error = 0.96463455708993 
2016-12-13 04:00:59 Test Loss = 0.015740394314051 
2016-12-13 04:00:59 -------------------LR------------------- 
2016-12-13 04:00:59 0.0001220703125 
2016-12-13 04:00:59 Epoch 370 
2016-12-13 04:09:10 Training Error = 0.90317882999085 
2016-12-13 04:09:10 Training Loss = 0.015222978336516 
2016-12-13 04:09:20 Valid Error = 0.95731935604642 
2016-12-13 04:09:20 Valid Loss = 0.015662457363478 
2016-12-13 04:09:30 Test Error = 0.96934994947794 
2016-12-13 04:09:30 Test Loss = 0.015721125061376 
2016-12-13 04:09:30 -------------------LR------------------- 
2016-12-13 04:09:30 0.0001220703125 
2016-12-13 04:09:31 Epoch 371 
2016-12-13 04:17:35 Training Error = 0.90388616127153 
2016-12-13 04:17:35 Training Loss = 0.015227637106904 
2016-12-13 04:17:45 Valid Error = 0.95207787345563 
2016-12-13 04:17:45 Valid Loss = 0.015667034744237 
2016-12-13 04:17:55 Test Error = 0.96227686089592 
2016-12-13 04:17:55 Test Loss = 0.015720567549712 
2016-12-13 04:17:55 -------------------LR------------------- 
2016-12-13 04:17:55 0.0001220703125 
2016-12-13 04:17:55 Epoch 372 
2016-12-13 04:25:53 Training Error = 0.90421902305068 
2016-12-13 04:25:53 Training Loss = 0.01522601822071 
2016-12-13 04:26:03 Valid Error = 0.94795956570573 
2016-12-13 04:26:03 Valid Loss = 0.015684633038863 
2016-12-13 04:26:11 Test Error = 0.95655102728191 
2016-12-13 04:26:11 Test Loss = 0.015745042854924 
2016-12-13 04:26:11 -------------------LR------------------- 
2016-12-13 04:26:11 0.0001220703125 
2016-12-13 04:26:11 Epoch 373 
2016-12-13 04:34:21 Training Error = 0.90168095198469 
2016-12-13 04:34:21 Training Loss = 0.015223380099956 
2016-12-13 04:34:31 Valid Error = 0.95207787345563 
2016-12-13 04:34:31 Valid Loss = 0.015665918389648 
2016-12-13 04:34:43 Test Error = 0.96227686089592 
2016-12-13 04:34:43 Test Loss = 0.015719880422318 
2016-12-13 04:34:43 -------------------LR------------------- 
2016-12-13 04:34:43 0.0001220703125 
2016-12-13 04:34:43 Epoch 374 
2016-12-13 04:42:44 Training Error = 0.90305400682367 
2016-12-13 04:42:44 Training Loss = 0.015217830134848 
2016-12-13 04:42:54 Valid Error = 0.95731935604642 
2016-12-13 04:42:54 Valid Loss = 0.015658938576564 
2016-12-13 04:43:04 Test Error = 0.96934994947794 
2016-12-13 04:43:04 Test Loss = 0.015716152469324 
2016-12-13 04:43:04 -------------------LR------------------- 
2016-12-13 04:43:04 0.0001220703125 
2016-12-13 04:43:04 Epoch 375 
2016-12-13 04:51:12 Training Error = 0.90280436048931 
2016-12-13 04:51:12 Training Loss = 0.015221268223726 
2016-12-13 04:51:22 Valid Error = 0.95731935604642 
2016-12-13 04:51:22 Valid Loss = 0.01566761019538 
2016-12-13 04:51:33 Test Error = 0.96934994947794 
2016-12-13 04:51:33 Test Loss = 0.015721363358653 
2016-12-13 04:51:33 -------------------LR------------------- 
2016-12-13 04:51:33 0.0001220703125 
2016-12-13 04:51:33 Epoch 376 
2016-12-13 04:59:37 Training Error = 0.90326204543563 
2016-12-13 04:59:37 Training Loss = 0.01522313104198 
2016-12-13 04:59:50 Valid Error = 0.95544739797829 
2016-12-13 04:59:50 Valid Loss = 0.015700248571475 
2016-12-13 05:00:01 Test Error = 0.96463455708993 
2016-12-13 05:00:01 Test Loss = 0.01574714141149 
2016-12-13 05:00:01 -------------------LR------------------- 
2016-12-13 05:00:01 0.0001220703125 
2016-12-13 05:00:01 Epoch 377 
2016-12-13 05:08:08 Training Error = 0.90259632187734 
2016-12-13 05:08:08 Training Loss = 0.015220708361334 
2016-12-13 05:08:18 Valid Error = 0.95207787345563 
2016-12-13 05:08:18 Valid Loss = 0.015658991496549 
2016-12-13 05:08:29 Test Error = 0.96227686089592 
2016-12-13 05:08:29 Test Loss = 0.015711963998358 
2016-12-13 05:08:29 -------------------LR------------------- 
2016-12-13 05:08:29 0.0001220703125 
2016-12-13 05:08:29 Epoch 378 
2016-12-13 05:16:38 Training Error = 0.90442706166264 
2016-12-13 05:16:38 Training Loss = 0.015220536952758 
2016-12-13 05:16:48 Valid Error = 0.95544739797829 
2016-12-13 05:16:48 Valid Loss = 0.015704846610681 
2016-12-13 05:16:59 Test Error = 0.96463455708993 
2016-12-13 05:16:59 Test Loss = 0.015750735921987 
2016-12-13 05:16:59 -------------------LR------------------- 
2016-12-13 05:16:59 0.0001220703125 
2016-12-13 05:16:59 Epoch 379 
2016-12-13 05:25:02 Training Error = 0.9022218523758 
2016-12-13 05:25:02 Training Loss = 0.015217110209951 
2016-12-13 05:25:11 Valid Error = 0.95731935604642 
2016-12-13 05:25:11 Valid Loss = 0.015666559820339 
2016-12-13 05:25:22 Test Error = 0.96934994947794 
2016-12-13 05:25:22 Test Loss = 0.015723822829158 
2016-12-13 05:25:22 -------------------LR------------------- 
2016-12-13 05:25:22 0.0001220703125 
2016-12-13 05:25:22 Epoch 380 
2016-12-13 05:33:30 Training Error = 0.90234667554298 
2016-12-13 05:33:30 Training Loss = 0.015223586642444 
2016-12-13 05:33:39 Valid Error = 0.95731935604642 
2016-12-13 05:33:39 Valid Loss = 0.015681404904826 
2016-12-13 05:33:49 Test Error = 0.96934994947794 
2016-12-13 05:33:49 Test Loss = 0.015737940641799 
2016-12-13 05:33:49 -------------------LR------------------- 
2016-12-13 05:33:49 0.0001220703125 
2016-12-13 05:33:49 Epoch 381 
2016-12-13 05:41:54 Training Error = 0.90513439294333 
2016-12-13 05:41:54 Training Loss = 0.015227940818638 
2016-12-13 05:42:04 Valid Error = 0.95320104829652 
2016-12-13 05:42:04 Valid Loss = 0.015666042138681 
2016-12-13 05:42:15 Test Error = 0.96362411586393 
2016-12-13 05:42:15 Test Loss = 0.015722922792152 
2016-12-13 05:42:15 -------------------LR------------------- 
2016-12-13 05:42:15 0.0001220703125 
2016-12-13 05:42:15 Epoch 382 
2016-12-13 05:50:21 Training Error = 0.90446866938504 
2016-12-13 05:50:21 Training Loss = 0.015230491802896 
2016-12-13 05:50:31 Valid Error = 0.95731935604642 
2016-12-13 05:50:31 Valid Loss = 0.015695102046796 
2016-12-13 05:50:41 Test Error = 0.96934994947794 
2016-12-13 05:50:41 Test Loss = 0.015758269504563 
2016-12-13 05:50:41 -------------------LR------------------- 
2016-12-13 05:50:41 0.0001220703125 
2016-12-13 05:50:41 Epoch 383 
2016-12-13 05:58:50 Training Error = 0.9028459682117 
2016-12-13 05:58:50 Training Loss = 0.015215232943143 
2016-12-13 05:59:05 Valid Error = 0.95731935604642 
2016-12-13 05:59:05 Valid Loss = 0.015696009954031 
2016-12-13 05:59:16 Test Error = 0.96934994947794 
2016-12-13 05:59:16 Test Loss = 0.015751201622484 
2016-12-13 05:59:16 -------------------LR------------------- 
2016-12-13 05:59:16 0.0001220703125 
2016-12-13 05:59:16 Epoch 384 
2016-12-13 06:07:23 Training Error = 0.90272114504452 
2016-12-13 06:07:23 Training Loss = 0.015223346601267 
2016-12-13 06:07:32 Valid Error = 0.95731935604642 
2016-12-13 06:07:32 Valid Loss = 0.015661860229426 
2016-12-13 06:07:43 Test Error = 0.96934994947794 
2016-12-13 06:07:43 Test Loss = 0.015715654384985 
2016-12-13 06:07:43 -------------------LR------------------- 
2016-12-13 06:07:43 0.0001220703125 
2016-12-13 06:07:43 Epoch 385 
2016-12-13 06:15:49 Training Error = 0.90455188482982 
2016-12-13 06:15:49 Training Loss = 0.015222591173817 
2016-12-13 06:15:59 Valid Error = 0.95544739797829 
2016-12-13 06:15:59 Valid Loss = 0.015750605777999 
2016-12-13 06:16:10 Test Error = 0.96463455708993 
2016-12-13 06:16:10 Test Loss = 0.015786513980144 
2016-12-13 06:16:10 -------------------LR------------------- 
2016-12-13 06:16:10 0.0001220703125 
2016-12-13 06:16:10 Epoch 386 
2016-12-13 06:23:56 Training Error = 0.90313722226845 
2016-12-13 06:23:56 Training Loss = 0.015226697449076 
2016-12-13 06:24:05 Valid Error = 0.95544739797829 
2016-12-13 06:24:05 Valid Loss = 0.015728886412622 
2016-12-13 06:24:21 Test Error = 0.96463455708993 
2016-12-13 06:24:21 Test Loss = 0.015778730601493 
2016-12-13 06:24:21 -------------------LR------------------- 
2016-12-13 06:24:21 0.0001220703125 
2016-12-13 06:24:21 Epoch 387 
2016-12-13 06:32:06 Training Error = 0.90280436048931 
2016-12-13 06:32:06 Training Loss = 0.015220469149744 
2016-12-13 06:32:16 Valid Error = 0.9502059153875 
2016-12-13 06:32:16 Valid Loss = 0.015745470780872 
2016-12-13 06:32:27 Test Error = 0.95756146850792 
2016-12-13 06:32:27 Test Loss = 0.015772590663079 
2016-12-13 06:32:27 -------------------LR------------------- 
2016-12-13 06:32:27 0.0001220703125 
2016-12-13 06:32:27 Epoch 388 
2016-12-13 06:40:14 Training Error = 0.90376133810435 
2016-12-13 06:40:14 Training Loss = 0.015228040404497 
2016-12-13 06:40:25 Valid Error = 0.95207787345563 
2016-12-13 06:40:25 Valid Loss = 0.015670197542995 
2016-12-13 06:40:36 Test Error = 0.96227686089592 
2016-12-13 06:40:36 Test Loss = 0.015722601398144 
2016-12-13 06:40:36 -------------------LR------------------- 
2016-12-13 06:40:36 0.0001220703125 
2016-12-13 06:40:36 Epoch 389 
2016-12-13 06:48:23 Training Error = 0.90251310643255 
2016-12-13 06:48:23 Training Loss = 0.015221313863314 
2016-12-13 06:48:33 Valid Error = 0.95320104829652 
2016-12-13 06:48:33 Valid Loss = 0.015638597925739 
2016-12-13 06:48:44 Test Error = 0.96362411586393 
2016-12-13 06:48:44 Test Loss = 0.01569592569721 
2016-12-13 06:48:44 -------------------LR------------------- 
2016-12-13 06:48:44 0.0001220703125 
2016-12-13 06:48:44 Epoch 390 
2016-12-13 06:56:35 Training Error = 0.90342847632521 
2016-12-13 06:56:35 Training Loss = 0.015224427611769 
2016-12-13 06:56:45 Valid Error = 0.95731935604642 
2016-12-13 06:56:45 Valid Loss = 0.015692695555949 
2016-12-13 06:56:55 Test Error = 0.96934994947794 
2016-12-13 06:56:55 Test Loss = 0.015760800590345 
2016-12-13 06:56:55 -------------------LR------------------- 
2016-12-13 06:56:55 0.0001220703125 
2016-12-13 06:56:55 Epoch 391 
2016-12-13 07:04:40 Training Error = 0.90430223849546 
2016-12-13 07:04:40 Training Loss = 0.015226831894557 
2016-12-13 07:04:48 Valid Error = 0.95731935604642 
2016-12-13 07:04:48 Valid Loss = 0.015641689196866 
2016-12-13 07:05:05 Test Error = 0.96934994947794 
2016-12-13 07:05:05 Test Loss = 0.015700489819125 
2016-12-13 07:05:05 -------------------LR------------------- 
2016-12-13 07:05:05 0.0001220703125 
2016-12-13 07:05:05 Epoch 392 
2016-12-13 07:12:54 Training Error = 0.90267953732213 
2016-12-13 07:12:54 Training Loss = 0.015217876113573 
2016-12-13 07:13:04 Valid Error = 0.95731935604642 
2016-12-13 07:13:04 Valid Loss = 0.015670227606401 
2016-12-13 07:13:15 Test Error = 0.96934994947794 
2016-12-13 07:13:15 Test Loss = 0.015730746324963 
2016-12-13 07:13:15 -------------------LR------------------- 
2016-12-13 07:13:15 0.0001220703125 
2016-12-13 07:13:15 Epoch 393 
2016-12-13 07:21:01 Training Error = 0.90309561454606 
2016-12-13 07:21:01 Training Loss = 0.015223749132368 
2016-12-13 07:21:11 Valid Error = 0.95544739797829 
2016-12-13 07:21:11 Valid Loss = 0.015677123274911 
2016-12-13 07:21:23 Test Error = 0.96463455708993 
2016-12-13 07:21:23 Test Loss = 0.015737213072904 
2016-12-13 07:21:23 -------------------LR------------------- 
2016-12-13 07:21:23 0.0001220703125 
2016-12-13 07:21:23 Epoch 394 
2016-12-13 07:29:10 Training Error = 0.90201381376383 
2016-12-13 07:29:10 Training Loss = 0.015220223103405 
2016-12-13 07:29:20 Valid Error = 0.95731935604642 
2016-12-13 07:29:20 Valid Loss = 0.015668645712895 
2016-12-13 07:29:30 Test Error = 0.96934994947794 
2016-12-13 07:29:30 Test Loss = 0.015729305494041 
2016-12-13 07:29:30 -------------------LR------------------- 
2016-12-13 07:29:30 0.0001220703125 
2016-12-13 07:29:30 Epoch 395 
2016-12-13 07:37:19 Training Error = 0.9028459682117 
2016-12-13 07:37:19 Training Loss = 0.015222460980849 
2016-12-13 07:37:29 Valid Error = 0.95731935604642 
2016-12-13 07:37:29 Valid Loss = 0.015671400249655 
2016-12-13 07:37:40 Test Error = 0.96934994947794 
2016-12-13 07:37:40 Test Loss = 0.015729134219228 
2016-12-13 07:37:40 -------------------LR------------------- 
2016-12-13 07:37:40 0.0001220703125 
2016-12-13 07:37:40 Epoch 396 
2016-12-13 07:45:29 Training Error = 0.90484313888658 
2016-12-13 07:45:29 Training Loss = 0.015229482883558 
2016-12-13 07:45:39 Valid Error = 0.95544739797829 
2016-12-13 07:45:39 Valid Loss = 0.015664427076541 
2016-12-13 07:45:49 Test Error = 0.96463455708993 
2016-12-13 07:45:49 Test Loss = 0.015722496289557 
2016-12-13 07:45:49 -------------------LR------------------- 
2016-12-13 07:45:49 0.0001220703125 
2016-12-13 07:45:49 Epoch 397 
2016-12-13 07:53:40 Training Error = 0.90338686860281 
2016-12-13 07:53:40 Training Loss = 0.015223791519037 
2016-12-13 07:53:50 Valid Error = 0.95207787345563 
2016-12-13 07:53:50 Valid Loss = 0.015690151604743 
2016-12-13 07:54:01 Test Error = 0.96227686089592 
2016-12-13 07:54:01 Test Loss = 0.015749954962218 
2016-12-13 07:54:01 -------------------LR------------------- 
2016-12-13 07:54:01 0.0001220703125 
2016-12-13 07:54:01 Epoch 398 
2016-12-13 08:01:54 Training Error = 0.90230506782059 
2016-12-13 08:01:54 Training Loss = 0.015222154416677 
2016-12-13 08:02:04 Valid Error = 0.9502059153875 
2016-12-13 08:02:04 Valid Loss = 0.015765123200955 
2016-12-13 08:02:15 Test Error = 0.95756146850792 
2016-12-13 08:02:15 Test Loss = 0.015800737080019 
2016-12-13 08:02:15 -------------------LR------------------- 
2016-12-13 08:02:15 0.0001220703125 
2016-12-13 08:02:15 Epoch 399 
2016-12-13 08:10:10 Training Error = 0.90392776899393 
2016-12-13 08:10:10 Training Loss = 0.015224692146812 
2016-12-13 08:10:20 Valid Error = 0.95207787345563 
2016-12-13 08:10:20 Valid Loss = 0.015656462904799 
2016-12-13 08:10:30 Test Error = 0.96227686089592 
2016-12-13 08:10:30 Test Loss = 0.015711239874651 
2016-12-13 08:10:30 -------------------LR------------------- 
2016-12-13 08:10:30 0.0001220703125 
2016-12-13 08:10:30 Epoch 400 
2016-12-13 08:18:25 Training Error = 0.90313722226845 
2016-12-13 08:18:25 Training Loss = 0.015222097619136 
2016-12-13 08:18:35 Valid Error = 0.9502059153875 
2016-12-13 08:18:35 Valid Loss = 0.015758110496423 
2016-12-13 08:18:47 Test Error = 0.95756146850792 
2016-12-13 08:18:47 Test Loss = 0.015787647963857 
2016-12-13 08:18:47 -------------------LR------------------- 
2016-12-13 08:18:47 6.103515625e-05 
2016-12-13 08:18:47 Epoch 401 
2016-12-13 08:26:37 Training Error = 0.90213863693101 
2016-12-13 08:26:37 Training Loss = 0.015220019641784 
2016-12-13 08:26:47 Valid Error = 0.95207787345563 
2016-12-13 08:26:47 Valid Loss = 0.015665072532043 
2016-12-13 08:26:58 Test Error = 0.96227686089592 
2016-12-13 08:26:58 Test Loss = 0.015720485223653 
2016-12-13 08:26:58 -------------------LR------------------- 
2016-12-13 08:26:58 6.103515625e-05 
2016-12-13 08:26:58 Epoch 402 
2016-12-13 08:34:51 Training Error = 0.90309561454606 
2016-12-13 08:34:51 Training Loss = 0.015221958936623 
2016-12-13 08:35:01 Valid Error = 0.95207787345563 
2016-12-13 08:35:01 Valid Loss = 0.015686971839601 
2016-12-13 08:35:12 Test Error = 0.96227686089592 
2016-12-13 08:35:12 Test Loss = 0.015745681406845 
2016-12-13 08:35:12 -------------------LR------------------- 
2016-12-13 08:35:12 6.103515625e-05 
2016-12-13 08:35:12 Epoch 403 
2016-12-13 08:42:52 Training Error = 0.90280436048931 
2016-12-13 08:42:52 Training Loss = 0.015220995766413 
2016-12-13 08:43:02 Valid Error = 0.95320104829652 
2016-12-13 08:43:02 Valid Loss = 0.015668270005852 
2016-12-13 08:43:13 Test Error = 0.96362411586393 
2016-12-13 08:43:13 Test Loss = 0.015724447332066 
2016-12-13 08:43:13 -------------------LR------------------- 
2016-12-13 08:43:13 6.103515625e-05 
2016-12-13 08:43:13 Epoch 404 
2016-12-13 08:50:57 Training Error = 0.90313722226845 
2016-12-13 08:50:57 Training Loss = 0.015220752066288 
2016-12-13 08:51:13 Valid Error = 0.95731935604642 
2016-12-13 08:51:13 Valid Loss = 0.015655159296945 
2016-12-13 08:51:24 Test Error = 0.96934994947794 
2016-12-13 08:51:24 Test Loss = 0.015709538850227 
2016-12-13 08:51:24 -------------------LR------------------- 
2016-12-13 08:51:24 6.103515625e-05 
2016-12-13 08:51:24 Epoch 405 
2016-12-13 08:59:12 Training Error = 0.90421902305068 
2016-12-13 08:59:12 Training Loss = 0.015230251410605 
2016-12-13 08:59:22 Valid Error = 0.95132909022838 
2016-12-13 08:59:22 Valid Loss = 0.015687576792286 
2016-12-13 08:59:34 Test Error = 0.95890872347592 
2016-12-13 08:59:34 Test Loss = 0.015748757223737 
2016-12-13 08:59:34 -------------------LR------------------- 
2016-12-13 08:59:34 6.103515625e-05 
2016-12-13 08:59:34 Epoch 406 
2016-12-13 09:07:19 Training Error = 0.90363651493717 
2016-12-13 09:07:19 Training Loss = 0.015223687907049 
2016-12-13 09:07:29 Valid Error = 0.95320104829652 
2016-12-13 09:07:29 Valid Loss = 0.015660605937518 
2016-12-13 09:07:40 Test Error = 0.96362411586393 
2016-12-13 09:07:40 Test Loss = 0.015718100862755 
2016-12-13 09:07:40 -------------------LR------------------- 
2016-12-13 09:07:40 6.103515625e-05 
2016-12-13 09:07:40 Epoch 407 
2016-12-13 09:15:35 Training Error = 0.90559207788966 
2016-12-13 09:15:35 Training Loss = 0.015229899249785 
2016-12-13 09:15:45 Valid Error = 0.95731935604642 
2016-12-13 09:15:45 Valid Loss = 0.015661123209016 
2016-12-13 09:15:56 Test Error = 0.96934994947794 
2016-12-13 09:15:56 Test Loss = 0.015715405398896 
2016-12-13 09:15:56 -------------------LR------------------- 
2016-12-13 09:15:56 6.103515625e-05 
2016-12-13 09:15:56 Epoch 408 
2016-12-13 09:23:46 Training Error = 0.9028459682117 
2016-12-13 09:23:46 Training Loss = 0.015221212324419 
