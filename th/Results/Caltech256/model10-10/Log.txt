2016-12-11 13:20:13 [program started on Sun Dec 11 13:20:13 2016] 
2016-12-11 13:20:13 [command line arguments] 
2016-12-11 13:20:13 stcWeights false 
2016-12-11 13:20:13 LR 0.015625 
2016-12-11 13:20:13 batchSize 100 
2016-12-11 13:20:13 network ./Models/Cifar10_Custom 
2016-12-11 13:20:13 stcNeurons true 
2016-12-11 13:20:13 constBatchSize false 
2016-12-11 13:20:13 chartFileName chart1 
2016-12-11 13:20:13 dp_prepro false 
2016-12-11 13:20:13 nGPU 1 
2016-12-11 13:20:13 dataset Caltech256 
2016-12-11 13:20:13 type cuda 
2016-12-11 13:20:13 momentum 0 
2016-12-11 13:20:13 threads 8 
2016-12-11 13:20:13 weightDecay 0 
2016-12-11 13:20:13 runningVal false 
2016-12-11 13:20:13 convLayerN 10 
2016-12-11 13:20:13 LRDecay 0 
2016-12-11 13:20:13 numHid 1024 
2016-12-11 13:20:13 save /dev/shm/clone/temp/th/Results/Caltech256/model10-10 
2016-12-11 13:20:13 augment false 
2016-12-11 13:20:13 epoch -1 
2016-12-11 13:20:13 modelsFolder ./Models/ 
2016-12-11 13:20:13 format rgb 
2016-12-11 13:20:13 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-11 13:20:13 imageFileExtension svg 
2016-12-11 13:20:13 channel 1 
2016-12-11 13:20:13 devid 2 
2016-12-11 13:20:13 visualize 1 
2016-12-11 13:20:13 LRDecayPerEpoch 0.0001 
2016-12-11 13:20:13 optimization adam 
2016-12-11 13:20:13 SBN true 
2016-12-11 13:20:13 normalization simple 
2016-12-11 13:20:13 title model1 
2016-12-11 13:20:13 load  
2016-12-11 13:20:13 whiten true 
2016-12-11 13:20:13 [----------------------] 
2016-12-11 13:20:15 ==> Network 
2016-12-11 13:20:15 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> (43) -> (44) -> (45) -> (46) -> (47) -> (48) -> (49) -> (50) -> (51) -> (52) -> (53) -> (54) -> (55) -> (56) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (29): SpatialBatchNormalizationShiftPow2
  (30): nn.HardTanh
  (31): BinarizedNeurons
  (32): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (33): cudnn.SpatialMaxPooling(2x2, 2,2)
  (34): SpatialBatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (38): SpatialBatchNormalizationShiftPow2
  (39): nn.HardTanh
  (40): BinarizedNeurons
  (41): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (42): cudnn.SpatialMaxPooling(2x2, 2,2)
  (43): SpatialBatchNormalizationShiftPow2
  (44): nn.HardTanh
  (45): BinarizedNeurons
  (46): nn.View(512)
  (47): BinaryLinear(512 -> 1024)
  (48): BatchNormalizationShiftPow2
  (49): nn.HardTanh
  (50): BinarizedNeurons
  (51): BinaryLinear(1024 -> 1024)
  (52): BatchNormalizationShiftPow2
  (53): nn.HardTanh
  (54): BinarizedNeurons
  (55): BinaryLinear(1024 -> 255)
  (56): nn.BatchNormalization
} 
2016-12-11 13:20:15 ==>15864189 Parameters 
2016-12-11 13:20:15 ==> Loss 
2016-12-11 13:20:15 SqrtHingeEmbeddingCriterion 
2016-12-11 13:20:15 
==> Starting Training
 
2016-12-11 13:20:15 Epoch 1 
2016-12-11 13:25:39 Training Error = 0.97233086460847 
2016-12-11 13:25:39 Training Loss = 0.1656419887141 
2016-12-11 13:25:45 Valid Error = 0.93223511793336 
2016-12-11 13:25:45 Valid Loss = 0.015766950679074 
2016-12-11 13:25:52 Test Error = 0.94307847760189 
2016-12-11 13:25:52 Test Loss = 0.015760391199217 
2016-12-11 13:25:52 -------------------LR------------------- 
2016-12-11 13:25:52 0.015625 
2016-12-11 13:25:52 Epoch 2 
2016-12-11 13:31:23 Training Error = 0.95801780810518 
2016-12-11 13:31:23 Training Loss = 0.016146928219857 
2016-12-11 13:31:30 Valid Error = 0.93448146761513 
2016-12-11 13:31:30 Valid Loss = 0.015620840991024 
2016-12-11 13:31:37 Test Error = 0.94543617379589 
2016-12-11 13:31:37 Test Loss = 0.015663339876011 
2016-12-11 13:31:37 -------------------LR------------------- 
2016-12-11 13:31:37 0.015625 
2016-12-11 13:31:37 Epoch 3 
2016-12-11 13:37:00 Training Error = 0.93971041025214 
2016-12-11 13:37:00 Training Loss = 0.015767518213292 
2016-12-11 13:37:06 Valid Error = 0.93036315986522 
2016-12-11 13:37:06 Valid Loss = 0.015512051610634 
2016-12-11 13:37:13 Test Error = 0.93836308521388 
2016-12-11 13:37:13 Test Loss = 0.015511978542266 
2016-12-11 13:37:13 -------------------LR------------------- 
2016-12-11 13:37:13 0.015625 
2016-12-11 13:37:13 Epoch 4 
2016-12-11 13:42:27 Training Error = 0.93205458933178 
2016-12-11 13:42:27 Training Loss = 0.015596765054403 
2016-12-11 13:42:33 Valid Error = 0.93934855859229 
2016-12-11 13:42:33 Valid Loss = 0.015554515790357 
2016-12-11 13:42:40 Test Error = 0.9514988211519 
2016-12-11 13:42:40 Test Loss = 0.015568694098226 
2016-12-11 13:42:40 -------------------LR------------------- 
2016-12-11 13:42:40 0.015625 
2016-12-11 13:42:40 Epoch 5 
2016-12-11 13:48:30 Training Error = 0.93097278854955 
2016-12-11 13:48:30 Training Loss = 0.015514851359013 
2016-12-11 13:48:36 Valid Error = 0.93223511793336 
2016-12-11 13:48:36 Valid Loss = 0.015503700847942 
2016-12-11 13:48:43 Test Error = 0.94307847760189 
2016-12-11 13:48:43 Test Loss = 0.015513664126651 
2016-12-11 13:48:43 -------------------LR------------------- 
2016-12-11 13:48:43 0.015625 
2016-12-11 13:48:43 Epoch 6 
2016-12-11 13:54:54 Training Error = 0.9307231422152 
2016-12-11 13:54:54 Training Loss = 0.015456302833806 
2016-12-11 13:55:00 Valid Error = 0.93223511793336 
2016-12-11 13:55:00 Valid Loss = 0.015519749046127 
2016-12-11 13:55:07 Test Error = 0.94307847760189 
2016-12-11 13:55:07 Test Loss = 0.015546230871257 
2016-12-11 13:55:07 -------------------LR------------------- 
2016-12-11 13:55:07 0.015625 
2016-12-11 13:55:07 Epoch 7 
2016-12-11 14:00:16 Training Error = 0.92989098776733 
2016-12-11 14:00:16 Training Loss = 0.015425429428902 
2016-12-11 14:00:23 Valid Error = 0.93223511793336 
2016-12-11 14:00:23 Valid Loss = 0.015502737448015 
2016-12-11 14:00:30 Test Error = 0.94307847760189 
2016-12-11 14:00:30 Test Loss = 0.015525721975885 
2016-12-11 14:00:30 -------------------LR------------------- 
2016-12-11 14:00:30 0.015625 
2016-12-11 14:00:30 Epoch 8 
2016-12-11 14:05:18 Training Error = 0.92756095531331 
2016-12-11 14:05:18 Training Loss = 0.015370174259915 
2016-12-11 14:05:25 Valid Error = 0.96443279670535 
2016-12-11 14:05:25 Valid Loss = 0.015620535485616 
2016-12-11 14:05:32 Test Error = 0.97777029302796 
2016-12-11 14:05:32 Test Loss = 0.015646574311231 
2016-12-11 14:05:32 -------------------LR------------------- 
2016-12-11 14:05:32 0.015625 
2016-12-11 14:05:32 Epoch 9 
2016-12-11 14:10:21 Training Error = 0.92044603478406 
2016-12-11 14:10:21 Training Loss = 0.015308037107225 
2016-12-11 14:10:27 Valid Error = 0.95731935604642 
2016-12-11 14:10:27 Valid Loss = 0.015707433217886 
2016-12-11 14:10:34 Test Error = 0.96934994947794 
2016-12-11 14:10:34 Test Loss = 0.015713173636873 
2016-12-11 14:10:34 -------------------LR------------------- 
2016-12-11 14:10:34 0.015625 
2016-12-11 14:10:34 Epoch 10 
2016-12-11 14:15:23 Training Error = 0.91116751269036 
2016-12-11 14:15:23 Training Loss = 0.015268501529629 
2016-12-11 14:15:29 Valid Error = 0.95320104829652 
2016-12-11 14:15:29 Valid Loss = 0.015650433890309 
2016-12-11 14:15:36 Test Error = 0.96362411586393 
2016-12-11 14:15:36 Test Loss = 0.01570324961937 
2016-12-11 14:15:36 -------------------LR------------------- 
2016-12-11 14:15:36 0.015625 
2016-12-11 14:15:36 Epoch 11 
2016-12-11 14:20:23 Training Error = 0.90559207788966 
2016-12-11 14:20:23 Training Loss = 0.015231853572722 
2016-12-11 14:20:29 Valid Error = 0.95731935604642 
2016-12-11 14:20:29 Valid Loss = 0.015676367053777 
2016-12-11 14:20:36 Test Error = 0.96934994947794 
2016-12-11 14:20:36 Test Loss = 0.015736487128607 
2016-12-11 14:20:36 -------------------LR------------------- 
2016-12-11 14:20:36 0.015625 
2016-12-11 14:20:36 Epoch 12 
2016-12-11 14:25:23 Training Error = 0.90488474660897 
2016-12-11 14:25:23 Training Loss = 0.01522181587161 
2016-12-11 14:25:30 Valid Error = 0.95320104829652 
2016-12-11 14:25:30 Valid Loss = 0.015691159135248 
2016-12-11 14:25:37 Test Error = 0.96362411586393 
2016-12-11 14:25:37 Test Loss = 0.015747871373921 
2016-12-11 14:25:37 -------------------LR------------------- 
2016-12-11 14:25:37 0.015625 
2016-12-11 14:25:37 Epoch 13 
2016-12-11 14:30:20 Training Error = 0.90363651493717 
2016-12-11 14:30:20 Training Loss = 0.015228135230159 
2016-12-11 14:30:27 Valid Error = 0.95544739797829 
2016-12-11 14:30:27 Valid Loss = 0.01566149529579 
2016-12-11 14:30:34 Test Error = 0.96463455708993 
2016-12-11 14:30:34 Test Loss = 0.015711559179808 
2016-12-11 14:30:34 -------------------LR------------------- 
2016-12-11 14:30:34 0.015625 
2016-12-11 14:30:34 Epoch 14 
2016-12-11 14:35:22 Training Error = 0.90326204543563 
2016-12-11 14:35:22 Training Loss = 0.01522290629355 
2016-12-11 14:35:28 Valid Error = 0.95731935604642 
2016-12-11 14:35:28 Valid Loss = 0.01566838184277 
2016-12-11 14:35:35 Test Error = 0.96934994947794 
2016-12-11 14:35:35 Test Loss = 0.015726140638205 
2016-12-11 14:35:35 -------------------LR------------------- 
2016-12-11 14:35:35 0.015625 
2016-12-11 14:35:35 Epoch 15 
2016-12-11 14:40:20 Training Error = 0.90197220604144 
2016-12-11 14:40:20 Training Loss = 0.015220852351746 
2016-12-11 14:40:27 Valid Error = 0.9502059153875 
2016-12-11 14:40:27 Valid Loss = 0.015752455035169 
2016-12-11 14:40:34 Test Error = 0.95756146850792 
2016-12-11 14:40:34 Test Loss = 0.015790318863914 
2016-12-11 14:40:34 -------------------LR------------------- 
2016-12-11 14:40:34 0.015625 
2016-12-11 14:40:34 Epoch 16 
2016-12-11 14:45:20 Training Error = 0.90301239910127 
2016-12-11 14:45:20 Training Loss = 0.015217646658109 
2016-12-11 14:45:26 Valid Error = 0.95544739797829 
2016-12-11 14:45:26 Valid Loss = 0.015731668600524 
2016-12-11 14:45:33 Test Error = 0.96463455708993 
2016-12-11 14:45:33 Test Loss = 0.015776441302692 
2016-12-11 14:45:33 -------------------LR------------------- 
2016-12-11 14:45:33 0.015625 
2016-12-11 14:45:33 Epoch 17 
2016-12-11 14:50:19 Training Error = 0.9047183157194 
2016-12-11 14:50:19 Training Loss = 0.015228559492074 
2016-12-11 14:50:26 Valid Error = 0.95731935604642 
2016-12-11 14:50:26 Valid Loss = 0.015670349727281 
2016-12-11 14:50:33 Test Error = 0.96934994947794 
2016-12-11 14:50:33 Test Loss = 0.01572510389274 
2016-12-11 14:50:33 -------------------LR------------------- 
2016-12-11 14:50:33 0.015625 
2016-12-11 14:50:33 Epoch 18 
2016-12-11 14:55:19 Training Error = 0.90280436048931 
2016-12-11 14:55:19 Training Loss = 0.015220340369704 
2016-12-11 14:55:26 Valid Error = 0.95170348184201 
2016-12-11 14:55:26 Valid Loss = 0.015661662292652 
2016-12-11 14:55:33 Test Error = 0.96631862579993 
2016-12-11 14:55:33 Test Loss = 0.015719356675115 
2016-12-11 14:55:33 -------------------LR------------------- 
2016-12-11 14:55:33 0.015625 
2016-12-11 14:55:33 Epoch 19 
2016-12-11 15:00:20 Training Error = 0.90238828326537 
2016-12-11 15:00:20 Training Loss = 0.015228449872294 
2016-12-11 15:00:26 Valid Error = 0.95320104829652 
2016-12-11 15:00:26 Valid Loss = 0.015674473582375 
2016-12-11 15:00:33 Test Error = 0.96362411586393 
2016-12-11 15:00:33 Test Loss = 0.015734457407 
2016-12-11 15:00:33 -------------------LR------------------- 
2016-12-11 15:00:33 0.015625 
2016-12-11 15:00:33 Epoch 20 
2016-12-11 15:05:20 Training Error = 0.90371973038196 
2016-12-11 15:05:20 Training Loss = 0.015219132277771 
2016-12-11 15:05:27 Valid Error = 0.95731935604642 
2016-12-11 15:05:27 Valid Loss = 0.015672371392052 
2016-12-11 15:05:34 Test Error = 0.96934994947794 
2016-12-11 15:05:34 Test Loss = 0.01573243582804 
2016-12-11 15:05:34 -------------------LR------------------- 
2016-12-11 15:05:34 0.015625 
2016-12-11 15:05:34 Epoch 21 
2016-12-11 15:10:20 Training Error = 0.90301239910127 
2016-12-11 15:10:20 Training Loss = 0.015220979323928 
2016-12-11 15:10:26 Valid Error = 0.95544739797829 
2016-12-11 15:10:26 Valid Loss = 0.015722688465965 
2016-12-11 15:10:33 Test Error = 0.96463455708993 
2016-12-11 15:10:33 Test Loss = 0.015765112457319 
2016-12-11 15:10:33 -------------------LR------------------- 
2016-12-11 15:10:33 0.015625 
2016-12-11 15:10:33 Epoch 22 
2016-12-11 15:15:22 Training Error = 0.90384455354914 
2016-12-11 15:15:22 Training Loss = 0.015222037957765 
2016-12-11 15:15:28 Valid Error = 0.95207787345563 
2016-12-11 15:15:28 Valid Loss = 0.015662471484963 
2016-12-11 15:15:35 Test Error = 0.96227686089592 
2016-12-11 15:15:35 Test Loss = 0.015718170157343 
2016-12-11 15:15:35 -------------------LR------------------- 
2016-12-11 15:15:35 0.015625 
2016-12-11 15:15:35 Epoch 23 
2016-12-11 15:20:24 Training Error = 0.90380294582675 
2016-12-11 15:20:24 Training Loss = 0.01522121834185 
2016-12-11 15:20:30 Valid Error = 0.94795956570573 
2016-12-11 15:20:30 Valid Loss = 0.015681131138424 
2016-12-11 15:20:37 Test Error = 0.95655102728191 
2016-12-11 15:20:37 Test Loss = 0.015742061388428 
2016-12-11 15:20:37 -------------------LR------------------- 
2016-12-11 15:20:37 0.015625 
2016-12-11 15:20:37 Epoch 24 
2016-12-11 15:25:25 Training Error = 0.90371973038196 
2016-12-11 15:25:25 Training Loss = 0.015225778862774 
2016-12-11 15:25:31 Valid Error = 0.95544739797829 
2016-12-11 15:25:31 Valid Loss = 0.015696038187013 
2016-12-11 15:25:38 Test Error = 0.96463455708993 
2016-12-11 15:25:38 Test Loss = 0.015731889756783 
2016-12-11 15:25:38 -------------------LR------------------- 
2016-12-11 15:25:38 0.015625 
2016-12-11 15:25:38 Epoch 25 
2016-12-11 15:30:28 Training Error = 0.90230506782059 
2016-12-11 15:30:28 Training Loss = 0.015218746459647 
2016-12-11 15:30:34 Valid Error = 0.9502059153875 
2016-12-11 15:30:34 Valid Loss = 0.015686733593541 
2016-12-11 15:30:41 Test Error = 0.95756146850792 
2016-12-11 15:30:41 Test Loss = 0.015750597780876 
2016-12-11 15:30:41 -------------------LR------------------- 
2016-12-11 15:30:41 0.015625 
2016-12-11 15:30:41 Epoch 26 
2016-12-11 15:35:31 Training Error = 0.90338686860281 
2016-12-11 15:35:31 Training Loss = 0.015224232609897 
2016-12-11 15:35:37 Valid Error = 0.9475851740921 
2016-12-11 15:35:37 Valid Loss = 0.015684924933456 
2016-12-11 15:35:44 Test Error = 0.96059279218592 
2016-12-11 15:35:44 Test Loss = 0.015749430062765 
2016-12-11 15:35:44 -------------------LR------------------- 
2016-12-11 15:35:44 0.015625 
2016-12-11 15:35:44 Epoch 27 
2016-12-11 15:40:32 Training Error = 0.90459349255222 
2016-12-11 15:40:32 Training Loss = 0.015228055539505 
2016-12-11 15:40:39 Valid Error = 0.9502059153875 
2016-12-11 15:40:39 Valid Loss = 0.015703953507906 
2016-12-11 15:40:46 Test Error = 0.95756146850792 
2016-12-11 15:40:46 Test Loss = 0.015768463817559 
2016-12-11 15:40:46 -------------------LR------------------- 
2016-12-11 15:40:46 0.015625 
2016-12-11 15:40:46 Epoch 28 
2016-12-11 15:45:36 Training Error = 0.90292918365649 
2016-12-11 15:45:36 Training Loss = 0.015220419443425 
2016-12-11 15:45:42 Valid Error = 0.95207787345563 
2016-12-11 15:45:42 Valid Loss = 0.01565248955527 
2016-12-11 15:45:49 Test Error = 0.96227686089592 
2016-12-11 15:45:49 Test Loss = 0.015708940273819 
2016-12-11 15:45:49 -------------------LR------------------- 
2016-12-11 15:45:49 0.015625 
2016-12-11 15:45:49 Epoch 29 
2016-12-11 15:50:34 Training Error = 0.90172255970708 
2016-12-11 15:50:34 Training Loss = 0.015223739172643 
2016-12-11 15:50:40 Valid Error = 0.94795956570573 
2016-12-11 15:50:40 Valid Loss = 0.015670273799015 
2016-12-11 15:50:47 Test Error = 0.95655102728191 
2016-12-11 15:50:47 Test Loss = 0.015726587924088 
2016-12-11 15:50:47 -------------------LR------------------- 
2016-12-11 15:50:47 0.015625 
2016-12-11 15:50:47 Epoch 30 
2016-12-11 15:55:36 Training Error = 0.90342847632521 
2016-12-11 15:55:36 Training Loss = 0.015231137955838 
2016-12-11 15:55:43 Valid Error = 0.95207787345563 
2016-12-11 15:55:43 Valid Loss = 0.015687617197713 
2016-12-11 15:55:50 Test Error = 0.96227686089592 
2016-12-11 15:55:50 Test Loss = 0.01574287205868 
2016-12-11 15:55:50 -------------------LR------------------- 
2016-12-11 15:55:50 0.015625 
2016-12-11 15:55:50 Epoch 31 
2016-12-11 16:00:40 Training Error = 0.9034700840476 
2016-12-11 16:00:40 Training Loss = 0.015228328281624 
2016-12-11 16:00:47 Valid Error = 0.9502059153875 
2016-12-11 16:00:47 Valid Loss = 0.015652767112997 
2016-12-11 16:00:54 Test Error = 0.95756146850792 
2016-12-11 16:00:54 Test Loss = 0.015700094352708 
2016-12-11 16:00:54 -------------------LR------------------- 
2016-12-11 16:00:54 0.015625 
2016-12-11 16:00:54 Epoch 32 
2016-12-11 16:05:41 Training Error = 0.90322043771324 
2016-12-11 16:05:41 Training Loss = 0.015226044074924 
2016-12-11 16:05:47 Valid Error = 0.95132909022838 
2016-12-11 16:05:47 Valid Loss = 0.015729474703578 
2016-12-11 16:05:54 Test Error = 0.95890872347592 
2016-12-11 16:05:54 Test Loss = 0.015784372680467 
2016-12-11 16:05:54 -------------------LR------------------- 
2016-12-11 16:05:54 0.015625 
2016-12-11 16:05:54 Epoch 33 
2016-12-11 16:10:42 Training Error = 0.90276275276691 
2016-12-11 16:10:42 Training Loss = 0.015225434069218 
2016-12-11 16:10:48 Valid Error = 0.95544739797829 
2016-12-11 16:10:48 Valid Loss = 0.015711484519012 
2016-12-11 16:10:55 Test Error = 0.96463455708993 
2016-12-11 16:10:55 Test Loss = 0.015751889784187 
2016-12-11 16:10:55 -------------------LR------------------- 
2016-12-11 16:10:55 0.015625 
2016-12-11 16:10:55 Epoch 34 
2016-12-11 16:15:46 Training Error = 0.90359490721478 
2016-12-11 16:15:46 Training Loss = 0.015225492026721 
2016-12-11 16:15:52 Valid Error = 0.95731935604642 
2016-12-11 16:15:52 Valid Loss = 0.015651794633991 
2016-12-11 16:15:59 Test Error = 0.96934994947794 
2016-12-11 16:15:59 Test Loss = 0.015707601138671 
2016-12-11 16:15:59 -------------------LR------------------- 
2016-12-11 16:15:59 0.015625 
2016-12-11 16:15:59 Epoch 35 
2016-12-11 16:20:45 Training Error = 0.90326204543563 
2016-12-11 16:20:45 Training Loss = 0.015224651983672 
2016-12-11 16:20:51 Valid Error = 0.95544739797829 
2016-12-11 16:20:51 Valid Loss = 0.015686811384071 
2016-12-11 16:20:58 Test Error = 0.96463455708993 
2016-12-11 16:20:58 Test Loss = 0.015744664556054 
2016-12-11 16:20:58 -------------------LR------------------- 
2016-12-11 16:20:58 0.015625 
2016-12-11 16:20:58 Epoch 36 
2016-12-11 16:25:44 Training Error = 0.90297079137888 
2016-12-11 16:25:44 Training Loss = 0.015218731212177 
2016-12-11 16:25:51 Valid Error = 0.94795956570573 
2016-12-11 16:25:51 Valid Loss = 0.015651607431919 
2016-12-11 16:25:58 Test Error = 0.95655102728191 
2016-12-11 16:25:58 Test Loss = 0.015706658765571 
2016-12-11 16:25:58 -------------------LR------------------- 
2016-12-11 16:25:58 0.015625 
2016-12-11 16:25:58 Epoch 37 
2016-12-11 16:30:47 Training Error = 0.90380294582675 
2016-12-11 16:30:47 Training Loss = 0.015225611094452 
2016-12-11 16:30:54 Valid Error = 0.9502059153875 
2016-12-11 16:30:54 Valid Loss = 0.015714936728929 
2016-12-11 16:31:01 Test Error = 0.95756146850792 
2016-12-11 16:31:01 Test Loss = 0.015754961313528 
2016-12-11 16:31:01 -------------------LR------------------- 
2016-12-11 16:31:01 0.015625 
2016-12-11 16:31:01 Epoch 38 
2016-12-11 16:35:46 Training Error = 0.90276275276691 
2016-12-11 16:35:46 Training Loss = 0.015219885888307 
2016-12-11 16:35:52 Valid Error = 0.95731935604642 
2016-12-11 16:35:52 Valid Loss = 0.015694583417463 
2016-12-11 16:35:59 Test Error = 0.96934994947794 
2016-12-11 16:35:59 Test Loss = 0.015751598731422 
2016-12-11 16:35:59 -------------------LR------------------- 
2016-12-11 16:35:59 0.015625 
2016-12-11 16:35:59 Epoch 39 
2016-12-11 16:40:50 Training Error = 0.90297079137888 
2016-12-11 16:40:50 Training Loss = 0.015226834562675 
2016-12-11 16:40:56 Valid Error = 0.9502059153875 
2016-12-11 16:40:56 Valid Loss = 0.015777454075507 
2016-12-11 16:41:03 Test Error = 0.95756146850792 
2016-12-11 16:41:03 Test Loss = 0.015816744810399 
2016-12-11 16:41:03 -------------------LR------------------- 
2016-12-11 16:41:03 0.015625 
2016-12-11 16:41:03 Epoch 40 
2016-12-11 16:45:52 Training Error = 0.90392776899393 
2016-12-11 16:45:52 Training Loss = 0.015228046968463 
2016-12-11 16:45:58 Valid Error = 0.95544739797829 
2016-12-11 16:45:58 Valid Loss = 0.015706177134261 
2016-12-11 16:46:05 Test Error = 0.96463455708993 
2016-12-11 16:46:05 Test Loss = 0.015741463709307 
2016-12-11 16:46:05 -------------------LR------------------- 
2016-12-11 16:46:05 0.015625 
2016-12-11 16:46:05 Epoch 41 
2016-12-11 16:50:50 Training Error = 0.90126487476076 
2016-12-11 16:50:50 Training Loss = 0.015215392174892 
2016-12-11 16:50:57 Valid Error = 0.95731935604642 
2016-12-11 16:50:57 Valid Loss = 0.01567043159194 
2016-12-11 16:51:04 Test Error = 0.96934994947794 
2016-12-11 16:51:04 Test Loss = 0.015727547838797 
2016-12-11 16:51:04 -------------------LR------------------- 
2016-12-11 16:51:04 0.015625 
2016-12-11 16:51:04 Epoch 42 
2016-12-11 16:55:53 Training Error = 0.90263792959973 
2016-12-11 16:55:53 Training Loss = 0.015221507777667 
2016-12-11 16:55:59 Valid Error = 0.95170348184201 
2016-12-11 16:55:59 Valid Loss = 0.015667082439522 
2016-12-11 16:56:06 Test Error = 0.96631862579993 
2016-12-11 16:56:06 Test Loss = 0.01572975877706 
2016-12-11 16:56:06 -------------------LR------------------- 
2016-12-11 16:56:06 0.015625 
2016-12-11 16:56:06 Epoch 43 
2016-12-11 17:00:51 Training Error = 0.90384455354914 
2016-12-11 17:00:51 Training Loss = 0.015223244742513 
2016-12-11 17:00:57 Valid Error = 0.95544739797829 
2016-12-11 17:00:57 Valid Loss = 0.01573229668947 
2016-12-11 17:01:04 Test Error = 0.96463455708993 
2016-12-11 17:01:04 Test Loss = 0.015772859274425 
2016-12-11 17:01:04 -------------------LR------------------- 
2016-12-11 17:01:04 0.015625 
2016-12-11 17:01:04 Epoch 44 
2016-12-11 17:05:49 Training Error = 0.90272114504452 
2016-12-11 17:05:49 Training Loss = 0.015221253101571 
2016-12-11 17:05:55 Valid Error = 0.95207787345563 
2016-12-11 17:05:55 Valid Loss = 0.015672058079873 
2016-12-11 17:06:02 Test Error = 0.96227686089592 
2016-12-11 17:06:02 Test Loss = 0.015727615778205 
2016-12-11 17:06:02 -------------------LR------------------- 
2016-12-11 17:06:02 0.015625 
2016-12-11 17:06:02 Epoch 45 
2016-12-11 17:10:50 Training Error = 0.90272114504452 
2016-12-11 17:10:50 Training Loss = 0.015222403550893 
2016-12-11 17:10:57 Valid Error = 0.95320104829652 
2016-12-11 17:10:57 Valid Loss = 0.015669010348744 
2016-12-11 17:11:03 Test Error = 0.96362411586393 
2016-12-11 17:11:03 Test Loss = 0.015724331454882 
2016-12-11 17:11:03 -------------------LR------------------- 
2016-12-11 17:11:03 0.015625 
2016-12-11 17:11:04 Epoch 46 
2016-12-11 17:15:48 Training Error = 0.90334526088042 
2016-12-11 17:15:48 Training Loss = 0.015222204967189 
2016-12-11 17:15:54 Valid Error = 0.95207787345563 
2016-12-11 17:15:54 Valid Loss = 0.015655815979714 
2016-12-11 17:16:01 Test Error = 0.96227686089592 
2016-12-11 17:16:01 Test Loss = 0.015710957406237 
2016-12-11 17:16:01 -------------------LR------------------- 
2016-12-11 17:16:01 0.015625 
2016-12-11 17:16:01 Epoch 47 
2016-12-11 17:20:49 Training Error = 0.90263792959973 
2016-12-11 17:20:49 Training Loss = 0.015217436224447 
2016-12-11 17:20:55 Valid Error = 0.95207787345563 
2016-12-11 17:20:55 Valid Loss = 0.015668878417115 
2016-12-11 17:21:02 Test Error = 0.96227686089592 
2016-12-11 17:21:02 Test Loss = 0.015720671441874 
2016-12-11 17:21:02 -------------------LR------------------- 
2016-12-11 17:21:02 0.015625 
2016-12-11 17:21:02 Epoch 48 
2016-12-11 17:25:48 Training Error = 0.90193059831905 
2016-12-11 17:25:48 Training Loss = 0.015218352818863 
2016-12-11 17:25:54 Valid Error = 0.95207787345563 
2016-12-11 17:25:54 Valid Loss = 0.015642051508475 
2016-12-11 17:26:01 Test Error = 0.96227686089592 
2016-12-11 17:26:01 Test Loss = 0.015692294045286 
2016-12-11 17:26:01 -------------------LR------------------- 
2016-12-11 17:26:01 0.015625 
2016-12-11 17:26:01 Epoch 49 
2016-12-11 17:30:48 Training Error = 0.90342847632521 
2016-12-11 17:30:48 Training Loss = 0.015217320296296 
2016-12-11 17:30:55 Valid Error = 0.94646199925122 
2016-12-11 17:30:55 Valid Loss = 0.015696972195897 
2016-12-11 17:31:02 Test Error = 0.95924553721792 
2016-12-11 17:31:02 Test Loss = 0.015758209411211 
2016-12-11 17:31:02 -------------------LR------------------- 
2016-12-11 17:31:02 0.015625 
2016-12-11 17:31:02 Epoch 50 
2016-12-11 17:35:51 Training Error = 0.90238828326537 
2016-12-11 17:35:51 Training Loss = 0.015217512144859 
2016-12-11 17:35:57 Valid Error = 0.95731935604642 
2016-12-11 17:35:57 Valid Loss = 0.015655047897655 
2016-12-11 17:36:04 Test Error = 0.96934994947794 
2016-12-11 17:36:04 Test Loss = 0.015705171256658 
2016-12-11 17:36:04 -------------------LR------------------- 
2016-12-11 17:36:04 0.0078125 
2016-12-11 17:36:04 Epoch 51 
2016-12-11 17:40:50 Training Error = 0.90292918365649 
2016-12-11 17:40:50 Training Loss = 0.015218034780968 
2016-12-11 17:40:56 Valid Error = 0.9502059153875 
2016-12-11 17:40:56 Valid Loss = 0.015714628562165 
2016-12-11 17:41:03 Test Error = 0.95756146850792 
2016-12-11 17:41:03 Test Loss = 0.015766549471882 
2016-12-11 17:41:03 -------------------LR------------------- 
2016-12-11 17:41:03 0.0078125 
2016-12-11 17:41:03 Epoch 52 
2016-12-11 17:45:51 Training Error = 0.90205542148623 
2016-12-11 17:45:51 Training Loss = 0.015214014255858 
2016-12-11 17:45:57 Valid Error = 0.9502059153875 
2016-12-11 17:45:57 Valid Loss = 0.015684480731592 
2016-12-11 17:46:04 Test Error = 0.95756146850792 
2016-12-11 17:46:04 Test Loss = 0.015744302416439 
2016-12-11 17:46:04 -------------------LR------------------- 
2016-12-11 17:46:04 0.0078125 
2016-12-11 17:46:04 Epoch 53 
2016-12-11 17:50:50 Training Error = 0.90384455354914 
2016-12-11 17:50:50 Training Loss = 0.015227190250994 
2016-12-11 17:50:56 Valid Error = 0.95731935604642 
2016-12-11 17:50:56 Valid Loss = 0.015644507612432 
2016-12-11 17:51:03 Test Error = 0.96934994947794 
2016-12-11 17:51:03 Test Loss = 0.015698583339739 
2016-12-11 17:51:03 -------------------LR------------------- 
2016-12-11 17:51:03 0.0078125 
2016-12-11 17:51:03 Epoch 54 
2016-12-11 17:55:50 Training Error = 0.9034700840476 
2016-12-11 17:55:50 Training Loss = 0.015223328618203 
2016-12-11 17:55:56 Valid Error = 0.95132909022838 
2016-12-11 17:55:56 Valid Loss = 0.0156545334105 
2016-12-11 17:56:03 Test Error = 0.95890872347592 
2016-12-11 17:56:03 Test Loss = 0.015707520519306 
2016-12-11 17:56:03 -------------------LR------------------- 
2016-12-11 17:56:03 0.0078125 
2016-12-11 17:56:03 Epoch 55 
2016-12-11 18:00:48 Training Error = 0.90255471415495 
2016-12-11 18:00:48 Training Loss = 0.015219011310752 
2016-12-11 18:00:54 Valid Error = 0.95544739797829 
2016-12-11 18:00:54 Valid Loss = 0.015713233165906 
2016-12-11 18:01:01 Test Error = 0.96463455708993 
2016-12-11 18:01:01 Test Loss = 0.015759647177945 
2016-12-11 18:01:01 -------------------LR------------------- 
2016-12-11 18:01:01 0.0078125 
2016-12-11 18:01:01 Epoch 56 
2016-12-11 18:05:51 Training Error = 0.90376133810435 
2016-12-11 18:05:51 Training Loss = 0.015227230629127 
2016-12-11 18:05:57 Valid Error = 0.95731935604642 
2016-12-11 18:05:57 Valid Loss = 0.01566034249753 
2016-12-11 18:06:04 Test Error = 0.96934994947794 
2016-12-11 18:06:04 Test Loss = 0.015713161134986 
2016-12-11 18:06:04 -------------------LR------------------- 
2016-12-11 18:06:04 0.0078125 
2016-12-11 18:06:04 Epoch 57 
2016-12-11 18:10:50 Training Error = 0.90276275276691 
2016-12-11 18:10:50 Training Loss = 0.015219561965598 
2016-12-11 18:10:57 Valid Error = 0.94795956570573 
2016-12-11 18:10:57 Valid Loss = 0.015706626634491 
2016-12-11 18:11:04 Test Error = 0.95655102728191 
2016-12-11 18:11:04 Test Loss = 0.015762765847795 
2016-12-11 18:11:04 -------------------LR------------------- 
2016-12-11 18:11:04 0.0078125 
2016-12-11 18:11:04 Epoch 58 
2016-12-11 18:15:49 Training Error = 0.90392776899393 
2016-12-11 18:15:49 Training Loss = 0.015221699327403 
2016-12-11 18:15:56 Valid Error = 0.95544739797829 
2016-12-11 18:15:56 Valid Loss = 0.015726983925195 
2016-12-11 18:16:03 Test Error = 0.96463455708993 
2016-12-11 18:16:03 Test Loss = 0.015773111468083 
2016-12-11 18:16:03 -------------------LR------------------- 
2016-12-11 18:16:03 0.0078125 
2016-12-11 18:16:03 Epoch 59 
2016-12-11 18:20:52 Training Error = 0.90438545394025 
2016-12-11 18:20:52 Training Loss = 0.015228646445125 
2016-12-11 18:20:59 Valid Error = 0.95207787345563 
2016-12-11 18:20:59 Valid Loss = 0.015689054687485 
2016-12-11 18:21:06 Test Error = 0.96227686089592 
2016-12-11 18:21:06 Test Loss = 0.01574926018765 
2016-12-11 18:21:06 -------------------LR------------------- 
2016-12-11 18:21:06 0.0078125 
2016-12-11 18:21:06 Epoch 60 
2016-12-11 18:25:53 Training Error = 0.90334526088042 
2016-12-11 18:25:53 Training Loss = 0.015224440714872 
2016-12-11 18:25:59 Valid Error = 0.95544739797829 
2016-12-11 18:25:59 Valid Loss = 0.015744915875804 
2016-12-11 18:26:06 Test Error = 0.96463455708993 
2016-12-11 18:26:06 Test Loss = 0.015786370474391 
2016-12-11 18:26:06 -------------------LR------------------- 
2016-12-11 18:26:06 0.0078125 
2016-12-11 18:26:06 Epoch 61 
2016-12-11 18:30:54 Training Error = 0.90297079137888 
2016-12-11 18:30:54 Training Loss = 0.015223256731223 
2016-12-11 18:31:00 Valid Error = 0.95731935604642 
2016-12-11 18:31:00 Valid Loss = 0.015675619292423 
2016-12-11 18:31:07 Test Error = 0.96934994947794 
2016-12-11 18:31:07 Test Loss = 0.015734387991579 
2016-12-11 18:31:07 -------------------LR------------------- 
2016-12-11 18:31:07 0.0078125 
2016-12-11 18:31:07 Epoch 62 
2016-12-11 18:35:56 Training Error = 0.90218024465341 
2016-12-11 18:35:56 Training Loss = 0.015221133956431 
2016-12-11 18:36:03 Valid Error = 0.94608760763759 
2016-12-11 18:36:03 Valid Loss = 0.015720781901286 
2016-12-11 18:36:10 Test Error = 0.9518356348939 
2016-12-11 18:36:10 Test Loss = 0.015760096525507 
2016-12-11 18:36:10 -------------------LR------------------- 
2016-12-11 18:36:10 0.0078125 
2016-12-11 18:36:10 Epoch 63 
2016-12-11 18:40:55 Training Error = 0.90326204543563 
2016-12-11 18:40:55 Training Loss = 0.015225102536212 
2016-12-11 18:41:01 Valid Error = 0.95731935604642 
2016-12-11 18:41:01 Valid Loss = 0.015658899005815 
2016-12-11 18:41:08 Test Error = 0.96934994947794 
2016-12-11 18:41:08 Test Loss = 0.015718907803948 
2016-12-11 18:41:08 -------------------LR------------------- 
2016-12-11 18:41:08 0.0078125 
2016-12-11 18:41:08 Epoch 64 
2016-12-11 18:46:00 Training Error = 0.90238828326537 
2016-12-11 18:46:00 Training Loss = 0.015220094450139 
2016-12-11 18:46:07 Valid Error = 0.95731935604642 
2016-12-11 18:46:07 Valid Loss = 0.015655032053124 
2016-12-11 18:46:14 Test Error = 0.96934994947794 
2016-12-11 18:46:14 Test Loss = 0.015708163867548 
2016-12-11 18:46:14 -------------------LR------------------- 
2016-12-11 18:46:14 0.0078125 
2016-12-11 18:46:14 Epoch 65 
2016-12-11 18:51:01 Training Error = 0.90297079137888 
2016-12-11 18:51:01 Training Loss = 0.015219583682683 
2016-12-11 18:51:07 Valid Error = 0.95207787345563 
2016-12-11 18:51:07 Valid Loss = 0.015709795985194 
2016-12-11 18:51:14 Test Error = 0.96227686089592 
2016-12-11 18:51:14 Test Loss = 0.015770572236764 
2016-12-11 18:51:14 -------------------LR------------------- 
2016-12-11 18:51:14 0.0078125 
2016-12-11 18:51:14 Epoch 66 
2016-12-11 18:56:02 Training Error = 0.90455188482982 
2016-12-11 18:56:02 Training Loss = 0.015226013332861 
2016-12-11 18:56:08 Valid Error = 0.95207787345563 
2016-12-11 18:56:08 Valid Loss = 0.015649209366517 
2016-12-11 18:56:15 Test Error = 0.96227686089592 
2016-12-11 18:56:15 Test Loss = 0.015702722684834 
2016-12-11 18:56:15 -------------------LR------------------- 
2016-12-11 18:56:15 0.0078125 
2016-12-11 18:56:15 Epoch 67 
2016-12-11 19:01:01 Training Error = 0.90330365315803 
2016-12-11 19:01:01 Training Loss = 0.015223737868087 
2016-12-11 19:01:08 Valid Error = 0.94608760763759 
2016-12-11 19:01:08 Valid Loss = 0.015656638491295 
2016-12-11 19:01:15 Test Error = 0.9518356348939 
2016-12-11 19:01:15 Test Loss = 0.015710926340574 
2016-12-11 19:01:15 -------------------LR------------------- 
2016-12-11 19:01:15 0.0078125 
2016-12-11 19:01:15 Epoch 68 
2016-12-11 19:06:02 Training Error = 0.90371973038196 
2016-12-11 19:06:02 Training Loss = 0.015223643877271 
2016-12-11 19:06:08 Valid Error = 0.94795956570573 
2016-12-11 19:06:08 Valid Loss = 0.015662625325496 
2016-12-11 19:06:15 Test Error = 0.95655102728191 
2016-12-11 19:06:15 Test Loss = 0.015716552613542 
2016-12-11 19:06:15 -------------------LR------------------- 
2016-12-11 19:06:15 0.0078125 
2016-12-11 19:06:15 Epoch 69 
2016-12-11 19:10:59 Training Error = 0.9028459682117 
2016-12-11 19:10:59 Training Loss = 0.01522068480163 
2016-12-11 19:11:06 Valid Error = 0.94795956570573 
2016-12-11 19:11:06 Valid Loss = 0.01567484765627 
2016-12-11 19:11:13 Test Error = 0.95655102728191 
2016-12-11 19:11:13 Test Loss = 0.01573347823705 
2016-12-11 19:11:13 -------------------LR------------------- 
2016-12-11 19:11:13 0.0078125 
2016-12-11 19:11:13 Epoch 70 
2016-12-11 19:16:01 Training Error = 0.90367812265957 
2016-12-11 19:16:01 Training Loss = 0.015222542537783 
2016-12-11 19:16:08 Valid Error = 0.95207787345563 
2016-12-11 19:16:08 Valid Loss = 0.015657952207061 
2016-12-11 19:16:15 Test Error = 0.96227686089592 
2016-12-11 19:16:15 Test Loss = 0.015712414196954 
2016-12-11 19:16:15 -------------------LR------------------- 
2016-12-11 19:16:15 0.0078125 
2016-12-11 19:16:15 Epoch 71 
2016-12-11 19:21:02 Training Error = 0.9028459682117 
2016-12-11 19:21:02 Training Loss = 0.015227356954581 
2016-12-11 19:21:09 Valid Error = 0.9502059153875 
2016-12-11 19:21:09 Valid Loss = 0.015724396031948 
2016-12-11 19:21:16 Test Error = 0.95756146850792 
2016-12-11 19:21:16 Test Loss = 0.015768504533102 
2016-12-11 19:21:16 -------------------LR------------------- 
2016-12-11 19:21:16 0.0078125 
2016-12-11 19:21:16 Epoch 72 
2016-12-11 19:26:02 Training Error = 0.90201381376383 
2016-12-11 19:26:02 Training Loss = 0.015218981413466 
2016-12-11 19:26:08 Valid Error = 0.95544739797829 
2016-12-11 19:26:08 Valid Loss = 0.015680467242585 
2016-12-11 19:26:15 Test Error = 0.96463455708993 
2016-12-11 19:26:15 Test Loss = 0.015741193698841 
2016-12-11 19:26:15 -------------------LR------------------- 
2016-12-11 19:26:15 0.0078125 
2016-12-11 19:26:15 Epoch 73 
2016-12-11 19:31:06 Training Error = 0.90263792959973 
2016-12-11 19:31:06 Training Loss = 0.015220030452713 
2016-12-11 19:31:13 Valid Error = 0.95731935604642 
2016-12-11 19:31:13 Valid Loss = 0.015670507053236 
2016-12-11 19:31:20 Test Error = 0.96934994947794 
2016-12-11 19:31:20 Test Loss = 0.015723019175319 
2016-12-11 19:31:20 -------------------LR------------------- 
2016-12-11 19:31:20 0.0078125 
2016-12-11 19:31:20 Epoch 74 
2016-12-11 19:36:06 Training Error = 0.90330365315803 
2016-12-11 19:36:06 Training Loss = 0.015224122229759 
2016-12-11 19:36:12 Valid Error = 0.95731935604642 
2016-12-11 19:36:12 Valid Loss = 0.015682961266662 
2016-12-11 19:36:19 Test Error = 0.96934994947794 
2016-12-11 19:36:19 Test Loss = 0.015744840228843 
2016-12-11 19:36:19 -------------------LR------------------- 
2016-12-11 19:36:19 0.0078125 
2016-12-11 19:36:19 Epoch 75 
2016-12-11 19:41:08 Training Error = 0.90276275276691 
2016-12-11 19:41:08 Training Loss = 0.015222891293642 
2016-12-11 19:41:15 Valid Error = 0.94608760763759 
2016-12-11 19:41:15 Valid Loss = 0.015661575356245 
2016-12-11 19:41:22 Test Error = 0.9518356348939 
2016-12-11 19:41:22 Test Loss = 0.015711668606009 
2016-12-11 19:41:22 -------------------LR------------------- 
2016-12-11 19:41:22 0.0078125 
2016-12-11 19:41:22 Epoch 76 
2016-12-11 19:46:09 Training Error = 0.90297079137888 
2016-12-11 19:46:09 Training Loss = 0.015223125668355 
2016-12-11 19:46:16 Valid Error = 0.95731935604642 
2016-12-11 19:46:16 Valid Loss = 0.015697860476016 
2016-12-11 19:46:23 Test Error = 0.96934994947794 
2016-12-11 19:46:23 Test Loss = 0.015759496196152 
2016-12-11 19:46:23 -------------------LR------------------- 
2016-12-11 19:46:23 0.0078125 
2016-12-11 19:46:23 Epoch 77 
2016-12-11 19:51:10 Training Error = 0.90288757593409 
2016-12-11 19:51:10 Training Loss = 0.015220844318183 
2016-12-11 19:51:16 Valid Error = 0.95207787345563 
2016-12-11 19:51:16 Valid Loss = 0.015673020080138 
2016-12-11 19:51:23 Test Error = 0.96227686089592 
2016-12-11 19:51:23 Test Loss = 0.015733991385053 
2016-12-11 19:51:23 -------------------LR------------------- 
2016-12-11 19:51:23 0.0078125 
2016-12-11 19:51:23 Epoch 78 
2016-12-11 19:56:11 Training Error = 0.9034700840476 
2016-12-11 19:56:11 Training Loss = 0.015227628242 
2016-12-11 19:56:17 Valid Error = 0.95544739797829 
2016-12-11 19:56:17 Valid Loss = 0.01567421900983 
2016-12-11 19:56:24 Test Error = 0.96463455708993 
2016-12-11 19:56:24 Test Loss = 0.015739087229732 
2016-12-11 19:56:24 -------------------LR------------------- 
2016-12-11 19:56:24 0.0078125 
2016-12-11 19:56:24 Epoch 79 
2016-12-11 20:01:07 Training Error = 0.90338686860281 
2016-12-11 20:01:07 Training Loss = 0.015223861564859 
2016-12-11 20:01:13 Valid Error = 0.95544739797829 
2016-12-11 20:01:13 Valid Loss = 0.015725675513414 
2016-12-11 20:01:20 Test Error = 0.96463455708993 
2016-12-11 20:01:20 Test Loss = 0.01576665805572 
2016-12-11 20:01:20 -------------------LR------------------- 
2016-12-11 20:01:20 0.0078125 
2016-12-11 20:01:20 Epoch 80 
2016-12-11 20:06:09 Training Error = 0.90367812265957 
2016-12-11 20:06:09 Training Loss = 0.015224451965716 
2016-12-11 20:06:15 Valid Error = 0.95731935604642 
2016-12-11 20:06:15 Valid Loss = 0.015654627091133 
2016-12-11 20:06:22 Test Error = 0.96934994947794 
2016-12-11 20:06:22 Test Loss = 0.015704542154578 
2016-12-11 20:06:22 -------------------LR------------------- 
2016-12-11 20:06:22 0.0078125 
2016-12-11 20:06:22 Epoch 81 
2016-12-11 20:11:08 Training Error = 0.90168095198469 
2016-12-11 20:11:08 Training Loss = 0.015222442573351 
2016-12-11 20:11:15 Valid Error = 0.95544739797829 
2016-12-11 20:11:15 Valid Loss = 0.015671598841935 
2016-12-11 20:11:22 Test Error = 0.96463455708993 
2016-12-11 20:11:22 Test Loss = 0.015731285039857 
2016-12-11 20:11:22 -------------------LR------------------- 
2016-12-11 20:11:22 0.0078125 
2016-12-11 20:11:22 Epoch 82 
2016-12-11 20:16:06 Training Error = 0.90292918365649 
2016-12-11 20:16:06 Training Loss = 0.015226466558192 
2016-12-11 20:16:12 Valid Error = 0.94795956570573 
2016-12-11 20:16:12 Valid Loss = 0.015675087541096 
2016-12-11 20:16:19 Test Error = 0.95655102728191 
2016-12-11 20:16:19 Test Loss = 0.01573353694747 
2016-12-11 20:16:19 -------------------LR------------------- 
2016-12-11 20:16:19 0.0078125 
2016-12-11 20:16:19 Epoch 83 
2016-12-11 20:21:06 Training Error = 0.90084879753682 
2016-12-11 20:21:06 Training Loss = 0.015214641504718 
2016-12-11 20:21:13 Valid Error = 0.95207787345563 
2016-12-11 20:21:13 Valid Loss = 0.015672128429466 
2016-12-11 20:21:20 Test Error = 0.96227686089592 
2016-12-11 20:21:20 Test Loss = 0.015722795086046 
2016-12-11 20:21:20 -------------------LR------------------- 
2016-12-11 20:21:20 0.0078125 
2016-12-11 20:21:20 Epoch 84 
2016-12-11 20:26:06 Training Error = 0.90384455354914 
2016-12-11 20:26:06 Training Loss = 0.015220383704849 
2016-12-11 20:26:13 Valid Error = 0.95544739797829 
2016-12-11 20:26:13 Valid Loss = 0.015750305288778 
2016-12-11 20:26:20 Test Error = 0.96463455708993 
2016-12-11 20:26:20 Test Loss = 0.015787640309169 
2016-12-11 20:26:20 -------------------LR------------------- 
2016-12-11 20:26:20 0.0078125 
2016-12-11 20:26:20 Epoch 85 
2016-12-11 20:31:07 Training Error = 0.90255471415495 
2016-12-11 20:31:07 Training Loss = 0.015226413701777 
2016-12-11 20:31:13 Valid Error = 0.95132909022838 
2016-12-11 20:31:13 Valid Loss = 0.015666172588865 
2016-12-11 20:31:20 Test Error = 0.95890872347592 
2016-12-11 20:31:20 Test Loss = 0.015720829330232 
2016-12-11 20:31:20 -------------------LR------------------- 
2016-12-11 20:31:20 0.0078125 
2016-12-11 20:31:20 Epoch 86 
2016-12-11 20:36:07 Training Error = 0.90434384621786 
2016-12-11 20:36:07 Training Loss = 0.01522252471567 
2016-12-11 20:36:13 Valid Error = 0.95731935604642 
2016-12-11 20:36:13 Valid Loss = 0.015665987485662 
2016-12-11 20:36:20 Test Error = 0.96934994947794 
2016-12-11 20:36:20 Test Loss = 0.015723583924826 
2016-12-11 20:36:20 -------------------LR------------------- 
2016-12-11 20:36:20 0.0078125 
2016-12-11 20:36:20 Epoch 87 
2016-12-11 20:41:10 Training Error = 0.90367812265957 
2016-12-11 20:41:10 Training Loss = 0.015222702727062 
2016-12-11 20:41:16 Valid Error = 0.95544739797829 
2016-12-11 20:41:16 Valid Loss = 0.015733438774879 
2016-12-11 20:41:23 Test Error = 0.96463455708993 
2016-12-11 20:41:23 Test Loss = 0.015769774190966 
2016-12-11 20:41:23 -------------------LR------------------- 
2016-12-11 20:41:23 0.0078125 
2016-12-11 20:41:23 Epoch 88 
2016-12-11 20:46:09 Training Error = 0.90434384621786 
2016-12-11 20:46:09 Training Loss = 0.015228742192681 
2016-12-11 20:46:16 Valid Error = 0.95731935604642 
2016-12-11 20:46:16 Valid Loss = 0.015691421576993 
2016-12-11 20:46:23 Test Error = 0.96934994947794 
2016-12-11 20:46:23 Test Loss = 0.015752029465486 
2016-12-11 20:46:23 -------------------LR------------------- 
2016-12-11 20:46:23 0.0078125 
2016-12-11 20:46:23 Epoch 89 
2016-12-11 20:51:07 Training Error = 0.90421902305068 
2016-12-11 20:51:07 Training Loss = 0.015228856857755 
2016-12-11 20:51:13 Valid Error = 0.95207787345563 
2016-12-11 20:51:13 Valid Loss = 0.015658368284571 
2016-12-11 20:51:20 Test Error = 0.96227686089592 
2016-12-11 20:51:20 Test Loss = 0.015715356918816 
2016-12-11 20:51:20 -------------------LR------------------- 
2016-12-11 20:51:20 0.0078125 
2016-12-11 20:51:20 Epoch 90 
2016-12-11 20:56:10 Training Error = 0.90388616127153 
2016-12-11 20:56:10 Training Loss = 0.015227078544977 
2016-12-11 20:56:16 Valid Error = 0.95731935604642 
2016-12-11 20:56:16 Valid Loss = 0.015669938198363 
2016-12-11 20:56:23 Test Error = 0.96934994947794 
2016-12-11 20:56:23 Test Loss = 0.015727583283358 
2016-12-11 20:56:23 -------------------LR------------------- 
2016-12-11 20:56:23 0.0078125 
2016-12-11 20:56:23 Epoch 91 
2016-12-11 21:01:10 Training Error = 0.90438545394025 
2016-12-11 21:01:10 Training Loss = 0.015225249226873 
2016-12-11 21:01:17 Valid Error = 0.95544739797829 
2016-12-11 21:01:17 Valid Loss = 0.015714459025683 
2016-12-11 21:01:24 Test Error = 0.96463455708993 
2016-12-11 21:01:24 Test Loss = 0.015750688871091 
2016-12-11 21:01:24 -------------------LR------------------- 
2016-12-11 21:01:24 0.0078125 
2016-12-11 21:01:24 Epoch 92 
2016-12-11 21:06:14 Training Error = 0.90405259216111 
2016-12-11 21:06:14 Training Loss = 0.015225814713228 
2016-12-11 21:06:20 Valid Error = 0.95207787345563 
2016-12-11 21:06:20 Valid Loss = 0.015690223460753 
2016-12-11 21:06:27 Test Error = 0.96227686089592 
2016-12-11 21:06:27 Test Loss = 0.015745328228535 
2016-12-11 21:06:27 -------------------LR------------------- 
2016-12-11 21:06:27 0.0078125 
2016-12-11 21:06:27 Epoch 93 
2016-12-11 21:11:11 Training Error = 0.90392776899393 
2016-12-11 21:11:11 Training Loss = 0.015221527772189 
2016-12-11 21:11:18 Valid Error = 0.95544739797829 
2016-12-11 21:11:18 Valid Loss = 0.015716280167862 
2016-12-11 21:11:25 Test Error = 0.96463455708993 
2016-12-11 21:11:25 Test Loss = 0.015760709085019 
2016-12-11 21:11:25 -------------------LR------------------- 
2016-12-11 21:11:25 0.0078125 
2016-12-11 21:11:25 Epoch 94 
2016-12-11 21:16:08 Training Error = 0.904676707997 
2016-12-11 21:16:08 Training Loss = 0.015225988701119 
2016-12-11 21:16:14 Valid Error = 0.95731935604642 
2016-12-11 21:16:14 Valid Loss = 0.01564746035566 
2016-12-11 21:16:21 Test Error = 0.96934994947794 
2016-12-11 21:16:21 Test Loss = 0.015703718325084 
2016-12-11 21:16:21 -------------------LR------------------- 
2016-12-11 21:16:21 0.0078125 
2016-12-11 21:16:21 Epoch 95 
2016-12-11 21:21:08 Training Error = 0.90338686860281 
2016-12-11 21:21:08 Training Loss = 0.015219330590983 
2016-12-11 21:21:14 Valid Error = 0.95731935604642 
2016-12-11 21:21:14 Valid Loss = 0.015668631500887 
2016-12-11 21:21:21 Test Error = 0.96934994947794 
2016-12-11 21:21:21 Test Loss = 0.015724949646719 
2016-12-11 21:21:21 -------------------LR------------------- 
2016-12-11 21:21:21 0.0078125 
2016-12-11 21:21:21 Epoch 96 
2016-12-11 21:26:05 Training Error = 0.90230506782059 
2016-12-11 21:26:05 Training Loss = 0.015218507243968 
2016-12-11 21:26:11 Valid Error = 0.95132909022838 
2016-12-11 21:26:11 Valid Loss = 0.015714259520688 
2016-12-11 21:26:18 Test Error = 0.95890872347592 
2016-12-11 21:26:18 Test Loss = 0.015762214203184 
2016-12-11 21:26:18 -------------------LR------------------- 
2016-12-11 21:26:18 0.0078125 
2016-12-11 21:26:18 Epoch 97 
2016-12-11 21:31:05 Training Error = 0.90330365315803 
2016-12-11 21:31:05 Training Loss = 0.015231336126209 
2016-12-11 21:31:12 Valid Error = 0.95731935604642 
2016-12-11 21:31:12 Valid Loss = 0.01570818014144 
2016-12-11 21:31:19 Test Error = 0.96934994947794 
2016-12-11 21:31:19 Test Loss = 0.015771406260754 
2016-12-11 21:31:19 -------------------LR------------------- 
2016-12-11 21:31:19 0.0078125 
2016-12-11 21:31:19 Epoch 98 
2016-12-11 21:36:02 Training Error = 0.90392776899393 
2016-12-11 21:36:02 Training Loss = 0.015226755242414 
2016-12-11 21:36:08 Valid Error = 0.95207787345563 
2016-12-11 21:36:08 Valid Loss = 0.015666594698285 
2016-12-11 21:36:15 Test Error = 0.96227686089592 
2016-12-11 21:36:15 Test Loss = 0.015715936651625 
2016-12-11 21:36:15 -------------------LR------------------- 
2016-12-11 21:36:15 0.0078125 
2016-12-11 21:36:15 Epoch 99 
2016-12-11 21:41:02 Training Error = 0.90413580760589 
2016-12-11 21:41:02 Training Loss = 0.015226364609469 
2016-12-11 21:41:08 Valid Error = 0.95544739797829 
2016-12-11 21:41:08 Valid Loss = 0.015666830092579 
2016-12-11 21:41:15 Test Error = 0.96463455708993 
2016-12-11 21:41:15 Test Loss = 0.01572681977385 
2016-12-11 21:41:15 -------------------LR------------------- 
2016-12-11 21:41:15 0.0078125 
2016-12-11 21:41:15 Epoch 100 
2016-12-11 21:46:03 Training Error = 0.90205542148623 
2016-12-11 21:46:03 Training Loss = 0.015216121275203 
2016-12-11 21:46:09 Valid Error = 0.95207787345563 
2016-12-11 21:46:09 Valid Loss = 0.015667886056281 
2016-12-11 21:46:16 Test Error = 0.96227686089592 
2016-12-11 21:46:16 Test Loss = 0.015722408681531 
2016-12-11 21:46:16 -------------------LR------------------- 
2016-12-11 21:46:16 0.00390625 
2016-12-11 21:46:16 Epoch 101 
2016-12-11 21:51:02 Training Error = 0.90205542148623 
2016-12-11 21:51:02 Training Loss = 0.015218274215144 
2016-12-11 21:51:08 Valid Error = 0.95731935604642 
2016-12-11 21:51:08 Valid Loss = 0.015653592953928 
2016-12-11 21:51:15 Test Error = 0.96934994947794 
2016-12-11 21:51:15 Test Loss = 0.015713632962125 
2016-12-11 21:51:15 -------------------LR------------------- 
2016-12-11 21:51:15 0.00390625 
2016-12-11 21:51:15 Epoch 102 
2016-12-11 21:56:03 Training Error = 0.90334526088042 
2016-12-11 21:56:03 Training Loss = 0.015222503115721 
2016-12-11 21:56:09 Valid Error = 0.95320104829652 
2016-12-11 21:56:09 Valid Loss = 0.015645870985633 
2016-12-11 21:56:16 Test Error = 0.96362411586393 
2016-12-11 21:56:16 Test Loss = 0.015699726800466 
2016-12-11 21:56:16 -------------------LR------------------- 
2016-12-11 21:56:16 0.00390625 
2016-12-11 21:56:16 Epoch 103 
2016-12-11 22:01:00 Training Error = 0.90430223849546 
2016-12-11 22:01:00 Training Loss = 0.015228915986613 
2016-12-11 22:01:07 Valid Error = 0.94795956570573 
2016-12-11 22:01:07 Valid Loss = 0.015650590904742 
2016-12-11 22:01:14 Test Error = 0.95655102728191 
2016-12-11 22:01:14 Test Loss = 0.015711175041058 
2016-12-11 22:01:14 -------------------LR------------------- 
2016-12-11 22:01:14 0.00390625 
2016-12-11 22:01:14 Epoch 104 
2016-12-11 22:06:06 Training Error = 0.90417741532828 
2016-12-11 22:06:06 Training Loss = 0.015225710386451 
2016-12-11 22:06:13 Valid Error = 0.95731935604642 
2016-12-11 22:06:13 Valid Loss = 0.015656193708839 
2016-12-11 22:06:20 Test Error = 0.96934994947794 
2016-12-11 22:06:20 Test Loss = 0.0157123030762 
2016-12-11 22:06:20 -------------------LR------------------- 
2016-12-11 22:06:20 0.00390625 
2016-12-11 22:06:20 Epoch 105 
2016-12-11 22:11:06 Training Error = 0.90384455354914 
2016-12-11 22:11:06 Training Loss = 0.015224573888805 
2016-12-11 22:11:13 Valid Error = 0.95207787345563 
2016-12-11 22:11:13 Valid Loss = 0.01567075246492 
2016-12-11 22:11:20 Test Error = 0.96227686089592 
2016-12-11 22:11:20 Test Loss = 0.015725263118934 
2016-12-11 22:11:20 -------------------LR------------------- 
2016-12-11 22:11:20 0.00390625 
2016-12-11 22:11:20 Epoch 106 
2016-12-11 22:16:07 Training Error = 0.90363651493717 
2016-12-11 22:16:07 Training Loss = 0.015219080349092 
2016-12-11 22:16:14 Valid Error = 0.95320104829652 
2016-12-11 22:16:14 Valid Loss = 0.015678177139744 
2016-12-11 22:16:21 Test Error = 0.96362411586393 
2016-12-11 22:16:21 Test Loss = 0.015738087135424 
2016-12-11 22:16:21 -------------------LR------------------- 
2016-12-11 22:16:21 0.00390625 
2016-12-11 22:16:21 Epoch 107 
2016-12-11 22:21:05 Training Error = 0.90292918365649 
2016-12-11 22:21:05 Training Loss = 0.015225989591174 
2016-12-11 22:21:12 Valid Error = 0.95320104829652 
2016-12-11 22:21:12 Valid Loss = 0.015664759456471 
2016-12-11 22:21:19 Test Error = 0.96362411586393 
2016-12-11 22:21:19 Test Loss = 0.015720332336859 
2016-12-11 22:21:19 -------------------LR------------------- 
2016-12-11 22:21:19 0.00390625 
2016-12-11 22:21:19 Epoch 108 
2016-12-11 22:26:03 Training Error = 0.9034700840476 
2016-12-11 22:26:03 Training Loss = 0.015226661813906 
2016-12-11 22:26:09 Valid Error = 0.95207787345563 
2016-12-11 22:26:09 Valid Loss = 0.015672085788449 
2016-12-11 22:26:16 Test Error = 0.96227686089592 
2016-12-11 22:26:16 Test Loss = 0.015731508202357 
2016-12-11 22:26:16 -------------------LR------------------- 
2016-12-11 22:26:16 0.00390625 
2016-12-11 22:26:16 Epoch 109 
2016-12-11 22:31:02 Training Error = 0.90242989098777 
2016-12-11 22:31:02 Training Loss = 0.015215476694096 
2016-12-11 22:31:09 Valid Error = 0.95731935604642 
2016-12-11 22:31:09 Valid Loss = 0.015681956135935 
2016-12-11 22:31:16 Test Error = 0.96934994947794 
2016-12-11 22:31:16 Test Loss = 0.01573753326841 
2016-12-11 22:31:16 -------------------LR------------------- 
2016-12-11 22:31:16 0.00390625 
2016-12-11 22:31:16 Epoch 110 
2016-12-11 22:36:04 Training Error = 0.90267953732213 
2016-12-11 22:36:04 Training Loss = 0.015224998486061 
2016-12-11 22:36:11 Valid Error = 0.95132909022838 
2016-12-11 22:36:11 Valid Loss = 0.015710402986181 
2016-12-11 22:36:18 Test Error = 0.95890872347592 
2016-12-11 22:36:18 Test Loss = 0.015752640206143 
2016-12-11 22:36:18 -------------------LR------------------- 
2016-12-11 22:36:18 0.00390625 
2016-12-11 22:36:18 Epoch 111 
2016-12-11 22:41:05 Training Error = 0.90326204543563 
2016-12-11 22:41:05 Training Loss = 0.015221861937676 
2016-12-11 22:41:11 Valid Error = 0.95207787345563 
2016-12-11 22:41:11 Valid Loss = 0.015661668399477 
2016-12-11 22:41:18 Test Error = 0.96227686089592 
2016-12-11 22:41:18 Test Loss = 0.015717376862772 
2016-12-11 22:41:18 -------------------LR------------------- 
2016-12-11 22:41:18 0.00390625 
2016-12-11 22:41:18 Epoch 112 
2016-12-11 22:46:04 Training Error = 0.90334526088042 
2016-12-11 22:46:04 Training Loss = 0.015220624072019 
2016-12-11 22:46:10 Valid Error = 0.95731935604642 
2016-12-11 22:46:10 Valid Loss = 0.015689097478956 
2016-12-11 22:46:17 Test Error = 0.96934994947794 
2016-12-11 22:46:17 Test Loss = 0.015747238764212 
2016-12-11 22:46:17 -------------------LR------------------- 
2016-12-11 22:46:17 0.00390625 
2016-12-11 22:46:17 Epoch 113 
2016-12-11 22:51:01 Training Error = 0.90259632187734 
2016-12-11 22:51:01 Training Loss = 0.015227682830326 
2016-12-11 22:51:08 Valid Error = 0.9502059153875 
2016-12-11 22:51:08 Valid Loss = 0.015698587756222 
2016-12-11 22:51:15 Test Error = 0.95756146850792 
2016-12-11 22:51:15 Test Loss = 0.01573664757585 
2016-12-11 22:51:15 -------------------LR------------------- 
2016-12-11 22:51:15 0.00390625 
2016-12-11 22:51:15 Epoch 114 
2016-12-11 22:56:02 Training Error = 0.90338686860281 
2016-12-11 22:56:02 Training Loss = 0.01521997962645 
2016-12-11 22:56:08 Valid Error = 0.95207787345563 
2016-12-11 22:56:08 Valid Loss = 0.015653984657205 
2016-12-11 22:56:15 Test Error = 0.96227686089592 
2016-12-11 22:56:15 Test Loss = 0.015707170088359 
2016-12-11 22:56:15 -------------------LR------------------- 
2016-12-11 22:56:15 0.00390625 
2016-12-11 22:56:15 Epoch 115 
2016-12-11 23:01:02 Training Error = 0.90230506782059 
2016-12-11 23:01:02 Training Loss = 0.015212447276143 
2016-12-11 23:01:08 Valid Error = 0.95207787345563 
2016-12-11 23:01:08 Valid Loss = 0.015684116930422 
2016-12-11 23:01:15 Test Error = 0.96227686089592 
2016-12-11 23:01:15 Test Loss = 0.01574624680041 
2016-12-11 23:01:15 -------------------LR------------------- 
2016-12-11 23:01:15 0.00390625 
2016-12-11 23:01:15 Epoch 116 
2016-12-11 23:06:01 Training Error = 0.90272114504452 
2016-12-11 23:06:01 Training Loss = 0.015222689375667 
2016-12-11 23:06:08 Valid Error = 0.95731935604642 
2016-12-11 23:06:08 Valid Loss = 0.015675248533518 
2016-12-11 23:06:15 Test Error = 0.96934994947794 
2016-12-11 23:06:15 Test Loss = 0.015733797963677 
2016-12-11 23:06:15 -------------------LR------------------- 
2016-12-11 23:06:15 0.00390625 
2016-12-11 23:06:15 Epoch 117 
2016-12-11 23:10:59 Training Error = 0.90334526088042 
2016-12-11 23:10:59 Training Loss = 0.015219187892566 
2016-12-11 23:11:06 Valid Error = 0.95207787345563 
2016-12-11 23:11:06 Valid Loss = 0.015675335790811 
2016-12-11 23:11:13 Test Error = 0.96227686089592 
2016-12-11 23:11:13 Test Loss = 0.015732368662774 
2016-12-11 23:11:13 -------------------LR------------------- 
2016-12-11 23:11:13 0.00390625 
2016-12-11 23:11:13 Epoch 118 
2016-12-11 23:16:03 Training Error = 0.90238828326537 
2016-12-11 23:16:03 Training Loss = 0.015218029408512 
2016-12-11 23:16:09 Valid Error = 0.95544739797829 
2016-12-11 23:16:09 Valid Loss = 0.015673041511458 
2016-12-11 23:16:16 Test Error = 0.96463455708993 
2016-12-11 23:16:16 Test Loss = 0.015731285823249 
2016-12-11 23:16:16 -------------------LR------------------- 
2016-12-11 23:16:16 0.00390625 
2016-12-11 23:16:16 Epoch 119 
2016-12-11 23:21:01 Training Error = 0.90396937671632 
2016-12-11 23:21:01 Training Loss = 0.015227726690098 
2016-12-11 23:21:08 Valid Error = 0.95320104829652 
2016-12-11 23:21:08 Valid Loss = 0.015696662191217 
2016-12-11 23:21:15 Test Error = 0.96362411586393 
2016-12-11 23:21:15 Test Loss = 0.015758464236601 
2016-12-11 23:21:15 -------------------LR------------------- 
2016-12-11 23:21:15 0.00390625 
2016-12-11 23:21:15 Epoch 120 
2016-12-11 23:26:07 Training Error = 0.90480153116418 
2016-12-11 23:26:07 Training Loss = 0.015229784766986 
2016-12-11 23:26:13 Valid Error = 0.95731935604642 
2016-12-11 23:26:13 Valid Loss = 0.015682014206329 
2016-12-11 23:26:20 Test Error = 0.96934994947794 
2016-12-11 23:26:20 Test Loss = 0.015742351651442 
2016-12-11 23:26:20 -------------------LR------------------- 
2016-12-11 23:26:20 0.00390625 
2016-12-11 23:26:20 Epoch 121 
2016-12-11 23:31:48 Training Error = 0.90317882999085 
2016-12-11 23:31:48 Training Loss = 0.015223739862603 
2016-12-11 23:31:54 Valid Error = 0.95731935604642 
2016-12-11 23:31:54 Valid Loss = 0.015678567051928 
2016-12-11 23:32:01 Test Error = 0.96934994947794 
2016-12-11 23:32:01 Test Loss = 0.015732229228344 
2016-12-11 23:32:01 -------------------LR------------------- 
2016-12-11 23:32:01 0.00390625 
2016-12-11 23:32:01 Epoch 122 
2016-12-11 23:38:06 Training Error = 0.90193059831905 
2016-12-11 23:38:06 Training Loss = 0.01521806112797 
2016-12-11 23:38:12 Valid Error = 0.95731935604642 
2016-12-11 23:38:12 Valid Loss = 0.015673638420765 
2016-12-11 23:38:19 Test Error = 0.96934994947794 
2016-12-11 23:38:19 Test Loss = 0.015732790921179 
2016-12-11 23:38:19 -------------------LR------------------- 
2016-12-11 23:38:19 0.00390625 
2016-12-11 23:38:19 Epoch 123 
2016-12-11 23:44:29 Training Error = 0.90251310643255 
2016-12-11 23:44:29 Training Loss = 0.015223592028921 
2016-12-11 23:44:35 Valid Error = 0.9502059153875 
2016-12-11 23:44:35 Valid Loss = 0.015729787398957 
2016-12-11 23:44:42 Test Error = 0.95756146850792 
2016-12-11 23:44:42 Test Loss = 0.015759840823064 
2016-12-11 23:44:42 -------------------LR------------------- 
2016-12-11 23:44:42 0.00390625 
2016-12-11 23:44:42 Epoch 124 
2016-12-11 23:50:35 Training Error = 0.90338686860281 
2016-12-11 23:50:35 Training Loss = 0.015218815702755 
2016-12-11 23:50:41 Valid Error = 0.95544739797829 
2016-12-11 23:50:41 Valid Loss = 0.01571983443891 
2016-12-11 23:50:48 Test Error = 0.96463455708993 
2016-12-11 23:50:48 Test Loss = 0.015766429819965 
2016-12-11 23:50:48 -------------------LR------------------- 
2016-12-11 23:50:48 0.00390625 
2016-12-11 23:50:48 Epoch 125 
2016-12-11 23:56:39 Training Error = 0.90371973038196 
2016-12-11 23:56:39 Training Loss = 0.015228151979066 
2016-12-11 23:56:46 Valid Error = 0.95731935604642 
2016-12-11 23:56:46 Valid Loss = 0.015647827165918 
2016-12-11 23:56:53 Test Error = 0.96934994947794 
2016-12-11 23:56:53 Test Loss = 0.015714233823955 
2016-12-11 23:56:53 -------------------LR------------------- 
2016-12-11 23:56:53 0.00390625 
2016-12-11 23:56:53 Epoch 126 
2016-12-12 00:02:43 Training Error = 0.90475992344179 
2016-12-12 00:02:43 Training Loss = 0.015222549154328 
2016-12-12 00:02:50 Valid Error = 0.94795956570573 
2016-12-12 00:02:50 Valid Loss = 0.015627500233285 
2016-12-12 00:02:57 Test Error = 0.95655102728191 
2016-12-12 00:02:57 Test Loss = 0.015685240069996 
2016-12-12 00:02:57 -------------------LR------------------- 
2016-12-12 00:02:57 0.00390625 
2016-12-12 00:02:57 Epoch 127 
2016-12-12 00:08:34 Training Error = 0.90492635433136 
2016-12-12 00:08:34 Training Loss = 0.015222793407999 
2016-12-12 00:08:40 Valid Error = 0.95544739797829 
2016-12-12 00:08:40 Valid Loss = 0.015653806360033 
2016-12-12 00:08:47 Test Error = 0.96463455708993 
2016-12-12 00:08:47 Test Loss = 0.015712030481987 
2016-12-12 00:08:47 -------------------LR------------------- 
2016-12-12 00:08:47 0.00390625 
2016-12-12 00:08:47 Epoch 128 
2016-12-12 00:14:36 Training Error = 0.90451027710743 
2016-12-12 00:14:36 Training Loss = 0.015226163840794 
2016-12-12 00:14:43 Valid Error = 0.95544739797829 
2016-12-12 00:14:43 Valid Loss = 0.015768728448566 
2016-12-12 00:14:50 Test Error = 0.96463455708993 
2016-12-12 00:14:50 Test Loss = 0.015801818786372 
2016-12-12 00:14:50 -------------------LR------------------- 
2016-12-12 00:14:50 0.00390625 
2016-12-12 00:14:50 Epoch 129 
2016-12-12 00:20:33 Training Error = 0.90309561454606 
2016-12-12 00:20:33 Training Loss = 0.015219877505091 
2016-12-12 00:20:39 Valid Error = 0.95731935604642 
2016-12-12 00:20:39 Valid Loss = 0.015683477753424 
2016-12-12 00:20:46 Test Error = 0.96934994947794 
2016-12-12 00:20:46 Test Loss = 0.015742559251336 
2016-12-12 00:20:46 -------------------LR------------------- 
2016-12-12 00:20:46 0.00390625 
2016-12-12 00:20:46 Epoch 130 
2016-12-12 00:26:28 Training Error = 0.90351169176999 
2016-12-12 00:26:28 Training Loss = 0.015222318739873 
2016-12-12 00:26:34 Valid Error = 0.95731935604642 
2016-12-12 00:26:34 Valid Loss = 0.015697564087145 
2016-12-12 00:26:41 Test Error = 0.96934994947794 
2016-12-12 00:26:41 Test Loss = 0.015757053604119 
2016-12-12 00:26:41 -------------------LR------------------- 
2016-12-12 00:26:41 0.00390625 
2016-12-12 00:26:41 Epoch 131 
2016-12-12 00:32:25 Training Error = 0.90367812265957 
2016-12-12 00:32:25 Training Loss = 0.015222750899813 
2016-12-12 00:32:31 Valid Error = 0.9502059153875 
2016-12-12 00:32:31 Valid Loss = 0.015720064175245 
2016-12-12 00:32:38 Test Error = 0.95756146850792 
2016-12-12 00:32:38 Test Loss = 0.015764369898185 
2016-12-12 00:32:38 -------------------LR------------------- 
2016-12-12 00:32:38 0.00390625 
2016-12-12 00:32:38 Epoch 132 
2016-12-12 00:38:27 Training Error = 0.90242989098777 
2016-12-12 00:38:27 Training Loss = 0.015220301508198 
2016-12-12 00:38:33 Valid Error = 0.9502059153875 
2016-12-12 00:38:33 Valid Loss = 0.015743959262555 
2016-12-12 00:38:40 Test Error = 0.95756146850792 
2016-12-12 00:38:40 Test Loss = 0.01576772208749 
2016-12-12 00:38:40 -------------------LR------------------- 
2016-12-12 00:38:40 0.00390625 
2016-12-12 00:38:40 Epoch 133 
2016-12-12 00:44:22 Training Error = 0.90297079137888 
2016-12-12 00:44:22 Training Loss = 0.015218955927307 
2016-12-12 00:44:28 Valid Error = 0.95207787345563 
2016-12-12 00:44:28 Valid Loss = 0.015652336679893 
2016-12-12 00:44:35 Test Error = 0.96227686089592 
2016-12-12 00:44:35 Test Loss = 0.015705082522399 
2016-12-12 00:44:35 -------------------LR------------------- 
2016-12-12 00:44:35 0.00390625 
2016-12-12 00:44:35 Epoch 134 
2016-12-12 00:50:22 Training Error = 0.9022218523758 
2016-12-12 00:50:22 Training Loss = 0.015220176937438 
2016-12-12 00:50:28 Valid Error = 0.95544739797829 
2016-12-12 00:50:28 Valid Loss = 0.015711484597048 
2016-12-12 00:50:35 Test Error = 0.96463455708993 
2016-12-12 00:50:35 Test Loss = 0.015756117458837 
2016-12-12 00:50:35 -------------------LR------------------- 
2016-12-12 00:50:35 0.00390625 
2016-12-12 00:50:35 Epoch 135 
2016-12-12 00:56:22 Training Error = 0.90371973038196 
2016-12-12 00:56:22 Training Loss = 0.015220835079674 
2016-12-12 00:56:28 Valid Error = 0.95731935604642 
2016-12-12 00:56:28 Valid Loss = 0.015673669358179 
2016-12-12 00:56:35 Test Error = 0.96934994947794 
2016-12-12 00:56:35 Test Loss = 0.015730023255221 
2016-12-12 00:56:35 -------------------LR------------------- 
2016-12-12 00:56:35 0.00390625 
2016-12-12 00:56:35 Epoch 136 
2016-12-12 01:02:17 Training Error = 0.90367812265957 
2016-12-12 01:02:17 Training Loss = 0.0152201148615 
2016-12-12 01:02:24 Valid Error = 0.95207787345563 
2016-12-12 01:02:24 Valid Loss = 0.015683296442171 
2016-12-12 01:02:31 Test Error = 0.96227686089592 
2016-12-12 01:02:31 Test Loss = 0.015748484881019 
2016-12-12 01:02:31 -------------------LR------------------- 
2016-12-12 01:02:31 0.00390625 
2016-12-12 01:02:31 Epoch 137 
2016-12-12 01:08:24 Training Error = 0.90363651493717 
2016-12-12 01:08:24 Training Loss = 0.015225831898544 
2016-12-12 01:08:31 Valid Error = 0.95731935604642 
2016-12-12 01:08:31 Valid Loss = 0.01566236932145 
2016-12-12 01:08:38 Test Error = 0.96934994947794 
2016-12-12 01:08:38 Test Loss = 0.01571927457858 
2016-12-12 01:08:38 -------------------LR------------------- 
2016-12-12 01:08:38 0.00390625 
2016-12-12 01:08:38 Epoch 138 
2016-12-12 01:14:22 Training Error = 0.90334526088042 
2016-12-12 01:14:22 Training Loss = 0.015227599511979 
2016-12-12 01:14:28 Valid Error = 0.9502059153875 
2016-12-12 01:14:28 Valid Loss = 0.015676830384572 
2016-12-12 01:14:35 Test Error = 0.95756146850792 
2016-12-12 01:14:35 Test Loss = 0.015734300174263 
2016-12-12 01:14:35 -------------------LR------------------- 
2016-12-12 01:14:35 0.00390625 
2016-12-12 01:14:35 Epoch 139 
2016-12-12 01:20:15 Training Error = 0.90305400682367 
2016-12-12 01:20:15 Training Loss = 0.015220542940102 
2016-12-12 01:20:21 Valid Error = 0.95731935604642 
2016-12-12 01:20:21 Valid Loss = 0.015659507154876 
2016-12-12 01:20:28 Test Error = 0.96934994947794 
2016-12-12 01:20:28 Test Loss = 0.01571179178521 
2016-12-12 01:20:28 -------------------LR------------------- 
2016-12-12 01:20:28 0.00390625 
2016-12-12 01:20:28 Epoch 140 
2016-12-12 01:26:17 Training Error = 0.90371973038196 
2016-12-12 01:26:17 Training Loss = 0.015231154447105 
2016-12-12 01:26:24 Valid Error = 0.95731935604642 
2016-12-12 01:26:24 Valid Loss = 0.015677907270173 
2016-12-12 01:26:31 Test Error = 0.96934994947794 
2016-12-12 01:26:31 Test Loss = 0.015740205464675 
2016-12-12 01:26:31 -------------------LR------------------- 
2016-12-12 01:26:31 0.00390625 
2016-12-12 01:26:31 Epoch 141 
2016-12-12 01:32:16 Training Error = 0.90367812265957 
2016-12-12 01:32:16 Training Loss = 0.015224467532168 
2016-12-12 01:32:23 Valid Error = 0.9502059153875 
2016-12-12 01:32:23 Valid Loss = 0.015686800686203 
2016-12-12 01:32:30 Test Error = 0.95756146850792 
2016-12-12 01:32:30 Test Loss = 0.015749854072382 
2016-12-12 01:32:30 -------------------LR------------------- 
2016-12-12 01:32:30 0.00390625 
2016-12-12 01:32:30 Epoch 142 
2016-12-12 01:37:59 Training Error = 0.90301239910127 
2016-12-12 01:37:59 Training Loss = 0.015219626827374 
2016-12-12 01:38:06 Valid Error = 0.95207787345563 
2016-12-12 01:38:06 Valid Loss = 0.015669474278236 
2016-12-12 01:38:13 Test Error = 0.96227686089592 
2016-12-12 01:38:13 Test Loss = 0.015724317616893 
2016-12-12 01:38:13 -------------------LR------------------- 
2016-12-12 01:38:13 0.00390625 
2016-12-12 01:38:13 Epoch 143 
2016-12-12 01:43:55 Training Error = 0.90405259216111 
2016-12-12 01:43:55 Training Loss = 0.015223102629773 
2016-12-12 01:44:01 Valid Error = 0.95207787345563 
2016-12-12 01:44:01 Valid Loss = 0.015685004412071 
2016-12-12 01:44:08 Test Error = 0.96227686089592 
2016-12-12 01:44:08 Test Loss = 0.015741345248955 
2016-12-12 01:44:08 -------------------LR------------------- 
2016-12-12 01:44:08 0.00390625 
2016-12-12 01:44:08 Epoch 144 
2016-12-12 01:50:03 Training Error = 0.90251310643255 
2016-12-12 01:50:03 Training Loss = 0.015220661131216 
2016-12-12 01:50:09 Valid Error = 0.95207787345563 
2016-12-12 01:50:09 Valid Loss = 0.015669974386698 
2016-12-12 01:50:16 Test Error = 0.96227686089592 
2016-12-12 01:50:16 Test Loss = 0.015724792712306 
2016-12-12 01:50:16 -------------------LR------------------- 
2016-12-12 01:50:16 0.00390625 
2016-12-12 01:50:16 Epoch 145 
2016-12-12 01:55:58 Training Error = 0.90330365315803 
2016-12-12 01:55:58 Training Loss = 0.015223555524437 
2016-12-12 01:56:04 Valid Error = 0.95320104829652 
2016-12-12 01:56:04 Valid Loss = 0.015689373290539 
2016-12-12 01:56:11 Test Error = 0.96362411586393 
2016-12-12 01:56:11 Test Loss = 0.01574948732897 
2016-12-12 01:56:11 -------------------LR------------------- 
2016-12-12 01:56:11 0.00390625 
2016-12-12 01:56:11 Epoch 146 
2016-12-12 02:02:04 Training Error = 0.90376133810435 
2016-12-12 02:02:04 Training Loss = 0.015225745265644 
2016-12-12 02:02:11 Valid Error = 0.95320104829652 
2016-12-12 02:02:11 Valid Loss = 0.015675725165479 
2016-12-12 02:02:18 Test Error = 0.96362411586393 
2016-12-12 02:02:18 Test Loss = 0.015738301619334 
2016-12-12 02:02:18 -------------------LR------------------- 
2016-12-12 02:02:18 0.00390625 
2016-12-12 02:02:18 Epoch 147 
2016-12-12 02:08:03 Training Error = 0.9022218523758 
2016-12-12 02:08:03 Training Loss = 0.015217958545663 
2016-12-12 02:08:09 Valid Error = 0.95731935604642 
2016-12-12 02:08:09 Valid Loss = 0.015652623206824 
2016-12-12 02:08:16 Test Error = 0.96934994947794 
2016-12-12 02:08:16 Test Loss = 0.015707926296427 
2016-12-12 02:08:16 -------------------LR------------------- 
2016-12-12 02:08:16 0.00390625 
2016-12-12 02:08:16 Epoch 148 
2016-12-12 02:13:52 Training Error = 0.90438545394025 
2016-12-12 02:13:52 Training Loss = 0.015226672011992 
2016-12-12 02:13:58 Valid Error = 0.95731935604642 
2016-12-12 02:13:58 Valid Loss = 0.01569003242303 
2016-12-12 02:14:05 Test Error = 0.96934994947794 
2016-12-12 02:14:05 Test Loss = 0.015752557963337 
2016-12-12 02:14:05 -------------------LR------------------- 
2016-12-12 02:14:05 0.00390625 
2016-12-12 02:14:05 Epoch 149 
2016-12-12 02:19:53 Training Error = 0.90459349255222 
2016-12-12 02:19:53 Training Loss = 0.015234810657353 
2016-12-12 02:20:00 Valid Error = 0.9502059153875 
2016-12-12 02:20:00 Valid Loss = 0.015690445910976 
2016-12-12 02:20:07 Test Error = 0.95756146850792 
2016-12-12 02:20:07 Test Loss = 0.015750780449842 
2016-12-12 02:20:07 -------------------LR------------------- 
2016-12-12 02:20:07 0.00390625 
2016-12-12 02:20:07 Epoch 150 
2016-12-12 02:25:59 Training Error = 0.90313722226845 
2016-12-12 02:25:59 Training Loss = 0.015217936351858 
2016-12-12 02:26:06 Valid Error = 0.9502059153875 
2016-12-12 02:26:06 Valid Loss = 0.01568004776518 
2016-12-12 02:26:13 Test Error = 0.95756146850792 
2016-12-12 02:26:13 Test Loss = 0.015740000937642 
2016-12-12 02:26:13 -------------------LR------------------- 
2016-12-12 02:26:13 0.001953125 
2016-12-12 02:26:13 Epoch 151 
2016-12-12 02:31:46 Training Error = 0.90218024465341 
2016-12-12 02:31:46 Training Loss = 0.015218180899098 
2016-12-12 02:31:52 Valid Error = 0.95207787345563 
2016-12-12 02:31:52 Valid Loss = 0.015667156920055 
2016-12-12 02:31:59 Test Error = 0.96227686089592 
2016-12-12 02:31:59 Test Loss = 0.015729751880903 
2016-12-12 02:31:59 -------------------LR------------------- 
2016-12-12 02:31:59 0.001953125 
2016-12-12 02:31:59 Epoch 152 
2016-12-12 02:37:46 Training Error = 0.9022218523758 
2016-12-12 02:37:46 Training Loss = 0.015221452466957 
2016-12-12 02:37:52 Valid Error = 0.95544739797829 
2016-12-12 02:37:52 Valid Loss = 0.015678818047279 
2016-12-12 02:37:59 Test Error = 0.96463455708993 
2016-12-12 02:37:59 Test Loss = 0.015737140490962 
2016-12-12 02:37:59 -------------------LR------------------- 
2016-12-12 02:37:59 0.001953125 
2016-12-12 02:37:59 Epoch 153 
2016-12-12 02:43:46 Training Error = 0.90355329949239 
2016-12-12 02:43:46 Training Loss = 0.015223455974507 
2016-12-12 02:43:53 Valid Error = 0.94795956570573 
2016-12-12 02:43:53 Valid Loss = 0.015678111670242 
2016-12-12 02:44:00 Test Error = 0.95655102728191 
2016-12-12 02:44:00 Test Loss = 0.015734945153463 
2016-12-12 02:44:00 -------------------LR------------------- 
2016-12-12 02:44:00 0.001953125 
2016-12-12 02:44:00 Epoch 154 
2016-12-12 02:49:40 Training Error = 0.90213863693101 
2016-12-12 02:49:40 Training Loss = 0.015222907489441 
2016-12-12 02:49:46 Valid Error = 0.95207787345563 
2016-12-12 02:49:46 Valid Loss = 0.015674837613909 
2016-12-12 02:49:53 Test Error = 0.96227686089592 
2016-12-12 02:49:53 Test Loss = 0.015730081930953 
2016-12-12 02:49:53 -------------------LR------------------- 
2016-12-12 02:49:53 0.001953125 
2016-12-12 02:49:53 Epoch 155 
2016-12-12 02:55:43 Training Error = 0.90338686860281 
2016-12-12 02:55:43 Training Loss = 0.015219818390254 
2016-12-12 02:55:49 Valid Error = 0.95544739797829 
2016-12-12 02:55:49 Valid Loss = 0.015667697267882 
2016-12-12 02:55:56 Test Error = 0.96463455708993 
2016-12-12 02:55:56 Test Loss = 0.015724562226975 
2016-12-12 02:55:56 -------------------LR------------------- 
2016-12-12 02:55:56 0.001953125 
2016-12-12 02:55:56 Epoch 156 
2016-12-12 03:01:40 Training Error = 0.90276275276691 
2016-12-12 03:01:40 Training Loss = 0.015218769003106 
2016-12-12 03:01:47 Valid Error = 0.95207787345563 
2016-12-12 03:01:47 Valid Loss = 0.015669768901609 
2016-12-12 03:01:54 Test Error = 0.96227686089592 
2016-12-12 03:01:54 Test Loss = 0.015728309543903 
2016-12-12 03:01:54 -------------------LR------------------- 
2016-12-12 03:01:54 0.001953125 
2016-12-12 03:01:54 Epoch 157 
2016-12-12 03:07:33 Training Error = 0.90413580760589 
2016-12-12 03:07:33 Training Loss = 0.015223087088734 
2016-12-12 03:07:39 Valid Error = 0.95731935604642 
2016-12-12 03:07:39 Valid Loss = 0.015676349222124 
2016-12-12 03:07:46 Test Error = 0.96934994947794 
2016-12-12 03:07:46 Test Loss = 0.015731954691552 
2016-12-12 03:07:46 -------------------LR------------------- 
2016-12-12 03:07:46 0.001953125 
2016-12-12 03:07:46 Epoch 158 
2016-12-12 03:13:30 Training Error = 0.90267953732213 
2016-12-12 03:13:30 Training Loss = 0.015224247102267 
2016-12-12 03:13:37 Valid Error = 0.95731935604642 
2016-12-12 03:13:37 Valid Loss = 0.015668164190854 
2016-12-12 03:13:44 Test Error = 0.96934994947794 
2016-12-12 03:13:44 Test Loss = 0.015723392184128 
2016-12-12 03:13:44 -------------------LR------------------- 
2016-12-12 03:13:44 0.001953125 
2016-12-12 03:13:44 Epoch 159 
2016-12-12 03:19:28 Training Error = 0.90413580760589 
2016-12-12 03:19:28 Training Loss = 0.015220087491827 
2016-12-12 03:19:35 Valid Error = 0.95731935604642 
2016-12-12 03:19:35 Valid Loss = 0.0156717738391 
2016-12-12 03:19:42 Test Error = 0.96934994947794 
2016-12-12 03:19:42 Test Loss = 0.015727802749754 
2016-12-12 03:19:42 -------------------LR------------------- 
2016-12-12 03:19:42 0.001953125 
2016-12-12 03:19:42 Epoch 160 
2016-12-12 03:25:25 Training Error = 0.90242989098777 
2016-12-12 03:25:25 Training Loss = 0.015220316045552 
2016-12-12 03:25:31 Valid Error = 0.95731935604642 
2016-12-12 03:25:31 Valid Loss = 0.015680074525457 
2016-12-12 03:25:38 Test Error = 0.96934994947794 
2016-12-12 03:25:38 Test Loss = 0.015736817882842 
2016-12-12 03:25:38 -------------------LR------------------- 
2016-12-12 03:25:38 0.001953125 
2016-12-12 03:25:38 Epoch 161 
2016-12-12 03:31:22 Training Error = 0.90172255970708 
2016-12-12 03:31:22 Training Loss = 0.01522499451368 
2016-12-12 03:31:28 Valid Error = 0.95731935604642 
2016-12-12 03:31:28 Valid Loss = 0.015665715606495 
2016-12-12 03:31:35 Test Error = 0.96934994947794 
2016-12-12 03:31:35 Test Loss = 0.015722455258346 
2016-12-12 03:31:35 -------------------LR------------------- 
2016-12-12 03:31:35 0.001953125 
2016-12-12 03:31:35 Epoch 162 
2016-12-12 03:37:23 Training Error = 0.90338686860281 
2016-12-12 03:37:23 Training Loss = 0.015223455990573 
2016-12-12 03:37:29 Valid Error = 0.95544739797829 
2016-12-12 03:37:29 Valid Loss = 0.015669543499109 
2016-12-12 03:37:36 Test Error = 0.96463455708993 
2016-12-12 03:37:36 Test Loss = 0.015725925124034 
2016-12-12 03:37:36 -------------------LR------------------- 
2016-12-12 03:37:36 0.001953125 
2016-12-12 03:37:36 Epoch 163 
2016-12-12 03:43:14 Training Error = 0.904676707997 
2016-12-12 03:43:14 Training Loss = 0.015227921108921 
2016-12-12 03:43:21 Valid Error = 0.95731935604642 
2016-12-12 03:43:21 Valid Loss = 0.015686843609399 
2016-12-12 03:43:28 Test Error = 0.96934994947794 
2016-12-12 03:43:28 Test Loss = 0.015750185702513 
2016-12-12 03:43:28 -------------------LR------------------- 
2016-12-12 03:43:28 0.001953125 
2016-12-12 03:43:28 Epoch 164 
2016-12-12 03:49:19 Training Error = 0.90184738287426 
2016-12-12 03:49:19 Training Loss = 0.015217980574428 
2016-12-12 03:49:25 Valid Error = 0.94795956570573 
2016-12-12 03:49:25 Valid Loss = 0.015668996156089 
2016-12-12 03:49:32 Test Error = 0.95655102728191 
2016-12-12 03:49:32 Test Loss = 0.015728531441413 
2016-12-12 03:49:32 -------------------LR------------------- 
2016-12-12 03:49:32 0.001953125 
2016-12-12 03:49:32 Epoch 165 
2016-12-12 03:55:21 Training Error = 0.90426063077307 
2016-12-12 03:55:21 Training Loss = 0.01522329390259 
2016-12-12 03:55:28 Valid Error = 0.95207787345563 
2016-12-12 03:55:28 Valid Loss = 0.015692700696369 
2016-12-12 03:55:35 Test Error = 0.96227686089592 
2016-12-12 03:55:35 Test Loss = 0.015755120775606 
2016-12-12 03:55:35 -------------------LR------------------- 
2016-12-12 03:55:35 0.001953125 
2016-12-12 03:55:35 Epoch 166 
2016-12-12 04:01:13 Training Error = 0.90292918365649 
2016-12-12 04:01:13 Training Loss = 0.01522051980454 
2016-12-12 04:01:19 Valid Error = 0.95544739797829 
2016-12-12 04:01:19 Valid Loss = 0.015689981649361 
2016-12-12 04:01:26 Test Error = 0.96463455708993 
2016-12-12 04:01:26 Test Loss = 0.015741860566749 
2016-12-12 04:01:26 -------------------LR------------------- 
2016-12-12 04:01:26 0.001953125 
2016-12-12 04:01:26 Epoch 167 
2016-12-12 04:07:13 Training Error = 0.90247149871016 
2016-12-12 04:07:13 Training Loss = 0.015220302308282 
2016-12-12 04:07:19 Valid Error = 0.95207787345563 
2016-12-12 04:07:19 Valid Loss = 0.015662681266429 
2016-12-12 04:07:26 Test Error = 0.96227686089592 
2016-12-12 04:07:26 Test Loss = 0.015719336562479 
2016-12-12 04:07:26 -------------------LR------------------- 
2016-12-12 04:07:26 0.001953125 
2016-12-12 04:07:26 Epoch 168 
2016-12-12 04:13:13 Training Error = 0.90130648248315 
2016-12-12 04:13:13 Training Loss = 0.015219085927776 
2016-12-12 04:13:19 Valid Error = 0.9502059153875 
2016-12-12 04:13:19 Valid Loss = 0.015675294196108 
2016-12-12 04:13:26 Test Error = 0.95756146850792 
2016-12-12 04:13:26 Test Loss = 0.015736875097591 
2016-12-12 04:13:26 -------------------LR------------------- 
2016-12-12 04:13:26 0.001953125 
2016-12-12 04:13:26 Epoch 169 
2016-12-12 04:19:03 Training Error = 0.90201381376383 
2016-12-12 04:19:03 Training Loss = 0.015218384014278 
2016-12-12 04:19:10 Valid Error = 0.95544739797829 
2016-12-12 04:19:10 Valid Loss = 0.015723315808882 
2016-12-12 04:19:17 Test Error = 0.96463455708993 
2016-12-12 04:19:17 Test Loss = 0.015758458059083 
2016-12-12 04:19:17 -------------------LR------------------- 
2016-12-12 04:19:17 0.001953125 
2016-12-12 04:19:17 Epoch 170 
2016-12-12 04:25:04 Training Error = 0.90317882999085 
2016-12-12 04:25:04 Training Loss = 0.01522703646064 
2016-12-12 04:25:11 Valid Error = 0.95207787345563 
2016-12-12 04:25:11 Valid Loss = 0.015669179654862 
2016-12-12 04:25:18 Test Error = 0.96227686089592 
2016-12-12 04:25:18 Test Loss = 0.015737212158851 
2016-12-12 04:25:18 -------------------LR------------------- 
2016-12-12 04:25:18 0.001953125 
2016-12-12 04:25:18 Epoch 171 
2016-12-12 04:31:06 Training Error = 0.90334526088042 
2016-12-12 04:31:06 Training Loss = 0.015222957664302 
2016-12-12 04:31:12 Valid Error = 0.95207787345563 
2016-12-12 04:31:12 Valid Loss = 0.015670755474007 
2016-12-12 04:31:19 Test Error = 0.96227686089592 
2016-12-12 04:31:19 Test Loss = 0.015724612250712 
2016-12-12 04:31:19 -------------------LR------------------- 
2016-12-12 04:31:19 0.001953125 
2016-12-12 04:31:19 Epoch 172 
2016-12-12 04:36:58 Training Error = 0.90330365315803 
2016-12-12 04:36:58 Training Loss = 0.015219616222381 
2016-12-12 04:37:05 Valid Error = 0.95320104829652 
2016-12-12 04:37:05 Valid Loss = 0.015669951420868 
2016-12-12 04:37:12 Test Error = 0.96362411586393 
2016-12-12 04:37:12 Test Loss = 0.015727797261966 
2016-12-12 04:37:12 -------------------LR------------------- 
2016-12-12 04:37:12 0.001953125 
2016-12-12 04:37:12 Epoch 173 
2016-12-12 04:43:02 Training Error = 0.90434384621786 
2016-12-12 04:43:02 Training Loss = 0.015226641777321 
2016-12-12 04:43:08 Valid Error = 0.95544739797829 
2016-12-12 04:43:08 Valid Loss = 0.015772447256141 
2016-12-12 04:43:15 Test Error = 0.96463455708993 
2016-12-12 04:43:15 Test Loss = 0.01580646191693 
2016-12-12 04:43:15 -------------------LR------------------- 
2016-12-12 04:43:15 0.001953125 
2016-12-12 04:43:15 Epoch 174 
2016-12-12 04:49:02 Training Error = 0.90371973038196 
2016-12-12 04:49:02 Training Loss = 0.015226467473367 
2016-12-12 04:49:08 Valid Error = 0.95207787345563 
2016-12-12 04:49:08 Valid Loss = 0.015669577613545 
2016-12-12 04:49:15 Test Error = 0.96227686089592 
2016-12-12 04:49:15 Test Loss = 0.015722981127932 
2016-12-12 04:49:15 -------------------LR------------------- 
2016-12-12 04:49:15 0.001953125 
2016-12-12 04:49:15 Epoch 175 
2016-12-12 04:54:52 Training Error = 0.90446866938504 
2016-12-12 04:54:52 Training Loss = 0.015220294871789 
2016-12-12 04:54:58 Valid Error = 0.95544739797829 
2016-12-12 04:54:58 Valid Loss = 0.015705385543238 
2016-12-12 04:55:05 Test Error = 0.96463455708993 
2016-12-12 04:55:05 Test Loss = 0.015753137658565 
2016-12-12 04:55:05 -------------------LR------------------- 
2016-12-12 04:55:05 0.001953125 
2016-12-12 04:55:05 Epoch 176 
2016-12-12 05:00:50 Training Error = 0.90309561454606 
2016-12-12 05:00:50 Training Loss = 0.015219637544536 
2016-12-12 05:00:56 Valid Error = 0.95544739797829 
2016-12-12 05:00:56 Valid Loss = 0.015660320963202 
2016-12-12 05:01:03 Test Error = 0.96463455708993 
2016-12-12 05:01:03 Test Loss = 0.015719078108049 
2016-12-12 05:01:03 -------------------LR------------------- 
2016-12-12 05:01:03 0.001953125 
2016-12-12 05:01:03 Epoch 177 
2016-12-12 05:06:45 Training Error = 0.90280436048931 
2016-12-12 05:06:45 Training Loss = 0.015216885640583 
2016-12-12 05:06:52 Valid Error = 0.95731935604642 
2016-12-12 05:06:52 Valid Loss = 0.015676089870625 
2016-12-12 05:06:59 Test Error = 0.96934994947794 
2016-12-12 05:06:59 Test Loss = 0.015738187217008 
2016-12-12 05:06:59 -------------------LR------------------- 
2016-12-12 05:06:59 0.001953125 
2016-12-12 05:06:59 Epoch 178 
2016-12-12 05:12:28 Training Error = 0.90317882999085 
2016-12-12 05:12:28 Training Loss = 0.015217624522433 
2016-12-12 05:12:34 Valid Error = 0.9502059153875 
2016-12-12 05:12:34 Valid Loss = 0.015688048487971 
2016-12-12 05:12:41 Test Error = 0.95756146850792 
2016-12-12 05:12:41 Test Loss = 0.015729213367783 
2016-12-12 05:12:41 -------------------LR------------------- 
2016-12-12 05:12:41 0.001953125 
2016-12-12 05:12:41 Epoch 179 
2016-12-12 05:17:55 Training Error = 0.90251310643255 
2016-12-12 05:17:55 Training Loss = 0.015222881195895 
2016-12-12 05:18:02 Valid Error = 0.95731935604642 
2016-12-12 05:18:02 Valid Loss = 0.015670869971658 
2016-12-12 05:18:09 Test Error = 0.96934994947794 
2016-12-12 05:18:09 Test Loss = 0.015726749716106 
2016-12-12 05:18:09 -------------------LR------------------- 
2016-12-12 05:18:09 0.001953125 
2016-12-12 05:18:09 Epoch 180 
2016-12-12 05:23:31 Training Error = 0.90317882999085 
2016-12-12 05:23:31 Training Loss = 0.015224495189859 
2016-12-12 05:23:37 Valid Error = 0.95207787345563 
2016-12-12 05:23:37 Valid Loss = 0.01567965401048 
2016-12-12 05:23:44 Test Error = 0.96227686089592 
2016-12-12 05:23:44 Test Loss = 0.015737070651758 
2016-12-12 05:23:44 -------------------LR------------------- 
2016-12-12 05:23:44 0.001953125 
2016-12-12 05:23:44 Epoch 181 
2016-12-12 05:28:50 Training Error = 0.90242989098777 
2016-12-12 05:28:50 Training Loss = 0.015217932816179 
2016-12-12 05:28:56 Valid Error = 0.95207787345563 
2016-12-12 05:28:56 Valid Loss = 0.015658588887514 
2016-12-12 05:29:03 Test Error = 0.96227686089592 
2016-12-12 05:29:03 Test Loss = 0.015711831734128 
2016-12-12 05:29:03 -------------------LR------------------- 
2016-12-12 05:29:03 0.001953125 
2016-12-12 05:29:03 Epoch 182 
2016-12-12 05:34:22 Training Error = 0.90242989098777 
2016-12-12 05:34:22 Training Loss = 0.01522466383363 
2016-12-12 05:34:28 Valid Error = 0.95544739797829 
2016-12-12 05:34:28 Valid Loss = 0.01576648287585 
2016-12-12 05:34:35 Test Error = 0.96463455708993 
2016-12-12 05:34:35 Test Loss = 0.015803759053346 
2016-12-12 05:34:35 -------------------LR------------------- 
2016-12-12 05:34:35 0.001953125 
2016-12-12 05:34:35 Epoch 183 
2016-12-12 05:39:54 Training Error = 0.90413580760589 
2016-12-12 05:39:54 Training Loss = 0.01521674265327 
2016-12-12 05:40:01 Valid Error = 0.95207787345563 
2016-12-12 05:40:01 Valid Loss = 0.015649434029855 
2016-12-12 05:40:08 Test Error = 0.96227686089592 
2016-12-12 05:40:08 Test Loss = 0.015700074488098 
2016-12-12 05:40:08 -------------------LR------------------- 
2016-12-12 05:40:08 0.001953125 
2016-12-12 05:40:08 Epoch 184 
2016-12-12 05:45:11 Training Error = 0.90338686860281 
2016-12-12 05:45:11 Training Loss = 0.01522528640642 
2016-12-12 05:45:18 Valid Error = 0.95731935604642 
2016-12-12 05:45:18 Valid Loss = 0.015669407716846 
2016-12-12 05:45:25 Test Error = 0.96934994947794 
2016-12-12 05:45:25 Test Loss = 0.015729143272458 
2016-12-12 05:45:25 -------------------LR------------------- 
2016-12-12 05:45:25 0.001953125 
2016-12-12 05:45:25 Epoch 185 
2016-12-12 05:50:43 Training Error = 0.90326204543563 
2016-12-12 05:50:43 Training Loss = 0.015225625202992 
2016-12-12 05:50:49 Valid Error = 0.95320104829652 
2016-12-12 05:50:49 Valid Loss = 0.01565645206709 
2016-12-12 05:50:56 Test Error = 0.96362411586393 
2016-12-12 05:50:56 Test Loss = 0.015709889363271 
2016-12-12 05:50:56 -------------------LR------------------- 
2016-12-12 05:50:56 0.001953125 
2016-12-12 05:50:56 Epoch 186 
2016-12-12 05:56:13 Training Error = 0.90317882999085 
2016-12-12 05:56:13 Training Loss = 0.015222579662705 
2016-12-12 05:56:19 Valid Error = 0.94608760763759 
2016-12-12 05:56:19 Valid Loss = 0.015688734820864 
2016-12-12 05:56:26 Test Error = 0.9518356348939 
2016-12-12 05:56:26 Test Loss = 0.015755169984153 
2016-12-12 05:56:26 -------------------LR------------------- 
2016-12-12 05:56:26 0.001953125 
2016-12-12 05:56:26 Epoch 187 
2016-12-12 06:01:41 Training Error = 0.90388616127153 
2016-12-12 06:01:41 Training Loss = 0.015220580697731 
2016-12-12 06:01:48 Valid Error = 0.95544739797829 
2016-12-12 06:01:48 Valid Loss = 0.015666344505773 
2016-12-12 06:01:55 Test Error = 0.96463455708993 
2016-12-12 06:01:55 Test Loss = 0.015718732175676 
2016-12-12 06:01:55 -------------------LR------------------- 
2016-12-12 06:01:55 0.001953125 
2016-12-12 06:01:55 Epoch 188 
2016-12-12 06:07:08 Training Error = 0.90380294582675 
2016-12-12 06:07:08 Training Loss = 0.015223238863833 
2016-12-12 06:07:14 Valid Error = 0.95544739797829 
2016-12-12 06:07:14 Valid Loss = 0.015668233683294 
2016-12-12 06:07:21 Test Error = 0.96463455708993 
2016-12-12 06:07:21 Test Loss = 0.015723815482045 
2016-12-12 06:07:21 -------------------LR------------------- 
2016-12-12 06:07:21 0.001953125 
2016-12-12 06:07:21 Epoch 189 
