2016-12-09 22:30:24 [program started on Fri Dec  9 22:30:24 2016] 
2016-12-09 22:30:24 [command line arguments] 
2016-12-09 22:30:24 stcWeights false 
2016-12-09 22:30:24 LR 0.015625 
2016-12-09 22:30:24 batchSize 64 
2016-12-09 22:30:24 network ./Models/Cifar10_Custom 
2016-12-09 22:30:24 stcNeurons true 
2016-12-09 22:30:24 constBatchSize false 
2016-12-09 22:30:24 chartFileName chart1 
2016-12-09 22:30:24 dp_prepro false 
2016-12-09 22:30:24 nGPU 1 
2016-12-09 22:30:24 dataset Caltech256 
2016-12-09 22:30:24 type cuda 
2016-12-09 22:30:24 momentum 0 
2016-12-09 22:30:24 threads 8 
2016-12-09 22:30:24 weightDecay 0 
2016-12-09 22:30:24 runningVal false 
2016-12-09 22:30:24 convLayerN 6 
2016-12-09 22:30:24 LRDecay 0 
2016-12-09 22:30:24 numHid 1024 
2016-12-09 22:30:24 save /dev/shm/clone/temp/th/Results/Caltech256/model6-10 
2016-12-09 22:30:24 augment false 
2016-12-09 22:30:24 epoch -1 
2016-12-09 22:30:24 modelsFolder ./Models/ 
2016-12-09 22:30:24 format rgb 
2016-12-09 22:30:24 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 22:30:24 imageFileExtension svg 
2016-12-09 22:30:24 channel 1 
2016-12-09 22:30:24 devid 1 
2016-12-09 22:30:24 visualize 1 
2016-12-09 22:30:24 LRDecayPerEpoch 0.0001 
2016-12-09 22:30:24 optimization adam 
2016-12-09 22:30:24 SBN true 
2016-12-09 22:30:24 normalization simple 
2016-12-09 22:30:24 title model1 
2016-12-09 22:30:24 load  
2016-12-09 22:30:24 whiten true 
2016-12-09 22:30:24 [----------------------] 
2016-12-09 22:30:25 ==> Network 
2016-12-09 22:30:25 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-09 22:30:25 ==>14285181 Parameters 
2016-12-09 22:30:25 ==> Loss 
2016-12-09 22:30:25 SqrtHingeEmbeddingCriterion 
2016-12-09 22:30:25 
==> Starting Training
 
2016-12-09 22:30:25 Epoch 1 
2016-12-09 22:33:46 Training Error = 0.97873845385704 
2016-12-09 22:33:46 Training Loss = 0.11245769431961 
2016-12-09 22:33:52 Valid Error = 0.93223511793336 
2016-12-09 22:33:52 Valid Loss = 0.015538990953472 
2016-12-09 22:33:58 Test Error = 0.94543617379589 
2016-12-09 22:33:58 Test Loss = 0.015563903436991 
2016-12-09 22:33:58 -------------------LR------------------- 
2016-12-09 22:33:58 0.015625 
2016-12-09 22:33:58 Epoch 2 
2016-12-09 22:37:30 Training Error = 0.94744944661729 
2016-12-09 22:37:30 Training Loss = 0.015830855799288 
2016-12-09 22:37:35 Valid Error = 0.93934855859229 
2016-12-09 22:37:35 Valid Loss = 0.015518421897242 
2016-12-09 22:37:42 Test Error = 0.9514988211519 
2016-12-09 22:37:42 Test Loss = 0.015538717994801 
2016-12-09 22:37:42 -------------------LR------------------- 
2016-12-09 22:37:42 0.015625 
2016-12-09 22:37:42 Epoch 3 
2016-12-09 22:41:12 Training Error = 0.93330282100358 
2016-12-09 22:41:12 Training Loss = 0.01553221349687 
2016-12-09 22:41:18 Valid Error = 0.9341070760015 
2016-12-09 22:41:18 Valid Loss = 0.015488798490385 
2016-12-09 22:41:24 Test Error = 0.9484674974739 
2016-12-09 22:41:24 Test Loss = 0.015516116210307 
2016-12-09 22:41:24 -------------------LR------------------- 
2016-12-09 22:41:24 0.015625 
2016-12-09 22:41:25 Epoch 4 
2016-12-09 22:45:15 Training Error = 0.91416326870267 
2016-12-09 22:45:15 Training Loss = 0.015349054486624 
2016-12-09 22:45:21 Valid Error = 0.96593036315987 
2016-12-09 22:45:21 Valid Loss = 0.015719223734349 
2016-12-09 22:45:27 Test Error = 0.96833950825194 
2016-12-09 22:45:27 Test Loss = 0.015704006774355 
2016-12-09 22:45:27 -------------------LR------------------- 
2016-12-09 22:45:27 0.015625 
2016-12-09 22:45:27 Epoch 5 
2016-12-09 22:49:21 Training Error = 0.89152866772073 
2016-12-09 22:49:21 Training Loss = 0.01503737635307 
2016-12-09 22:49:26 Valid Error = 0.98202920254586 
2016-12-09 22:49:26 Valid Loss = 0.015871181592144 
2016-12-09 22:49:33 Test Error = 0.98113843044796 
2016-12-09 22:49:33 Test Loss = 0.015868420899685 
2016-12-09 22:49:33 -------------------LR------------------- 
2016-12-09 22:49:33 0.015625 
2016-12-09 22:49:33 Epoch 6 
2016-12-09 22:53:30 Training Error = 0.85982358325705 
2016-12-09 22:53:30 Training Loss = 0.014711560928069 
2016-12-09 22:53:36 Valid Error = 0.91576188693373 
2016-12-09 22:53:36 Valid Loss = 0.015570009213929 
2016-12-09 22:53:43 Test Error = 0.90266082856181 
2016-12-09 22:53:43 Test Loss = 0.015544014092431 
2016-12-09 22:53:43 -------------------LR------------------- 
2016-12-09 22:53:43 0.015625 
2016-12-09 22:53:43 Epoch 7 
2016-12-09 22:57:54 Training Error = 0.81234917200632 
2016-12-09 22:57:54 Training Loss = 0.014387909859926 
2016-12-09 22:58:00 Valid Error = 0.83901160614002 
2016-12-09 22:58:00 Valid Loss = 0.014685483312456 
2016-12-09 22:58:07 Test Error = 0.83091950151566 
2016-12-09 22:58:07 Test Loss = 0.014766229487878 
2016-12-09 22:58:07 -------------------LR------------------- 
2016-12-09 22:58:07 0.015625 
2016-12-09 22:58:07 Epoch 8 
2016-12-09 23:02:45 Training Error = 0.75784305567113 
2016-12-09 23:02:45 Training Loss = 0.013985104424116 
2016-12-09 23:02:51 Valid Error = 0.72257581430176 
2016-12-09 23:02:51 Valid Loss = 0.013706723704517 
2016-12-09 23:02:57 Test Error = 0.71438194678343 
2016-12-09 23:02:57 Test Loss = 0.013693831854778 
2016-12-09 23:02:57 -------------------LR------------------- 
2016-12-09 23:02:57 0.015625 
2016-12-09 23:02:57 Epoch 9 
2016-12-09 23:07:54 Training Error = 0.69297661646001 
2016-12-09 23:07:54 Training Loss = 0.013676907128973 
2016-12-09 23:08:01 Valid Error = 0.70535380007488 
2016-12-09 23:08:01 Valid Loss = 0.01571671348326 
2016-12-09 23:08:07 Test Error = 0.68507915122937 
2016-12-09 23:08:07 Test Loss = 0.015395929776583 
2016-12-09 23:08:07 -------------------LR------------------- 
2016-12-09 23:08:07 0.015625 
2016-12-09 23:08:07 Epoch 10 
2016-12-09 23:14:44 Training Error = 0.63185487226429 
2016-12-09 23:14:44 Training Loss = 0.013402721806916 
2016-12-09 23:14:50 Valid Error = 0.63122426057656 
2016-12-09 23:14:50 Valid Loss = 0.013656438883537 
2016-12-09 23:14:57 Test Error = 0.63051532502526 
2016-12-09 23:14:57 Test Loss = 0.01364939602425 
2016-12-09 23:14:57 -------------------LR------------------- 
2016-12-09 23:14:57 0.015625 
2016-12-09 23:14:57 Epoch 11 
2016-12-09 23:22:05 Training Error = 0.60006657235583 
2016-12-09 23:22:05 Training Loss = 0.013343876641514 
2016-12-09 23:22:11 Valid Error = 0.59153874953201 
2016-12-09 23:22:11 Valid Loss = 0.013115724680437 
2016-12-09 23:22:18 Test Error = 0.59616032334119 
2016-12-09 23:22:18 Test Loss = 0.013115567783042 
2016-12-09 23:22:18 -------------------LR------------------- 
2016-12-09 23:22:18 0.015625 
2016-12-09 23:22:18 Epoch 12 
2016-12-09 23:29:20 Training Error = 0.59773653990181 
2016-12-09 23:29:20 Training Loss = 0.013356819844468 
2016-12-09 23:29:26 Valid Error = 0.59827779857731 
2016-12-09 23:29:26 Valid Loss = 0.013062584265899 
2016-12-09 23:29:33 Test Error = 0.59683395082519 
2016-12-09 23:29:33 Test Loss = 0.013067728157187 
2016-12-09 23:29:33 -------------------LR------------------- 
2016-12-09 23:29:33 0.015625 
2016-12-09 23:29:33 Epoch 13 
2016-12-09 23:36:39 Training Error = 0.59661313139719 
2016-12-09 23:36:39 Training Loss = 0.013336834461927 
2016-12-09 23:36:44 Valid Error = 0.62149007862224 
2016-12-09 23:36:44 Valid Loss = 0.013021615928572 
2016-12-09 23:36:51 Test Error = 0.62041091276524 
2016-12-09 23:36:51 Test Loss = 0.013020159272189 
2016-12-09 23:36:51 -------------------LR------------------- 
2016-12-09 23:36:51 0.015625 
2016-12-09 23:36:51 Epoch 14 
2016-12-09 23:43:53 Training Error = 0.59682117000915 
2016-12-09 23:43:53 Training Loss = 0.013336345926613 
2016-12-09 23:43:59 Valid Error = 0.60688880569075 
2016-12-09 23:43:59 Valid Loss = 0.013033831968546 
2016-12-09 23:44:06 Test Error = 0.60255978443921 
2016-12-09 23:44:06 Test Loss = 0.013041039898538 
2016-12-09 23:44:06 -------------------LR------------------- 
2016-12-09 23:44:06 0.015625 
2016-12-09 23:44:06 Epoch 15 
2016-12-09 23:51:11 Training Error = 0.60193891986353 
2016-12-09 23:51:11 Training Loss = 0.013342621024598 
2016-12-09 23:51:17 Valid Error = 0.59640584050917 
2016-12-09 23:51:17 Valid Loss = 0.013000139531379 
2016-12-09 23:51:23 Test Error = 0.59717076456719 
2016-12-09 23:51:23 Test Loss = 0.012992284239259 
2016-12-09 23:51:23 -------------------LR------------------- 
2016-12-09 23:51:23 0.015625 
2016-12-09 23:51:24 Epoch 16 
2016-12-09 23:59:01 Training Error = 0.59944245651993 
2016-12-09 23:59:01 Training Loss = 0.013352979440075 
2016-12-09 23:59:07 Valid Error = 0.59378509921378 
2016-12-09 23:59:07 Valid Loss = 0.013113688027724 
2016-12-09 23:59:13 Test Error = 0.5988548332772 
2016-12-09 23:59:13 Test Loss = 0.013114610431689 
2016-12-09 23:59:13 -------------------LR------------------- 
2016-12-09 23:59:13 0.015625 
2016-12-09 23:59:13 Epoch 17 
2016-12-10 00:06:36 Training Error = 0.59690438545394 
2016-12-10 00:06:36 Training Loss = 0.013346727123178 
2016-12-10 00:06:42 Valid Error = 0.5967802321228 
2016-12-10 00:06:42 Valid Loss = 0.013056500848443 
2016-12-10 00:06:48 Test Error = 0.58942404850118 
2016-12-10 00:06:48 Test Loss = 0.013051346351168 
2016-12-10 00:06:48 -------------------LR------------------- 
2016-12-10 00:06:48 0.015625 
2016-12-10 00:06:48 Epoch 18 
2016-12-10 00:13:27 Training Error = 0.60227178164267 
2016-12-10 00:13:27 Training Loss = 0.013361690200271 
2016-12-10 00:13:33 Valid Error = 0.60202171471359 
2016-12-10 00:13:33 Valid Loss = 0.013015129762424 
2016-12-10 00:13:39 Test Error = 0.5978443920512 
2016-12-10 00:13:39 Test Loss = 0.013008784261902 
2016-12-10 00:13:39 -------------------LR------------------- 
2016-12-10 00:13:39 0.015625 
2016-12-10 00:13:39 Epoch 19 
2016-12-10 00:20:18 Training Error = 0.59752850128984 
2016-12-10 00:20:18 Training Loss = 0.013332278527097 
2016-12-10 00:20:24 Valid Error = 0.59378509921378 
2016-12-10 00:20:24 Valid Loss = 0.012986066611993 
2016-12-10 00:20:30 Test Error = 0.59178174469518 
2016-12-10 00:20:30 Test Loss = 0.012997373581728 
2016-12-10 00:20:30 -------------------LR------------------- 
2016-12-10 00:20:30 0.015625 
2016-12-10 00:20:30 Epoch 20 
2016-12-10 00:27:12 Training Error = 0.60123158858284 
2016-12-10 00:27:12 Training Loss = 0.013351962035786 
2016-12-10 00:27:18 Valid Error = 0.58442530887308 
2016-12-10 00:27:18 Valid Loss = 0.013025550799941 
2016-12-10 00:27:25 Test Error = 0.58302458740317 
2016-12-10 00:27:25 Test Loss = 0.013019034955021 
2016-12-10 00:27:25 -------------------LR------------------- 
2016-12-10 00:27:25 0.015625 
2016-12-10 00:27:25 Epoch 21 
2016-12-10 00:34:05 Training Error = 0.60127319630523 
2016-12-10 00:34:05 Training Loss = 0.013354835282741 
2016-12-10 00:34:11 Valid Error = 0.57843504305504 
2016-12-10 00:34:11 Valid Loss = 0.013012037235162 
2016-12-10 00:34:18 Test Error = 0.57965644998316 
2016-12-10 00:34:18 Test Loss = 0.01300312610144 
2016-12-10 00:34:18 -------------------LR------------------- 
2016-12-10 00:34:18 0.015625 
2016-12-10 00:34:18 Epoch 22 
2016-12-10 00:41:01 Training Error = 0.5989847715736 
2016-12-10 00:41:01 Training Loss = 0.013331102541015 
2016-12-10 00:41:07 Valid Error = 0.57880943466866 
2016-12-10 00:41:07 Valid Loss = 0.013015480815629 
2016-12-10 00:41:14 Test Error = 0.58706635230717 
2016-12-10 00:41:14 Test Loss = 0.01302812491072 
2016-12-10 00:41:14 -------------------LR------------------- 
2016-12-10 00:41:14 0.015625 
2016-12-10 00:41:14 Epoch 23 
2016-12-10 00:47:53 Training Error = 0.59923441790796 
2016-12-10 00:47:53 Training Loss = 0.013343856864281 
2016-12-10 00:47:59 Valid Error = 0.5874204417821 
2016-12-10 00:47:59 Valid Loss = 0.013027858953902 
2016-12-10 00:48:06 Test Error = 0.59245537217918 
2016-12-10 00:48:06 Test Loss = 0.013041895238171 
2016-12-10 00:48:06 -------------------LR------------------- 
2016-12-10 00:48:06 0.015625 
2016-12-10 00:48:06 Epoch 24 
2016-12-10 00:54:45 Training Error = 0.6002746109678 
2016-12-10 00:54:45 Training Loss = 0.013349219043169 
2016-12-10 00:54:51 Valid Error = 0.60651441407712 
2016-12-10 00:54:51 Valid Loss = 0.013101763754363 
2016-12-10 00:54:58 Test Error = 0.60996968676322 
2016-12-10 00:54:58 Test Loss = 0.013093719474465 
2016-12-10 00:54:58 -------------------LR------------------- 
2016-12-10 00:54:58 0.015625 
2016-12-10 00:54:58 Epoch 25 
2016-12-10 01:01:34 Training Error = 0.59944245651993 
2016-12-10 01:01:34 Training Loss = 0.013346278941126 
2016-12-10 01:01:40 Valid Error = 0.58405091725945 
2016-12-10 01:01:40 Valid Loss = 0.012999385628122 
2016-12-10 01:01:46 Test Error = 0.59077130346918 
2016-12-10 01:01:46 Test Loss = 0.013020306104613 
2016-12-10 01:01:46 -------------------LR------------------- 
2016-12-10 01:01:46 0.015625 
2016-12-10 01:01:46 Epoch 26 
2016-12-10 01:07:43 Training Error = 0.60006657235583 
2016-12-10 01:07:43 Training Loss = 0.013346026187827 
2016-12-10 01:07:49 Valid Error = 0.5967802321228 
2016-12-10 01:07:49 Valid Loss = 0.013037247254894 
2016-12-10 01:07:56 Test Error = 0.60323341192321 
2016-12-10 01:07:56 Test Loss = 0.013028568724567 
2016-12-10 01:07:56 -------------------LR------------------- 
2016-12-10 01:07:56 0.015625 
2016-12-10 01:07:56 Epoch 27 
2016-12-10 01:13:53 Training Error = 0.59873512523924 
2016-12-10 01:13:53 Training Loss = 0.013335850587134 
2016-12-10 01:13:59 Valid Error = 0.59752901535006 
2016-12-10 01:13:59 Valid Loss = 0.013021018478241 
2016-12-10 01:14:05 Test Error = 0.59548669585719 
2016-12-10 01:14:05 Test Loss = 0.013028086393736 
2016-12-10 01:14:05 -------------------LR------------------- 
2016-12-10 01:14:05 0.015625 
2016-12-10 01:14:05 Epoch 28 
2016-12-10 01:20:00 Training Error = 0.59856869434967 
2016-12-10 01:20:00 Training Loss = 0.013346599811261 
2016-12-10 01:20:06 Valid Error = 0.58966679146387 
2016-12-10 01:20:06 Valid Loss = 0.012963052939527 
2016-12-10 01:20:12 Test Error = 0.58942404850118 
2016-12-10 01:20:12 Test Loss = 0.012967273749557 
2016-12-10 01:20:12 -------------------LR------------------- 
2016-12-10 01:20:12 0.015625 
2016-12-10 01:20:12 Epoch 29 
2016-12-10 01:26:06 Training Error = 0.60127319630523 
2016-12-10 01:26:06 Training Loss = 0.013352681061263 
2016-12-10 01:26:12 Valid Error = 0.58704605016848 
2016-12-10 01:26:12 Valid Loss = 0.013036423465347 
2016-12-10 01:26:19 Test Error = 0.59110811721118 
2016-12-10 01:26:19 Test Loss = 0.013060590233164 
2016-12-10 01:26:19 -------------------LR------------------- 
2016-12-10 01:26:19 0.015625 
2016-12-10 01:26:19 Epoch 30 
2016-12-10 01:32:40 Training Error = 0.59623866189565 
2016-12-10 01:32:40 Training Loss = 0.013328717906898 
2016-12-10 01:32:46 Valid Error = 0.59191314114564 
2016-12-10 01:32:46 Valid Loss = 0.013046117453372 
2016-12-10 01:32:53 Test Error = 0.59312899966319 
2016-12-10 01:32:53 Test Loss = 0.013028643132649 
2016-12-10 01:32:53 -------------------LR------------------- 
2016-12-10 01:32:53 0.015625 
2016-12-10 01:32:53 Epoch 31 
2016-12-10 01:38:52 Training Error = 0.60060747274694 
2016-12-10 01:38:52 Training Loss = 0.01334154830043 
2016-12-10 01:38:57 Valid Error = 0.6357169599401 
2016-12-10 01:38:57 Valid Loss = 0.013131485604026 
2016-12-10 01:39:04 Test Error = 0.63523071741327 
2016-12-10 01:39:04 Test Loss = 0.013130343151132 
2016-12-10 01:39:04 -------------------LR------------------- 
2016-12-10 01:39:04 0.015625 
2016-12-10 01:39:04 Epoch 32 
2016-12-10 01:44:45 Training Error = 0.59869351751685 
2016-12-10 01:44:45 Training Loss = 0.013340418304372 
2016-12-10 01:44:51 Valid Error = 0.59528266566829 
2016-12-10 01:44:51 Valid Loss = 0.013077993175257 
2016-12-10 01:44:58 Test Error = 0.5978443920512 
2016-12-10 01:44:58 Test Loss = 0.013072399213407 
2016-12-10 01:44:58 -------------------LR------------------- 
2016-12-10 01:44:58 0.015625 
2016-12-10 01:44:58 Epoch 33 
2016-12-10 01:50:44 Training Error = 0.59940084879754 
2016-12-10 01:50:44 Training Loss = 0.013356144264896 
2016-12-10 01:50:50 Valid Error = 0.59977536503182 
2016-12-10 01:50:50 Valid Loss = 0.013012923368678 
2016-12-10 01:50:56 Test Error = 0.59683395082519 
2016-12-10 01:50:56 Test Loss = 0.013026288322573 
2016-12-10 01:50:56 -------------------LR------------------- 
2016-12-10 01:50:56 0.015625 
2016-12-10 01:50:56 Epoch 34 
2016-12-10 01:56:59 Training Error = 0.59927602563036 
2016-12-10 01:56:59 Training Loss = 0.013343329696603 
2016-12-10 01:57:05 Valid Error = 0.57469112691876 
2016-12-10 01:57:05 Valid Loss = 0.013000078731018 
2016-12-10 01:57:11 Test Error = 0.57797238127316 
2016-12-10 01:57:11 Test Loss = 0.013009148937093 
2016-12-10 01:57:11 -------------------LR------------------- 
2016-12-10 01:57:11 0.015625 
2016-12-10 01:57:11 Epoch 35 
2016-12-10 02:04:03 Training Error = 0.6021053507531 
2016-12-10 02:04:03 Training Loss = 0.013365073600615 
2016-12-10 02:04:09 Valid Error = 0.59790340696368 
2016-12-10 02:04:09 Valid Loss = 0.013091624759057 
2016-12-10 02:04:17 Test Error = 0.5985180195352 
2016-12-10 02:04:17 Test Loss = 0.013099235025405 
2016-12-10 02:04:17 -------------------LR------------------- 
2016-12-10 02:04:17 0.015625 
2016-12-10 02:04:17 Epoch 36 
2016-12-10 02:10:32 Training Error = 0.59915120246318 
2016-12-10 02:10:32 Training Loss = 0.013342413818556 
2016-12-10 02:10:38 Valid Error = 0.59116435791838 
2016-12-10 02:10:38 Valid Loss = 0.013075599568198 
2016-12-10 02:10:44 Test Error = 0.59683395082519 
2016-12-10 02:10:44 Test Loss = 0.013090445780684 
2016-12-10 02:10:44 -------------------LR------------------- 
2016-12-10 02:10:44 0.015625 
2016-12-10 02:10:44 Epoch 37 
2016-12-10 02:16:54 Training Error = 0.59952567196472 
2016-12-10 02:16:54 Training Loss = 0.013350197250774 
2016-12-10 02:17:00 Valid Error = 0.59715462373643 
2016-12-10 02:17:00 Valid Loss = 0.013034392945859 
2016-12-10 02:17:06 Test Error = 0.5978443920512 
2016-12-10 02:17:06 Test Loss = 0.013027864626462 
2016-12-10 02:17:06 -------------------LR------------------- 
2016-12-10 02:17:06 0.015625 
2016-12-10 02:17:07 Epoch 38 
