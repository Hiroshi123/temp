2016-12-10 01:33:47 [program started on Sat Dec 10 01:33:47 2016] 
2016-12-10 01:33:47 [command line arguments] 
2016-12-10 01:33:47 stcWeights false 
2016-12-10 01:33:47 LR 0.015625 
2016-12-10 01:33:47 batchSize 100 
2016-12-10 01:33:47 network ./Models/Cifar10_Custom 
2016-12-10 01:33:47 stcNeurons true 
2016-12-10 01:33:47 constBatchSize false 
2016-12-10 01:33:47 chartFileName chart1 
2016-12-10 01:33:47 dp_prepro false 
2016-12-10 01:33:47 nGPU 1 
2016-12-10 01:33:47 dataset Caltech256 
2016-12-10 01:33:47 type cuda 
2016-12-10 01:33:47 momentum 0 
2016-12-10 01:33:47 threads 8 
2016-12-10 01:33:47 weightDecay 0 
2016-12-10 01:33:47 runningVal false 
2016-12-10 01:33:47 convLayerN 6 
2016-12-10 01:33:47 LRDecay 0 
2016-12-10 01:33:47 numHid 1024 
2016-12-10 01:33:47 save /dev/shm/clone/temp/th/Results/Caltech256/model6-20 
2016-12-10 01:33:47 augment false 
2016-12-10 01:33:47 epoch -1 
2016-12-10 01:33:47 modelsFolder ./Models/ 
2016-12-10 01:33:47 format rgb 
2016-12-10 01:33:47 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 01:33:47 imageFileExtension svg 
2016-12-10 01:33:47 channel 2 
2016-12-10 01:33:47 devid 16 
2016-12-10 01:33:47 visualize 1 
2016-12-10 01:33:47 LRDecayPerEpoch 0.0001 
2016-12-10 01:33:47 optimization adam 
2016-12-10 01:33:47 SBN true 
2016-12-10 01:33:47 normalization simple 
2016-12-10 01:33:47 title model1 
2016-12-10 01:33:47 load  
2016-12-10 01:33:47 whiten true 
2016-12-10 01:33:47 [----------------------] 
2016-12-10 01:33:49 ==> Network 
2016-12-10 01:33:49 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 256, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(512 -> 1024, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(16384)
  (29): BinaryLinear(16384 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-10 01:33:49 ==>36396029 Parameters 
2016-12-10 01:33:49 ==> Loss 
2016-12-10 01:33:49 SqrtHingeEmbeddingCriterion 
2016-12-10 01:33:49 
==> Starting Training
 
2016-12-10 01:33:49 Epoch 1 
2016-12-10 01:43:11 Training Error = 0.98223350253807 
2016-12-10 01:43:11 Training Loss = 0.16853406150223 
2016-12-10 01:43:26 Valid Error = 0.93934855859229 
2016-12-10 01:43:26 Valid Loss = 0.015760758380386 
2016-12-10 01:43:44 Test Error = 0.9514988211519 
2016-12-10 01:43:44 Test Loss = 0.015813436874327 
2016-12-10 01:43:44 -------------------LR------------------- 
2016-12-10 01:43:44 0.015625 
2016-12-10 01:43:44 Epoch 2 
2016-12-10 01:53:05 Training Error = 0.96142964134143 
2016-12-10 01:53:05 Training Loss = 0.016182564037224 
2016-12-10 01:53:21 Valid Error = 0.93934855859229 
2016-12-10 01:53:21 Valid Loss = 0.01559411324555 
2016-12-10 01:53:38 Test Error = 0.9514988211519 
2016-12-10 01:53:38 Test Loss = 0.015612011843052 
2016-12-10 01:53:38 -------------------LR------------------- 
2016-12-10 01:53:38 0.015625 
2016-12-10 01:53:38 Epoch 3 
2016-12-10 02:03:29 Training Error = 0.94507780644088 
2016-12-10 02:03:29 Training Loss = 0.015742207803573 
2016-12-10 02:03:45 Valid Error = 0.93448146761513 
2016-12-10 02:03:45 Valid Loss = 0.015520301726843 
2016-12-10 02:04:02 Test Error = 0.94610980127989 
2016-12-10 02:04:02 Test Loss = 0.015540570078188 
2016-12-10 02:04:02 -------------------LR------------------- 
2016-12-10 02:04:02 0.015625 
2016-12-10 02:04:02 Epoch 4 
2016-12-10 02:13:41 Training Error = 0.93105600399434 
2016-12-10 02:13:41 Training Loss = 0.015562184310948 
2016-12-10 02:13:56 Valid Error = 0.9543242231374 
2016-12-10 02:13:56 Valid Loss = 0.015633647726536 
2016-12-10 02:14:13 Test Error = 0.95318288986191 
2016-12-10 02:14:13 Test Loss = 0.015624648698361 
2016-12-10 02:14:13 -------------------LR------------------- 
2016-12-10 02:14:13 0.015625 
2016-12-10 02:14:13 Epoch 5 
2016-12-10 02:23:44 Training Error = 0.92215195140218 
2016-12-10 02:23:44 Training Loss = 0.015317277105803 
2016-12-10 02:24:00 Valid Error = 0.98427555222763 
2016-12-10 02:24:00 Valid Loss = 0.015626884036477 
2016-12-10 02:24:17 Test Error = 0.98484338160997 
2016-12-10 02:24:17 Test Loss = 0.01560697177758 
2016-12-10 02:24:17 -------------------LR------------------- 
2016-12-10 02:24:17 0.015625 
2016-12-10 02:24:17 Epoch 6 
2016-12-10 02:33:48 Training Error = 0.9096280269618 
2016-12-10 02:33:48 Training Loss = 0.015075157618843 
2016-12-10 02:34:04 Valid Error = 0.97079745413703 
2016-12-10 02:34:04 Valid Loss = 0.015639599517354 
2016-12-10 02:34:21 Test Error = 0.96699225328393 
2016-12-10 02:34:21 Test Loss = 0.015662119511681 
2016-12-10 02:34:21 -------------------LR------------------- 
2016-12-10 02:34:21 0.015625 
2016-12-10 02:34:21 Epoch 7 
2016-12-10 02:43:52 Training Error = 0.89256886078056 
2016-12-10 02:43:52 Training Loss = 0.014939502391404 
2016-12-10 02:44:08 Valid Error = 0.97416697865968 
2016-12-10 02:44:08 Valid Loss = 0.016426126906123 
2016-12-10 02:44:25 Test Error = 0.97339171438195 
2016-12-10 02:44:25 Test Loss = 0.016503140157902 
2016-12-10 02:44:25 -------------------LR------------------- 
2016-12-10 02:44:25 0.015625 
2016-12-10 02:44:25 Epoch 8 
2016-12-10 02:53:56 Training Error = 0.86614795706083 
2016-12-10 02:53:56 Training Loss = 0.014749155480683 
2016-12-10 02:54:12 Valid Error = 0.96667914638712 
2016-12-10 02:54:12 Valid Loss = 0.016630252153013 
2016-12-10 02:54:29 Test Error = 0.96227686089592 
2016-12-10 02:54:29 Test Loss = 0.01662397599751 
2016-12-10 02:54:29 -------------------LR------------------- 
2016-12-10 02:54:29 0.015625 
2016-12-10 02:54:29 Epoch 9 
2016-12-10 03:03:50 Training Error = 0.83157193975202 
2016-12-10 03:03:50 Training Loss = 0.014447385226121 
2016-12-10 03:04:05 Valid Error = 0.9502059153875 
2016-12-10 03:04:05 Valid Loss = 0.016168732469506 
2016-12-10 03:04:22 Test Error = 0.94173122263388 
2016-12-10 03:04:22 Test Loss = 0.016130554292301 
2016-12-10 03:04:22 -------------------LR------------------- 
2016-12-10 03:04:22 0.015625 
2016-12-10 03:04:22 Epoch 10 
2016-12-10 03:13:49 Training Error = 0.78393109761172 
2016-12-10 03:13:49 Training Loss = 0.014102955630428 
2016-12-10 03:14:04 Valid Error = 0.84837139648072 
2016-12-10 03:14:04 Valid Loss = 0.015374423335858 
2016-12-10 03:14:21 Test Error = 0.8491074435837 
2016-12-10 03:14:21 Test Loss = 0.015343319702438 
2016-12-10 03:14:21 -------------------LR------------------- 
2016-12-10 03:14:21 0.015625 
2016-12-10 03:14:21 Epoch 11 
2016-12-10 03:23:37 Training Error = 0.75326620620787 
2016-12-10 03:23:37 Training Loss = 0.01387687830423 
2016-12-10 03:23:53 Valid Error = 0.85286409584425 
2016-12-10 03:23:53 Valid Loss = 0.015644692322331 
2016-12-10 03:24:10 Test Error = 0.85281239474571 
2016-12-10 03:24:10 Test Loss = 0.015623158662938 
2016-12-10 03:24:10 -------------------LR------------------- 
2016-12-10 03:24:10 0.015625 
2016-12-10 03:24:10 Epoch 12 
2016-12-10 03:33:28 Training Error = 0.75018723475077 
2016-12-10 03:33:28 Training Loss = 0.013865041044572 
2016-12-10 03:33:43 Valid Error = 0.88880569075253 
2016-12-10 03:33:43 Valid Loss = 0.015698845800455 
2016-12-10 03:34:01 Test Error = 0.87403166049175 
2016-12-10 03:34:01 Test Loss = 0.015686229884242 
2016-12-10 03:34:01 -------------------LR------------------- 
2016-12-10 03:34:01 0.015625 
2016-12-10 03:34:01 Epoch 13 
2016-12-10 03:43:17 Training Error = 0.75018723475077 
2016-12-10 03:43:17 Training Loss = 0.013860478949768 
2016-12-10 03:43:32 Valid Error = 0.8494945713216 
2016-12-10 03:43:32 Valid Loss = 0.015674261900564 
2016-12-10 03:43:50 Test Error = 0.8484338160997 
2016-12-10 03:43:50 Test Loss = 0.015667372294819 
2016-12-10 03:43:50 -------------------LR------------------- 
2016-12-10 03:43:50 0.015625 
2016-12-10 03:43:50 Epoch 14 
2016-12-10 03:53:12 Training Error = 0.75052009652992 
2016-12-10 03:53:12 Training Loss = 0.013867526842815 
2016-12-10 03:53:27 Valid Error = 0.88618494945713 
2016-12-10 03:53:27 Valid Loss = 0.015740342550445 
2016-12-10 03:53:44 Test Error = 0.86897945436174 
2016-12-10 03:53:44 Test Loss = 0.015784803204664 
2016-12-10 03:53:44 -------------------LR------------------- 
2016-12-10 03:53:44 0.015625 
2016-12-10 03:53:44 Epoch 15 
2016-12-10 04:02:47 Training Error = 0.75451443787967 
2016-12-10 04:02:47 Training Loss = 0.013874037604169 
2016-12-10 04:03:03 Valid Error = 0.89479595657057 
2016-12-10 04:03:03 Valid Loss = 0.015801334859038 
2016-12-10 04:03:20 Test Error = 0.88110474907376 
2016-12-10 04:03:20 Test Loss = 0.015854649246214 
2016-12-10 04:03:20 -------------------LR------------------- 
2016-12-10 04:03:20 0.015625 
2016-12-10 04:03:20 Epoch 16 
2016-12-10 04:12:22 Training Error = 0.75463926104685 
2016-12-10 04:12:22 Training Loss = 0.013880917662585 
2016-12-10 04:12:37 Valid Error = 0.88356420816174 
2016-12-10 04:12:37 Valid Loss = 0.015741855457188 
2016-12-10 04:12:54 Test Error = 0.87167396429774 
2016-12-10 04:12:54 Test Loss = 0.015711738078667 
2016-12-10 04:12:54 -------------------LR------------------- 
2016-12-10 04:12:54 0.015625 
2016-12-10 04:12:54 Epoch 17 
2016-12-10 04:21:58 Training Error = 0.75289173670633 
2016-12-10 04:21:58 Training Loss = 0.013874314676063 
2016-12-10 04:22:14 Valid Error = 0.88131785847997 
2016-12-10 04:22:14 Valid Loss = 0.01580364012281 
2016-12-10 04:22:31 Test Error = 0.86965308184574 
2016-12-10 04:22:31 Test Loss = 0.015787659763294 
2016-12-10 04:22:31 -------------------LR------------------- 
2016-12-10 04:22:31 0.015625 
2016-12-10 04:22:31 Epoch 18 
2016-12-10 04:31:29 Training Error = 0.75285012898394 
2016-12-10 04:31:29 Training Loss = 0.013873129417799 
2016-12-10 04:31:44 Valid Error = 0.88281542493448 
2016-12-10 04:31:44 Valid Loss = 0.01568191942819 
2016-12-10 04:32:02 Test Error = 0.87504210171775 
2016-12-10 04:32:02 Test Loss = 0.015684941187363 
2016-12-10 04:32:02 -------------------LR------------------- 
2016-12-10 04:32:02 0.015625 
2016-12-10 04:32:02 Epoch 19 
2016-12-10 04:41:02 Training Error = 0.75097778147624 
2016-12-10 04:41:02 Training Loss = 0.013856526313698 
2016-12-10 04:41:17 Valid Error = 0.88805690752527 
2016-12-10 04:41:17 Valid Loss = 0.015779956982635 
2016-12-10 04:41:34 Test Error = 0.87268440552375 
2016-12-10 04:41:34 Test Loss = 0.015793383509817 
2016-12-10 04:41:34 -------------------LR------------------- 
2016-12-10 04:41:34 0.015625 
2016-12-10 04:41:34 Epoch 20 
2016-12-10 04:50:43 Training Error = 0.75322459848548 
2016-12-10 04:50:43 Training Loss = 0.01387675112246 
2016-12-10 04:50:58 Valid Error = 0.87944590041183 
2016-12-10 04:50:58 Valid Loss = 0.015594245713446 
2016-12-10 04:51:16 Test Error = 0.87100033681374 
2016-12-10 04:51:16 Test Loss = 0.015576563593279 
2016-12-10 04:51:16 -------------------LR------------------- 
2016-12-10 04:51:16 0.015625 
2016-12-10 04:51:16 Epoch 21 
2016-12-10 05:00:18 Training Error = 0.75014562702838 
2016-12-10 05:00:18 Training Loss = 0.01387128595844 
2016-12-10 05:00:33 Valid Error = 0.88955447397978 
2016-12-10 05:00:33 Valid Loss = 0.015782067936769 
2016-12-10 05:00:50 Test Error = 0.87201077803974 
2016-12-10 05:00:50 Test Loss = 0.01576196078096 
2016-12-10 05:00:50 -------------------LR------------------- 
2016-12-10 05:00:50 0.015625 
2016-12-10 05:00:50 Epoch 22 
2016-12-10 05:09:51 Training Error = 0.75505533827078 
2016-12-10 05:09:51 Training Loss = 0.013871357085355 
2016-12-10 05:10:07 Valid Error = 0.88805690752527 
2016-12-10 05:10:07 Valid Loss = 0.015908718338207 
2016-12-10 05:10:24 Test Error = 0.87605254294375 
2016-12-10 05:10:24 Test Loss = 0.015935276377733 
2016-12-10 05:10:24 -------------------LR------------------- 
2016-12-10 05:10:24 0.015625 
2016-12-10 05:10:24 Epoch 23 
2016-12-10 05:19:23 Training Error = 0.75239244403761 
2016-12-10 05:19:23 Training Loss = 0.013871641551533 
2016-12-10 05:19:39 Valid Error = 0.88318981654811 
2016-12-10 05:19:39 Valid Loss = 0.015639737526466 
2016-12-10 05:19:56 Test Error = 0.87167396429774 
2016-12-10 05:19:56 Test Loss = 0.015605262946414 
2016-12-10 05:19:56 -------------------LR------------------- 
2016-12-10 05:19:56 0.015625 
2016-12-10 05:19:56 Epoch 24 
2016-12-10 05:28:54 Training Error = 0.75393192976616 
2016-12-10 05:28:54 Training Loss = 0.0138882438148 
2016-12-10 05:29:10 Valid Error = 0.88693373268439 
2016-12-10 05:29:10 Valid Loss = 0.015676095469899 
2016-12-10 05:29:27 Test Error = 0.87032670932974 
2016-12-10 05:29:27 Test Loss = 0.015713063784577 
2016-12-10 05:29:27 -------------------LR------------------- 
2016-12-10 05:29:27 0.015625 
2016-12-10 05:29:27 Epoch 25 
2016-12-10 05:38:29 Training Error = 0.7500208038612 
2016-12-10 05:38:29 Training Loss = 0.013861447176665 
2016-12-10 05:38:45 Valid Error = 0.88655934107076 
2016-12-10 05:38:45 Valid Loss = 0.015750110105132 
2016-12-10 05:39:02 Test Error = 0.87605254294375 
2016-12-10 05:39:02 Test Loss = 0.015718171177776 
2016-12-10 05:39:02 -------------------LR------------------- 
2016-12-10 05:39:02 0.015625 
2016-12-10 05:39:02 Epoch 26 
2016-12-10 05:48:11 Training Error = 0.75297495215112 
2016-12-10 05:48:11 Training Loss = 0.013871091569411 
2016-12-10 05:48:26 Valid Error = 0.88655934107076 
2016-12-10 05:48:26 Valid Loss = 0.015654280210149 
2016-12-10 05:48:44 Test Error = 0.87605254294375 
2016-12-10 05:48:44 Test Loss = 0.015645756721117 
2016-12-10 05:48:44 -------------------LR------------------- 
2016-12-10 05:48:44 0.015625 
2016-12-10 05:48:44 Epoch 27 
2016-12-10 05:58:10 Training Error = 0.75355746026463 
2016-12-10 05:58:10 Training Loss = 0.0138834634368 
2016-12-10 05:58:25 Valid Error = 0.88356420816174 
2016-12-10 05:58:25 Valid Loss = 0.015831877333928 
2016-12-10 05:58:42 Test Error = 0.87302121926575 
2016-12-10 05:58:42 Test Loss = 0.015811521483936 
2016-12-10 05:58:42 -------------------LR------------------- 
2016-12-10 05:58:42 0.015625 
2016-12-10 05:58:42 Epoch 28 
2016-12-10 06:08:41 Training Error = 0.75226762087043 
2016-12-10 06:08:41 Training Loss = 0.013878330922517 
2016-12-10 06:08:56 Valid Error = 0.85473605391239 
2016-12-10 06:08:56 Valid Loss = 0.015743718996286 
2016-12-10 06:09:14 Test Error = 0.85752778713372 
2016-12-10 06:09:14 Test Loss = 0.015741927544118 
2016-12-10 06:09:14 -------------------LR------------------- 
2016-12-10 06:09:14 0.015625 
2016-12-10 06:09:14 Epoch 29 
2016-12-10 06:19:07 Training Error = 0.75343263709745 
2016-12-10 06:19:07 Training Loss = 0.013874528930794 
2016-12-10 06:19:23 Valid Error = 0.8494945713216 
2016-12-10 06:19:23 Valid Loss = 0.015535124835002 
2016-12-10 06:19:40 Test Error = 0.8484338160997 
2016-12-10 06:19:40 Test Loss = 0.015546389458018 
2016-12-10 06:19:40 -------------------LR------------------- 
2016-12-10 06:19:40 0.015625 
2016-12-10 06:19:40 Epoch 30 
2016-12-10 06:29:33 Training Error = 0.74993758841641 
2016-12-10 06:29:33 Training Loss = 0.013878842943409 
2016-12-10 06:29:49 Valid Error = 0.88206664170723 
2016-12-10 06:29:49 Valid Loss = 0.01567073170284 
2016-12-10 06:30:06 Test Error = 0.87032670932974 
2016-12-10 06:30:06 Test Loss = 0.015686318204547 
2016-12-10 06:30:06 -------------------LR------------------- 
2016-12-10 06:30:06 0.015625 
2016-12-10 06:30:06 Epoch 31 
2016-12-10 06:39:54 Training Error = 0.75197636681368 
2016-12-10 06:39:54 Training Loss = 0.01386807168529 
2016-12-10 06:40:10 Valid Error = 0.88131785847997 
2016-12-10 06:40:10 Valid Loss = 0.015622006409346 
2016-12-10 06:40:27 Test Error = 0.87571572920175 
2016-12-10 06:40:27 Test Loss = 0.01560603028211 
2016-12-10 06:40:27 -------------------LR------------------- 
2016-12-10 06:40:27 0.015625 
2016-12-10 06:40:27 Epoch 32 
2016-12-10 06:50:23 Training Error = 0.74977115752684 
2016-12-10 06:50:23 Training Loss = 0.013866915775003 
2016-12-10 06:50:38 Valid Error = 0.89030325720704 
2016-12-10 06:50:38 Valid Loss = 0.015699555827727 
2016-12-10 06:50:56 Test Error = 0.87975749410576 
2016-12-10 06:50:56 Test Loss = 0.015678028774668 
2016-12-10 06:50:56 -------------------LR------------------- 
2016-12-10 06:50:56 0.015625 
2016-12-10 06:50:56 Epoch 33 
2016-12-10 07:01:20 Training Error = 0.75197636681368 
2016-12-10 07:01:20 Training Loss = 0.013861496505727 
2016-12-10 07:01:36 Valid Error = 0.88768251591164 
2016-12-10 07:01:36 Valid Loss = 0.015731060795448 
2016-12-10 07:01:53 Test Error = 0.87335803300775 
2016-12-10 07:01:53 Test Loss = 0.015705006218336 
2016-12-10 07:01:53 -------------------LR------------------- 
2016-12-10 07:01:53 0.015625 
2016-12-10 07:01:53 Epoch 34 
2016-12-10 07:12:19 Training Error = 0.75264209037197 
2016-12-10 07:12:19 Training Loss = 0.013877692568137 
2016-12-10 07:12:34 Valid Error = 0.87982029202546 
2016-12-10 07:12:34 Valid Loss = 0.015789926667465 
2016-12-10 07:12:51 Test Error = 0.86695857190973 
2016-12-10 07:12:51 Test Loss = 0.015790382220915 
2016-12-10 07:12:51 -------------------LR------------------- 
2016-12-10 07:12:51 0.015625 
2016-12-10 07:12:51 Epoch 35 
2016-12-10 07:23:22 Training Error = 0.7512274278106 
2016-12-10 07:23:22 Training Loss = 0.013886346824986 
2016-12-10 07:23:38 Valid Error = 0.89105204043429 
2016-12-10 07:23:38 Valid Loss = 0.015708490310309 
2016-12-10 07:23:55 Test Error = 0.88009430784776 
2016-12-10 07:23:55 Test Loss = 0.015688097219493 
2016-12-10 07:23:55 -------------------LR------------------- 
2016-12-10 07:23:55 0.015625 
2016-12-10 07:23:55 Epoch 36 
2016-12-10 07:34:22 Training Error = 0.75364067570941 
2016-12-10 07:34:22 Training Loss = 0.013876717931945 
2016-12-10 07:34:37 Valid Error = 0.88019468363909 
2016-12-10 07:34:37 Valid Loss = 0.015720825960694 
2016-12-10 07:34:54 Test Error = 0.86796901313574 
2016-12-10 07:34:54 Test Loss = 0.015699456994087 
2016-12-10 07:34:54 -------------------LR------------------- 
2016-12-10 07:34:54 0.015625 
2016-12-10 07:34:54 Epoch 37 
2016-12-10 07:45:24 Training Error = 0.75280852126155 
2016-12-10 07:45:24 Training Loss = 0.01387354080285 
2016-12-10 07:45:39 Valid Error = 0.89292399850243 
2016-12-10 07:45:39 Valid Loss = 0.015841093938436 
2016-12-10 07:45:57 Test Error = 0.87773661165376 
2016-12-10 07:45:57 Test Loss = 0.0158355828821 
2016-12-10 07:45:57 -------------------LR------------------- 
2016-12-10 07:45:57 0.015625 
2016-12-10 07:45:57 Epoch 38 
2016-12-10 07:56:20 Training Error = 0.75226762087043 
2016-12-10 07:56:20 Training Loss = 0.013874172396091 
2016-12-10 07:56:35 Valid Error = 0.88955447397978 
2016-12-10 07:56:35 Valid Loss = 0.015738785923909 
2016-12-10 07:56:52 Test Error = 0.87436847423375 
2016-12-10 07:56:52 Test Loss = 0.015752790942223 
2016-12-10 07:56:52 -------------------LR------------------- 
2016-12-10 07:56:52 0.015625 
2016-12-10 07:56:52 Epoch 39 
2016-12-10 08:06:45 Training Error = 0.75193475909129 
2016-12-10 08:06:45 Training Loss = 0.013870313498894 
2016-12-10 08:07:00 Valid Error = 0.87158367652565 
2016-12-10 08:07:00 Valid Loss = 0.015696652090797 
2016-12-10 08:07:17 Test Error = 0.86257999326373 
2016-12-10 08:07:17 Test Loss = 0.015692220185058 
2016-12-10 08:07:17 -------------------LR------------------- 
2016-12-10 08:07:17 0.015625 
2016-12-10 08:07:17 Epoch 40 
2016-12-10 08:17:14 Training Error = 0.75039527336274 
2016-12-10 08:17:14 Training Loss = 0.013873503254225 
2016-12-10 08:17:29 Valid Error = 0.87982029202546 
2016-12-10 08:17:29 Valid Loss = 0.015713256245982 
2016-12-10 08:17:47 Test Error = 0.86931626810374 
2016-12-10 08:17:47 Test Loss = 0.015680630746104 
2016-12-10 08:17:47 -------------------LR------------------- 
2016-12-10 08:17:47 0.015625 
2016-12-10 08:17:47 Epoch 41 
2016-12-10 08:27:38 Training Error = 0.75085295830906 
2016-12-10 08:27:38 Training Loss = 0.013869347110526 
2016-12-10 08:27:54 Valid Error = 0.88655934107076 
2016-12-10 08:27:54 Valid Loss = 0.015903663670604 
2016-12-10 08:28:11 Test Error = 0.86998989558774 
2016-12-10 08:28:11 Test Loss = 0.015916381579239 
2016-12-10 08:28:11 -------------------LR------------------- 
2016-12-10 08:28:11 0.015625 
2016-12-10 08:28:11 Epoch 42 
2016-12-10 08:38:00 Training Error = 0.75380710659898 
2016-12-10 08:38:00 Training Loss = 0.01388451976006 
2016-12-10 08:38:16 Valid Error = 0.89030325720704 
2016-12-10 08:38:16 Valid Loss = 0.015612038970095 
2016-12-10 08:38:33 Test Error = 0.87841023913776 
2016-12-10 08:38:33 Test Loss = 0.015603510607826 
2016-12-10 08:38:33 -------------------LR------------------- 
2016-12-10 08:38:33 0.015625 
2016-12-10 08:38:33 Epoch 43 
2016-12-10 08:48:24 Training Error = 0.75289173670633 
2016-12-10 08:48:24 Training Loss = 0.013882761122237 
2016-12-10 08:48:40 Valid Error = 0.88019468363909 
2016-12-10 08:48:40 Valid Loss = 0.015744751778778 
2016-12-10 08:48:57 Test Error = 0.86897945436174 
2016-12-10 08:48:57 Test Loss = 0.015736269939539 
2016-12-10 08:48:57 -------------------LR------------------- 
2016-12-10 08:48:57 0.015625 
2016-12-10 08:48:57 Epoch 44 
2016-12-10 08:58:43 Training Error = 0.75176832820171 
2016-12-10 08:58:43 Training Loss = 0.013860500514226 
2016-12-10 08:58:58 Valid Error = 0.84462748034444 
2016-12-10 08:58:58 Valid Loss = 0.015594545795629 
2016-12-10 08:59:15 Test Error = 0.84674974738969 
2016-12-10 08:59:15 Test Loss = 0.015570521454496 
2016-12-10 08:59:15 -------------------LR------------------- 
2016-12-10 08:59:15 0.015625 
2016-12-10 08:59:15 Epoch 45 
2016-12-10 09:09:05 Training Error = 0.75285012898394 
2016-12-10 09:09:05 Training Loss = 0.013876901890662 
2016-12-10 09:09:20 Valid Error = 0.88244103332085 
2016-12-10 09:09:20 Valid Loss = 0.015624982389347 
2016-12-10 09:09:37 Test Error = 0.87268440552375 
2016-12-10 09:09:37 Test Loss = 0.015588858665588 
2016-12-10 09:09:37 -------------------LR------------------- 
2016-12-10 09:09:37 0.015625 
2016-12-10 09:09:37 Epoch 46 
2016-12-10 09:19:28 Training Error = 0.75289173670633 
2016-12-10 09:19:28 Training Loss = 0.013870914375485 
2016-12-10 09:19:43 Valid Error = 0.8790715087982 
2016-12-10 09:19:43 Valid Loss = 0.015948863001572 
2016-12-10 09:20:01 Test Error = 0.86931626810374 
2016-12-10 09:20:01 Test Loss = 0.015912169955153 
2016-12-10 09:20:01 -------------------LR------------------- 
2016-12-10 09:20:01 0.015625 
2016-12-10 09:20:01 Epoch 47 
2016-12-10 09:29:50 Training Error = 0.75260048264958 
2016-12-10 09:29:50 Training Loss = 0.013870202048325 
2016-12-10 09:30:06 Valid Error = 0.87832272557095 
2016-12-10 09:30:06 Valid Loss = 0.01562507006991 
2016-12-10 09:30:23 Test Error = 0.86998989558774 
2016-12-10 09:30:23 Test Loss = 0.015594215020016 
2016-12-10 09:30:23 -------------------LR------------------- 
2016-12-10 09:30:23 0.015625 
2016-12-10 09:30:23 Epoch 48 
2016-12-10 09:40:12 Training Error = 0.75027045019556 
2016-12-10 09:40:12 Training Loss = 0.013860987626605 
2016-12-10 09:40:27 Valid Error = 0.88955447397978 
2016-12-10 09:40:27 Valid Loss = 0.015804995678001 
2016-12-10 09:40:45 Test Error = 0.87436847423375 
2016-12-10 09:40:45 Test Loss = 0.015853655600577 
2016-12-10 09:40:45 -------------------LR------------------- 
2016-12-10 09:40:45 0.015625 
2016-12-10 09:40:45 Epoch 49 
2016-12-10 09:50:32 Training Error = 0.75151868186735 
2016-12-10 09:50:32 Training Loss = 0.013870268216262 
2016-12-10 09:50:47 Valid Error = 0.8816922500936 
2016-12-10 09:50:47 Valid Loss = 0.015774228871272 
2016-12-10 09:51:04 Test Error = 0.86729538565173 
2016-12-10 09:51:04 Test Loss = 0.015726723645069 
2016-12-10 09:51:04 -------------------LR------------------- 
2016-12-10 09:51:04 0.015625 
2016-12-10 09:51:05 Epoch 50 
2016-12-10 10:01:05 Training Error = 0.75364067570941 
2016-12-10 10:01:05 Training Loss = 0.013886910000033 
2016-12-10 10:01:21 Valid Error = 0.8749532010483 
2016-12-10 10:01:21 Valid Loss = 0.015647693534966 
2016-12-10 10:01:38 Test Error = 0.86695857190973 
2016-12-10 10:01:38 Test Loss = 0.015619579919134 
2016-12-10 10:01:38 -------------------LR------------------- 
2016-12-10 10:01:38 0.0078125 
2016-12-10 10:01:38 Epoch 51 
2016-12-10 10:11:25 Training Error = 0.75068652741949 
2016-12-10 10:11:25 Training Loss = 0.013860983249654 
2016-12-10 10:11:41 Valid Error = 0.88094346686634 
2016-12-10 10:11:41 Valid Loss = 0.015769408261978 
2016-12-10 10:11:58 Test Error = 0.87066352307174 
2016-12-10 10:11:58 Test Loss = 0.015748423160178 
2016-12-10 10:11:58 -------------------LR------------------- 
2016-12-10 10:11:58 0.0078125 
2016-12-10 10:11:58 Epoch 52 
2016-12-10 10:21:47 Training Error = 0.75239244403761 
2016-12-10 10:21:47 Training Loss = 0.01386580253546 
2016-12-10 10:22:03 Valid Error = 0.8790715087982 
2016-12-10 10:22:03 Valid Loss = 0.015557467188236 
2016-12-10 10:22:20 Test Error = 0.86931626810374 
2016-12-10 10:22:20 Test Loss = 0.015556108675602 
2016-12-10 10:22:20 -------------------LR------------------- 
2016-12-10 10:22:20 0.0078125 
2016-12-10 10:22:20 Epoch 53 
2016-12-10 10:32:10 Training Error = 0.75047848880752 
2016-12-10 10:32:10 Training Loss = 0.01386380302585 
2016-12-10 10:32:25 Valid Error = 0.87158367652565 
2016-12-10 10:32:25 Valid Loss = 0.015802484728744 
2016-12-10 10:32:42 Test Error = 0.86359043448973 
2016-12-10 10:32:42 Test Loss = 0.015763818717249 
2016-12-10 10:32:42 -------------------LR------------------- 
2016-12-10 10:32:42 0.0078125 
2016-12-10 10:32:43 Epoch 54 
2016-12-10 10:42:38 Training Error = 0.75164350503453 
2016-12-10 10:42:38 Training Loss = 0.013880701663676 
2016-12-10 10:42:53 Valid Error = 0.88992886559341 
2016-12-10 10:42:53 Valid Loss = 0.015763065857897 
2016-12-10 10:43:10 Test Error = 0.87874705287976 
2016-12-10 10:43:10 Test Loss = 0.015737150371523 
2016-12-10 10:43:10 -------------------LR------------------- 
2016-12-10 10:43:10 0.0078125 
2016-12-10 10:43:10 Epoch 55 
2016-12-10 10:53:03 Training Error = 0.75081135058667 
2016-12-10 10:53:03 Training Loss = 0.01385961848601 
2016-12-10 10:53:18 Valid Error = 0.88318981654811 
2016-12-10 10:53:18 Valid Loss = 0.015736809472239 
2016-12-10 10:53:35 Test Error = 0.87167396429774 
2016-12-10 10:53:35 Test Loss = 0.015711353396457 
2016-12-10 10:53:35 -------------------LR------------------- 
2016-12-10 10:53:35 0.0078125 
2016-12-10 10:53:35 Epoch 56 
2016-12-10 11:03:28 Training Error = 0.75484729965882 
2016-12-10 11:03:28 Training Loss = 0.013858888694863 
2016-12-10 11:03:44 Valid Error = 0.88992886559341 
2016-12-10 11:03:44 Valid Loss = 0.015681697814518 
2016-12-10 11:04:01 Test Error = 0.87504210171775 
2016-12-10 11:04:01 Test Loss = 0.015696416449468 
2016-12-10 11:04:01 -------------------LR------------------- 
2016-12-10 11:04:01 0.0078125 
2016-12-10 11:04:01 Epoch 57 
2016-12-10 11:13:53 Training Error = 0.75364067570941 
2016-12-10 11:13:53 Training Loss = 0.013870692638253 
2016-12-10 11:14:08 Valid Error = 0.83938599775365 
2016-12-10 11:14:08 Valid Loss = 0.015687925096656 
2016-12-10 11:14:25 Test Error = 0.84371842371169 
2016-12-10 11:14:25 Test Loss = 0.015688871298715 
2016-12-10 11:14:25 -------------------LR------------------- 
2016-12-10 11:14:25 0.0078125 
2016-12-10 11:14:25 Epoch 58 
2016-12-10 11:24:17 Training Error = 0.75205958225847 
2016-12-10 11:24:17 Training Loss = 0.013860316329855 
2016-12-10 11:24:33 Valid Error = 0.88693373268439 
2016-12-10 11:24:33 Valid Loss = 0.015728244634825 
2016-12-10 11:24:51 Test Error = 0.87403166049175 
2016-12-10 11:24:51 Test Loss = 0.015719319496686 
2016-12-10 11:24:51 -------------------LR------------------- 
2016-12-10 11:24:51 0.0078125 
2016-12-10 11:24:51 Epoch 59 
2016-12-10 11:34:20 Training Error = 0.75168511275693 
2016-12-10 11:34:20 Training Loss = 0.013853795847428 
2016-12-10 11:34:36 Valid Error = 0.88281542493448 
2016-12-10 11:34:36 Valid Loss = 0.015695259052489 
2016-12-10 11:34:53 Test Error = 0.87302121926575 
2016-12-10 11:34:53 Test Loss = 0.015676667849096 
2016-12-10 11:34:53 -------------------LR------------------- 
2016-12-10 11:34:53 0.0078125 
2016-12-10 11:34:53 Epoch 60 
