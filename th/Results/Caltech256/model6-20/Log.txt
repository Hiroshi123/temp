2016-12-10 01:33:47 [program started on Sat Dec 10 01:33:47 2016] 
2016-12-10 01:33:47 [command line arguments] 
2016-12-10 01:33:47 stcWeights false 
2016-12-10 01:33:47 LR 0.015625 
2016-12-10 01:33:47 batchSize 100 
2016-12-10 01:33:47 network ./Models/Cifar10_Custom 
2016-12-10 01:33:47 stcNeurons true 
2016-12-10 01:33:47 constBatchSize false 
2016-12-10 01:33:47 chartFileName chart1 
2016-12-10 01:33:47 dp_prepro false 
2016-12-10 01:33:47 nGPU 1 
2016-12-10 01:33:47 dataset Caltech256 
2016-12-10 01:33:47 type cuda 
2016-12-10 01:33:47 momentum 0 
2016-12-10 01:33:47 threads 8 
2016-12-10 01:33:47 weightDecay 0 
2016-12-10 01:33:47 runningVal false 
2016-12-10 01:33:47 convLayerN 6 
2016-12-10 01:33:47 LRDecay 0 
2016-12-10 01:33:47 numHid 1024 
2016-12-10 01:33:47 save /dev/shm/clone/temp/th/Results/Caltech256/model6-20 
2016-12-10 01:33:47 augment false 
2016-12-10 01:33:47 epoch -1 
2016-12-10 01:33:47 modelsFolder ./Models/ 
2016-12-10 01:33:47 format rgb 
2016-12-10 01:33:47 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 01:33:47 imageFileExtension svg 
2016-12-10 01:33:47 channel 2 
2016-12-10 01:33:47 devid 16 
2016-12-10 01:33:47 visualize 1 
2016-12-10 01:33:47 LRDecayPerEpoch 0.0001 
2016-12-10 01:33:47 optimization adam 
2016-12-10 01:33:47 SBN true 
2016-12-10 01:33:47 normalization simple 
2016-12-10 01:33:47 title model1 
2016-12-10 01:33:47 load  
2016-12-10 01:33:47 whiten true 
2016-12-10 01:33:47 [----------------------] 
2016-12-10 01:33:49 ==> Network 
2016-12-10 01:33:49 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 256, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(512 -> 1024, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(16384)
  (29): BinaryLinear(16384 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-10 01:33:49 ==>36396029 Parameters 
2016-12-10 01:33:49 ==> Loss 
2016-12-10 01:33:49 SqrtHingeEmbeddingCriterion 
2016-12-10 01:33:49 
==> Starting Training
 
2016-12-10 01:33:49 Epoch 1 
2016-12-10 01:43:11 Training Error = 0.98223350253807 
2016-12-10 01:43:11 Training Loss = 0.16853406150223 
2016-12-10 01:43:26 Valid Error = 0.93934855859229 
2016-12-10 01:43:26 Valid Loss = 0.015760758380386 
2016-12-10 01:43:44 Test Error = 0.9514988211519 
2016-12-10 01:43:44 Test Loss = 0.015813436874327 
2016-12-10 01:43:44 -------------------LR------------------- 
2016-12-10 01:43:44 0.015625 
2016-12-10 01:43:44 Epoch 2 
2016-12-10 01:53:05 Training Error = 0.96142964134143 
2016-12-10 01:53:05 Training Loss = 0.016182564037224 
2016-12-10 01:53:21 Valid Error = 0.93934855859229 
2016-12-10 01:53:21 Valid Loss = 0.01559411324555 
2016-12-10 01:53:38 Test Error = 0.9514988211519 
2016-12-10 01:53:38 Test Loss = 0.015612011843052 
2016-12-10 01:53:38 -------------------LR------------------- 
2016-12-10 01:53:38 0.015625 
2016-12-10 01:53:38 Epoch 3 
2016-12-10 02:03:29 Training Error = 0.94507780644088 
2016-12-10 02:03:29 Training Loss = 0.015742207803573 
2016-12-10 02:03:45 Valid Error = 0.93448146761513 
2016-12-10 02:03:45 Valid Loss = 0.015520301726843 
2016-12-10 02:04:02 Test Error = 0.94610980127989 
2016-12-10 02:04:02 Test Loss = 0.015540570078188 
2016-12-10 02:04:02 -------------------LR------------------- 
2016-12-10 02:04:02 0.015625 
2016-12-10 02:04:02 Epoch 4 
2016-12-10 02:13:41 Training Error = 0.93105600399434 
2016-12-10 02:13:41 Training Loss = 0.015562184310948 
2016-12-10 02:13:56 Valid Error = 0.9543242231374 
2016-12-10 02:13:56 Valid Loss = 0.015633647726536 
2016-12-10 02:14:13 Test Error = 0.95318288986191 
2016-12-10 02:14:13 Test Loss = 0.015624648698361 
2016-12-10 02:14:13 -------------------LR------------------- 
2016-12-10 02:14:13 0.015625 
2016-12-10 02:14:13 Epoch 5 
2016-12-10 02:23:44 Training Error = 0.92215195140218 
2016-12-10 02:23:44 Training Loss = 0.015317277105803 
2016-12-10 02:24:00 Valid Error = 0.98427555222763 
2016-12-10 02:24:00 Valid Loss = 0.015626884036477 
2016-12-10 02:24:17 Test Error = 0.98484338160997 
2016-12-10 02:24:17 Test Loss = 0.01560697177758 
2016-12-10 02:24:17 -------------------LR------------------- 
2016-12-10 02:24:17 0.015625 
2016-12-10 02:24:17 Epoch 6 
2016-12-10 02:33:48 Training Error = 0.9096280269618 
2016-12-10 02:33:48 Training Loss = 0.015075157618843 
2016-12-10 02:34:04 Valid Error = 0.97079745413703 
2016-12-10 02:34:04 Valid Loss = 0.015639599517354 
2016-12-10 02:34:21 Test Error = 0.96699225328393 
2016-12-10 02:34:21 Test Loss = 0.015662119511681 
2016-12-10 02:34:21 -------------------LR------------------- 
2016-12-10 02:34:21 0.015625 
2016-12-10 02:34:21 Epoch 7 
2016-12-10 02:43:52 Training Error = 0.89256886078056 
2016-12-10 02:43:52 Training Loss = 0.014939502391404 
2016-12-10 02:44:08 Valid Error = 0.97416697865968 
2016-12-10 02:44:08 Valid Loss = 0.016426126906123 
2016-12-10 02:44:25 Test Error = 0.97339171438195 
2016-12-10 02:44:25 Test Loss = 0.016503140157902 
2016-12-10 02:44:25 -------------------LR------------------- 
2016-12-10 02:44:25 0.015625 
2016-12-10 02:44:25 Epoch 8 
2016-12-10 02:53:56 Training Error = 0.86614795706083 
2016-12-10 02:53:56 Training Loss = 0.014749155480683 
2016-12-10 02:54:12 Valid Error = 0.96667914638712 
2016-12-10 02:54:12 Valid Loss = 0.016630252153013 
2016-12-10 02:54:29 Test Error = 0.96227686089592 
2016-12-10 02:54:29 Test Loss = 0.01662397599751 
2016-12-10 02:54:29 -------------------LR------------------- 
2016-12-10 02:54:29 0.015625 
2016-12-10 02:54:29 Epoch 9 
2016-12-10 03:03:50 Training Error = 0.83157193975202 
2016-12-10 03:03:50 Training Loss = 0.014447385226121 
2016-12-10 03:04:05 Valid Error = 0.9502059153875 
2016-12-10 03:04:05 Valid Loss = 0.016168732469506 
2016-12-10 03:04:22 Test Error = 0.94173122263388 
2016-12-10 03:04:22 Test Loss = 0.016130554292301 
2016-12-10 03:04:22 -------------------LR------------------- 
2016-12-10 03:04:22 0.015625 
2016-12-10 03:04:22 Epoch 10 
2016-12-10 03:13:49 Training Error = 0.78393109761172 
2016-12-10 03:13:49 Training Loss = 0.014102955630428 
2016-12-10 03:14:04 Valid Error = 0.84837139648072 
2016-12-10 03:14:04 Valid Loss = 0.015374423335858 
2016-12-10 03:14:21 Test Error = 0.8491074435837 
2016-12-10 03:14:21 Test Loss = 0.015343319702438 
2016-12-10 03:14:21 -------------------LR------------------- 
2016-12-10 03:14:21 0.015625 
2016-12-10 03:14:21 Epoch 11 
2016-12-10 03:23:37 Training Error = 0.75326620620787 
2016-12-10 03:23:37 Training Loss = 0.01387687830423 
2016-12-10 03:23:53 Valid Error = 0.85286409584425 
2016-12-10 03:23:53 Valid Loss = 0.015644692322331 
2016-12-10 03:24:10 Test Error = 0.85281239474571 
2016-12-10 03:24:10 Test Loss = 0.015623158662938 
2016-12-10 03:24:10 -------------------LR------------------- 
2016-12-10 03:24:10 0.015625 
2016-12-10 03:24:10 Epoch 12 
2016-12-10 03:33:28 Training Error = 0.75018723475077 
2016-12-10 03:33:28 Training Loss = 0.013865041044572 
2016-12-10 03:33:43 Valid Error = 0.88880569075253 
2016-12-10 03:33:43 Valid Loss = 0.015698845800455 
2016-12-10 03:34:01 Test Error = 0.87403166049175 
2016-12-10 03:34:01 Test Loss = 0.015686229884242 
2016-12-10 03:34:01 -------------------LR------------------- 
2016-12-10 03:34:01 0.015625 
2016-12-10 03:34:01 Epoch 13 
2016-12-10 03:43:17 Training Error = 0.75018723475077 
2016-12-10 03:43:17 Training Loss = 0.013860478949768 
2016-12-10 03:43:32 Valid Error = 0.8494945713216 
2016-12-10 03:43:32 Valid Loss = 0.015674261900564 
2016-12-10 03:43:50 Test Error = 0.8484338160997 
2016-12-10 03:43:50 Test Loss = 0.015667372294819 
2016-12-10 03:43:50 -------------------LR------------------- 
2016-12-10 03:43:50 0.015625 
2016-12-10 03:43:50 Epoch 14 
2016-12-10 03:53:12 Training Error = 0.75052009652992 
2016-12-10 03:53:12 Training Loss = 0.013867526842815 
2016-12-10 03:53:27 Valid Error = 0.88618494945713 
2016-12-10 03:53:27 Valid Loss = 0.015740342550445 
2016-12-10 03:53:44 Test Error = 0.86897945436174 
2016-12-10 03:53:44 Test Loss = 0.015784803204664 
2016-12-10 03:53:44 -------------------LR------------------- 
2016-12-10 03:53:44 0.015625 
2016-12-10 03:53:44 Epoch 15 
2016-12-10 04:02:47 Training Error = 0.75451443787967 
2016-12-10 04:02:47 Training Loss = 0.013874037604169 
2016-12-10 04:03:03 Valid Error = 0.89479595657057 
2016-12-10 04:03:03 Valid Loss = 0.015801334859038 
2016-12-10 04:03:20 Test Error = 0.88110474907376 
2016-12-10 04:03:20 Test Loss = 0.015854649246214 
2016-12-10 04:03:20 -------------------LR------------------- 
2016-12-10 04:03:20 0.015625 
2016-12-10 04:03:20 Epoch 16 
2016-12-10 04:12:22 Training Error = 0.75463926104685 
2016-12-10 04:12:22 Training Loss = 0.013880917662585 
2016-12-10 04:12:37 Valid Error = 0.88356420816174 
2016-12-10 04:12:37 Valid Loss = 0.015741855457188 
2016-12-10 04:12:54 Test Error = 0.87167396429774 
2016-12-10 04:12:54 Test Loss = 0.015711738078667 
2016-12-10 04:12:54 -------------------LR------------------- 
2016-12-10 04:12:54 0.015625 
2016-12-10 04:12:54 Epoch 17 
2016-12-10 04:21:58 Training Error = 0.75289173670633 
2016-12-10 04:21:58 Training Loss = 0.013874314676063 
2016-12-10 04:22:14 Valid Error = 0.88131785847997 
2016-12-10 04:22:14 Valid Loss = 0.01580364012281 
2016-12-10 04:22:31 Test Error = 0.86965308184574 
2016-12-10 04:22:31 Test Loss = 0.015787659763294 
2016-12-10 04:22:31 -------------------LR------------------- 
2016-12-10 04:22:31 0.015625 
2016-12-10 04:22:31 Epoch 18 
