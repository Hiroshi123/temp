2016-12-09 22:56:18 [program started on Fri Dec  9 22:56:18 2016] 
2016-12-09 22:56:18 [command line arguments] 
2016-12-09 22:56:18 stcWeights false 
2016-12-09 22:56:18 LR 0.015625 
2016-12-09 22:56:18 batchSize 300 
2016-12-09 22:56:18 network ./Models/Cifar10_Custom 
2016-12-09 22:56:18 stcNeurons true 
2016-12-09 22:56:18 constBatchSize false 
2016-12-09 22:56:18 chartFileName chart1 
2016-12-09 22:56:18 dp_prepro false 
2016-12-09 22:56:18 nGPU 1 
2016-12-09 22:56:18 dataset Caltech256 
2016-12-09 22:56:18 type cuda 
2016-12-09 22:56:18 momentum 0 
2016-12-09 22:56:18 threads 8 
2016-12-09 22:56:18 weightDecay 0 
2016-12-09 22:56:18 runningVal false 
2016-12-09 22:56:18 convLayerN 6 
2016-12-09 22:56:18 LRDecay 0 
2016-12-09 22:56:18 numHid 512 
2016-12-09 22:56:18 save /dev/shm/clone/temp/th/Results/Caltech256/model6-10-512 
2016-12-09 22:56:18 augment false 
2016-12-09 22:56:18 epoch -1 
2016-12-09 22:56:18 modelsFolder ./Models/ 
2016-12-09 22:56:18 format rgb 
2016-12-09 22:56:18 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 22:56:18 imageFileExtension svg 
2016-12-09 22:56:18 channel 1 
2016-12-09 22:56:18 devid 10 
2016-12-09 22:56:18 visualize 1 
2016-12-09 22:56:18 LRDecayPerEpoch 0.0001 
2016-12-09 22:56:18 optimization adam 
2016-12-09 22:56:18 SBN true 
2016-12-09 22:56:18 normalization simple 
2016-12-09 22:56:18 title model1 
2016-12-09 22:56:18 load  
2016-12-09 22:56:18 whiten true 
2016-12-09 22:56:18 [----------------------] 
2016-12-09 22:56:19 ==> Network 
2016-12-09 22:56:19 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 512)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(512 -> 512)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(512 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-09 22:56:19 ==>9170813 Parameters 
2016-12-09 22:56:19 ==> Loss 
2016-12-09 22:56:19 SqrtHingeEmbeddingCriterion 
2016-12-09 22:56:19 
==> Starting Training
 
2016-12-09 22:56:19 Epoch 1 
2016-12-09 22:59:20 Training Error = 0.99151202463177 
2016-12-09 22:59:20 Training Loss = 0.43828873580992 
2016-12-09 22:59:26 Valid Error = 0.99363534256833 
2016-12-09 22:59:26 Valid Loss = 0.063943965258433 
2016-12-09 22:59:33 Test Error = 0.99157965644998 
2016-12-09 22:59:33 Test Loss = 0.063875683992376 
2016-12-09 22:59:33 -------------------LR------------------- 
2016-12-09 22:59:33 0.015625 
2016-12-09 22:59:33 Epoch 2 
2016-12-09 23:02:50 Training Error = 0.97715736040609 
2016-12-09 23:02:50 Training Loss = 0.035972236364709 
2016-12-09 23:02:56 Valid Error = 0.93635342568326 
2016-12-09 23:02:56 Valid Loss = 0.017597735634123 
2016-12-09 23:03:03 Test Error = 0.9491411249579 
2016-12-09 23:03:03 Test Loss = 0.017644226244762 
2016-12-09 23:03:03 -------------------LR------------------- 
2016-12-09 23:03:03 0.015625 
2016-12-09 23:03:03 Epoch 3 
2016-12-09 23:06:18 Training Error = 0.97382874261463 
2016-12-09 23:06:18 Training Loss = 0.018081112567489 
2016-12-09 23:06:24 Valid Error = 0.93934855859229 
2016-12-09 23:06:24 Valid Loss = 0.015732724859242 
2016-12-09 23:06:31 Test Error = 0.9514988211519 
2016-12-09 23:06:31 Test Loss = 0.015776275584196 
2016-12-09 23:06:31 -------------------LR------------------- 
2016-12-09 23:06:31 0.015625 
2016-12-09 23:06:31 Epoch 4 
2016-12-09 23:09:46 Training Error = 0.97174835649497 
2016-12-09 23:09:46 Training Loss = 0.016960217206299 
2016-12-09 23:09:52 Valid Error = 0.93635342568326 
2016-12-09 23:09:52 Valid Loss = 0.015626975293254 
2016-12-09 23:09:59 Test Error = 0.9491411249579 
2016-12-09 23:09:59 Test Loss = 0.015663161074941 
2016-12-09 23:09:59 -------------------LR------------------- 
2016-12-09 23:09:59 0.015625 
2016-12-09 23:09:59 Epoch 5 
2016-12-09 23:13:34 Training Error = 0.96891903137222 
2016-12-09 23:13:34 Training Loss = 0.016639121511457 
2016-12-09 23:13:40 Valid Error = 0.93934855859229 
2016-12-09 23:13:40 Valid Loss = 0.015682775357117 
2016-12-09 23:13:47 Test Error = 0.9514988211519 
2016-12-09 23:13:47 Test Loss = 0.015746245089663 
2016-12-09 23:13:47 -------------------LR------------------- 
2016-12-09 23:13:47 0.015625 
2016-12-09 23:13:47 Epoch 6 
2016-12-09 23:17:17 Training Error = 0.96334359657152 
2016-12-09 23:17:17 Training Loss = 0.016405813573762 
2016-12-09 23:17:23 Valid Error = 0.93934855859229 
2016-12-09 23:17:23 Valid Loss = 0.015660822536758 
2016-12-09 23:17:30 Test Error = 0.9514988211519 
2016-12-09 23:17:30 Test Loss = 0.015700742277784 
2016-12-09 23:17:30 -------------------LR------------------- 
2016-12-09 23:17:30 0.015625 
2016-12-09 23:17:30 Epoch 7 
2016-12-09 23:21:04 Training Error = 0.95169343430141 
2016-12-09 23:21:04 Training Loss = 0.016151971581297 
2016-12-09 23:21:09 Valid Error = 0.93934855859229 
2016-12-09 23:21:09 Valid Loss = 0.015749811875369 
2016-12-09 23:21:16 Test Error = 0.9514988211519 
2016-12-09 23:21:16 Test Loss = 0.015934527762734 
2016-12-09 23:21:16 -------------------LR------------------- 
2016-12-09 23:21:16 0.015625 
2016-12-09 23:21:16 Epoch 8 
2016-12-09 23:24:50 Training Error = 0.94474494466173 
2016-12-09 23:24:50 Training Loss = 0.015991221288339 
2016-12-09 23:24:56 Valid Error = 0.93934855859229 
2016-12-09 23:24:56 Valid Loss = 0.015667122330802 
2016-12-09 23:25:02 Test Error = 0.9514988211519 
2016-12-09 23:25:02 Test Loss = 0.015752016324423 
2016-12-09 23:25:02 -------------------LR------------------- 
2016-12-09 23:25:02 0.015625 
2016-12-09 23:25:02 Epoch 9 
2016-12-09 23:28:35 Training Error = 0.9405841724224 
2016-12-09 23:28:35 Training Loss = 0.01589714673222 
2016-12-09 23:28:41 Valid Error = 0.93934855859229 
2016-12-09 23:28:41 Valid Loss = 0.015593486787637 
2016-12-09 23:28:47 Test Error = 0.9514988211519 
2016-12-09 23:28:47 Test Loss = 0.015624402246087 
2016-12-09 23:28:47 -------------------LR------------------- 
2016-12-09 23:28:47 0.015625 
2016-12-09 23:28:47 Epoch 10 
2016-12-09 23:32:29 Training Error = 0.93313639011401 
2016-12-09 23:32:29 Training Loss = 0.015755279760466 
2016-12-09 23:32:35 Valid Error = 0.95919131411456 
2016-12-09 23:32:35 Valid Loss = 0.015608944312115 
2016-12-09 23:32:42 Test Error = 0.95857190973392 
2016-12-09 23:32:42 Test Loss = 0.015643873183737 
2016-12-09 23:32:42 -------------------LR------------------- 
2016-12-09 23:32:42 0.015625 
2016-12-09 23:32:42 Epoch 11 
2016-12-09 23:36:19 Training Error = 0.93197137388699 
2016-12-09 23:36:19 Training Loss = 0.015712129493446 
2016-12-09 23:36:25 Valid Error = 0.92362411081992 
2016-12-09 23:36:25 Valid Loss = 0.015586299320008 
2016-12-09 23:36:33 Test Error = 0.93634220276187 
2016-12-09 23:36:33 Test Loss = 0.015623988592131 
2016-12-09 23:36:33 -------------------LR------------------- 
2016-12-09 23:36:33 0.015625 
2016-12-09 23:36:33 Epoch 12 
2016-12-09 23:40:07 Training Error = 0.93309478239161 
2016-12-09 23:40:07 Training Loss = 0.015721438202013 
2016-12-09 23:40:13 Valid Error = 0.95919131411456 
2016-12-09 23:40:13 Valid Loss = 0.015593014757698 
2016-12-09 23:40:20 Test Error = 0.95857190973392 
2016-12-09 23:40:20 Test Loss = 0.01563178498159 
2016-12-09 23:40:20 -------------------LR------------------- 
2016-12-09 23:40:20 0.015625 
2016-12-09 23:40:20 Epoch 13 
2016-12-09 23:43:58 Training Error = 0.93201298160939 
2016-12-09 23:43:58 Training Loss = 0.015713974124827 
2016-12-09 23:44:04 Valid Error = 0.98427555222763 
2016-12-09 23:44:04 Valid Loss = 0.015595406666798 
2016-12-09 23:44:11 Test Error = 0.98484338160997 
2016-12-09 23:44:11 Test Loss = 0.015633056517834 
2016-12-09 23:44:11 -------------------LR------------------- 
2016-12-09 23:44:11 0.015625 
2016-12-09 23:44:11 Epoch 14 
2016-12-09 23:47:45 Training Error = 0.93309478239161 
2016-12-09 23:47:45 Training Loss = 0.01570823718198 
2016-12-09 23:47:51 Valid Error = 0.96443279670535 
2016-12-09 23:47:51 Valid Loss = 0.015596022963762 
2016-12-09 23:47:59 Test Error = 0.97777029302796 
2016-12-09 23:47:59 Test Loss = 0.015635424540123 
2016-12-09 23:47:59 -------------------LR------------------- 
2016-12-09 23:47:59 0.015625 
2016-12-09 23:47:59 Epoch 15 
2016-12-09 23:51:35 Training Error = 0.93346925189315 
2016-12-09 23:51:35 Training Loss = 0.015706648419026 
2016-12-09 23:51:41 Valid Error = 0.96443279670535 
2016-12-09 23:51:41 Valid Loss = 0.015593085150607 
2016-12-09 23:51:48 Test Error = 0.97777029302796 
2016-12-09 23:51:48 Test Loss = 0.015632024343449 
2016-12-09 23:51:48 -------------------LR------------------- 
2016-12-09 23:51:48 0.015625 
2016-12-09 23:51:48 Epoch 16 
2016-12-09 23:55:27 Training Error = 0.93326121328118 
2016-12-09 23:55:27 Training Loss = 0.015727581328015 
2016-12-09 23:55:33 Valid Error = 0.95919131411456 
2016-12-09 23:55:33 Valid Loss = 0.01557867766366 
2016-12-09 23:55:43 Test Error = 0.95857190973392 
2016-12-09 23:55:43 Test Loss = 0.015614029614542 
2016-12-09 23:55:43 -------------------LR------------------- 
2016-12-09 23:55:43 0.015625 
2016-12-09 23:55:43 Epoch 17 
2016-12-09 23:59:40 Training Error = 0.93338603644836 
2016-12-09 23:59:40 Training Loss = 0.015706629834216 
2016-12-09 23:59:46 Valid Error = 0.98427555222763 
2016-12-09 23:59:46 Valid Loss = 0.015581556786944 
2016-12-09 23:59:54 Test Error = 0.98484338160997 
2016-12-09 23:59:54 Test Loss = 0.015618102347841 
2016-12-09 23:59:54 -------------------LR------------------- 
2016-12-09 23:59:54 0.015625 
2016-12-09 23:59:54 Epoch 18 
2016-12-10 00:03:33 Training Error = 0.93367729050512 
2016-12-10 00:03:33 Training Loss = 0.015704119618889 
2016-12-10 00:03:39 Valid Error = 0.98427555222763 
2016-12-10 00:03:39 Valid Loss = 0.015588320608923 
2016-12-10 00:03:47 Test Error = 0.98484338160997 
2016-12-10 00:03:47 Test Loss = 0.015626677431229 
2016-12-10 00:03:47 -------------------LR------------------- 
2016-12-10 00:03:47 0.015625 
2016-12-10 00:03:47 Epoch 19 
2016-12-10 00:07:25 Training Error = 0.93126404260631 
2016-12-10 00:07:25 Training Loss = 0.015694764486393 
2016-12-10 00:07:31 Valid Error = 0.97491576188693 
2016-12-10 00:07:31 Valid Loss = 0.015589055768136 
2016-12-10 00:07:39 Test Error = 0.97372852812395 
2016-12-10 00:07:39 Test Loss = 0.015631244428727 
2016-12-10 00:07:39 -------------------LR------------------- 
2016-12-10 00:07:39 0.015625 
2016-12-10 00:07:39 Epoch 20 
2016-12-10 00:11:22 Training Error = 0.93138886577349 
2016-12-10 00:11:22 Training Loss = 0.015711207898249 
2016-12-10 00:11:28 Valid Error = 0.98427555222763 
2016-12-10 00:11:28 Valid Loss = 0.015588095957441 
2016-12-10 00:11:35 Test Error = 0.98484338160997 
2016-12-10 00:11:35 Test Loss = 0.015624567761294 
2016-12-10 00:11:35 -------------------LR------------------- 
2016-12-10 00:11:35 0.015625 
2016-12-10 00:11:35 Epoch 21 
2016-12-10 00:15:07 Training Error = 0.93267870516768 
2016-12-10 00:15:07 Training Loss = 0.015706510060099 
2016-12-10 00:15:13 Valid Error = 0.93934855859229 
2016-12-10 00:15:13 Valid Loss = 0.01558483268495 
2016-12-10 00:15:21 Test Error = 0.9514988211519 
2016-12-10 00:15:21 Test Loss = 0.015623053118954 
2016-12-10 00:15:21 -------------------LR------------------- 
2016-12-10 00:15:21 0.015625 
2016-12-10 00:15:21 Epoch 22 
2016-12-10 00:18:53 Training Error = 0.93321960555879 
2016-12-10 00:18:53 Training Loss = 0.015708129011382 
2016-12-10 00:18:59 Valid Error = 0.96443279670535 
2016-12-10 00:18:59 Valid Loss = 0.015584692268779 
2016-12-10 00:19:06 Test Error = 0.97777029302796 
2016-12-10 00:19:06 Test Loss = 0.015621254628214 
2016-12-10 00:19:06 -------------------LR------------------- 
2016-12-10 00:19:06 0.015625 
2016-12-10 00:19:06 Epoch 23 
2016-12-10 00:22:36 Training Error = 0.93430140634102 
2016-12-10 00:22:36 Training Loss = 0.015737793649555 
2016-12-10 00:22:42 Valid Error = 0.97491576188693 
2016-12-10 00:22:42 Valid Loss = 0.01559359649184 
2016-12-10 00:22:49 Test Error = 0.97372852812395 
2016-12-10 00:22:49 Test Loss = 0.01563405906102 
2016-12-10 00:22:49 -------------------LR------------------- 
2016-12-10 00:22:49 0.015625 
2016-12-10 00:22:49 Epoch 24 
2016-12-10 00:26:21 Training Error = 0.93363568278272 
2016-12-10 00:26:21 Training Loss = 0.015708061484826 
2016-12-10 00:26:27 Valid Error = 0.96443279670535 
2016-12-10 00:26:27 Valid Loss = 0.015592629226084 
2016-12-10 00:26:34 Test Error = 0.97777029302796 
2016-12-10 00:26:34 Test Loss = 0.01563484090718 
2016-12-10 00:26:34 -------------------LR------------------- 
2016-12-10 00:26:34 0.015625 
2016-12-10 00:26:34 Epoch 25 
2016-12-10 00:30:07 Training Error = 0.9337605059499 
2016-12-10 00:30:07 Training Loss = 0.015730186904962 
2016-12-10 00:30:13 Valid Error = 0.95919131411456 
2016-12-10 00:30:13 Valid Loss = 0.015620198592569 
2016-12-10 00:30:20 Test Error = 0.95857190973392 
2016-12-10 00:30:20 Test Loss = 0.015663533281877 
2016-12-10 00:30:20 -------------------LR------------------- 
2016-12-10 00:30:20 0.015625 
2016-12-10 00:30:20 Epoch 26 
2016-12-10 00:33:51 Training Error = 0.93355246733794 
2016-12-10 00:33:51 Training Loss = 0.015717509361465 
2016-12-10 00:33:57 Valid Error = 0.95919131411456 
2016-12-10 00:33:57 Valid Loss = 0.01560235368175 
2016-12-10 00:34:05 Test Error = 0.95857190973392 
2016-12-10 00:34:05 Test Loss = 0.015642960157 
2016-12-10 00:34:05 -------------------LR------------------- 
2016-12-10 00:34:05 0.015625 
2016-12-10 00:34:05 Epoch 27 
2016-12-10 00:37:37 Training Error = 0.93168011983024 
2016-12-10 00:37:37 Training Loss = 0.015718652898418 
2016-12-10 00:37:43 Valid Error = 0.95919131411456 
2016-12-10 00:37:43 Valid Loss = 0.015589019726077 
2016-12-10 00:37:51 Test Error = 0.95857190973392 
2016-12-10 00:37:51 Test Loss = 0.01562834623446 
2016-12-10 00:37:51 -------------------LR------------------- 
2016-12-10 00:37:51 0.015625 
2016-12-10 00:37:51 Epoch 28 
2016-12-10 00:41:21 Training Error = 0.93109761171673 
2016-12-10 00:41:21 Training Loss = 0.01570288966696 
2016-12-10 00:41:27 Valid Error = 0.94870834893298 
2016-12-10 00:41:27 Valid Loss = 0.015596605526171 
2016-12-10 00:41:34 Test Error = 0.96261367463793 
2016-12-10 00:41:34 Test Loss = 0.015640960923074 
2016-12-10 00:41:34 -------------------LR------------------- 
2016-12-10 00:41:34 0.015625 
2016-12-10 00:41:34 Epoch 29 
2016-12-10 00:45:07 Training Error = 0.93338603644836 
2016-12-10 00:45:07 Training Loss = 0.015713675387721 
2016-12-10 00:45:13 Valid Error = 0.93934855859229 
2016-12-10 00:45:13 Valid Loss = 0.015589856398414 
2016-12-10 00:45:21 Test Error = 0.9514988211519 
2016-12-10 00:45:21 Test Loss = 0.015632337890079 
2016-12-10 00:45:21 -------------------LR------------------- 
2016-12-10 00:45:21 0.015625 
2016-12-10 00:45:21 Epoch 30 
2016-12-10 00:49:02 Training Error = 0.93197137388699 
2016-12-10 00:49:02 Training Loss = 0.015723808394352 
2016-12-10 00:49:09 Valid Error = 0.95919131411456 
2016-12-10 00:49:09 Valid Loss = 0.015579232837636 
2016-12-10 00:49:15 Test Error = 0.95857190973392 
2016-12-10 00:49:15 Test Loss = 0.015615066361855 
2016-12-10 00:49:15 -------------------LR------------------- 
2016-12-10 00:49:15 0.015625 
2016-12-10 00:49:15 Epoch 31 
2016-12-10 00:52:46 Training Error = 0.93105600399434 
2016-12-10 00:52:46 Training Loss = 0.015704542406726 
2016-12-10 00:52:52 Valid Error = 0.98427555222763 
2016-12-10 00:52:52 Valid Loss = 0.015586309915419 
2016-12-10 00:52:59 Test Error = 0.98484338160997 
2016-12-10 00:52:59 Test Loss = 0.015623162461708 
2016-12-10 00:52:59 -------------------LR------------------- 
2016-12-10 00:52:59 0.015625 
2016-12-10 00:52:59 Epoch 32 
2016-12-10 00:56:29 Training Error = 0.93288674377965 
2016-12-10 00:56:29 Training Loss = 0.015706643293001 
2016-12-10 00:56:35 Valid Error = 0.98427555222763 
2016-12-10 00:56:35 Valid Loss = 0.01559778582673 
2016-12-10 00:56:43 Test Error = 0.98484338160997 
2016-12-10 00:56:43 Test Loss = 0.01563237258893 
2016-12-10 00:56:43 -------------------LR------------------- 
2016-12-10 00:56:43 0.015625 
2016-12-10 00:56:43 Epoch 33 
2016-12-10 01:00:14 Training Error = 0.93313639011401 
2016-12-10 01:00:14 Training Loss = 0.01571227760758 
2016-12-10 01:00:20 Valid Error = 0.98427555222763 
2016-12-10 01:00:20 Valid Loss = 0.015583807142149 
2016-12-10 01:00:27 Test Error = 0.98484338160997 
2016-12-10 01:00:27 Test Loss = 0.01562374677801 
2016-12-10 01:00:27 -------------------LR------------------- 
2016-12-10 01:00:27 0.015625 
2016-12-10 01:00:27 Epoch 34 
2016-12-10 01:03:57 Training Error = 0.93251227427811 
2016-12-10 01:03:57 Training Loss = 0.015715955296084 
2016-12-10 01:04:03 Valid Error = 0.96443279670535 
2016-12-10 01:04:03 Valid Loss = 0.015589246870212 
2016-12-10 01:04:10 Test Error = 0.97777029302796 
2016-12-10 01:04:10 Test Loss = 0.015630643928328 
2016-12-10 01:04:10 -------------------LR------------------- 
2016-12-10 01:04:10 0.015625 
2016-12-10 01:04:10 Epoch 35 
2016-12-10 01:07:32 Training Error = 0.93159690438545 
2016-12-10 01:07:32 Training Loss = 0.015701785456764 
2016-12-10 01:07:38 Valid Error = 0.98427555222763 
2016-12-10 01:07:38 Valid Loss = 0.015594002242728 
2016-12-10 01:07:45 Test Error = 0.98484338160997 
2016-12-10 01:07:45 Test Loss = 0.015633083522372 
2016-12-10 01:07:45 -------------------LR------------------- 
2016-12-10 01:07:45 0.015625 
2016-12-10 01:07:46 Epoch 36 
2016-12-10 01:11:06 Training Error = 0.93313639011401 
2016-12-10 01:11:06 Training Loss = 0.015715114056123 
2016-12-10 01:11:13 Valid Error = 0.96443279670535 
2016-12-10 01:11:13 Valid Loss = 0.015595385656548 
2016-12-10 01:11:20 Test Error = 0.97777029302796 
2016-12-10 01:11:20 Test Loss = 0.015629233507111 
2016-12-10 01:11:20 -------------------LR------------------- 
2016-12-10 01:11:20 0.015625 
2016-12-10 01:11:20 Epoch 37 
2016-12-10 01:14:42 Training Error = 0.93267870516768 
2016-12-10 01:14:42 Training Loss = 0.015729424730762 
2016-12-10 01:14:48 Valid Error = 1 
2016-12-10 01:14:48 Valid Loss = 0.015611811701613 
2016-12-10 01:14:55 Test Error = 1 
2016-12-10 01:14:55 Test Loss = 0.015656920716707 
2016-12-10 01:14:55 -------------------LR------------------- 
2016-12-10 01:14:55 0.015625 
2016-12-10 01:14:55 Epoch 38 
2016-12-10 01:18:20 Training Error = 0.93326121328118 
2016-12-10 01:18:20 Training Loss = 0.015705390932457 
2016-12-10 01:18:26 Valid Error = 1 
2016-12-10 01:18:26 Valid Loss = 0.015605029159223 
2016-12-10 01:18:33 Test Error = 1 
2016-12-10 01:18:33 Test Loss = 0.015641521152163 
2016-12-10 01:18:33 -------------------LR------------------- 
2016-12-10 01:18:33 0.015625 
2016-12-10 01:18:33 Epoch 39 
2016-12-10 01:21:55 Training Error = 0.93475909128734 
2016-12-10 01:21:55 Training Loss = 0.015715891738474 
2016-12-10 01:22:01 Valid Error = 0.95919131411456 
2016-12-10 01:22:01 Valid Loss = 0.015574928717064 
2016-12-10 01:22:08 Test Error = 0.95857190973392 
2016-12-10 01:22:08 Test Loss = 0.015612404794825 
2016-12-10 01:22:08 -------------------LR------------------- 
2016-12-10 01:22:08 0.015625 
2016-12-10 01:22:08 Epoch 40 
2016-12-10 01:25:41 Training Error = 0.93263709744529 
2016-12-10 01:25:41 Training Loss = 0.015728005836984 
2016-12-10 01:25:47 Valid Error = 0.96443279670535 
2016-12-10 01:25:47 Valid Loss = 0.015615927335106 
2016-12-10 01:25:53 Test Error = 0.97777029302796 
2016-12-10 01:25:53 Test Loss = 0.015662533720081 
2016-12-10 01:25:53 -------------------LR------------------- 
2016-12-10 01:25:53 0.015625 
2016-12-10 01:25:53 Epoch 41 
2016-12-10 01:29:15 Training Error = 0.93230423566614 
2016-12-10 01:29:15 Training Loss = 0.015715494931883 
2016-12-10 01:29:21 Valid Error = 0.98427555222763 
2016-12-10 01:29:21 Valid Loss = 0.015591313685697 
2016-12-10 01:29:29 Test Error = 0.98484338160997 
2016-12-10 01:29:29 Test Loss = 0.015630990983863 
2016-12-10 01:29:29 -------------------LR------------------- 
2016-12-10 01:29:29 0.015625 
2016-12-10 01:29:29 Epoch 42 
2016-12-10 01:33:06 Training Error = 0.93076474993759 
2016-12-10 01:33:06 Training Loss = 0.015698607305384 
2016-12-10 01:33:12 Valid Error = 0.9771621115687 
2016-12-10 01:33:12 Valid Loss = 0.015593095127106 
2016-12-10 01:33:19 Test Error = 0.97810710676996 
2016-12-10 01:33:19 Test Loss = 0.015632108232865 
2016-12-10 01:33:19 -------------------LR------------------- 
2016-12-10 01:33:19 0.015625 
2016-12-10 01:33:19 Epoch 43 
2016-12-10 01:36:44 Training Error = 0.93188815844221 
2016-12-10 01:36:44 Training Loss = 0.015713580822787 
2016-12-10 01:36:50 Valid Error = 0.97491576188693 
2016-12-10 01:36:50 Valid Loss = 0.015625016948077 
2016-12-10 01:36:58 Test Error = 0.97372852812395 
2016-12-10 01:36:58 Test Loss = 0.01566628807163 
2016-12-10 01:36:58 -------------------LR------------------- 
2016-12-10 01:36:58 0.015625 
2016-12-10 01:36:58 Epoch 44 
2016-12-10 01:40:17 Training Error = 0.93313639011401 
2016-12-10 01:40:17 Training Loss = 0.015710352058068 
2016-12-10 01:40:23 Valid Error = 0.95919131411456 
2016-12-10 01:40:23 Valid Loss = 0.015589173073949 
2016-12-10 01:40:30 Test Error = 0.95857190973392 
2016-12-10 01:40:30 Test Loss = 0.015624955156355 
2016-12-10 01:40:30 -------------------LR------------------- 
2016-12-10 01:40:30 0.015625 
2016-12-10 01:40:30 Epoch 45 
2016-12-10 01:43:51 Training Error = 0.93305317466922 
2016-12-10 01:43:51 Training Loss = 0.015713671282323 
2016-12-10 01:43:57 Valid Error = 0.95919131411456 
2016-12-10 01:43:57 Valid Loss = 0.015597717995824 
2016-12-10 01:44:04 Test Error = 0.95857190973392 
2016-12-10 01:44:04 Test Loss = 0.015637440785058 
2016-12-10 01:44:04 -------------------LR------------------- 
2016-12-10 01:44:04 0.015625 
2016-12-10 01:44:04 Epoch 46 
2016-12-10 01:47:22 Training Error = 0.93421819089623 
2016-12-10 01:47:22 Training Loss = 0.015706284590905 
2016-12-10 01:47:28 Valid Error = 0.93934855859229 
2016-12-10 01:47:28 Valid Loss = 0.015602681199322 
2016-12-10 01:47:36 Test Error = 0.9514988211519 
2016-12-10 01:47:36 Test Loss = 0.015641022786031 
2016-12-10 01:47:36 -------------------LR------------------- 
2016-12-10 01:47:36 0.015625 
2016-12-10 01:47:36 Epoch 47 
2016-12-10 01:50:55 Training Error = 0.93205458933178 
2016-12-10 01:50:55 Training Loss = 0.015708527128015 
2016-12-10 01:51:01 Valid Error = 0.9771621115687 
2016-12-10 01:51:01 Valid Loss = 0.015584915169515 
2016-12-10 01:51:08 Test Error = 0.97810710676996 
2016-12-10 01:51:08 Test Loss = 0.015623848042063 
2016-12-10 01:51:08 -------------------LR------------------- 
2016-12-10 01:51:08 0.015625 
2016-12-10 01:51:08 Epoch 48 
2016-12-10 01:54:29 Training Error = 0.93276192061247 
2016-12-10 01:54:29 Training Loss = 0.015721923209317 
2016-12-10 01:54:35 Valid Error = 0.93934855859229 
2016-12-10 01:54:35 Valid Loss = 0.01559195632889 
2016-12-10 01:54:42 Test Error = 0.9514988211519 
2016-12-10 01:54:42 Test Loss = 0.015631222318035 
2016-12-10 01:54:42 -------------------LR------------------- 
2016-12-10 01:54:42 0.015625 
2016-12-10 01:54:43 Epoch 49 
2016-12-10 01:58:27 Training Error = 0.9331779978364 
2016-12-10 01:58:27 Training Loss = 0.015715167533188 
2016-12-10 01:58:33 Valid Error = 0.95919131411456 
2016-12-10 01:58:33 Valid Loss = 0.015588175630084 
2016-12-10 01:58:40 Test Error = 0.95857190973392 
2016-12-10 01:58:40 Test Loss = 0.015623226868279 
2016-12-10 01:58:40 -------------------LR------------------- 
2016-12-10 01:58:40 0.015625 
2016-12-10 01:58:40 Epoch 50 
2016-12-10 02:02:24 Training Error = 0.93363568278272 
2016-12-10 02:02:24 Training Loss = 0.015708753094921 
2016-12-10 02:02:30 Valid Error = 0.95919131411456 
2016-12-10 02:02:30 Valid Loss = 0.015589447144727 
2016-12-10 02:02:37 Test Error = 0.95857190973392 
2016-12-10 02:02:37 Test Loss = 0.015628224979196 
2016-12-10 02:02:37 -------------------LR------------------- 
2016-12-10 02:02:37 0.0078125 
2016-12-10 02:02:37 Epoch 51 
2016-12-10 02:06:07 Training Error = 0.93292835150204 
2016-12-10 02:06:07 Training Loss = 0.01571225059238 
2016-12-10 02:06:13 Valid Error = 1 
2016-12-10 02:06:13 Valid Loss = 0.015607767936994 
2016-12-10 02:06:20 Test Error = 1 
2016-12-10 02:06:20 Test Loss = 0.015648152209546 
2016-12-10 02:06:20 -------------------LR------------------- 
2016-12-10 02:06:20 0.0078125 
2016-12-10 02:06:20 Epoch 52 
2016-12-10 02:09:47 Training Error = 0.93413497545144 
2016-12-10 02:09:47 Training Loss = 0.015718189582131 
2016-12-10 02:09:53 Valid Error = 0.95919131411456 
2016-12-10 02:09:53 Valid Loss = 0.015581560420591 
2016-12-10 02:10:01 Test Error = 0.95857190973392 
2016-12-10 02:10:01 Test Loss = 0.015621920053635 
2016-12-10 02:10:01 -------------------LR------------------- 
2016-12-10 02:10:01 0.0078125 
2016-12-10 02:10:01 Epoch 53 
2016-12-10 02:13:25 Training Error = 0.93284513605725 
2016-12-10 02:13:25 Training Loss = 0.015706769535343 
2016-12-10 02:13:31 Valid Error = 0.93934855859229 
2016-12-10 02:13:31 Valid Loss = 0.01557985192755 
2016-12-10 02:13:38 Test Error = 0.9514988211519 
2016-12-10 02:13:38 Test Loss = 0.015620490689971 
2016-12-10 02:13:38 -------------------LR------------------- 
2016-12-10 02:13:38 0.0078125 
2016-12-10 02:13:38 Epoch 54 
2016-12-10 02:17:02 Training Error = 0.93088957310477 
2016-12-10 02:17:02 Training Loss = 0.015705185387086 
2016-12-10 02:17:08 Valid Error = 0.94870834893298 
2016-12-10 02:17:08 Valid Loss = 0.015588591241672 
2016-12-10 02:17:15 Test Error = 0.96261367463793 
2016-12-10 02:17:15 Test Loss = 0.015626537734174 
2016-12-10 02:17:15 -------------------LR------------------- 
2016-12-10 02:17:15 0.0078125 
2016-12-10 02:17:15 Epoch 55 
2016-12-10 02:20:43 Training Error = 0.93172172755263 
2016-12-10 02:20:43 Training Loss = 0.015717162699182 
2016-12-10 02:20:49 Valid Error = 1 
2016-12-10 02:20:49 Valid Loss = 0.015586735659869 
2016-12-10 02:20:57 Test Error = 1 
2016-12-10 02:20:57 Test Loss = 0.015627000613101 
2016-12-10 02:20:57 -------------------LR------------------- 
2016-12-10 02:20:57 0.0078125 
2016-12-10 02:20:57 Epoch 56 
2016-12-10 02:24:21 Training Error = 0.9319297661646 
2016-12-10 02:24:21 Training Loss = 0.015728295200135 
2016-12-10 02:24:27 Valid Error = 0.93934855859229 
2016-12-10 02:24:27 Valid Loss = 0.015598947448095 
2016-12-10 02:24:35 Test Error = 0.9514988211519 
2016-12-10 02:24:35 Test Loss = 0.015635231633616 
2016-12-10 02:24:35 -------------------LR------------------- 
2016-12-10 02:24:35 0.0078125 
2016-12-10 02:24:35 Epoch 57 
2016-12-10 02:28:00 Training Error = 0.93284513605725 
2016-12-10 02:28:00 Training Loss = 0.015701910832021 
2016-12-10 02:28:06 Valid Error = 0.97491576188693 
2016-12-10 02:28:06 Valid Loss = 0.015587839571414 
2016-12-10 02:28:13 Test Error = 0.97372852812395 
2016-12-10 02:28:13 Test Loss = 0.015623970819462 
2016-12-10 02:28:13 -------------------LR------------------- 
2016-12-10 02:28:13 0.0078125 
2016-12-10 02:28:13 Epoch 58 
2016-12-10 02:31:40 Training Error = 0.9350087376217 
2016-12-10 02:31:40 Training Loss = 0.015719866621121 
2016-12-10 02:31:46 Valid Error = 0.9771621115687 
2016-12-10 02:31:46 Valid Loss = 0.015591367372597 
2016-12-10 02:31:53 Test Error = 0.97810710676996 
2016-12-10 02:31:53 Test Loss = 0.015626775514579 
2016-12-10 02:31:53 -------------------LR------------------- 
2016-12-10 02:31:53 0.0078125 
2016-12-10 02:31:53 Epoch 59 
2016-12-10 02:35:16 Training Error = 0.93330282100358 
2016-12-10 02:35:16 Training Loss = 0.01571626314062 
2016-12-10 02:35:22 Valid Error = 0.97491576188693 
2016-12-10 02:35:22 Valid Loss = 0.01558562613822 
2016-12-10 02:35:29 Test Error = 0.97372852812395 
2016-12-10 02:35:29 Test Loss = 0.015625805531187 
2016-12-10 02:35:29 -------------------LR------------------- 
2016-12-10 02:35:29 0.0078125 
2016-12-10 02:35:29 Epoch 60 
2016-12-10 02:39:04 Training Error = 0.93371889822751 
2016-12-10 02:39:04 Training Loss = 0.015724293044161 
2016-12-10 02:39:10 Valid Error = 0.97491576188693 
2016-12-10 02:39:10 Valid Loss = 0.015572874365498 
2016-12-10 02:39:17 Test Error = 0.97372852812395 
2016-12-10 02:39:17 Test Loss = 0.015610819528061 
2016-12-10 02:39:17 -------------------LR------------------- 
2016-12-10 02:39:17 0.0078125 
2016-12-10 02:39:17 Epoch 61 
2016-12-10 02:42:41 Training Error = 0.93292835150204 
2016-12-10 02:42:41 Training Loss = 0.015707140167745 
2016-12-10 02:42:47 Valid Error = 0.97491576188693 
2016-12-10 02:42:47 Valid Loss = 0.015598790816595 
2016-12-10 02:42:55 Test Error = 0.97372852812395 
2016-12-10 02:42:55 Test Loss = 0.015638324656337 
2016-12-10 02:42:55 -------------------LR------------------- 
2016-12-10 02:42:55 0.0078125 
2016-12-10 02:42:55 Epoch 62 
2016-12-10 02:46:20 Training Error = 0.93313639011401 
2016-12-10 02:46:20 Training Loss = 0.015730678933535 
2016-12-10 02:46:26 Valid Error = 0.95919131411456 
2016-12-10 02:46:26 Valid Loss = 0.015601310798328 
2016-12-10 02:46:33 Test Error = 0.95857190973392 
2016-12-10 02:46:33 Test Loss = 0.015647682286447 
2016-12-10 02:46:33 -------------------LR------------------- 
2016-12-10 02:46:33 0.0078125 
2016-12-10 02:46:33 Epoch 63 
2016-12-10 02:49:59 Training Error = 0.93301156694683 
2016-12-10 02:49:59 Training Loss = 0.015704158261655 
2016-12-10 02:50:05 Valid Error = 1 
2016-12-10 02:50:05 Valid Loss = 0.015612243773215 
2016-12-10 02:50:12 Test Error = 1 
2016-12-10 02:50:12 Test Loss = 0.015651280674389 
2016-12-10 02:50:12 -------------------LR------------------- 
2016-12-10 02:50:12 0.0078125 
2016-12-10 02:50:12 Epoch 64 
2016-12-10 02:53:38 Training Error = 0.93346925189315 
2016-12-10 02:53:38 Training Loss = 0.015718865611938 
2016-12-10 02:53:44 Valid Error = 0.97491576188693 
2016-12-10 02:53:44 Valid Loss = 0.015597286685757 
2016-12-10 02:53:51 Test Error = 0.97372852812395 
2016-12-10 02:53:51 Test Loss = 0.015637614492859 
2016-12-10 02:53:51 -------------------LR------------------- 
2016-12-10 02:53:51 0.0078125 
2016-12-10 02:53:51 Epoch 65 
2016-12-10 02:57:11 Training Error = 0.93126404260631 
2016-12-10 02:57:11 Training Loss = 0.015718117135819 
2016-12-10 02:57:17 Valid Error = 0.95919131411456 
2016-12-10 02:57:17 Valid Loss = 0.015610352768264 
2016-12-10 02:57:24 Test Error = 0.95857190973392 
2016-12-10 02:57:24 Test Loss = 0.015651844268071 
2016-12-10 02:57:24 -------------------LR------------------- 
2016-12-10 02:57:24 0.0078125 
2016-12-10 02:57:24 Epoch 66 
2016-12-10 03:00:48 Training Error = 0.93263709744529 
2016-12-10 03:00:48 Training Loss = 0.01570266096322 
2016-12-10 03:00:54 Valid Error = 0.95919131411456 
2016-12-10 03:00:54 Valid Loss = 0.015583984144053 
2016-12-10 03:01:01 Test Error = 0.95857190973392 
2016-12-10 03:01:01 Test Loss = 0.015620871602022 
2016-12-10 03:01:01 -------------------LR------------------- 
2016-12-10 03:01:01 0.0078125 
2016-12-10 03:01:01 Epoch 67 
2016-12-10 03:04:19 Training Error = 0.93147208121827 
2016-12-10 03:04:19 Training Loss = 0.015713758604943 
2016-12-10 03:04:25 Valid Error = 0.92362411081992 
2016-12-10 03:04:25 Valid Loss = 0.015594848939978 
2016-12-10 03:04:32 Test Error = 0.93634220276187 
2016-12-10 03:04:32 Test Loss = 0.015632965001729 
2016-12-10 03:04:32 -------------------LR------------------- 
2016-12-10 03:04:32 0.0078125 
2016-12-10 03:04:32 Epoch 68 
2016-12-10 03:07:49 Training Error = 0.93284513605725 
2016-12-10 03:07:49 Training Loss = 0.015718187684569 
2016-12-10 03:07:55 Valid Error = 0.95919131411456 
2016-12-10 03:07:55 Valid Loss = 0.015592033548789 
2016-12-10 03:08:03 Test Error = 0.95857190973392 
2016-12-10 03:08:03 Test Loss = 0.015630436427483 
2016-12-10 03:08:03 -------------------LR------------------- 
2016-12-10 03:08:03 0.0078125 
2016-12-10 03:08:03 Epoch 69 
2016-12-10 03:11:24 Training Error = 0.93280352833486 
2016-12-10 03:11:24 Training Loss = 0.015724875793583 
2016-12-10 03:11:30 Valid Error = 0.97491576188693 
2016-12-10 03:11:30 Valid Loss = 0.015595823983334 
2016-12-10 03:11:37 Test Error = 0.97372852812395 
2016-12-10 03:11:37 Test Loss = 0.015635611380634 
2016-12-10 03:11:37 -------------------LR------------------- 
2016-12-10 03:11:37 0.0078125 
2016-12-10 03:11:38 Epoch 70 
2016-12-10 03:15:07 Training Error = 0.93217941249896 
2016-12-10 03:15:07 Training Loss = 0.015704120419921 
2016-12-10 03:15:13 Valid Error = 0.96443279670535 
2016-12-10 03:15:13 Valid Loss = 0.015586777304836 
2016-12-10 03:15:20 Test Error = 0.97777029302796 
2016-12-10 03:15:20 Test Loss = 0.015622563497087 
2016-12-10 03:15:20 -------------------LR------------------- 
2016-12-10 03:15:20 0.0078125 
2016-12-10 03:15:20 Epoch 71 
2016-12-10 03:18:39 Training Error = 0.93280352833486 
2016-12-10 03:18:39 Training Loss = 0.01572730230035 
2016-12-10 03:18:45 Valid Error = 0.95919131411456 
2016-12-10 03:18:45 Valid Loss = 0.015591801308127 
2016-12-10 03:18:52 Test Error = 0.95857190973392 
2016-12-10 03:18:52 Test Loss = 0.015628165300376 
2016-12-10 03:18:52 -------------------LR------------------- 
2016-12-10 03:18:52 0.0078125 
2016-12-10 03:18:52 Epoch 72 
2016-12-10 03:22:11 Training Error = 0.93405176000666 
2016-12-10 03:22:11 Training Loss = 0.015715256115151 
2016-12-10 03:22:17 Valid Error = 0.97491576188693 
2016-12-10 03:22:17 Valid Loss = 0.015606871668664 
2016-12-10 03:22:24 Test Error = 0.97372852812395 
2016-12-10 03:22:24 Test Loss = 0.015644812899433 
2016-12-10 03:22:24 -------------------LR------------------- 
2016-12-10 03:22:24 0.0078125 
2016-12-10 03:22:24 Epoch 73 
2016-12-10 03:25:43 Training Error = 0.93409336772905 
2016-12-10 03:25:43 Training Loss = 0.015708090012861 
2016-12-10 03:25:49 Valid Error = 0.93934855859229 
2016-12-10 03:25:49 Valid Loss = 0.015589838063349 
2016-12-10 03:25:56 Test Error = 0.9514988211519 
2016-12-10 03:25:56 Test Loss = 0.015630548961024 
2016-12-10 03:25:56 -------------------LR------------------- 
2016-12-10 03:25:56 0.0078125 
2016-12-10 03:25:56 Epoch 74 
2016-12-10 03:29:17 Training Error = 0.93105600399434 
2016-12-10 03:29:17 Training Loss = 0.015706633768398 
2016-12-10 03:29:23 Valid Error = 1 
2016-12-10 03:29:23 Valid Loss = 0.015596603023051 
2016-12-10 03:29:30 Test Error = 1 
2016-12-10 03:29:30 Test Loss = 0.015635318728057 
2016-12-10 03:29:30 -------------------LR------------------- 
2016-12-10 03:29:30 0.0078125 
2016-12-10 03:29:30 Epoch 75 
2016-12-10 03:32:49 Training Error = 0.93334442872597 
2016-12-10 03:32:49 Training Loss = 0.01571539083018 
2016-12-10 03:32:55 Valid Error = 0.95919131411456 
2016-12-10 03:32:55 Valid Loss = 0.01558137346116 
2016-12-10 03:33:02 Test Error = 0.95857190973392 
2016-12-10 03:33:02 Test Loss = 0.015616315571484 
2016-12-10 03:33:02 -------------------LR------------------- 
2016-12-10 03:33:02 0.0078125 
2016-12-10 03:33:02 Epoch 76 
2016-12-10 03:36:21 Training Error = 0.93292835150204 
2016-12-10 03:36:21 Training Loss = 0.015701259884218 
2016-12-10 03:36:27 Valid Error = 0.96443279670535 
2016-12-10 03:36:27 Valid Loss = 0.015591768264449 
2016-12-10 03:36:35 Test Error = 0.97777029302796 
2016-12-10 03:36:35 Test Loss = 0.01562962028881 
2016-12-10 03:36:35 -------------------LR------------------- 
2016-12-10 03:36:35 0.0078125 
2016-12-10 03:36:35 Epoch 77 
2016-12-10 03:39:53 Training Error = 0.93296995922443 
2016-12-10 03:39:53 Training Loss = 0.015710292719998 
2016-12-10 03:39:59 Valid Error = 1 
2016-12-10 03:39:59 Valid Loss = 0.015591581257258 
2016-12-10 03:40:07 Test Error = 1 
2016-12-10 03:40:07 Test Loss = 0.015626655270116 
2016-12-10 03:40:07 -------------------LR------------------- 
2016-12-10 03:40:07 0.0078125 
2016-12-10 03:40:07 Epoch 78 
2016-12-10 03:43:26 Training Error = 0.93259548972289 
2016-12-10 03:43:26 Training Loss = 0.015708147448443 
2016-12-10 03:43:32 Valid Error = 0.92362411081992 
2016-12-10 03:43:32 Valid Loss = 0.015592704084832 
2016-12-10 03:43:39 Test Error = 0.93634220276187 
2016-12-10 03:43:39 Test Loss = 0.015630636614253 
2016-12-10 03:43:39 -------------------LR------------------- 
2016-12-10 03:43:39 0.0078125 
2016-12-10 03:43:39 Epoch 79 
2016-12-10 03:46:57 Training Error = 0.93334442872597 
2016-12-10 03:46:57 Training Loss = 0.015712424516545 
2016-12-10 03:47:03 Valid Error = 0.93934855859229 
2016-12-10 03:47:03 Valid Loss = 0.015586268469341 
2016-12-10 03:47:10 Test Error = 0.9514988211519 
2016-12-10 03:47:10 Test Loss = 0.015624669617353 
2016-12-10 03:47:10 -------------------LR------------------- 
2016-12-10 03:47:10 0.0078125 
2016-12-10 03:47:10 Epoch 80 
2016-12-10 03:50:39 Training Error = 0.93276192061247 
2016-12-10 03:50:39 Training Loss = 0.015710795410553 
2016-12-10 03:50:46 Valid Error = 0.96443279670535 
2016-12-10 03:50:46 Valid Loss = 0.015599277960122 
2016-12-10 03:50:52 Test Error = 0.97777029302796 
2016-12-10 03:50:52 Test Loss = 0.015638986040331 
2016-12-10 03:50:52 -------------------LR------------------- 
2016-12-10 03:50:52 0.0078125 
2016-12-10 03:50:52 Epoch 81 
2016-12-10 03:54:10 Training Error = 0.93288674377965 
2016-12-10 03:54:10 Training Loss = 0.015706068343863 
2016-12-10 03:54:16 Valid Error = 0.96443279670535 
2016-12-10 03:54:16 Valid Loss = 0.015582774152139 
2016-12-10 03:54:23 Test Error = 0.97777029302796 
2016-12-10 03:54:23 Test Loss = 0.015620568722196 
2016-12-10 03:54:23 -------------------LR------------------- 
2016-12-10 03:54:23 0.0078125 
2016-12-10 03:54:24 Epoch 82 
2016-12-10 03:57:34 Training Error = 0.93151368894067 
2016-12-10 03:57:34 Training Loss = 0.0157121788486 
2016-12-10 03:57:40 Valid Error = 0.96443279670535 
2016-12-10 03:57:40 Valid Loss = 0.015599189022138 
2016-12-10 03:57:47 Test Error = 0.97777029302796 
2016-12-10 03:57:47 Test Loss = 0.015638512358758 
2016-12-10 03:57:47 -------------------LR------------------- 
2016-12-10 03:57:47 0.0078125 
2016-12-10 03:57:47 Epoch 83 
2016-12-10 04:00:58 Training Error = 0.93213780477657 
2016-12-10 04:00:58 Training Loss = 0.0157140412739 
2016-12-10 04:01:04 Valid Error = 0.98427555222763 
2016-12-10 04:01:04 Valid Loss = 0.015588660954171 
2016-12-10 04:01:11 Test Error = 0.98484338160997 
2016-12-10 04:01:11 Test Loss = 0.0156246652645 
2016-12-10 04:01:11 -------------------LR------------------- 
2016-12-10 04:01:11 0.0078125 
2016-12-10 04:01:11 Epoch 84 
2016-12-10 04:04:21 Training Error = 0.93463426812016 
2016-12-10 04:04:21 Training Loss = 0.015723189693807 
2016-12-10 04:04:27 Valid Error = 0.93934855859229 
2016-12-10 04:04:27 Valid Loss = 0.01559277426773 
2016-12-10 04:04:34 Test Error = 0.9514988211519 
2016-12-10 04:04:34 Test Loss = 0.015636260098762 
2016-12-10 04:04:34 -------------------LR------------------- 
2016-12-10 04:04:34 0.0078125 
2016-12-10 04:04:34 Epoch 85 
2016-12-10 04:07:45 Training Error = 0.93263709744529 
2016-12-10 04:07:45 Training Loss = 0.015706137755235 
2016-12-10 04:07:51 Valid Error = 0.97491576188693 
2016-12-10 04:07:51 Valid Loss = 0.015595731759104 
2016-12-10 04:07:58 Test Error = 0.97372852812395 
2016-12-10 04:07:58 Test Loss = 0.015634382098746 
2016-12-10 04:07:58 -------------------LR------------------- 
2016-12-10 04:07:58 0.0078125 
2016-12-10 04:07:58 Epoch 86 
2016-12-10 04:11:10 Training Error = 0.9313056503287 
2016-12-10 04:11:10 Training Loss = 0.015711199434543 
2016-12-10 04:11:16 Valid Error = 0.95919131411456 
2016-12-10 04:11:16 Valid Loss = 0.015578032822221 
2016-12-10 04:11:23 Test Error = 0.95857190973392 
2016-12-10 04:11:23 Test Loss = 0.01561679151609 
2016-12-10 04:11:23 -------------------LR------------------- 
2016-12-10 04:11:23 0.0078125 
2016-12-10 04:11:23 Epoch 87 
2016-12-10 04:14:37 Training Error = 0.93296995922443 
2016-12-10 04:14:37 Training Loss = 0.015718336006132 
2016-12-10 04:14:43 Valid Error = 0.93934855859229 
2016-12-10 04:14:43 Valid Loss = 0.015591710497055 
2016-12-10 04:14:50 Test Error = 0.9514988211519 
2016-12-10 04:14:50 Test Loss = 0.015630940689364 
2016-12-10 04:14:50 -------------------LR------------------- 
2016-12-10 04:14:50 0.0078125 
2016-12-10 04:14:50 Epoch 88 
2016-12-10 04:18:03 Training Error = 0.93267870516768 
2016-12-10 04:18:03 Training Loss = 0.015711768655071 
2016-12-10 04:18:09 Valid Error = 0.93934855859229 
2016-12-10 04:18:09 Valid Loss = 0.015589477466115 
2016-12-10 04:18:16 Test Error = 0.9514988211519 
2016-12-10 04:18:16 Test Loss = 0.015629780210203 
2016-12-10 04:18:16 -------------------LR------------------- 
2016-12-10 04:18:16 0.0078125 
2016-12-10 04:18:16 Epoch 89 
2016-12-10 04:21:27 Training Error = 0.93405176000666 
2016-12-10 04:21:27 Training Loss = 0.015715256521896 
2016-12-10 04:21:33 Valid Error = 0.96443279670535 
2016-12-10 04:21:33 Valid Loss = 0.015580399380191 
2016-12-10 04:21:40 Test Error = 0.97777029302796 
2016-12-10 04:21:40 Test Loss = 0.015617740425099 
2016-12-10 04:21:40 -------------------LR------------------- 
2016-12-10 04:21:40 0.0078125 
2016-12-10 04:21:40 Epoch 90 
2016-12-10 04:25:04 Training Error = 0.93134725805109 
2016-12-10 04:25:04 Training Loss = 0.015727043164349 
