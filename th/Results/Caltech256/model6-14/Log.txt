2016-12-09 22:39:29 [program started on Fri Dec  9 22:39:29 2016] 
2016-12-09 22:39:29 [command line arguments] 
2016-12-09 22:39:29 stcWeights false 
2016-12-09 22:39:29 LR 0.015625 
2016-12-09 22:39:29 batchSize 64 
2016-12-09 22:39:29 network ./Models/Cifar10_Custom 
2016-12-09 22:39:29 stcNeurons true 
2016-12-09 22:39:29 constBatchSize false 
2016-12-09 22:39:29 chartFileName chart1 
2016-12-09 22:39:29 dp_prepro false 
2016-12-09 22:39:29 nGPU 1 
2016-12-09 22:39:29 dataset Caltech256 
2016-12-09 22:39:29 type cuda 
2016-12-09 22:39:29 momentum 0 
2016-12-09 22:39:29 threads 8 
2016-12-09 22:39:29 weightDecay 0 
2016-12-09 22:39:29 runningVal false 
2016-12-09 22:39:29 convLayerN 6 
2016-12-09 22:39:29 LRDecay 0 
2016-12-09 22:39:29 numHid 1024 
2016-12-09 22:39:29 save /dev/shm/clone/temp/th/Results/Caltech256/model6-14 
2016-12-09 22:39:29 augment false 
2016-12-09 22:39:29 epoch -1 
2016-12-09 22:39:29 modelsFolder ./Models/ 
2016-12-09 22:39:29 format rgb 
2016-12-09 22:39:29 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 22:39:29 imageFileExtension svg 
2016-12-09 22:39:29 channel 1.4 
2016-12-09 22:39:29 devid 5 
2016-12-09 22:39:29 visualize 1 
2016-12-09 22:39:29 LRDecayPerEpoch 0.0001 
2016-12-09 22:39:29 optimization adam 
2016-12-09 22:39:29 SBN true 
2016-12-09 22:39:29 normalization simple 
2016-12-09 22:39:29 title model1 
2016-12-09 22:39:29 load  
2016-12-09 22:39:29 whiten true 
2016-12-09 22:39:29 [----------------------] 
2016-12-09 22:39:30 ==> Network 
2016-12-09 22:39:30 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 179, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(179 -> 179, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(179 -> 358, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(358 -> 358, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(358 -> 716, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(716 -> 716, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(11456)
  (29): BinaryLinear(11456 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-09 22:39:30 ==>21999339 Parameters 
2016-12-09 22:39:30 ==> Loss 
2016-12-09 22:39:30 SqrtHingeEmbeddingCriterion 
2016-12-09 22:39:30 
==> Starting Training
 
2016-12-09 22:39:30 Epoch 1 
2016-12-09 22:45:36 Training Error = 0.97595073645669 
2016-12-09 22:45:36 Training Loss = 0.11278828472333 
2016-12-09 22:45:46 Valid Error = 0.93597903406964 
2016-12-09 22:45:46 Valid Loss = 0.015628829856267 
2016-12-09 22:45:57 Test Error = 0.9477938699899 
2016-12-09 22:45:57 Test Loss = 0.015656164753372 
2016-12-09 22:45:57 -------------------LR------------------- 
2016-12-09 22:45:57 0.015625 
2016-12-09 22:45:57 Epoch 2 
2016-12-09 22:52:21 Training Error = 0.94607639177831 
2016-12-09 22:52:21 Training Loss = 0.015760503061804 
2016-12-09 22:52:31 Valid Error = 0.93223511793336 
2016-12-09 22:52:31 Valid Loss = 0.015503946835902 
2016-12-09 22:52:42 Test Error = 0.94543617379589 
2016-12-09 22:52:42 Test Loss = 0.015520940272968 
2016-12-09 22:52:42 -------------------LR------------------- 
2016-12-09 22:52:42 0.015625 
2016-12-09 22:52:42 Epoch 3 
2016-12-09 22:59:05 Training Error = 0.92810185570442 
2016-12-09 22:59:05 Training Loss = 0.015475363314829 
2016-12-09 22:59:15 Valid Error = 0.95207787345563 
2016-12-09 22:59:15 Valid Loss = 0.015520114015524 
2016-12-09 22:59:26 Test Error = 0.96092960592792 
2016-12-09 22:59:26 Test Loss = 0.015564359364134 
2016-12-09 22:59:26 -------------------LR------------------- 
2016-12-09 22:59:26 0.015625 
2016-12-09 22:59:26 Epoch 4 
2016-12-09 23:06:39 Training Error = 0.91100108180078 
2016-12-09 23:06:39 Training Loss = 0.015258244103387 
2016-12-09 23:06:49 Valid Error = 0.91988019468364 
2016-12-09 23:06:49 Valid Loss = 0.015779920155474 
2016-12-09 23:07:00 Test Error = 0.92792185921186 
2016-12-09 23:07:00 Test Loss = 0.015934875505787 
2016-12-09 23:07:00 -------------------LR------------------- 
2016-12-09 23:07:00 0.015625 
2016-12-09 23:07:00 Epoch 5 
2016-12-09 23:15:31 Training Error = 0.88033619039694 
2016-12-09 23:15:31 Training Loss = 0.0148949028767 
2016-12-09 23:15:41 Valid Error = 0.89142643204792 
2016-12-09 23:15:41 Valid Loss = 0.01506384729091 
2016-12-09 23:15:52 Test Error = 0.88615695520377 
2016-12-09 23:15:52 Test Loss = 0.015142130791669 
2016-12-09 23:15:52 -------------------LR------------------- 
2016-12-09 23:15:52 0.015625 
2016-12-09 23:15:52 Epoch 6 
2016-12-09 23:24:56 Training Error = 0.82824332196056 
2016-12-09 23:24:56 Training Loss = 0.014471456557918 
2016-12-09 23:25:06 Valid Error = 0.84500187195807 
2016-12-09 23:25:06 Valid Loss = 0.01469343316937 
2016-12-09 23:25:17 Test Error = 0.83597170764567 
2016-12-09 23:25:17 Test Loss = 0.01468595011651 
2016-12-09 23:25:17 -------------------LR------------------- 
2016-12-09 23:25:17 0.015625 
2016-12-09 23:25:17 Epoch 7 
2016-12-09 23:34:16 Training Error = 0.75721893983523 
2016-12-09 23:34:16 Training Loss = 0.013991793436859 
2016-12-09 23:34:27 Valid Error = 0.73717708723325 
2016-12-09 23:34:27 Valid Loss = 0.013901902875403 
2016-12-09 23:34:38 Test Error = 0.70798248568542 
2016-12-09 23:34:38 Test Loss = 0.013825590084332 
2016-12-09 23:34:38 -------------------LR------------------- 
2016-12-09 23:34:38 0.015625 
2016-12-09 23:34:38 Epoch 8 
2016-12-09 23:43:36 Training Error = 0.659648830823 
2016-12-09 23:43:36 Training Loss = 0.013549921176411 
2016-12-09 23:43:46 Valid Error = 0.66566828903033 
2016-12-09 23:43:46 Valid Loss = 0.013300591331037 
2016-12-09 23:43:57 Test Error = 0.6476928258673 
2016-12-09 23:43:57 Test Loss = 0.013250050837167 
2016-12-09 23:43:57 -------------------LR------------------- 
2016-12-09 23:43:57 0.015625 
2016-12-09 23:43:57 Epoch 9 
2016-12-09 23:52:47 Training Error = 0.5736456686361 
2016-12-09 23:52:47 Training Loss = 0.013162994928754 
2016-12-09 23:52:57 Valid Error = 0.53013852489704 
2016-12-09 23:52:57 Valid Loss = 0.012539063855192 
2016-12-09 23:53:08 Test Error = 0.52004041764904 
2016-12-09 23:53:08 Test Loss = 0.01239081534098 
2016-12-09 23:53:08 -------------------LR------------------- 
2016-12-09 23:53:08 0.015625 
2016-12-09 23:53:08 Epoch 10 
2016-12-10 00:03:09 Training Error = 0.49263543313639 
2016-12-10 00:03:09 Training Loss = 0.012847295169664 
2016-12-10 00:03:19 Valid Error = 0.52564582553351 
2016-12-10 00:03:19 Valid Loss = 0.012585578818385 
2016-12-10 00:03:30 Test Error = 0.51599865274503 
2016-12-10 00:03:30 Test Loss = 0.012497076150721 
2016-12-10 00:03:30 -------------------LR------------------- 
2016-12-10 00:03:30 0.015625 
2016-12-10 00:03:30 Epoch 11 
2016-12-10 00:12:22 Training Error = 0.44890571690106 
2016-12-10 00:12:22 Training Loss = 0.012660705232893 
2016-12-10 00:12:33 Valid Error = 0.47023586671659 
2016-12-10 00:12:33 Valid Loss = 0.011691443885607 
2016-12-10 00:12:44 Test Error = 0.45638262041091 
2016-12-10 00:12:44 Test Loss = 0.011588007001117 
2016-12-10 00:12:44 -------------------LR------------------- 
2016-12-10 00:12:44 0.015625 
2016-12-10 00:12:44 Epoch 12 
2016-12-10 00:21:21 Training Error = 0.45285845052842 
2016-12-10 00:21:21 Training Loss = 0.012678325899557 
2016-12-10 00:21:31 Valid Error = 0.45675776862598 
2016-12-10 00:21:31 Valid Loss = 0.011698219976363 
2016-12-10 00:21:42 Test Error = 0.44661502189289 
2016-12-10 00:21:42 Test Loss = 0.011602246080382 
2016-12-10 00:21:42 -------------------LR------------------- 
2016-12-10 00:21:42 0.015625 
2016-12-10 00:21:42 Epoch 13 
2016-12-10 00:30:22 Training Error = 0.44848963967712 
2016-12-10 00:30:22 Training Loss = 0.012657293122737 
2016-12-10 00:30:32 Valid Error = 0.46050168476226 
2016-12-10 00:30:32 Valid Loss = 0.01164388259323 
2016-12-10 00:30:43 Test Error = 0.45301448299091 
2016-12-10 00:30:43 Test Loss = 0.011561948045771 
2016-12-10 00:30:43 -------------------LR------------------- 
2016-12-10 00:30:43 0.015625 
2016-12-10 00:30:43 Epoch 14 
2016-12-10 00:39:25 Training Error = 0.45206790380295 
2016-12-10 00:39:25 Training Loss = 0.012664936491427 
2016-12-10 00:39:35 Valid Error = 0.45189067764882 
2016-12-10 00:39:35 Valid Loss = 0.011628260355204 
2016-12-10 00:39:46 Test Error = 0.44257325698889 
2016-12-10 00:39:46 Test Loss = 0.011553255093908 
2016-12-10 00:39:46 -------------------LR------------------- 
2016-12-10 00:39:46 0.015625 
2016-12-10 00:39:46 Epoch 15 
2016-12-10 00:48:23 Training Error = 0.44878089373388 
2016-12-10 00:48:23 Training Loss = 0.012642514011448 
2016-12-10 00:48:33 Valid Error = 0.4825907899663 
2016-12-10 00:48:33 Valid Loss = 0.011770829631136 
2016-12-10 00:48:44 Test Error = 0.47086561131694 
2016-12-10 00:48:44 Test Loss = 0.011679486597385 
2016-12-10 00:48:44 -------------------LR------------------- 
2016-12-10 00:48:44 0.015625 
2016-12-10 00:48:45 Epoch 16 
2016-12-10 00:57:19 Training Error = 0.45073645668636 
2016-12-10 00:57:19 Training Loss = 0.012665880630375 
2016-12-10 00:57:29 Valid Error = 0.46611755896668 
2016-12-10 00:57:29 Valid Loss = 0.011745333165244 
2016-12-10 00:57:40 Test Error = 0.45772987537892 
2016-12-10 00:57:40 Test Loss = 0.011638341342702 
2016-12-10 00:57:40 -------------------LR------------------- 
2016-12-10 00:57:40 0.015625 
2016-12-10 00:57:40 Epoch 17 
2016-12-10 01:06:01 Training Error = 0.45181825746859 
2016-12-10 01:06:01 Training Loss = 0.012677656646863 
2016-12-10 01:06:11 Valid Error = 0.47622613253463 
2016-12-10 01:06:11 Valid Loss = 0.011675473972884 
2016-12-10 01:06:23 Test Error = 0.46177164028292 
2016-12-10 01:06:23 Test Loss = 0.011621391370389 
2016-12-10 01:06:23 -------------------LR------------------- 
2016-12-10 01:06:23 0.015625 
2016-12-10 01:06:23 Epoch 18 
2016-12-10 01:14:23 Training Error = 0.44857285512191 
2016-12-10 01:14:23 Training Loss = 0.012664928142622 
2016-12-10 01:14:33 Valid Error = 0.46274803444403 
2016-12-10 01:14:33 Valid Loss = 0.011698952448615 
2016-12-10 01:14:44 Test Error = 0.4493095318289 
2016-12-10 01:14:44 Test Loss = 0.011586068118767 
2016-12-10 01:14:44 -------------------LR------------------- 
2016-12-10 01:14:44 0.015625 
2016-12-10 01:14:44 Epoch 19 
2016-12-10 01:22:41 Training Error = 0.450486810352 
2016-12-10 01:22:41 Training Loss = 0.012672034708362 
2016-12-10 01:22:51 Valid Error = 0.475851740921 
2016-12-10 01:22:51 Valid Loss = 0.011757415800794 
2016-12-10 01:23:02 Test Error = 0.45975075783092 
2016-12-10 01:23:02 Test Loss = 0.01170252930009 
2016-12-10 01:23:02 -------------------LR------------------- 
2016-12-10 01:23:02 0.015625 
2016-12-10 01:23:02 Epoch 20 
2016-12-10 01:31:13 Training Error = 0.45032037946243 
2016-12-10 01:31:13 Training Loss = 0.012670084737632 
2016-12-10 01:31:23 Valid Error = 0.45937850992138 
2016-12-10 01:31:23 Valid Loss = 0.011674570674954 
2016-12-10 01:31:34 Test Error = 0.4482990906029 
2016-12-10 01:31:34 Test Loss = 0.011591921259276 
2016-12-10 01:31:34 -------------------LR------------------- 
2016-12-10 01:31:34 0.015625 
2016-12-10 01:31:34 Epoch 21 
2016-12-10 01:39:57 Training Error = 0.45177664974619 
2016-12-10 01:39:57 Training Loss = 0.012678000963481 
2016-12-10 01:40:07 Valid Error = 0.46461999251217 
2016-12-10 01:40:07 Valid Loss = 0.011739105571261 
2016-12-10 01:40:18 Test Error = 0.45368811047491 
2016-12-10 01:40:18 Test Loss = 0.011643111818176 
2016-12-10 01:40:18 -------------------LR------------------- 
2016-12-10 01:40:18 0.015625 
2016-12-10 01:40:18 Epoch 22 
2016-12-10 01:48:09 Training Error = 0.45152700341183 
2016-12-10 01:48:09 Training Loss = 0.012663575155509 
2016-12-10 01:48:19 Valid Error = 0.45825533508049 
2016-12-10 01:48:19 Valid Loss = 0.011734383917159 
2016-12-10 01:48:31 Test Error = 0.4482990906029 
2016-12-10 01:48:31 Test Loss = 0.011664736504648 
2016-12-10 01:48:31 -------------------LR------------------- 
2016-12-10 01:48:31 0.015625 
2016-12-10 01:48:31 Epoch 23 
2016-12-10 01:56:38 Training Error = 0.44686693850379 
2016-12-10 01:56:38 Training Loss = 0.01265930322718 
2016-12-10 01:56:48 Valid Error = 0.47360539123924 
2016-12-10 01:56:48 Valid Loss = 0.01169647158387 
2016-12-10 01:57:00 Test Error = 0.46177164028292 
2016-12-10 01:57:00 Test Loss = 0.011617218343029 
2016-12-10 01:57:00 -------------------LR------------------- 
2016-12-10 01:57:00 0.015625 
2016-12-10 01:57:00 Epoch 24 
2016-12-10 02:05:50 Training Error = 0.44749105433969 
2016-12-10 02:05:50 Training Loss = 0.012654005502168 
2016-12-10 02:06:01 Valid Error = 0.46087607637589 
2016-12-10 02:06:01 Valid Loss = 0.01165127981182 
2016-12-10 02:06:12 Test Error = 0.44156281576288 
2016-12-10 02:06:12 Test Loss = 0.011614382308177 
2016-12-10 02:06:12 -------------------LR------------------- 
2016-12-10 02:06:12 0.015625 
2016-12-10 02:06:12 Epoch 25 
2016-12-10 02:14:28 Training Error = 0.45152700341183 
2016-12-10 02:14:28 Training Loss = 0.012666820485143 
2016-12-10 02:14:38 Valid Error = 0.45226506926245 
2016-12-10 02:14:38 Valid Loss = 0.011634772409829 
2016-12-10 02:14:49 Test Error = 0.44594139440889 
2016-12-10 02:14:49 Test Loss = 0.011583148931631 
2016-12-10 02:14:49 -------------------LR------------------- 
2016-12-10 02:14:49 0.015625 
2016-12-10 02:14:49 Epoch 26 
2016-12-10 02:23:07 Training Error = 0.4523591578597 
2016-12-10 02:23:07 Training Loss = 0.012667889931781 
2016-12-10 02:23:17 Valid Error = 0.4784724822164 
2016-12-10 02:23:17 Valid Loss = 0.011678684681626 
2016-12-10 02:23:29 Test Error = 0.46615021892893 
2016-12-10 02:23:29 Test Loss = 0.01160030866455 
2016-12-10 02:23:29 -------------------LR------------------- 
2016-12-10 02:23:29 0.015625 
2016-12-10 02:23:29 Epoch 27 
2016-12-10 02:31:41 Training Error = 0.45040359490721 
2016-12-10 02:31:41 Training Loss = 0.01266622280483 
2016-12-10 02:31:51 Valid Error = 0.47622613253463 
2016-12-10 02:31:51 Valid Loss = 0.011733811462011 
2016-12-10 02:32:02 Test Error = 0.46311889525093 
2016-12-10 02:32:02 Test Loss = 0.011657176859239 
2016-12-10 02:32:02 -------------------LR------------------- 
2016-12-10 02:32:02 0.015625 
2016-12-10 02:32:02 Epoch 28 
2016-12-10 02:40:11 Training Error = 0.45381542814346 
2016-12-10 02:40:11 Training Loss = 0.01267321670859 
2016-12-10 02:40:22 Valid Error = 0.47547734930738 
2016-12-10 02:40:22 Valid Loss = 0.011740532838268 
2016-12-10 02:40:33 Test Error = 0.46379252273493 
2016-12-10 02:40:33 Test Loss = 0.011658095649843 
2016-12-10 02:40:33 -------------------LR------------------- 
2016-12-10 02:40:33 0.015625 
2016-12-10 02:40:33 Epoch 29 
2016-12-10 02:48:49 Training Error = 0.45052841807439 
2016-12-10 02:48:49 Training Loss = 0.012669417102421 
2016-12-10 02:48:59 Valid Error = 0.46274803444403 
2016-12-10 02:48:59 Valid Loss = 0.011716114576907 
2016-12-10 02:49:11 Test Error = 0.44560458066689 
2016-12-10 02:49:11 Test Loss = 0.011632789606246 
2016-12-10 02:49:11 -------------------LR------------------- 
2016-12-10 02:49:11 0.015625 
2016-12-10 02:49:11 Epoch 30 
2016-12-10 02:57:13 Training Error = 0.44994590996089 
2016-12-10 02:57:13 Training Loss = 0.012666562100054 
2016-12-10 02:57:23 Valid Error = 0.48371396480719 
2016-12-10 02:57:23 Valid Loss = 0.011764966922681 
2016-12-10 02:57:35 Test Error = 0.47153923880094 
2016-12-10 02:57:35 Test Loss = 0.011677330565343 
2016-12-10 02:57:35 -------------------LR------------------- 
2016-12-10 02:57:35 0.015625 
2016-12-10 02:57:35 Epoch 31 
2016-12-10 03:05:22 Training Error = 0.44907214779063 
2016-12-10 03:05:22 Training Loss = 0.012663686291572 
2016-12-10 03:05:32 Valid Error = 0.45900411830775 
2016-12-10 03:05:32 Valid Loss = 0.011637829268796 
2016-12-10 03:05:43 Test Error = 0.44493095318289 
2016-12-10 03:05:43 Test Loss = 0.011505762000754 
2016-12-10 03:05:43 -------------------LR------------------- 
2016-12-10 03:05:43 0.015625 
2016-12-10 03:05:43 Epoch 32 
2016-12-10 03:13:27 Training Error = 0.45206790380295 
2016-12-10 03:13:27 Training Loss = 0.012677232054787 
2016-12-10 03:13:37 Valid Error = 0.46312242605766 
2016-12-10 03:13:37 Valid Loss = 0.011645452035616 
2016-12-10 03:13:48 Test Error = 0.4486359043449 
2016-12-10 03:13:48 Test Loss = 0.011573193350781 
2016-12-10 03:13:48 -------------------LR------------------- 
2016-12-10 03:13:48 0.015625 
2016-12-10 03:13:49 Epoch 33 
2016-12-10 03:21:28 Training Error = 0.44998751768328 
2016-12-10 03:21:28 Training Loss = 0.012651742423261 
2016-12-10 03:21:38 Valid Error = 0.46349681767128 
2016-12-10 03:21:38 Valid Loss = 0.01174903332762 
2016-12-10 03:21:49 Test Error = 0.4506567867969 
2016-12-10 03:21:49 Test Loss = 0.011663683923523 
2016-12-10 03:21:49 -------------------LR------------------- 
2016-12-10 03:21:49 0.015625 
2016-12-10 03:21:49 Epoch 34 
2016-12-10 03:29:33 Training Error = 0.45194308063577 
2016-12-10 03:29:33 Training Loss = 0.012673367505606 
2016-12-10 03:29:43 Valid Error = 0.45937850992138 
2016-12-10 03:29:43 Valid Loss = 0.011642057080944 
2016-12-10 03:29:54 Test Error = 0.4489727180869 
2016-12-10 03:29:54 Test Loss = 0.011538767215059 
2016-12-10 03:29:54 -------------------LR------------------- 
2016-12-10 03:29:54 0.015625 
2016-12-10 03:29:54 Epoch 35 
2016-12-10 03:37:41 Training Error = 0.4486560705667 
2016-12-10 03:37:41 Training Loss = 0.012655120503084 
2016-12-10 03:37:51 Valid Error = 0.46836390864845 
2016-12-10 03:37:51 Valid Loss = 0.011669884354754 
2016-12-10 03:38:03 Test Error = 0.45402492421691 
2016-12-10 03:38:03 Test Loss = 0.011570329999546 
2016-12-10 03:38:03 -------------------LR------------------- 
2016-12-10 03:38:03 0.015625 
2016-12-10 03:38:03 Epoch 36 
2016-12-10 03:45:43 Training Error = 0.45302488141799 
2016-12-10 03:45:43 Training Loss = 0.012663900926217 
2016-12-10 03:45:54 Valid Error = 0.4623736428304 
2016-12-10 03:45:54 Valid Loss = 0.011672642894232 
2016-12-10 03:46:05 Test Error = 0.44728864937689 
2016-12-10 03:46:05 Test Loss = 0.011578057950767 
2016-12-10 03:46:05 -------------------LR------------------- 
2016-12-10 03:46:05 0.015625 
2016-12-10 03:46:05 Epoch 37 
2016-12-10 03:53:42 Training Error = 0.4492385786802 
2016-12-10 03:53:42 Training Loss = 0.012665494997875 
2016-12-10 03:53:52 Valid Error = 0.46836390864845 
2016-12-10 03:53:52 Valid Loss = 0.011710265265969 
2016-12-10 03:54:03 Test Error = 0.46042438531492 
2016-12-10 03:54:03 Test Loss = 0.011631720647545 
2016-12-10 03:54:03 -------------------LR------------------- 
2016-12-10 03:54:03 0.015625 
2016-12-10 03:54:03 Epoch 38 
2016-12-10 04:01:14 Training Error = 0.45169343430141 
2016-12-10 04:01:14 Training Loss = 0.012670826933136 
2016-12-10 04:01:24 Valid Error = 0.46050168476226 
2016-12-10 04:01:24 Valid Loss = 0.011696980514252 
2016-12-10 04:01:35 Test Error = 0.4479622768609 
2016-12-10 04:01:35 Test Loss = 0.011603231496894 
2016-12-10 04:01:35 -------------------LR------------------- 
2016-12-10 04:01:35 0.015625 
2016-12-10 04:01:35 Epoch 39 
2016-12-10 04:08:51 Training Error = 0.45106931846551 
2016-12-10 04:08:51 Training Loss = 0.012659059299241 
2016-12-10 04:09:01 Valid Error = 0.46836390864845 
2016-12-10 04:09:01 Valid Loss = 0.011704601332497 
2016-12-10 04:09:12 Test Error = 0.45368811047491 
2016-12-10 04:09:12 Test Loss = 0.011608702634542 
2016-12-10 04:09:12 -------------------LR------------------- 
2016-12-10 04:09:12 0.015625 
2016-12-10 04:09:12 Epoch 40 
2016-12-10 04:16:29 Training Error = 0.45306648914038 
2016-12-10 04:16:29 Training Loss = 0.012671445613814 
2016-12-10 04:16:39 Valid Error = 0.46761512542119 
2016-12-10 04:16:39 Valid Loss = 0.011645339443617 
2016-12-10 04:16:50 Test Error = 0.45436173795891 
2016-12-10 04:16:50 Test Loss = 0.011555476262264 
2016-12-10 04:16:50 -------------------LR------------------- 
2016-12-10 04:16:50 0.015625 
2016-12-10 04:16:50 Epoch 41 
2016-12-10 04:24:04 Training Error = 0.45510526753766 
2016-12-10 04:24:04 Training Loss = 0.012690280676444 
2016-12-10 04:24:14 Valid Error = 0.47098464994384 
2016-12-10 04:24:14 Valid Loss = 0.011638913668601 
2016-12-10 04:24:25 Test Error = 0.46345570899293 
2016-12-10 04:24:25 Test Loss = 0.011542101610587 
2016-12-10 04:24:25 -------------------LR------------------- 
2016-12-10 04:24:25 0.015625 
2016-12-10 04:24:25 Epoch 42 
2016-12-10 04:31:34 Training Error = 0.45098610302072 
2016-12-10 04:31:34 Training Loss = 0.012662510516123 
2016-12-10 04:31:44 Valid Error = 0.48071883189817 
2016-12-10 04:31:44 Valid Loss = 0.01173721171961 
2016-12-10 04:31:55 Test Error = 0.47457056247895 
2016-12-10 04:31:55 Test Loss = 0.01165442520288 
2016-12-10 04:31:55 -------------------LR------------------- 
2016-12-10 04:31:55 0.015625 
2016-12-10 04:31:55 Epoch 43 
2016-12-10 04:39:10 Training Error = 0.45523009070483 
2016-12-10 04:39:10 Training Loss = 0.012676354592328 
2016-12-10 04:39:20 Valid Error = 0.46274803444403 
2016-12-10 04:39:20 Valid Loss = 0.01162297863887 
2016-12-10 04:39:31 Test Error = 0.4482990906029 
2016-12-10 04:39:31 Test Loss = 0.011542669039246 
2016-12-10 04:39:31 -------------------LR------------------- 
2016-12-10 04:39:31 0.015625 
2016-12-10 04:39:31 Epoch 44 
2016-12-10 04:46:42 Training Error = 0.45185986519098 
2016-12-10 04:46:42 Training Loss = 0.012659841166376 
2016-12-10 04:46:52 Valid Error = 0.47772369898914 
2016-12-10 04:46:52 Valid Loss = 0.011673776783761 
2016-12-10 04:47:03 Test Error = 0.46042438531492 
2016-12-10 04:47:03 Test Loss = 0.011596301852637 
2016-12-10 04:47:03 -------------------LR------------------- 
2016-12-10 04:47:03 0.015625 
2016-12-10 04:47:03 Epoch 45 
2016-12-10 04:54:16 Training Error = 0.45210951152534 
2016-12-10 04:54:16 Training Loss = 0.012665607450392 
2016-12-10 04:54:26 Valid Error = 0.47248221639835 
2016-12-10 04:54:26 Valid Loss = 0.011640490736195 
2016-12-10 04:54:37 Test Error = 0.46278208150893 
2016-12-10 04:54:37 Test Loss = 0.011559406765113 
2016-12-10 04:54:37 -------------------LR------------------- 
2016-12-10 04:54:37 0.015625 
2016-12-10 04:54:37 Epoch 46 
2016-12-10 05:01:48 Training Error = 0.45194308063577 
2016-12-10 05:01:48 Training Loss = 0.012664568135775 
2016-12-10 05:01:58 Valid Error = 0.475851740921 
2016-12-10 05:01:58 Valid Loss = 0.011725845497859 
2016-12-10 05:02:09 Test Error = 0.46076119905692 
2016-12-10 05:02:09 Test Loss = 0.011623638951982 
2016-12-10 05:02:09 -------------------LR------------------- 
2016-12-10 05:02:09 0.015625 
2016-12-10 05:02:09 Epoch 47 
2016-12-10 05:09:22 Training Error = 0.44857285512191 
2016-12-10 05:09:22 Training Loss = 0.012661471081124 
2016-12-10 05:09:32 Valid Error = 0.46836390864845 
2016-12-10 05:09:32 Valid Loss = 0.011698764399791 
2016-12-10 05:09:43 Test Error = 0.45537217918491 
2016-12-10 05:09:43 Test Loss = 0.011607497120182 
2016-12-10 05:09:43 -------------------LR------------------- 
2016-12-10 05:09:43 0.015625 
2016-12-10 05:09:43 Epoch 48 
2016-12-10 05:16:53 Training Error = 0.44882250145627 
2016-12-10 05:16:53 Training Loss = 0.012657790891366 
2016-12-10 05:17:03 Valid Error = 0.46948708348933 
2016-12-10 05:17:03 Valid Loss = 0.01165335370154 
2016-12-10 05:17:15 Test Error = 0.45772987537892 
2016-12-10 05:17:15 Test Loss = 0.011570495284792 
2016-12-10 05:17:15 -------------------LR------------------- 
2016-12-10 05:17:15 0.015625 
2016-12-10 05:17:15 Epoch 49 
2016-12-10 05:24:25 Training Error = 0.44994590996089 
2016-12-10 05:24:25 Training Loss = 0.012664683413987 
2016-12-10 05:24:36 Valid Error = 0.47323099962561 
2016-12-10 05:24:36 Valid Loss = 0.011654482389028 
2016-12-10 05:24:47 Test Error = 0.45705624789491 
2016-12-10 05:24:47 Test Loss = 0.01156023910914 
2016-12-10 05:24:47 -------------------LR------------------- 
2016-12-10 05:24:47 0.015625 
2016-12-10 05:24:47 Epoch 50 
2016-12-10 05:32:01 Training Error = 0.45377382042107 
2016-12-10 05:32:01 Training Loss = 0.012667406860043 
2016-12-10 05:32:11 Valid Error = 0.47997004867091 
2016-12-10 05:32:11 Valid Loss = 0.011731987185465 
2016-12-10 05:32:22 Test Error = 0.47187605254294 
2016-12-10 05:32:22 Test Loss = 0.011642091517952 
2016-12-10 05:32:22 -------------------LR------------------- 
2016-12-10 05:32:22 0.0078125 
2016-12-10 05:32:22 Epoch 51 
2016-12-10 05:39:35 Training Error = 0.45414828992261 
2016-12-10 05:39:35 Training Loss = 0.012691684268484 
2016-12-10 05:39:46 Valid Error = 0.46536877573942 
2016-12-10 05:39:46 Valid Loss = 0.011714942499293 
2016-12-10 05:39:57 Test Error = 0.45671943415291 
2016-12-10 05:39:57 Test Loss = 0.011615871158102 
2016-12-10 05:39:57 -------------------LR------------------- 
2016-12-10 05:39:57 0.0078125 
2016-12-10 05:39:57 Epoch 52 
2016-12-10 05:47:25 Training Error = 0.45023716401764 
2016-12-10 05:47:25 Training Loss = 0.012658620575325 
2016-12-10 05:47:35 Valid Error = 0.45638337701235 
2016-12-10 05:47:35 Valid Loss = 0.011748781762082 
2016-12-10 05:47:47 Test Error = 0.44156281576288 
2016-12-10 05:47:47 Test Loss = 0.011639982527477 
2016-12-10 05:47:47 -------------------LR------------------- 
2016-12-10 05:47:47 0.0078125 
2016-12-10 05:47:47 Epoch 53 
2016-12-10 05:55:55 Training Error = 0.45007073312807 
2016-12-10 05:55:55 Training Loss = 0.012658424853149 
2016-12-10 05:56:05 Valid Error = 0.46798951703482 
2016-12-10 05:56:05 Valid Loss = 0.01170193928962 
2016-12-10 05:56:17 Test Error = 0.45874031660492 
2016-12-10 05:56:17 Test Loss = 0.011631729106879 
2016-12-10 05:56:17 -------------------LR------------------- 
2016-12-10 05:56:17 0.0078125 
2016-12-10 05:56:17 Epoch 54 
2016-12-10 06:04:30 Training Error = 0.45098610302072 
2016-12-10 06:04:30 Training Loss = 0.012657988826062 
2016-12-10 06:04:40 Valid Error = 0.44402845376264 
2016-12-10 06:04:40 Valid Loss = 0.011681814997217 
2016-12-10 06:04:51 Test Error = 0.43145840350286 
2016-12-10 06:04:51 Test Loss = 0.011606039955957 
2016-12-10 06:04:51 -------------------LR------------------- 
2016-12-10 06:04:51 0.0078125 
2016-12-10 06:04:51 Epoch 55 
2016-12-10 06:13:58 Training Error = 0.44632603811267 
2016-12-10 06:13:58 Training Loss = 0.012654065337485 
2016-12-10 06:14:09 Valid Error = 0.48333957319356 
2016-12-10 06:14:09 Valid Loss = 0.011782454699293 
2016-12-10 06:14:21 Test Error = 0.47221286628494 
2016-12-10 06:14:21 Test Loss = 0.011697603635505 
2016-12-10 06:14:21 -------------------LR------------------- 
2016-12-10 06:14:21 0.0078125 
2016-12-10 06:14:21 Epoch 56 
2016-12-10 06:22:35 Training Error = 0.45410668220022 
2016-12-10 06:22:35 Training Loss = 0.012671727345921 
2016-12-10 06:22:45 Valid Error = 0.4623736428304 
2016-12-10 06:22:45 Valid Loss = 0.011753857060226 
2016-12-10 06:22:56 Test Error = 0.44291007073089 
2016-12-10 06:22:56 Test Loss = 0.011691927682672 
2016-12-10 06:22:56 -------------------LR------------------- 
2016-12-10 06:22:56 0.0078125 
2016-12-10 06:22:56 Epoch 57 
2016-12-10 06:31:47 Training Error = 0.44907214779063 
2016-12-10 06:31:47 Training Loss = 0.012667640475613 
2016-12-10 06:31:57 Valid Error = 0.45713216023961 
2016-12-10 06:31:57 Valid Loss = 0.011636518506092 
2016-12-10 06:32:08 Test Error = 0.4503199730549 
2016-12-10 06:32:08 Test Loss = 0.011562828597895 
2016-12-10 06:32:08 -------------------LR------------------- 
2016-12-10 06:32:08 0.0078125 
2016-12-10 06:32:08 Epoch 58 
2016-12-10 06:41:03 Training Error = 0.45352417408671 
2016-12-10 06:41:03 Training Loss = 0.012686276557697 
2016-12-10 06:41:13 Valid Error = 0.47098464994384 
2016-12-10 06:41:13 Valid Loss = 0.011749284109749 
2016-12-10 06:41:24 Test Error = 0.45806668912092 
2016-12-10 06:41:24 Test Loss = 0.011670446704615 
2016-12-10 06:41:24 -------------------LR------------------- 
2016-12-10 06:41:24 0.0078125 
2016-12-10 06:41:24 Epoch 59 
2016-12-10 06:50:21 Training Error = 0.45210951152534 
2016-12-10 06:50:21 Training Loss = 0.012663356393635 
2016-12-10 06:50:31 Valid Error = 0.46012729314863 
2016-12-10 06:50:31 Valid Loss = 0.011684470110197 
2016-12-10 06:50:42 Test Error = 0.45301448299091 
2016-12-10 06:50:42 Test Loss = 0.011610354763695 
2016-12-10 06:50:42 -------------------LR------------------- 
2016-12-10 06:50:42 0.0078125 
2016-12-10 06:50:43 Epoch 60 
