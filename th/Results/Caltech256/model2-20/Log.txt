2016-12-10 06:51:03 [program started on Sat Dec 10 06:51:03 2016] 
2016-12-10 06:51:03 [command line arguments] 
2016-12-10 06:51:03 stcWeights false 
2016-12-10 06:51:03 LR 0.015625 
2016-12-10 06:51:03 batchSize 64 
2016-12-10 06:51:03 network ./Models/Cifar10_Custom 
2016-12-10 06:51:03 stcNeurons true 
2016-12-10 06:51:03 constBatchSize false 
2016-12-10 06:51:03 chartFileName chart1 
2016-12-10 06:51:03 dp_prepro false 
2016-12-10 06:51:03 nGPU 1 
2016-12-10 06:51:03 dataset Caltech256 
2016-12-10 06:51:03 type cuda 
2016-12-10 06:51:03 momentum 0 
2016-12-10 06:51:03 threads 8 
2016-12-10 06:51:03 weightDecay 0 
2016-12-10 06:51:03 runningVal false 
2016-12-10 06:51:03 convLayerN 2 
2016-12-10 06:51:03 LRDecay 0 
2016-12-10 06:51:03 numHid 1024 
2016-12-10 06:51:03 save /dev/shm/clone/temp/th/Results/Caltech256/model2-20 
2016-12-10 06:51:03 augment false 
2016-12-10 06:51:03 epoch -1 
2016-12-10 06:51:03 modelsFolder ./Models/ 
2016-12-10 06:51:03 format rgb 
2016-12-10 06:51:03 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 06:51:03 imageFileExtension svg 
2016-12-10 06:51:03 channel 2 
2016-12-10 06:51:03 devid 2 
2016-12-10 06:51:03 visualize 1 
2016-12-10 06:51:03 LRDecayPerEpoch 0.0001 
2016-12-10 06:51:03 optimization adam 
2016-12-10 06:51:03 SBN true 
2016-12-10 06:51:03 normalization simple 
2016-12-10 06:51:03 title model1 
2016-12-10 06:51:03 load  
2016-12-10 06:51:03 whiten true 
2016-12-10 06:51:03 [----------------------] 
2016-12-10 06:51:07 ==> Network 
2016-12-10 06:51:07 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 256, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): nn.View(65536)
  (11): BinaryLinear(65536 -> 1024)
  (12): BatchNormalizationShiftPow2
  (13): nn.HardTanh
  (14): BinarizedNeurons
  (15): BinaryLinear(1024 -> 1024)
  (16): BatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): BinaryLinear(1024 -> 255)
  (20): nn.BatchNormalization
} 
2016-12-10 06:51:07 ==>69023741 Parameters 
2016-12-10 06:51:07 ==> Loss 
2016-12-10 06:51:07 SqrtHingeEmbeddingCriterion 
2016-12-10 06:51:07 
==> Starting Training
 
2016-12-10 06:51:07 Epoch 1 
2016-12-10 06:58:00 Training Error = 0.95801780810518 
2016-12-10 06:58:00 Training Loss = 0.11232111136452 
2016-12-10 06:58:09 Valid Error = 0.9273680269562 
2016-12-10 06:58:09 Valid Loss = 0.015629215678316 
2016-12-10 06:58:18 Test Error = 0.93432132030987 
2016-12-10 06:58:18 Test Loss = 0.015618006272171 
2016-12-10 06:58:18 -------------------LR------------------- 
2016-12-10 06:58:18 0.015625 
2016-12-10 06:58:18 Epoch 2 
2016-12-10 07:05:07 Training Error = 0.88790879587251 
2016-12-10 07:05:07 Training Loss = 0.015115767594054 
2016-12-10 07:05:16 Valid Error = 0.86259827779858 
2016-12-10 07:05:16 Valid Loss = 0.014717424967118 
2016-12-10 07:05:25 Test Error = 0.87908386662176 
2016-12-10 07:05:25 Test Loss = 0.014899785316731 
2016-12-10 07:05:25 -------------------LR------------------- 
2016-12-10 07:05:25 0.015625 
2016-12-10 07:05:25 Epoch 3 
2016-12-10 07:12:17 Training Error = 0.78060247982025 
2016-12-10 07:12:17 Training Loss = 0.014287242222635 
2016-12-10 07:12:25 Valid Error = 0.71359041557469 
2016-12-10 07:12:25 Valid Loss = 0.013714634164131 
2016-12-10 07:12:35 Test Error = 0.72145503536544 
2016-12-10 07:12:35 Test Loss = 0.013760720775383 
2016-12-10 07:12:35 -------------------LR------------------- 
2016-12-10 07:12:35 0.015625 
2016-12-10 07:12:35 Epoch 4 
2016-12-10 07:19:31 Training Error = 0.64379628859116 
2016-12-10 07:19:31 Training Loss = 0.013498182585963 
2016-12-10 07:19:40 Valid Error = 0.47660052414826 
2016-12-10 07:19:40 Valid Loss = 0.011794210409103 
2016-12-10 07:19:49 Test Error = 0.47019198383294 
2016-12-10 07:19:49 Test Loss = 0.011772253702519 
2016-12-10 07:19:49 -------------------LR------------------- 
2016-12-10 07:19:49 0.015625 
2016-12-10 07:19:49 Epoch 5 
2016-12-10 07:26:44 Training Error = 0.48905716901057 
2016-12-10 07:26:44 Training Loss = 0.01278194314281 
2016-12-10 07:26:52 Valid Error = 0.36503182328716 
2016-12-10 07:26:52 Valid Loss = 0.010712918132206 
2016-12-10 07:27:01 Test Error = 0.35870663523072 
2016-12-10 07:27:01 Test Loss = 0.010640263838722 
2016-12-10 07:27:01 -------------------LR------------------- 
2016-12-10 07:27:01 0.015625 
2016-12-10 07:27:01 Epoch 6 
2016-12-10 07:33:55 Training Error = 0.37542647915453 
2016-12-10 07:33:55 Training Loss = 0.012263508857887 
2016-12-10 07:34:03 Valid Error = 0.30849868962935 
2016-12-10 07:34:03 Valid Loss = 0.009631665990073 
2016-12-10 07:34:12 Test Error = 0.31424722128663 
2016-12-10 07:34:12 Test Loss = 0.0095963352996705 
2016-12-10 07:34:12 -------------------LR------------------- 
2016-12-10 07:34:12 0.015625 
2016-12-10 07:34:12 Epoch 7 
2016-12-10 07:41:09 Training Error = 0.31384705001248 
2016-12-10 07:41:09 Training Loss = 0.011877592602883 
2016-12-10 07:41:17 Valid Error = 0.25009359790341 
2016-12-10 07:41:17 Valid Loss = 0.0086410698993088 
2016-12-10 07:41:26 Test Error = 0.25294712024251 
2016-12-10 07:41:26 Test Loss = 0.0086071178932015 
2016-12-10 07:41:26 -------------------LR------------------- 
2016-12-10 07:41:26 0.015625 
2016-12-10 07:41:26 Epoch 8 
2016-12-10 07:48:18 Training Error = 0.27731546975119 
2016-12-10 07:48:18 Training Loss = 0.011609269467046 
2016-12-10 07:48:26 Valid Error = 0.26843878697117 
2016-12-10 07:48:26 Valid Loss = 0.0085378842953739 
2016-12-10 07:48:35 Test Error = 0.26204109127652 
2016-12-10 07:48:35 Test Loss = 0.0084342587681477 
2016-12-10 07:48:35 -------------------LR------------------- 
2016-12-10 07:48:35 0.015625 
2016-12-10 07:48:35 Epoch 9 
2016-12-10 07:55:27 Training Error = 0.24839810268786 
2016-12-10 07:55:27 Training Loss = 0.011381366602988 
2016-12-10 07:55:36 Valid Error = 0.24372894047173 
2016-12-10 07:55:36 Valid Loss = 0.0079395455361303 
2016-12-10 07:55:45 Test Error = 0.23981138430448 
2016-12-10 07:55:45 Test Loss = 0.0078750355218816 
2016-12-10 07:55:45 -------------------LR------------------- 
2016-12-10 07:55:45 0.015625 
2016-12-10 07:55:45 Epoch 10 
2016-12-10 08:02:16 Training Error = 0.2357909628027 
2016-12-10 08:02:16 Training Loss = 0.01118719310593 
2016-12-10 08:02:24 Valid Error = 0.22014226881318 
2016-12-10 08:02:24 Valid Loss = 0.0072426166921297 
2016-12-10 08:02:33 Test Error = 0.21623442236443 
2016-12-10 08:02:33 Test Loss = 0.0071850382849033 
2016-12-10 08:02:33 -------------------LR------------------- 
2016-12-10 08:02:33 0.015625 
2016-12-10 08:02:33 Epoch 11 
2016-12-10 08:08:56 Training Error = 0.22322543063993 
2016-12-10 08:08:56 Training Loss = 0.011061155774988 
2016-12-10 08:09:04 Valid Error = 0.19767877199551 
2016-12-10 08:09:04 Valid Loss = 0.0065551372154333 
2016-12-10 08:09:13 Test Error = 0.18996295048838 
2016-12-10 08:09:13 Test Loss = 0.0064882843004051 
2016-12-10 08:09:13 -------------------LR------------------- 
2016-12-10 08:09:13 0.015625 
2016-12-10 08:09:13 Epoch 12 
2016-12-10 08:15:33 Training Error = 0.2245984854789 
2016-12-10 08:15:33 Training Loss = 0.011087311683583 
2016-12-10 08:15:41 Valid Error = 0.19580681392737 
2016-12-10 08:15:41 Valid Loss = 0.0066544255385806 
2016-12-10 08:15:50 Test Error = 0.18827888177838 
2016-12-10 08:15:50 Test Loss = 0.006571019803677 
2016-12-10 08:15:50 -------------------LR------------------- 
2016-12-10 08:15:50 0.015625 
2016-12-10 08:15:50 Epoch 13 
2016-12-10 08:22:12 Training Error = 0.22218523758009 
2016-12-10 08:22:12 Training Loss = 0.011078791033227 
2016-12-10 08:22:21 Valid Error = 0.19805316360914 
2016-12-10 08:22:21 Valid Loss = 0.0065243616287805 
2016-12-10 08:22:30 Test Error = 0.18895250926238 
2016-12-10 08:22:30 Test Loss = 0.0064651588890321 
2016-12-10 08:22:30 -------------------LR------------------- 
2016-12-10 08:22:30 0.015625 
2016-12-10 08:22:30 Epoch 14 
2016-12-10 08:28:55 Training Error = 0.22434883914455 
2016-12-10 08:28:55 Training Loss = 0.011066756533062 
2016-12-10 08:29:03 Valid Error = 0.19505803070011 
2016-12-10 08:29:03 Valid Loss = 0.0066071182214089 
2016-12-10 08:29:12 Test Error = 0.18659481306837 
2016-12-10 08:29:12 Test Loss = 0.006544960322756 
2016-12-10 08:29:12 -------------------LR------------------- 
2016-12-10 08:29:12 0.015625 
2016-12-10 08:29:12 Epoch 15 
2016-12-10 08:35:36 Training Error = 0.22047932096197 
2016-12-10 08:35:36 Training Loss = 0.011071418622493 
2016-12-10 08:35:44 Valid Error = 0.19917633845002 
2016-12-10 08:35:44 Valid Loss = 0.0066514912704903 
2016-12-10 08:35:53 Test Error = 0.19131020545638 
2016-12-10 08:35:53 Test Loss = 0.0065845691607702 
2016-12-10 08:35:53 -------------------LR------------------- 
2016-12-10 08:35:53 0.015625 
2016-12-10 08:35:53 Epoch 16 
2016-12-10 08:42:15 Training Error = 0.22305899975035 
2016-12-10 08:42:15 Training Loss = 0.011048693510093 
2016-12-10 08:42:23 Valid Error = 0.19505803070011 
2016-12-10 08:42:23 Valid Loss = 0.0065210335804618 
2016-12-10 08:42:32 Test Error = 0.18659481306837 
2016-12-10 08:42:32 Test Loss = 0.0064492764530651 
2016-12-10 08:42:32 -------------------LR------------------- 
2016-12-10 08:42:32 0.015625 
2016-12-10 08:42:32 Epoch 17 
2016-12-10 08:48:54 Training Error = 0.22326703836232 
2016-12-10 08:48:54 Training Loss = 0.011047526845236 
2016-12-10 08:49:02 Valid Error = 0.19992512167727 
2016-12-10 08:49:02 Valid Loss = 0.0066382221230014 
2016-12-10 08:49:12 Test Error = 0.19299427416639 
2016-12-10 08:49:12 Test Loss = 0.0065633199753043 
2016-12-10 08:49:12 -------------------LR------------------- 
2016-12-10 08:49:12 0.015625 
2016-12-10 08:49:12 Epoch 18 
2016-12-10 08:55:35 Training Error = 0.2221436298577 
2016-12-10 08:55:35 Training Loss = 0.011054853140736 
2016-12-10 08:55:44 Valid Error = 0.19243728940472 
2016-12-10 08:55:44 Valid Loss = 0.0066254741652427 
2016-12-10 08:55:53 Test Error = 0.18187942068036 
2016-12-10 08:55:53 Test Loss = 0.0065399713018908 
2016-12-10 08:55:53 -------------------LR------------------- 
2016-12-10 08:55:53 0.015625 
2016-12-10 08:55:53 Epoch 19 
2016-12-10 09:02:13 Training Error = 0.22380793875343 
2016-12-10 09:02:13 Training Loss = 0.011083968455708 
2016-12-10 09:02:22 Valid Error = 0.19505803070011 
2016-12-10 09:02:22 Valid Loss = 0.0065384118814213 
2016-12-10 09:02:31 Test Error = 0.18659481306837 
2016-12-10 09:02:31 Test Loss = 0.0064576536233494 
2016-12-10 09:02:31 -------------------LR------------------- 
2016-12-10 09:02:31 0.015625 
2016-12-10 09:02:31 Epoch 20 
2016-12-10 09:08:55 Training Error = 0.22380793875343 
2016-12-10 09:08:55 Training Loss = 0.011083434585963 
2016-12-10 09:09:03 Valid Error = 0.19505803070011 
2016-12-10 09:09:03 Valid Loss = 0.0064812106879388 
2016-12-10 09:09:12 Test Error = 0.18659481306837 
2016-12-10 09:09:12 Test Loss = 0.0064183594926875 
2016-12-10 09:09:12 -------------------LR------------------- 
2016-12-10 09:09:12 0.015625 
2016-12-10 09:09:12 Epoch 21 
2016-12-10 09:15:31 Training Error = 0.2233918615295 
2016-12-10 09:15:31 Training Loss = 0.011076771336224 
2016-12-10 09:15:39 Valid Error = 0.19206289779109 
2016-12-10 09:15:39 Valid Loss = 0.0065138872555438 
2016-12-10 09:15:48 Test Error = 0.18322667564837 
2016-12-10 09:15:48 Test Loss = 0.0064518047053465 
2016-12-10 09:15:48 -------------------LR------------------- 
2016-12-10 09:15:48 0.015625 
2016-12-10 09:15:48 Epoch 22 
2016-12-10 09:22:13 Training Error = 0.22484813181326 
2016-12-10 09:22:13 Training Loss = 0.011064536129496 
2016-12-10 09:22:21 Valid Error = 0.19505803070011 
2016-12-10 09:22:21 Valid Loss = 0.0066460393039571 
2016-12-10 09:22:31 Test Error = 0.18659481306837 
2016-12-10 09:22:31 Test Loss = 0.0065822656804142 
2016-12-10 09:22:31 -------------------LR------------------- 
2016-12-10 09:22:31 0.015625 
2016-12-10 09:22:31 Epoch 23 
2016-12-10 09:28:51 Training Error = 0.22218523758009 
2016-12-10 09:28:51 Training Loss = 0.011059965985009 
2016-12-10 09:28:59 Valid Error = 0.19243728940472 
2016-12-10 09:28:59 Valid Loss = 0.0064959322264499 
2016-12-10 09:29:08 Test Error = 0.18390030313237 
2016-12-10 09:29:08 Test Loss = 0.0064305391777144 
2016-12-10 09:29:08 -------------------LR------------------- 
2016-12-10 09:29:08 0.015625 
2016-12-10 09:29:08 Epoch 24 
2016-12-10 09:35:30 Training Error = 0.22530581675959 
2016-12-10 09:35:30 Training Loss = 0.011070936590023 
2016-12-10 09:35:39 Valid Error = 0.19580681392737 
2016-12-10 09:35:39 Valid Loss = 0.0066216197346259 
2016-12-10 09:35:48 Test Error = 0.18827888177838 
2016-12-10 09:35:48 Test Loss = 0.0065666534923542 
2016-12-10 09:35:48 -------------------LR------------------- 
2016-12-10 09:35:48 0.015625 
2016-12-10 09:35:48 Epoch 25 
2016-12-10 09:42:10 Training Error = 0.22068735957394 
2016-12-10 09:42:10 Training Loss = 0.011053738975037 
2016-12-10 09:42:18 Valid Error = 0.19580681392737 
2016-12-10 09:42:18 Valid Loss = 0.0066031064950144 
2016-12-10 09:42:27 Test Error = 0.18827888177838 
2016-12-10 09:42:27 Test Loss = 0.0065443668826998 
2016-12-10 09:42:27 -------------------LR------------------- 
2016-12-10 09:42:27 0.015625 
2016-12-10 09:42:27 Epoch 26 
2016-12-10 09:48:52 Training Error = 0.22534742448198 
2016-12-10 09:48:52 Training Loss = 0.01106639241493 
2016-12-10 09:49:01 Valid Error = 0.19505803070011 
2016-12-10 09:49:01 Valid Loss = 0.0065896583306343 
2016-12-10 09:49:10 Test Error = 0.18659481306837 
2016-12-10 09:49:10 Test Loss = 0.0065091778234387 
2016-12-10 09:49:10 -------------------LR------------------- 
2016-12-10 09:49:10 0.015625 
2016-12-10 09:49:10 Epoch 27 
2016-12-10 09:55:32 Training Error = 0.22280935341599 
2016-12-10 09:55:32 Training Loss = 0.011071481314222 
2016-12-10 09:55:40 Valid Error = 0.19243728940472 
2016-12-10 09:55:40 Valid Loss = 0.0065609945700446 
2016-12-10 09:55:49 Test Error = 0.18390030313237 
2016-12-10 09:55:49 Test Loss = 0.0065004167369768 
2016-12-10 09:55:49 -------------------LR------------------- 
2016-12-10 09:55:49 0.015625 
2016-12-10 09:55:49 Epoch 28 
2016-12-10 10:02:12 Training Error = 0.2209370059083 
2016-12-10 10:02:12 Training Loss = 0.011056480618874 
2016-12-10 10:02:20 Valid Error = 0.19505803070011 
2016-12-10 10:02:20 Valid Loss = 0.0065458828521897 
2016-12-10 10:02:29 Test Error = 0.18659481306837 
2016-12-10 10:02:29 Test Loss = 0.0064773699904065 
2016-12-10 10:02:29 -------------------LR------------------- 
2016-12-10 10:02:29 0.015625 
2016-12-10 10:02:29 Epoch 29 
2016-12-10 10:08:54 Training Error = 0.22222684530249 
2016-12-10 10:08:54 Training Loss = 0.011053349999036 
2016-12-10 10:09:03 Valid Error = 0.19805316360914 
2016-12-10 10:09:03 Valid Loss = 0.0065134330678427 
2016-12-10 10:09:12 Test Error = 0.18895250926238 
2016-12-10 10:09:12 Test Loss = 0.0064389495638743 
2016-12-10 10:09:12 -------------------LR------------------- 
2016-12-10 10:09:12 0.015625 
2016-12-10 10:09:12 Epoch 30 
2016-12-10 10:15:45 Training Error = 0.22206041441292 
2016-12-10 10:15:45 Training Loss = 0.011058259027721 
2016-12-10 10:15:53 Valid Error = 0.19243728940472 
2016-12-10 10:15:53 Valid Loss = 0.0065644723270619 
2016-12-10 10:16:02 Test Error = 0.18187942068036 
2016-12-10 10:16:02 Test Loss = 0.0064751176261186 
2016-12-10 10:16:02 -------------------LR------------------- 
2016-12-10 10:16:02 0.015625 
2016-12-10 10:16:02 Epoch 31 
2016-12-10 10:22:37 Training Error = 0.22305899975035 
2016-12-10 10:22:37 Training Loss = 0.011055415108726 
2016-12-10 10:22:45 Valid Error = 0.19580681392737 
2016-12-10 10:22:45 Valid Loss = 0.006575899670779 
2016-12-10 10:22:54 Test Error = 0.18827888177838 
2016-12-10 10:22:54 Test Loss = 0.0064989204621584 
2016-12-10 10:22:54 -------------------LR------------------- 
2016-12-10 10:22:54 0.015625 
2016-12-10 10:22:54 Epoch 32 
2016-12-10 10:29:28 Training Error = 0.22197719896813 
2016-12-10 10:29:28 Training Loss = 0.011070877094059 
2016-12-10 10:29:36 Valid Error = 0.19505803070011 
2016-12-10 10:29:36 Valid Loss = 0.006561227322411 
2016-12-10 10:29:45 Test Error = 0.18659481306837 
2016-12-10 10:29:45 Test Loss = 0.0064971778505188 
2016-12-10 10:29:45 -------------------LR------------------- 
2016-12-10 10:29:45 0.015625 
2016-12-10 10:29:45 Epoch 33 
2016-12-10 10:36:20 Training Error = 0.22231006074727 
2016-12-10 10:36:20 Training Loss = 0.01104359214442 
2016-12-10 10:36:28 Valid Error = 0.19505803070011 
2016-12-10 10:36:28 Valid Loss = 0.0065872153934696 
2016-12-10 10:36:37 Test Error = 0.18659481306837 
2016-12-10 10:36:37 Test Loss = 0.0065300662255954 
2016-12-10 10:36:37 -------------------LR------------------- 
2016-12-10 10:36:37 0.015625 
2016-12-10 10:36:37 Epoch 34 
2016-12-10 10:43:10 Training Error = 0.2258883248731 
2016-12-10 10:43:10 Training Loss = 0.011083004187741 
2016-12-10 10:43:19 Valid Error = 0.19805316360914 
2016-12-10 10:43:19 Valid Loss = 0.0065384023734757 
2016-12-10 10:43:28 Test Error = 0.18895250926238 
2016-12-10 10:43:28 Test Loss = 0.0064605607735797 
2016-12-10 10:43:28 -------------------LR------------------- 
2016-12-10 10:43:28 0.015625 
2016-12-10 10:43:28 Epoch 35 
2016-12-10 10:50:02 Training Error = 0.22326703836232 
2016-12-10 10:50:02 Training Loss = 0.011062734398059 
2016-12-10 10:50:10 Valid Error = 0.19580681392737 
2016-12-10 10:50:10 Valid Loss = 0.0065677389479139 
2016-12-10 10:50:19 Test Error = 0.18827888177838 
2016-12-10 10:50:19 Test Loss = 0.0065117286181619 
2016-12-10 10:50:19 -------------------LR------------------- 
2016-12-10 10:50:19 0.015625 
2016-12-10 10:50:19 Epoch 36 
2016-12-10 10:56:50 Training Error = 0.22380793875343 
2016-12-10 10:56:50 Training Loss = 0.01104766565667 
2016-12-10 10:56:59 Valid Error = 0.19505803070011 
2016-12-10 10:56:59 Valid Loss = 0.0065613884170568 
2016-12-10 10:57:08 Test Error = 0.18659481306837 
2016-12-10 10:57:08 Test Loss = 0.0065057083674158 
2016-12-10 10:57:08 -------------------LR------------------- 
2016-12-10 10:57:08 0.015625 
2016-12-10 10:57:08 Epoch 37 
2016-12-10 11:03:41 Training Error = 0.22297578430557 
2016-12-10 11:03:41 Training Loss = 0.011075050182151 
2016-12-10 11:03:50 Valid Error = 0.19243728940472 
2016-12-10 11:03:50 Valid Loss = 0.0065177678685342 
2016-12-10 11:03:59 Test Error = 0.18187942068036 
2016-12-10 11:03:59 Test Loss = 0.0064669776489996 
2016-12-10 11:03:59 -------------------LR------------------- 
2016-12-10 11:03:59 0.015625 
2016-12-10 11:03:59 Epoch 38 
2016-12-10 11:10:34 Training Error = 0.22488973953566 
2016-12-10 11:10:34 Training Loss = 0.011069190177588 
2016-12-10 11:10:42 Valid Error = 0.19580681392737 
2016-12-10 11:10:42 Valid Loss = 0.0065807239857315 
2016-12-10 11:10:52 Test Error = 0.18827888177838 
2016-12-10 11:10:52 Test Loss = 0.0065220652903723 
2016-12-10 11:10:52 -------------------LR------------------- 
2016-12-10 11:10:52 0.015625 
2016-12-10 11:10:52 Epoch 39 
2016-12-10 11:17:25 Training Error = 0.22330864608471 
2016-12-10 11:17:25 Training Loss = 0.011086036736589 
2016-12-10 11:17:34 Valid Error = 0.19243728940472 
2016-12-10 11:17:34 Valid Loss = 0.0065733649152031 
2016-12-10 11:17:43 Test Error = 0.18187942068036 
2016-12-10 11:17:43 Test Loss = 0.0065032901147231 
2016-12-10 11:17:43 -------------------LR------------------- 
2016-12-10 11:17:43 0.015625 
2016-12-10 11:17:43 Epoch 40 
2016-12-10 11:24:20 Training Error = 0.22434883914455 
2016-12-10 11:24:20 Training Loss = 0.011083120913906 
2016-12-10 11:24:28 Valid Error = 0.19243728940472 
2016-12-10 11:24:28 Valid Loss = 0.0065674081709685 
2016-12-10 11:24:40 Test Error = 0.18187942068036 
2016-12-10 11:24:40 Test Loss = 0.0065201509958712 
2016-12-10 11:24:40 -------------------LR------------------- 
2016-12-10 11:24:40 0.015625 
2016-12-10 11:24:40 Epoch 41 
2016-12-10 11:30:56 Training Error = 0.22268453024881 
2016-12-10 11:30:56 Training Loss = 0.011071400348797 
2016-12-10 11:31:04 Valid Error = 0.19992512167727 
2016-12-10 11:31:04 Valid Loss = 0.0066727609870938 
2016-12-10 11:31:13 Test Error = 0.19299427416639 
2016-12-10 11:31:13 Test Loss = 0.0066195765588002 
2016-12-10 11:31:13 -------------------LR------------------- 
2016-12-10 11:31:13 0.015625 
2016-12-10 11:31:13 Epoch 42 
2016-12-10 11:37:31 Training Error = 0.22376633103104 
2016-12-10 11:37:31 Training Loss = 0.011069818434445 
2016-12-10 11:37:39 Valid Error = 0.19917633845002 
2016-12-10 11:37:39 Valid Loss = 0.006627052905276 
2016-12-10 11:37:48 Test Error = 0.18996295048838 
2016-12-10 11:37:48 Test Loss = 0.0065450099476387 
2016-12-10 11:37:48 -------------------LR------------------- 
2016-12-10 11:37:48 0.015625 
2016-12-10 11:37:48 Epoch 43 
2016-12-10 11:44:07 Training Error = 0.22434883914455 
2016-12-10 11:44:07 Training Loss = 0.01107411491581 
2016-12-10 11:44:16 Valid Error = 0.19505803070011 
2016-12-10 11:44:16 Valid Loss = 0.006537827167162 
2016-12-10 11:44:25 Test Error = 0.18659481306837 
2016-12-10 11:44:25 Test Loss = 0.0064581671847271 
2016-12-10 11:44:25 -------------------LR------------------- 
2016-12-10 11:44:25 0.015625 
2016-12-10 11:44:25 Epoch 44 
2016-12-10 11:50:41 Training Error = 0.22297578430557 
2016-12-10 11:50:41 Training Loss = 0.011074057208614 
2016-12-10 11:50:50 Valid Error = 0.19580681392737 
2016-12-10 11:50:50 Valid Loss = 0.0066522930914444 
2016-12-10 11:50:59 Test Error = 0.18827888177838 
2016-12-10 11:50:59 Test Loss = 0.0065886116668389 
2016-12-10 11:50:59 -------------------LR------------------- 
2016-12-10 11:50:59 0.015625 
2016-12-10 11:50:59 Epoch 45 
2016-12-10 11:57:14 Training Error = 0.22201880669052 
2016-12-10 11:57:14 Training Loss = 0.011057276537399 
2016-12-10 11:57:22 Valid Error = 0.19243728940472 
2016-12-10 11:57:22 Valid Loss = 0.0065473574718356 
2016-12-10 11:57:31 Test Error = 0.18390030313237 
2016-12-10 11:57:31 Test Loss = 0.0064767940013569 
2016-12-10 11:57:31 -------------------LR------------------- 
2016-12-10 11:57:31 0.015625 
2016-12-10 11:57:31 Epoch 46 
2016-12-10 12:03:45 Training Error = 0.22409919281019 
2016-12-10 12:03:45 Training Loss = 0.011059797130487 
2016-12-10 12:03:54 Valid Error = 0.19505803070011 
2016-12-10 12:03:54 Valid Loss = 0.0065300851976838 
2016-12-10 12:04:03 Test Error = 0.18659481306837 
2016-12-10 12:04:03 Test Loss = 0.0064683555241769 
2016-12-10 12:04:03 -------------------LR------------------- 
2016-12-10 12:04:03 0.015625 
2016-12-10 12:04:03 Epoch 47 
2016-12-10 12:10:19 Training Error = 0.22264292252642 
2016-12-10 12:10:19 Training Loss = 0.011069417938887 
2016-12-10 12:10:27 Valid Error = 0.19580681392737 
2016-12-10 12:10:27 Valid Loss = 0.0066071564177827 
2016-12-10 12:10:36 Test Error = 0.18827888177838 
2016-12-10 12:10:36 Test Loss = 0.0065417019259596 
2016-12-10 12:10:36 -------------------LR------------------- 
2016-12-10 12:10:36 0.015625 
2016-12-10 12:10:36 Epoch 48 
2016-12-10 12:16:51 Training Error = 0.22543063992677 
2016-12-10 12:16:51 Training Loss = 0.0110794687633 
2016-12-10 12:16:59 Valid Error = 0.19917633845002 
2016-12-10 12:16:59 Valid Loss = 0.0066177832075454 
2016-12-10 12:17:08 Test Error = 0.19131020545638 
2016-12-10 12:17:08 Test Loss = 0.0065406766273998 
2016-12-10 12:17:08 -------------------LR------------------- 
2016-12-10 12:17:08 0.015625 
2016-12-10 12:17:08 Epoch 49 
2016-12-10 12:23:26 Training Error = 0.22434883914455 
2016-12-10 12:23:26 Training Loss = 0.01106890970445 
2016-12-10 12:23:34 Valid Error = 0.19318607263197 
2016-12-10 12:23:34 Valid Loss = 0.0065746373931981 
2016-12-10 12:23:43 Test Error = 0.18356348939037 
2016-12-10 12:23:43 Test Loss = 0.0065136330799108 
2016-12-10 12:23:43 -------------------LR------------------- 
2016-12-10 12:23:43 0.015625 
2016-12-10 12:23:43 Epoch 50 
2016-12-10 12:30:03 Training Error = 0.22264292252642 
2016-12-10 12:30:03 Training Loss = 0.011064271999256 
2016-12-10 12:30:11 Valid Error = 0.19505803070011 
2016-12-10 12:30:11 Valid Loss = 0.0065365101352959 
2016-12-10 12:30:21 Test Error = 0.18726844055237 
2016-12-10 12:30:21 Test Loss = 0.0064679922235972 
2016-12-10 12:30:21 -------------------LR------------------- 
2016-12-10 12:30:21 0.0078125 
2016-12-10 12:30:21 Epoch 51 
2016-12-10 12:36:36 Training Error = 0.22422401597737 
2016-12-10 12:36:36 Training Loss = 0.011068998616576 
2016-12-10 12:36:44 Valid Error = 0.19580681392737 
2016-12-10 12:36:44 Valid Loss = 0.006653556294764 
2016-12-10 12:36:53 Test Error = 0.18827888177838 
2016-12-10 12:36:53 Test Loss = 0.0065709874575268 
2016-12-10 12:36:53 -------------------LR------------------- 
2016-12-10 12:36:53 0.0078125 
2016-12-10 12:36:53 Epoch 52 
2016-12-10 12:43:04 Training Error = 0.22189398352334 
2016-12-10 12:43:04 Training Loss = 0.011050047269964 
2016-12-10 12:43:12 Valid Error = 0.19505803070011 
2016-12-10 12:43:12 Valid Loss = 0.0064907139290226 
2016-12-10 12:43:21 Test Error = 0.18659481306837 
2016-12-10 12:43:21 Test Loss = 0.0064255937501496 
2016-12-10 12:43:21 -------------------LR------------------- 
2016-12-10 12:43:21 0.0078125 
2016-12-10 12:43:21 Epoch 53 
