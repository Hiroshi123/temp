2016-12-09 23:12:12 [program started on Fri Dec  9 23:12:12 2016] 
2016-12-09 23:12:12 [command line arguments] 
2016-12-09 23:12:12 stcWeights false 
2016-12-09 23:12:12 LR 0.015625 
2016-12-09 23:12:12 batchSize 300 
2016-12-09 23:12:12 network ./Models/Cifar10_Custom 
2016-12-09 23:12:12 stcNeurons true 
2016-12-09 23:12:12 constBatchSize false 
2016-12-09 23:12:12 chartFileName chart1 
2016-12-09 23:12:12 dp_prepro false 
2016-12-09 23:12:12 nGPU 1 
2016-12-09 23:12:12 dataset Caltech256 
2016-12-09 23:12:12 type cuda 
2016-12-09 23:12:12 momentum 0 
2016-12-09 23:12:12 threads 8 
2016-12-09 23:12:12 weightDecay 0 
2016-12-09 23:12:12 runningVal false 
2016-12-09 23:12:12 convLayerN 2 
2016-12-09 23:12:12 LRDecay 0 
2016-12-09 23:12:12 numHid 1024 
2016-12-09 23:12:12 save /dev/shm/clone/temp/th/Results/Caltech256/model2-10 
2016-12-09 23:12:12 augment false 
2016-12-09 23:12:12 epoch -1 
2016-12-09 23:12:12 modelsFolder ./Models/ 
2016-12-09 23:12:12 format rgb 
2016-12-09 23:12:12 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 23:12:12 imageFileExtension svg 
2016-12-09 23:12:12 channel 1 
2016-12-09 23:12:12 devid 15 
2016-12-09 23:12:12 visualize 1 
2016-12-09 23:12:12 LRDecayPerEpoch 0.0001 
2016-12-09 23:12:12 optimization adam 
2016-12-09 23:12:12 SBN true 
2016-12-09 23:12:12 normalization simple 
2016-12-09 23:12:12 title model1 
2016-12-09 23:12:12 load  
2016-12-09 23:12:12 whiten true 
2016-12-09 23:12:12 [----------------------] 
2016-12-09 23:12:14 ==> Network 
2016-12-09 23:12:14 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): nn.View(32768)
  (11): BinaryLinear(32768 -> 1024)
  (12): BatchNormalizationShiftPow2
  (13): nn.HardTanh
  (14): BinarizedNeurons
  (15): BinaryLinear(1024 -> 1024)
  (16): BatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): BinaryLinear(1024 -> 255)
  (20): nn.BatchNormalization
} 
2016-12-09 23:12:14 ==>35022717 Parameters 
2016-12-09 23:12:14 ==> Loss 
2016-12-09 23:12:14 SqrtHingeEmbeddingCriterion 
2016-12-09 23:12:14 
==> Starting Training
 
2016-12-09 23:12:14 Epoch 1 
2016-12-09 23:14:13 Training Error = 0.98681035200133 
2016-12-09 23:14:13 Training Loss = 0.44148062215181 
2016-12-09 23:14:17 Valid Error = 0.98839385997754 
2016-12-09 23:14:17 Valid Loss = 0.079844750973488 
2016-12-09 23:14:20 Test Error = 0.98720107780397 
2016-12-09 23:14:20 Test Loss = 0.081327395096824 
2016-12-09 23:14:20 -------------------LR------------------- 
2016-12-09 23:14:20 0.015625 
2016-12-09 23:14:20 Epoch 2 
2016-12-09 23:16:22 Training Error = 0.95993176333528 
2016-12-09 23:16:22 Training Loss = 0.036305875408038 
2016-12-09 23:16:25 Valid Error = 0.94309247472857 
2016-12-09 23:16:25 Valid Loss = 0.019711665421361 
2016-12-09 23:16:29 Test Error = 0.95486695857191 
2016-12-09 23:16:29 Test Loss = 0.019635249982869 
2016-12-09 23:16:29 -------------------LR------------------- 
2016-12-09 23:16:29 0.015625 
2016-12-09 23:16:29 Epoch 3 
2016-12-09 23:18:30 Training Error = 0.94241491220771 
2016-12-09 23:18:30 Training Loss = 0.017414228328383 
2016-12-09 23:18:33 Valid Error = 0.9906402096593 
2016-12-09 23:18:33 Valid Loss = 0.016828422254412 
2016-12-09 23:18:37 Test Error = 0.98854833277198 
2016-12-09 23:18:37 Test Loss = 0.016908077714415 
2016-12-09 23:18:37 -------------------LR------------------- 
2016-12-09 23:18:37 0.015625 
2016-12-09 23:18:37 Epoch 4 
2016-12-09 23:20:39 Training Error = 0.9245235915786 
2016-12-09 23:20:39 Training Loss = 0.016357355990486 
2016-12-09 23:20:42 Valid Error = 0.94983152377387 
2016-12-09 23:20:42 Valid Loss = 0.016211630827134 
2016-12-09 23:20:46 Test Error = 0.96328730212193 
2016-12-09 23:20:46 Test Loss = 0.016223425620708 
2016-12-09 23:20:46 -------------------LR------------------- 
2016-12-09 23:20:46 0.015625 
2016-12-09 23:20:46 Epoch 5 
2016-12-09 23:22:46 Training Error = 0.91408005325788 
2016-12-09 23:22:46 Training Loss = 0.016111063831397 
2016-12-09 23:22:49 Valid Error = 0.94496443279671 
2016-12-09 23:22:49 Valid Loss = 0.016586245190842 
2016-12-09 23:22:53 Test Error = 0.95587739979791 
2016-12-09 23:22:53 Test Loss = 0.017273527594813 
2016-12-09 23:22:53 -------------------LR------------------- 
2016-12-09 23:22:53 0.015625 
2016-12-09 23:22:53 Epoch 6 
2016-12-09 23:24:55 Training Error = 0.90184738287426 
2016-12-09 23:24:55 Training Loss = 0.015793699468125 
2016-12-09 23:24:58 Valid Error = 0.91950580307001 
2016-12-09 23:24:58 Valid Loss = 0.016211802090048 
2016-12-09 23:25:02 Test Error = 0.93533176153587 
2016-12-09 23:25:02 Test Loss = 0.016545584424619 
2016-12-09 23:25:02 -------------------LR------------------- 
2016-12-09 23:25:02 0.015625 
2016-12-09 23:25:02 Epoch 7 
2016-12-09 23:27:01 Training Error = 0.88433053174669 
2016-12-09 23:27:01 Training Loss = 0.01556151404703 
2016-12-09 23:27:04 Valid Error = 0.9382253837514 
2016-12-09 23:27:04 Valid Loss = 0.016413624811097 
2016-12-09 23:27:08 Test Error = 0.95486695857191 
2016-12-09 23:27:08 Test Loss = 0.016613667969414 
2016-12-09 23:27:08 -------------------LR------------------- 
2016-12-09 23:27:08 0.015625 
2016-12-09 23:27:08 Epoch 8 
2016-12-09 23:29:08 Training Error = 0.87463593242906 
2016-12-09 23:29:08 Training Loss = 0.015302405655833 
2016-12-09 23:29:11 Valid Error = 0.92324971920629 
2016-12-09 23:29:11 Valid Loss = 0.015948974258048 
2016-12-09 23:29:15 Test Error = 0.93566857527787 
2016-12-09 23:29:15 Test Loss = 0.01606281507707 
2016-12-09 23:29:15 -------------------LR------------------- 
2016-12-09 23:29:15 0.015625 
2016-12-09 23:29:15 Epoch 9 
2016-12-09 23:31:16 Training Error = 0.85412332528917 
2016-12-09 23:31:16 Training Loss = 0.015008777959299 
2016-12-09 23:31:19 Valid Error = 0.89853987270685 
2016-12-09 23:31:19 Valid Loss = 0.015266748135066 
2016-12-09 23:31:23 Test Error = 0.91714381946783 
2016-12-09 23:31:23 Test Loss = 0.015493550649039 
2016-12-09 23:31:23 -------------------LR------------------- 
2016-12-09 23:31:23 0.015625 
2016-12-09 23:31:23 Epoch 10 
2016-12-09 23:33:30 Training Error = 0.83423483398519 
2016-12-09 23:33:30 Training Loss = 0.014790301269654 
2016-12-09 23:33:34 Valid Error = 0.86634219393486 
2016-12-09 23:33:34 Valid Loss = 0.015331222381537 
2016-12-09 23:33:37 Test Error = 0.87638935668575 
2016-12-09 23:33:37 Test Loss = 0.015526965158522 
2016-12-09 23:33:37 -------------------LR------------------- 
2016-12-09 23:33:37 0.015625 
2016-12-09 23:33:37 Epoch 11 
2016-12-09 23:35:37 Training Error = 0.81967213114754 
2016-12-09 23:35:37 Training Loss = 0.014790350515011 
2016-12-09 23:35:40 Valid Error = 0.85174092100337 
2016-12-09 23:35:40 Valid Loss = 0.015119149612289 
2016-12-09 23:35:44 Test Error = 0.86460087571573 
2016-12-09 23:35:44 Test Loss = 0.015376940680395 
2016-12-09 23:35:44 -------------------LR------------------- 
2016-12-09 23:35:44 0.015625 
2016-12-09 23:35:44 Epoch 12 
2016-12-09 23:37:45 Training Error = 0.81888158442207 
2016-12-09 23:37:45 Training Loss = 0.014821506035251 
2016-12-09 23:37:48 Valid Error = 0.85660801198053 
2016-12-09 23:37:48 Valid Loss = 0.015039644982592 
2016-12-09 23:37:52 Test Error = 0.86864264061974 
2016-12-09 23:37:52 Test Loss = 0.015233280055664 
2016-12-09 23:37:52 -------------------LR------------------- 
2016-12-09 23:37:52 0.015625 
2016-12-09 23:37:52 Epoch 13 
2016-12-09 23:39:54 Training Error = 0.82029624698344 
2016-12-09 23:39:54 Training Loss = 0.014823373091761 
2016-12-09 23:39:57 Valid Error = 0.86110071134407 
2016-12-09 23:39:57 Valid Loss = 0.015117917159675 
2016-12-09 23:40:01 Test Error = 0.87201077803974 
2016-12-09 23:40:01 Test Loss = 0.015356470365432 
2016-12-09 23:40:01 -------------------LR------------------- 
2016-12-09 23:40:01 0.015625 
2016-12-09 23:40:01 Epoch 14 
2016-12-09 23:42:02 Training Error = 0.81942248481318 
2016-12-09 23:42:02 Training Loss = 0.014800728362193 
2016-12-09 23:42:05 Valid Error = 0.8562336203669 
2016-12-09 23:42:05 Valid Loss = 0.015041523725784 
2016-12-09 23:42:09 Test Error = 0.86729538565173 
2016-12-09 23:42:09 Test Loss = 0.015254139524508 
2016-12-09 23:42:09 -------------------LR------------------- 
2016-12-09 23:42:09 0.015625 
2016-12-09 23:42:09 Epoch 15 
2016-12-09 23:44:09 Training Error = 0.81863193808771 
2016-12-09 23:44:09 Training Loss = 0.014786756095296 
2016-12-09 23:44:12 Valid Error = 0.85660801198053 
2016-12-09 23:44:12 Valid Loss = 0.015083019622833 
2016-12-09 23:44:16 Test Error = 0.86864264061974 
2016-12-09 23:44:16 Test Loss = 0.015319520674547 
2016-12-09 23:44:16 -------------------LR------------------- 
2016-12-09 23:44:16 0.015625 
2016-12-09 23:44:16 Epoch 16 
2016-12-09 23:46:18 Training Error = 0.81883997669968 
2016-12-09 23:46:18 Training Loss = 0.014798732524954 
2016-12-09 23:46:22 Valid Error = 0.86409584425309 
2016-12-09 23:46:22 Valid Loss = 0.015034317754298 
2016-12-09 23:46:25 Test Error = 0.87369484674975 
2016-12-09 23:46:25 Test Loss = 0.015266989385254 
2016-12-09 23:46:25 -------------------LR------------------- 
2016-12-09 23:46:25 0.015625 
2016-12-09 23:46:25 Epoch 17 
2016-12-09 23:48:26 Training Error = 0.81954730798036 
2016-12-09 23:48:26 Training Loss = 0.014821384826518 
2016-12-09 23:48:30 Valid Error = 0.85660801198053 
2016-12-09 23:48:30 Valid Loss = 0.015102340581256 
2016-12-09 23:48:34 Test Error = 0.86864264061974 
2016-12-09 23:48:34 Test Loss = 0.015298703406079 
2016-12-09 23:48:34 -------------------LR------------------- 
2016-12-09 23:48:34 0.015625 
2016-12-09 23:48:34 Epoch 18 
2016-12-09 23:50:35 Training Error = 0.82050428559541 
2016-12-09 23:50:35 Training Loss = 0.014820090488135 
2016-12-09 23:50:38 Valid Error = 0.85660801198053 
2016-12-09 23:50:38 Valid Loss = 0.015103586183431 
2016-12-09 23:50:42 Test Error = 0.86864264061974 
2016-12-09 23:50:42 Test Loss = 0.015323043296857 
2016-12-09 23:50:42 -------------------LR------------------- 
2016-12-09 23:50:42 0.015625 
2016-12-09 23:50:42 Epoch 19 
2016-12-09 23:52:40 Training Error = 0.81863193808771 
2016-12-09 23:52:40 Training Loss = 0.01479804366502 
2016-12-09 23:52:44 Valid Error = 0.85174092100337 
2016-12-09 23:52:44 Valid Loss = 0.015116566168007 
2016-12-09 23:52:47 Test Error = 0.86460087571573 
2016-12-09 23:52:47 Test Loss = 0.015385273265711 
2016-12-09 23:52:47 -------------------LR------------------- 
2016-12-09 23:52:47 0.015625 
2016-12-09 23:52:47 Epoch 20 
2016-12-09 23:54:58 Training Error = 0.82079553965216 
2016-12-09 23:54:58 Training Loss = 0.014821564034598 
2016-12-09 23:55:02 Valid Error = 0.85174092100337 
2016-12-09 23:55:02 Valid Loss = 0.015090134487531 
2016-12-09 23:55:06 Test Error = 0.86460087571573 
2016-12-09 23:55:06 Test Loss = 0.015338852696377 
2016-12-09 23:55:06 -------------------LR------------------- 
2016-12-09 23:55:06 0.015625 
2016-12-09 23:55:06 Epoch 21 
2016-12-09 23:57:22 Training Error = 0.81950570025797 
2016-12-09 23:57:22 Training Loss = 0.01481041947529 
2016-12-09 23:57:26 Valid Error = 0.8562336203669 
2016-12-09 23:57:26 Valid Loss = 0.015139120732427 
2016-12-09 23:57:29 Test Error = 0.86796901313574 
2016-12-09 23:57:29 Test Loss = 0.015403958582712 
2016-12-09 23:57:29 -------------------LR------------------- 
2016-12-09 23:57:29 0.015625 
2016-12-09 23:57:29 Epoch 22 
2016-12-09 23:59:45 Training Error = 0.81825746858617 
2016-12-09 23:59:45 Training Loss = 0.014794652352237 
2016-12-09 23:59:48 Valid Error = 0.85660801198053 
2016-12-09 23:59:48 Valid Loss = 0.015088835584457 
2016-12-09 23:59:52 Test Error = 0.86864264061974 
2016-12-09 23:59:52 Test Loss = 0.015291130742492 
2016-12-09 23:59:52 -------------------LR------------------- 
2016-12-09 23:59:52 0.015625 
2016-12-09 23:59:52 Epoch 23 
2016-12-10 00:02:01 Training Error = 0.81829907630856 
2016-12-10 00:02:01 Training Loss = 0.014810238903864 
2016-12-10 00:02:04 Valid Error = 0.85660801198053 
2016-12-10 00:02:04 Valid Loss = 0.015115358384152 
2016-12-10 00:02:08 Test Error = 0.86864264061974 
2016-12-10 00:02:08 Test Loss = 0.015351845288957 
2016-12-10 00:02:08 -------------------LR------------------- 
2016-12-10 00:02:08 0.015625 
2016-12-10 00:02:08 Epoch 24 
2016-12-10 00:04:10 Training Error = 0.82021303153865 
2016-12-10 00:04:10 Training Loss = 0.014815512203349 
2016-12-10 00:04:14 Valid Error = 0.86110071134407 
2016-12-10 00:04:14 Valid Loss = 0.015084470914664 
2016-12-10 00:04:17 Test Error = 0.87201077803974 
2016-12-10 00:04:17 Test Loss = 0.015271157985731 
2016-12-10 00:04:17 -------------------LR------------------- 
2016-12-10 00:04:17 0.015625 
2016-12-10 00:04:17 Epoch 25 
2016-12-10 00:06:20 Training Error = 0.81933926936839 
2016-12-10 00:06:20 Training Loss = 0.014805747628816 
2016-12-10 00:06:24 Valid Error = 0.85174092100337 
2016-12-10 00:06:24 Valid Loss = 0.015114542158111 
2016-12-10 00:06:28 Test Error = 0.86460087571573 
2016-12-10 00:06:28 Test Loss = 0.015381217722565 
2016-12-10 00:06:28 -------------------LR------------------- 
2016-12-10 00:06:28 0.015625 
2016-12-10 00:06:28 Epoch 26 
2016-12-10 00:08:26 Training Error = 0.81721727552634 
2016-12-10 00:08:26 Training Loss = 0.014820451507865 
2016-12-10 00:08:29 Valid Error = 0.85660801198053 
2016-12-10 00:08:29 Valid Loss = 0.015159012109917 
2016-12-10 00:08:33 Test Error = 0.86864264061974 
2016-12-10 00:08:33 Test Loss = 0.015436435140656 
2016-12-10 00:08:33 -------------------LR------------------- 
2016-12-10 00:08:33 0.015625 
2016-12-10 00:08:33 Epoch 27 
2016-12-10 00:10:34 Training Error = 0.8174253141383 
2016-12-10 00:10:34 Training Loss = 0.014806474212573 
2016-12-10 00:10:37 Valid Error = 0.85960314488955 
2016-12-10 00:10:37 Valid Loss = 0.01514811047049 
2016-12-10 00:10:41 Test Error = 0.87032670932974 
2016-12-10 00:10:41 Test Loss = 0.015413247967102 
2016-12-10 00:10:41 -------------------LR------------------- 
2016-12-10 00:10:41 0.015625 
2016-12-10 00:10:41 Epoch 28 
2016-12-10 00:12:40 Training Error = 0.82121161687609 
2016-12-10 00:12:40 Training Loss = 0.014814302955994 
2016-12-10 00:12:43 Valid Error = 0.86110071134407 
2016-12-10 00:12:43 Valid Loss = 0.01509096318665 
2016-12-10 00:12:47 Test Error = 0.87201077803974 
2016-12-10 00:12:47 Test Loss = 0.015272023150655 
2016-12-10 00:12:47 -------------------LR------------------- 
2016-12-10 00:12:47 0.015625 
2016-12-10 00:12:47 Epoch 29 
2016-12-10 00:14:46 Training Error = 0.81838229175335 
2016-12-10 00:14:46 Training Loss = 0.014805716338452 
2016-12-10 00:14:49 Valid Error = 0.85660801198053 
2016-12-10 00:14:49 Valid Loss = 0.015116111482615 
2016-12-10 00:14:53 Test Error = 0.86864264061974 
2016-12-10 00:14:53 Test Loss = 0.015377144531914 
2016-12-10 00:14:53 -------------------LR------------------- 
2016-12-10 00:14:53 0.015625 
2016-12-10 00:14:53 Epoch 30 
2016-12-10 00:17:00 Training Error = 0.81846550719814 
2016-12-10 00:17:00 Training Loss = 0.014787182986792 
2016-12-10 00:17:04 Valid Error = 0.85960314488955 
2016-12-10 00:17:04 Valid Loss = 0.015153386488835 
2016-12-10 00:17:07 Test Error = 0.87032670932974 
2016-12-10 00:17:07 Test Loss = 0.015418541946298 
2016-12-10 00:17:07 -------------------LR------------------- 
2016-12-10 00:17:07 0.015625 
2016-12-10 00:17:08 Epoch 31 
2016-12-10 00:19:05 Training Error = 0.82000499292669 
2016-12-10 00:19:05 Training Loss = 0.014800652400611 
2016-12-10 00:19:09 Valid Error = 0.86110071134407 
2016-12-10 00:19:09 Valid Loss = 0.015044706051173 
2016-12-10 00:19:12 Test Error = 0.87201077803974 
2016-12-10 00:19:12 Test Loss = 0.015274852539229 
2016-12-10 00:19:12 -------------------LR------------------- 
2016-12-10 00:19:12 0.015625 
2016-12-10 00:19:12 Epoch 32 
2016-12-10 00:21:13 Training Error = 0.81834068403096 
2016-12-10 00:21:13 Training Loss = 0.014806741356286 
2016-12-10 00:21:16 Valid Error = 0.85286409584425 
2016-12-10 00:21:16 Valid Loss = 0.015057769712993 
2016-12-10 00:21:20 Test Error = 0.86359043448973 
2016-12-10 00:21:20 Test Loss = 0.015257942640709 
2016-12-10 00:21:20 -------------------LR------------------- 
2016-12-10 00:21:20 0.015625 
2016-12-10 00:21:20 Epoch 33 
2016-12-10 00:23:17 Training Error = 0.81725888324873 
2016-12-10 00:23:17 Training Loss = 0.014810172009441 
2016-12-10 00:23:21 Valid Error = 0.85660801198053 
2016-12-10 00:23:21 Valid Loss = 0.01510282647584 
2016-12-10 00:23:24 Test Error = 0.86864264061974 
2016-12-10 00:23:24 Test Loss = 0.015343173383349 
2016-12-10 00:23:24 -------------------LR------------------- 
2016-12-10 00:23:24 0.015625 
2016-12-10 00:23:24 Epoch 34 
2016-12-10 00:25:23 Training Error = 0.81913123075643 
2016-12-10 00:25:23 Training Loss = 0.014802426637655 
2016-12-10 00:25:27 Valid Error = 0.85773118682142 
2016-12-10 00:25:27 Valid Loss = 0.015083430428377 
2016-12-10 00:25:31 Test Error = 0.86897945436174 
2016-12-10 00:25:31 Test Loss = 0.01529174942427 
2016-12-10 00:25:31 -------------------LR------------------- 
2016-12-10 00:25:31 0.015625 
2016-12-10 00:25:31 Epoch 35 
2016-12-10 00:27:29 Training Error = 0.82042107015062 
2016-12-10 00:27:29 Training Loss = 0.01479489974624 
2016-12-10 00:27:32 Valid Error = 0.85174092100337 
2016-12-10 00:27:32 Valid Loss = 0.015159848149604 
2016-12-10 00:27:36 Test Error = 0.86460087571573 
2016-12-10 00:27:36 Test Loss = 0.015425227952376 
2016-12-10 00:27:36 -------------------LR------------------- 
2016-12-10 00:27:36 0.015625 
2016-12-10 00:27:36 Epoch 36 
2016-12-10 00:29:35 Training Error = 0.81825746858617 
2016-12-10 00:29:35 Training Loss = 0.014793720870887 
2016-12-10 00:29:38 Valid Error = 0.85660801198053 
2016-12-10 00:29:38 Valid Loss = 0.015161900222454 
2016-12-10 00:29:42 Test Error = 0.86864264061974 
2016-12-10 00:29:42 Test Loss = 0.015418955037906 
2016-12-10 00:29:42 -------------------LR------------------- 
2016-12-10 00:29:42 0.015625 
2016-12-10 00:29:42 Epoch 37 
2016-12-10 00:31:41 Training Error = 0.81921444620121 
2016-12-10 00:31:41 Training Loss = 0.014812235045292 
2016-12-10 00:31:44 Valid Error = 0.85660801198053 
2016-12-10 00:31:44 Valid Loss = 0.015185913170007 
2016-12-10 00:31:48 Test Error = 0.86864264061974 
2016-12-10 00:31:48 Test Loss = 0.015466564862215 
2016-12-10 00:31:48 -------------------LR------------------- 
2016-12-10 00:31:48 0.015625 
2016-12-10 00:31:48 Epoch 38 
2016-12-10 00:33:48 Training Error = 0.8199217774819 
2016-12-10 00:33:48 Training Loss = 0.014806838655157 
2016-12-10 00:33:51 Valid Error = 0.85660801198053 
2016-12-10 00:33:51 Valid Loss = 0.015098843365773 
2016-12-10 00:33:55 Test Error = 0.86864264061974 
2016-12-10 00:33:55 Test Loss = 0.015322404671322 
2016-12-10 00:33:55 -------------------LR------------------- 
2016-12-10 00:33:55 0.015625 
2016-12-10 00:33:55 Epoch 39 
2016-12-10 00:35:53 Training Error = 0.81813264541899 
2016-12-10 00:35:53 Training Loss = 0.014817444944766 
2016-12-10 00:35:56 Valid Error = 0.86110071134407 
2016-12-10 00:35:56 Valid Loss = 0.015074491661465 
2016-12-10 00:36:00 Test Error = 0.87201077803974 
2016-12-10 00:36:00 Test Loss = 0.015253549709302 
2016-12-10 00:36:00 -------------------LR------------------- 
2016-12-10 00:36:00 0.015625 
2016-12-10 00:36:00 Epoch 40 
2016-12-10 00:38:07 Training Error = 0.81888158442207 
2016-12-10 00:38:07 Training Loss = 0.014827453684548 
2016-12-10 00:38:11 Valid Error = 0.86072631973044 
2016-12-10 00:38:11 Valid Loss = 0.015043018834003 
2016-12-10 00:38:15 Test Error = 0.87066352307174 
2016-12-10 00:38:15 Test Loss = 0.015260889097195 
2016-12-10 00:38:15 -------------------LR------------------- 
2016-12-10 00:38:15 0.015625 
2016-12-10 00:38:15 Epoch 41 
2016-12-10 00:40:12 Training Error = 0.81734209869352 
2016-12-10 00:40:12 Training Loss = 0.014801139173371 
2016-12-10 00:40:15 Valid Error = 0.86110071134407 
2016-12-10 00:40:15 Valid Loss = 0.015101874265446 
2016-12-10 00:40:19 Test Error = 0.87201077803974 
2016-12-10 00:40:19 Test Loss = 0.015290658489329 
2016-12-10 00:40:19 -------------------LR------------------- 
2016-12-10 00:40:19 0.015625 
2016-12-10 00:40:19 Epoch 42 
2016-12-10 00:42:18 Training Error = 0.8162186901889 
2016-12-10 00:42:18 Training Loss = 0.014787183901098 
2016-12-10 00:42:22 Valid Error = 0.85660801198053 
2016-12-10 00:42:22 Valid Loss = 0.015091963121205 
2016-12-10 00:42:26 Test Error = 0.86864264061974 
2016-12-10 00:42:26 Test Loss = 0.015355110160412 
2016-12-10 00:42:26 -------------------LR------------------- 
2016-12-10 00:42:26 0.015625 
2016-12-10 00:42:26 Epoch 43 
2016-12-10 00:44:24 Training Error = 0.81863193808771 
2016-12-10 00:44:24 Training Loss = 0.014818252209386 
2016-12-10 00:44:28 Valid Error = 0.86110071134407 
2016-12-10 00:44:28 Valid Loss = 0.015090262671386 
2016-12-10 00:44:31 Test Error = 0.87201077803974 
2016-12-10 00:44:31 Test Loss = 0.015277559542504 
2016-12-10 00:44:31 -------------------LR------------------- 
2016-12-10 00:44:31 0.015625 
2016-12-10 00:44:32 Epoch 44 
2016-12-10 00:46:31 Training Error = 0.81946409253557 
2016-12-10 00:46:31 Training Loss = 0.014820497613118 
2016-12-10 00:46:34 Valid Error = 0.85660801198053 
2016-12-10 00:46:34 Valid Loss = 0.015124667401603 
2016-12-10 00:46:38 Test Error = 0.86864264061974 
2016-12-10 00:46:38 Test Loss = 0.015396618809243 
2016-12-10 00:46:38 -------------------LR------------------- 
2016-12-10 00:46:38 0.015625 
2016-12-10 00:46:38 Epoch 45 
2016-12-10 00:48:36 Training Error = 0.81796621452942 
2016-12-10 00:48:36 Training Loss = 0.014807288849004 
2016-12-10 00:48:40 Valid Error = 0.85922875327593 
2016-12-10 00:48:40 Valid Loss = 0.01513554987181 
2016-12-10 00:48:43 Test Error = 0.86965308184574 
2016-12-10 00:48:43 Test Loss = 0.01539728455321 
2016-12-10 00:48:43 -------------------LR------------------- 
2016-12-10 00:48:43 0.015625 
2016-12-10 00:48:43 Epoch 46 
2016-12-10 00:50:43 Training Error = 0.81925605392361 
2016-12-10 00:50:43 Training Loss = 0.014802500223084 
2016-12-10 00:50:46 Valid Error = 0.85660801198053 
2016-12-10 00:50:46 Valid Loss = 0.015204268920258 
2016-12-10 00:50:50 Test Error = 0.86864264061974 
2016-12-10 00:50:50 Test Loss = 0.01549091361649 
2016-12-10 00:50:50 -------------------LR------------------- 
2016-12-10 00:50:50 0.015625 
2016-12-10 00:50:50 Epoch 47 
2016-12-10 00:52:49 Training Error = 0.81900640758925 
2016-12-10 00:52:49 Training Loss = 0.014802710556975 
2016-12-10 00:52:53 Valid Error = 0.86110071134407 
2016-12-10 00:52:53 Valid Loss = 0.015067060995317 
2016-12-10 00:52:57 Test Error = 0.87201077803974 
2016-12-10 00:52:57 Test Loss = 0.015308613602998 
2016-12-10 00:52:57 -------------------LR------------------- 
2016-12-10 00:52:57 0.015625 
2016-12-10 00:52:57 Epoch 48 
2016-12-10 00:54:56 Training Error = 0.82017142381626 
2016-12-10 00:54:56 Training Loss = 0.014799379590432 
2016-12-10 00:54:59 Valid Error = 0.8562336203669 
2016-12-10 00:54:59 Valid Loss = 0.01509181520941 
2016-12-10 00:55:03 Test Error = 0.86729538565173 
2016-12-10 00:55:03 Test Loss = 0.01534322887007 
2016-12-10 00:55:03 -------------------LR------------------- 
2016-12-10 00:55:03 0.015625 
2016-12-10 00:55:03 Epoch 49 
2016-12-10 00:57:01 Training Error = 0.81829907630856 
2016-12-10 00:57:01 Training Loss = 0.014803896413038 
2016-12-10 00:57:04 Valid Error = 0.85660801198053 
2016-12-10 00:57:04 Valid Loss = 0.015090938878378 
2016-12-10 00:57:08 Test Error = 0.86864264061974 
2016-12-10 00:57:08 Test Loss = 0.015338966115557 
2016-12-10 00:57:08 -------------------LR------------------- 
2016-12-10 00:57:08 0.015625 
2016-12-10 00:57:08 Epoch 50 
2016-12-10 00:59:15 Training Error = 0.81771656819506 
2016-12-10 00:59:15 Training Loss = 0.014821730533936 
2016-12-10 00:59:18 Valid Error = 0.85323848745788 
2016-12-10 00:59:18 Valid Loss = 0.015064702353646 
2016-12-10 00:59:22 Test Error = 0.86561131694173 
2016-12-10 00:59:22 Test Loss = 0.01528225829479 
2016-12-10 00:59:22 -------------------LR------------------- 
2016-12-10 00:59:22 0.0078125 
2016-12-10 00:59:22 Epoch 51 
2016-12-10 01:01:20 Training Error = 0.81942248481318 
2016-12-10 01:01:20 Training Loss = 0.014802863140375 
2016-12-10 01:01:23 Valid Error = 0.86409584425309 
2016-12-10 01:01:23 Valid Loss = 0.015120163003244 
2016-12-10 01:01:27 Test Error = 0.87369484674975 
2016-12-10 01:01:27 Test Loss = 0.01537225072754 
2016-12-10 01:01:27 -------------------LR------------------- 
2016-12-10 01:01:27 0.0078125 
2016-12-10 01:01:27 Epoch 52 
2016-12-10 01:03:27 Training Error = 0.81917283847882 
2016-12-10 01:03:27 Training Loss = 0.014798066166051 
2016-12-10 01:03:31 Valid Error = 0.85773118682142 
2016-12-10 01:03:31 Valid Loss = 0.015073084837645 
2016-12-10 01:03:35 Test Error = 0.86897945436174 
2016-12-10 01:03:35 Test Loss = 0.015299306107225 
2016-12-10 01:03:35 -------------------LR------------------- 
2016-12-10 01:03:35 0.0078125 
2016-12-10 01:03:35 Epoch 53 
2016-12-10 01:05:28 Training Error = 0.81854872264292 
2016-12-10 01:05:28 Training Loss = 0.014818829345211 
2016-12-10 01:05:31 Valid Error = 0.85323848745788 
2016-12-10 01:05:31 Valid Loss = 0.015098586130543 
2016-12-10 01:05:35 Test Error = 0.86561131694173 
2016-12-10 01:05:35 Test Loss = 0.015325871951057 
2016-12-10 01:05:35 -------------------LR------------------- 
2016-12-10 01:05:35 0.0078125 
2016-12-10 01:05:35 Epoch 54 
2016-12-10 01:07:29 Training Error = 0.8174669218607 
2016-12-10 01:07:29 Training Loss = 0.014812138125354 
2016-12-10 01:07:32 Valid Error = 0.85660801198053 
2016-12-10 01:07:32 Valid Loss = 0.015120080180438 
2016-12-10 01:07:36 Test Error = 0.86864264061974 
2016-12-10 01:07:36 Test Loss = 0.015381032364444 
2016-12-10 01:07:36 -------------------LR------------------- 
2016-12-10 01:07:36 0.0078125 
2016-12-10 01:07:36 Epoch 55 
2016-12-10 01:09:31 Training Error = 0.81896479986686 
2016-12-10 01:09:31 Training Loss = 0.014795408650658 
2016-12-10 01:09:34 Valid Error = 0.85660801198053 
2016-12-10 01:09:34 Valid Loss = 0.015087704841238 
2016-12-10 01:09:38 Test Error = 0.86864264061974 
2016-12-10 01:09:38 Test Loss = 0.015339074038799 
2016-12-10 01:09:38 -------------------LR------------------- 
2016-12-10 01:09:38 0.0078125 
2016-12-10 01:09:38 Epoch 56 
2016-12-10 01:11:32 Training Error = 0.81646833652326 
2016-12-10 01:11:32 Training Loss = 0.01480026324076 
2016-12-10 01:11:35 Valid Error = 0.85660801198053 
2016-12-10 01:11:35 Valid Loss = 0.015099235436512 
2016-12-10 01:11:39 Test Error = 0.86864264061974 
2016-12-10 01:11:39 Test Loss = 0.015293614198446 
2016-12-10 01:11:39 -------------------LR------------------- 
2016-12-10 01:11:39 0.0078125 
2016-12-10 01:11:39 Epoch 57 
2016-12-10 01:13:38 Training Error = 0.8180494299742 
2016-12-10 01:13:38 Training Loss = 0.014803289440295 
2016-12-10 01:13:41 Valid Error = 0.85660801198053 
2016-12-10 01:13:41 Valid Loss = 0.015123719324695 
2016-12-10 01:13:45 Test Error = 0.86864264061974 
2016-12-10 01:13:45 Test Loss = 0.015369404616844 
2016-12-10 01:13:45 -------------------LR------------------- 
2016-12-10 01:13:45 0.0078125 
2016-12-10 01:13:45 Epoch 58 
2016-12-10 01:15:39 Training Error = 0.81917283847882 
2016-12-10 01:15:39 Training Loss = 0.014810649056544 
2016-12-10 01:15:42 Valid Error = 0.86110071134407 
2016-12-10 01:15:42 Valid Loss = 0.015033560123263 
2016-12-10 01:15:46 Test Error = 0.87201077803974 
2016-12-10 01:15:46 Test Loss = 0.015236600140971 
2016-12-10 01:15:46 -------------------LR------------------- 
2016-12-10 01:15:46 0.0078125 
2016-12-10 01:15:46 Epoch 59 
2016-12-10 01:17:41 Training Error = 0.81829907630856 
2016-12-10 01:17:41 Training Loss = 0.014793602831518 
2016-12-10 01:17:44 Valid Error = 0.85960314488955 
2016-12-10 01:17:44 Valid Loss = 0.015048807484395 
2016-12-10 01:17:48 Test Error = 0.87032670932974 
2016-12-10 01:17:48 Test Loss = 0.015286061164223 
2016-12-10 01:17:48 -------------------LR------------------- 
2016-12-10 01:17:48 0.0078125 
2016-12-10 01:17:48 Epoch 60 
2016-12-10 01:19:50 Training Error = 0.81634351335608 
2016-12-10 01:19:50 Training Loss = 0.014785964795402 
2016-12-10 01:19:53 Valid Error = 0.85660801198053 
2016-12-10 01:19:53 Valid Loss = 0.015115596326511 
2016-12-10 01:19:57 Test Error = 0.86864264061974 
2016-12-10 01:19:57 Test Loss = 0.015355318999502 
2016-12-10 01:19:57 -------------------LR------------------- 
2016-12-10 01:19:57 0.0078125 
2016-12-10 01:19:57 Epoch 61 
2016-12-10 01:21:51 Training Error = 0.81900640758925 
2016-12-10 01:21:51 Training Loss = 0.014822898990659 
2016-12-10 01:21:55 Valid Error = 0.85174092100337 
2016-12-10 01:21:55 Valid Loss = 0.015131622416596 
2016-12-10 01:21:58 Test Error = 0.86460087571573 
2016-12-10 01:21:58 Test Loss = 0.015410115227708 
2016-12-10 01:21:58 -------------------LR------------------- 
2016-12-10 01:21:58 0.0078125 
2016-12-10 01:21:58 Epoch 62 
2016-12-10 01:23:52 Training Error = 0.81821586086378 
2016-12-10 01:23:52 Training Loss = 0.014802088508029 
2016-12-10 01:23:55 Valid Error = 0.85660801198053 
2016-12-10 01:23:55 Valid Loss = 0.015132843633299 
2016-12-10 01:23:59 Test Error = 0.86864264061974 
2016-12-10 01:23:59 Test Loss = 0.015388737619816 
2016-12-10 01:23:59 -------------------LR------------------- 
2016-12-10 01:23:59 0.0078125 
2016-12-10 01:23:59 Epoch 63 
2016-12-10 01:25:53 Training Error = 0.81979695431472 
2016-12-10 01:25:53 Training Loss = 0.014804920259308 
2016-12-10 01:25:57 Valid Error = 0.85660801198053 
2016-12-10 01:25:57 Valid Loss = 0.015098931627928 
2016-12-10 01:26:00 Test Error = 0.86864264061974 
2016-12-10 01:26:00 Test Loss = 0.015345157162213 
2016-12-10 01:26:00 -------------------LR------------------- 
2016-12-10 01:26:00 0.0078125 
2016-12-10 01:26:00 Epoch 64 
2016-12-10 01:27:56 Training Error = 0.81709245235916 
2016-12-10 01:27:56 Training Loss = 0.014789134544493 
2016-12-10 01:27:59 Valid Error = 0.85660801198053 
2016-12-10 01:27:59 Valid Loss = 0.015080465182301 
2016-12-10 01:28:03 Test Error = 0.86864264061974 
2016-12-10 01:28:03 Test Loss = 0.015320380889865 
2016-12-10 01:28:03 -------------------LR------------------- 
2016-12-10 01:28:03 0.0078125 
2016-12-10 01:28:03 Epoch 65 
2016-12-10 01:30:00 Training Error = 0.81796621452942 
2016-12-10 01:30:00 Training Loss = 0.014812994456583 
2016-12-10 01:30:03 Valid Error = 0.85660801198053 
2016-12-10 01:30:03 Valid Loss = 0.01512255871413 
2016-12-10 01:30:07 Test Error = 0.86864264061974 
2016-12-10 01:30:07 Test Loss = 0.015315151415118 
2016-12-10 01:30:07 -------------------LR------------------- 
2016-12-10 01:30:07 0.0078125 
2016-12-10 01:30:07 Epoch 66 
2016-12-10 01:32:07 Training Error = 0.81950570025797 
2016-12-10 01:32:07 Training Loss = 0.014835013059909 
2016-12-10 01:32:11 Valid Error = 0.85660801198053 
2016-12-10 01:32:11 Valid Loss = 0.01510414657366 
2016-12-10 01:32:14 Test Error = 0.86864264061974 
2016-12-10 01:32:14 Test Loss = 0.015370847257363 
2016-12-10 01:32:14 -------------------LR------------------- 
2016-12-10 01:32:14 0.0078125 
2016-12-10 01:32:14 Epoch 67 
2016-12-10 01:34:22 Training Error = 0.81983856203711 
2016-12-10 01:34:22 Training Loss = 0.014802831329123 
2016-12-10 01:34:26 Valid Error = 0.8562336203669 
2016-12-10 01:34:26 Valid Loss = 0.015053889836699 
2016-12-10 01:34:29 Test Error = 0.86729538565173 
2016-12-10 01:34:29 Test Loss = 0.01525862775956 
2016-12-10 01:34:29 -------------------LR------------------- 
2016-12-10 01:34:29 0.0078125 
2016-12-10 01:34:29 Epoch 68 
2016-12-10 01:36:25 Training Error = 0.81734209869352 
2016-12-10 01:36:25 Training Loss = 0.014798691525156 
2016-12-10 01:36:28 Valid Error = 0.86110071134407 
2016-12-10 01:36:28 Valid Loss = 0.015045753798866 
2016-12-10 01:36:32 Test Error = 0.87201077803974 
2016-12-10 01:36:32 Test Loss = 0.015241651018817 
2016-12-10 01:36:32 -------------------LR------------------- 
2016-12-10 01:36:32 0.0078125 
2016-12-10 01:36:32 Epoch 69 
2016-12-10 01:38:27 Training Error = 0.8180910376966 
2016-12-10 01:38:27 Training Loss = 0.014792419721849 
2016-12-10 01:38:30 Valid Error = 0.86110071134407 
2016-12-10 01:38:30 Valid Loss = 0.015060335104841 
2016-12-10 01:38:34 Test Error = 0.87201077803974 
2016-12-10 01:38:34 Test Loss = 0.015311588831738 
2016-12-10 01:38:34 -------------------LR------------------- 
2016-12-10 01:38:34 0.0078125 
2016-12-10 01:38:34 Epoch 70 
2016-12-10 01:40:35 Training Error = 0.81879836897728 
2016-12-10 01:40:35 Training Loss = 0.014801775776184 
2016-12-10 01:40:38 Valid Error = 0.85660801198053 
2016-12-10 01:40:38 Valid Loss = 0.015049107605685 
2016-12-10 01:40:42 Test Error = 0.86864264061974 
2016-12-10 01:40:42 Test Loss = 0.01523963663473 
2016-12-10 01:40:42 -------------------LR------------------- 
2016-12-10 01:40:42 0.0078125 
2016-12-10 01:40:42 Epoch 71 
2016-12-10 01:42:36 Training Error = 0.82004660064908 
2016-12-10 01:42:36 Training Loss = 0.014816583043395 
2016-12-10 01:42:39 Valid Error = 0.85660801198053 
2016-12-10 01:42:39 Valid Loss = 0.015014659300494 
2016-12-10 01:42:43 Test Error = 0.86864264061974 
2016-12-10 01:42:43 Test Loss = 0.015215517185905 
2016-12-10 01:42:43 -------------------LR------------------- 
2016-12-10 01:42:43 0.0078125 
2016-12-10 01:42:43 Epoch 72 
2016-12-10 01:44:37 Training Error = 0.8180494299742 
2016-12-10 01:44:37 Training Loss = 0.014804495723687 
2016-12-10 01:44:41 Valid Error = 0.86409584425309 
2016-12-10 01:44:41 Valid Loss = 0.015056678437431 
2016-12-10 01:44:44 Test Error = 0.87369484674975 
2016-12-10 01:44:44 Test Loss = 0.015258296184001 
2016-12-10 01:44:44 -------------------LR------------------- 
2016-12-10 01:44:44 0.0078125 
2016-12-10 01:44:44 Epoch 73 
2016-12-10 01:46:38 Training Error = 0.81771656819506 
2016-12-10 01:46:38 Training Loss = 0.014796029932757 
2016-12-10 01:46:42 Valid Error = 0.85960314488955 
2016-12-10 01:46:42 Valid Loss = 0.015097089925818 
2016-12-10 01:46:46 Test Error = 0.87032670932974 
2016-12-10 01:46:46 Test Loss = 0.015333609400223 
2016-12-10 01:46:46 -------------------LR------------------- 
2016-12-10 01:46:46 0.0078125 
2016-12-10 01:46:46 Epoch 74 
2016-12-10 01:48:38 Training Error = 0.82025463926105 
2016-12-10 01:48:38 Training Loss = 0.014811891686506 
2016-12-10 01:48:42 Valid Error = 0.85922875327593 
2016-12-10 01:48:42 Valid Loss = 0.015121265512753 
2016-12-10 01:48:45 Test Error = 0.87268440552375 
2016-12-10 01:48:45 Test Loss = 0.015318448269783 
2016-12-10 01:48:45 -------------------LR------------------- 
2016-12-10 01:48:45 0.0078125 
2016-12-10 01:48:45 Epoch 75 
2016-12-10 01:50:41 Training Error = 0.82012981609387 
2016-12-10 01:50:41 Training Loss = 0.01481276930027 
2016-12-10 01:50:44 Valid Error = 0.86110071134407 
2016-12-10 01:50:44 Valid Loss = 0.015108001400429 
2016-12-10 01:50:48 Test Error = 0.87201077803974 
2016-12-10 01:50:48 Test Loss = 0.015379734671929 
2016-12-10 01:50:48 -------------------LR------------------- 
2016-12-10 01:50:48 0.0078125 
2016-12-10 01:50:48 Epoch 76 
2016-12-10 01:52:42 Training Error = 0.81850711492053 
2016-12-10 01:52:42 Training Loss = 0.014833661428767 
2016-12-10 01:52:45 Valid Error = 0.85660801198053 
2016-12-10 01:52:45 Valid Loss = 0.015158999286821 
2016-12-10 01:52:49 Test Error = 0.86864264061974 
2016-12-10 01:52:49 Test Loss = 0.015424214700862 
2016-12-10 01:52:49 -------------------LR------------------- 
2016-12-10 01:52:49 0.0078125 
2016-12-10 01:52:49 Epoch 77 
2016-12-10 01:54:43 Training Error = 0.81838229175335 
2016-12-10 01:54:43 Training Loss = 0.014806090305348 
2016-12-10 01:54:46 Valid Error = 0.86110071134407 
2016-12-10 01:54:46 Valid Loss = 0.015106653871651 
2016-12-10 01:54:50 Test Error = 0.87201077803974 
2016-12-10 01:54:50 Test Loss = 0.015301436095816 
2016-12-10 01:54:50 -------------------LR------------------- 
2016-12-10 01:54:50 0.0078125 
2016-12-10 01:54:50 Epoch 78 
2016-12-10 01:56:57 Training Error = 0.81854872264292 
2016-12-10 01:56:57 Training Loss = 0.014799700743975 
2016-12-10 01:57:01 Valid Error = 0.85174092100337 
2016-12-10 01:57:01 Valid Loss = 0.015169528909262 
2016-12-10 01:57:04 Test Error = 0.86460087571573 
2016-12-10 01:57:04 Test Loss = 0.015447467272213 
2016-12-10 01:57:04 -------------------LR------------------- 
2016-12-10 01:57:04 0.0078125 
2016-12-10 01:57:04 Epoch 79 
2016-12-10 01:59:09 Training Error = 0.81908962303404 
2016-12-10 01:59:09 Training Loss = 0.014787996887375 
2016-12-10 01:59:12 Valid Error = 0.85922875327593 
2016-12-10 01:59:12 Valid Loss = 0.015054352265671 
2016-12-10 01:59:16 Test Error = 0.87268440552375 
2016-12-10 01:59:16 Test Loss = 0.015249727378971 
2016-12-10 01:59:16 -------------------LR------------------- 
2016-12-10 01:59:16 0.0078125 
2016-12-10 01:59:16 Epoch 80 
2016-12-10 02:01:24 Training Error = 0.81933926936839 
2016-12-10 02:01:24 Training Loss = 0.014819408494479 
2016-12-10 02:01:27 Valid Error = 0.86110071134407 
2016-12-10 02:01:27 Valid Loss = 0.015129917039044 
2016-12-10 02:01:31 Test Error = 0.87201077803974 
2016-12-10 02:01:31 Test Loss = 0.015323351512458 
2016-12-10 02:01:31 -------------------LR------------------- 
2016-12-10 02:01:31 0.0078125 
2016-12-10 02:01:31 Epoch 81 
2016-12-10 02:03:31 Training Error = 0.81821586086378 
2016-12-10 02:03:31 Training Loss = 0.014809620724495 
2016-12-10 02:03:34 Valid Error = 0.85660801198053 
2016-12-10 02:03:34 Valid Loss = 0.015171902780321 
2016-12-10 02:03:38 Test Error = 0.86864264061974 
2016-12-10 02:03:38 Test Loss = 0.015433847420278 
2016-12-10 02:03:38 -------------------LR------------------- 
2016-12-10 02:03:38 0.0078125 
2016-12-10 02:03:38 Epoch 82 
2016-12-10 02:05:38 Training Error = 0.81592743613215 
2016-12-10 02:05:38 Training Loss = 0.014788966028524 
2016-12-10 02:05:42 Valid Error = 0.85773118682142 
2016-12-10 02:05:42 Valid Loss = 0.015060623139709 
2016-12-10 02:05:46 Test Error = 0.86897945436174 
2016-12-10 02:05:46 Test Loss = 0.015259245607901 
2016-12-10 02:05:46 -------------------LR------------------- 
2016-12-10 02:05:46 0.0078125 
2016-12-10 02:05:46 Epoch 83 
2016-12-10 02:07:40 Training Error = 0.81759174502788 
2016-12-10 02:07:40 Training Loss = 0.01479981202165 
2016-12-10 02:07:44 Valid Error = 0.86110071134407 
2016-12-10 02:07:44 Valid Loss = 0.0151676470074 
2016-12-10 02:07:47 Test Error = 0.87201077803974 
2016-12-10 02:07:47 Test Loss = 0.015426647832656 
2016-12-10 02:07:47 -------------------LR------------------- 
2016-12-10 02:07:47 0.0078125 
2016-12-10 02:07:47 Epoch 84 
2016-12-10 02:09:46 Training Error = 0.81875676125489 
2016-12-10 02:09:46 Training Loss = 0.014816585522393 
2016-12-10 02:09:49 Valid Error = 0.84837139648072 
2016-12-10 02:09:49 Valid Loss = 0.015197262975984 
2016-12-10 02:09:53 Test Error = 0.86156955203772 
2016-12-10 02:09:53 Test Loss = 0.015483412824814 
2016-12-10 02:09:53 -------------------LR------------------- 
2016-12-10 02:09:53 0.0078125 
2016-12-10 02:09:53 Epoch 85 
2016-12-10 02:11:52 Training Error = 0.81942248481318 
2016-12-10 02:11:52 Training Loss = 0.014807025422775 
2016-12-10 02:11:55 Valid Error = 0.85660801198053 
2016-12-10 02:11:55 Valid Loss = 0.015183587072831 
2016-12-10 02:11:59 Test Error = 0.86864264061974 
2016-12-10 02:11:59 Test Loss = 0.015475252905058 
2016-12-10 02:11:59 -------------------LR------------------- 
2016-12-10 02:11:59 0.0078125 
2016-12-10 02:11:59 Epoch 86 
2016-12-10 02:13:55 Training Error = 0.81942248481318 
2016-12-10 02:13:55 Training Loss = 0.014813819603191 
2016-12-10 02:13:58 Valid Error = 0.85660801198053 
2016-12-10 02:13:58 Valid Loss = 0.015226984989608 
2016-12-10 02:14:02 Test Error = 0.86864264061974 
2016-12-10 02:14:02 Test Loss = 0.015515533934129 
2016-12-10 02:14:02 -------------------LR------------------- 
2016-12-10 02:14:02 0.0078125 
2016-12-10 02:14:02 Epoch 87 
2016-12-10 02:15:58 Training Error = 0.8174669218607 
2016-12-10 02:15:58 Training Loss = 0.014789807789519 
2016-12-10 02:16:02 Valid Error = 0.86110071134407 
2016-12-10 02:16:02 Valid Loss = 0.015143230248125 
2016-12-10 02:16:05 Test Error = 0.87201077803974 
2016-12-10 02:16:05 Test Loss = 0.015419570175354 
2016-12-10 02:16:05 -------------------LR------------------- 
2016-12-10 02:16:05 0.0078125 
2016-12-10 02:16:05 Epoch 88 
2016-12-10 02:18:04 Training Error = 0.81859033036532 
2016-12-10 02:18:04 Training Loss = 0.014800380448679 
2016-12-10 02:18:08 Valid Error = 0.85323848745788 
2016-12-10 02:18:08 Valid Loss = 0.015125962042307 
2016-12-10 02:18:12 Test Error = 0.86561131694173 
2016-12-10 02:18:12 Test Loss = 0.015402229273157 
2016-12-10 02:18:12 -------------------LR------------------- 
2016-12-10 02:18:12 0.0078125 
2016-12-10 02:18:12 Epoch 89 
2016-12-10 02:20:10 Training Error = 0.8174669218607 
2016-12-10 02:20:10 Training Loss = 0.014812062225768 
2016-12-10 02:20:14 Valid Error = 0.85773118682142 
2016-12-10 02:20:14 Valid Loss = 0.01509209350723 
2016-12-10 02:20:17 Test Error = 0.86897945436174 
2016-12-10 02:20:17 Test Loss = 0.015307011022697 
2016-12-10 02:20:17 -------------------LR------------------- 
2016-12-10 02:20:17 0.0078125 
2016-12-10 02:20:17 Epoch 90 
2016-12-10 02:22:23 Training Error = 0.81892319214446 
2016-12-10 02:22:23 Training Loss = 0.014791927890565 
2016-12-10 02:22:26 Valid Error = 0.85773118682142 
2016-12-10 02:22:26 Valid Loss = 0.015085426489158 
2016-12-10 02:22:30 Test Error = 0.86830582687774 
2016-12-10 02:22:30 Test Loss = 0.015274104959482 
2016-12-10 02:22:30 -------------------LR------------------- 
2016-12-10 02:22:30 0.0078125 
2016-12-10 02:22:30 Epoch 91 
2016-12-10 02:24:26 Training Error = 0.81904801531164 
2016-12-10 02:24:26 Training Loss = 0.014800900164565 
2016-12-10 02:24:30 Valid Error = 0.85960314488955 
2016-12-10 02:24:30 Valid Loss = 0.0150366107391 
2016-12-10 02:24:33 Test Error = 0.87032670932974 
2016-12-10 02:24:33 Test Loss = 0.015263673237565 
2016-12-10 02:24:33 -------------------LR------------------- 
2016-12-10 02:24:33 0.0078125 
2016-12-10 02:24:33 Epoch 92 
2016-12-10 02:26:32 Training Error = 0.81838229175335 
2016-12-10 02:26:32 Training Loss = 0.014783906329199 
2016-12-10 02:26:35 Valid Error = 0.85660801198053 
2016-12-10 02:26:35 Valid Loss = 0.015121875697812 
2016-12-10 02:26:39 Test Error = 0.86864264061974 
2016-12-10 02:26:39 Test Loss = 0.01536894484447 
2016-12-10 02:26:39 -------------------LR------------------- 
2016-12-10 02:26:39 0.0078125 
2016-12-10 02:26:39 Epoch 93 
2016-12-10 02:28:37 Training Error = 0.81996338520429 
2016-12-10 02:28:37 Training Loss = 0.014804505908235 
2016-12-10 02:28:40 Valid Error = 0.85660801198053 
2016-12-10 02:28:40 Valid Loss = 0.015055657327758 
2016-12-10 02:28:44 Test Error = 0.86864264061974 
2016-12-10 02:28:44 Test Loss = 0.015253116968161 
2016-12-10 02:28:44 -------------------LR------------------- 
2016-12-10 02:28:44 0.0078125 
2016-12-10 02:28:44 Epoch 94 
2016-12-10 02:30:44 Training Error = 0.81700923691437 
2016-12-10 02:30:44 Training Loss = 0.014816451079397 
2016-12-10 02:30:48 Valid Error = 0.85773118682142 
2016-12-10 02:30:48 Valid Loss = 0.015034108466324 
2016-12-10 02:30:51 Test Error = 0.86897945436174 
2016-12-10 02:30:51 Test Loss = 0.015253010430619 
2016-12-10 02:30:51 -------------------LR------------------- 
2016-12-10 02:30:51 0.0078125 
2016-12-10 02:30:51 Epoch 95 
2016-12-10 02:32:49 Training Error = 0.8168428060248 
2016-12-10 02:32:49 Training Loss = 0.014787481163901 
2016-12-10 02:32:53 Valid Error = 0.85960314488955 
2016-12-10 02:32:53 Valid Loss = 0.015148717275093 
2016-12-10 02:32:56 Test Error = 0.87032670932974 
2016-12-10 02:32:56 Test Loss = 0.015417524265408 
2016-12-10 02:32:56 -------------------LR------------------- 
2016-12-10 02:32:56 0.0078125 
2016-12-10 02:32:56 Epoch 96 
2016-12-10 02:34:54 Training Error = 0.81958891570275 
2016-12-10 02:34:54 Training Loss = 0.014795573140608 
2016-12-10 02:34:58 Valid Error = 0.86110071134407 
2016-12-10 02:34:58 Valid Loss = 0.015077322338963 
2016-12-10 02:35:01 Test Error = 0.87201077803974 
2016-12-10 02:35:01 Test Loss = 0.015311781815954 
2016-12-10 02:35:01 -------------------LR------------------- 
2016-12-10 02:35:01 0.0078125 
2016-12-10 02:35:01 Epoch 97 
2016-12-10 02:36:58 Training Error = 0.81946409253557 
2016-12-10 02:36:58 Training Loss = 0.014790526765211 
2016-12-10 02:37:01 Valid Error = 0.85660801198053 
2016-12-10 02:37:01 Valid Loss = 0.015054808544792 
2016-12-10 02:37:05 Test Error = 0.86864264061974 
2016-12-10 02:37:05 Test Loss = 0.015258920339175 
2016-12-10 02:37:05 -------------------LR------------------- 
2016-12-10 02:37:05 0.0078125 
2016-12-10 02:37:05 Epoch 98 
2016-12-10 02:39:05 Training Error = 0.81838229175335 
2016-12-10 02:39:05 Training Loss = 0.014817263244941 
2016-12-10 02:39:08 Valid Error = 0.85174092100337 
2016-12-10 02:39:08 Valid Loss = 0.015152146969779 
2016-12-10 02:39:12 Test Error = 0.86460087571573 
2016-12-10 02:39:12 Test Loss = 0.015425976994938 
2016-12-10 02:39:12 -------------------LR------------------- 
2016-12-10 02:39:12 0.0078125 
2016-12-10 02:39:12 Epoch 99 
2016-12-10 02:41:10 Training Error = 0.81767496047266 
2016-12-10 02:41:10 Training Loss = 0.014803232210113 
2016-12-10 02:41:13 Valid Error = 0.85323848745788 
2016-12-10 02:41:13 Valid Loss = 0.015069263569442 
2016-12-10 02:41:17 Test Error = 0.86561131694173 
2016-12-10 02:41:17 Test Loss = 0.01529118593499 
2016-12-10 02:41:17 -------------------LR------------------- 
2016-12-10 02:41:17 0.0078125 
2016-12-10 02:41:17 Epoch 100 
2016-12-10 02:43:21 Training Error = 0.81996338520429 
2016-12-10 02:43:21 Training Loss = 0.01481375472453 
2016-12-10 02:43:25 Valid Error = 0.85660801198053 
2016-12-10 02:43:25 Valid Loss = 0.015144318616245 
2016-12-10 02:43:28 Test Error = 0.86864264061974 
2016-12-10 02:43:28 Test Loss = 0.015424157762596 
2016-12-10 02:43:28 -------------------LR------------------- 
2016-12-10 02:43:28 0.00390625 
2016-12-10 02:43:28 Epoch 101 
2016-12-10 02:45:26 Training Error = 0.81925605392361 
2016-12-10 02:45:26 Training Loss = 0.014807521009205 
2016-12-10 02:45:30 Valid Error = 0.85960314488955 
2016-12-10 02:45:30 Valid Loss = 0.015048233504301 
2016-12-10 02:45:33 Test Error = 0.87032670932974 
2016-12-10 02:45:33 Test Loss = 0.015281723535647 
2016-12-10 02:45:33 -------------------LR------------------- 
2016-12-10 02:45:33 0.00390625 
2016-12-10 02:45:33 Epoch 102 
2016-12-10 02:47:31 Training Error = 0.819297661646 
2016-12-10 02:47:31 Training Loss = 0.014785264298053 
2016-12-10 02:47:34 Valid Error = 0.85960314488955 
2016-12-10 02:47:34 Valid Loss = 0.015060810508694 
2016-12-10 02:47:38 Test Error = 0.87032670932974 
2016-12-10 02:47:38 Test Loss = 0.015311543369986 
2016-12-10 02:47:38 -------------------LR------------------- 
2016-12-10 02:47:38 0.00390625 
2016-12-10 02:47:38 Epoch 103 
2016-12-10 02:49:35 Training Error = 0.82096197054173 
2016-12-10 02:49:35 Training Loss = 0.014795203852143 
2016-12-10 02:49:39 Valid Error = 0.85773118682142 
2016-12-10 02:49:39 Valid Loss = 0.015118560827408 
2016-12-10 02:49:42 Test Error = 0.86897945436174 
2016-12-10 02:49:42 Test Loss = 0.015386090974567 
2016-12-10 02:49:42 -------------------LR------------------- 
2016-12-10 02:49:42 0.00390625 
2016-12-10 02:49:42 Epoch 104 
2016-12-10 02:51:43 Training Error = 0.81750852958309 
2016-12-10 02:51:43 Training Loss = 0.014798898483994 
2016-12-10 02:51:46 Valid Error = 0.85660801198053 
2016-12-10 02:51:46 Valid Loss = 0.015040171044869 
2016-12-10 02:51:50 Test Error = 0.86864264061974 
2016-12-10 02:51:50 Test Loss = 0.015231879235283 
2016-12-10 02:51:50 -------------------LR------------------- 
2016-12-10 02:51:50 0.00390625 
2016-12-10 02:51:50 Epoch 105 
2016-12-10 02:53:46 Training Error = 0.81983856203711 
2016-12-10 02:53:46 Training Loss = 0.014792949747147 
2016-12-10 02:53:50 Valid Error = 0.85660801198053 
2016-12-10 02:53:50 Valid Loss = 0.015042467603783 
2016-12-10 02:53:53 Test Error = 0.86864264061974 
2016-12-10 02:53:53 Test Loss = 0.015238372798137 
2016-12-10 02:53:53 -------------------LR------------------- 
2016-12-10 02:53:53 0.00390625 
2016-12-10 02:53:53 Epoch 106 
2016-12-10 02:55:48 Training Error = 0.81671798285762 
2016-12-10 02:55:48 Training Loss = 0.01480230866231 
2016-12-10 02:55:51 Valid Error = 0.85174092100337 
2016-12-10 02:55:51 Valid Loss = 0.015122281376734 
2016-12-10 02:55:55 Test Error = 0.86460087571573 
2016-12-10 02:55:55 Test Loss = 0.015386481467878 
2016-12-10 02:55:55 -------------------LR------------------- 
2016-12-10 02:55:55 0.00390625 
2016-12-10 02:55:55 Epoch 107 
2016-12-10 02:57:48 Training Error = 0.81642672880087 
2016-12-10 02:57:48 Training Loss = 0.014810969970213 
2016-12-10 02:57:51 Valid Error = 0.85660801198053 
2016-12-10 02:57:51 Valid Loss = 0.015098734395627 
2016-12-10 02:57:55 Test Error = 0.86864264061974 
2016-12-10 02:57:55 Test Loss = 0.01529594259304 
2016-12-10 02:57:55 -------------------LR------------------- 
2016-12-10 02:57:55 0.00390625 
2016-12-10 02:57:55 Epoch 108 
2016-12-10 02:59:49 Training Error = 0.8180910376966 
2016-12-10 02:59:49 Training Loss = 0.014805556550689 
2016-12-10 02:59:53 Valid Error = 0.85174092100337 
2016-12-10 02:59:53 Valid Loss = 0.015100833690836 
2016-12-10 02:59:57 Test Error = 0.86460087571573 
2016-12-10 02:59:57 Test Loss = 0.015369172958195 
2016-12-10 02:59:57 -------------------LR------------------- 
2016-12-10 02:59:57 0.00390625 
2016-12-10 02:59:57 Epoch 109 
2016-12-10 03:01:51 Training Error = 0.82004660064908 
2016-12-10 03:01:51 Training Loss = 0.01481879756177 
2016-12-10 03:01:55 Valid Error = 0.85323848745788 
2016-12-10 03:01:55 Valid Loss = 0.015022597824704 
2016-12-10 03:01:59 Test Error = 0.86561131694173 
2016-12-10 03:01:59 Test Loss = 0.01524053375973 
2016-12-10 03:01:59 -------------------LR------------------- 
2016-12-10 03:01:59 0.00390625 
2016-12-10 03:01:59 Epoch 110 
2016-12-10 03:04:00 Training Error = 0.81634351335608 
2016-12-10 03:04:00 Training Loss = 0.014800250527095 
2016-12-10 03:04:03 Valid Error = 0.85660801198053 
2016-12-10 03:04:03 Valid Loss = 0.015031746285871 
2016-12-10 03:04:07 Test Error = 0.86864264061974 
2016-12-10 03:04:07 Test Loss = 0.015236863796474 
2016-12-10 03:04:07 -------------------LR------------------- 
2016-12-10 03:04:07 0.00390625 
2016-12-10 03:04:07 Epoch 111 
2016-12-10 03:06:00 Training Error = 0.82033785470583 
2016-12-10 03:06:00 Training Loss = 0.014810817252969 
2016-12-10 03:06:03 Valid Error = 0.85286409584425 
2016-12-10 03:06:03 Valid Loss = 0.015128316669563 
2016-12-10 03:06:07 Test Error = 0.86493768945773 
2016-12-10 03:06:07 Test Loss = 0.015383204615695 
2016-12-10 03:06:07 -------------------LR------------------- 
2016-12-10 03:06:07 0.00390625 
2016-12-10 03:06:07 Epoch 112 
2016-12-10 03:08:02 Training Error = 0.81821586086378 
2016-12-10 03:08:02 Training Loss = 0.01483765653537 
2016-12-10 03:08:05 Valid Error = 0.85660801198053 
2016-12-10 03:08:05 Valid Loss = 0.015155191537825 
2016-12-10 03:08:09 Test Error = 0.86864264061974 
2016-12-10 03:08:09 Test Loss = 0.015431406185461 
2016-12-10 03:08:09 -------------------LR------------------- 
2016-12-10 03:08:09 0.00390625 
2016-12-10 03:08:09 Epoch 113 
2016-12-10 03:10:05 Training Error = 0.82150287093285 
2016-12-10 03:10:05 Training Loss = 0.014814183186512 
2016-12-10 03:10:08 Valid Error = 0.85323848745788 
2016-12-10 03:10:08 Valid Loss = 0.015145133414735 
2016-12-10 03:10:12 Test Error = 0.86561131694173 
2016-12-10 03:10:12 Test Loss = 0.015408618795814 
2016-12-10 03:10:12 -------------------LR------------------- 
2016-12-10 03:10:12 0.00390625 
2016-12-10 03:10:12 Epoch 114 
2016-12-10 03:12:07 Training Error = 0.81888158442207 
2016-12-10 03:12:07 Training Loss = 0.014802247599053 
2016-12-10 03:12:10 Valid Error = 0.85660801198053 
2016-12-10 03:12:10 Valid Loss = 0.015043584205613 
2016-12-10 03:12:14 Test Error = 0.86864264061974 
2016-12-10 03:12:14 Test Loss = 0.015245469511779 
2016-12-10 03:12:14 -------------------LR------------------- 
2016-12-10 03:12:14 0.00390625 
2016-12-10 03:12:14 Epoch 115 
2016-12-10 03:14:08 Training Error = 0.81671798285762 
2016-12-10 03:14:08 Training Loss = 0.014797626473398 
2016-12-10 03:14:12 Valid Error = 0.85773118682142 
2016-12-10 03:14:12 Valid Loss = 0.015059482471676 
2016-12-10 03:14:15 Test Error = 0.86897945436174 
2016-12-10 03:14:15 Test Loss = 0.015258319981142 
2016-12-10 03:14:15 -------------------LR------------------- 
2016-12-10 03:14:15 0.00390625 
2016-12-10 03:14:15 Epoch 116 
2016-12-10 03:16:09 Training Error = 0.81771656819506 
2016-12-10 03:16:09 Training Loss = 0.014813683507142 
2016-12-10 03:16:12 Valid Error = 0.85174092100337 
2016-12-10 03:16:12 Valid Loss = 0.015111443971204 
2016-12-10 03:16:16 Test Error = 0.86460087571573 
2016-12-10 03:16:16 Test Loss = 0.015378027490269 
2016-12-10 03:16:16 -------------------LR------------------- 
2016-12-10 03:16:16 0.00390625 
2016-12-10 03:16:16 Epoch 117 
2016-12-10 03:18:10 Training Error = 0.81838229175335 
2016-12-10 03:18:10 Training Loss = 0.014797834731849 
2016-12-10 03:18:14 Valid Error = 0.85660801198053 
2016-12-10 03:18:14 Valid Loss = 0.015133799661181 
2016-12-10 03:18:17 Test Error = 0.86864264061974 
2016-12-10 03:18:17 Test Loss = 0.015390313283371 
2016-12-10 03:18:17 -------------------LR------------------- 
2016-12-10 03:18:17 0.00390625 
2016-12-10 03:18:17 Epoch 118 
2016-12-10 03:20:13 Training Error = 0.81958891570275 
2016-12-10 03:20:13 Training Loss = 0.014801102748581 
2016-12-10 03:20:16 Valid Error = 0.85660801198053 
2016-12-10 03:20:16 Valid Loss = 0.015108290120939 
2016-12-10 03:20:20 Test Error = 0.86864264061974 
2016-12-10 03:20:20 Test Loss = 0.015308945037377 
2016-12-10 03:20:20 -------------------LR------------------- 
2016-12-10 03:20:20 0.00390625 
2016-12-10 03:20:20 Epoch 119 
2016-12-10 03:22:14 Training Error = 0.81925605392361 
2016-12-10 03:22:14 Training Loss = 0.01480302657783 
2016-12-10 03:22:17 Valid Error = 0.85099213777611 
2016-12-10 03:22:17 Valid Loss = 0.01512892308293 
2016-12-10 03:22:21 Test Error = 0.86561131694173 
2016-12-10 03:22:21 Test Loss = 0.015336492912952 
2016-12-10 03:22:21 -------------------LR------------------- 
2016-12-10 03:22:21 0.00390625 
2016-12-10 03:22:21 Epoch 120 
2016-12-10 03:24:20 Training Error = 0.81779978363984 
2016-12-10 03:24:20 Training Loss = 0.014790464177675 
2016-12-10 03:24:24 Valid Error = 0.85960314488955 
2016-12-10 03:24:24 Valid Loss = 0.015078665536675 
2016-12-10 03:24:27 Test Error = 0.87032670932974 
2016-12-10 03:24:27 Test Loss = 0.015295444955943 
2016-12-10 03:24:27 -------------------LR------------------- 
2016-12-10 03:24:27 0.00390625 
2016-12-10 03:24:27 Epoch 121 
2016-12-10 03:26:23 Training Error = 0.81971373886993 
2016-12-10 03:26:23 Training Loss = 0.01481549764166 
2016-12-10 03:26:26 Valid Error = 0.85922875327593 
2016-12-10 03:26:26 Valid Loss = 0.015140377167501 
2016-12-10 03:26:30 Test Error = 0.87268440552375 
2016-12-10 03:26:30 Test Loss = 0.015331955334883 
2016-12-10 03:26:30 -------------------LR------------------- 
2016-12-10 03:26:30 0.00390625 
2016-12-10 03:26:30 Epoch 122 
2016-12-10 03:28:27 Training Error = 0.81963052342515 
2016-12-10 03:28:27 Training Loss = 0.014807712218567 
2016-12-10 03:28:31 Valid Error = 0.85660801198053 
2016-12-10 03:28:31 Valid Loss = 0.015139123869505 
2016-12-10 03:28:35 Test Error = 0.86864264061974 
2016-12-10 03:28:35 Test Loss = 0.015418488449147 
2016-12-10 03:28:35 -------------------LR------------------- 
2016-12-10 03:28:35 0.00390625 
2016-12-10 03:28:35 Epoch 123 
2016-12-10 03:30:29 Training Error = 0.81917283847882 
2016-12-10 03:30:29 Training Loss = 0.014817484198227 
2016-12-10 03:30:32 Valid Error = 0.85660801198053 
2016-12-10 03:30:32 Valid Loss = 0.015087929193078 
2016-12-10 03:30:36 Test Error = 0.86864264061974 
2016-12-10 03:30:36 Test Loss = 0.015335620979098 
2016-12-10 03:30:36 -------------------LR------------------- 
2016-12-10 03:30:36 0.00390625 
2016-12-10 03:30:36 Epoch 124 
2016-12-10 03:32:30 Training Error = 0.81717566780394 
2016-12-10 03:32:30 Training Loss = 0.014816465330522 
2016-12-10 03:32:33 Valid Error = 0.86110071134407 
2016-12-10 03:32:33 Valid Loss = 0.015103038340863 
2016-12-10 03:32:37 Test Error = 0.87201077803974 
2016-12-10 03:32:37 Test Loss = 0.015364713966986 
2016-12-10 03:32:37 -------------------LR------------------- 
2016-12-10 03:32:37 0.00390625 
2016-12-10 03:32:37 Epoch 125 
2016-12-10 03:34:32 Training Error = 0.81963052342515 
2016-12-10 03:34:32 Training Loss = 0.01481701247154 
2016-12-10 03:34:36 Valid Error = 0.85922875327593 
2016-12-10 03:34:36 Valid Loss = 0.015126304500749 
2016-12-10 03:34:40 Test Error = 0.87268440552375 
2016-12-10 03:34:40 Test Loss = 0.015396977668141 
2016-12-10 03:34:40 -------------------LR------------------- 
2016-12-10 03:34:40 0.00390625 
2016-12-10 03:34:40 Epoch 126 
2016-12-10 03:36:35 Training Error = 0.81863193808771 
2016-12-10 03:36:35 Training Loss = 0.014792826874354 
2016-12-10 03:36:39 Valid Error = 0.85660801198053 
2016-12-10 03:36:39 Valid Loss = 0.015117377208545 
2016-12-10 03:36:42 Test Error = 0.86864264061974 
2016-12-10 03:36:42 Test Loss = 0.015311209282846 
2016-12-10 03:36:42 -------------------LR------------------- 
2016-12-10 03:36:42 0.00390625 
2016-12-10 03:36:42 Epoch 127 
2016-12-10 03:38:37 Training Error = 0.81775817591745 
2016-12-10 03:38:37 Training Loss = 0.0147922482396 
2016-12-10 03:38:40 Valid Error = 0.85922875327593 
2016-12-10 03:38:40 Valid Loss = 0.015126122054917 
2016-12-10 03:38:44 Test Error = 0.87268440552375 
2016-12-10 03:38:44 Test Loss = 0.015408881646946 
2016-12-10 03:38:44 -------------------LR------------------- 
2016-12-10 03:38:44 0.00390625 
2016-12-10 03:38:44 Epoch 128 
2016-12-10 03:40:41 Training Error = 0.81842389947574 
2016-12-10 03:40:41 Training Loss = 0.014795359520313 
2016-12-10 03:40:44 Valid Error = 0.85660801198053 
2016-12-10 03:40:44 Valid Loss = 0.015119516441156 
2016-12-10 03:40:48 Test Error = 0.86864264061974 
2016-12-10 03:40:48 Test Loss = 0.015383267320394 
2016-12-10 03:40:48 -------------------LR------------------- 
2016-12-10 03:40:48 0.00390625 
2016-12-10 03:40:48 Epoch 129 
2016-12-10 03:42:43 Training Error = 0.81917283847882 
2016-12-10 03:42:43 Training Loss = 0.014811782710241 
2016-12-10 03:42:46 Valid Error = 0.85174092100337 
2016-12-10 03:42:46 Valid Loss = 0.015114245839261 
2016-12-10 03:42:50 Test Error = 0.86460087571573 
2016-12-10 03:42:50 Test Loss = 0.015363633739187 
2016-12-10 03:42:50 -------------------LR------------------- 
2016-12-10 03:42:50 0.00390625 
2016-12-10 03:42:50 Epoch 130 
2016-12-10 03:44:52 Training Error = 0.82029624698344 
2016-12-10 03:44:52 Training Loss = 0.014836532515785 
2016-12-10 03:44:55 Valid Error = 0.85323848745788 
2016-12-10 03:44:55 Valid Loss = 0.015092207276223 
2016-12-10 03:44:59 Test Error = 0.86561131694173 
2016-12-10 03:44:59 Test Loss = 0.0153052113865 
2016-12-10 03:44:59 -------------------LR------------------- 
2016-12-10 03:44:59 0.00390625 
2016-12-10 03:44:59 Epoch 131 
2016-12-10 03:46:53 Training Error = 0.81846550719814 
2016-12-10 03:46:53 Training Loss = 0.01480712163062 
2016-12-10 03:46:56 Valid Error = 0.85997753650318 
2016-12-10 03:46:56 Valid Loss = 0.015108324063543 
2016-12-10 03:47:00 Test Error = 0.87032670932974 
2016-12-10 03:47:00 Test Loss = 0.015349475003042 
2016-12-10 03:47:00 -------------------LR------------------- 
2016-12-10 03:47:00 0.00390625 
2016-12-10 03:47:00 Epoch 132 
2016-12-10 03:48:55 Training Error = 0.81975534659233 
2016-12-10 03:48:55 Training Loss = 0.014811156826191 
2016-12-10 03:48:58 Valid Error = 0.86035192811681 
2016-12-10 03:48:58 Valid Loss = 0.015129209111899 
2016-12-10 03:49:02 Test Error = 0.87302121926575 
2016-12-10 03:49:02 Test Loss = 0.01535330827186 
2016-12-10 03:49:02 -------------------LR------------------- 
2016-12-10 03:49:02 0.00390625 
2016-12-10 03:49:02 Epoch 133 
2016-12-10 03:50:57 Training Error = 0.81888158442207 
2016-12-10 03:50:57 Training Loss = 0.01481283557038 
2016-12-10 03:51:01 Valid Error = 0.85286409584425 
2016-12-10 03:51:01 Valid Loss = 0.015103563660579 
2016-12-10 03:51:05 Test Error = 0.86662175816773 
2016-12-10 03:51:05 Test Loss = 0.015343361056703 
2016-12-10 03:51:05 -------------------LR------------------- 
2016-12-10 03:51:05 0.00390625 
2016-12-10 03:51:05 Epoch 134 
2016-12-10 03:53:00 Training Error = 0.81763335275027 
2016-12-10 03:53:00 Training Loss = 0.014795095352731 
2016-12-10 03:53:03 Valid Error = 0.85960314488955 
2016-12-10 03:53:03 Valid Loss = 0.015101259450334 
2016-12-10 03:53:07 Test Error = 0.87032670932974 
2016-12-10 03:53:07 Test Loss = 0.015333247300709 
2016-12-10 03:53:07 -------------------LR------------------- 
2016-12-10 03:53:07 0.00390625 
2016-12-10 03:53:07 Epoch 135 
2016-12-10 03:54:56 Training Error = 0.8199217774819 
2016-12-10 03:54:56 Training Loss = 0.014783473408381 
2016-12-10 03:54:59 Valid Error = 0.85323848745788 
2016-12-10 03:54:59 Valid Loss = 0.015065484849711 
2016-12-10 03:55:03 Test Error = 0.86561131694173 
2016-12-10 03:55:03 Test Loss = 0.01526700918961 
2016-12-10 03:55:03 -------------------LR------------------- 
2016-12-10 03:55:03 0.00390625 
2016-12-10 03:55:03 Epoch 136 
2016-12-10 03:56:55 Training Error = 0.81854872264292 
2016-12-10 03:56:55 Training Loss = 0.014815326632498 
2016-12-10 03:56:58 Valid Error = 0.85660801198053 
2016-12-10 03:56:58 Valid Loss = 0.015080595076337 
2016-12-10 03:57:02 Test Error = 0.86864264061974 
2016-12-10 03:57:02 Test Loss = 0.015272118702255 
2016-12-10 03:57:02 -------------------LR------------------- 
2016-12-10 03:57:02 0.00390625 
2016-12-10 03:57:02 Epoch 137 
2016-12-10 03:58:52 Training Error = 0.82104518598652 
2016-12-10 03:58:52 Training Loss = 0.014810676416492 
2016-12-10 03:58:55 Valid Error = 0.85660801198053 
2016-12-10 03:58:55 Valid Loss = 0.015062588955649 
2016-12-10 03:58:59 Test Error = 0.86864264061974 
2016-12-10 03:58:59 Test Loss = 0.01526133693155 
2016-12-10 03:58:59 -------------------LR------------------- 
2016-12-10 03:58:59 0.00390625 
2016-12-10 03:58:59 Epoch 138 
2016-12-10 04:00:50 Training Error = 0.81921444620121 
2016-12-10 04:00:50 Training Loss = 0.014824200802539 
2016-12-10 04:00:54 Valid Error = 0.85773118682142 
2016-12-10 04:00:54 Valid Loss = 0.015078370414429 
2016-12-10 04:00:57 Test Error = 0.86897945436174 
2016-12-10 04:00:57 Test Loss = 0.015284966003965 
2016-12-10 04:00:57 -------------------LR------------------- 
2016-12-10 04:00:57 0.00390625 
2016-12-10 04:00:57 Epoch 139 
2016-12-10 04:02:48 Training Error = 0.81755013730548 
2016-12-10 04:02:48 Training Loss = 0.014796858963283 
2016-12-10 04:02:51 Valid Error = 0.86110071134407 
2016-12-10 04:02:51 Valid Loss = 0.015058229494912 
2016-12-10 04:02:55 Test Error = 0.87201077803974 
2016-12-10 04:02:55 Test Loss = 0.015237435981377 
2016-12-10 04:02:55 -------------------LR------------------- 
2016-12-10 04:02:55 0.00390625 
2016-12-10 04:02:55 Epoch 140 
2016-12-10 04:04:50 Training Error = 0.81875676125489 
2016-12-10 04:04:50 Training Loss = 0.014820929017915 
2016-12-10 04:04:54 Valid Error = 0.86072631973044 
2016-12-10 04:04:54 Valid Loss = 0.015145842510352 
2016-12-10 04:04:58 Test Error = 0.87066352307174 
2016-12-10 04:04:58 Test Loss = 0.015416472294378 
2016-12-10 04:04:58 -------------------LR------------------- 
2016-12-10 04:04:58 0.00390625 
2016-12-10 04:04:58 Epoch 141 
2016-12-10 04:06:49 Training Error = 0.81933926936839 
2016-12-10 04:06:49 Training Loss = 0.014796732215842 
2016-12-10 04:06:52 Valid Error = 0.86110071134407 
2016-12-10 04:06:52 Valid Loss = 0.015032045913864 
2016-12-10 04:06:56 Test Error = 0.87201077803974 
2016-12-10 04:06:56 Test Loss = 0.015241353289689 
2016-12-10 04:06:56 -------------------LR------------------- 
2016-12-10 04:06:56 0.00390625 
2016-12-10 04:06:56 Epoch 142 
2016-12-10 04:08:47 Training Error = 0.81975534659233 
2016-12-10 04:08:47 Training Loss = 0.014814220845442 
2016-12-10 04:08:50 Valid Error = 0.85660801198053 
2016-12-10 04:08:50 Valid Loss = 0.015129481844757 
2016-12-10 04:08:54 Test Error = 0.86864264061974 
2016-12-10 04:08:54 Test Loss = 0.015394557177299 
2016-12-10 04:08:54 -------------------LR------------------- 
2016-12-10 04:08:54 0.00390625 
2016-12-10 04:08:54 Epoch 143 
2016-12-10 04:10:46 Training Error = 0.82071232420737 
2016-12-10 04:10:46 Training Loss = 0.014801531621943 
2016-12-10 04:10:49 Valid Error = 0.85323848745788 
2016-12-10 04:10:49 Valid Loss = 0.015038018442218 
2016-12-10 04:10:53 Test Error = 0.86561131694173 
2016-12-10 04:10:53 Test Loss = 0.01526646152851 
2016-12-10 04:10:53 -------------------LR------------------- 
2016-12-10 04:10:53 0.00390625 
2016-12-10 04:10:53 Epoch 144 
2016-12-10 04:12:43 Training Error = 0.81879836897728 
2016-12-10 04:12:43 Training Loss = 0.014826239664318 
2016-12-10 04:12:46 Valid Error = 0.85323848745788 
2016-12-10 04:12:46 Valid Loss = 0.01508027165823 
2016-12-10 04:12:50 Test Error = 0.86561131694173 
2016-12-10 04:12:50 Test Loss = 0.015305031303648 
2016-12-10 04:12:50 -------------------LR------------------- 
2016-12-10 04:12:50 0.00390625 
2016-12-10 04:12:50 Epoch 145 
2016-12-10 04:14:41 Training Error = 0.81950570025797 
2016-12-10 04:14:41 Training Loss = 0.014797394300741 
2016-12-10 04:14:44 Valid Error = 0.85323848745788 
2016-12-10 04:14:44 Valid Loss = 0.015050425949489 
2016-12-10 04:14:48 Test Error = 0.86561131694173 
2016-12-10 04:14:48 Test Loss = 0.015273305777837 
2016-12-10 04:14:48 -------------------LR------------------- 
2016-12-10 04:14:48 0.00390625 
2016-12-10 04:14:48 Epoch 146 
2016-12-10 04:16:38 Training Error = 0.81954730798036 
2016-12-10 04:16:38 Training Loss = 0.014807413688309 
2016-12-10 04:16:42 Valid Error = 0.86110071134407 
2016-12-10 04:16:42 Valid Loss = 0.015077435419696 
2016-12-10 04:16:45 Test Error = 0.87201077803974 
2016-12-10 04:16:45 Test Loss = 0.01527898415884 
2016-12-10 04:16:45 -------------------LR------------------- 
2016-12-10 04:16:45 0.00390625 
2016-12-10 04:16:45 Epoch 147 
2016-12-10 04:18:36 Training Error = 0.81838229175335 
2016-12-10 04:18:36 Training Loss = 0.014806380633503 
2016-12-10 04:18:39 Valid Error = 0.85473605391239 
2016-12-10 04:18:39 Valid Loss = 0.015153963375715 
2016-12-10 04:18:43 Test Error = 0.86628494442573 
2016-12-10 04:18:43 Test Loss = 0.015415826851271 
2016-12-10 04:18:43 -------------------LR------------------- 
2016-12-10 04:18:43 0.00390625 
2016-12-10 04:18:43 Epoch 148 
2016-12-10 04:20:35 Training Error = 0.81771656819506 
2016-12-10 04:20:35 Training Loss = 0.014786365232855 
2016-12-10 04:20:38 Valid Error = 0.85660801198053 
2016-12-10 04:20:38 Valid Loss = 0.015093145005024 
2016-12-10 04:20:42 Test Error = 0.86864264061974 
2016-12-10 04:20:42 Test Loss = 0.015294707873941 
2016-12-10 04:20:42 -------------------LR------------------- 
2016-12-10 04:20:42 0.00390625 
2016-12-10 04:20:42 Epoch 149 
2016-12-10 04:22:31 Training Error = 0.8174669218607 
2016-12-10 04:22:31 Training Loss = 0.014798035343848 
2016-12-10 04:22:34 Valid Error = 0.86072631973044 
2016-12-10 04:22:34 Valid Loss = 0.015015198294472 
2016-12-10 04:22:38 Test Error = 0.87066352307174 
2016-12-10 04:22:38 Test Loss = 0.015213665913406 
2016-12-10 04:22:38 -------------------LR------------------- 
2016-12-10 04:22:38 0.00390625 
2016-12-10 04:22:38 Epoch 150 
2016-12-10 04:24:36 Training Error = 0.81817425314138 
2016-12-10 04:24:36 Training Loss = 0.014794404567714 
2016-12-10 04:24:39 Valid Error = 0.85323848745788 
2016-12-10 04:24:39 Valid Loss = 0.015098749602772 
2016-12-10 04:24:43 Test Error = 0.86561131694173 
2016-12-10 04:24:43 Test Loss = 0.01531346232823 
2016-12-10 04:24:43 -------------------LR------------------- 
2016-12-10 04:24:43 0.001953125 
2016-12-10 04:24:43 Epoch 151 
