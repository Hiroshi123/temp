2016-12-09 23:12:12 [program started on Fri Dec  9 23:12:12 2016] 
2016-12-09 23:12:12 [command line arguments] 
2016-12-09 23:12:12 stcWeights false 
2016-12-09 23:12:12 LR 0.015625 
2016-12-09 23:12:12 batchSize 300 
2016-12-09 23:12:12 network ./Models/Cifar10_Custom 
2016-12-09 23:12:12 stcNeurons true 
2016-12-09 23:12:12 constBatchSize false 
2016-12-09 23:12:12 chartFileName chart1 
2016-12-09 23:12:12 dp_prepro false 
2016-12-09 23:12:12 nGPU 1 
2016-12-09 23:12:12 dataset Caltech256 
2016-12-09 23:12:12 type cuda 
2016-12-09 23:12:12 momentum 0 
2016-12-09 23:12:12 threads 8 
2016-12-09 23:12:12 weightDecay 0 
2016-12-09 23:12:12 runningVal false 
2016-12-09 23:12:12 convLayerN 2 
2016-12-09 23:12:12 LRDecay 0 
2016-12-09 23:12:12 numHid 1024 
2016-12-09 23:12:12 save /dev/shm/clone/temp/th/Results/Caltech256/model2-10 
2016-12-09 23:12:12 augment false 
2016-12-09 23:12:12 epoch -1 
2016-12-09 23:12:12 modelsFolder ./Models/ 
2016-12-09 23:12:12 format rgb 
2016-12-09 23:12:12 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-09 23:12:12 imageFileExtension svg 
2016-12-09 23:12:12 channel 1 
2016-12-09 23:12:12 devid 15 
2016-12-09 23:12:12 visualize 1 
2016-12-09 23:12:12 LRDecayPerEpoch 0.0001 
2016-12-09 23:12:12 optimization adam 
2016-12-09 23:12:12 SBN true 
2016-12-09 23:12:12 normalization simple 
2016-12-09 23:12:12 title model1 
2016-12-09 23:12:12 load  
2016-12-09 23:12:12 whiten true 
2016-12-09 23:12:12 [----------------------] 
2016-12-09 23:12:14 ==> Network 
2016-12-09 23:12:14 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): nn.View(32768)
  (11): BinaryLinear(32768 -> 1024)
  (12): BatchNormalizationShiftPow2
  (13): nn.HardTanh
  (14): BinarizedNeurons
  (15): BinaryLinear(1024 -> 1024)
  (16): BatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): BinaryLinear(1024 -> 255)
  (20): nn.BatchNormalization
} 
2016-12-09 23:12:14 ==>35022717 Parameters 
2016-12-09 23:12:14 ==> Loss 
2016-12-09 23:12:14 SqrtHingeEmbeddingCriterion 
2016-12-09 23:12:14 
==> Starting Training
 
2016-12-09 23:12:14 Epoch 1 
2016-12-09 23:14:13 Training Error = 0.98681035200133 
2016-12-09 23:14:13 Training Loss = 0.44148062215181 
2016-12-09 23:14:17 Valid Error = 0.98839385997754 
2016-12-09 23:14:17 Valid Loss = 0.079844750973488 
2016-12-09 23:14:20 Test Error = 0.98720107780397 
2016-12-09 23:14:20 Test Loss = 0.081327395096824 
2016-12-09 23:14:20 -------------------LR------------------- 
2016-12-09 23:14:20 0.015625 
2016-12-09 23:14:20 Epoch 2 
2016-12-09 23:16:22 Training Error = 0.95993176333528 
2016-12-09 23:16:22 Training Loss = 0.036305875408038 
2016-12-09 23:16:25 Valid Error = 0.94309247472857 
2016-12-09 23:16:25 Valid Loss = 0.019711665421361 
2016-12-09 23:16:29 Test Error = 0.95486695857191 
2016-12-09 23:16:29 Test Loss = 0.019635249982869 
2016-12-09 23:16:29 -------------------LR------------------- 
2016-12-09 23:16:29 0.015625 
2016-12-09 23:16:29 Epoch 3 
2016-12-09 23:18:30 Training Error = 0.94241491220771 
2016-12-09 23:18:30 Training Loss = 0.017414228328383 
2016-12-09 23:18:33 Valid Error = 0.9906402096593 
2016-12-09 23:18:33 Valid Loss = 0.016828422254412 
2016-12-09 23:18:37 Test Error = 0.98854833277198 
2016-12-09 23:18:37 Test Loss = 0.016908077714415 
2016-12-09 23:18:37 -------------------LR------------------- 
2016-12-09 23:18:37 0.015625 
2016-12-09 23:18:37 Epoch 4 
2016-12-09 23:20:39 Training Error = 0.9245235915786 
2016-12-09 23:20:39 Training Loss = 0.016357355990486 
2016-12-09 23:20:42 Valid Error = 0.94983152377387 
2016-12-09 23:20:42 Valid Loss = 0.016211630827134 
2016-12-09 23:20:46 Test Error = 0.96328730212193 
2016-12-09 23:20:46 Test Loss = 0.016223425620708 
2016-12-09 23:20:46 -------------------LR------------------- 
2016-12-09 23:20:46 0.015625 
2016-12-09 23:20:46 Epoch 5 
2016-12-09 23:22:46 Training Error = 0.91408005325788 
2016-12-09 23:22:46 Training Loss = 0.016111063831397 
2016-12-09 23:22:49 Valid Error = 0.94496443279671 
2016-12-09 23:22:49 Valid Loss = 0.016586245190842 
2016-12-09 23:22:53 Test Error = 0.95587739979791 
2016-12-09 23:22:53 Test Loss = 0.017273527594813 
2016-12-09 23:22:53 -------------------LR------------------- 
2016-12-09 23:22:53 0.015625 
2016-12-09 23:22:53 Epoch 6 
2016-12-09 23:24:55 Training Error = 0.90184738287426 
2016-12-09 23:24:55 Training Loss = 0.015793699468125 
2016-12-09 23:24:58 Valid Error = 0.91950580307001 
2016-12-09 23:24:58 Valid Loss = 0.016211802090048 
2016-12-09 23:25:02 Test Error = 0.93533176153587 
2016-12-09 23:25:02 Test Loss = 0.016545584424619 
2016-12-09 23:25:02 -------------------LR------------------- 
2016-12-09 23:25:02 0.015625 
2016-12-09 23:25:02 Epoch 7 
2016-12-09 23:27:01 Training Error = 0.88433053174669 
2016-12-09 23:27:01 Training Loss = 0.01556151404703 
2016-12-09 23:27:04 Valid Error = 0.9382253837514 
2016-12-09 23:27:04 Valid Loss = 0.016413624811097 
2016-12-09 23:27:08 Test Error = 0.95486695857191 
2016-12-09 23:27:08 Test Loss = 0.016613667969414 
2016-12-09 23:27:08 -------------------LR------------------- 
2016-12-09 23:27:08 0.015625 
2016-12-09 23:27:08 Epoch 8 
2016-12-09 23:29:08 Training Error = 0.87463593242906 
2016-12-09 23:29:08 Training Loss = 0.015302405655833 
2016-12-09 23:29:11 Valid Error = 0.92324971920629 
2016-12-09 23:29:11 Valid Loss = 0.015948974258048 
2016-12-09 23:29:15 Test Error = 0.93566857527787 
2016-12-09 23:29:15 Test Loss = 0.01606281507707 
2016-12-09 23:29:15 -------------------LR------------------- 
2016-12-09 23:29:15 0.015625 
2016-12-09 23:29:15 Epoch 9 
2016-12-09 23:31:16 Training Error = 0.85412332528917 
2016-12-09 23:31:16 Training Loss = 0.015008777959299 
2016-12-09 23:31:19 Valid Error = 0.89853987270685 
2016-12-09 23:31:19 Valid Loss = 0.015266748135066 
2016-12-09 23:31:23 Test Error = 0.91714381946783 
2016-12-09 23:31:23 Test Loss = 0.015493550649039 
2016-12-09 23:31:23 -------------------LR------------------- 
2016-12-09 23:31:23 0.015625 
2016-12-09 23:31:23 Epoch 10 
2016-12-09 23:33:30 Training Error = 0.83423483398519 
2016-12-09 23:33:30 Training Loss = 0.014790301269654 
2016-12-09 23:33:34 Valid Error = 0.86634219393486 
2016-12-09 23:33:34 Valid Loss = 0.015331222381537 
2016-12-09 23:33:37 Test Error = 0.87638935668575 
2016-12-09 23:33:37 Test Loss = 0.015526965158522 
2016-12-09 23:33:37 -------------------LR------------------- 
2016-12-09 23:33:37 0.015625 
2016-12-09 23:33:37 Epoch 11 
2016-12-09 23:35:37 Training Error = 0.81967213114754 
2016-12-09 23:35:37 Training Loss = 0.014790350515011 
2016-12-09 23:35:40 Valid Error = 0.85174092100337 
2016-12-09 23:35:40 Valid Loss = 0.015119149612289 
2016-12-09 23:35:44 Test Error = 0.86460087571573 
2016-12-09 23:35:44 Test Loss = 0.015376940680395 
2016-12-09 23:35:44 -------------------LR------------------- 
2016-12-09 23:35:44 0.015625 
2016-12-09 23:35:44 Epoch 12 
2016-12-09 23:37:45 Training Error = 0.81888158442207 
2016-12-09 23:37:45 Training Loss = 0.014821506035251 
2016-12-09 23:37:48 Valid Error = 0.85660801198053 
2016-12-09 23:37:48 Valid Loss = 0.015039644982592 
2016-12-09 23:37:52 Test Error = 0.86864264061974 
2016-12-09 23:37:52 Test Loss = 0.015233280055664 
2016-12-09 23:37:52 -------------------LR------------------- 
2016-12-09 23:37:52 0.015625 
2016-12-09 23:37:52 Epoch 13 
2016-12-09 23:39:54 Training Error = 0.82029624698344 
2016-12-09 23:39:54 Training Loss = 0.014823373091761 
2016-12-09 23:39:57 Valid Error = 0.86110071134407 
2016-12-09 23:39:57 Valid Loss = 0.015117917159675 
2016-12-09 23:40:01 Test Error = 0.87201077803974 
2016-12-09 23:40:01 Test Loss = 0.015356470365432 
2016-12-09 23:40:01 -------------------LR------------------- 
2016-12-09 23:40:01 0.015625 
2016-12-09 23:40:01 Epoch 14 
2016-12-09 23:42:02 Training Error = 0.81942248481318 
2016-12-09 23:42:02 Training Loss = 0.014800728362193 
2016-12-09 23:42:05 Valid Error = 0.8562336203669 
2016-12-09 23:42:05 Valid Loss = 0.015041523725784 
2016-12-09 23:42:09 Test Error = 0.86729538565173 
2016-12-09 23:42:09 Test Loss = 0.015254139524508 
2016-12-09 23:42:09 -------------------LR------------------- 
2016-12-09 23:42:09 0.015625 
2016-12-09 23:42:09 Epoch 15 
2016-12-09 23:44:09 Training Error = 0.81863193808771 
2016-12-09 23:44:09 Training Loss = 0.014786756095296 
2016-12-09 23:44:12 Valid Error = 0.85660801198053 
2016-12-09 23:44:12 Valid Loss = 0.015083019622833 
2016-12-09 23:44:16 Test Error = 0.86864264061974 
2016-12-09 23:44:16 Test Loss = 0.015319520674547 
2016-12-09 23:44:16 -------------------LR------------------- 
2016-12-09 23:44:16 0.015625 
2016-12-09 23:44:16 Epoch 16 
2016-12-09 23:46:18 Training Error = 0.81883997669968 
2016-12-09 23:46:18 Training Loss = 0.014798732524954 
2016-12-09 23:46:22 Valid Error = 0.86409584425309 
2016-12-09 23:46:22 Valid Loss = 0.015034317754298 
2016-12-09 23:46:25 Test Error = 0.87369484674975 
2016-12-09 23:46:25 Test Loss = 0.015266989385254 
2016-12-09 23:46:25 -------------------LR------------------- 
2016-12-09 23:46:25 0.015625 
2016-12-09 23:46:25 Epoch 17 
2016-12-09 23:48:26 Training Error = 0.81954730798036 
2016-12-09 23:48:26 Training Loss = 0.014821384826518 
2016-12-09 23:48:30 Valid Error = 0.85660801198053 
2016-12-09 23:48:30 Valid Loss = 0.015102340581256 
2016-12-09 23:48:34 Test Error = 0.86864264061974 
2016-12-09 23:48:34 Test Loss = 0.015298703406079 
2016-12-09 23:48:34 -------------------LR------------------- 
2016-12-09 23:48:34 0.015625 
2016-12-09 23:48:34 Epoch 18 
2016-12-09 23:50:35 Training Error = 0.82050428559541 
2016-12-09 23:50:35 Training Loss = 0.014820090488135 
2016-12-09 23:50:38 Valid Error = 0.85660801198053 
2016-12-09 23:50:38 Valid Loss = 0.015103586183431 
2016-12-09 23:50:42 Test Error = 0.86864264061974 
2016-12-09 23:50:42 Test Loss = 0.015323043296857 
2016-12-09 23:50:42 -------------------LR------------------- 
2016-12-09 23:50:42 0.015625 
2016-12-09 23:50:42 Epoch 19 
2016-12-09 23:52:40 Training Error = 0.81863193808771 
2016-12-09 23:52:40 Training Loss = 0.01479804366502 
2016-12-09 23:52:44 Valid Error = 0.85174092100337 
2016-12-09 23:52:44 Valid Loss = 0.015116566168007 
2016-12-09 23:52:47 Test Error = 0.86460087571573 
2016-12-09 23:52:47 Test Loss = 0.015385273265711 
2016-12-09 23:52:47 -------------------LR------------------- 
2016-12-09 23:52:47 0.015625 
2016-12-09 23:52:47 Epoch 20 
2016-12-09 23:54:58 Training Error = 0.82079553965216 
2016-12-09 23:54:58 Training Loss = 0.014821564034598 
2016-12-09 23:55:02 Valid Error = 0.85174092100337 
2016-12-09 23:55:02 Valid Loss = 0.015090134487531 
2016-12-09 23:55:06 Test Error = 0.86460087571573 
2016-12-09 23:55:06 Test Loss = 0.015338852696377 
2016-12-09 23:55:06 -------------------LR------------------- 
2016-12-09 23:55:06 0.015625 
2016-12-09 23:55:06 Epoch 21 
2016-12-09 23:57:22 Training Error = 0.81950570025797 
2016-12-09 23:57:22 Training Loss = 0.01481041947529 
2016-12-09 23:57:26 Valid Error = 0.8562336203669 
2016-12-09 23:57:26 Valid Loss = 0.015139120732427 
2016-12-09 23:57:29 Test Error = 0.86796901313574 
2016-12-09 23:57:29 Test Loss = 0.015403958582712 
2016-12-09 23:57:29 -------------------LR------------------- 
2016-12-09 23:57:29 0.015625 
2016-12-09 23:57:29 Epoch 22 
2016-12-09 23:59:45 Training Error = 0.81825746858617 
2016-12-09 23:59:45 Training Loss = 0.014794652352237 
2016-12-09 23:59:48 Valid Error = 0.85660801198053 
2016-12-09 23:59:48 Valid Loss = 0.015088835584457 
2016-12-09 23:59:52 Test Error = 0.86864264061974 
2016-12-09 23:59:52 Test Loss = 0.015291130742492 
2016-12-09 23:59:52 -------------------LR------------------- 
2016-12-09 23:59:52 0.015625 
2016-12-09 23:59:52 Epoch 23 
2016-12-10 00:02:01 Training Error = 0.81829907630856 
2016-12-10 00:02:01 Training Loss = 0.014810238903864 
2016-12-10 00:02:04 Valid Error = 0.85660801198053 
2016-12-10 00:02:04 Valid Loss = 0.015115358384152 
2016-12-10 00:02:08 Test Error = 0.86864264061974 
2016-12-10 00:02:08 Test Loss = 0.015351845288957 
2016-12-10 00:02:08 -------------------LR------------------- 
2016-12-10 00:02:08 0.015625 
2016-12-10 00:02:08 Epoch 24 
2016-12-10 00:04:10 Training Error = 0.82021303153865 
2016-12-10 00:04:10 Training Loss = 0.014815512203349 
2016-12-10 00:04:14 Valid Error = 0.86110071134407 
2016-12-10 00:04:14 Valid Loss = 0.015084470914664 
2016-12-10 00:04:17 Test Error = 0.87201077803974 
2016-12-10 00:04:17 Test Loss = 0.015271157985731 
2016-12-10 00:04:17 -------------------LR------------------- 
2016-12-10 00:04:17 0.015625 
2016-12-10 00:04:17 Epoch 25 
2016-12-10 00:06:20 Training Error = 0.81933926936839 
2016-12-10 00:06:20 Training Loss = 0.014805747628816 
2016-12-10 00:06:24 Valid Error = 0.85174092100337 
2016-12-10 00:06:24 Valid Loss = 0.015114542158111 
2016-12-10 00:06:28 Test Error = 0.86460087571573 
2016-12-10 00:06:28 Test Loss = 0.015381217722565 
2016-12-10 00:06:28 -------------------LR------------------- 
2016-12-10 00:06:28 0.015625 
2016-12-10 00:06:28 Epoch 26 
2016-12-10 00:08:26 Training Error = 0.81721727552634 
2016-12-10 00:08:26 Training Loss = 0.014820451507865 
2016-12-10 00:08:29 Valid Error = 0.85660801198053 
2016-12-10 00:08:29 Valid Loss = 0.015159012109917 
2016-12-10 00:08:33 Test Error = 0.86864264061974 
2016-12-10 00:08:33 Test Loss = 0.015436435140656 
2016-12-10 00:08:33 -------------------LR------------------- 
2016-12-10 00:08:33 0.015625 
2016-12-10 00:08:33 Epoch 27 
2016-12-10 00:10:34 Training Error = 0.8174253141383 
2016-12-10 00:10:34 Training Loss = 0.014806474212573 
2016-12-10 00:10:37 Valid Error = 0.85960314488955 
2016-12-10 00:10:37 Valid Loss = 0.01514811047049 
2016-12-10 00:10:41 Test Error = 0.87032670932974 
2016-12-10 00:10:41 Test Loss = 0.015413247967102 
2016-12-10 00:10:41 -------------------LR------------------- 
2016-12-10 00:10:41 0.015625 
2016-12-10 00:10:41 Epoch 28 
2016-12-10 00:12:40 Training Error = 0.82121161687609 
2016-12-10 00:12:40 Training Loss = 0.014814302955994 
2016-12-10 00:12:43 Valid Error = 0.86110071134407 
2016-12-10 00:12:43 Valid Loss = 0.01509096318665 
2016-12-10 00:12:47 Test Error = 0.87201077803974 
2016-12-10 00:12:47 Test Loss = 0.015272023150655 
2016-12-10 00:12:47 -------------------LR------------------- 
2016-12-10 00:12:47 0.015625 
2016-12-10 00:12:47 Epoch 29 
2016-12-10 00:14:46 Training Error = 0.81838229175335 
2016-12-10 00:14:46 Training Loss = 0.014805716338452 
2016-12-10 00:14:49 Valid Error = 0.85660801198053 
2016-12-10 00:14:49 Valid Loss = 0.015116111482615 
2016-12-10 00:14:53 Test Error = 0.86864264061974 
2016-12-10 00:14:53 Test Loss = 0.015377144531914 
2016-12-10 00:14:53 -------------------LR------------------- 
2016-12-10 00:14:53 0.015625 
2016-12-10 00:14:53 Epoch 30 
2016-12-10 00:17:00 Training Error = 0.81846550719814 
2016-12-10 00:17:00 Training Loss = 0.014787182986792 
2016-12-10 00:17:04 Valid Error = 0.85960314488955 
2016-12-10 00:17:04 Valid Loss = 0.015153386488835 
2016-12-10 00:17:07 Test Error = 0.87032670932974 
2016-12-10 00:17:07 Test Loss = 0.015418541946298 
2016-12-10 00:17:07 -------------------LR------------------- 
2016-12-10 00:17:07 0.015625 
2016-12-10 00:17:08 Epoch 31 
2016-12-10 00:19:05 Training Error = 0.82000499292669 
2016-12-10 00:19:05 Training Loss = 0.014800652400611 
2016-12-10 00:19:09 Valid Error = 0.86110071134407 
2016-12-10 00:19:09 Valid Loss = 0.015044706051173 
2016-12-10 00:19:12 Test Error = 0.87201077803974 
2016-12-10 00:19:12 Test Loss = 0.015274852539229 
2016-12-10 00:19:12 -------------------LR------------------- 
2016-12-10 00:19:12 0.015625 
2016-12-10 00:19:12 Epoch 32 
2016-12-10 00:21:13 Training Error = 0.81834068403096 
2016-12-10 00:21:13 Training Loss = 0.014806741356286 
2016-12-10 00:21:16 Valid Error = 0.85286409584425 
2016-12-10 00:21:16 Valid Loss = 0.015057769712993 
2016-12-10 00:21:20 Test Error = 0.86359043448973 
2016-12-10 00:21:20 Test Loss = 0.015257942640709 
2016-12-10 00:21:20 -------------------LR------------------- 
2016-12-10 00:21:20 0.015625 
2016-12-10 00:21:20 Epoch 33 
2016-12-10 00:23:17 Training Error = 0.81725888324873 
2016-12-10 00:23:17 Training Loss = 0.014810172009441 
2016-12-10 00:23:21 Valid Error = 0.85660801198053 
2016-12-10 00:23:21 Valid Loss = 0.01510282647584 
2016-12-10 00:23:24 Test Error = 0.86864264061974 
2016-12-10 00:23:24 Test Loss = 0.015343173383349 
2016-12-10 00:23:24 -------------------LR------------------- 
2016-12-10 00:23:24 0.015625 
2016-12-10 00:23:24 Epoch 34 
2016-12-10 00:25:23 Training Error = 0.81913123075643 
2016-12-10 00:25:23 Training Loss = 0.014802426637655 
2016-12-10 00:25:27 Valid Error = 0.85773118682142 
2016-12-10 00:25:27 Valid Loss = 0.015083430428377 
2016-12-10 00:25:31 Test Error = 0.86897945436174 
2016-12-10 00:25:31 Test Loss = 0.01529174942427 
2016-12-10 00:25:31 -------------------LR------------------- 
2016-12-10 00:25:31 0.015625 
2016-12-10 00:25:31 Epoch 35 
2016-12-10 00:27:29 Training Error = 0.82042107015062 
2016-12-10 00:27:29 Training Loss = 0.01479489974624 
2016-12-10 00:27:32 Valid Error = 0.85174092100337 
2016-12-10 00:27:32 Valid Loss = 0.015159848149604 
2016-12-10 00:27:36 Test Error = 0.86460087571573 
2016-12-10 00:27:36 Test Loss = 0.015425227952376 
2016-12-10 00:27:36 -------------------LR------------------- 
2016-12-10 00:27:36 0.015625 
2016-12-10 00:27:36 Epoch 36 
2016-12-10 00:29:35 Training Error = 0.81825746858617 
2016-12-10 00:29:35 Training Loss = 0.014793720870887 
2016-12-10 00:29:38 Valid Error = 0.85660801198053 
2016-12-10 00:29:38 Valid Loss = 0.015161900222454 
2016-12-10 00:29:42 Test Error = 0.86864264061974 
2016-12-10 00:29:42 Test Loss = 0.015418955037906 
2016-12-10 00:29:42 -------------------LR------------------- 
2016-12-10 00:29:42 0.015625 
2016-12-10 00:29:42 Epoch 37 
2016-12-10 00:31:41 Training Error = 0.81921444620121 
2016-12-10 00:31:41 Training Loss = 0.014812235045292 
2016-12-10 00:31:44 Valid Error = 0.85660801198053 
2016-12-10 00:31:44 Valid Loss = 0.015185913170007 
2016-12-10 00:31:48 Test Error = 0.86864264061974 
2016-12-10 00:31:48 Test Loss = 0.015466564862215 
2016-12-10 00:31:48 -------------------LR------------------- 
2016-12-10 00:31:48 0.015625 
2016-12-10 00:31:48 Epoch 38 
2016-12-10 00:33:48 Training Error = 0.8199217774819 
2016-12-10 00:33:48 Training Loss = 0.014806838655157 
2016-12-10 00:33:51 Valid Error = 0.85660801198053 
2016-12-10 00:33:51 Valid Loss = 0.015098843365773 
2016-12-10 00:33:55 Test Error = 0.86864264061974 
2016-12-10 00:33:55 Test Loss = 0.015322404671322 
2016-12-10 00:33:55 -------------------LR------------------- 
2016-12-10 00:33:55 0.015625 
2016-12-10 00:33:55 Epoch 39 
2016-12-10 00:35:53 Training Error = 0.81813264541899 
2016-12-10 00:35:53 Training Loss = 0.014817444944766 
2016-12-10 00:35:56 Valid Error = 0.86110071134407 
2016-12-10 00:35:56 Valid Loss = 0.015074491661465 
2016-12-10 00:36:00 Test Error = 0.87201077803974 
2016-12-10 00:36:00 Test Loss = 0.015253549709302 
2016-12-10 00:36:00 -------------------LR------------------- 
2016-12-10 00:36:00 0.015625 
2016-12-10 00:36:00 Epoch 40 
2016-12-10 00:38:07 Training Error = 0.81888158442207 
2016-12-10 00:38:07 Training Loss = 0.014827453684548 
2016-12-10 00:38:11 Valid Error = 0.86072631973044 
2016-12-10 00:38:11 Valid Loss = 0.015043018834003 
2016-12-10 00:38:15 Test Error = 0.87066352307174 
2016-12-10 00:38:15 Test Loss = 0.015260889097195 
2016-12-10 00:38:15 -------------------LR------------------- 
2016-12-10 00:38:15 0.015625 
2016-12-10 00:38:15 Epoch 41 
2016-12-10 00:40:12 Training Error = 0.81734209869352 
2016-12-10 00:40:12 Training Loss = 0.014801139173371 
2016-12-10 00:40:15 Valid Error = 0.86110071134407 
2016-12-10 00:40:15 Valid Loss = 0.015101874265446 
2016-12-10 00:40:19 Test Error = 0.87201077803974 
2016-12-10 00:40:19 Test Loss = 0.015290658489329 
2016-12-10 00:40:19 -------------------LR------------------- 
2016-12-10 00:40:19 0.015625 
2016-12-10 00:40:19 Epoch 42 
2016-12-10 00:42:18 Training Error = 0.8162186901889 
2016-12-10 00:42:18 Training Loss = 0.014787183901098 
2016-12-10 00:42:22 Valid Error = 0.85660801198053 
2016-12-10 00:42:22 Valid Loss = 0.015091963121205 
2016-12-10 00:42:26 Test Error = 0.86864264061974 
2016-12-10 00:42:26 Test Loss = 0.015355110160412 
2016-12-10 00:42:26 -------------------LR------------------- 
2016-12-10 00:42:26 0.015625 
2016-12-10 00:42:26 Epoch 43 
2016-12-10 00:44:24 Training Error = 0.81863193808771 
2016-12-10 00:44:24 Training Loss = 0.014818252209386 
2016-12-10 00:44:28 Valid Error = 0.86110071134407 
2016-12-10 00:44:28 Valid Loss = 0.015090262671386 
2016-12-10 00:44:31 Test Error = 0.87201077803974 
2016-12-10 00:44:31 Test Loss = 0.015277559542504 
2016-12-10 00:44:31 -------------------LR------------------- 
2016-12-10 00:44:31 0.015625 
2016-12-10 00:44:32 Epoch 44 
2016-12-10 00:46:31 Training Error = 0.81946409253557 
2016-12-10 00:46:31 Training Loss = 0.014820497613118 
2016-12-10 00:46:34 Valid Error = 0.85660801198053 
2016-12-10 00:46:34 Valid Loss = 0.015124667401603 
2016-12-10 00:46:38 Test Error = 0.86864264061974 
2016-12-10 00:46:38 Test Loss = 0.015396618809243 
2016-12-10 00:46:38 -------------------LR------------------- 
2016-12-10 00:46:38 0.015625 
2016-12-10 00:46:38 Epoch 45 
2016-12-10 00:48:36 Training Error = 0.81796621452942 
2016-12-10 00:48:36 Training Loss = 0.014807288849004 
2016-12-10 00:48:40 Valid Error = 0.85922875327593 
2016-12-10 00:48:40 Valid Loss = 0.01513554987181 
2016-12-10 00:48:43 Test Error = 0.86965308184574 
2016-12-10 00:48:43 Test Loss = 0.01539728455321 
2016-12-10 00:48:43 -------------------LR------------------- 
2016-12-10 00:48:43 0.015625 
2016-12-10 00:48:43 Epoch 46 
2016-12-10 00:50:43 Training Error = 0.81925605392361 
2016-12-10 00:50:43 Training Loss = 0.014802500223084 
2016-12-10 00:50:46 Valid Error = 0.85660801198053 
2016-12-10 00:50:46 Valid Loss = 0.015204268920258 
2016-12-10 00:50:50 Test Error = 0.86864264061974 
2016-12-10 00:50:50 Test Loss = 0.01549091361649 
2016-12-10 00:50:50 -------------------LR------------------- 
2016-12-10 00:50:50 0.015625 
2016-12-10 00:50:50 Epoch 47 
2016-12-10 00:52:49 Training Error = 0.81900640758925 
2016-12-10 00:52:49 Training Loss = 0.014802710556975 
2016-12-10 00:52:53 Valid Error = 0.86110071134407 
2016-12-10 00:52:53 Valid Loss = 0.015067060995317 
2016-12-10 00:52:57 Test Error = 0.87201077803974 
2016-12-10 00:52:57 Test Loss = 0.015308613602998 
2016-12-10 00:52:57 -------------------LR------------------- 
2016-12-10 00:52:57 0.015625 
2016-12-10 00:52:57 Epoch 48 
2016-12-10 00:54:56 Training Error = 0.82017142381626 
2016-12-10 00:54:56 Training Loss = 0.014799379590432 
2016-12-10 00:54:59 Valid Error = 0.8562336203669 
2016-12-10 00:54:59 Valid Loss = 0.01509181520941 
2016-12-10 00:55:03 Test Error = 0.86729538565173 
2016-12-10 00:55:03 Test Loss = 0.01534322887007 
2016-12-10 00:55:03 -------------------LR------------------- 
2016-12-10 00:55:03 0.015625 
2016-12-10 00:55:03 Epoch 49 
2016-12-10 00:57:01 Training Error = 0.81829907630856 
2016-12-10 00:57:01 Training Loss = 0.014803896413038 
2016-12-10 00:57:04 Valid Error = 0.85660801198053 
2016-12-10 00:57:04 Valid Loss = 0.015090938878378 
2016-12-10 00:57:08 Test Error = 0.86864264061974 
2016-12-10 00:57:08 Test Loss = 0.015338966115557 
2016-12-10 00:57:08 -------------------LR------------------- 
2016-12-10 00:57:08 0.015625 
2016-12-10 00:57:08 Epoch 50 
2016-12-10 00:59:15 Training Error = 0.81771656819506 
2016-12-10 00:59:15 Training Loss = 0.014821730533936 
2016-12-10 00:59:18 Valid Error = 0.85323848745788 
2016-12-10 00:59:18 Valid Loss = 0.015064702353646 
2016-12-10 00:59:22 Test Error = 0.86561131694173 
2016-12-10 00:59:22 Test Loss = 0.01528225829479 
2016-12-10 00:59:22 -------------------LR------------------- 
2016-12-10 00:59:22 0.0078125 
2016-12-10 00:59:22 Epoch 51 
2016-12-10 01:01:20 Training Error = 0.81942248481318 
2016-12-10 01:01:20 Training Loss = 0.014802863140375 
2016-12-10 01:01:23 Valid Error = 0.86409584425309 
2016-12-10 01:01:23 Valid Loss = 0.015120163003244 
2016-12-10 01:01:27 Test Error = 0.87369484674975 
2016-12-10 01:01:27 Test Loss = 0.01537225072754 
2016-12-10 01:01:27 -------------------LR------------------- 
2016-12-10 01:01:27 0.0078125 
2016-12-10 01:01:27 Epoch 52 
2016-12-10 01:03:27 Training Error = 0.81917283847882 
2016-12-10 01:03:27 Training Loss = 0.014798066166051 
2016-12-10 01:03:31 Valid Error = 0.85773118682142 
2016-12-10 01:03:31 Valid Loss = 0.015073084837645 
2016-12-10 01:03:35 Test Error = 0.86897945436174 
2016-12-10 01:03:35 Test Loss = 0.015299306107225 
2016-12-10 01:03:35 -------------------LR------------------- 
2016-12-10 01:03:35 0.0078125 
2016-12-10 01:03:35 Epoch 53 
2016-12-10 01:05:28 Training Error = 0.81854872264292 
2016-12-10 01:05:28 Training Loss = 0.014818829345211 
2016-12-10 01:05:31 Valid Error = 0.85323848745788 
2016-12-10 01:05:31 Valid Loss = 0.015098586130543 
2016-12-10 01:05:35 Test Error = 0.86561131694173 
2016-12-10 01:05:35 Test Loss = 0.015325871951057 
2016-12-10 01:05:35 -------------------LR------------------- 
2016-12-10 01:05:35 0.0078125 
2016-12-10 01:05:35 Epoch 54 
2016-12-10 01:07:29 Training Error = 0.8174669218607 
2016-12-10 01:07:29 Training Loss = 0.014812138125354 
2016-12-10 01:07:32 Valid Error = 0.85660801198053 
2016-12-10 01:07:32 Valid Loss = 0.015120080180438 
2016-12-10 01:07:36 Test Error = 0.86864264061974 
2016-12-10 01:07:36 Test Loss = 0.015381032364444 
2016-12-10 01:07:36 -------------------LR------------------- 
2016-12-10 01:07:36 0.0078125 
2016-12-10 01:07:36 Epoch 55 
2016-12-10 01:09:31 Training Error = 0.81896479986686 
2016-12-10 01:09:31 Training Loss = 0.014795408650658 
2016-12-10 01:09:34 Valid Error = 0.85660801198053 
2016-12-10 01:09:34 Valid Loss = 0.015087704841238 
2016-12-10 01:09:38 Test Error = 0.86864264061974 
2016-12-10 01:09:38 Test Loss = 0.015339074038799 
2016-12-10 01:09:38 -------------------LR------------------- 
2016-12-10 01:09:38 0.0078125 
2016-12-10 01:09:38 Epoch 56 
2016-12-10 01:11:32 Training Error = 0.81646833652326 
2016-12-10 01:11:32 Training Loss = 0.01480026324076 
2016-12-10 01:11:35 Valid Error = 0.85660801198053 
2016-12-10 01:11:35 Valid Loss = 0.015099235436512 
2016-12-10 01:11:39 Test Error = 0.86864264061974 
2016-12-10 01:11:39 Test Loss = 0.015293614198446 
2016-12-10 01:11:39 -------------------LR------------------- 
2016-12-10 01:11:39 0.0078125 
2016-12-10 01:11:39 Epoch 57 
2016-12-10 01:13:38 Training Error = 0.8180494299742 
2016-12-10 01:13:38 Training Loss = 0.014803289440295 
2016-12-10 01:13:41 Valid Error = 0.85660801198053 
2016-12-10 01:13:41 Valid Loss = 0.015123719324695 
2016-12-10 01:13:45 Test Error = 0.86864264061974 
2016-12-10 01:13:45 Test Loss = 0.015369404616844 
2016-12-10 01:13:45 -------------------LR------------------- 
2016-12-10 01:13:45 0.0078125 
2016-12-10 01:13:45 Epoch 58 
2016-12-10 01:15:39 Training Error = 0.81917283847882 
2016-12-10 01:15:39 Training Loss = 0.014810649056544 
2016-12-10 01:15:42 Valid Error = 0.86110071134407 
2016-12-10 01:15:42 Valid Loss = 0.015033560123263 
2016-12-10 01:15:46 Test Error = 0.87201077803974 
2016-12-10 01:15:46 Test Loss = 0.015236600140971 
2016-12-10 01:15:46 -------------------LR------------------- 
2016-12-10 01:15:46 0.0078125 
2016-12-10 01:15:46 Epoch 59 
2016-12-10 01:17:41 Training Error = 0.81829907630856 
2016-12-10 01:17:41 Training Loss = 0.014793602831518 
2016-12-10 01:17:44 Valid Error = 0.85960314488955 
2016-12-10 01:17:44 Valid Loss = 0.015048807484395 
2016-12-10 01:17:48 Test Error = 0.87032670932974 
2016-12-10 01:17:48 Test Loss = 0.015286061164223 
2016-12-10 01:17:48 -------------------LR------------------- 
2016-12-10 01:17:48 0.0078125 
2016-12-10 01:17:48 Epoch 60 
2016-12-10 01:19:50 Training Error = 0.81634351335608 
2016-12-10 01:19:50 Training Loss = 0.014785964795402 
2016-12-10 01:19:53 Valid Error = 0.85660801198053 
2016-12-10 01:19:53 Valid Loss = 0.015115596326511 
2016-12-10 01:19:57 Test Error = 0.86864264061974 
2016-12-10 01:19:57 Test Loss = 0.015355318999502 
2016-12-10 01:19:57 -------------------LR------------------- 
2016-12-10 01:19:57 0.0078125 
2016-12-10 01:19:57 Epoch 61 
2016-12-10 01:21:51 Training Error = 0.81900640758925 
2016-12-10 01:21:51 Training Loss = 0.014822898990659 
2016-12-10 01:21:55 Valid Error = 0.85174092100337 
2016-12-10 01:21:55 Valid Loss = 0.015131622416596 
2016-12-10 01:21:58 Test Error = 0.86460087571573 
2016-12-10 01:21:58 Test Loss = 0.015410115227708 
2016-12-10 01:21:58 -------------------LR------------------- 
2016-12-10 01:21:58 0.0078125 
2016-12-10 01:21:58 Epoch 62 
2016-12-10 01:23:52 Training Error = 0.81821586086378 
2016-12-10 01:23:52 Training Loss = 0.014802088508029 
2016-12-10 01:23:55 Valid Error = 0.85660801198053 
2016-12-10 01:23:55 Valid Loss = 0.015132843633299 
2016-12-10 01:23:59 Test Error = 0.86864264061974 
2016-12-10 01:23:59 Test Loss = 0.015388737619816 
2016-12-10 01:23:59 -------------------LR------------------- 
2016-12-10 01:23:59 0.0078125 
2016-12-10 01:23:59 Epoch 63 
2016-12-10 01:25:53 Training Error = 0.81979695431472 
2016-12-10 01:25:53 Training Loss = 0.014804920259308 
2016-12-10 01:25:57 Valid Error = 0.85660801198053 
2016-12-10 01:25:57 Valid Loss = 0.015098931627928 
2016-12-10 01:26:00 Test Error = 0.86864264061974 
2016-12-10 01:26:00 Test Loss = 0.015345157162213 
2016-12-10 01:26:00 -------------------LR------------------- 
2016-12-10 01:26:00 0.0078125 
2016-12-10 01:26:00 Epoch 64 
2016-12-10 01:27:56 Training Error = 0.81709245235916 
2016-12-10 01:27:56 Training Loss = 0.014789134544493 
2016-12-10 01:27:59 Valid Error = 0.85660801198053 
2016-12-10 01:27:59 Valid Loss = 0.015080465182301 
2016-12-10 01:28:03 Test Error = 0.86864264061974 
2016-12-10 01:28:03 Test Loss = 0.015320380889865 
2016-12-10 01:28:03 -------------------LR------------------- 
2016-12-10 01:28:03 0.0078125 
2016-12-10 01:28:03 Epoch 65 
2016-12-10 01:30:00 Training Error = 0.81796621452942 
2016-12-10 01:30:00 Training Loss = 0.014812994456583 
2016-12-10 01:30:03 Valid Error = 0.85660801198053 
2016-12-10 01:30:03 Valid Loss = 0.01512255871413 
2016-12-10 01:30:07 Test Error = 0.86864264061974 
2016-12-10 01:30:07 Test Loss = 0.015315151415118 
2016-12-10 01:30:07 -------------------LR------------------- 
2016-12-10 01:30:07 0.0078125 
2016-12-10 01:30:07 Epoch 66 
2016-12-10 01:32:07 Training Error = 0.81950570025797 
2016-12-10 01:32:07 Training Loss = 0.014835013059909 
2016-12-10 01:32:11 Valid Error = 0.85660801198053 
2016-12-10 01:32:11 Valid Loss = 0.01510414657366 
2016-12-10 01:32:14 Test Error = 0.86864264061974 
2016-12-10 01:32:14 Test Loss = 0.015370847257363 
2016-12-10 01:32:14 -------------------LR------------------- 
2016-12-10 01:32:14 0.0078125 
2016-12-10 01:32:14 Epoch 67 
2016-12-10 01:34:22 Training Error = 0.81983856203711 
2016-12-10 01:34:22 Training Loss = 0.014802831329123 
2016-12-10 01:34:26 Valid Error = 0.8562336203669 
2016-12-10 01:34:26 Valid Loss = 0.015053889836699 
2016-12-10 01:34:29 Test Error = 0.86729538565173 
2016-12-10 01:34:29 Test Loss = 0.01525862775956 
2016-12-10 01:34:29 -------------------LR------------------- 
2016-12-10 01:34:29 0.0078125 
2016-12-10 01:34:29 Epoch 68 
2016-12-10 01:36:25 Training Error = 0.81734209869352 
2016-12-10 01:36:25 Training Loss = 0.014798691525156 
2016-12-10 01:36:28 Valid Error = 0.86110071134407 
2016-12-10 01:36:28 Valid Loss = 0.015045753798866 
2016-12-10 01:36:32 Test Error = 0.87201077803974 
2016-12-10 01:36:32 Test Loss = 0.015241651018817 
2016-12-10 01:36:32 -------------------LR------------------- 
2016-12-10 01:36:32 0.0078125 
2016-12-10 01:36:32 Epoch 69 
2016-12-10 01:38:27 Training Error = 0.8180910376966 
2016-12-10 01:38:27 Training Loss = 0.014792419721849 
2016-12-10 01:38:30 Valid Error = 0.86110071134407 
2016-12-10 01:38:30 Valid Loss = 0.015060335104841 
2016-12-10 01:38:34 Test Error = 0.87201077803974 
2016-12-10 01:38:34 Test Loss = 0.015311588831738 
2016-12-10 01:38:34 -------------------LR------------------- 
2016-12-10 01:38:34 0.0078125 
2016-12-10 01:38:34 Epoch 70 
2016-12-10 01:40:35 Training Error = 0.81879836897728 
2016-12-10 01:40:35 Training Loss = 0.014801775776184 
2016-12-10 01:40:38 Valid Error = 0.85660801198053 
2016-12-10 01:40:38 Valid Loss = 0.015049107605685 
2016-12-10 01:40:42 Test Error = 0.86864264061974 
2016-12-10 01:40:42 Test Loss = 0.01523963663473 
2016-12-10 01:40:42 -------------------LR------------------- 
2016-12-10 01:40:42 0.0078125 
2016-12-10 01:40:42 Epoch 71 
2016-12-10 01:42:36 Training Error = 0.82004660064908 
2016-12-10 01:42:36 Training Loss = 0.014816583043395 
2016-12-10 01:42:39 Valid Error = 0.85660801198053 
2016-12-10 01:42:39 Valid Loss = 0.015014659300494 
2016-12-10 01:42:43 Test Error = 0.86864264061974 
2016-12-10 01:42:43 Test Loss = 0.015215517185905 
2016-12-10 01:42:43 -------------------LR------------------- 
2016-12-10 01:42:43 0.0078125 
2016-12-10 01:42:43 Epoch 72 
2016-12-10 01:44:37 Training Error = 0.8180494299742 
2016-12-10 01:44:37 Training Loss = 0.014804495723687 
2016-12-10 01:44:41 Valid Error = 0.86409584425309 
2016-12-10 01:44:41 Valid Loss = 0.015056678437431 
2016-12-10 01:44:44 Test Error = 0.87369484674975 
2016-12-10 01:44:44 Test Loss = 0.015258296184001 
2016-12-10 01:44:44 -------------------LR------------------- 
2016-12-10 01:44:44 0.0078125 
2016-12-10 01:44:44 Epoch 73 
2016-12-10 01:46:38 Training Error = 0.81771656819506 
2016-12-10 01:46:38 Training Loss = 0.014796029932757 
2016-12-10 01:46:42 Valid Error = 0.85960314488955 
2016-12-10 01:46:42 Valid Loss = 0.015097089925818 
2016-12-10 01:46:46 Test Error = 0.87032670932974 
2016-12-10 01:46:46 Test Loss = 0.015333609400223 
2016-12-10 01:46:46 -------------------LR------------------- 
2016-12-10 01:46:46 0.0078125 
2016-12-10 01:46:46 Epoch 74 
2016-12-10 01:48:38 Training Error = 0.82025463926105 
2016-12-10 01:48:38 Training Loss = 0.014811891686506 
2016-12-10 01:48:42 Valid Error = 0.85922875327593 
2016-12-10 01:48:42 Valid Loss = 0.015121265512753 
2016-12-10 01:48:45 Test Error = 0.87268440552375 
2016-12-10 01:48:45 Test Loss = 0.015318448269783 
2016-12-10 01:48:45 -------------------LR------------------- 
2016-12-10 01:48:45 0.0078125 
2016-12-10 01:48:45 Epoch 75 
2016-12-10 01:50:41 Training Error = 0.82012981609387 
2016-12-10 01:50:41 Training Loss = 0.01481276930027 
2016-12-10 01:50:44 Valid Error = 0.86110071134407 
2016-12-10 01:50:44 Valid Loss = 0.015108001400429 
2016-12-10 01:50:48 Test Error = 0.87201077803974 
2016-12-10 01:50:48 Test Loss = 0.015379734671929 
2016-12-10 01:50:48 -------------------LR------------------- 
2016-12-10 01:50:48 0.0078125 
2016-12-10 01:50:48 Epoch 76 
2016-12-10 01:52:42 Training Error = 0.81850711492053 
2016-12-10 01:52:42 Training Loss = 0.014833661428767 
2016-12-10 01:52:45 Valid Error = 0.85660801198053 
2016-12-10 01:52:45 Valid Loss = 0.015158999286821 
2016-12-10 01:52:49 Test Error = 0.86864264061974 
2016-12-10 01:52:49 Test Loss = 0.015424214700862 
2016-12-10 01:52:49 -------------------LR------------------- 
2016-12-10 01:52:49 0.0078125 
2016-12-10 01:52:49 Epoch 77 
2016-12-10 01:54:43 Training Error = 0.81838229175335 
2016-12-10 01:54:43 Training Loss = 0.014806090305348 
2016-12-10 01:54:46 Valid Error = 0.86110071134407 
2016-12-10 01:54:46 Valid Loss = 0.015106653871651 
2016-12-10 01:54:50 Test Error = 0.87201077803974 
2016-12-10 01:54:50 Test Loss = 0.015301436095816 
2016-12-10 01:54:50 -------------------LR------------------- 
2016-12-10 01:54:50 0.0078125 
2016-12-10 01:54:50 Epoch 78 
2016-12-10 01:56:57 Training Error = 0.81854872264292 
2016-12-10 01:56:57 Training Loss = 0.014799700743975 
2016-12-10 01:57:01 Valid Error = 0.85174092100337 
2016-12-10 01:57:01 Valid Loss = 0.015169528909262 
2016-12-10 01:57:04 Test Error = 0.86460087571573 
2016-12-10 01:57:04 Test Loss = 0.015447467272213 
2016-12-10 01:57:04 -------------------LR------------------- 
2016-12-10 01:57:04 0.0078125 
2016-12-10 01:57:04 Epoch 79 
2016-12-10 01:59:09 Training Error = 0.81908962303404 
2016-12-10 01:59:09 Training Loss = 0.014787996887375 
2016-12-10 01:59:12 Valid Error = 0.85922875327593 
2016-12-10 01:59:12 Valid Loss = 0.015054352265671 
2016-12-10 01:59:16 Test Error = 0.87268440552375 
2016-12-10 01:59:16 Test Loss = 0.015249727378971 
2016-12-10 01:59:16 -------------------LR------------------- 
2016-12-10 01:59:16 0.0078125 
2016-12-10 01:59:16 Epoch 80 
2016-12-10 02:01:24 Training Error = 0.81933926936839 
2016-12-10 02:01:24 Training Loss = 0.014819408494479 
2016-12-10 02:01:27 Valid Error = 0.86110071134407 
2016-12-10 02:01:27 Valid Loss = 0.015129917039044 
2016-12-10 02:01:31 Test Error = 0.87201077803974 
2016-12-10 02:01:31 Test Loss = 0.015323351512458 
2016-12-10 02:01:31 -------------------LR------------------- 
2016-12-10 02:01:31 0.0078125 
2016-12-10 02:01:31 Epoch 81 
2016-12-10 02:03:31 Training Error = 0.81821586086378 
2016-12-10 02:03:31 Training Loss = 0.014809620724495 
2016-12-10 02:03:34 Valid Error = 0.85660801198053 
2016-12-10 02:03:34 Valid Loss = 0.015171902780321 
2016-12-10 02:03:38 Test Error = 0.86864264061974 
2016-12-10 02:03:38 Test Loss = 0.015433847420278 
2016-12-10 02:03:38 -------------------LR------------------- 
2016-12-10 02:03:38 0.0078125 
2016-12-10 02:03:38 Epoch 82 
2016-12-10 02:05:38 Training Error = 0.81592743613215 
2016-12-10 02:05:38 Training Loss = 0.014788966028524 
2016-12-10 02:05:42 Valid Error = 0.85773118682142 
2016-12-10 02:05:42 Valid Loss = 0.015060623139709 
2016-12-10 02:05:46 Test Error = 0.86897945436174 
2016-12-10 02:05:46 Test Loss = 0.015259245607901 
2016-12-10 02:05:46 -------------------LR------------------- 
2016-12-10 02:05:46 0.0078125 
2016-12-10 02:05:46 Epoch 83 
2016-12-10 02:07:40 Training Error = 0.81759174502788 
2016-12-10 02:07:40 Training Loss = 0.01479981202165 
2016-12-10 02:07:44 Valid Error = 0.86110071134407 
2016-12-10 02:07:44 Valid Loss = 0.0151676470074 
2016-12-10 02:07:47 Test Error = 0.87201077803974 
2016-12-10 02:07:47 Test Loss = 0.015426647832656 
2016-12-10 02:07:47 -------------------LR------------------- 
2016-12-10 02:07:47 0.0078125 
2016-12-10 02:07:47 Epoch 84 
2016-12-10 02:09:46 Training Error = 0.81875676125489 
2016-12-10 02:09:46 Training Loss = 0.014816585522393 
2016-12-10 02:09:49 Valid Error = 0.84837139648072 
2016-12-10 02:09:49 Valid Loss = 0.015197262975984 
2016-12-10 02:09:53 Test Error = 0.86156955203772 
2016-12-10 02:09:53 Test Loss = 0.015483412824814 
2016-12-10 02:09:53 -------------------LR------------------- 
2016-12-10 02:09:53 0.0078125 
2016-12-10 02:09:53 Epoch 85 
2016-12-10 02:11:52 Training Error = 0.81942248481318 
2016-12-10 02:11:52 Training Loss = 0.014807025422775 
2016-12-10 02:11:55 Valid Error = 0.85660801198053 
2016-12-10 02:11:55 Valid Loss = 0.015183587072831 
2016-12-10 02:11:59 Test Error = 0.86864264061974 
2016-12-10 02:11:59 Test Loss = 0.015475252905058 
2016-12-10 02:11:59 -------------------LR------------------- 
2016-12-10 02:11:59 0.0078125 
2016-12-10 02:11:59 Epoch 86 
2016-12-10 02:13:55 Training Error = 0.81942248481318 
2016-12-10 02:13:55 Training Loss = 0.014813819603191 
2016-12-10 02:13:58 Valid Error = 0.85660801198053 
2016-12-10 02:13:58 Valid Loss = 0.015226984989608 
2016-12-10 02:14:02 Test Error = 0.86864264061974 
2016-12-10 02:14:02 Test Loss = 0.015515533934129 
2016-12-10 02:14:02 -------------------LR------------------- 
2016-12-10 02:14:02 0.0078125 
2016-12-10 02:14:02 Epoch 87 
2016-12-10 02:15:58 Training Error = 0.8174669218607 
2016-12-10 02:15:58 Training Loss = 0.014789807789519 
2016-12-10 02:16:02 Valid Error = 0.86110071134407 
2016-12-10 02:16:02 Valid Loss = 0.015143230248125 
2016-12-10 02:16:05 Test Error = 0.87201077803974 
2016-12-10 02:16:05 Test Loss = 0.015419570175354 
2016-12-10 02:16:05 -------------------LR------------------- 
2016-12-10 02:16:05 0.0078125 
2016-12-10 02:16:05 Epoch 88 
2016-12-10 02:18:04 Training Error = 0.81859033036532 
2016-12-10 02:18:04 Training Loss = 0.014800380448679 
2016-12-10 02:18:08 Valid Error = 0.85323848745788 
2016-12-10 02:18:08 Valid Loss = 0.015125962042307 
2016-12-10 02:18:12 Test Error = 0.86561131694173 
2016-12-10 02:18:12 Test Loss = 0.015402229273157 
2016-12-10 02:18:12 -------------------LR------------------- 
2016-12-10 02:18:12 0.0078125 
2016-12-10 02:18:12 Epoch 89 
