2016-12-11 13:44:41 [program started on Sun Dec 11 13:44:41 2016] 
2016-12-11 13:44:41 [command line arguments] 
2016-12-11 13:44:41 stcWeights false 
2016-12-11 13:44:41 LR 0.015625 
2016-12-11 13:44:41 batchSize 64 
2016-12-11 13:44:41 network ./Models/Cifar10_Custom 
2016-12-11 13:44:41 stcNeurons true 
2016-12-11 13:44:41 constBatchSize false 
2016-12-11 13:44:41 chartFileName chart1 
2016-12-11 13:44:41 dp_prepro false 
2016-12-11 13:44:41 nGPU 1 
2016-12-11 13:44:41 dataset Caltech256 
2016-12-11 13:44:41 type cuda 
2016-12-11 13:44:41 momentum 0 
2016-12-11 13:44:41 threads 8 
2016-12-11 13:44:41 weightDecay 0 
2016-12-11 13:44:41 runningVal false 
2016-12-11 13:44:41 convLayerN 6 
2016-12-11 13:44:41 LRDecay 0 
2016-12-11 13:44:41 numHid 4096 
2016-12-11 13:44:41 save /dev/shm/clone/temp/th/Results/Caltech256/model6-10-4096 
2016-12-11 13:44:41 augment false 
2016-12-11 13:44:41 epoch -1 
2016-12-11 13:44:41 modelsFolder ./Models/ 
2016-12-11 13:44:41 format rgb 
2016-12-11 13:44:41 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-11 13:44:41 imageFileExtension svg 
2016-12-11 13:44:41 channel 1 
2016-12-11 13:44:41 devid 4 
2016-12-11 13:44:41 visualize 1 
2016-12-11 13:44:41 LRDecayPerEpoch 0.0001 
2016-12-11 13:44:41 optimization adam 
2016-12-11 13:44:41 SBN true 
2016-12-11 13:44:41 normalization simple 
2016-12-11 13:44:41 title model1 
2016-12-11 13:44:41 load  
2016-12-11 13:44:41 whiten true 
2016-12-11 13:44:41 [----------------------] 
2016-12-11 13:44:44 ==> Network 
2016-12-11 13:44:44 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 4096)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(4096 -> 4096)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(4096 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-11 13:44:44 ==>55981437 Parameters 
2016-12-11 13:44:44 ==> Loss 
2016-12-11 13:44:44 SqrtHingeEmbeddingCriterion 
2016-12-11 13:44:44 
==> Starting Training
 
2016-12-11 13:44:44 Epoch 1 
2016-12-11 13:51:28 Training Error = 0.9647582591329 
2016-12-11 13:51:28 Training Loss = 0.115490744242 
2016-12-11 13:51:35 Valid Error = 0.93635342568326 
2016-12-11 13:51:35 Valid Loss = 0.01580601048147 
2016-12-11 13:51:43 Test Error = 0.9491411249579 
2016-12-11 13:51:43 Test Loss = 0.015816662811865 
2016-12-11 13:51:43 -------------------LR------------------- 
2016-12-11 13:51:43 0.015625 
2016-12-11 13:51:43 Epoch 2 
2016-12-11 13:58:12 Training Error = 0.94499459099609 
2016-12-11 13:58:12 Training Loss = 0.015768424358487 
2016-12-11 13:58:19 Valid Error = 0.93635342568326 
2016-12-11 13:58:19 Valid Loss = 0.015701461813552 
2016-12-11 13:58:27 Test Error = 0.9491411249579 
2016-12-11 13:58:27 Test Loss = 0.015718148830288 
2016-12-11 13:58:27 -------------------LR------------------- 
2016-12-11 13:58:27 0.015625 
2016-12-11 13:58:27 Epoch 3 
2016-12-11 14:03:41 Training Error = 0.93421819089623 
2016-12-11 14:03:41 Training Loss = 0.015534800459129 
2016-12-11 14:03:48 Valid Error = 0.95619618120554 
2016-12-11 14:03:48 Valid Loss = 0.015577957209419 
2016-12-11 14:03:55 Test Error = 0.95621421353991 
2016-12-11 14:03:55 Test Loss = 0.01558641655643 
2016-12-11 14:03:55 -------------------LR------------------- 
2016-12-11 14:03:55 0.015625 
2016-12-11 14:03:55 Epoch 4 
2016-12-11 14:09:08 Training Error = 0.92181908962303 
2016-12-11 14:09:08 Training Loss = 0.015405077203516 
2016-12-11 14:09:15 Valid Error = 0.94795956570573 
2016-12-11 14:09:15 Valid Loss = 0.015490775155512 
2016-12-11 14:09:22 Test Error = 0.96564499831593 
2016-12-11 14:09:22 Test Loss = 0.015569352737605 
2016-12-11 14:09:22 -------------------LR------------------- 
2016-12-11 14:09:22 0.015625 
2016-12-11 14:09:22 Epoch 5 
2016-12-11 14:14:36 Training Error = 0.91258217525173 
2016-12-11 14:14:36 Training Loss = 0.015235128604917 
2016-12-11 14:14:43 Valid Error = 0.97154623736428 
2016-12-11 14:14:43 Valid Loss = 0.015727806148146 
2016-12-11 14:14:51 Test Error = 0.97002357696194 
2016-12-11 14:14:51 Test Loss = 0.015690816955662 
2016-12-11 14:14:51 -------------------LR------------------- 
2016-12-11 14:14:51 0.015625 
2016-12-11 14:14:51 Epoch 6 
2016-12-11 14:20:04 Training Error = 0.89298493800449 
2016-12-11 14:20:04 Training Loss = 0.015008196504503 
2016-12-11 14:20:12 Valid Error = 0.93485585922875 
2016-12-11 14:20:12 Valid Loss = 0.015743562295501 
2016-12-11 14:20:19 Test Error = 0.9494779386999 
2016-12-11 14:20:19 Test Loss = 0.015932311056851 
2016-12-11 14:20:19 -------------------LR------------------- 
2016-12-11 14:20:19 0.015625 
2016-12-11 14:20:19 Epoch 7 
2016-12-11 14:25:30 Training Error = 0.86506615627861 
2016-12-11 14:25:30 Training Loss = 0.014768646594899 
2016-12-11 14:25:38 Valid Error = 0.90228378884313 
2016-12-11 14:25:38 Valid Loss = 0.015674881911248 
2016-12-11 14:25:45 Test Error = 0.90771303469182 
2016-12-11 14:25:45 Test Loss = 0.015996205559461 
2016-12-11 14:25:45 -------------------LR------------------- 
2016-12-11 14:25:45 0.015625 
2016-12-11 14:25:45 Epoch 8 
2016-12-11 14:30:53 Training Error = 0.81305650328701 
2016-12-11 14:30:53 Training Loss = 0.014426601054628 
2016-12-11 14:31:01 Valid Error = 0.90116061400225 
2016-12-11 14:31:01 Valid Loss = 0.015406354973649 
2016-12-11 14:31:08 Test Error = 0.90468171101381 
2016-12-11 14:31:08 Test Loss = 0.015356208573693 
2016-12-11 14:31:08 -------------------LR------------------- 
2016-12-11 14:31:08 0.015625 
2016-12-11 14:31:08 Epoch 9 
2016-12-11 14:36:24 Training Error = 0.73046517433636 
2016-12-11 14:36:24 Training Loss = 0.013862604337393 
2016-12-11 14:36:31 Valid Error = 0.73305877948334 
2016-12-11 14:36:31 Valid Loss = 0.014302953171934 
2016-12-11 14:36:39 Test Error = 0.73223307510946 
2016-12-11 14:36:39 Test Loss = 0.014285212163881 
2016-12-11 14:36:39 -------------------LR------------------- 
2016-12-11 14:36:39 0.015625 
2016-12-11 14:36:39 Epoch 10 
2016-12-11 14:41:51 Training Error = 0.64059249396688 
2016-12-11 14:41:51 Training Loss = 0.013375482263382 
2016-12-11 14:41:58 Valid Error = 0.61437663796331 
2016-12-11 14:41:58 Valid Loss = 0.012886495921951 
2016-12-11 14:42:06 Test Error = 0.5988548332772 
2016-12-11 14:42:06 Test Loss = 0.012753719971187 
2016-12-11 14:42:06 -------------------LR------------------- 
2016-12-11 14:42:06 0.015625 
2016-12-11 14:42:06 Epoch 11 
2016-12-11 14:47:17 Training Error = 0.57214779062994 
2016-12-11 14:47:17 Training Loss = 0.013026562406024 
2016-12-11 14:47:24 Valid Error = 0.60876076375889 
2016-12-11 14:47:24 Valid Loss = 0.012734752629036 
2016-12-11 14:47:31 Test Error = 0.59144493095318 
2016-12-11 14:47:31 Test Loss = 0.012613591566153 
2016-12-11 14:47:31 -------------------LR------------------- 
2016-12-11 14:47:31 0.015625 
2016-12-11 14:47:31 Epoch 12 
2016-12-11 14:52:46 Training Error = 0.57476907714072 
2016-12-11 14:52:46 Training Loss = 0.01301094173563 
2016-12-11 14:52:53 Valid Error = 0.64395357543991 
2016-12-11 14:52:53 Valid Loss = 0.012834816181534 
2016-12-11 14:53:01 Test Error = 0.62512630515325 
2016-12-11 14:53:01 Test Loss = 0.012698323759478 
2016-12-11 14:53:01 -------------------LR------------------- 
2016-12-11 14:53:01 0.015625 
2016-12-11 14:53:01 Epoch 13 
2016-12-11 14:58:16 Training Error = 0.57285512191063 
2016-12-11 14:58:16 Training Loss = 0.013010402133606 
2016-12-11 14:58:23 Valid Error = 0.60688880569075 
2016-12-11 14:58:23 Valid Loss = 0.012660848913222 
2016-12-11 14:58:31 Test Error = 0.59312899966319 
2016-12-11 14:58:31 Test Loss = 0.012513109759385 
2016-12-11 14:58:31 -------------------LR------------------- 
2016-12-11 14:58:31 0.015625 
2016-12-11 14:58:31 Epoch 14 
2016-12-11 15:03:43 Training Error = 0.57227261379712 
2016-12-11 15:03:43 Training Loss = 0.01301559166995 
2016-12-11 15:03:50 Valid Error = 0.64020965930363 
2016-12-11 15:03:50 Valid Loss = 0.012803027762331 
2016-12-11 15:03:57 Test Error = 0.61872684405524 
2016-12-11 15:03:57 Test Loss = 0.012661867645416 
2016-12-11 15:03:57 -------------------LR------------------- 
2016-12-11 15:03:57 0.015625 
2016-12-11 15:03:57 Epoch 15 
2016-12-11 15:09:08 Training Error = 0.57252226013148 
2016-12-11 15:09:08 Training Loss = 0.013028944800121 
2016-12-11 15:09:15 Valid Error = 0.59790340696368 
2016-12-11 15:09:15 Valid Loss = 0.012631801887555 
2016-12-11 15:09:23 Test Error = 0.57999326372516 
2016-12-11 15:09:23 Test Loss = 0.012470011778359 
2016-12-11 15:09:23 -------------------LR------------------- 
2016-12-11 15:09:23 0.015625 
2016-12-11 15:09:23 Epoch 16 
2016-12-11 15:14:35 Training Error = 0.57010901223267 
2016-12-11 15:14:35 Training Loss = 0.013038124151354 
2016-12-11 15:14:42 Valid Error = 0.6196181205541 
2016-12-11 15:14:42 Valid Loss = 0.012759027314925 
2016-12-11 15:14:50 Test Error = 0.5988548332772 
2016-12-11 15:14:50 Test Loss = 0.012611122814874 
2016-12-11 15:14:50 -------------------LR------------------- 
2016-12-11 15:14:50 0.015625 
2016-12-11 15:14:50 Epoch 17 
2016-12-11 15:20:06 Training Error = 0.57443621536157 
2016-12-11 15:20:06 Training Loss = 0.013035194719317 
2016-12-11 15:20:13 Valid Error = 0.61175589666791 
2016-12-11 15:20:13 Valid Loss = 0.012819766734945 
2016-12-11 15:20:21 Test Error = 0.59245537217918 
2016-12-11 15:20:21 Test Loss = 0.012723876944372 
2016-12-11 15:20:21 -------------------LR------------------- 
2016-12-11 15:20:21 0.015625 
2016-12-11 15:20:21 Epoch 18 
2016-12-11 15:25:32 Training Error = 0.57035865856703 
2016-12-11 15:25:32 Training Loss = 0.013013308405124 
2016-12-11 15:25:39 Valid Error = 0.64320479221265 
2016-12-11 15:25:39 Valid Loss = 0.012801944345338 
2016-12-11 15:25:47 Test Error = 0.62546311889525 
2016-12-11 15:25:47 Test Loss = 0.012659935816358 
2016-12-11 15:25:47 -------------------LR------------------- 
2016-12-11 15:25:47 0.015625 
2016-12-11 15:25:47 Epoch 19 
2016-12-11 15:31:02 Training Error = 0.57377049180328 
2016-12-11 15:31:02 Training Loss = 0.013026540625148 
2016-12-11 15:31:09 Valid Error = 0.60950954698615 
2016-12-11 15:31:09 Valid Loss = 0.012657516266996 
2016-12-11 15:31:17 Test Error = 0.59009767598518 
2016-12-11 15:31:17 Test Loss = 0.012528873307535 
2016-12-11 15:31:17 -------------------LR------------------- 
2016-12-11 15:31:17 0.015625 
2016-12-11 15:31:17 Epoch 20 
2016-12-11 15:36:33 Training Error = 0.57368727635849 
2016-12-11 15:36:33 Training Loss = 0.013026758933284 
2016-12-11 15:36:40 Valid Error = 0.62935230250842 
2016-12-11 15:36:40 Valid Loss = 0.012790191981828 
2016-12-11 15:36:48 Test Error = 0.61199056921522 
2016-12-11 15:36:48 Test Loss = 0.012660778884347 
2016-12-11 15:36:48 -------------------LR------------------- 
2016-12-11 15:36:48 0.015625 
2016-12-11 15:36:48 Epoch 21 
2016-12-11 15:41:58 Training Error = 0.57193975201797 
2016-12-11 15:41:58 Training Loss = 0.013035028291458 
2016-12-11 15:42:05 Valid Error = 0.63272182703107 
2016-12-11 15:42:05 Valid Loss = 0.012797519882977 
2016-12-11 15:42:13 Test Error = 0.61367463792523 
2016-12-11 15:42:13 Test Loss = 0.012659872287405 
2016-12-11 15:42:13 -------------------LR------------------- 
2016-12-11 15:42:13 0.015625 
2016-12-11 15:42:13 Epoch 22 
2016-12-11 15:47:25 Training Error = 0.57360406091371 
2016-12-11 15:47:25 Training Loss = 0.013036658328344 
2016-12-11 15:47:32 Valid Error = 0.61063272182703 
2016-12-11 15:47:32 Valid Loss = 0.012728822699964 
2016-12-11 15:47:40 Test Error = 0.59346581340519 
2016-12-11 15:47:40 Test Loss = 0.012598353987094 
2016-12-11 15:47:40 -------------------LR------------------- 
2016-12-11 15:47:40 0.015625 
2016-12-11 15:47:40 Epoch 23 
2016-12-11 15:52:52 Training Error = 0.57397853041525 
2016-12-11 15:52:52 Training Loss = 0.013026526988148 
2016-12-11 15:52:59 Valid Error = 0.62411081991763 
2016-12-11 15:52:59 Valid Loss = 0.012647971641435 
2016-12-11 15:53:06 Test Error = 0.60357022566521 
2016-12-11 15:53:06 Test Loss = 0.012510183008104 
2016-12-11 15:53:06 -------------------LR------------------- 
2016-12-11 15:53:06 0.015625 
2016-12-11 15:53:06 Epoch 24 
2016-12-11 15:58:18 Training Error = 0.57443621536157 
2016-12-11 15:58:18 Training Loss = 0.013034065054274 
2016-12-11 15:58:25 Valid Error = 0.63234743541745 
2016-12-11 15:58:25 Valid Loss = 0.012684155893067 
2016-12-11 15:58:32 Test Error = 0.61603233411923 
2016-12-11 15:58:32 Test Loss = 0.012542496221683 
2016-12-11 15:58:32 -------------------LR------------------- 
2016-12-11 15:58:32 0.015625 
2016-12-11 15:58:32 Epoch 25 
2016-12-11 16:03:45 Training Error = 0.57605891653491 
2016-12-11 16:03:45 Training Loss = 0.013028661428444 
2016-12-11 16:03:52 Valid Error = 0.62186447023587 
2016-12-11 16:03:52 Valid Loss = 0.012799783055839 
2016-12-11 16:04:00 Test Error = 0.59447625463119 
2016-12-11 16:04:00 Test Loss = 0.012617613372675 
2016-12-11 16:04:00 -------------------LR------------------- 
2016-12-11 16:04:00 0.015625 
2016-12-11 16:04:00 Epoch 26 
2016-12-11 16:09:10 Training Error = 0.57372888408089 
2016-12-11 16:09:10 Training Loss = 0.013017497840356 
2016-12-11 16:09:17 Valid Error = 0.63796330962186 
2016-12-11 16:09:17 Valid Loss = 0.01279381097096 
2016-12-11 16:09:25 Test Error = 0.61771640282924 
2016-12-11 16:09:25 Test Loss = 0.012671895582973 
2016-12-11 16:09:25 -------------------LR------------------- 
2016-12-11 16:09:25 0.015625 
2016-12-11 16:09:25 Epoch 27 
2016-12-11 16:14:36 Training Error = 0.57356245319131 
2016-12-11 16:14:36 Training Loss = 0.01301828649425 
2016-12-11 16:14:43 Valid Error = 0.59977536503182 
2016-12-11 16:14:43 Valid Loss = 0.012713223844361 
2016-12-11 16:14:51 Test Error = 0.58706635230717 
2016-12-11 16:14:51 Test Loss = 0.012589082459285 
2016-12-11 16:14:51 -------------------LR------------------- 
2016-12-11 16:14:51 0.015625 
2016-12-11 16:14:51 Epoch 28 
2016-12-11 16:20:02 Training Error = 0.57185653657319 
2016-12-11 16:20:02 Training Loss = 0.013012643612137 
2016-12-11 16:20:09 Valid Error = 0.58891800823662 
2016-12-11 16:20:09 Valid Loss = 0.012678295738505 
2016-12-11 16:20:17 Test Error = 0.57527787133715 
2016-12-11 16:20:17 Test Loss = 0.012569718078021 
2016-12-11 16:20:17 -------------------LR------------------- 
2016-12-11 16:20:17 0.015625 
2016-12-11 16:20:17 Epoch 29 
2016-12-11 16:25:28 Training Error = 0.57243904468669 
2016-12-11 16:25:28 Training Loss = 0.013016023262635 
2016-12-11 16:25:35 Valid Error = 0.60539123923624 
2016-12-11 16:25:35 Valid Loss = 0.012764093592977 
2016-12-11 16:25:43 Test Error = 0.58639272482317 
2016-12-11 16:25:43 Test Loss = 0.012647444438178 
2016-12-11 16:25:43 -------------------LR------------------- 
2016-12-11 16:25:43 0.015625 
2016-12-11 16:25:43 Epoch 30 
2016-12-11 16:30:55 Training Error = 0.57073312806857 
2016-12-11 16:30:55 Training Loss = 0.013019197378256 
2016-12-11 16:31:02 Valid Error = 0.64020965930363 
2016-12-11 16:31:02 Valid Loss = 0.012807484950232 
2016-12-11 16:31:10 Test Error = 0.62613674637925 
2016-12-11 16:31:10 Test Loss = 0.012698310948333 
2016-12-11 16:31:10 -------------------LR------------------- 
2016-12-11 16:31:10 0.015625 
2016-12-11 16:31:10 Epoch 31 
2016-12-11 16:36:16 Training Error = 0.57327119913456 
2016-12-11 16:36:16 Training Loss = 0.013029576747583 
2016-12-11 16:36:23 Valid Error = 0.64170722575814 
2016-12-11 16:36:23 Valid Loss = 0.012827137152344 
2016-12-11 16:36:31 Test Error = 0.62108454024924 
2016-12-11 16:36:31 Test Loss = 0.012700660061826 
2016-12-11 16:36:31 -------------------LR------------------- 
2016-12-11 16:36:31 0.015625 
2016-12-11 16:36:31 Epoch 32 
2016-12-11 16:41:41 Training Error = 0.57160689023883 
2016-12-11 16:41:41 Training Loss = 0.013018629764726 
2016-12-11 16:41:48 Valid Error = 0.64020965930363 
2016-12-11 16:41:48 Valid Loss = 0.012781676013765 
2016-12-11 16:41:56 Test Error = 0.61940047153924 
2016-12-11 16:41:56 Test Loss = 0.01266488821406 
2016-12-11 16:41:56 -------------------LR------------------- 
2016-12-11 16:41:56 0.015625 
2016-12-11 16:41:56 Epoch 33 
2016-12-11 16:47:08 Training Error = 0.57256386785387 
2016-12-11 16:47:08 Training Loss = 0.013026408146295 
2016-12-11 16:47:15 Valid Error = 0.62298764507675 
2016-12-11 16:47:15 Valid Loss = 0.012725383050275 
2016-12-11 16:47:23 Test Error = 0.59616032334119 
2016-12-11 16:47:23 Test Loss = 0.012545501738426 
2016-12-11 16:47:23 -------------------LR------------------- 
2016-12-11 16:47:23 0.015625 
2016-12-11 16:47:23 Epoch 34 
2016-12-11 16:52:30 Training Error = 0.57189814429558 
2016-12-11 16:52:30 Training Loss = 0.013004855282711 
2016-12-11 16:52:37 Valid Error = 0.64994384125796 
2016-12-11 16:52:37 Valid Loss = 0.012806958225015 
2016-12-11 16:52:45 Test Error = 0.63118895250926 
2016-12-11 16:52:45 Test Loss = 0.012661943733269 
2016-12-11 16:52:45 -------------------LR------------------- 
2016-12-11 16:52:45 0.015625 
2016-12-11 16:52:45 Epoch 35 
2016-12-11 16:57:55 Training Error = 0.5693184655072 
2016-12-11 16:57:55 Training Loss = 0.013018462837054 
2016-12-11 16:58:02 Valid Error = 0.63197304380382 
2016-12-11 16:58:02 Valid Loss = 0.012736764673534 
2016-12-11 16:58:10 Test Error = 0.61434826540923 
2016-12-11 16:58:10 Test Loss = 0.012578604379494 
2016-12-11 16:58:10 -------------------LR------------------- 
2016-12-11 16:58:10 0.015625 
2016-12-11 16:58:10 Epoch 36 
2016-12-11 17:03:22 Training Error = 0.5692768577848 
2016-12-11 17:03:22 Training Loss = 0.013011556490936 
2016-12-11 17:03:29 Valid Error = 0.63721452639461 
2016-12-11 17:03:29 Valid Loss = 0.012778882897743 
2016-12-11 17:03:36 Test Error = 0.62377905018525 
2016-12-11 17:03:36 Test Loss = 0.01268654414381 
2016-12-11 17:03:36 -------------------LR------------------- 
2016-12-11 17:03:36 0.015625 
2016-12-11 17:03:36 Epoch 37 
2016-12-11 17:08:44 Training Error = 0.5748522925855 
2016-12-11 17:08:44 Training Loss = 0.013031032823423 
2016-12-11 17:08:51 Valid Error = 0.63908648446275 
2016-12-11 17:08:51 Valid Loss = 0.012767062947016 
2016-12-11 17:08:59 Test Error = 0.62175816773324 
2016-12-11 17:08:59 Test Loss = 0.012626521242227 
2016-12-11 17:08:59 -------------------LR------------------- 
2016-12-11 17:08:59 0.015625 
2016-12-11 17:08:59 Epoch 38 
2016-12-11 17:14:08 Training Error = 0.57439460763918 
2016-12-11 17:14:08 Training Loss = 0.013023109387063 
2016-12-11 17:14:15 Valid Error = 0.65144140771247 
2016-12-11 17:14:15 Valid Loss = 0.01270614525799 
2016-12-11 17:14:23 Test Error = 0.62647356012125 
2016-12-11 17:14:23 Test Loss = 0.012527393202609 
2016-12-11 17:14:23 -------------------LR------------------- 
2016-12-11 17:14:23 0.015625 
2016-12-11 17:14:23 Epoch 39 
2016-12-11 17:19:32 Training Error = 0.56960971956395 
2016-12-11 17:19:32 Training Loss = 0.013011841993805 
2016-12-11 17:19:39 Valid Error = 0.61400224634968 
2016-12-11 17:19:39 Valid Loss = 0.012690504809743 
2016-12-11 17:19:47 Test Error = 0.59649713708319 
2016-12-11 17:19:47 Test Loss = 0.012553573734123 
2016-12-11 17:19:47 -------------------LR------------------- 
2016-12-11 17:19:47 0.015625 
2016-12-11 17:19:47 Epoch 40 
2016-12-11 17:24:55 Training Error = 0.57335441457935 
2016-12-11 17:24:55 Training Loss = 0.013020565488206 
2016-12-11 17:25:02 Valid Error = 0.63946087607638 
2016-12-11 17:25:02 Valid Loss = 0.012759040690653 
2016-12-11 17:25:10 Test Error = 0.62074772650724 
2016-12-11 17:25:10 Test Loss = 0.012629966501897 
2016-12-11 17:25:10 -------------------LR------------------- 
2016-12-11 17:25:10 0.015625 
2016-12-11 17:25:10 Epoch 41 
2016-12-11 17:30:19 Training Error = 0.5736456686361 
2016-12-11 17:30:19 Training Loss = 0.013028399624524 
2016-12-11 17:30:26 Valid Error = 0.64395357543991 
2016-12-11 17:30:26 Valid Loss = 0.012765787922233 
2016-12-11 17:30:34 Test Error = 0.62074772650724 
2016-12-11 17:30:34 Test Loss = 0.012639730155891 
2016-12-11 17:30:34 -------------------LR------------------- 
2016-12-11 17:30:34 0.015625 
2016-12-11 17:30:34 Epoch 42 
2016-12-11 17:35:44 Training Error = 0.57385370724807 
2016-12-11 17:35:44 Training Loss = 0.013015975233569 
2016-12-11 17:35:51 Valid Error = 0.62149007862224 
2016-12-11 17:35:51 Valid Loss = 0.012770053539761 
2016-12-11 17:35:58 Test Error = 0.5991916470192 
2016-12-11 17:35:58 Test Loss = 0.012610943436573 
2016-12-11 17:35:58 -------------------LR------------------- 
2016-12-11 17:35:58 0.015625 
2016-12-11 17:35:58 Epoch 43 
2016-12-11 17:41:06 Training Error = 0.57135724390447 
2016-12-11 17:41:06 Training Loss = 0.013007456882181 
2016-12-11 17:41:13 Valid Error = 0.61063272182703 
2016-12-11 17:41:13 Valid Loss = 0.012773684100982 
2016-12-11 17:41:21 Test Error = 0.59211855843718 
2016-12-11 17:41:21 Test Loss = 0.012677134062282 
2016-12-11 17:41:21 -------------------LR------------------- 
2016-12-11 17:41:21 0.015625 
2016-12-11 17:41:21 Epoch 44 
2016-12-11 17:46:31 Training Error = 0.57356245319131 
2016-12-11 17:46:31 Training Loss = 0.013008293307554 
2016-12-11 17:46:38 Valid Error = 0.63459378509921 
2016-12-11 17:46:38 Valid Loss = 0.012785712819651 
2016-12-11 17:46:46 Test Error = 0.62377905018525 
2016-12-11 17:46:46 Test Loss = 0.012654181620057 
2016-12-11 17:46:46 -------------------LR------------------- 
2016-12-11 17:46:46 0.015625 
2016-12-11 17:46:46 Epoch 45 
2016-12-11 17:51:54 Training Error = 0.57293833735541 
2016-12-11 17:51:54 Training Loss = 0.013028650452437 
2016-12-11 17:52:01 Valid Error = 0.6263571695994 
2016-12-11 17:52:01 Valid Loss = 0.012814896830497 
2016-12-11 17:52:09 Test Error = 0.60794880431122 
2016-12-11 17:52:09 Test Loss = 0.012693459441973 
2016-12-11 17:52:09 -------------------LR------------------- 
2016-12-11 17:52:09 0.015625 
2016-12-11 17:52:09 Epoch 46 
2016-12-11 17:57:20 Training Error = 0.57327119913456 
2016-12-11 17:57:20 Training Loss = 0.013024592990539 
2016-12-11 17:57:27 Valid Error = 0.60539123923624 
2016-12-11 17:57:27 Valid Loss = 0.012749211724283 
2016-12-11 17:57:34 Test Error = 0.58437184237117 
2016-12-11 17:57:34 Test Loss = 0.012617672996219 
2016-12-11 17:57:34 -------------------LR------------------- 
2016-12-11 17:57:34 0.015625 
2016-12-11 17:57:34 Epoch 47 
2016-12-11 18:02:44 Training Error = 0.5711908130149 
2016-12-11 18:02:44 Training Loss = 0.013015369126342 
2016-12-11 18:02:51 Valid Error = 0.60539123923624 
2016-12-11 18:02:51 Valid Loss = 0.012756211822502 
2016-12-11 18:02:59 Test Error = 0.58336140114517 
2016-12-11 18:02:59 Test Loss = 0.012607052127868 
2016-12-11 18:02:59 -------------------LR------------------- 
2016-12-11 18:02:59 0.015625 
2016-12-11 18:02:59 Epoch 48 
2016-12-11 18:08:08 Training Error = 0.57443621536157 
2016-12-11 18:08:08 Training Loss = 0.01301988812323 
2016-12-11 18:08:15 Valid Error = 0.64020965930363 
2016-12-11 18:08:15 Valid Loss = 0.01280887244055 
2016-12-11 18:08:22 Test Error = 0.62647356012125 
2016-12-11 18:08:22 Test Loss = 0.012687149261105 
2016-12-11 18:08:22 -------------------LR------------------- 
2016-12-11 18:08:22 0.015625 
2016-12-11 18:08:22 Epoch 49 
2016-12-11 18:13:35 Training Error = 0.57164849796122 
2016-12-11 18:13:35 Training Loss = 0.013007608106606 
2016-12-11 18:13:42 Valid Error = 0.64020965930363 
2016-12-11 18:13:42 Valid Loss = 0.012830358545566 
2016-12-11 18:13:49 Test Error = 0.61771640282924 
2016-12-11 18:13:49 Test Loss = 0.012721006666366 
2016-12-11 18:13:49 -------------------LR------------------- 
2016-12-11 18:13:49 0.015625 
2016-12-11 18:13:49 Epoch 50 
2016-12-11 18:19:00 Training Error = 0.57102438212532 
2016-12-11 18:19:00 Training Loss = 0.013018103460642 
2016-12-11 18:19:07 Valid Error = 0.60464245600899 
2016-12-11 18:19:07 Valid Loss = 0.012636935473374 
2016-12-11 18:19:15 Test Error = 0.58976086224318 
2016-12-11 18:19:15 Test Loss = 0.012486542397357 
2016-12-11 18:19:15 -------------------LR------------------- 
2016-12-11 18:19:15 0.0078125 
2016-12-11 18:19:15 Epoch 51 
2016-12-11 18:24:26 Training Error = 0.57518515436465 
2016-12-11 18:24:26 Training Loss = 0.013027344994868 
2016-12-11 18:24:33 Valid Error = 0.60763758891801 
2016-12-11 18:24:33 Valid Loss = 0.012708201281355 
2016-12-11 18:24:41 Test Error = 0.58740316604917 
2016-12-11 18:24:41 Test Loss = 0.012571424687162 
2016-12-11 18:24:41 -------------------LR------------------- 
2016-12-11 18:24:41 0.0078125 
2016-12-11 18:24:41 Epoch 52 
2016-12-11 18:29:52 Training Error = 0.57064991262378 
2016-12-11 18:29:52 Training Loss = 0.013016484106633 
2016-12-11 18:29:59 Valid Error = 0.6035192811681 
2016-12-11 18:29:59 Valid Loss = 0.012732777838121 
2016-12-11 18:30:07 Test Error = 0.58976086224318 
2016-12-11 18:30:07 Test Loss = 0.01258119401705 
2016-12-11 18:30:07 -------------------LR------------------- 
2016-12-11 18:30:07 0.0078125 
2016-12-11 18:30:07 Epoch 53 
2016-12-11 18:35:14 Training Error = 0.57285512191063 
2016-12-11 18:35:14 Training Loss = 0.0130190033761 
2016-12-11 18:35:22 Valid Error = 0.61812055409959 
2016-12-11 18:35:22 Valid Loss = 0.012724768943278 
2016-12-11 18:35:29 Test Error = 0.5985180195352 
2016-12-11 18:35:29 Test Loss = 0.012566373305466 
2016-12-11 18:35:29 -------------------LR------------------- 
2016-12-11 18:35:29 0.0078125 
2016-12-11 18:35:29 Epoch 54 
2016-12-11 18:40:40 Training Error = 0.570566697179 
2016-12-11 18:40:40 Training Loss = 0.013021347626531 
2016-12-11 18:40:47 Valid Error = 0.63159865219019 
2016-12-11 18:40:47 Valid Loss = 0.012819718742886 
2016-12-11 18:40:54 Test Error = 0.61030650050522 
2016-12-11 18:40:54 Test Loss = 0.012689923268534 
2016-12-11 18:40:54 -------------------LR------------------- 
2016-12-11 18:40:54 0.0078125 
2016-12-11 18:40:55 Epoch 55 
2016-12-11 18:46:09 Training Error = 0.57347923774653 
2016-12-11 18:46:09 Training Loss = 0.013021671785899 
2016-12-11 18:46:16 Valid Error = 0.64470235866717 
2016-12-11 18:46:16 Valid Loss = 0.012794254170339 
2016-12-11 18:46:24 Test Error = 0.62377905018525 
2016-12-11 18:46:24 Test Loss = 0.01266374412874 
2016-12-11 18:46:24 -------------------LR------------------- 
2016-12-11 18:46:24 0.0078125 
2016-12-11 18:46:24 Epoch 56 
2016-12-11 18:51:33 Training Error = 0.57248065240909 
2016-12-11 18:51:33 Training Loss = 0.013013902590253 
2016-12-11 18:51:40 Valid Error = 0.62523399475852 
2016-12-11 18:51:40 Valid Loss = 0.012759756854841 
2016-12-11 18:51:48 Test Error = 0.61468507915123 
2016-12-11 18:51:48 Test Loss = 0.01261608767599 
2016-12-11 18:51:48 -------------------LR------------------- 
2016-12-11 18:51:48 0.0078125 
2016-12-11 18:51:48 Epoch 57 
2016-12-11 18:56:57 Training Error = 0.5748939003079 
2016-12-11 18:56:57 Training Loss = 0.013029740630444 
2016-12-11 18:57:04 Valid Error = 0.6330962186447 
2016-12-11 18:57:04 Valid Loss = 0.012751009837164 
2016-12-11 18:57:12 Test Error = 0.60660154934321 
2016-12-11 18:57:12 Test Loss = 0.0126020004247 
2016-12-11 18:57:12 -------------------LR------------------- 
2016-12-11 18:57:12 0.0078125 
2016-12-11 18:57:12 Epoch 58 
2016-12-11 19:02:20 Training Error = 0.57464425397354 
2016-12-11 19:02:20 Training Loss = 0.013025281482329 
2016-12-11 19:02:27 Valid Error = 0.63272182703107 
2016-12-11 19:02:27 Valid Loss = 0.012722772307392 
2016-12-11 19:02:34 Test Error = 0.60963287302122 
2016-12-11 19:02:34 Test Loss = 0.012565847747765 
2016-12-11 19:02:34 -------------------LR------------------- 
2016-12-11 19:02:34 0.0078125 
2016-12-11 19:02:34 Epoch 59 
2016-12-11 19:07:46 Training Error = 0.57626695514688 
2016-12-11 19:07:46 Training Loss = 0.013034043281297 
2016-12-11 19:07:53 Valid Error = 0.6061400224635 
2016-12-11 19:07:53 Valid Loss = 0.012651050841754 
2016-12-11 19:08:01 Test Error = 0.57864600875716 
2016-12-11 19:08:01 Test Loss = 0.012499699781575 
2016-12-11 19:08:01 -------------------LR------------------- 
2016-12-11 19:08:01 0.0078125 
2016-12-11 19:08:01 Epoch 60 
2016-12-11 19:13:13 Training Error = 0.57572605475576 
2016-12-11 19:13:13 Training Loss = 0.013024086671249 
2016-12-11 19:13:20 Valid Error = 0.60576563084987 
2016-12-11 19:13:20 Valid Loss = 0.012680960073823 
2016-12-11 19:13:27 Test Error = 0.58369821488717 
2016-12-11 19:13:27 Test Loss = 0.012528741589874 
2016-12-11 19:13:27 -------------------LR------------------- 
2016-12-11 19:13:27 0.0078125 
2016-12-11 19:13:27 Epoch 61 
2016-12-11 19:18:33 Training Error = 0.57535158525422 
2016-12-11 19:18:33 Training Loss = 0.01302148842742 
2016-12-11 19:18:41 Valid Error = 0.62074129539498 
2016-12-11 19:18:41 Valid Loss = 0.012717486580708 
2016-12-11 19:18:48 Test Error = 0.60458066689121 
2016-12-11 19:18:48 Test Loss = 0.012585999747838 
2016-12-11 19:18:48 -------------------LR------------------- 
2016-12-11 19:18:48 0.0078125 
2016-12-11 19:18:48 Epoch 62 
2016-12-11 19:24:00 Training Error = 0.57277190646584 
2016-12-11 19:24:00 Training Loss = 0.013021914662137 
2016-12-11 19:24:07 Valid Error = 0.62261325346312 
2016-12-11 19:24:07 Valid Loss = 0.012767892300468 
2016-12-11 19:24:15 Test Error = 0.5995284607612 
2016-12-11 19:24:15 Test Loss = 0.012656987279765 
2016-12-11 19:24:15 -------------------LR------------------- 
2016-12-11 19:24:15 0.0078125 
2016-12-11 19:24:15 Epoch 63 
2016-12-11 19:29:27 Training Error = 0.57293833735541 
2016-12-11 19:29:27 Training Loss = 0.013022234093827 
2016-12-11 19:29:34 Valid Error = 0.62860351928117 
2016-12-11 19:29:34 Valid Loss = 0.012746051571912 
2016-12-11 19:29:42 Test Error = 0.61670596160323 
2016-12-11 19:29:42 Test Loss = 0.012608933291636 
2016-12-11 19:29:42 -------------------LR------------------- 
2016-12-11 19:29:42 0.0078125 
2016-12-11 19:29:42 Epoch 64 
2016-12-11 19:34:49 Training Error = 0.56969293500874 
2016-12-11 19:34:49 Training Loss = 0.013011914802044 
2016-12-11 19:34:56 Valid Error = 0.6263571695994 
2016-12-11 19:34:56 Valid Loss = 0.012810076216368 
2016-12-11 19:35:04 Test Error = 0.60862243179522 
2016-12-11 19:35:04 Test Loss = 0.012679149790809 
2016-12-11 19:35:04 -------------------LR------------------- 
2016-12-11 19:35:04 0.0078125 
2016-12-11 19:35:04 Epoch 65 
2016-12-11 19:40:15 Training Error = 0.57693267870517 
2016-12-11 19:40:15 Training Loss = 0.013029677626861 
2016-12-11 19:40:22 Valid Error = 0.65518532384875 
2016-12-11 19:40:22 Valid Loss = 0.012744006449009 
2016-12-11 19:40:30 Test Error = 0.62984169754126 
2016-12-11 19:40:30 Test Loss = 0.012603289084182 
2016-12-11 19:40:30 -------------------LR------------------- 
2016-12-11 19:40:30 0.0078125 
2016-12-11 19:40:30 Epoch 66 
2016-12-11 19:45:37 Training Error = 0.57281351418823 
2016-12-11 19:45:37 Training Loss = 0.01302823598945 
2016-12-11 19:45:44 Valid Error = 0.6263571695994 
2016-12-11 19:45:44 Valid Loss = 0.012707011553368 
2016-12-11 19:45:52 Test Error = 0.5981812057932 
2016-12-11 19:45:52 Test Loss = 0.012557587342308 
2016-12-11 19:45:52 -------------------LR------------------- 
2016-12-11 19:45:52 0.0078125 
2016-12-11 19:45:52 Epoch 67 
2016-12-11 19:51:02 Training Error = 0.57094116668054 
2016-12-11 19:51:02 Training Loss = 0.013005276451275 
2016-12-11 19:51:09 Valid Error = 0.63684013478098 
2016-12-11 19:51:09 Valid Loss = 0.012767238592503 
2016-12-11 19:51:17 Test Error = 0.61434826540923 
2016-12-11 19:51:17 Test Loss = 0.012609592958147 
2016-12-11 19:51:17 -------------------LR------------------- 
2016-12-11 19:51:17 0.0078125 
2016-12-11 19:51:17 Epoch 68 
2016-12-11 19:56:27 Training Error = 0.56998418906549 
2016-12-11 19:56:27 Training Loss = 0.013015520719813 
2016-12-11 19:56:34 Valid Error = 0.65930363159865 
2016-12-11 19:56:34 Valid Loss = 0.012882125926846 
2016-12-11 19:56:41 Test Error = 0.63859885483328 
2016-12-11 19:56:41 Test Loss = 0.012753012499214 
2016-12-11 19:56:41 -------------------LR------------------- 
2016-12-11 19:56:41 0.0078125 
2016-12-11 19:56:41 Epoch 69 
2016-12-11 20:01:47 Training Error = 0.57148206707165 
2016-12-11 20:01:47 Training Loss = 0.013027357689141 
2016-12-11 20:01:54 Valid Error = 0.60127293148633 
2016-12-11 20:01:54 Valid Loss = 0.012743148711445 
2016-12-11 20:02:02 Test Error = 0.58841360727518 
2016-12-11 20:02:02 Test Loss = 0.012614872383783 
2016-12-11 20:02:02 -------------------LR------------------- 
2016-12-11 20:02:02 0.0078125 
2016-12-11 20:02:02 Epoch 70 
2016-12-11 20:07:12 Training Error = 0.5767246400932 
2016-12-11 20:07:12 Training Loss = 0.013031929698311 
2016-12-11 20:07:19 Valid Error = 0.60988393859978 
2016-12-11 20:07:19 Valid Loss = 0.012841180017074 
2016-12-11 20:07:27 Test Error = 0.59009767598518 
2016-12-11 20:07:27 Test Loss = 0.012719186683372 
2016-12-11 20:07:27 -------------------LR------------------- 
2016-12-11 20:07:27 0.0078125 
2016-12-11 20:07:27 Epoch 71 
2016-12-11 20:12:35 Training Error = 0.5748939003079 
2016-12-11 20:12:35 Training Loss = 0.013033372705274 
2016-12-11 20:12:42 Valid Error = 0.63758891800824 
2016-12-11 20:12:42 Valid Loss = 0.012811938669631 
2016-12-11 20:12:50 Test Error = 0.62142135399124 
2016-12-11 20:12:50 Test Loss = 0.012671241687843 
2016-12-11 20:12:50 -------------------LR------------------- 
2016-12-11 20:12:50 0.0078125 
2016-12-11 20:12:50 Epoch 72 
2016-12-11 20:18:00 Training Error = 0.57460264625114 
2016-12-11 20:18:00 Training Loss = 0.013026296637822 
2016-12-11 20:18:07 Valid Error = 0.60164732309996 
2016-12-11 20:18:07 Valid Loss = 0.012744220066599 
2016-12-11 20:18:15 Test Error = 0.58504546985517 
2016-12-11 20:18:15 Test Loss = 0.012627036763471 
2016-12-11 20:18:15 -------------------LR------------------- 
2016-12-11 20:18:15 0.0078125 
2016-12-11 20:18:15 Epoch 73 
2016-12-11 20:23:26 Training Error = 0.57297994507781 
2016-12-11 20:23:26 Training Loss = 0.013017872322638 
2016-12-11 20:23:33 Valid Error = 0.60426806439536 
2016-12-11 20:23:33 Valid Loss = 0.012785814834687 
2016-12-11 20:23:41 Test Error = 0.58908723475918 
2016-12-11 20:23:41 Test Loss = 0.012652231471858 
2016-12-11 20:23:41 -------------------LR------------------- 
2016-12-11 20:23:41 0.0078125 
2016-12-11 20:23:41 Epoch 74 
2016-12-11 20:28:48 Training Error = 0.57680785553799 
2016-12-11 20:28:48 Training Loss = 0.013038961342318 
2016-12-11 20:28:55 Valid Error = 0.60426806439536 
2016-12-11 20:28:55 Valid Loss = 0.0125607035509 
2016-12-11 20:29:03 Test Error = 0.58672953856517 
2016-12-11 20:29:03 Test Loss = 0.012435749193207 
2016-12-11 20:29:03 -------------------LR------------------- 
2016-12-11 20:29:03 0.0078125 
2016-12-11 20:29:03 Epoch 75 
2016-12-11 20:34:13 Training Error = 0.57501872347508 
2016-12-11 20:34:13 Training Loss = 0.013025079139999 
2016-12-11 20:34:20 Valid Error = 0.63946087607638 
2016-12-11 20:34:20 Valid Loss = 0.012705155741077 
2016-12-11 20:34:28 Test Error = 0.62007409902324 
2016-12-11 20:34:28 Test Loss = 0.01256827014339 
2016-12-11 20:34:28 -------------------LR------------------- 
2016-12-11 20:34:28 0.0078125 
2016-12-11 20:34:28 Epoch 76 
2016-12-11 20:39:39 Training Error = 0.57381209952567 
2016-12-11 20:39:39 Training Loss = 0.013026069652499 
2016-12-11 20:39:46 Valid Error = 0.62186447023587 
2016-12-11 20:39:46 Valid Loss = 0.012744717754548 
2016-12-11 20:39:54 Test Error = 0.6012125294712 
2016-12-11 20:39:54 Test Loss = 0.012613794234478 
2016-12-11 20:39:54 -------------------LR------------------- 
2016-12-11 20:39:54 0.0078125 
2016-12-11 20:39:54 Epoch 77 
2016-12-11 20:45:01 Training Error = 0.57356245319131 
2016-12-11 20:45:01 Training Loss = 0.0130266051545 
2016-12-11 20:45:08 Valid Error = 0.60950954698615 
2016-12-11 20:45:08 Valid Loss = 0.012744260298935 
2016-12-11 20:45:16 Test Error = 0.58942404850118 
2016-12-11 20:45:16 Test Loss = 0.012591078723626 
2016-12-11 20:45:16 -------------------LR------------------- 
2016-12-11 20:45:16 0.0078125 
2016-12-11 20:45:16 Epoch 78 
2016-12-11 20:50:29 Training Error = 0.5730215528002 
2016-12-11 20:50:29 Training Loss = 0.013027694085094 
2016-12-11 20:50:36 Valid Error = 0.62336203669038 
2016-12-11 20:50:36 Valid Loss = 0.012779646497931 
2016-12-11 20:50:44 Test Error = 0.60727517682721 
2016-12-11 20:50:44 Test Loss = 0.012637811908237 
2016-12-11 20:50:44 -------------------LR------------------- 
2016-12-11 20:50:44 0.0078125 
2016-12-11 20:50:44 Epoch 79 
2016-12-11 20:55:51 Training Error = 0.57497711575268 
2016-12-11 20:55:51 Training Loss = 0.013024398843573 
2016-12-11 20:55:59 Valid Error = 0.62485960314489 
2016-12-11 20:55:59 Valid Loss = 0.012915822183484 
2016-12-11 20:56:06 Test Error = 0.61468507915123 
2016-12-11 20:56:06 Test Loss = 0.012790144834013 
2016-12-11 20:56:06 -------------------LR------------------- 
2016-12-11 20:56:06 0.0078125 
2016-12-11 20:56:06 Epoch 80 
2016-12-11 21:01:16 Training Error = 0.57089955895814 
2016-12-11 21:01:16 Training Loss = 0.013022459936322 
2016-12-11 21:01:23 Valid Error = 0.62748034444028 
2016-12-11 21:01:23 Valid Loss = 0.012743056614057 
2016-12-11 21:01:31 Test Error = 0.5995284607612 
2016-12-11 21:01:31 Test Loss = 0.012586114072581 
2016-12-11 21:01:31 -------------------LR------------------- 
2016-12-11 21:01:31 0.0078125 
2016-12-11 21:01:31 Epoch 81 
2016-12-11 21:06:43 Training Error = 0.57314637596738 
2016-12-11 21:06:43 Training Loss = 0.013038329502659 
2016-12-11 21:06:50 Valid Error = 0.60127293148633 
2016-12-11 21:06:50 Valid Loss = 0.012721197573446 
2016-12-11 21:06:58 Test Error = 0.58268777366117 
2016-12-11 21:06:58 Test Loss = 0.012584732850592 
2016-12-11 21:06:58 -------------------LR------------------- 
2016-12-11 21:06:58 0.0078125 
2016-12-11 21:06:58 Epoch 82 
2016-12-11 21:12:07 Training Error = 0.57314637596738 
2016-12-11 21:12:07 Training Loss = 0.01302751194726 
2016-12-11 21:12:14 Valid Error = 0.58517409210034 
2016-12-11 21:12:14 Valid Loss = 0.012655420319638 
2016-12-11 21:12:22 Test Error = 0.57089929269114 
2016-12-11 21:12:22 Test Loss = 0.012511772345144 
2016-12-11 21:12:22 -------------------LR------------------- 
2016-12-11 21:12:22 0.0078125 
2016-12-11 21:12:22 Epoch 83 
2016-12-11 21:17:27 Training Error = 0.57539319297662 
2016-12-11 21:17:27 Training Loss = 0.013021683464015 
2016-12-11 21:17:34 Valid Error = 0.60763758891801 
2016-12-11 21:17:34 Valid Loss = 0.012724147218652 
2016-12-11 21:17:42 Test Error = 0.58437184237117 
2016-12-11 21:17:42 Test Loss = 0.012567557304265 
2016-12-11 21:17:42 -------------------LR------------------- 
2016-12-11 21:17:42 0.0078125 
2016-12-11 21:17:42 Epoch 84 
2016-12-11 21:22:49 Training Error = 0.57318798368977 
2016-12-11 21:22:49 Training Loss = 0.013014901944788 
2016-12-11 21:22:56 Valid Error = 0.61213028828154 
2016-12-11 21:22:56 Valid Loss = 0.01276386769283 
2016-12-11 21:23:04 Test Error = 0.58706635230717 
2016-12-11 21:23:04 Test Loss = 0.012615101234586 
2016-12-11 21:23:04 -------------------LR------------------- 
2016-12-11 21:23:04 0.0078125 
2016-12-11 21:23:04 Epoch 85 
2016-12-11 21:28:13 Training Error = 0.57285512191063 
2016-12-11 21:28:13 Training Loss = 0.013015870318483 
2016-12-11 21:28:20 Valid Error = 0.60501684762261 
2016-12-11 21:28:20 Valid Loss = 0.012642277574682 
2016-12-11 21:28:28 Test Error = 0.58875042101718 
2016-12-11 21:28:28 Test Loss = 0.012498912827194 
2016-12-11 21:28:28 -------------------LR------------------- 
2016-12-11 21:28:28 0.0078125 
2016-12-11 21:28:28 Epoch 86 
2016-12-11 21:33:35 Training Error = 0.57514354664226 
2016-12-11 21:33:35 Training Loss = 0.013039015318976 
2016-12-11 21:33:42 Valid Error = 0.64395357543991 
2016-12-11 21:33:42 Valid Loss = 0.012826067588515 
2016-12-11 21:33:50 Test Error = 0.62209498147524 
2016-12-11 21:33:50 Test Loss = 0.012691482980002 
2016-12-11 21:33:50 -------------------LR------------------- 
2016-12-11 21:33:50 0.0078125 
2016-12-11 21:33:50 Epoch 87 
2016-12-11 21:39:00 Training Error = 0.57456103852875 
2016-12-11 21:39:00 Training Loss = 0.013027320465967 
2016-12-11 21:39:07 Valid Error = 0.6128790715088 
2016-12-11 21:39:07 Valid Loss = 0.012685565593537 
2016-12-11 21:39:14 Test Error = 0.59211855843718 
2016-12-11 21:39:14 Test Loss = 0.012527068347796 
2016-12-11 21:39:14 -------------------LR------------------- 
2016-12-11 21:39:14 0.0078125 
2016-12-11 21:39:14 Epoch 88 
2016-12-11 21:44:22 Training Error = 0.57210618290755 
2016-12-11 21:44:22 Training Loss = 0.013017966759337 
2016-12-11 21:44:29 Valid Error = 0.61886933732684 
2016-12-11 21:44:29 Valid Loss = 0.012773646241133 
2016-12-11 21:44:37 Test Error = 0.59750757830919 
2016-12-11 21:44:37 Test Loss = 0.012641389121102 
2016-12-11 21:44:37 -------------------LR------------------- 
2016-12-11 21:44:37 0.0078125 
2016-12-11 21:44:37 Epoch 89 
2016-12-11 21:49:47 Training Error = 0.57064991262378 
2016-12-11 21:49:47 Training Loss = 0.013019407527304 
2016-12-11 21:49:54 Valid Error = 0.59790340696368 
2016-12-11 21:49:54 Valid Loss = 0.012831621574347 
2016-12-11 21:50:02 Test Error = 0.58504546985517 
2016-12-11 21:50:02 Test Loss = 0.012724590672321 
2016-12-11 21:50:02 -------------------LR------------------- 
2016-12-11 21:50:02 0.0078125 
2016-12-11 21:50:02 Epoch 90 
2016-12-11 21:55:14 Training Error = 0.57493550803029 
2016-12-11 21:55:14 Training Loss = 0.013041773376068 
2016-12-11 21:55:21 Valid Error = 0.61325346312243 
2016-12-11 21:55:21 Valid Loss = 0.012814605106038 
2016-12-11 21:55:28 Test Error = 0.59514988211519 
2016-12-11 21:55:28 Test Loss = 0.012710332031791 
2016-12-11 21:55:28 -------------------LR------------------- 
2016-12-11 21:55:28 0.0078125 
2016-12-11 21:55:28 Epoch 91 
2016-12-11 22:00:39 Training Error = 0.57397853041525 
2016-12-11 22:00:39 Training Loss = 0.013030169503482 
2016-12-11 22:00:46 Valid Error = 0.64844627480344 
2016-12-11 22:00:46 Valid Loss = 0.012864556903101 
2016-12-11 22:00:53 Test Error = 0.63253620747727 
2016-12-11 22:00:53 Test Loss = 0.012738029905692 
2016-12-11 22:00:53 -------------------LR------------------- 
2016-12-11 22:00:53 0.0078125 
2016-12-11 22:00:53 Epoch 92 
2016-12-11 22:06:04 Training Error = 0.57040026628942 
2016-12-11 22:06:04 Training Loss = 0.013022770417881 
2016-12-11 22:06:11 Valid Error = 0.6128790715088 
2016-12-11 22:06:11 Valid Loss = 0.012735696909555 
2016-12-11 22:06:19 Test Error = 0.59346581340519 
2016-12-11 22:06:19 Test Loss = 0.012603958422709 
2016-12-11 22:06:19 -------------------LR------------------- 
2016-12-11 22:06:19 0.0078125 
2016-12-11 22:06:19 Epoch 93 
2016-12-11 22:11:27 Training Error = 0.57306316052259 
2016-12-11 22:11:27 Training Loss = 0.013025418757023 
2016-12-11 22:11:34 Valid Error = 0.62223886184949 
2016-12-11 22:11:34 Valid Loss = 0.01275888875393 
2016-12-11 22:11:42 Test Error = 0.60929605927922 
2016-12-11 22:11:42 Test Loss = 0.012644295835276 
2016-12-11 22:11:42 -------------------LR------------------- 
2016-12-11 22:11:42 0.0078125 
2016-12-11 22:11:42 Epoch 94 
2016-12-11 22:16:48 Training Error = 0.57410335358242 
2016-12-11 22:16:48 Training Loss = 0.013023520435461 
2016-12-11 22:16:55 Valid Error = 0.62111568700861 
2016-12-11 22:16:55 Valid Loss = 0.012756776510823 
2016-12-11 22:17:02 Test Error = 0.6005389019872 
2016-12-11 22:17:02 Test Loss = 0.012626992962885 
2016-12-11 22:17:02 -------------------LR------------------- 
2016-12-11 22:17:02 0.0078125 
2016-12-11 22:17:02 Epoch 95 
2016-12-11 22:22:10 Training Error = 0.57934592660398 
2016-12-11 22:22:10 Training Loss = 0.013025622091228 
2016-12-11 22:22:17 Valid Error = 0.62036690378136 
2016-12-11 22:22:17 Valid Loss = 0.012813504591889 
2016-12-11 22:22:25 Test Error = 0.60727517682721 
2016-12-11 22:22:25 Test Loss = 0.012689382511723 
2016-12-11 22:22:25 -------------------LR------------------- 
2016-12-11 22:22:25 0.0078125 
2016-12-11 22:22:25 Epoch 96 
2016-12-11 22:27:29 Training Error = 0.57331280685695 
2016-12-11 22:27:29 Training Loss = 0.013021434391667 
2016-12-11 22:27:36 Valid Error = 0.61662298764508 
2016-12-11 22:27:36 Valid Loss = 0.012767985003648 
2016-12-11 22:27:44 Test Error = 0.59548669585719 
2016-12-11 22:27:44 Test Loss = 0.012622271817477 
2016-12-11 22:27:44 -------------------LR------------------- 
2016-12-11 22:27:44 0.0078125 
2016-12-11 22:27:44 Epoch 97 
2016-12-11 22:32:52 Training Error = 0.5730215528002 
2016-12-11 22:32:52 Training Loss = 0.013026615571161 
2016-12-11 22:33:00 Valid Error = 0.64956944964433 
2016-12-11 22:33:00 Valid Loss = 0.012740076409763 
2016-12-11 22:33:07 Test Error = 0.62411586392725 
2016-12-11 22:33:07 Test Loss = 0.012573401493682 
2016-12-11 22:33:07 -------------------LR------------------- 
2016-12-11 22:33:07 0.0078125 
2016-12-11 22:33:07 Epoch 98 
2016-12-11 22:38:21 Training Error = 0.56969293500874 
2016-12-11 22:38:21 Training Loss = 0.013018634694992 
2016-12-11 22:38:28 Valid Error = 0.64470235866717 
2016-12-11 22:38:28 Valid Loss = 0.012708387281665 
2016-12-11 22:38:36 Test Error = 0.62613674637925 
2016-12-11 22:38:36 Test Loss = 0.012549853605383 
2016-12-11 22:38:36 -------------------LR------------------- 
2016-12-11 22:38:36 0.0078125 
2016-12-11 22:38:36 Epoch 99 
2016-12-11 22:43:41 Training Error = 0.57481068486311 
2016-12-11 22:43:41 Training Loss = 0.013033081906018 
2016-12-11 22:43:48 Valid Error = 0.64432796705354 
2016-12-11 22:43:48 Valid Loss = 0.01282821091693 
2016-12-11 22:43:55 Test Error = 0.62344223644325 
2016-12-11 22:43:55 Test Loss = 0.012695128566979 
2016-12-11 22:43:55 -------------------LR------------------- 
2016-12-11 22:43:55 0.0078125 
2016-12-11 22:43:56 Epoch 100 
2016-12-11 22:49:07 Training Error = 0.57530997753183 
2016-12-11 22:49:07 Training Loss = 0.013033406111901 
2016-12-11 22:49:14 Valid Error = 0.59378509921378 
2016-12-11 22:49:14 Valid Loss = 0.012695001468359 
2016-12-11 22:49:22 Test Error = 0.57494105759515 
2016-12-11 22:49:22 Test Loss = 0.01255753696666 
2016-12-11 22:49:22 -------------------LR------------------- 
2016-12-11 22:49:22 0.00390625 
2016-12-11 22:49:22 Epoch 101 
2016-12-11 22:54:31 Training Error = 0.56998418906549 
2016-12-11 22:54:31 Training Loss = 0.013024038264069 
2016-12-11 22:54:38 Valid Error = 0.62298764507675 
2016-12-11 22:54:38 Valid Loss = 0.01275340571393 
2016-12-11 22:54:45 Test Error = 0.61401145166723 
2016-12-11 22:54:45 Test Loss = 0.012679895333365 
2016-12-11 22:54:45 -------------------LR------------------- 
2016-12-11 22:54:45 0.00390625 
2016-12-11 22:54:46 Epoch 102 
2016-12-11 22:59:51 Training Error = 0.57451943080636 
2016-12-11 22:59:51 Training Loss = 0.013023203705866 
2016-12-11 22:59:58 Valid Error = 0.62860351928117 
2016-12-11 22:59:58 Valid Loss = 0.012620803989519 
2016-12-11 23:00:06 Test Error = 0.61569552037723 
2016-12-11 23:00:06 Test Loss = 0.012482570521673 
2016-12-11 23:00:06 -------------------LR------------------- 
2016-12-11 23:00:06 0.00390625 
2016-12-11 23:00:06 Epoch 103 
2016-12-11 23:05:18 Training Error = 0.57456103852875 
2016-12-11 23:05:18 Training Loss = 0.013021700712195 
2016-12-11 23:05:25 Valid Error = 0.61213028828154 
2016-12-11 23:05:25 Valid Loss = 0.012760582089952 
2016-12-11 23:05:33 Test Error = 0.58706635230717 
2016-12-11 23:05:33 Test Loss = 0.012643377218139 
2016-12-11 23:05:33 -------------------LR------------------- 
2016-12-11 23:05:33 0.00390625 
2016-12-11 23:05:33 Epoch 104 
2016-12-11 23:10:44 Training Error = 0.57522676208704 
2016-12-11 23:10:44 Training Loss = 0.013032207693006 
2016-12-11 23:10:51 Valid Error = 0.61662298764508 
2016-12-11 23:10:51 Valid Loss = 0.012765574157812 
2016-12-11 23:10:59 Test Error = 0.59447625463119 
2016-12-11 23:10:59 Test Loss = 0.012645026181109 
2016-12-11 23:10:59 -------------------LR------------------- 
2016-12-11 23:10:59 0.00390625 
2016-12-11 23:10:59 Epoch 105 
2016-12-11 23:16:12 Training Error = 0.57256386785387 
2016-12-11 23:16:12 Training Loss = 0.01302062090799 
2016-12-11 23:16:19 Valid Error = 0.6035192811681 
2016-12-11 23:16:19 Valid Loss = 0.012684071926266 
2016-12-11 23:16:27 Test Error = 0.58336140114517 
2016-12-11 23:16:27 Test Loss = 0.012538408200642 
2016-12-11 23:16:27 -------------------LR------------------- 
2016-12-11 23:16:27 0.00390625 
2016-12-11 23:16:27 Epoch 106 
2016-12-11 23:21:34 Training Error = 0.57343763002413 
2016-12-11 23:21:34 Training Loss = 0.013026797323274 
2016-12-11 23:21:41 Valid Error = 0.59191314114564 
2016-12-11 23:21:41 Valid Loss = 0.012711677798607 
2016-12-11 23:21:49 Test Error = 0.57830919501516 
2016-12-11 23:21:49 Test Loss = 0.012591189924359 
2016-12-11 23:21:49 -------------------LR------------------- 
2016-12-11 23:21:49 0.00390625 
2016-12-11 23:21:49 Epoch 107 
2016-12-11 23:26:58 Training Error = 0.5730215528002 
2016-12-11 23:26:58 Training Loss = 0.013024122395566 
2016-12-11 23:27:05 Valid Error = 0.63347061025833 
2016-12-11 23:27:05 Valid Loss = 0.012800354143575 
2016-12-11 23:27:13 Test Error = 0.61737958908723 
2016-12-11 23:27:13 Test Loss = 0.012683286613557 
2016-12-11 23:27:13 -------------------LR------------------- 
2016-12-11 23:27:13 0.00390625 
2016-12-11 23:27:13 Epoch 108 
2016-12-11 23:33:41 Training Error = 0.57514354664226 
2016-12-11 23:33:41 Training Loss = 0.013019485232458 
2016-12-11 23:33:49 Valid Error = 0.62785473605391 
2016-12-11 23:33:49 Valid Loss = 0.012718328468222 
2016-12-11 23:33:56 Test Error = 0.61165375547322 
2016-12-11 23:33:56 Test Loss = 0.012596163221732 
2016-12-11 23:33:56 -------------------LR------------------- 
2016-12-11 23:33:56 0.00390625 
2016-12-11 23:33:56 Epoch 109 
2016-12-11 23:40:54 Training Error = 0.57173171340601 
2016-12-11 23:40:54 Training Loss = 0.013021458022893 
2016-12-11 23:41:01 Valid Error = 0.62523399475852 
2016-12-11 23:41:01 Valid Loss = 0.012761546433591 
2016-12-11 23:41:09 Test Error = 0.60761199056922 
2016-12-11 23:41:09 Test Loss = 0.012639546337454 
2016-12-11 23:41:09 -------------------LR------------------- 
2016-12-11 23:41:09 0.00390625 
2016-12-11 23:41:09 Epoch 110 
2016-12-11 23:48:05 Training Error = 0.57447782308396 
2016-12-11 23:48:05 Training Loss = 0.013037603251899 
2016-12-11 23:48:12 Valid Error = 0.62149007862224 
2016-12-11 23:48:12 Valid Loss = 0.012631697821637 
2016-12-11 23:48:20 Test Error = 0.60357022566521 
2016-12-11 23:48:20 Test Loss = 0.012470786142807 
2016-12-11 23:48:20 -------------------LR------------------- 
2016-12-11 23:48:20 0.00390625 
2016-12-11 23:48:20 Epoch 111 
2016-12-11 23:55:00 Training Error = 0.57327119913456 
2016-12-11 23:55:00 Training Loss = 0.013014707233064 
2016-12-11 23:55:07 Valid Error = 0.59603144889554 
2016-12-11 23:55:07 Valid Loss = 0.012716387288563 
2016-12-11 23:55:15 Test Error = 0.58066689120916 
2016-12-11 23:55:15 Test Loss = 0.01258196073221 
2016-12-11 23:55:15 -------------------LR------------------- 
2016-12-11 23:55:15 0.00390625 
2016-12-11 23:55:15 Epoch 112 
2016-12-12 00:01:45 Training Error = 0.57169010568361 
2016-12-12 00:01:45 Training Loss = 0.013024420901636 
2016-12-12 00:01:52 Valid Error = 0.62822912766754 
2016-12-12 00:01:52 Valid Loss = 0.012730752148863 
2016-12-12 00:02:00 Test Error = 0.61670596160323 
2016-12-12 00:02:00 Test Loss = 0.012616273003914 
2016-12-12 00:02:00 -------------------LR------------------- 
2016-12-12 00:02:00 0.00390625 
2016-12-12 00:02:00 Epoch 113 
2016-12-12 00:08:22 Training Error = 0.57335441457935 
2016-12-12 00:08:22 Training Loss = 0.013029618506964 
2016-12-12 00:08:29 Valid Error = 0.6263571695994 
2016-12-12 00:08:29 Valid Loss = 0.012628533464248 
2016-12-12 00:08:37 Test Error = 0.60828561805322 
2016-12-12 00:08:37 Test Loss = 0.012495706113418 
2016-12-12 00:08:37 -------------------LR------------------- 
2016-12-12 00:08:37 0.00390625 
2016-12-12 00:08:37 Epoch 114 
2016-12-12 00:15:11 Training Error = 0.570566697179 
2016-12-12 00:15:11 Training Loss = 0.013001558611667 
2016-12-12 00:15:18 Valid Error = 0.61662298764508 
2016-12-12 00:15:18 Valid Loss = 0.012775752525789 
2016-12-12 00:15:26 Test Error = 0.59750757830919 
2016-12-12 00:15:26 Test Loss = 0.012641472162781 
2016-12-12 00:15:26 -------------------LR------------------- 
2016-12-12 00:15:26 0.00390625 
2016-12-12 00:15:26 Epoch 115 
2016-12-12 00:21:54 Training Error = 0.57077473579096 
2016-12-12 00:21:54 Training Loss = 0.013006956464115 
2016-12-12 00:22:01 Valid Error = 0.61587420441782 
2016-12-12 00:22:01 Valid Loss = 0.012665993169311 
2016-12-12 00:22:09 Test Error = 0.58942404850118 
2016-12-12 00:22:09 Test Loss = 0.012497497490162 
2016-12-12 00:22:09 -------------------LR------------------- 
2016-12-12 00:22:09 0.00390625 
2016-12-12 00:22:09 Epoch 116 
2016-12-12 00:28:30 Training Error = 0.57223100607473 
2016-12-12 00:28:30 Training Loss = 0.013023019761711 
2016-12-12 00:28:37 Valid Error = 0.62935230250842 
2016-12-12 00:28:37 Valid Loss = 0.012769068912284 
2016-12-12 00:28:45 Test Error = 0.61670596160323 
2016-12-12 00:28:45 Test Loss = 0.012620674859796 
2016-12-12 00:28:45 -------------------LR------------------- 
2016-12-12 00:28:45 0.00390625 
2016-12-12 00:28:45 Epoch 117 
2016-12-12 00:35:18 Training Error = 0.57202296746276 
2016-12-12 00:35:18 Training Loss = 0.013010525891244 
2016-12-12 00:35:25 Valid Error = 0.60539123923624 
2016-12-12 00:35:25 Valid Loss = 0.012655881472049 
2016-12-12 00:35:33 Test Error = 0.59178174469518 
2016-12-12 00:35:33 Test Loss = 0.012533563417348 
2016-12-12 00:35:33 -------------------LR------------------- 
2016-12-12 00:35:33 0.00390625 
2016-12-12 00:35:33 Epoch 118 
2016-12-12 00:42:03 Training Error = 0.57297994507781 
2016-12-12 00:42:03 Training Loss = 0.013015332564175 
2016-12-12 00:42:11 Valid Error = 0.60202171471359 
2016-12-12 00:42:11 Valid Loss = 0.012591693441454 
2016-12-12 00:42:18 Test Error = 0.58134051869316 
2016-12-12 00:42:18 Test Loss = 0.01243751557867 
2016-12-12 00:42:18 -------------------LR------------------- 
2016-12-12 00:42:18 0.00390625 
2016-12-12 00:42:18 Epoch 119 
2016-12-12 00:48:44 Training Error = 0.57139885162686 
2016-12-12 00:48:44 Training Loss = 0.013018846488437 
2016-12-12 00:48:51 Valid Error = 0.63047547734931 
2016-12-12 00:48:51 Valid Loss = 0.01275752271309 
2016-12-12 00:48:59 Test Error = 0.61535870663523 
2016-12-12 00:48:59 Test Loss = 0.012618111773934 
2016-12-12 00:48:59 -------------------LR------------------- 
2016-12-12 00:48:59 0.00390625 
2016-12-12 00:48:59 Epoch 120 
2016-12-12 00:55:30 Training Error = 0.5711492052925 
2016-12-12 00:55:30 Training Loss = 0.013019941390027 
2016-12-12 00:55:37 Valid Error = 0.63609135155373 
2016-12-12 00:55:37 Valid Loss = 0.012774802293923 
2016-12-12 00:55:45 Test Error = 0.62007409902324 
2016-12-12 00:55:45 Test Loss = 0.012638786377984 
2016-12-12 00:55:45 -------------------LR------------------- 
2016-12-12 00:55:45 0.00390625 
2016-12-12 00:55:45 Epoch 121 
2016-12-12 01:02:06 Training Error = 0.57526836980944 
2016-12-12 01:02:06 Training Loss = 0.013036399678648 
2016-12-12 01:02:13 Valid Error = 0.60052414825908 
2016-12-12 01:02:13 Valid Loss = 0.012673333839923 
2016-12-12 01:02:21 Test Error = 0.58841360727518 
2016-12-12 01:02:21 Test Loss = 0.012520116919023 
2016-12-12 01:02:21 -------------------LR------------------- 
2016-12-12 01:02:21 0.00390625 
2016-12-12 01:02:21 Epoch 122 
2016-12-12 01:08:58 Training Error = 0.57123242073729 
2016-12-12 01:08:58 Training Loss = 0.013027979983924 
2016-12-12 01:09:05 Valid Error = 0.63534256832647 
2016-12-12 01:09:05 Valid Loss = 0.012756746360963 
2016-12-12 01:09:13 Test Error = 0.61367463792523 
2016-12-12 01:09:13 Test Loss = 0.012613773397669 
2016-12-12 01:09:13 -------------------LR------------------- 
2016-12-12 01:09:13 0.00390625 
2016-12-12 01:09:13 Epoch 123 
2016-12-12 01:15:46 Training Error = 0.57094116668054 
2016-12-12 01:15:46 Training Loss = 0.013012855221717 
2016-12-12 01:15:53 Valid Error = 0.6330962186447 
2016-12-12 01:15:53 Valid Loss = 0.012860094178767 
2016-12-12 01:16:01 Test Error = 0.60626473560121 
2016-12-12 01:16:01 Test Loss = 0.012736860373143 
2016-12-12 01:16:01 -------------------LR------------------- 
2016-12-12 01:16:01 0.00390625 
2016-12-12 01:16:01 Epoch 124 
2016-12-12 01:22:25 Training Error = 0.57431139219439 
2016-12-12 01:22:25 Training Loss = 0.013017050971247 
2016-12-12 01:22:32 Valid Error = 0.6035192811681 
2016-12-12 01:22:32 Valid Loss = 0.012634638380914 
2016-12-12 01:22:40 Test Error = 0.59077130346918 
2016-12-12 01:22:40 Test Loss = 0.012470364582156 
2016-12-12 01:22:40 -------------------LR------------------- 
2016-12-12 01:22:40 0.00390625 
2016-12-12 01:22:40 Epoch 125 
2016-12-12 01:29:11 Training Error = 0.57510193891986 
2016-12-12 01:29:11 Training Loss = 0.013022014165428 
2016-12-12 01:29:18 Valid Error = 0.62748034444028 
2016-12-12 01:29:18 Valid Loss = 0.01272823487078 
2016-12-12 01:29:26 Test Error = 0.61468507915123 
2016-12-12 01:29:26 Test Loss = 0.012591692550907 
2016-12-12 01:29:26 -------------------LR------------------- 
2016-12-12 01:29:26 0.00390625 
2016-12-12 01:29:26 Epoch 126 
2016-12-12 01:35:56 Training Error = 0.57518515436465 
2016-12-12 01:35:56 Training Loss = 0.013030579457906 
2016-12-12 01:36:03 Valid Error = 0.63010108573568 
2016-12-12 01:36:03 Valid Loss = 0.012761698680552 
2016-12-12 01:36:11 Test Error = 0.61535870663523 
2016-12-12 01:36:11 Test Loss = 0.012613065301054 
2016-12-12 01:36:11 -------------------LR------------------- 
2016-12-12 01:36:11 0.00390625 
2016-12-12 01:36:11 Epoch 127 
2016-12-12 01:42:43 Training Error = 0.57123242073729 
2016-12-12 01:42:43 Training Loss = 0.013003509107954 
2016-12-12 01:42:50 Valid Error = 0.63047547734931 
2016-12-12 01:42:50 Valid Loss = 0.012711100596591 
2016-12-12 01:42:58 Test Error = 0.61401145166723 
2016-12-12 01:42:58 Test Loss = 0.012565219397738 
2016-12-12 01:42:58 -------------------LR------------------- 
2016-12-12 01:42:58 0.00390625 
2016-12-12 01:42:58 Epoch 128 
2016-12-12 01:49:30 Training Error = 0.57360406091371 
2016-12-12 01:49:30 Training Loss = 0.013033223764604 
2016-12-12 01:49:37 Valid Error = 0.61250467989517 
2016-12-12 01:49:37 Valid Loss = 0.012825247363145 
2016-12-12 01:49:45 Test Error = 0.60525429437521 
2016-12-12 01:49:45 Test Loss = 0.012718697820448 
2016-12-12 01:49:45 -------------------LR------------------- 
2016-12-12 01:49:45 0.00390625 
2016-12-12 01:49:45 Epoch 129 
2016-12-12 01:56:07 Training Error = 0.57277190646584 
2016-12-12 01:56:07 Training Loss = 0.013036690504087 
2016-12-12 01:56:14 Valid Error = 0.6289779108948 
2016-12-12 01:56:14 Valid Loss = 0.01274503874173 
2016-12-12 01:56:22 Test Error = 0.61030650050522 
2016-12-12 01:56:22 Test Loss = 0.012607977275506 
2016-12-12 01:56:22 -------------------LR------------------- 
2016-12-12 01:56:22 0.00390625 
2016-12-12 01:56:22 Epoch 130 
2016-12-12 02:02:55 Training Error = 0.5723974369643 
2016-12-12 02:02:55 Training Loss = 0.013017047619848 
2016-12-12 02:03:02 Valid Error = 0.65106701609884 
2016-12-12 02:03:02 Valid Loss = 0.012643884548682 
2016-12-12 02:03:09 Test Error = 0.62916807005726 
2016-12-12 02:03:09 Test Loss = 0.012485103716988 
2016-12-12 02:03:09 -------------------LR------------------- 
2016-12-12 02:03:09 0.00390625 
2016-12-12 02:03:10 Epoch 131 
2016-12-12 02:09:43 Training Error = 0.57331280685695 
2016-12-12 02:09:43 Training Loss = 0.013021009700565 
2016-12-12 02:09:50 Valid Error = 0.65293897416698 
2016-12-12 02:09:50 Valid Loss = 0.012832958005757 
2016-12-12 02:09:58 Test Error = 0.63186257999326 
2016-12-12 02:09:58 Test Loss = 0.012708897088934 
2016-12-12 02:09:58 -------------------LR------------------- 
2016-12-12 02:09:58 0.00390625 
2016-12-12 02:09:58 Epoch 132 
2016-12-12 02:16:15 Training Error = 0.57472746941832 
2016-12-12 02:16:15 Training Loss = 0.01301483095428 
2016-12-12 02:16:22 Valid Error = 0.62860351928117 
2016-12-12 02:16:22 Valid Loss = 0.012742688803773 
2016-12-12 02:16:30 Test Error = 0.61603233411923 
2016-12-12 02:16:30 Test Loss = 0.012614873122214 
2016-12-12 02:16:30 -------------------LR------------------- 
2016-12-12 02:16:30 0.00390625 
2016-12-12 02:16:30 Epoch 133 
2016-12-12 02:23:05 Training Error = 0.57218939835233 
2016-12-12 02:23:05 Training Loss = 0.013014976435309 
2016-12-12 02:23:12 Valid Error = 0.63197304380382 
2016-12-12 02:23:12 Valid Loss = 0.012937603052811 
2016-12-12 02:23:20 Test Error = 0.62411586392725 
2016-12-12 02:23:20 Test Loss = 0.012845912887993 
2016-12-12 02:23:20 -------------------LR------------------- 
2016-12-12 02:23:20 0.00390625 
2016-12-12 02:23:20 Epoch 134 
2016-12-12 02:29:55 Training Error = 0.57181492885079 
2016-12-12 02:29:55 Training Loss = 0.013026826333677 
2016-12-12 02:30:02 Valid Error = 0.61886933732684 
2016-12-12 02:30:02 Valid Loss = 0.01272676484691 
2016-12-12 02:30:10 Test Error = 0.60996968676322 
2016-12-12 02:30:10 Test Loss = 0.012592509257381 
2016-12-12 02:30:10 -------------------LR------------------- 
2016-12-12 02:30:10 0.00390625 
2016-12-12 02:30:10 Epoch 135 
2016-12-12 02:36:34 Training Error = 0.57343763002413 
2016-12-12 02:36:34 Training Loss = 0.013014642547638 
2016-12-12 02:36:41 Valid Error = 0.65967802321228 
2016-12-12 02:36:41 Valid Loss = 0.012858146053106 
2016-12-12 02:36:49 Test Error = 0.63758841360728 
2016-12-12 02:36:49 Test Loss = 0.012723079947964 
2016-12-12 02:36:49 -------------------LR------------------- 
2016-12-12 02:36:49 0.00390625 
2016-12-12 02:36:49 Epoch 136 
2016-12-12 02:43:21 Training Error = 0.574269784472 
2016-12-12 02:43:21 Training Loss = 0.013030247826053 
2016-12-12 02:43:28 Valid Error = 0.61662298764508 
2016-12-12 02:43:28 Valid Loss = 0.012897803425957 
2016-12-12 02:43:36 Test Error = 0.5978443920512 
2016-12-12 02:43:36 Test Loss = 0.012787661372198 
2016-12-12 02:43:36 -------------------LR------------------- 
2016-12-12 02:43:36 0.00390625 
2016-12-12 02:43:36 Epoch 137 
2016-12-12 02:49:57 Training Error = 0.57156528251644 
2016-12-12 02:49:57 Training Loss = 0.013027572305794 
2016-12-12 02:50:04 Valid Error = 0.64582553350805 
2016-12-12 02:50:04 Valid Loss = 0.012724212101357 
2016-12-12 02:50:12 Test Error = 0.62613674637925 
2016-12-12 02:50:12 Test Loss = 0.012569895902275 
2016-12-12 02:50:12 -------------------LR------------------- 
2016-12-12 02:50:12 0.00390625 
2016-12-12 02:50:12 Epoch 138 
2016-12-12 02:56:48 Training Error = 0.57535158525422 
2016-12-12 02:56:48 Training Loss = 0.013032357291317 
2016-12-12 02:56:55 Valid Error = 0.60539123923624 
2016-12-12 02:56:55 Valid Loss = 0.012649595150375 
2016-12-12 02:57:03 Test Error = 0.58571909733917 
2016-12-12 02:57:03 Test Loss = 0.012500470480125 
2016-12-12 02:57:03 -------------------LR------------------- 
2016-12-12 02:57:03 0.00390625 
2016-12-12 02:57:03 Epoch 139 
2016-12-12 03:03:31 Training Error = 0.57539319297662 
2016-12-12 03:03:31 Training Loss = 0.013019982028813 
2016-12-12 03:03:38 Valid Error = 0.61475102957694 
2016-12-12 03:03:38 Valid Loss = 0.01282327662142 
2016-12-12 03:03:46 Test Error = 0.59312899966319 
2016-12-12 03:03:46 Test Loss = 0.012688929002783 
2016-12-12 03:03:46 -------------------LR------------------- 
2016-12-12 03:03:46 0.00390625 
2016-12-12 03:03:46 Epoch 140 
2016-12-12 03:10:08 Training Error = 0.57439460763918 
2016-12-12 03:10:08 Training Loss = 0.013027748023136 
2016-12-12 03:10:15 Valid Error = 0.64058405091726 
2016-12-12 03:10:15 Valid Loss = 0.012917009364683 
2016-12-12 03:10:22 Test Error = 0.62647356012125 
2016-12-12 03:10:22 Test Loss = 0.012822811539689 
2016-12-12 03:10:22 -------------------LR------------------- 
2016-12-12 03:10:22 0.00390625 
2016-12-12 03:10:22 Epoch 141 
2016-12-12 03:16:59 Training Error = 0.57356245319131 
2016-12-12 03:16:59 Training Loss = 0.01301662654051 
2016-12-12 03:17:06 Valid Error = 0.62560838637215 
2016-12-12 03:17:06 Valid Loss = 0.012722583507841 
2016-12-12 03:17:14 Test Error = 0.60996968676322 
2016-12-12 03:17:14 Test Loss = 0.012588095094842 
2016-12-12 03:17:14 -------------------LR------------------- 
2016-12-12 03:17:14 0.00390625 
2016-12-12 03:17:14 Epoch 142 
2016-12-12 03:23:38 Training Error = 0.57318798368977 
2016-12-12 03:23:38 Training Loss = 0.013012008146671 
2016-12-12 03:23:45 Valid Error = 0.62074129539498 
2016-12-12 03:23:45 Valid Loss = 0.012677113134609 
2016-12-12 03:23:53 Test Error = 0.60862243179522 
2016-12-12 03:23:53 Test Loss = 0.012535593006578 
2016-12-12 03:23:53 -------------------LR------------------- 
2016-12-12 03:23:53 0.00390625 
2016-12-12 03:23:53 Epoch 143 
2016-12-12 03:30:13 Training Error = 0.57106598984772 
2016-12-12 03:30:13 Training Loss = 0.013014906526925 
2016-12-12 03:30:20 Valid Error = 0.62223886184949 
2016-12-12 03:30:20 Valid Loss = 0.012898097304552 
2016-12-12 03:30:28 Test Error = 0.60727517682721 
2016-12-12 03:30:28 Test Loss = 0.012792605353536 
2016-12-12 03:30:28 -------------------LR------------------- 
2016-12-12 03:30:28 0.00390625 
2016-12-12 03:30:28 Epoch 144 
2016-12-12 03:37:05 Training Error = 0.57510193891986 
2016-12-12 03:37:05 Training Loss = 0.013032857535318 
2016-12-12 03:37:12 Valid Error = 0.65967802321228 
2016-12-12 03:37:12 Valid Loss = 0.012703091829632 
2016-12-12 03:37:20 Test Error = 0.63556753115527 
2016-12-12 03:37:20 Test Loss = 0.0125568822957 
2016-12-12 03:37:20 -------------------LR------------------- 
2016-12-12 03:37:20 0.00390625 
2016-12-12 03:37:20 Epoch 145 
2016-12-12 03:43:34 Training Error = 0.57073312806857 
2016-12-12 03:43:34 Training Loss = 0.013010604834012 
2016-12-12 03:43:42 Valid Error = 0.63871209284912 
2016-12-12 03:43:42 Valid Loss = 0.01277164784092 
2016-12-12 03:43:49 Test Error = 0.62276860895925 
2016-12-12 03:43:49 Test Loss = 0.012630917906811 
2016-12-12 03:43:49 -------------------LR------------------- 
2016-12-12 03:43:49 0.00390625 
2016-12-12 03:43:49 Epoch 146 
2016-12-12 03:50:16 Training Error = 0.57181492885079 
2016-12-12 03:50:16 Training Loss = 0.013008085495358 
2016-12-12 03:50:23 Valid Error = 0.59453388244103 
2016-12-12 03:50:23 Valid Loss = 0.012591057262136 
2016-12-12 03:50:31 Test Error = 0.58033007746716 
2016-12-12 03:50:31 Test Loss = 0.012439544883827 
2016-12-12 03:50:31 -------------------LR------------------- 
2016-12-12 03:50:31 0.00390625 
2016-12-12 03:50:31 Epoch 147 
2016-12-12 03:57:00 Training Error = 0.57443621536157 
2016-12-12 03:57:00 Training Loss = 0.013018620247349 
2016-12-12 03:57:07 Valid Error = 0.60763758891801 
2016-12-12 03:57:07 Valid Loss = 0.012733248146086 
2016-12-12 03:57:15 Test Error = 0.58504546985517 
2016-12-12 03:57:15 Test Loss = 0.012562117550738 
2016-12-12 03:57:15 -------------------LR------------------- 
2016-12-12 03:57:15 0.00390625 
2016-12-12 03:57:15 Epoch 148 
2016-12-12 04:03:32 Training Error = 0.57377049180328 
2016-12-12 04:03:32 Training Loss = 0.013023509795296 
2016-12-12 04:03:39 Valid Error = 0.64732309996256 
2016-12-12 04:03:39 Valid Loss = 0.012725819789613 
2016-12-12 04:03:47 Test Error = 0.62512630515325 
2016-12-12 04:03:47 Test Loss = 0.012557235189413 
2016-12-12 04:03:47 -------------------LR------------------- 
2016-12-12 04:03:47 0.00390625 
2016-12-12 04:03:47 Epoch 149 
2016-12-12 04:10:16 Training Error = 0.57514354664226 
2016-12-12 04:10:16 Training Loss = 0.013019802140506 
2016-12-12 04:10:23 Valid Error = 0.62748034444028 
2016-12-12 04:10:23 Valid Loss = 0.012813591356511 
2016-12-12 04:10:31 Test Error = 0.60626473560121 
2016-12-12 04:10:31 Test Loss = 0.012707316519968 
2016-12-12 04:10:31 -------------------LR------------------- 
2016-12-12 04:10:31 0.00390625 
2016-12-12 04:10:31 Epoch 150 
2016-12-12 04:17:01 Training Error = 0.57206457518515 
2016-12-12 04:17:01 Training Loss = 0.013033644680848 
2016-12-12 04:17:08 Valid Error = 0.66192437289405 
2016-12-12 04:17:08 Valid Loss = 0.012879931456161 
2016-12-12 04:17:16 Test Error = 0.64129336476928 
2016-12-12 04:17:16 Test Loss = 0.012748920056339 
2016-12-12 04:17:16 -------------------LR------------------- 
2016-12-12 04:17:16 0.001953125 
2016-12-12 04:17:16 Epoch 151 
2016-12-12 04:23:31 Training Error = 0.57722393276192 
2016-12-12 04:23:31 Training Loss = 0.01304606467748 
2016-12-12 04:23:38 Valid Error = 0.60239610632722 
2016-12-12 04:23:38 Valid Loss = 0.012653763192339 
2016-12-12 04:23:46 Test Error = 0.58672953856517 
2016-12-12 04:23:46 Test Loss = 0.01251449781982 
2016-12-12 04:23:46 -------------------LR------------------- 
2016-12-12 04:23:46 0.001953125 
2016-12-12 04:23:46 Epoch 152 
2016-12-12 04:30:12 Training Error = 0.57431139219439 
2016-12-12 04:30:12 Training Loss = 0.013024130383516 
2016-12-12 04:30:19 Valid Error = 0.62373642830401 
2016-12-12 04:30:19 Valid Loss = 0.012717595658735 
2016-12-12 04:30:27 Test Error = 0.60491748063321 
2016-12-12 04:30:27 Test Loss = 0.012590741699817 
2016-12-12 04:30:27 -------------------LR------------------- 
2016-12-12 04:30:27 0.001953125 
2016-12-12 04:30:27 Epoch 153 
2016-12-12 04:36:47 Training Error = 0.574269784472 
2016-12-12 04:36:47 Training Loss = 0.013020584822526 
2016-12-12 04:36:54 Valid Error = 0.60876076375889 
2016-12-12 04:36:54 Valid Loss = 0.012740247929805 
2016-12-12 04:37:02 Test Error = 0.58403502862917 
2016-12-12 04:37:02 Test Loss = 0.01260595884152 
2016-12-12 04:37:02 -------------------LR------------------- 
2016-12-12 04:37:02 0.001953125 
2016-12-12 04:37:02 Epoch 154 
2016-12-12 04:43:33 Training Error = 0.5711908130149 
2016-12-12 04:43:33 Training Loss = 0.013028085888545 
2016-12-12 04:43:40 Valid Error = 0.60726319730438 
2016-12-12 04:43:40 Valid Loss = 0.012746062576102 
2016-12-12 04:43:48 Test Error = 0.59279218592119 
2016-12-12 04:43:48 Test Loss = 0.012632237658383 
2016-12-12 04:43:48 -------------------LR------------------- 
2016-12-12 04:43:48 0.001953125 
2016-12-12 04:43:48 Epoch 155 
2016-12-12 04:50:15 Training Error = 0.57310476824499 
2016-12-12 04:50:15 Training Loss = 0.01301990861208 
2016-12-12 04:50:22 Valid Error = 0.60052414825908 
2016-12-12 04:50:22 Valid Loss = 0.012548386295402 
2016-12-12 04:50:30 Test Error = 0.58302458740317 
2016-12-12 04:50:30 Test Loss = 0.012418752289137 
2016-12-12 04:50:30 -------------------LR------------------- 
2016-12-12 04:50:30 0.001953125 
2016-12-12 04:50:30 Epoch 156 
2016-12-12 04:56:41 Training Error = 0.57518515436465 
2016-12-12 04:56:41 Training Loss = 0.01301585030107 
2016-12-12 04:56:48 Valid Error = 0.64807188318982 
2016-12-12 04:56:48 Valid Loss = 0.012750147536507 
2016-12-12 04:56:56 Test Error = 0.62782081508926 
2016-12-12 04:56:56 Test Loss = 0.012599301253451 
2016-12-12 04:56:56 -------------------LR------------------- 
2016-12-12 04:56:56 0.001953125 
2016-12-12 04:56:56 Epoch 157 
2016-12-12 05:03:28 Training Error = 0.57297994507781 
2016-12-12 05:03:28 Training Loss = 0.013007902206797 
2016-12-12 05:03:35 Valid Error = 0.63796330962186 
2016-12-12 05:03:35 Valid Loss = 0.012765421848804 
2016-12-12 05:03:43 Test Error = 0.61906365779724 
2016-12-12 05:03:43 Test Loss = 0.012615023224265 
2016-12-12 05:03:43 -------------------LR------------------- 
2016-12-12 05:03:43 0.001953125 
2016-12-12 05:03:43 Epoch 158 
2016-12-12 05:10:09 Training Error = 0.57318798368977 
2016-12-12 05:10:09 Training Loss = 0.013028784024385 
2016-12-12 05:10:16 Valid Error = 0.64170722575814 
2016-12-12 05:10:16 Valid Loss = 0.012800739577708 
2016-12-12 05:10:24 Test Error = 0.62243179521724 
2016-12-12 05:10:24 Test Loss = 0.012646451921427 
2016-12-12 05:10:24 -------------------LR------------------- 
2016-12-12 05:10:24 0.001953125 
2016-12-12 05:10:24 Epoch 159 
2016-12-12 05:16:07 Training Error = 0.57497711575268 
2016-12-12 05:16:07 Training Loss = 0.013019103476476 
2016-12-12 05:16:14 Valid Error = 0.63047547734931 
2016-12-12 05:16:14 Valid Loss = 0.012682889842432 
2016-12-12 05:16:22 Test Error = 0.61535870663523 
2016-12-12 05:16:22 Test Loss = 0.012552770034542 
2016-12-12 05:16:22 -------------------LR------------------- 
2016-12-12 05:16:22 0.001953125 
2016-12-12 05:16:22 Epoch 160 
2016-12-12 05:22:19 Training Error = 0.57410335358242 
2016-12-12 05:22:19 Training Loss = 0.013030870263599 
2016-12-12 05:22:26 Valid Error = 0.63946087607638 
2016-12-12 05:22:26 Valid Loss = 0.012785295399337 
2016-12-12 05:22:34 Test Error = 0.62175816773324 
2016-12-12 05:22:34 Test Loss = 0.01265749369157 
2016-12-12 05:22:34 -------------------LR------------------- 
2016-12-12 05:22:34 0.001953125 
2016-12-12 05:22:34 Epoch 161 
2016-12-12 05:28:14 Training Error = 0.57352084546892 
2016-12-12 05:28:14 Training Loss = 0.013033620107335 
2016-12-12 05:28:21 Valid Error = 0.6169973792587 
2016-12-12 05:28:21 Valid Loss = 0.012836579550676 
2016-12-12 05:28:29 Test Error = 0.59683395082519 
2016-12-12 05:28:29 Test Loss = 0.012700863614995 
2016-12-12 05:28:29 -------------------LR------------------- 
2016-12-12 05:28:29 0.001953125 
2016-12-12 05:28:29 Epoch 162 
2016-12-12 05:34:22 Training Error = 0.57597570109012 
2016-12-12 05:34:22 Training Loss = 0.013026665272562 
2016-12-12 05:34:29 Valid Error = 0.63796330962186 
2016-12-12 05:34:29 Valid Loss = 0.012834977114194 
2016-12-12 05:34:37 Test Error = 0.61401145166723 
2016-12-12 05:34:37 Test Loss = 0.012674684863514 
2016-12-12 05:34:37 -------------------LR------------------- 
2016-12-12 05:34:37 0.001953125 
2016-12-12 05:34:37 Epoch 163 
2016-12-12 05:40:31 Training Error = 0.5742281767496 
2016-12-12 05:40:31 Training Loss = 0.013026519334577 
2016-12-12 05:40:38 Valid Error = 0.61737177087233 
2016-12-12 05:40:38 Valid Loss = 0.012743292239553 
2016-12-12 05:40:46 Test Error = 0.59312899966319 
2016-12-12 05:40:46 Test Loss = 0.012615109315155 
2016-12-12 05:40:46 -------------------LR------------------- 
2016-12-12 05:40:46 0.001953125 
2016-12-12 05:40:46 Epoch 164 
2016-12-12 05:46:28 Training Error = 0.57256386785387 
2016-12-12 05:46:28 Training Loss = 0.013024617335428 
2016-12-12 05:46:35 Valid Error = 0.62560838637215 
2016-12-12 05:46:35 Valid Loss = 0.012804221107543 
2016-12-12 05:46:43 Test Error = 0.61199056921522 
2016-12-12 05:46:43 Test Loss = 0.012671459152642 
2016-12-12 05:46:43 -------------------LR------------------- 
2016-12-12 05:46:43 0.001953125 
2016-12-12 05:46:43 Epoch 165 
2016-12-12 05:52:36 Training Error = 0.57027544312224 
2016-12-12 05:52:36 Training Loss = 0.013002522760129 
2016-12-12 05:52:44 Valid Error = 0.62935230250842 
2016-12-12 05:52:44 Valid Loss = 0.012726435856079 
2016-12-12 05:52:51 Test Error = 0.61670596160323 
2016-12-12 05:52:51 Test Loss = 0.012593130316195 
2016-12-12 05:52:51 -------------------LR------------------- 
2016-12-12 05:52:51 0.001953125 
2016-12-12 05:52:51 Epoch 166 
2016-12-12 05:58:33 Training Error = 0.57518515436465 
2016-12-12 05:58:33 Training Loss = 0.013024139084106 
2016-12-12 05:58:40 Valid Error = 0.6263571695994 
2016-12-12 05:58:40 Valid Loss = 0.012664361355958 
2016-12-12 05:58:47 Test Error = 0.61266419669923 
2016-12-12 05:58:47 Test Loss = 0.012534323481853 
2016-12-12 05:58:47 -------------------LR------------------- 
2016-12-12 05:58:47 0.001953125 
2016-12-12 05:58:48 Epoch 167 
2016-12-12 06:04:41 Training Error = 0.56919364234002 
2016-12-12 06:04:41 Training Loss = 0.013013447612958 
2016-12-12 06:04:48 Valid Error = 0.60651441407712 
2016-12-12 06:04:48 Valid Loss = 0.01255841820483 
2016-12-12 06:04:56 Test Error = 0.59346581340519 
2016-12-12 06:04:56 Test Loss = 0.012411339829452 
2016-12-12 06:04:56 -------------------LR------------------- 
2016-12-12 06:04:56 0.001953125 
2016-12-12 06:04:56 Epoch 168 
2016-12-12 06:10:46 Training Error = 0.57451943080636 
2016-12-12 06:10:46 Training Loss = 0.013012530122255 
2016-12-12 06:10:53 Valid Error = 0.64994384125796 
2016-12-12 06:10:53 Valid Loss = 0.012749062081421 
2016-12-12 06:11:01 Test Error = 0.63152576625126 
2016-12-12 06:11:01 Test Loss = 0.012626415518457 
2016-12-12 06:11:01 -------------------LR------------------- 
2016-12-12 06:11:01 0.001953125 
2016-12-12 06:11:01 Epoch 169 
2016-12-12 06:16:44 Training Error = 0.57418656902721 
2016-12-12 06:16:44 Training Loss = 0.013016125211897 
2016-12-12 06:16:51 Valid Error = 0.62485960314489 
2016-12-12 06:16:51 Valid Loss = 0.012707309050609 
2016-12-12 06:16:59 Test Error = 0.61064331424722 
2016-12-12 06:16:59 Test Loss = 0.012562788289738 
2016-12-12 06:16:59 -------------------LR------------------- 
2016-12-12 06:16:59 0.001953125 
2016-12-12 06:16:59 Epoch 170 
2016-12-12 06:22:52 Training Error = 0.5730215528002 
2016-12-12 06:22:52 Training Loss = 0.013045286566481 
2016-12-12 06:22:59 Valid Error = 0.6330962186447 
2016-12-12 06:22:59 Valid Loss = 0.012783793475964 
2016-12-12 06:23:07 Test Error = 0.61737958908723 
2016-12-12 06:23:07 Test Loss = 0.012659376406202 
2016-12-12 06:23:07 -------------------LR------------------- 
2016-12-12 06:23:07 0.001953125 
2016-12-12 06:23:08 Epoch 171 
2016-12-12 06:28:53 Training Error = 0.57414496130482 
2016-12-12 06:28:53 Training Loss = 0.013041143169982 
2016-12-12 06:29:00 Valid Error = 0.60052414825908 
2016-12-12 06:29:00 Valid Loss = 0.012774456163308 
2016-12-12 06:29:08 Test Error = 0.58538228359717 
2016-12-12 06:29:08 Test Loss = 0.012665363811482 
2016-12-12 06:29:08 -------------------LR------------------- 
2016-12-12 06:29:08 0.001953125 
2016-12-12 06:29:08 Epoch 172 
2016-12-12 06:34:58 Training Error = 0.57322959141217 
2016-12-12 06:34:58 Training Loss = 0.013015515244096 
2016-12-12 06:35:05 Valid Error = 0.61549981280419 
2016-12-12 06:35:05 Valid Loss = 0.012737560066655 
2016-12-12 06:35:13 Test Error = 0.60491748063321 
2016-12-12 06:35:13 Test Loss = 0.012596016668607 
2016-12-12 06:35:13 -------------------LR------------------- 
2016-12-12 06:35:13 0.001953125 
2016-12-12 06:35:13 Epoch 173 
2016-12-12 06:40:57 Training Error = 0.57006740451028 
2016-12-12 06:40:57 Training Loss = 0.013014235687173 
2016-12-12 06:41:04 Valid Error = 0.62149007862224 
2016-12-12 06:41:04 Valid Loss = 0.012784223762838 
2016-12-12 06:41:12 Test Error = 0.59717076456719 
2016-12-12 06:41:12 Test Loss = 0.012657226339697 
2016-12-12 06:41:12 -------------------LR------------------- 
2016-12-12 06:41:12 0.001953125 
2016-12-12 06:41:12 Epoch 174 
2016-12-12 06:47:08 Training Error = 0.57647499375884 
2016-12-12 06:47:08 Training Loss = 0.013031823766337 
2016-12-12 06:47:15 Valid Error = 0.58966679146387 
2016-12-12 06:47:15 Valid Loss = 0.012677683427568 
2016-12-12 06:47:23 Test Error = 0.57426743011115 
2016-12-12 06:47:23 Test Loss = 0.012540438482947 
2016-12-12 06:47:23 -------------------LR------------------- 
2016-12-12 06:47:23 0.001953125 
2016-12-12 06:47:23 Epoch 175 
2016-12-12 06:53:16 Training Error = 0.574269784472 
2016-12-12 06:53:16 Training Loss = 0.013035691829134 
2016-12-12 06:53:23 Valid Error = 0.60539123923624 
2016-12-12 06:53:23 Valid Loss = 0.012596664545322 
2016-12-12 06:53:30 Test Error = 0.59312899966319 
2016-12-12 06:53:30 Test Loss = 0.012452071762403 
2016-12-12 06:53:30 -------------------LR------------------- 
2016-12-12 06:53:30 0.001953125 
2016-12-12 06:53:30 Epoch 176 
2016-12-12 06:59:15 Training Error = 0.57676624781559 
2016-12-12 06:59:15 Training Loss = 0.013015023545489 
2016-12-12 06:59:22 Valid Error = 0.63496817671284 
2016-12-12 06:59:22 Valid Loss = 0.012708910967977 
2016-12-12 06:59:30 Test Error = 0.61434826540923 
2016-12-12 06:59:30 Test Loss = 0.012571683912313 
2016-12-12 06:59:30 -------------------LR------------------- 
2016-12-12 06:59:30 0.001953125 
2016-12-12 06:59:30 Epoch 177 
2016-12-12 07:05:24 Training Error = 0.57268869102105 
2016-12-12 07:05:24 Training Loss = 0.01302189603841 
2016-12-12 07:05:31 Valid Error = 0.61549981280419 
2016-12-12 07:05:31 Valid Loss = 0.012695195957331 
2016-12-12 07:05:39 Test Error = 0.6008757157292 
2016-12-12 07:05:39 Test Loss = 0.012553028734515 
2016-12-12 07:05:39 -------------------LR------------------- 
2016-12-12 07:05:39 0.001953125 
2016-12-12 07:05:39 Epoch 178 
2016-12-12 07:11:21 Training Error = 0.57368727635849 
2016-12-12 07:11:21 Training Loss = 0.013032563467453 
2016-12-12 07:11:28 Valid Error = 0.60426806439536 
2016-12-12 07:11:28 Valid Loss = 0.012640434145361 
2016-12-12 07:11:36 Test Error = 0.58437184237117 
2016-12-12 07:11:36 Test Loss = 0.012504037792602 
2016-12-12 07:11:36 -------------------LR------------------- 
2016-12-12 07:11:36 0.001953125 
2016-12-12 07:11:36 Epoch 179 
2016-12-12 07:17:30 Training Error = 0.57543480069901 
2016-12-12 07:17:30 Training Loss = 0.013024468330984 
2016-12-12 07:17:38 Valid Error = 0.64283040059903 
2016-12-12 07:17:38 Valid Loss = 0.012823574632565 
2016-12-12 07:17:45 Test Error = 0.62175816773324 
2016-12-12 07:17:45 Test Loss = 0.012693039171985 
2016-12-12 07:17:45 -------------------LR------------------- 
2016-12-12 07:17:45 0.001953125 
2016-12-12 07:17:45 Epoch 180 
2016-12-12 07:23:40 Training Error = 0.57664142464841 
2016-12-12 07:23:40 Training Loss = 0.013035902341962 
2016-12-12 07:23:48 Valid Error = 0.61138150505429 
2016-12-12 07:23:48 Valid Loss = 0.012798400072725 
2016-12-12 07:23:55 Test Error = 0.59548669585719 
2016-12-12 07:23:55 Test Loss = 0.012661527611387 
2016-12-12 07:23:55 -------------------LR------------------- 
2016-12-12 07:23:55 0.001953125 
2016-12-12 07:23:55 Epoch 181 
2016-12-12 07:29:35 Training Error = 0.57518515436465 
2016-12-12 07:29:35 Training Loss = 0.013023358044143 
2016-12-12 07:29:42 Valid Error = 0.62523399475852 
2016-12-12 07:29:42 Valid Loss = 0.012645213869735 
2016-12-12 07:29:50 Test Error = 0.61333782418323 
2016-12-12 07:29:50 Test Loss = 0.012540090354821 
2016-12-12 07:29:50 -------------------LR------------------- 
2016-12-12 07:29:50 0.001953125 
2016-12-12 07:29:50 Epoch 182 
2016-12-12 07:35:43 Training Error = 0.57360406091371 
2016-12-12 07:35:43 Training Loss = 0.01302069495589 
2016-12-12 07:35:50 Valid Error = 0.62822912766754 
2016-12-12 07:35:50 Valid Loss = 0.01289073329083 
2016-12-12 07:35:58 Test Error = 0.60592792185921 
2016-12-12 07:35:58 Test Loss = 0.012762616365613 
2016-12-12 07:35:58 -------------------LR------------------- 
2016-12-12 07:35:58 0.001953125 
2016-12-12 07:35:58 Epoch 183 
2016-12-12 07:41:38 Training Error = 0.57227261379712 
2016-12-12 07:41:38 Training Loss = 0.013010309903431 
2016-12-12 07:41:45 Valid Error = 0.61325346312243 
2016-12-12 07:41:45 Valid Loss = 0.012689394538512 
2016-12-12 07:41:53 Test Error = 0.59750757830919 
2016-12-12 07:41:53 Test Loss = 0.012522783432994 
2016-12-12 07:41:53 -------------------LR------------------- 
2016-12-12 07:41:53 0.001953125 
2016-12-12 07:41:53 Epoch 184 
2016-12-12 07:47:46 Training Error = 0.57160689023883 
2016-12-12 07:47:46 Training Loss = 0.013016613784218 
2016-12-12 07:47:53 Valid Error = 0.61624859603145 
2016-12-12 07:47:53 Valid Loss = 0.012810754108162 
2016-12-12 07:48:01 Test Error = 0.59178174469518 
2016-12-12 07:48:01 Test Loss = 0.012715460499177 
2016-12-12 07:48:01 -------------------LR------------------- 
2016-12-12 07:48:01 0.001953125 
2016-12-12 07:48:01 Epoch 185 
2016-12-12 07:53:52 Training Error = 0.57102438212532 
2016-12-12 07:53:52 Training Loss = 0.013000990837383 
2016-12-12 07:53:59 Valid Error = 0.62186447023587 
2016-12-12 07:53:59 Valid Loss = 0.012736282602601 
2016-12-12 07:54:06 Test Error = 0.60491748063321 
2016-12-12 07:54:06 Test Loss = 0.012622332685532 
2016-12-12 07:54:06 -------------------LR------------------- 
2016-12-12 07:54:06 0.001953125 
2016-12-12 07:54:06 Epoch 186 
2016-12-12 07:59:45 Training Error = 0.57327119913456 
2016-12-12 07:59:45 Training Loss = 0.013027998321834 
2016-12-12 07:59:52 Valid Error = 0.61437663796331 
2016-12-12 07:59:52 Valid Loss = 0.012773597576973 
2016-12-12 08:00:00 Test Error = 0.59683395082519 
2016-12-12 08:00:00 Test Loss = 0.012650975116353 
2016-12-12 08:00:00 -------------------LR------------------- 
2016-12-12 08:00:00 0.001953125 
2016-12-12 08:00:00 Epoch 187 
2016-12-12 08:05:54 Training Error = 0.57231422151951 
2016-12-12 08:05:54 Training Loss = 0.013026802061631 
2016-12-12 08:06:01 Valid Error = 0.6128790715088 
2016-12-12 08:06:01 Valid Loss = 0.012721231505833 
2016-12-12 08:06:09 Test Error = 0.58841360727518 
2016-12-12 08:06:09 Test Loss = 0.012593337466829 
2016-12-12 08:06:09 -------------------LR------------------- 
2016-12-12 08:06:09 0.001953125 
2016-12-12 08:06:09 Epoch 188 
2016-12-12 08:11:47 Training Error = 0.57248065240909 
2016-12-12 08:11:47 Training Loss = 0.013003834260367 
2016-12-12 08:11:54 Valid Error = 0.62673156121303 
2016-12-12 08:11:54 Valid Loss = 0.012794069979826 
2016-12-12 08:12:02 Test Error = 0.61232738295722 
2016-12-12 08:12:02 Test Loss = 0.0126747899889 
2016-12-12 08:12:02 -------------------LR------------------- 
2016-12-12 08:12:02 0.001953125 
2016-12-12 08:12:02 Epoch 189 
2016-12-12 08:17:50 Training Error = 0.5730215528002 
2016-12-12 08:17:50 Training Loss = 0.01302500540132 
2016-12-12 08:17:57 Valid Error = 0.62336203669038 
2016-12-12 08:17:57 Valid Loss = 0.012661817397937 
2016-12-12 08:18:05 Test Error = 0.6002020882452 
2016-12-12 08:18:05 Test Loss = 0.012490411013626 
2016-12-12 08:18:05 -------------------LR------------------- 
2016-12-12 08:18:05 0.001953125 
2016-12-12 08:18:05 Epoch 190 
2016-12-12 08:23:58 Training Error = 0.5711908130149 
2016-12-12 08:23:58 Training Loss = 0.013008134869693 
2016-12-12 08:24:05 Valid Error = 0.6263571695994 
2016-12-12 08:24:05 Valid Loss = 0.012726907338209 
2016-12-12 08:24:13 Test Error = 0.5998652745032 
2016-12-12 08:24:13 Test Loss = 0.012615514076497 
2016-12-12 08:24:13 -------------------LR------------------- 
2016-12-12 08:24:13 0.001953125 
2016-12-12 08:24:13 Epoch 191 
2016-12-12 08:30:01 Training Error = 0.57285512191063 
2016-12-12 08:30:01 Training Loss = 0.013017613706731 
2016-12-12 08:30:08 Valid Error = 0.63272182703107 
2016-12-12 08:30:08 Valid Loss = 0.01279980493965 
2016-12-12 08:30:16 Test Error = 0.61636914786123 
2016-12-12 08:30:16 Test Loss = 0.012658349806237 
2016-12-12 08:30:16 -------------------LR------------------- 
2016-12-12 08:30:16 0.001953125 
2016-12-12 08:30:16 Epoch 192 
2016-12-12 08:36:08 Training Error = 0.57381209952567 
2016-12-12 08:36:08 Training Loss = 0.013019762771367 
2016-12-12 08:36:15 Valid Error = 0.63496817671284 
2016-12-12 08:36:15 Valid Loss = 0.012769911713459 
2016-12-12 08:36:23 Test Error = 0.61940047153924 
2016-12-12 08:36:23 Test Loss = 0.012617705144234 
2016-12-12 08:36:23 -------------------LR------------------- 
2016-12-12 08:36:23 0.001953125 
2016-12-12 08:36:23 Epoch 193 
2016-12-12 08:42:09 Training Error = 0.57418656902721 
2016-12-12 08:42:09 Training Loss = 0.013025929224459 
2016-12-12 08:42:16 Valid Error = 0.61138150505429 
2016-12-12 08:42:16 Valid Loss = 0.012610558630644 
2016-12-12 08:42:24 Test Error = 0.59447625463119 
2016-12-12 08:42:24 Test Loss = 0.01245234976901 
2016-12-12 08:42:24 -------------------LR------------------- 
2016-12-12 08:42:24 0.001953125 
2016-12-12 08:42:24 Epoch 194 
2016-12-12 08:48:20 Training Error = 0.57418656902721 
2016-12-12 08:48:20 Training Loss = 0.01302228759115 
2016-12-12 08:48:27 Valid Error = 0.60950954698615 
2016-12-12 08:48:27 Valid Loss = 0.012741881591793 
2016-12-12 08:48:35 Test Error = 0.58976086224318 
2016-12-12 08:48:35 Test Loss = 0.012611667348188 
2016-12-12 08:48:35 -------------------LR------------------- 
2016-12-12 08:48:35 0.001953125 
2016-12-12 08:48:35 Epoch 195 
2016-12-12 08:54:18 Training Error = 0.57098277440293 
2016-12-12 08:54:18 Training Loss = 0.013012367552484 
2016-12-12 08:54:25 Valid Error = 0.6061400224635 
2016-12-12 08:54:25 Valid Loss = 0.012687917780359 
2016-12-12 08:54:32 Test Error = 0.58201414617716 
2016-12-12 08:54:32 Test Loss = 0.012540962921066 
2016-12-12 08:54:32 -------------------LR------------------- 
2016-12-12 08:54:32 0.001953125 
2016-12-12 08:54:33 Epoch 196 
2016-12-12 09:00:25 Training Error = 0.57243904468669 
2016-12-12 09:00:25 Training Loss = 0.013014857003538 
2016-12-12 09:00:32 Valid Error = 0.59977536503182 
2016-12-12 09:00:32 Valid Loss = 0.012575905782511 
2016-12-12 09:00:39 Test Error = 0.58504546985517 
2016-12-12 09:00:39 Test Loss = 0.012411699635613 
2016-12-12 09:00:39 -------------------LR------------------- 
2016-12-12 09:00:39 0.001953125 
2016-12-12 09:00:39 Epoch 197 
2016-12-12 09:06:34 Training Error = 0.57193975201797 
2016-12-12 09:06:34 Training Loss = 0.013023631866995 
2016-12-12 09:06:41 Valid Error = 0.6169973792587 
2016-12-12 09:06:41 Valid Loss = 0.012707658315805 
2016-12-12 09:06:49 Test Error = 0.5988548332772 
2016-12-12 09:06:49 Test Loss = 0.012579807217041 
2016-12-12 09:06:49 -------------------LR------------------- 
2016-12-12 09:06:49 0.001953125 
2016-12-12 09:06:49 Epoch 198 
2016-12-12 09:12:33 Training Error = 0.57522676208704 
2016-12-12 09:12:33 Training Loss = 0.013021353664081 
2016-12-12 09:12:40 Valid Error = 0.62860351928117 
2016-12-12 09:12:40 Valid Loss = 0.012779145017981 
2016-12-12 09:12:48 Test Error = 0.60255978443921 
2016-12-12 09:12:48 Test Loss = 0.012621214906822 
2016-12-12 09:12:48 -------------------LR------------------- 
2016-12-12 09:12:48 0.001953125 
2016-12-12 09:12:48 Epoch 199 
2016-12-12 09:18:45 Training Error = 0.57335441457935 
2016-12-12 09:18:45 Training Loss = 0.013026404902114 
2016-12-12 09:18:52 Valid Error = 0.64882066641707 
2016-12-12 09:18:52 Valid Loss = 0.012873651517798 
2016-12-12 09:19:00 Test Error = 0.63051532502526 
2016-12-12 09:19:00 Test Loss = 0.012742033737622 
2016-12-12 09:19:00 -------------------LR------------------- 
2016-12-12 09:19:00 0.001953125 
2016-12-12 09:19:00 Epoch 200 
2016-12-12 09:24:43 Training Error = 0.57402013813764 
2016-12-12 09:24:43 Training Loss = 0.013021370183383 
2016-12-12 09:24:50 Valid Error = 0.60426806439536 
2016-12-12 09:24:50 Valid Loss = 0.01271768647823 
2016-12-12 09:24:58 Test Error = 0.58807679353318 
2016-12-12 09:24:58 Test Loss = 0.012558877115007 
2016-12-12 09:24:58 -------------------LR------------------- 
2016-12-12 09:24:58 0.0009765625 
2016-12-12 09:24:58 Epoch 201 
2016-12-12 09:30:56 Training Error = 0.57231422151951 
2016-12-12 09:30:56 Training Loss = 0.013017970414837 
2016-12-12 09:31:03 Valid Error = 0.62336203669038 
2016-12-12 09:31:03 Valid Loss = 0.012696493480241 
2016-12-12 09:31:11 Test Error = 0.60491748063321 
2016-12-12 09:31:11 Test Loss = 0.012553979827505 
2016-12-12 09:31:11 -------------------LR------------------- 
2016-12-12 09:31:11 0.0009765625 
2016-12-12 09:31:11 Epoch 202 
2016-12-12 09:37:01 Training Error = 0.57218939835233 
2016-12-12 09:37:01 Training Loss = 0.013017469818904 
2016-12-12 09:37:08 Valid Error = 0.60763758891801 
2016-12-12 09:37:08 Valid Loss = 0.01283822945205 
2016-12-12 09:37:16 Test Error = 0.58875042101718 
2016-12-12 09:37:16 Test Loss = 0.01272944870202 
2016-12-12 09:37:16 -------------------LR------------------- 
2016-12-12 09:37:16 0.0009765625 
2016-12-12 09:37:16 Epoch 203 
2016-12-12 09:42:56 Training Error = 0.57564283931098 
2016-12-12 09:42:56 Training Loss = 0.013040849904276 
2016-12-12 09:43:03 Valid Error = 0.62448521153126 
2016-12-12 09:43:03 Valid Loss = 0.012683128573617 
2016-12-12 09:43:11 Test Error = 0.61199056921522 
2016-12-12 09:43:11 Test Loss = 0.012536088367378 
2016-12-12 09:43:11 -------------------LR------------------- 
2016-12-12 09:43:11 0.0009765625 
2016-12-12 09:43:11 Epoch 204 
2016-12-12 09:49:06 Training Error = 0.57635017059166 
2016-12-12 09:49:06 Training Loss = 0.013041590706972 
2016-12-12 09:49:13 Valid Error = 0.59827779857731 
2016-12-12 09:49:13 Valid Loss = 0.012606426031046 
2016-12-12 09:49:20 Test Error = 0.57898282249916 
2016-12-12 09:49:20 Test Loss = 0.012444111889683 
2016-12-12 09:49:20 -------------------LR------------------- 
2016-12-12 09:49:20 0.0009765625 
2016-12-12 09:49:21 Epoch 205 
2016-12-12 09:55:00 Training Error = 0.57397853041525 
2016-12-12 09:55:00 Training Loss = 0.01301109289511 
2016-12-12 09:55:07 Valid Error = 0.60988393859978 
2016-12-12 09:55:07 Valid Loss = 0.012653149236434 
2016-12-12 09:55:15 Test Error = 0.59245537217918 
2016-12-12 09:55:15 Test Loss = 0.012503693546809 
2016-12-12 09:55:15 -------------------LR------------------- 
2016-12-12 09:55:15 0.0009765625 
2016-12-12 09:55:15 Epoch 206 
2016-12-12 10:01:05 Training Error = 0.57514354664226 
2016-12-12 10:01:05 Training Loss = 0.013033487829168 
2016-12-12 10:01:12 Valid Error = 0.61250467989517 
2016-12-12 10:01:12 Valid Loss = 0.012687418284034 
2016-12-12 10:01:20 Test Error = 0.60255978443921 
2016-12-12 10:01:20 Test Loss = 0.012534767707885 
2016-12-12 10:01:20 -------------------LR------------------- 
2016-12-12 10:01:20 0.0009765625 
2016-12-12 10:01:20 Epoch 207 
2016-12-12 10:07:15 Training Error = 0.57281351418823 
2016-12-12 10:07:15 Training Loss = 0.013030317920349 
2016-12-12 10:07:22 Valid Error = 0.62710595282666 
2016-12-12 10:07:22 Valid Loss = 0.012714706902463 
2016-12-12 10:07:30 Test Error = 0.61232738295722 
2016-12-12 10:07:30 Test Loss = 0.012592471725502 
2016-12-12 10:07:30 -------------------LR------------------- 
2016-12-12 10:07:30 0.0009765625 
2016-12-12 10:07:30 Epoch 208 
2016-12-12 10:13:12 Training Error = 0.57310476824499 
2016-12-12 10:13:12 Training Loss = 0.013014121023452 
2016-12-12 10:13:19 Valid Error = 0.64769749157619 
2016-12-12 10:13:19 Valid Loss = 0.012908110249717 
2016-12-12 10:13:27 Test Error = 0.62411586392725 
2016-12-12 10:13:27 Test Loss = 0.012790437404742 
2016-12-12 10:13:27 -------------------LR------------------- 
2016-12-12 10:13:27 0.0009765625 
2016-12-12 10:13:27 Epoch 209 
2016-12-12 10:19:16 Training Error = 0.57368727635849 
2016-12-12 10:19:16 Training Loss = 0.013021590786099 
2016-12-12 10:19:23 Valid Error = 0.64020965930363 
2016-12-12 10:19:23 Valid Loss = 0.012852124313202 
2016-12-12 10:19:31 Test Error = 0.62512630515325 
2016-12-12 10:19:31 Test Loss = 0.012751133163223 
2016-12-12 10:19:31 -------------------LR------------------- 
2016-12-12 10:19:31 0.0009765625 
2016-12-12 10:19:31 Epoch 210 
2016-12-12 10:25:13 Training Error = 0.5736456686361 
2016-12-12 10:25:13 Training Loss = 0.013016761116035 
2016-12-12 10:25:20 Valid Error = 0.62336203669038 
2016-12-12 10:25:20 Valid Loss = 0.012741176036775 
2016-12-12 10:25:28 Test Error = 0.60357022566521 
2016-12-12 10:25:28 Test Loss = 0.012599036078678 
2016-12-12 10:25:28 -------------------LR------------------- 
2016-12-12 10:25:28 0.0009765625 
2016-12-12 10:25:28 Epoch 211 
2016-12-12 10:31:17 Training Error = 0.57210618290755 
2016-12-12 10:31:17 Training Loss = 0.01301932434731 
2016-12-12 10:31:24 Valid Error = 0.60988393859978 
2016-12-12 10:31:24 Valid Loss = 0.012764148968211 
2016-12-12 10:31:32 Test Error = 0.58504546985517 
2016-12-12 10:31:32 Test Loss = 0.012637712453175 
2016-12-12 10:31:32 -------------------LR------------------- 
2016-12-12 10:31:32 0.0009765625 
2016-12-12 10:31:32 Epoch 212 
2016-12-12 10:37:25 Training Error = 0.57493550803029 
2016-12-12 10:37:25 Training Loss = 0.01303396651887 
2016-12-12 10:37:32 Valid Error = 0.63421939348559 
2016-12-12 10:37:32 Valid Loss = 0.012739027104195 
2016-12-12 10:37:39 Test Error = 0.61199056921522 
2016-12-12 10:37:39 Test Loss = 0.012578888702552 
2016-12-12 10:37:39 -------------------LR------------------- 
2016-12-12 10:37:39 0.0009765625 
2016-12-12 10:37:39 Epoch 213 
2016-12-12 10:43:23 Training Error = 0.57506033119747 
2016-12-12 10:43:23 Training Loss = 0.013024902413815 
2016-12-12 10:43:30 Valid Error = 0.61886933732684 
2016-12-12 10:43:30 Valid Loss = 0.012868751471069 
2016-12-12 10:43:37 Test Error = 0.60289659818121 
2016-12-12 10:43:37 Test Loss = 0.012767048104087 
2016-12-12 10:43:37 -------------------LR------------------- 
2016-12-12 10:43:37 0.0009765625 
2016-12-12 10:43:37 Epoch 214 
2016-12-12 10:49:31 Training Error = 0.57268869102105 
2016-12-12 10:49:31 Training Loss = 0.013010868832753 
2016-12-12 10:49:38 Valid Error = 0.63871209284912 
2016-12-12 10:49:38 Valid Loss = 0.012727976015375 
2016-12-12 10:49:46 Test Error = 0.61670596160323 
2016-12-12 10:49:46 Test Loss = 0.012594203115057 
2016-12-12 10:49:46 -------------------LR------------------- 
2016-12-12 10:49:46 0.0009765625 
2016-12-12 10:49:46 Epoch 215 
2016-12-12 10:55:32 Training Error = 0.57198135974037 
2016-12-12 10:55:32 Training Loss = 0.013020237632967 
2016-12-12 10:55:39 Valid Error = 0.59415949082741 
2016-12-12 10:55:39 Valid Loss = 0.012719927599138 
2016-12-12 10:55:47 Test Error = 0.57864600875716 
2016-12-12 10:55:47 Test Loss = 0.012580854757259 
2016-12-12 10:55:47 -------------------LR------------------- 
2016-12-12 10:55:47 0.0009765625 
2016-12-12 10:55:47 Epoch 216 
2016-12-12 11:00:47 Training Error = 0.56981775817592 
2016-12-12 11:00:47 Training Loss = 0.013014907172134 
2016-12-12 11:00:54 Valid Error = 0.63833770123549 
2016-12-12 11:00:54 Valid Loss = 0.012737156422774 
2016-12-12 11:01:02 Test Error = 0.62579993263725 
2016-12-12 11:01:02 Test Loss = 0.01261870987852 
2016-12-12 11:01:02 -------------------LR------------------- 
2016-12-12 11:01:02 0.0009765625 
2016-12-12 11:01:02 Epoch 217 
2016-12-12 11:06:03 Training Error = 0.57293833735541 
2016-12-12 11:06:03 Training Loss = 0.013022464253267 
2016-12-12 11:06:10 Valid Error = 0.63496817671284 
2016-12-12 11:06:10 Valid Loss = 0.012840455827448 
2016-12-12 11:06:18 Test Error = 0.62007409902324 
2016-12-12 11:06:18 Test Loss = 0.012725213299506 
2016-12-12 11:06:18 -------------------LR------------------- 
2016-12-12 11:06:18 0.0009765625 
2016-12-12 11:06:18 Epoch 218 
2016-12-12 11:11:21 Training Error = 0.57385370724807 
2016-12-12 11:11:21 Training Loss = 0.013029374486289 
2016-12-12 11:11:28 Valid Error = 0.62673156121303 
2016-12-12 11:11:28 Valid Loss = 0.01276273933263 
2016-12-12 11:11:36 Test Error = 0.60996968676322 
2016-12-12 11:11:36 Test Loss = 0.012622258133425 
2016-12-12 11:11:36 -------------------LR------------------- 
2016-12-12 11:11:36 0.0009765625 
2016-12-12 11:11:36 Epoch 219 
2016-12-12 11:16:36 Training Error = 0.57081634351336 
2016-12-12 11:16:36 Training Loss = 0.013006968209224 
2016-12-12 11:16:43 Valid Error = 0.60651441407712 
2016-12-12 11:16:43 Valid Loss = 0.012765501793887 
2016-12-12 11:16:51 Test Error = 0.59616032334119 
2016-12-12 11:16:51 Test Loss = 0.012643363720286 
2016-12-12 11:16:51 -------------------LR------------------- 
2016-12-12 11:16:51 0.0009765625 
2016-12-12 11:16:51 Epoch 220 
2016-12-12 11:21:51 Training Error = 0.57468586169593 
2016-12-12 11:21:51 Training Loss = 0.01301529097725 
2016-12-12 11:21:58 Valid Error = 0.61250467989517 
2016-12-12 11:21:58 Valid Loss = 0.012591163450457 
2016-12-12 11:22:06 Test Error = 0.59380262714719 
2016-12-12 11:22:06 Test Loss = 0.012436199017152 
2016-12-12 11:22:06 -------------------LR------------------- 
2016-12-12 11:22:06 0.0009765625 
2016-12-12 11:22:06 Epoch 221 
2016-12-12 11:27:08 Training Error = 0.57368727635849 
2016-12-12 11:27:08 Training Loss = 0.013019113005701 
2016-12-12 11:27:15 Valid Error = 0.62485960314489 
2016-12-12 11:27:15 Valid Loss = 0.012791964560519 
2016-12-12 11:27:23 Test Error = 0.6002020882452 
2016-12-12 11:27:23 Test Loss = 0.012671645057465 
2016-12-12 11:27:23 -------------------LR------------------- 
2016-12-12 11:27:23 0.0009765625 
2016-12-12 11:27:23 Epoch 222 
2016-12-12 11:32:21 Training Error = 0.57456103852875 
2016-12-12 11:32:21 Training Loss = 0.013024003296859 
2016-12-12 11:32:28 Valid Error = 0.61587420441782 
2016-12-12 11:32:28 Valid Loss = 0.012675586754113 
2016-12-12 11:32:35 Test Error = 0.59043448972718 
2016-12-12 11:32:35 Test Loss = 0.01251054639502 
2016-12-12 11:32:35 -------------------LR------------------- 
2016-12-12 11:32:35 0.0009765625 
2016-12-12 11:32:35 Epoch 223 
2016-12-12 11:37:36 Training Error = 0.57347923774653 
2016-12-12 11:37:36 Training Loss = 0.013025975317167 
2016-12-12 11:37:43 Valid Error = 0.6169973792587 
2016-12-12 11:37:43 Valid Loss = 0.012919090678312 
2016-12-12 11:37:51 Test Error = 0.59649713708319 
2016-12-12 11:37:51 Test Loss = 0.012793778151734 
2016-12-12 11:37:51 -------------------LR------------------- 
2016-12-12 11:37:51 0.0009765625 
2016-12-12 11:37:51 Epoch 224 
2016-12-12 11:42:51 Training Error = 0.57352084546892 
2016-12-12 11:42:51 Training Loss = 0.013027069341414 
2016-12-12 11:42:58 Valid Error = 0.60801198053164 
2016-12-12 11:42:58 Valid Loss = 0.012679153551378 
2016-12-12 11:43:06 Test Error = 0.59144493095318 
2016-12-12 11:43:06 Test Loss = 0.012552449659651 
2016-12-12 11:43:06 -------------------LR------------------- 
2016-12-12 11:43:06 0.0009765625 
2016-12-12 11:43:06 Epoch 225 
2016-12-12 11:48:05 Training Error = 0.57497711575268 
2016-12-12 11:48:05 Training Loss = 0.013033211009775 
2016-12-12 11:48:12 Valid Error = 0.62373642830401 
2016-12-12 11:48:12 Valid Loss = 0.012850599779921 
2016-12-12 11:48:19 Test Error = 0.59750757830919 
2016-12-12 11:48:19 Test Loss = 0.012725306550314 
2016-12-12 11:48:19 -------------------LR------------------- 
2016-12-12 11:48:19 0.0009765625 
2016-12-12 11:48:19 Epoch 226 
2016-12-12 11:53:20 Training Error = 0.57576766247816 
2016-12-12 11:53:20 Training Loss = 0.013027460845884 
2016-12-12 11:53:27 Valid Error = 0.63272182703107 
2016-12-12 11:53:27 Valid Loss = 0.012661112449658 
2016-12-12 11:53:35 Test Error = 0.61367463792523 
2016-12-12 11:53:35 Test Loss = 0.012500796339141 
2016-12-12 11:53:35 -------------------LR------------------- 
2016-12-12 11:53:35 0.0009765625 
2016-12-12 11:53:35 Epoch 227 
2016-12-12 11:58:33 Training Error = 0.57460264625114 
2016-12-12 11:58:33 Training Loss = 0.013025105821741 
2016-12-12 11:58:40 Valid Error = 0.6128790715088 
2016-12-12 11:58:40 Valid Loss = 0.012833060703315 
2016-12-12 11:58:48 Test Error = 0.59178174469518 
2016-12-12 11:58:48 Test Loss = 0.01272556068761 
2016-12-12 11:58:48 -------------------LR------------------- 
2016-12-12 11:58:48 0.0009765625 
2016-12-12 11:58:48 Epoch 228 
2016-12-12 12:03:49 Training Error = 0.57343763002413 
2016-12-12 12:03:49 Training Loss = 0.013022524970462 
2016-12-12 12:03:56 Valid Error = 0.60726319730438 
2016-12-12 12:03:56 Valid Loss = 0.0128178488354 
2016-12-12 12:04:04 Test Error = 0.59178174469518 
2016-12-12 12:04:04 Test Loss = 0.012700105525476 
2016-12-12 12:04:04 -------------------LR------------------- 
2016-12-12 12:04:04 0.0009765625 
2016-12-12 12:04:04 Epoch 229 
2016-12-12 12:09:24 Training Error = 0.5736456686361 
2016-12-12 12:09:24 Training Loss = 0.013023929581144 
2016-12-12 12:09:31 Valid Error = 0.63421939348559 
2016-12-12 12:09:31 Valid Loss = 0.012766328221636 
2016-12-12 12:09:39 Test Error = 0.61737958908723 
2016-12-12 12:09:39 Test Loss = 0.012620256171706 
2016-12-12 12:09:39 -------------------LR------------------- 
2016-12-12 12:09:39 0.0009765625 
2016-12-12 12:09:39 Epoch 230 
2016-12-12 12:15:31 Training Error = 0.57360406091371 
2016-12-12 12:15:31 Training Loss = 0.013024464171282 
2016-12-12 12:15:38 Valid Error = 0.60950954698615 
2016-12-12 12:15:38 Valid Loss = 0.012688384931008 
2016-12-12 12:15:46 Test Error = 0.58672953856517 
2016-12-12 12:15:46 Test Loss = 0.012527768781596 
2016-12-12 12:15:46 -------------------LR------------------- 
2016-12-12 12:15:46 0.0009765625 
2016-12-12 12:15:46 Epoch 231 
2016-12-12 12:20:45 Training Error = 0.57414496130482 
2016-12-12 12:20:45 Training Loss = 0.013027877476193 
2016-12-12 12:20:52 Valid Error = 0.63084986896294 
2016-12-12 12:20:52 Valid Loss = 0.012735200768056 
2016-12-12 12:21:00 Test Error = 0.60929605927922 
2016-12-12 12:21:00 Test Loss = 0.012590290555767 
2016-12-12 12:21:00 -------------------LR------------------- 
2016-12-12 12:21:00 0.0009765625 
2016-12-12 12:21:00 Epoch 232 
2016-12-12 12:25:59 Training Error = 0.57335441457935 
2016-12-12 12:25:59 Training Loss = 0.01302582409874 
2016-12-12 12:26:07 Valid Error = 0.63796330962186 
2016-12-12 12:26:07 Valid Loss = 0.012852470371823 
2016-12-12 12:26:14 Test Error = 0.61468507915123 
2016-12-12 12:26:14 Test Loss = 0.012754266412645 
2016-12-12 12:26:14 -------------------LR------------------- 
2016-12-12 12:26:14 0.0009765625 
2016-12-12 12:26:14 Epoch 233 
2016-12-12 12:31:13 Training Error = 0.57081634351336 
2016-12-12 12:31:13 Training Loss = 0.013008796929283 
2016-12-12 12:31:20 Valid Error = 0.64470235866717 
2016-12-12 12:31:20 Valid Loss = 0.012760700313587 
2016-12-12 12:31:28 Test Error = 0.62310542270125 
2016-12-12 12:31:28 Test Loss = 0.012634980402641 
2016-12-12 12:31:28 -------------------LR------------------- 
2016-12-12 12:31:28 0.0009765625 
2016-12-12 12:31:28 Epoch 234 
2016-12-12 12:36:27 Training Error = 0.57231422151951 
2016-12-12 12:36:27 Training Loss = 0.013013385174573 
2016-12-12 12:36:34 Valid Error = 0.63084986896294 
2016-12-12 12:36:34 Valid Loss = 0.012645094254059 
2016-12-12 12:36:42 Test Error = 0.61468507915123 
2016-12-12 12:36:42 Test Loss = 0.012495878927798 
2016-12-12 12:36:42 -------------------LR------------------- 
2016-12-12 12:36:42 0.0009765625 
2016-12-12 12:36:42 Epoch 235 
2016-12-12 12:41:43 Training Error = 0.57318798368977 
2016-12-12 12:41:43 Training Loss = 0.013024951619059 
2016-12-12 12:41:50 Valid Error = 0.61924372894047 
2016-12-12 12:41:50 Valid Loss = 0.012745295860752 
2016-12-12 12:41:58 Test Error = 0.60761199056922 
2016-12-12 12:41:58 Test Loss = 0.012617876715694 
2016-12-12 12:41:58 -------------------LR------------------- 
2016-12-12 12:41:58 0.0009765625 
2016-12-12 12:41:58 Epoch 236 
2016-12-12 12:46:57 Training Error = 0.57447782308396 
2016-12-12 12:46:57 Training Loss = 0.013019384344112 
2016-12-12 12:47:04 Valid Error = 0.62261325346312 
2016-12-12 12:47:04 Valid Loss = 0.01277746305938 
2016-12-12 12:47:11 Test Error = 0.6018861569552 
2016-12-12 12:47:11 Test Loss = 0.012640866689797 
2016-12-12 12:47:11 -------------------LR------------------- 
2016-12-12 12:47:11 0.0009765625 
2016-12-12 12:47:11 Epoch 237 
2016-12-12 12:52:25 Training Error = 0.57514354664226 
2016-12-12 12:52:25 Training Loss = 0.013039986081011 
2016-12-12 12:52:32 Valid Error = 0.63047547734931 
2016-12-12 12:52:32 Valid Loss = 0.012713467554973 
2016-12-12 12:52:40 Test Error = 0.60895924553722 
2016-12-12 12:52:40 Test Loss = 0.012557324744882 
2016-12-12 12:52:40 -------------------LR------------------- 
2016-12-12 12:52:40 0.0009765625 
2016-12-12 12:52:40 Epoch 238 
2016-12-12 12:58:25 Training Error = 0.57094116668054 
2016-12-12 12:58:25 Training Loss = 0.01301048802886 
2016-12-12 12:58:32 Valid Error = 0.62036690378136 
2016-12-12 12:58:32 Valid Loss = 0.012698155648068 
2016-12-12 12:58:40 Test Error = 0.59413944088919 
2016-12-12 12:58:40 Test Loss = 0.01256331261009 
2016-12-12 12:58:40 -------------------LR------------------- 
2016-12-12 12:58:40 0.0009765625 
2016-12-12 12:58:40 Epoch 239 
2016-12-12 13:04:27 Training Error = 0.57418656902721 
2016-12-12 13:04:27 Training Loss = 0.013030293261997 
2016-12-12 13:04:34 Valid Error = 0.61325346312243 
2016-12-12 13:04:34 Valid Loss = 0.012674920561345 
2016-12-12 13:04:42 Test Error = 0.59312899966319 
2016-12-12 13:04:42 Test Loss = 0.012514687570374 
2016-12-12 13:04:42 -------------------LR------------------- 
2016-12-12 13:04:42 0.0009765625 
2016-12-12 13:04:42 Epoch 240 
2016-12-12 13:10:30 Training Error = 0.57148206707165 
2016-12-12 13:10:30 Training Loss = 0.013014350315056 
2016-12-12 13:10:37 Valid Error = 0.62336203669038 
2016-12-12 13:10:37 Valid Loss = 0.012896801531759 
2016-12-12 13:10:45 Test Error = 0.59683395082519 
2016-12-12 13:10:45 Test Loss = 0.012779911383421 
2016-12-12 13:10:45 -------------------LR------------------- 
2016-12-12 13:10:45 0.0009765625 
2016-12-12 13:10:46 Epoch 241 
2016-12-12 13:16:30 Training Error = 0.57293833735541 
2016-12-12 13:16:30 Training Loss = 0.013031278056406 
2016-12-12 13:16:37 Valid Error = 0.62560838637215 
2016-12-12 13:16:37 Valid Loss = 0.012721795713404 
2016-12-12 13:16:45 Test Error = 0.60626473560121 
2016-12-12 13:16:45 Test Loss = 0.012575869133336 
2016-12-12 13:16:45 -------------------LR------------------- 
2016-12-12 13:16:45 0.0009765625 
2016-12-12 13:16:45 Epoch 242 
2016-12-12 13:22:33 Training Error = 0.57206457518515 
2016-12-12 13:22:33 Training Loss = 0.013013247903682 
2016-12-12 13:22:40 Valid Error = 0.6263571695994 
2016-12-12 13:22:40 Valid Loss = 0.012688381985411 
2016-12-12 13:22:48 Test Error = 0.61670596160323 
2016-12-12 13:22:48 Test Loss = 0.012561141423499 
2016-12-12 13:22:48 -------------------LR------------------- 
2016-12-12 13:22:48 0.0009765625 
2016-12-12 13:22:48 Epoch 243 
2016-12-12 13:28:32 Training Error = 0.56948489639677 
2016-12-12 13:28:32 Training Loss = 0.013000104511825 
2016-12-12 13:28:39 Valid Error = 0.61250467989517 
2016-12-12 13:28:39 Valid Loss = 0.012792968026744 
2016-12-12 13:28:47 Test Error = 0.59144493095318 
2016-12-12 13:28:47 Test Loss = 0.012656336830913 
2016-12-12 13:28:47 -------------------LR------------------- 
2016-12-12 13:28:47 0.0009765625 
2016-12-12 13:28:47 Epoch 244 
2016-12-12 13:34:31 Training Error = 0.57456103852875 
2016-12-12 13:34:31 Training Loss = 0.013028491104614 
2016-12-12 13:34:38 Valid Error = 0.63646574316735 
2016-12-12 13:34:38 Valid Loss = 0.012776756052641 
2016-12-12 13:34:46 Test Error = 0.62344223644325 
2016-12-12 13:34:46 Test Loss = 0.012644201641536 
2016-12-12 13:34:46 -------------------LR------------------- 
2016-12-12 13:34:46 0.0009765625 
2016-12-12 13:34:46 Epoch 245 
2016-12-12 13:40:36 Training Error = 0.57389531497046 
2016-12-12 13:40:36 Training Loss = 0.01301421607786 
2016-12-12 13:40:43 Valid Error = 0.62373642830401 
2016-12-12 13:40:43 Valid Loss = 0.012763246969962 
2016-12-12 13:40:51 Test Error = 0.60559110811721 
2016-12-12 13:40:51 Test Loss = 0.012650845229651 
2016-12-12 13:40:51 -------------------LR------------------- 
2016-12-12 13:40:51 0.0009765625 
2016-12-12 13:40:51 Epoch 246 
2016-12-12 13:47:18 Training Error = 0.57381209952567 
2016-12-12 13:47:18 Training Loss = 0.013030537356248 
2016-12-12 13:47:25 Valid Error = 0.61213028828154 
2016-12-12 13:47:25 Valid Loss = 0.012705853269237 
2016-12-12 13:47:33 Test Error = 0.59009767598518 
2016-12-12 13:47:33 Test Loss = 0.012550146051183 
2016-12-12 13:47:33 -------------------LR------------------- 
2016-12-12 13:47:33 0.0009765625 
2016-12-12 13:47:33 Epoch 247 
2016-12-12 13:54:25 Training Error = 0.57447782308396 
2016-12-12 13:54:25 Training Loss = 0.013020556436269 
2016-12-12 13:54:32 Valid Error = 0.63534256832647 
2016-12-12 13:54:32 Valid Loss = 0.012897624193084 
2016-12-12 13:54:40 Test Error = 0.61266419669923 
2016-12-12 13:54:40 Test Loss = 0.012786206965154 
2016-12-12 13:54:40 -------------------LR------------------- 
2016-12-12 13:54:40 0.0009765625 
2016-12-12 13:54:40 Epoch 248 
2016-12-12 14:01:39 Training Error = 0.57468586169593 
2016-12-12 14:01:39 Training Loss = 0.013024309785759 
2016-12-12 14:01:46 Valid Error = 0.6169973792587 
2016-12-12 14:01:46 Valid Loss = 0.012754376843951 
2016-12-12 14:01:54 Test Error = 0.60458066689121 
2016-12-12 14:01:54 Test Loss = 0.012604315832152 
2016-12-12 14:01:54 -------------------LR------------------- 
2016-12-12 14:01:54 0.0009765625 
2016-12-12 14:01:54 Epoch 249 
2016-12-12 14:08:44 Training Error = 0.57281351418823 
2016-12-12 14:08:44 Training Loss = 0.013020883964151 
2016-12-12 14:08:51 Valid Error = 0.61662298764508 
2016-12-12 14:08:51 Valid Loss = 0.012776341001498 
2016-12-12 14:08:59 Test Error = 0.5978443920512 
2016-12-12 14:08:59 Test Loss = 0.012622113704085 
2016-12-12 14:08:59 -------------------LR------------------- 
2016-12-12 14:08:59 0.0009765625 
2016-12-12 14:08:59 Epoch 250 
2016-12-12 14:15:46 Training Error = 0.57347923774653 
2016-12-12 14:15:46 Training Loss = 0.013028006752698 
2016-12-12 14:15:53 Valid Error = 0.64170722575814 
2016-12-12 14:15:53 Valid Loss = 0.012633570303855 
2016-12-12 14:16:01 Test Error = 0.62209498147524 
2016-12-12 14:16:01 Test Loss = 0.012481414323854 
2016-12-12 14:16:01 -------------------LR------------------- 
2016-12-12 14:16:01 0.00048828125 
2016-12-12 14:16:01 Epoch 251 
2016-12-12 14:22:58 Training Error = 0.57260547557627 
2016-12-12 14:22:58 Training Loss = 0.013026559891304 
2016-12-12 14:23:05 Valid Error = 0.61849494571322 
2016-12-12 14:23:05 Valid Loss = 0.012762495533446 
2016-12-12 14:23:13 Test Error = 0.59312899966319 
2016-12-12 14:23:13 Test Loss = 0.012620199067423 
2016-12-12 14:23:13 -------------------LR------------------- 
2016-12-12 14:23:13 0.00048828125 
2016-12-12 14:23:13 Epoch 252 
2016-12-12 14:30:02 Training Error = 0.56944328867438 
2016-12-12 14:30:02 Training Loss = 0.01301554647872 
2016-12-12 14:30:09 Valid Error = 0.6357169599401 
2016-12-12 14:30:09 Valid Loss = 0.012845731644536 
2016-12-12 14:30:17 Test Error = 0.62478949141125 
2016-12-12 14:30:17 Test Loss = 0.012745440336282 
2016-12-12 14:30:17 -------------------LR------------------- 
2016-12-12 14:30:17 0.00048828125 
2016-12-12 14:30:17 Epoch 253 
2016-12-12 14:37:08 Training Error = 0.57443621536157 
2016-12-12 14:37:08 Training Loss = 0.013024937073413 
2016-12-12 14:37:16 Valid Error = 0.6263571695994 
2016-12-12 14:37:16 Valid Loss = 0.012596104407781 
2016-12-12 14:37:23 Test Error = 0.61300101044123 
2016-12-12 14:37:23 Test Loss = 0.012463189109544 
2016-12-12 14:37:23 -------------------LR------------------- 
2016-12-12 14:37:23 0.00048828125 
2016-12-12 14:37:24 Epoch 254 
2016-12-12 14:44:11 Training Error = 0.57468586169593 
2016-12-12 14:44:11 Training Loss = 0.013035951418778 
2016-12-12 14:44:18 Valid Error = 0.61175589666791 
2016-12-12 14:44:18 Valid Loss = 0.012740902230299 
2016-12-12 14:44:26 Test Error = 0.59178174469518 
2016-12-12 14:44:26 Test Loss = 0.01258790141819 
2016-12-12 14:44:26 -------------------LR------------------- 
2016-12-12 14:44:26 0.00048828125 
2016-12-12 14:44:26 Epoch 255 
2016-12-12 14:51:16 Training Error = 0.57443621536157 
2016-12-12 14:51:16 Training Loss = 0.013009510458126 
2016-12-12 14:51:23 Valid Error = 0.64058405091726 
2016-12-12 14:51:23 Valid Loss = 0.012775016293271 
2016-12-12 14:51:31 Test Error = 0.61872684405524 
2016-12-12 14:51:31 Test Loss = 0.012632384384976 
2016-12-12 14:51:31 -------------------LR------------------- 
2016-12-12 14:51:31 0.00048828125 
2016-12-12 14:51:31 Epoch 256 
2016-12-12 14:58:18 Training Error = 0.57410335358242 
2016-12-12 14:58:18 Training Loss = 0.013013282250403 
2016-12-12 14:58:25 Valid Error = 0.6357169599401 
2016-12-12 14:58:25 Valid Loss = 0.012767879306023 
2016-12-12 14:58:32 Test Error = 0.61401145166723 
2016-12-12 14:58:32 Test Loss = 0.012634411127109 
2016-12-12 14:58:32 -------------------LR------------------- 
2016-12-12 14:58:32 0.00048828125 
2016-12-12 14:58:32 Epoch 257 
2016-12-12 15:05:27 Training Error = 0.57414496130482 
2016-12-12 15:05:27 Training Loss = 0.013026923839615 
2016-12-12 15:05:34 Valid Error = 0.62972669412205 
2016-12-12 15:05:34 Valid Loss = 0.012777972191535 
2016-12-12 15:05:42 Test Error = 0.61199056921522 
2016-12-12 15:05:42 Test Loss = 0.012659936043139 
2016-12-12 15:05:42 -------------------LR------------------- 
2016-12-12 15:05:42 0.00048828125 
2016-12-12 15:05:42 Epoch 258 
2016-12-12 15:12:22 Training Error = 0.57293833735541 
2016-12-12 15:12:22 Training Loss = 0.013014255489126 
2016-12-12 15:12:29 Valid Error = 0.63534256832647 
2016-12-12 15:12:29 Valid Loss = 0.012776095230531 
2016-12-12 15:12:37 Test Error = 0.62175816773324 
2016-12-12 15:12:37 Test Loss = 0.012630257996809 
2016-12-12 15:12:37 -------------------LR------------------- 
2016-12-12 15:12:37 0.00048828125 
2016-12-12 15:12:37 Epoch 259 
2016-12-12 15:19:26 Training Error = 0.57618373970209 
2016-12-12 15:19:26 Training Loss = 0.013025720572073 
2016-12-12 15:19:33 Valid Error = 0.61886933732684 
2016-12-12 15:19:33 Valid Loss = 0.012864932968067 
2016-12-12 15:19:41 Test Error = 0.59750757830919 
2016-12-12 15:19:41 Test Loss = 0.012736868775184 
2016-12-12 15:19:41 -------------------LR------------------- 
2016-12-12 15:19:41 0.00048828125 
2016-12-12 15:19:41 Epoch 260 
2016-12-12 15:26:27 Training Error = 0.57127402845968 
2016-12-12 15:26:27 Training Loss = 0.013020112408799 
2016-12-12 15:26:34 Valid Error = 0.64732309996256 
2016-12-12 15:26:34 Valid Loss = 0.012750526305511 
2016-12-12 15:26:42 Test Error = 0.62175816773324 
2016-12-12 15:26:42 Test Loss = 0.012583883026117 
2016-12-12 15:26:42 -------------------LR------------------- 
2016-12-12 15:26:42 0.00048828125 
2016-12-12 15:26:42 Epoch 261 
2016-12-12 15:33:27 Training Error = 0.57501872347508 
2016-12-12 15:33:27 Training Loss = 0.013028223561247 
2016-12-12 15:33:35 Valid Error = 0.62523399475852 
2016-12-12 15:33:35 Valid Loss = 0.012710372876891 
2016-12-12 15:33:42 Test Error = 0.61468507915123 
2016-12-12 15:33:42 Test Loss = 0.01257747151228 
2016-12-12 15:33:42 -------------------LR------------------- 
2016-12-12 15:33:42 0.00048828125 
2016-12-12 15:33:42 Epoch 262 
2016-12-12 15:40:36 Training Error = 0.57243904468669 
2016-12-12 15:40:36 Training Loss = 0.013033362593445 
2016-12-12 15:40:43 Valid Error = 0.60913515537252 
2016-12-12 15:40:43 Valid Loss = 0.0126972669114 
2016-12-12 15:40:50 Test Error = 0.59279218592119 
2016-12-12 15:40:50 Test Loss = 0.012562728687679 
2016-12-12 15:40:50 -------------------LR------------------- 
2016-12-12 15:40:50 0.00048828125 
2016-12-12 15:40:50 Epoch 263 
2016-12-12 15:47:34 Training Error = 0.57618373970209 
2016-12-12 15:47:34 Training Loss = 0.013030435069095 
2016-12-12 15:47:42 Valid Error = 0.61100711344066 
2016-12-12 15:47:42 Valid Loss = 0.012832634975745 
2016-12-12 15:47:49 Test Error = 0.58605591108117 
2016-12-12 15:47:49 Test Loss = 0.012697122628757 
2016-12-12 15:47:49 -------------------LR------------------- 
2016-12-12 15:47:49 0.00048828125 
2016-12-12 15:47:49 Epoch 264 
2016-12-12 15:54:40 Training Error = 0.57297994507781 
2016-12-12 15:54:40 Training Loss = 0.013030287471501 
2016-12-12 15:54:47 Valid Error = 0.63197304380382 
2016-12-12 15:54:47 Valid Loss = 0.01278700131205 
2016-12-12 15:54:55 Test Error = 0.60357022566521 
2016-12-12 15:54:55 Test Loss = 0.012647184135618 
2016-12-12 15:54:55 -------------------LR------------------- 
2016-12-12 15:54:55 0.00048828125 
2016-12-12 15:54:55 Epoch 265 
2016-12-12 16:01:45 Training Error = 0.57264708329866 
2016-12-12 16:01:45 Training Loss = 0.013001624570981 
2016-12-12 16:01:52 Valid Error = 0.63833770123549 
2016-12-12 16:01:52 Valid Loss = 0.012767155785184 
2016-12-12 16:02:00 Test Error = 0.62209498147524 
2016-12-12 16:02:00 Test Loss = 0.012615419656772 
2016-12-12 16:02:00 -------------------LR------------------- 
2016-12-12 16:02:00 0.00048828125 
2016-12-12 16:02:00 Epoch 266 
2016-12-12 16:08:52 Training Error = 0.57389531497046 
2016-12-12 16:08:52 Training Loss = 0.013034237302614 
2016-12-12 16:08:59 Valid Error = 0.61737177087233 
2016-12-12 16:08:59 Valid Loss = 0.012729076750716 
2016-12-12 16:09:07 Test Error = 0.59616032334119 
2016-12-12 16:09:07 Test Loss = 0.012575823151672 
2016-12-12 16:09:07 -------------------LR------------------- 
2016-12-12 16:09:07 0.00048828125 
2016-12-12 16:09:07 Epoch 267 
2016-12-12 16:15:57 Training Error = 0.57472746941832 
2016-12-12 16:15:57 Training Loss = 0.013011103602415 
2016-12-12 16:16:04 Valid Error = 0.6169973792587 
2016-12-12 16:16:04 Valid Loss = 0.01276218805272 
2016-12-12 16:16:12 Test Error = 0.5988548332772 
2016-12-12 16:16:12 Test Loss = 0.012650689991206 
2016-12-12 16:16:12 -------------------LR------------------- 
2016-12-12 16:16:12 0.00048828125 
2016-12-12 16:16:12 Epoch 268 
2016-12-12 16:23:01 Training Error = 0.574269784472 
2016-12-12 16:23:01 Training Loss = 0.013018782205993 
2016-12-12 16:23:08 Valid Error = 0.62186447023587 
2016-12-12 16:23:08 Valid Loss = 0.012732589148929 
2016-12-12 16:23:16 Test Error = 0.60996968676322 
2016-12-12 16:23:16 Test Loss = 0.012605942835547 
2016-12-12 16:23:16 -------------------LR------------------- 
2016-12-12 16:23:16 0.00048828125 
2016-12-12 16:23:16 Epoch 269 
2016-12-12 16:29:59 Training Error = 0.57377049180328 
2016-12-12 16:29:59 Training Loss = 0.013011228626188 
2016-12-12 16:30:07 Valid Error = 0.60950954698615 
2016-12-12 16:30:07 Valid Loss = 0.012818364823563 
2016-12-12 16:30:14 Test Error = 0.59245537217918 
2016-12-12 16:30:14 Test Loss = 0.012713039854143 
2016-12-12 16:30:14 -------------------LR------------------- 
2016-12-12 16:30:14 0.00048828125 
2016-12-12 16:30:14 Epoch 270 
2016-12-12 16:37:02 Training Error = 0.57535158525422 
2016-12-12 16:37:02 Training Loss = 0.013025458394865 
2016-12-12 16:37:10 Valid Error = 0.59865219019094 
2016-12-12 16:37:10 Valid Loss = 0.012724400987585 
2016-12-12 16:37:17 Test Error = 0.57797238127316 
2016-12-12 16:37:17 Test Loss = 0.01259954771361 
2016-12-12 16:37:17 -------------------LR------------------- 
2016-12-12 16:37:17 0.00048828125 
2016-12-12 16:37:17 Epoch 271 
2016-12-12 16:44:04 Training Error = 0.57443621536157 
2016-12-12 16:44:04 Training Loss = 0.01301368633359 
2016-12-12 16:44:11 Valid Error = 0.59078996630475 
2016-12-12 16:44:11 Valid Loss = 0.012565244910217 
2016-12-12 16:44:18 Test Error = 0.56887841023914 
2016-12-12 16:44:18 Test Loss = 0.012397597297411 
2016-12-12 16:44:18 -------------------LR------------------- 
2016-12-12 16:44:18 0.00048828125 
2016-12-12 16:44:19 Epoch 272 
2016-12-12 16:51:04 Training Error = 0.57169010568361 
2016-12-12 16:51:04 Training Loss = 0.013017645437804 
2016-12-12 16:51:11 Valid Error = 0.64208161737177 
2016-12-12 16:51:11 Valid Loss = 0.012746545355608 
2016-12-12 16:51:19 Test Error = 0.62142135399124 
2016-12-12 16:51:19 Test Loss = 0.012582792104658 
2016-12-12 16:51:19 -------------------LR------------------- 
2016-12-12 16:51:19 0.00048828125 
2016-12-12 16:51:19 Epoch 273 
2016-12-12 16:58:11 Training Error = 0.5723974369643 
2016-12-12 16:58:11 Training Loss = 0.013014921751422 
2016-12-12 16:58:18 Valid Error = 0.63833770123549 
2016-12-12 16:58:18 Valid Loss = 0.012818877504739 
2016-12-12 16:58:25 Test Error = 0.62041091276524 
2016-12-12 16:58:25 Test Loss = 0.01268874304783 
2016-12-12 16:58:25 -------------------LR------------------- 
2016-12-12 16:58:25 0.00048828125 
2016-12-12 16:58:26 Epoch 274 
2016-12-12 17:05:10 Training Error = 0.57164849796122 
2016-12-12 17:05:10 Training Loss = 0.013024522809796 
2016-12-12 17:05:17 Valid Error = 0.6035192811681 
2016-12-12 17:05:17 Valid Loss = 0.012795060910568 
2016-12-12 17:05:25 Test Error = 0.58672953856517 
2016-12-12 17:05:25 Test Loss = 0.012680201931899 
2016-12-12 17:05:25 -------------------LR------------------- 
2016-12-12 17:05:25 0.00048828125 
2016-12-12 17:05:25 Epoch 275 
2016-12-12 17:12:11 Training Error = 0.57293833735541 
2016-12-12 17:12:11 Training Loss = 0.013021545438358 
2016-12-12 17:12:18 Valid Error = 0.62560838637215 
2016-12-12 17:12:18 Valid Loss = 0.012762219963117 
2016-12-12 17:12:26 Test Error = 0.61131694173122 
2016-12-12 17:12:26 Test Loss = 0.012620467499887 
2016-12-12 17:12:26 -------------------LR------------------- 
2016-12-12 17:12:26 0.00048828125 
2016-12-12 17:12:26 Epoch 276 
2016-12-12 17:19:19 Training Error = 0.57601730881252 
2016-12-12 17:19:19 Training Loss = 0.013029791209188 
2016-12-12 17:19:26 Valid Error = 0.6196181205541 
2016-12-12 17:19:26 Valid Loss = 0.012758476247207 
2016-12-12 17:19:34 Test Error = 0.59548669585719 
2016-12-12 17:19:34 Test Loss = 0.012622372517846 
2016-12-12 17:19:34 -------------------LR------------------- 
2016-12-12 17:19:34 0.00048828125 
2016-12-12 17:19:34 Epoch 277 
2016-12-12 17:26:22 Training Error = 0.57277190646584 
2016-12-12 17:26:22 Training Loss = 0.013034865387747 
2016-12-12 17:26:30 Valid Error = 0.64020965930363 
2016-12-12 17:26:30 Valid Loss = 0.012888123048115 
2016-12-12 17:26:37 Test Error = 0.62276860895925 
2016-12-12 17:26:37 Test Loss = 0.012759213760688 
2016-12-12 17:26:37 -------------------LR------------------- 
2016-12-12 17:26:37 0.00048828125 
2016-12-12 17:26:37 Epoch 278 
2016-12-12 17:33:35 Training Error = 0.57418656902721 
2016-12-12 17:33:35 Training Loss = 0.013030642268848 
2016-12-12 17:33:42 Valid Error = 0.61549981280419 
2016-12-12 17:33:42 Valid Loss = 0.012730316675105 
2016-12-12 17:33:50 Test Error = 0.59043448972718 
2016-12-12 17:33:50 Test Loss = 0.012589812629264 
2016-12-12 17:33:50 -------------------LR------------------- 
2016-12-12 17:33:50 0.00048828125 
2016-12-12 17:33:50 Epoch 279 
2016-12-12 17:40:37 Training Error = 0.57031705084464 
2016-12-12 17:40:37 Training Loss = 0.013002179817011 
2016-12-12 17:40:44 Valid Error = 0.63496817671284 
2016-12-12 17:40:44 Valid Loss = 0.012834873439506 
2016-12-12 17:40:51 Test Error = 0.61535870663523 
2016-12-12 17:40:51 Test Loss = 0.012732152375471 
2016-12-12 17:40:51 -------------------LR------------------- 
2016-12-12 17:40:51 0.00048828125 
2016-12-12 17:40:51 Epoch 280 
2016-12-12 17:47:40 Training Error = 0.57040026628942 
2016-12-12 17:47:40 Training Loss = 0.013014530091757 
2016-12-12 17:47:47 Valid Error = 0.61587420441782 
2016-12-12 17:47:47 Valid Loss = 0.012723990056678 
2016-12-12 17:47:55 Test Error = 0.60357022566521 
2016-12-12 17:47:55 Test Loss = 0.012563486406392 
2016-12-12 17:47:55 -------------------LR------------------- 
2016-12-12 17:47:55 0.00048828125 
2016-12-12 17:47:55 Epoch 281 
2016-12-12 17:54:47 Training Error = 0.57339602230174 
2016-12-12 17:54:47 Training Loss = 0.013018066008698 
2016-12-12 17:54:54 Valid Error = 0.61475102957694 
2016-12-12 17:54:54 Valid Loss = 0.012704000735516 
2016-12-12 17:55:02 Test Error = 0.58908723475918 
2016-12-12 17:55:02 Test Loss = 0.012532422785467 
2016-12-12 17:55:02 -------------------LR------------------- 
2016-12-12 17:55:02 0.00048828125 
2016-12-12 17:55:02 Epoch 282 
2016-12-12 18:01:55 Training Error = 0.57451943080636 
2016-12-12 18:01:55 Training Loss = 0.01304445514963 
2016-12-12 18:02:02 Valid Error = 0.61999251216773 
2016-12-12 18:02:02 Valid Loss = 0.01283127173462 
2016-12-12 18:02:10 Test Error = 0.59616032334119 
2016-12-12 18:02:10 Test Loss = 0.012682694391753 
2016-12-12 18:02:10 -------------------LR------------------- 
2016-12-12 18:02:10 0.00048828125 
2016-12-12 18:02:10 Epoch 283 
2016-12-12 18:08:54 Training Error = 0.56902721145045 
2016-12-12 18:08:54 Training Loss = 0.013006891502673 
2016-12-12 18:09:01 Valid Error = 0.62111568700861 
2016-12-12 18:09:01 Valid Loss = 0.012724380579652 
2016-12-12 18:09:09 Test Error = 0.59717076456719 
2016-12-12 18:09:09 Test Loss = 0.012557741641004 
2016-12-12 18:09:09 -------------------LR------------------- 
2016-12-12 18:09:09 0.00048828125 
2016-12-12 18:09:09 Epoch 284 
2016-12-12 18:16:04 Training Error = 0.57164849796122 
2016-12-12 18:16:04 Training Loss = 0.013019523430393 
2016-12-12 18:16:11 Valid Error = 0.61812055409959 
2016-12-12 18:16:11 Valid Loss = 0.012702266995225 
2016-12-12 18:16:19 Test Error = 0.59211855843718 
2016-12-12 18:16:19 Test Loss = 0.01257593956678 
2016-12-12 18:16:19 -------------------LR------------------- 
2016-12-12 18:16:19 0.00048828125 
2016-12-12 18:16:19 Epoch 285 
2016-12-12 18:23:05 Training Error = 0.57048348173421 
2016-12-12 18:23:05 Training Loss = 0.013004082723782 
2016-12-12 18:23:12 Valid Error = 0.61549981280419 
2016-12-12 18:23:12 Valid Loss = 0.012705678440787 
2016-12-12 18:23:20 Test Error = 0.6005389019872 
2016-12-12 18:23:20 Test Loss = 0.012557212547108 
2016-12-12 18:23:20 -------------------LR------------------- 
2016-12-12 18:23:20 0.00048828125 
2016-12-12 18:23:20 Epoch 286 
2016-12-12 18:30:09 Training Error = 0.57322959141217 
2016-12-12 18:30:09 Training Loss = 0.013018607804081 
2016-12-12 18:30:16 Valid Error = 0.65256458255335 
2016-12-12 18:30:16 Valid Loss = 0.012800705309034 
2016-12-12 18:30:24 Test Error = 0.62950488379926 
2016-12-12 18:30:24 Test Loss = 0.012674324474884 
2016-12-12 18:30:24 -------------------LR------------------- 
2016-12-12 18:30:24 0.00048828125 
2016-12-12 18:30:24 Epoch 287 
2016-12-12 18:37:20 Training Error = 0.57310476824499 
2016-12-12 18:37:20 Training Loss = 0.013026943546052 
2016-12-12 18:37:28 Valid Error = 0.63609135155373 
2016-12-12 18:37:28 Valid Loss = 0.012824933137717 
2016-12-12 18:37:35 Test Error = 0.62243179521724 
2016-12-12 18:37:35 Test Loss = 0.01269740511449 
2016-12-12 18:37:35 -------------------LR------------------- 
2016-12-12 18:37:35 0.00048828125 
2016-12-12 18:37:35 Epoch 288 
2016-12-12 18:44:24 Training Error = 0.57347923774653 
2016-12-12 18:44:24 Training Loss = 0.013025825009141 
2016-12-12 18:44:31 Valid Error = 0.64170722575814 
2016-12-12 18:44:31 Valid Loss = 0.012753115613599 
2016-12-12 18:44:39 Test Error = 0.62175816773324 
2016-12-12 18:44:39 Test Loss = 0.012615782750066 
2016-12-12 18:44:39 -------------------LR------------------- 
2016-12-12 18:44:39 0.00048828125 
2016-12-12 18:44:39 Epoch 289 
2016-12-12 18:51:31 Training Error = 0.57402013813764 
2016-12-12 18:51:31 Training Loss = 0.01301759434535 
2016-12-12 18:51:38 Valid Error = 0.60913515537252 
2016-12-12 18:51:38 Valid Loss = 0.012719919053638 
2016-12-12 18:51:46 Test Error = 0.59312899966319 
2016-12-12 18:51:46 Test Loss = 0.012582195966304 
2016-12-12 18:51:46 -------------------LR------------------- 
2016-12-12 18:51:46 0.00048828125 
2016-12-12 18:51:46 Epoch 290 
2016-12-12 18:58:34 Training Error = 0.5730215528002 
2016-12-12 18:58:34 Training Loss = 0.013022084569676 
2016-12-12 18:58:41 Valid Error = 0.61400224634968 
2016-12-12 18:58:41 Valid Loss = 0.012804598293152 
2016-12-12 18:58:49 Test Error = 0.59380262714719 
2016-12-12 18:58:49 Test Loss = 0.012692419819997 
2016-12-12 18:58:49 -------------------LR------------------- 
2016-12-12 18:58:49 0.00048828125 
2016-12-12 18:58:49 Epoch 291 
2016-12-12 19:05:36 Training Error = 0.56890238828327 
2016-12-12 19:05:36 Training Loss = 0.013008612563863 
2016-12-12 19:05:44 Valid Error = 0.61886933732684 
2016-12-12 19:05:44 Valid Loss = 0.01275515202286 
2016-12-12 19:05:51 Test Error = 0.59616032334119 
2016-12-12 19:05:51 Test Loss = 0.012616903173759 
2016-12-12 19:05:51 -------------------LR------------------- 
2016-12-12 19:05:51 0.00048828125 
2016-12-12 19:05:51 Epoch 292 
2016-12-12 19:12:43 Training Error = 0.57268869102105 
2016-12-12 19:12:43 Training Loss = 0.013026607257755 
2016-12-12 19:12:50 Valid Error = 0.59490827405466 
2016-12-12 19:12:50 Valid Loss = 0.012604379832021 
2016-12-12 19:12:58 Test Error = 0.58538228359717 
2016-12-12 19:12:58 Test Loss = 0.012464448889843 
2016-12-12 19:12:58 -------------------LR------------------- 
2016-12-12 19:12:58 0.00048828125 
2016-12-12 19:12:58 Epoch 293 
2016-12-12 19:19:44 Training Error = 0.57339602230174 
2016-12-12 19:19:44 Training Loss = 0.013024679934713 
2016-12-12 19:19:51 Valid Error = 0.62822912766754 
2016-12-12 19:19:51 Valid Loss = 0.012675701853113 
2016-12-12 19:19:58 Test Error = 0.61232738295722 
2016-12-12 19:19:58 Test Loss = 0.012514374585365 
2016-12-12 19:19:58 -------------------LR------------------- 
2016-12-12 19:19:58 0.00048828125 
2016-12-12 19:19:58 Epoch 294 
2016-12-12 19:26:42 Training Error = 0.57223100607473 
2016-12-12 19:26:42 Training Loss = 0.013021740592118 
2016-12-12 19:26:49 Valid Error = 0.62223886184949 
2016-12-12 19:26:49 Valid Loss = 0.012863065127094 
2016-12-12 19:26:57 Test Error = 0.59717076456719 
2016-12-12 19:26:57 Test Loss = 0.012741672092544 
2016-12-12 19:26:57 -------------------LR------------------- 
2016-12-12 19:26:57 0.00048828125 
2016-12-12 19:26:57 Epoch 295 
2016-12-12 19:33:47 Training Error = 0.57227261379712 
2016-12-12 19:33:47 Training Loss = 0.013031337710784 
2016-12-12 19:33:54 Valid Error = 0.59752901535006 
2016-12-12 19:33:54 Valid Loss = 0.012631240743044 
2016-12-12 19:34:02 Test Error = 0.58369821488717 
2016-12-12 19:34:02 Test Loss = 0.012488588871835 
2016-12-12 19:34:02 -------------------LR------------------- 
2016-12-12 19:34:02 0.00048828125 
2016-12-12 19:34:02 Epoch 296 
2016-12-12 19:40:52 Training Error = 0.57468586169593 
2016-12-12 19:40:52 Training Loss = 0.013029112416737 
2016-12-12 19:40:59 Valid Error = 0.63721452639461 
2016-12-12 19:40:59 Valid Loss = 0.012868660136722 
2016-12-12 19:41:07 Test Error = 0.62074772650724 
2016-12-12 19:41:07 Test Loss = 0.012752327004322 
2016-12-12 19:41:07 -------------------LR------------------- 
2016-12-12 19:41:07 0.00048828125 
2016-12-12 19:41:07 Epoch 297 
2016-12-12 19:47:59 Training Error = 0.57089955895814 
2016-12-12 19:47:59 Training Loss = 0.013011747768471 
2016-12-12 19:48:06 Valid Error = 0.61774616248596 
2016-12-12 19:48:06 Valid Loss = 0.012735218260232 
2016-12-12 19:48:14 Test Error = 0.5978443920512 
2016-12-12 19:48:14 Test Loss = 0.012636960146971 
2016-12-12 19:48:14 -------------------LR------------------- 
2016-12-12 19:48:14 0.00048828125 
2016-12-12 19:48:14 Epoch 298 
2016-12-12 19:55:01 Training Error = 0.57759840226346 
2016-12-12 19:55:01 Training Loss = 0.013040130984702 
2016-12-12 19:55:08 Valid Error = 0.63609135155373 
2016-12-12 19:55:08 Valid Loss = 0.012861635186361 
2016-12-12 19:55:16 Test Error = 0.61636914786123 
2016-12-12 19:55:16 Test Loss = 0.012742238493925 
2016-12-12 19:55:16 -------------------LR------------------- 
2016-12-12 19:55:16 0.00048828125 
2016-12-12 19:55:16 Epoch 299 
2016-12-12 20:02:01 Training Error = 0.57198135974037 
2016-12-12 20:02:01 Training Loss = 0.013026227096291 
2016-12-12 20:02:08 Valid Error = 0.6357169599401 
2016-12-12 20:02:08 Valid Loss = 0.012794313779483 
2016-12-12 20:02:16 Test Error = 0.62041091276524 
2016-12-12 20:02:16 Test Loss = 0.012661413462499 
2016-12-12 20:02:16 -------------------LR------------------- 
2016-12-12 20:02:16 0.00048828125 
2016-12-12 20:02:16 Epoch 300 
2016-12-12 20:09:10 Training Error = 0.5761421319797 
2016-12-12 20:09:10 Training Loss = 0.013034095093412 
2016-12-12 20:09:17 Valid Error = 0.60726319730438 
2016-12-12 20:09:17 Valid Loss = 0.012757639829343 
2016-12-12 20:09:24 Test Error = 0.58369821488717 
2016-12-12 20:09:24 Test Loss = 0.012640388104435 
2016-12-12 20:09:24 -------------------LR------------------- 
2016-12-12 20:09:24 0.000244140625 
2016-12-12 20:09:24 Epoch 301 
2016-12-12 20:16:13 Training Error = 0.57431139219439 
2016-12-12 20:16:13 Training Loss = 0.013035731424849 
2016-12-12 20:16:20 Valid Error = 0.60464245600899 
2016-12-12 20:16:20 Valid Loss = 0.012674390464725 
2016-12-12 20:16:28 Test Error = 0.58807679353318 
2016-12-12 20:16:28 Test Loss = 0.012533828673285 
2016-12-12 20:16:28 -------------------LR------------------- 
2016-12-12 20:16:28 0.000244140625 
2016-12-12 20:16:28 Epoch 302 
2016-12-12 20:23:17 Training Error = 0.57060830490139 
2016-12-12 20:23:17 Training Loss = 0.013017271548073 
2016-12-12 20:23:24 Valid Error = 0.61587420441782 
2016-12-12 20:23:24 Valid Loss = 0.012701083648654 
2016-12-12 20:23:31 Test Error = 0.59380262714719 
2016-12-12 20:23:31 Test Loss = 0.012516007779487 
2016-12-12 20:23:31 -------------------LR------------------- 
2016-12-12 20:23:31 0.000244140625 
2016-12-12 20:23:31 Epoch 303 
2016-12-12 20:30:24 Training Error = 0.57335441457935 
2016-12-12 20:30:24 Training Loss = 0.013020431031016 
2016-12-12 20:30:31 Valid Error = 0.63272182703107 
2016-12-12 20:30:31 Valid Loss = 0.012796613533354 
2016-12-12 20:30:39 Test Error = 0.61468507915123 
2016-12-12 20:30:39 Test Loss = 0.012688792260926 
2016-12-12 20:30:39 -------------------LR------------------- 
2016-12-12 20:30:39 0.000244140625 
2016-12-12 20:30:39 Epoch 304 
2016-12-12 20:37:28 Training Error = 0.57339602230174 
2016-12-12 20:37:28 Training Loss = 0.013033081315515 
2016-12-12 20:37:35 Valid Error = 0.6169973792587 
2016-12-12 20:37:35 Valid Loss = 0.012773609897895 
2016-12-12 20:37:43 Test Error = 0.59178174469518 
2016-12-12 20:37:43 Test Loss = 0.012655295671599 
2016-12-12 20:37:43 -------------------LR------------------- 
2016-12-12 20:37:43 0.000244140625 
2016-12-12 20:37:43 Epoch 305 
2016-12-12 20:44:35 Training Error = 0.57243904468669 
2016-12-12 20:44:35 Training Loss = 0.01302621104667 
2016-12-12 20:44:42 Valid Error = 0.61812055409959 
2016-12-12 20:44:42 Valid Loss = 0.012791115650273 
2016-12-12 20:44:50 Test Error = 0.6002020882452 
2016-12-12 20:44:50 Test Loss = 0.012687863198329 
2016-12-12 20:44:50 -------------------LR------------------- 
2016-12-12 20:44:50 0.000244140625 
2016-12-12 20:44:50 Epoch 306 
2016-12-12 20:51:49 Training Error = 0.57335441457935 
2016-12-12 20:51:49 Training Loss = 0.013021037385737 
2016-12-12 20:51:56 Valid Error = 0.62111568700861 
2016-12-12 20:51:56 Valid Loss = 0.012904326110592 
2016-12-12 20:52:03 Test Error = 0.61569552037723 
2016-12-12 20:52:03 Test Loss = 0.012808260107219 
2016-12-12 20:52:03 -------------------LR------------------- 
2016-12-12 20:52:03 0.000244140625 
2016-12-12 20:52:03 Epoch 307 
2016-12-12 20:58:54 Training Error = 0.57268869102105 
2016-12-12 20:58:54 Training Loss = 0.013020430888547 
2016-12-12 20:59:01 Valid Error = 0.60052414825908 
2016-12-12 20:59:01 Valid Loss = 0.012696912927281 
2016-12-12 20:59:09 Test Error = 0.57898282249916 
2016-12-12 20:59:09 Test Loss = 0.012567066436914 
2016-12-12 20:59:09 -------------------LR------------------- 
2016-12-12 20:59:09 0.000244140625 
2016-12-12 20:59:09 Epoch 308 
2016-12-12 21:06:07 Training Error = 0.57360406091371 
2016-12-12 21:06:07 Training Loss = 0.013025421722701 
2016-12-12 21:06:14 Valid Error = 0.61362785473605 
2016-12-12 21:06:14 Valid Loss = 0.012600971867748 
2016-12-12 21:06:21 Test Error = 0.59447625463119 
2016-12-12 21:06:21 Test Loss = 0.01244964087084 
2016-12-12 21:06:21 -------------------LR------------------- 
2016-12-12 21:06:21 0.000244140625 
2016-12-12 21:06:21 Epoch 309 
2016-12-12 21:13:13 Training Error = 0.57414496130482 
2016-12-12 21:13:13 Training Loss = 0.013025275046771 
2016-12-12 21:13:20 Valid Error = 0.62074129539498 
2016-12-12 21:13:20 Valid Loss = 0.012740362304602 
2016-12-12 21:13:28 Test Error = 0.5998652745032 
2016-12-12 21:13:28 Test Loss = 0.012616089692353 
2016-12-12 21:13:28 -------------------LR------------------- 
2016-12-12 21:13:28 0.000244140625 
2016-12-12 21:13:28 Epoch 310 
2016-12-12 21:20:26 Training Error = 0.57048348173421 
2016-12-12 21:20:26 Training Loss = 0.013019578096287 
2016-12-12 21:20:33 Valid Error = 0.62223886184949 
2016-12-12 21:20:33 Valid Loss = 0.012726077818507 
2016-12-12 21:20:41 Test Error = 0.61300101044123 
2016-12-12 21:20:41 Test Loss = 0.012573222103445 
2016-12-12 21:20:41 -------------------LR------------------- 
2016-12-12 21:20:41 0.000244140625 
2016-12-12 21:20:41 Epoch 311 
2016-12-12 21:27:38 Training Error = 0.57264708329866 
2016-12-12 21:27:38 Training Loss = 0.013017232103311 
2016-12-12 21:27:45 Valid Error = 0.60164732309996 
2016-12-12 21:27:45 Valid Loss = 0.012702498141462 
2016-12-12 21:27:53 Test Error = 0.58605591108117 
2016-12-12 21:27:53 Test Loss = 0.012544543729009 
2016-12-12 21:27:53 -------------------LR------------------- 
2016-12-12 21:27:53 0.000244140625 
2016-12-12 21:27:53 Epoch 312 
2016-12-12 21:34:43 Training Error = 0.57518515436465 
2016-12-12 21:34:43 Training Loss = 0.013028177730367 
2016-12-12 21:34:50 Valid Error = 0.61812055409959 
2016-12-12 21:34:50 Valid Loss = 0.012831794017522 
2016-12-12 21:34:58 Test Error = 0.60289659818121 
2016-12-12 21:34:58 Test Loss = 0.012741037045711 
2016-12-12 21:34:58 -------------------LR------------------- 
2016-12-12 21:34:58 0.000244140625 
2016-12-12 21:34:58 Epoch 313 
2016-12-12 21:41:47 Training Error = 0.57360406091371 
2016-12-12 21:41:47 Training Loss = 0.013008274729756 
2016-12-12 21:41:54 Valid Error = 0.59865219019094 
2016-12-12 21:41:54 Valid Loss = 0.012747974978051 
2016-12-12 21:42:02 Test Error = 0.58841360727518 
2016-12-12 21:42:02 Test Loss = 0.012633776292733 
2016-12-12 21:42:02 -------------------LR------------------- 
2016-12-12 21:42:02 0.000244140625 
2016-12-12 21:42:02 Epoch 314 
2016-12-12 21:48:56 Training Error = 0.57368727635849 
2016-12-12 21:48:56 Training Loss = 0.013009946599452 
2016-12-12 21:49:03 Valid Error = 0.62373642830401 
2016-12-12 21:49:03 Valid Loss = 0.012705959310254 
2016-12-12 21:49:11 Test Error = 0.59447625463119 
2016-12-12 21:49:11 Test Loss = 0.012542554201262 
2016-12-12 21:49:11 -------------------LR------------------- 
2016-12-12 21:49:11 0.000244140625 
2016-12-12 21:49:11 Epoch 315 
2016-12-12 21:56:03 Training Error = 0.57589248564534 
2016-12-12 21:56:03 Training Loss = 0.013040950064185 
2016-12-12 21:56:10 Valid Error = 0.62860351928117 
2016-12-12 21:56:10 Valid Loss = 0.012785694588116 
2016-12-12 21:56:18 Test Error = 0.62108454024924 
2016-12-12 21:56:18 Test Loss = 0.012667594938314 
2016-12-12 21:56:18 -------------------LR------------------- 
2016-12-12 21:56:18 0.000244140625 
2016-12-12 21:56:18 Epoch 316 
2016-12-12 22:03:18 Training Error = 0.56877756511609 
2016-12-12 22:03:18 Training Loss = 0.013024866214111 
2016-12-12 22:03:25 Valid Error = 0.63684013478098 
2016-12-12 22:03:25 Valid Loss = 0.012728012646116 
2016-12-12 22:03:33 Test Error = 0.62108454024924 
2016-12-12 22:03:33 Test Loss = 0.012592687489044 
2016-12-12 22:03:33 -------------------LR------------------- 
2016-12-12 22:03:33 0.000244140625 
2016-12-12 22:03:33 Epoch 317 
2016-12-12 22:10:23 Training Error = 0.57023383539985 
2016-12-12 22:10:23 Training Loss = 0.013012470086544 
2016-12-12 22:10:30 Valid Error = 0.6061400224635 
2016-12-12 22:10:30 Valid Loss = 0.012785191632289 
2016-12-12 22:10:38 Test Error = 0.58504546985517 
2016-12-12 22:10:38 Test Loss = 0.012648894292094 
2016-12-12 22:10:38 -------------------LR------------------- 
2016-12-12 22:10:38 0.000244140625 
2016-12-12 22:10:38 Epoch 318 
2016-12-12 22:17:21 Training Error = 0.57235582924191 
2016-12-12 22:17:21 Training Loss = 0.013016433343878 
2016-12-12 22:17:28 Valid Error = 0.60726319730438 
2016-12-12 22:17:28 Valid Loss = 0.012670886252988 
2016-12-12 22:17:36 Test Error = 0.58807679353318 
2016-12-12 22:17:36 Test Loss = 0.01252763546294 
2016-12-12 22:17:36 -------------------LR------------------- 
2016-12-12 22:17:36 0.000244140625 
2016-12-12 22:17:36 Epoch 319 
2016-12-12 22:24:28 Training Error = 0.57647499375884 
2016-12-12 22:24:28 Training Loss = 0.013036793308605 
2016-12-12 22:24:36 Valid Error = 0.59453388244103 
2016-12-12 22:24:36 Valid Loss = 0.012651607434064 
2016-12-12 22:24:43 Test Error = 0.57898282249916 
2016-12-12 22:24:43 Test Loss = 0.012501459721679 
2016-12-12 22:24:43 -------------------LR------------------- 
2016-12-12 22:24:43 0.000244140625 
2016-12-12 22:24:43 Epoch 320 
2016-12-12 22:31:32 Training Error = 0.57273029874345 
2016-12-12 22:31:32 Training Loss = 0.013031030773997 
2016-12-12 22:31:39 Valid Error = 0.63983526769 
2016-12-12 22:31:39 Valid Loss = 0.012753626114114 
2016-12-12 22:31:47 Test Error = 0.61872684405524 
2016-12-12 22:31:47 Test Loss = 0.0126210048701 
2016-12-12 22:31:47 -------------------LR------------------- 
2016-12-12 22:31:47 0.000244140625 
2016-12-12 22:31:47 Epoch 321 
2016-12-12 22:38:36 Training Error = 0.57352084546892 
2016-12-12 22:38:36 Training Loss = 0.013028465495928 
2016-12-12 22:38:43 Valid Error = 0.64095844253089 
2016-12-12 22:38:43 Valid Loss = 0.012776713499445 
2016-12-12 22:38:50 Test Error = 0.61872684405524 
2016-12-12 22:38:50 Test Loss = 0.012650370662691 
2016-12-12 22:38:50 -------------------LR------------------- 
2016-12-12 22:38:50 0.000244140625 
2016-12-12 22:38:50 Epoch 322 
2016-12-12 22:45:45 Training Error = 0.57460264625114 
2016-12-12 22:45:45 Training Loss = 0.013038281905976 
2016-12-12 22:45:52 Valid Error = 0.62373642830401 
2016-12-12 22:45:52 Valid Loss = 0.012729529771593 
2016-12-12 22:46:00 Test Error = 0.60592792185921 
2016-12-12 22:46:00 Test Loss = 0.012590274618226 
2016-12-12 22:46:00 -------------------LR------------------- 
2016-12-12 22:46:00 0.000244140625 
2016-12-12 22:46:00 Epoch 323 
2016-12-12 22:52:54 Training Error = 0.57044187401182 
2016-12-12 22:52:54 Training Loss = 0.013012769270734 
2016-12-12 22:53:01 Valid Error = 0.63721452639461 
2016-12-12 22:53:01 Valid Loss = 0.012809606249901 
2016-12-12 22:53:09 Test Error = 0.62377905018525 
2016-12-12 22:53:09 Test Loss = 0.012696408266617 
2016-12-12 22:53:09 -------------------LR------------------- 
2016-12-12 22:53:09 0.000244140625 
2016-12-12 22:53:09 Epoch 324 
2016-12-12 22:59:58 Training Error = 0.57655820920363 
2016-12-12 22:59:58 Training Loss = 0.013023684165613 
2016-12-12 23:00:05 Valid Error = 0.61624859603145 
2016-12-12 23:00:05 Valid Loss = 0.01265294263826 
2016-12-12 23:00:13 Test Error = 0.60357022566521 
2016-12-12 23:00:13 Test Loss = 0.012513954281956 
2016-12-12 23:00:13 -------------------LR------------------- 
2016-12-12 23:00:13 0.000244140625 
2016-12-12 23:00:13 Epoch 325 
2016-12-12 23:07:05 Training Error = 0.57243904468669 
2016-12-12 23:07:05 Training Loss = 0.013004796512112 
2016-12-12 23:07:12 Valid Error = 0.6169973792587 
2016-12-12 23:07:12 Valid Loss = 0.012777467959709 
2016-12-12 23:07:20 Test Error = 0.59481306837319 
2016-12-12 23:07:20 Test Loss = 0.012632980928353 
2016-12-12 23:07:20 -------------------LR------------------- 
2016-12-12 23:07:20 0.000244140625 
2016-12-12 23:07:20 Epoch 326 
2016-12-12 23:14:01 Training Error = 0.5742281767496 
2016-12-12 23:14:01 Training Loss = 0.013014115527842 
2016-12-12 23:14:08 Valid Error = 0.65069262448521 
2016-12-12 23:14:08 Valid Loss = 0.012894370062482 
2016-12-12 23:14:16 Test Error = 0.62579993263725 
2016-12-12 23:14:16 Test Loss = 0.012788860310701 
2016-12-12 23:14:16 -------------------LR------------------- 
2016-12-12 23:14:16 0.000244140625 
2016-12-12 23:14:16 Epoch 327 
2016-12-12 23:21:11 Training Error = 0.57402013813764 
2016-12-12 23:21:11 Training Loss = 0.013023222267135 
2016-12-12 23:21:18 Valid Error = 0.59153874953201 
2016-12-12 23:21:18 Valid Loss = 0.012677487204109 
2016-12-12 23:21:26 Test Error = 0.57426743011115 
2016-12-12 23:21:26 Test Loss = 0.01252785876596 
2016-12-12 23:21:26 -------------------LR------------------- 
2016-12-12 23:21:26 0.000244140625 
2016-12-12 23:21:26 Epoch 328 
2016-12-12 23:28:12 Training Error = 0.57156528251644 
2016-12-12 23:28:12 Training Loss = 0.013019606245436 
2016-12-12 23:28:20 Valid Error = 0.63758891800824 
2016-12-12 23:28:20 Valid Loss = 0.012750917276552 
2016-12-12 23:28:27 Test Error = 0.62276860895925 
2016-12-12 23:28:27 Test Loss = 0.012614089710393 
2016-12-12 23:28:27 -------------------LR------------------- 
2016-12-12 23:28:27 0.000244140625 
2016-12-12 23:28:27 Epoch 329 
2016-12-12 23:35:11 Training Error = 0.57073312806857 
2016-12-12 23:35:11 Training Loss = 0.013005074177108 
2016-12-12 23:35:18 Valid Error = 0.60239610632722 
2016-12-12 23:35:18 Valid Loss = 0.012614804384457 
2016-12-12 23:35:26 Test Error = 0.58605591108117 
2016-12-12 23:35:26 Test Loss = 0.012461059430265 
2016-12-12 23:35:26 -------------------LR------------------- 
2016-12-12 23:35:26 0.000244140625 
2016-12-12 23:35:26 Epoch 330 
2016-12-12 23:42:14 Training Error = 0.57372888408089 
2016-12-12 23:42:14 Training Loss = 0.013022363735575 
2016-12-12 23:42:21 Valid Error = 0.64357918382628 
2016-12-12 23:42:21 Valid Loss = 0.012755562084154 
2016-12-12 23:42:28 Test Error = 0.62074772650724 
2016-12-12 23:42:28 Test Loss = 0.012630695119419 
2016-12-12 23:42:28 -------------------LR------------------- 
2016-12-12 23:42:28 0.000244140625 
2016-12-12 23:42:28 Epoch 331 
2016-12-12 23:49:15 Training Error = 0.56890238828327 
2016-12-12 23:49:15 Training Loss = 0.013011692752107 
2016-12-12 23:49:22 Valid Error = 0.6424560089854 
2016-12-12 23:49:22 Valid Loss = 0.012700408488369 
2016-12-12 23:49:30 Test Error = 0.61636914786123 
2016-12-12 23:49:30 Test Loss = 0.012531259380781 
2016-12-12 23:49:30 -------------------LR------------------- 
2016-12-12 23:49:30 0.000244140625 
2016-12-12 23:49:30 Epoch 332 
2016-12-12 23:56:21 Training Error = 0.57626695514688 
2016-12-12 23:56:21 Training Loss = 0.013016005723812 
2016-12-12 23:56:28 Valid Error = 0.60838637214526 
2016-12-12 23:56:28 Valid Loss = 0.012608859700876 
2016-12-12 23:56:36 Test Error = 0.58773997979118 
2016-12-12 23:56:36 Test Loss = 0.012444356988359 
2016-12-12 23:56:36 -------------------LR------------------- 
2016-12-12 23:56:36 0.000244140625 
2016-12-12 23:56:36 Epoch 333 
2016-12-13 00:03:30 Training Error = 0.570566697179 
2016-12-13 00:03:30 Training Loss = 0.013018389593508 
2016-12-13 00:03:37 Valid Error = 0.61737177087233 
2016-12-13 00:03:37 Valid Loss = 0.012741745449229 
2016-12-13 00:03:45 Test Error = 0.59514988211519 
2016-12-13 00:03:45 Test Loss = 0.012599435051929 
2016-12-13 00:03:45 -------------------LR------------------- 
2016-12-13 00:03:45 0.000244140625 
2016-12-13 00:03:45 Epoch 334 
2016-12-13 00:10:36 Training Error = 0.57389531497046 
2016-12-13 00:10:36 Training Loss = 0.013020474706422 
2016-12-13 00:10:43 Valid Error = 0.61737177087233 
2016-12-13 00:10:43 Valid Loss = 0.012725579208845 
2016-12-13 00:10:51 Test Error = 0.59380262714719 
2016-12-13 00:10:51 Test Loss = 0.01255129769667 
2016-12-13 00:10:51 -------------------LR------------------- 
2016-12-13 00:10:51 0.000244140625 
2016-12-13 00:10:51 Epoch 335 
2016-12-13 00:17:36 Training Error = 0.57593409336773 
2016-12-13 00:17:36 Training Loss = 0.013026904367652 
2016-12-13 00:17:43 Valid Error = 0.63421939348559 
2016-12-13 00:17:43 Valid Loss = 0.01281251613973 
2016-12-13 00:17:51 Test Error = 0.61973728528124 
2016-12-13 00:17:51 Test Loss = 0.012727578060897 
2016-12-13 00:17:51 -------------------LR------------------- 
2016-12-13 00:17:51 0.000244140625 
2016-12-13 00:17:51 Epoch 336 
2016-12-13 00:24:42 Training Error = 0.56865274194891 
2016-12-13 00:24:42 Training Loss = 0.013013676051061 
2016-12-13 00:24:49 Valid Error = 0.60501684762261 
2016-12-13 00:24:49 Valid Loss = 0.012650509849408 
2016-12-13 00:24:57 Test Error = 0.58908723475918 
2016-12-13 00:24:57 Test Loss = 0.01249835020709 
2016-12-13 00:24:57 -------------------LR------------------- 
2016-12-13 00:24:57 0.000244140625 
2016-12-13 00:24:57 Epoch 337 
2016-12-13 00:31:41 Training Error = 0.57414496130482 
2016-12-13 00:31:41 Training Loss = 0.013017277435401 
2016-12-13 00:31:48 Valid Error = 0.61849494571322 
2016-12-13 00:31:48 Valid Loss = 0.012667486992885 
2016-12-13 00:31:56 Test Error = 0.59279218592119 
2016-12-13 00:31:56 Test Loss = 0.012508000694119 
2016-12-13 00:31:56 -------------------LR------------------- 
2016-12-13 00:31:56 0.000244140625 
2016-12-13 00:31:56 Epoch 338 
2016-12-13 00:38:50 Training Error = 0.57185653657319 
2016-12-13 00:38:50 Training Loss = 0.013021951936652 
2016-12-13 00:38:57 Valid Error = 0.63946087607638 
2016-12-13 00:38:57 Valid Loss = 0.012746032608122 
2016-12-13 00:39:05 Test Error = 0.61535870663523 
2016-12-13 00:39:05 Test Loss = 0.012588701879973 
2016-12-13 00:39:05 -------------------LR------------------- 
2016-12-13 00:39:05 0.000244140625 
2016-12-13 00:39:05 Epoch 339 
2016-12-13 00:45:47 Training Error = 0.57510193891986 
2016-12-13 00:45:47 Training Loss = 0.013037365548739 
2016-12-13 00:45:54 Valid Error = 0.62822912766754 
2016-12-13 00:45:54 Valid Loss = 0.012849460020512 
2016-12-13 00:46:02 Test Error = 0.60794880431122 
2016-12-13 00:46:02 Test Loss = 0.012721327770139 
2016-12-13 00:46:02 -------------------LR------------------- 
2016-12-13 00:46:02 0.000244140625 
2016-12-13 00:46:02 Epoch 340 
2016-12-13 00:52:50 Training Error = 0.57805608720979 
2016-12-13 00:52:50 Training Loss = 0.013043374490315 
2016-12-13 00:52:57 Valid Error = 0.63983526769 
2016-12-13 00:52:57 Valid Loss = 0.012743598552745 
2016-12-13 00:53:05 Test Error = 0.62041091276524 
2016-12-13 00:53:05 Test Loss = 0.012601472790161 
2016-12-13 00:53:05 -------------------LR------------------- 
2016-12-13 00:53:05 0.000244140625 
2016-12-13 00:53:06 Epoch 341 
2016-12-13 00:59:56 Training Error = 0.57306316052259 
2016-12-13 00:59:56 Training Loss = 0.013026719975025 
2016-12-13 01:00:03 Valid Error = 0.61138150505429 
2016-12-13 01:00:03 Valid Loss = 0.012730095554507 
2016-12-13 01:00:11 Test Error = 0.58875042101718 
2016-12-13 01:00:11 Test Loss = 0.01254682031392 
2016-12-13 01:00:11 -------------------LR------------------- 
2016-12-13 01:00:11 0.000244140625 
2016-12-13 01:00:11 Epoch 342 
2016-12-13 01:06:59 Training Error = 0.57501872347508 
2016-12-13 01:06:59 Training Loss = 0.013007443687656 
2016-12-13 01:07:06 Valid Error = 0.6289779108948 
2016-12-13 01:07:06 Valid Loss = 0.012835544840946 
2016-12-13 01:07:13 Test Error = 0.61670596160323 
2016-12-13 01:07:13 Test Loss = 0.012701931676916 
2016-12-13 01:07:13 -------------------LR------------------- 
2016-12-13 01:07:13 0.000244140625 
2016-12-13 01:07:13 Epoch 343 
2016-12-13 01:14:00 Training Error = 0.5761421319797 
2016-12-13 01:14:00 Training Loss = 0.013024925073351 
2016-12-13 01:14:07 Valid Error = 0.60576563084987 
2016-12-13 01:14:07 Valid Loss = 0.012750620819434 
2016-12-13 01:14:15 Test Error = 0.58538228359717 
2016-12-13 01:14:15 Test Loss = 0.012631329210589 
2016-12-13 01:14:15 -------------------LR------------------- 
2016-12-13 01:14:15 0.000244140625 
2016-12-13 01:14:15 Epoch 344 
2016-12-13 01:21:06 Training Error = 0.57593409336773 
2016-12-13 01:21:06 Training Loss = 0.013024169984058 
2016-12-13 01:21:13 Valid Error = 0.61662298764508 
2016-12-13 01:21:13 Valid Loss = 0.012707666294352 
2016-12-13 01:21:21 Test Error = 0.60491748063321 
2016-12-13 01:21:21 Test Loss = 0.01256480450843 
2016-12-13 01:21:21 -------------------LR------------------- 
2016-12-13 01:21:21 0.000244140625 
2016-12-13 01:21:21 Epoch 345 
2016-12-13 01:28:08 Training Error = 0.57285512191063 
2016-12-13 01:28:08 Training Loss = 0.013017113323624 
2016-12-13 01:28:15 Valid Error = 0.62448521153126 
2016-12-13 01:28:15 Valid Loss = 0.01274295545016 
2016-12-13 01:28:23 Test Error = 0.5991916470192 
2016-12-13 01:28:23 Test Loss = 0.012607939113415 
2016-12-13 01:28:23 -------------------LR------------------- 
2016-12-13 01:28:23 0.000244140625 
2016-12-13 01:28:23 Epoch 346 
2016-12-13 01:35:15 Training Error = 0.57210618290755 
2016-12-13 01:35:15 Training Loss = 0.013025988112075 
2016-12-13 01:35:22 Valid Error = 0.63684013478098 
2016-12-13 01:35:22 Valid Loss = 0.012734442527633 
2016-12-13 01:35:30 Test Error = 0.61737958908723 
2016-12-13 01:35:30 Test Loss = 0.012578789448808 
2016-12-13 01:35:30 -------------------LR------------------- 
2016-12-13 01:35:30 0.000244140625 
2016-12-13 01:35:30 Epoch 347 
2016-12-13 01:42:11 Training Error = 0.5748522925855 
2016-12-13 01:42:11 Training Loss = 0.013027605560736 
2016-12-13 01:42:18 Valid Error = 0.60389367278173 
2016-12-13 01:42:18 Valid Loss = 0.012701887502018 
2016-12-13 01:42:26 Test Error = 0.58033007746716 
2016-12-13 01:42:26 Test Loss = 0.012551302669145 
2016-12-13 01:42:26 -------------------LR------------------- 
2016-12-13 01:42:26 0.000244140625 
2016-12-13 01:42:26 Epoch 348 
2016-12-13 01:49:09 Training Error = 0.57360406091371 
2016-12-13 01:49:09 Training Loss = 0.013020661432391 
2016-12-13 01:49:17 Valid Error = 0.60763758891801 
2016-12-13 01:49:17 Valid Loss = 0.012813224625663 
2016-12-13 01:49:24 Test Error = 0.58706635230717 
2016-12-13 01:49:24 Test Loss = 0.012687561098814 
2016-12-13 01:49:24 -------------------LR------------------- 
2016-12-13 01:49:24 0.000244140625 
2016-12-13 01:49:24 Epoch 349 
2016-12-13 01:56:17 Training Error = 0.57160689023883 
2016-12-13 01:56:17 Training Loss = 0.013010484720026 
2016-12-13 01:56:24 Valid Error = 0.61886933732684 
2016-12-13 01:56:24 Valid Loss = 0.012806632894511 
2016-12-13 01:56:32 Test Error = 0.6008757157292 
2016-12-13 01:56:32 Test Loss = 0.012697154627177 
2016-12-13 01:56:32 -------------------LR------------------- 
2016-12-13 01:56:32 0.000244140625 
2016-12-13 01:56:32 Epoch 350 
2016-12-13 02:03:18 Training Error = 0.57451943080636 
2016-12-13 02:03:18 Training Loss = 0.013025600130144 
2016-12-13 02:03:26 Valid Error = 0.62523399475852 
2016-12-13 02:03:26 Valid Loss = 0.012743510394187 
2016-12-13 02:03:33 Test Error = 0.61064331424722 
2016-12-13 02:03:33 Test Loss = 0.012621700169098 
2016-12-13 02:03:33 -------------------LR------------------- 
2016-12-13 02:03:33 0.0001220703125 
2016-12-13 02:03:33 Epoch 351 
2016-12-13 02:10:22 Training Error = 0.57281351418823 
2016-12-13 02:10:22 Training Loss = 0.013021535779974 
2016-12-13 02:10:29 Valid Error = 0.6061400224635 
2016-12-13 02:10:29 Valid Loss = 0.012806651932663 
2016-12-13 02:10:36 Test Error = 0.58942404850118 
2016-12-13 02:10:36 Test Loss = 0.012689517650994 
2016-12-13 02:10:36 -------------------LR------------------- 
2016-12-13 02:10:36 0.0001220703125 
2016-12-13 02:10:36 Epoch 352 
2016-12-13 02:17:26 Training Error = 0.57601730881252 
2016-12-13 02:17:26 Training Loss = 0.013018976798944 
2016-12-13 02:17:33 Valid Error = 0.63421939348559 
2016-12-13 02:17:33 Valid Loss = 0.012834263076671 
2016-12-13 02:17:41 Test Error = 0.62411586392725 
2016-12-13 02:17:41 Test Loss = 0.012718638733222 
2016-12-13 02:17:41 -------------------LR------------------- 
2016-12-13 02:17:41 0.0001220703125 
2016-12-13 02:17:41 Epoch 353 
2016-12-13 02:24:28 Training Error = 0.57456103852875 
2016-12-13 02:24:28 Training Loss = 0.013027338628058 
2016-12-13 02:24:35 Valid Error = 0.63197304380382 
2016-12-13 02:24:35 Valid Loss = 0.012764489433087 
2016-12-13 02:24:43 Test Error = 0.61636914786123 
2016-12-13 02:24:43 Test Loss = 0.012611015802033 
2016-12-13 02:24:43 -------------------LR------------------- 
2016-12-13 02:24:43 0.0001220703125 
2016-12-13 02:24:43 Epoch 354 
2016-12-13 02:31:31 Training Error = 0.57131563618208 
2016-12-13 02:31:31 Training Loss = 0.013021882647587 
2016-12-13 02:31:38 Valid Error = 0.60314488955447 
2016-12-13 02:31:38 Valid Loss = 0.012670222624059 
2016-12-13 02:31:45 Test Error = 0.58437184237117 
2016-12-13 02:31:45 Test Loss = 0.012530976949158 
2016-12-13 02:31:45 -------------------LR------------------- 
2016-12-13 02:31:45 0.0001220703125 
2016-12-13 02:31:45 Epoch 355 
2016-12-13 02:38:36 Training Error = 0.57318798368977 
2016-12-13 02:38:36 Training Loss = 0.013020954350553 
2016-12-13 02:38:43 Valid Error = 0.64956944964433 
2016-12-13 02:38:43 Valid Loss = 0.012818590810861 
2016-12-13 02:38:51 Test Error = 0.63118895250926 
2016-12-13 02:38:51 Test Loss = 0.012697305756506 
2016-12-13 02:38:51 -------------------LR------------------- 
2016-12-13 02:38:51 0.0001220703125 
2016-12-13 02:38:51 Epoch 356 
2016-12-13 02:45:37 Training Error = 0.57227261379712 
2016-12-13 02:45:37 Training Loss = 0.013015404233974 
2016-12-13 02:45:45 Valid Error = 0.6169973792587 
2016-12-13 02:45:45 Valid Loss = 0.01270443018546 
2016-12-13 02:45:52 Test Error = 0.59346581340519 
2016-12-13 02:45:52 Test Loss = 0.012548851658515 
2016-12-13 02:45:52 -------------------LR------------------- 
2016-12-13 02:45:52 0.0001220703125 
2016-12-13 02:45:52 Epoch 357 
2016-12-13 02:52:43 Training Error = 0.57277190646584 
2016-12-13 02:52:43 Training Loss = 0.013029331840057 
2016-12-13 02:52:50 Valid Error = 0.62485960314489 
2016-12-13 02:52:50 Valid Loss = 0.012679637441581 
2016-12-13 02:52:57 Test Error = 0.6022229706972 
2016-12-13 02:52:57 Test Loss = 0.012528917947609 
2016-12-13 02:52:57 -------------------LR------------------- 
2016-12-13 02:52:57 0.0001220703125 
2016-12-13 02:52:57 Epoch 358 
2016-12-13 02:59:40 Training Error = 0.57597570109012 
2016-12-13 02:59:40 Training Loss = 0.013027387498045 
2016-12-13 02:59:47 Valid Error = 0.6169973792587 
2016-12-13 02:59:47 Valid Loss = 0.012720304920683 
2016-12-13 02:59:55 Test Error = 0.59178174469518 
2016-12-13 02:59:55 Test Loss = 0.012572141588455 
2016-12-13 02:59:55 -------------------LR------------------- 
2016-12-13 02:59:55 0.0001220703125 
2016-12-13 02:59:55 Epoch 359 
2016-12-13 03:06:43 Training Error = 0.57568444703337 
2016-12-13 03:06:43 Training Loss = 0.013021290844802 
2016-12-13 03:06:51 Valid Error = 0.61175589666791 
2016-12-13 03:06:51 Valid Loss = 0.012701034614103 
2016-12-13 03:06:58 Test Error = 0.59009767598518 
2016-12-13 03:06:58 Test Loss = 0.012546213667245 
2016-12-13 03:06:58 -------------------LR------------------- 
2016-12-13 03:06:58 0.0001220703125 
2016-12-13 03:06:58 Epoch 360 
2016-12-13 03:13:50 Training Error = 0.57481068486311 
2016-12-13 03:13:50 Training Loss = 0.013008628201141 
2016-12-13 03:13:57 Valid Error = 0.61512542119057 
2016-12-13 03:13:57 Valid Loss = 0.012863953456427 
2016-12-13 03:14:05 Test Error = 0.59717076456719 
2016-12-13 03:14:05 Test Loss = 0.012733043724763 
2016-12-13 03:14:05 -------------------LR------------------- 
2016-12-13 03:14:05 0.0001220703125 
2016-12-13 03:14:05 Epoch 361 
2016-12-13 03:20:51 Training Error = 0.57539319297662 
2016-12-13 03:20:51 Training Loss = 0.013029447854459 
2016-12-13 03:20:58 Valid Error = 0.62822912766754 
2016-12-13 03:20:58 Valid Loss = 0.012685628674971 
2016-12-13 03:21:06 Test Error = 0.60862243179522 
2016-12-13 03:21:06 Test Loss = 0.012524719496096 
2016-12-13 03:21:06 -------------------LR------------------- 
2016-12-13 03:21:06 0.0001220703125 
2016-12-13 03:21:06 Epoch 362 
2016-12-13 03:27:51 Training Error = 0.56894399600566 
2016-12-13 03:27:51 Training Loss = 0.013012556634466 
2016-12-13 03:27:58 Valid Error = 0.65555971546237 
2016-12-13 03:27:58 Valid Loss = 0.012800310287856 
2016-12-13 03:28:06 Test Error = 0.62984169754126 
2016-12-13 03:28:06 Test Loss = 0.012641128647462 
2016-12-13 03:28:06 -------------------LR------------------- 
2016-12-13 03:28:06 0.0001220703125 
2016-12-13 03:28:06 Epoch 363 
2016-12-13 03:35:00 Training Error = 0.57368727635849 
2016-12-13 03:35:00 Training Loss = 0.013029556639335 
2016-12-13 03:35:07 Valid Error = 0.61587420441782 
2016-12-13 03:35:07 Valid Loss = 0.012750264909475 
2016-12-13 03:35:15 Test Error = 0.59009767598518 
2016-12-13 03:35:15 Test Loss = 0.012619019291527 
2016-12-13 03:35:15 -------------------LR------------------- 
2016-12-13 03:35:15 0.0001220703125 
2016-12-13 03:35:15 Epoch 364 
2016-12-13 03:42:01 Training Error = 0.57189814429558 
2016-12-13 03:42:01 Training Loss = 0.013015436249986 
2016-12-13 03:42:08 Valid Error = 0.65106701609884 
2016-12-13 03:42:08 Valid Loss = 0.012808071894647 
2016-12-13 03:42:16 Test Error = 0.63152576625126 
2016-12-13 03:42:16 Test Loss = 0.012658034282075 
2016-12-13 03:42:16 -------------------LR------------------- 
2016-12-13 03:42:16 0.0001220703125 
2016-12-13 03:42:16 Epoch 365 
2016-12-13 03:49:06 Training Error = 0.57223100607473 
2016-12-13 03:49:06 Training Loss = 0.013010954995832 
2016-12-13 03:49:13 Valid Error = 0.62036690378136 
2016-12-13 03:49:13 Valid Loss = 0.012685753491268 
2016-12-13 03:49:21 Test Error = 0.60424385314921 
2016-12-13 03:49:21 Test Loss = 0.01256827381804 
2016-12-13 03:49:21 -------------------LR------------------- 
2016-12-13 03:49:21 0.0001220703125 
2016-12-13 03:49:21 Epoch 366 
2016-12-13 03:56:04 Training Error = 0.57277190646584 
2016-12-13 03:56:04 Training Loss = 0.013017983209452 
2016-12-13 03:56:11 Valid Error = 0.63758891800824 
2016-12-13 03:56:11 Valid Loss = 0.012815659659117 
2016-12-13 03:56:19 Test Error = 0.61906365779724 
2016-12-13 03:56:19 Test Loss = 0.012683424104986 
2016-12-13 03:56:19 -------------------LR------------------- 
2016-12-13 03:56:19 0.0001220703125 
2016-12-13 03:56:19 Epoch 367 
2016-12-13 04:03:00 Training Error = 0.57019222767746 
2016-12-13 04:03:00 Training Loss = 0.013018998955448 
2016-12-13 04:03:07 Valid Error = 0.64208161737177 
2016-12-13 04:03:07 Valid Loss = 0.012862239037054 
2016-12-13 04:03:15 Test Error = 0.61973728528124 
2016-12-13 04:03:15 Test Loss = 0.01278241752494 
2016-12-13 04:03:15 -------------------LR------------------- 
2016-12-13 04:03:15 0.0001220703125 
2016-12-13 04:03:15 Epoch 368 
2016-12-13 04:10:07 Training Error = 0.57206457518515 
2016-12-13 04:10:07 Training Loss = 0.013010029814697 
2016-12-13 04:10:14 Valid Error = 0.60801198053164 
2016-12-13 04:10:14 Valid Loss = 0.012761989828112 
2016-12-13 04:10:22 Test Error = 0.58605591108117 
2016-12-13 04:10:22 Test Loss = 0.012628424196876 
2016-12-13 04:10:22 -------------------LR------------------- 
2016-12-13 04:10:22 0.0001220703125 
2016-12-13 04:10:22 Epoch 369 
2016-12-13 04:17:07 Training Error = 0.57468586169593 
2016-12-13 04:17:07 Training Loss = 0.01302889283442 
2016-12-13 04:17:15 Valid Error = 0.62074129539498 
2016-12-13 04:17:15 Valid Loss = 0.012734014910694 
2016-12-13 04:17:22 Test Error = 0.60592792185921 
2016-12-13 04:17:22 Test Loss = 0.012606501386322 
2016-12-13 04:17:22 -------------------LR------------------- 
2016-12-13 04:17:22 0.0001220703125 
2016-12-13 04:17:22 Epoch 370 
2016-12-13 04:24:11 Training Error = 0.57339602230174 
2016-12-13 04:24:11 Training Loss = 0.013033940182624 
2016-12-13 04:24:18 Valid Error = 0.63758891800824 
2016-12-13 04:24:18 Valid Loss = 0.012828002083625 
2016-12-13 04:24:26 Test Error = 0.62175816773324 
2016-12-13 04:24:26 Test Loss = 0.012706192205984 
2016-12-13 04:24:26 -------------------LR------------------- 
2016-12-13 04:24:26 0.0001220703125 
2016-12-13 04:24:26 Epoch 371 
2016-12-13 04:31:15 Training Error = 0.57372888408089 
2016-12-13 04:31:15 Training Loss = 0.013023304415906 
2016-12-13 04:31:22 Valid Error = 0.60838637214526 
2016-12-13 04:31:22 Valid Loss = 0.012684404876767 
2016-12-13 04:31:30 Test Error = 0.58740316604917 
2016-12-13 04:31:30 Test Loss = 0.012555159040029 
2016-12-13 04:31:30 -------------------LR------------------- 
2016-12-13 04:31:30 0.0001220703125 
2016-12-13 04:31:30 Epoch 372 
2016-12-13 04:38:15 Training Error = 0.57464425397354 
2016-12-13 04:38:15 Training Loss = 0.013028027413857 
2016-12-13 04:38:22 Valid Error = 0.59865219019094 
2016-12-13 04:38:22 Valid Loss = 0.012794971819877 
2016-12-13 04:38:30 Test Error = 0.58437184237117 
2016-12-13 04:38:30 Test Loss = 0.012686177340855 
2016-12-13 04:38:30 -------------------LR------------------- 
2016-12-13 04:38:30 0.0001220703125 
2016-12-13 04:38:30 Epoch 373 
2016-12-13 04:45:16 Training Error = 0.5730215528002 
2016-12-13 04:45:16 Training Loss = 0.013021599844618 
2016-12-13 04:45:24 Valid Error = 0.64732309996256 
2016-12-13 04:45:24 Valid Loss = 0.012776743295492 
2016-12-13 04:45:31 Test Error = 0.62916807005726 
2016-12-13 04:45:31 Test Loss = 0.012646966844287 
2016-12-13 04:45:31 -------------------LR------------------- 
2016-12-13 04:45:31 0.0001220703125 
2016-12-13 04:45:31 Epoch 374 
2016-12-13 04:52:19 Training Error = 0.57040026628942 
2016-12-13 04:52:19 Training Loss = 0.013012763468829 
2016-12-13 04:52:26 Valid Error = 0.62560838637215 
2016-12-13 04:52:26 Valid Loss = 0.012854753915674 
2016-12-13 04:52:34 Test Error = 0.6018861569552 
2016-12-13 04:52:34 Test Loss = 0.01275935416526 
2016-12-13 04:52:34 -------------------LR------------------- 
2016-12-13 04:52:34 0.0001220703125 
2016-12-13 04:52:34 Epoch 375 
2016-12-13 04:59:22 Training Error = 0.57443621536157 
2016-12-13 04:59:22 Training Loss = 0.013027865285976 
2016-12-13 04:59:29 Valid Error = 0.59153874953201 
2016-12-13 04:59:29 Valid Loss = 0.012703090684359 
2016-12-13 04:59:37 Test Error = 0.57864600875716 
2016-12-13 04:59:37 Test Loss = 0.012558274820142 
2016-12-13 04:59:37 -------------------LR------------------- 
2016-12-13 04:59:37 0.0001220703125 
2016-12-13 04:59:37 Epoch 376 
2016-12-13 05:06:25 Training Error = 0.57439460763918 
2016-12-13 05:06:25 Training Loss = 0.013025664502692 
2016-12-13 05:06:32 Valid Error = 0.59752901535006 
2016-12-13 05:06:32 Valid Loss = 0.012603421159331 
2016-12-13 05:06:40 Test Error = 0.57662512630515 
2016-12-13 05:06:40 Test Loss = 0.01244862611999 
2016-12-13 05:06:40 -------------------LR------------------- 
2016-12-13 05:06:40 0.0001220703125 
2016-12-13 05:06:40 Epoch 377 
2016-12-13 05:13:23 Training Error = 0.57439460763918 
2016-12-13 05:13:23 Training Loss = 0.013024845511703 
2016-12-13 05:13:30 Valid Error = 0.65144140771247 
2016-12-13 05:13:30 Valid Loss = 0.012850230244622 
2016-12-13 05:13:38 Test Error = 0.63017851128326 
2016-12-13 05:13:38 Test Loss = 0.012716379137003 
2016-12-13 05:13:38 -------------------LR------------------- 
2016-12-13 05:13:38 0.0001220703125 
2016-12-13 05:13:38 Epoch 378 
2016-12-13 05:20:25 Training Error = 0.57647499375884 
2016-12-13 05:20:25 Training Loss = 0.013029079083832 
2016-12-13 05:20:32 Valid Error = 0.60651441407712 
2016-12-13 05:20:32 Valid Loss = 0.012757158715646 
2016-12-13 05:20:40 Test Error = 0.58437184237117 
2016-12-13 05:20:40 Test Loss = 0.01261714455402 
2016-12-13 05:20:40 -------------------LR------------------- 
2016-12-13 05:20:40 0.0001220703125 
2016-12-13 05:20:40 Epoch 379 
2016-12-13 05:27:30 Training Error = 0.57418656902721 
2016-12-13 05:27:30 Training Loss = 0.013025625965552 
2016-12-13 05:27:37 Valid Error = 0.6330962186447 
2016-12-13 05:27:37 Valid Loss = 0.012822386639066 
2016-12-13 05:27:45 Test Error = 0.61872684405524 
2016-12-13 05:27:45 Test Loss = 0.012683513206097 
2016-12-13 05:27:45 -------------------LR------------------- 
2016-12-13 05:27:45 0.0001220703125 
2016-12-13 05:27:45 Epoch 380 
2016-12-13 05:34:29 Training Error = 0.57189814429558 
2016-12-13 05:34:29 Training Loss = 0.013016425302685 
2016-12-13 05:34:36 Valid Error = 0.60988393859978 
2016-12-13 05:34:36 Valid Loss = 0.012656996141546 
2016-12-13 05:34:44 Test Error = 0.58740316604917 
2016-12-13 05:34:44 Test Loss = 0.012490184597736 
2016-12-13 05:34:44 -------------------LR------------------- 
2016-12-13 05:34:44 0.0001220703125 
2016-12-13 05:34:44 Epoch 381 
2016-12-13 05:41:33 Training Error = 0.574269784472 
2016-12-13 05:41:33 Training Loss = 0.013018305084334 
2016-12-13 05:41:40 Valid Error = 0.5967802321228 
2016-12-13 05:41:40 Valid Loss = 0.012766557620123 
2016-12-13 05:41:48 Test Error = 0.57561468507915 
2016-12-13 05:41:48 Test Loss = 0.012637210442516 
2016-12-13 05:41:48 -------------------LR------------------- 
2016-12-13 05:41:48 0.0001220703125 
2016-12-13 05:41:48 Epoch 382 
2016-12-13 05:48:34 Training Error = 0.57385370724807 
2016-12-13 05:48:34 Training Loss = 0.013031986056142 
2016-12-13 05:48:41 Valid Error = 0.64133283414452 
2016-12-13 05:48:41 Valid Loss = 0.01275351830356 
2016-12-13 05:48:49 Test Error = 0.62647356012125 
2016-12-13 05:48:49 Test Loss = 0.012637703286443 
2016-12-13 05:48:49 -------------------LR------------------- 
2016-12-13 05:48:49 0.0001220703125 
2016-12-13 05:48:49 Epoch 383 
2016-12-13 05:55:34 Training Error = 0.57514354664226 
2016-12-13 05:55:34 Training Loss = 0.013025891952285 
2016-12-13 05:55:41 Valid Error = 0.61213028828154 
2016-12-13 05:55:41 Valid Loss = 0.012683081876977 
2016-12-13 05:55:49 Test Error = 0.59312899966319 
2016-12-13 05:55:49 Test Loss = 0.012521786502365 
2016-12-13 05:55:49 -------------------LR------------------- 
2016-12-13 05:55:49 0.0001220703125 
2016-12-13 05:55:49 Epoch 384 
2016-12-13 06:02:39 Training Error = 0.57443621536157 
2016-12-13 06:02:39 Training Loss = 0.013024573832624 
2016-12-13 06:02:46 Valid Error = 0.60314488955447 
2016-12-13 06:02:46 Valid Loss = 0.012666408801615 
2016-12-13 06:02:54 Test Error = 0.58369821488717 
2016-12-13 06:02:54 Test Loss = 0.012532212757497 
2016-12-13 06:02:54 -------------------LR------------------- 
2016-12-13 06:02:54 0.0001220703125 
2016-12-13 06:02:54 Epoch 385 
2016-12-13 06:09:43 Training Error = 0.57098277440293 
2016-12-13 06:09:43 Training Loss = 0.013014367788934 
2016-12-13 06:09:50 Valid Error = 0.63084986896294 
2016-12-13 06:09:50 Valid Loss = 0.012785695213327 
2016-12-13 06:09:57 Test Error = 0.61704277534523 
2016-12-13 06:09:57 Test Loss = 0.012667307406104 
2016-12-13 06:09:57 -------------------LR------------------- 
2016-12-13 06:09:57 0.0001220703125 
2016-12-13 06:09:58 Epoch 386 
2016-12-13 06:16:24 Training Error = 0.57476907714072 
2016-12-13 06:16:24 Training Loss = 0.013025689248808 
2016-12-13 06:16:31 Valid Error = 0.6061400224635 
2016-12-13 06:16:31 Valid Loss = 0.012804511934445 
2016-12-13 06:16:39 Test Error = 0.58369821488717 
2016-12-13 06:16:39 Test Loss = 0.012663693529494 
2016-12-13 06:16:39 -------------------LR------------------- 
2016-12-13 06:16:39 0.0001220703125 
2016-12-13 06:16:39 Epoch 387 
2016-12-13 06:22:32 Training Error = 0.57377049180328 
2016-12-13 06:22:32 Training Loss = 0.013008509497077 
2016-12-13 06:22:39 Valid Error = 0.61475102957694 
2016-12-13 06:22:39 Valid Loss = 0.012753130471836 
2016-12-13 06:22:47 Test Error = 0.59616032334119 
2016-12-13 06:22:47 Test Loss = 0.012644244269227 
2016-12-13 06:22:47 -------------------LR------------------- 
2016-12-13 06:22:47 0.0001220703125 
2016-12-13 06:22:47 Epoch 388 
2016-12-13 06:28:31 Training Error = 0.57539319297662 
2016-12-13 06:28:31 Training Loss = 0.013025916257388 
2016-12-13 06:28:38 Valid Error = 0.61812055409959 
2016-12-13 06:28:38 Valid Loss = 0.012821319284789 
2016-12-13 06:28:46 Test Error = 0.61199056921522 
2016-12-13 06:28:46 Test Loss = 0.012731428922192 
2016-12-13 06:28:46 -------------------LR------------------- 
2016-12-13 06:28:46 0.0001220703125 
2016-12-13 06:28:46 Epoch 389 
2016-12-13 06:34:32 Training Error = 0.57273029874345 
2016-12-13 06:34:32 Training Loss = 0.013028475301462 
2016-12-13 06:34:39 Valid Error = 0.60164732309996 
2016-12-13 06:34:39 Valid Loss = 0.012681663800572 
2016-12-13 06:34:47 Test Error = 0.58066689120916 
2016-12-13 06:34:47 Test Loss = 0.012531502940528 
2016-12-13 06:34:47 -------------------LR------------------- 
2016-12-13 06:34:47 0.0001220703125 
2016-12-13 06:34:47 Epoch 390 
2016-12-13 06:40:33 Training Error = 0.57568444703337 
2016-12-13 06:40:33 Training Loss = 0.013024570269422 
2016-12-13 06:40:40 Valid Error = 0.63234743541745 
2016-12-13 06:40:40 Valid Loss = 0.01281097776418 
2016-12-13 06:40:47 Test Error = 0.61300101044123 
2016-12-13 06:40:47 Test Loss = 0.012697830431751 
2016-12-13 06:40:47 -------------------LR------------------- 
2016-12-13 06:40:47 0.0001220703125 
2016-12-13 06:40:47 Epoch 391 
2016-12-13 06:46:32 Training Error = 0.57389531497046 
2016-12-13 06:46:32 Training Loss = 0.013029710480139 
2016-12-13 06:46:39 Valid Error = 0.62448521153126 
2016-12-13 06:46:39 Valid Loss = 0.012732159876602 
2016-12-13 06:46:47 Test Error = 0.61199056921522 
2016-12-13 06:46:47 Test Loss = 0.012591515451558 
2016-12-13 06:46:47 -------------------LR------------------- 
2016-12-13 06:46:47 0.0001220703125 
2016-12-13 06:46:47 Epoch 392 
2016-12-13 06:52:36 Training Error = 0.57372888408089 
2016-12-13 06:52:36 Training Loss = 0.013026751466797 
2016-12-13 06:52:43 Valid Error = 0.59228753275927 
2016-12-13 06:52:43 Valid Loss = 0.012682989729856 
2016-12-13 06:52:51 Test Error = 0.58066689120916 
2016-12-13 06:52:51 Test Loss = 0.012544474232132 
2016-12-13 06:52:51 -------------------LR------------------- 
2016-12-13 06:52:51 0.0001220703125 
2016-12-13 06:52:51 Epoch 393 
2016-12-13 06:58:31 Training Error = 0.57356245319131 
2016-12-13 06:58:31 Training Loss = 0.01302225645994 
2016-12-13 06:58:38 Valid Error = 0.64020965930363 
2016-12-13 06:58:38 Valid Loss = 0.012816210301501 
2016-12-13 06:58:46 Test Error = 0.62142135399124 
2016-12-13 06:58:46 Test Loss = 0.012679312785168 
2016-12-13 06:58:46 -------------------LR------------------- 
2016-12-13 06:58:46 0.0001220703125 
2016-12-13 06:58:46 Epoch 394 
2016-12-13 07:04:28 Training Error = 0.5717733211284 
2016-12-13 07:04:28 Training Loss = 0.013029216619037 
2016-12-13 07:04:35 Valid Error = 0.63010108573568 
2016-12-13 07:04:35 Valid Loss = 0.012806208010502 
2016-12-13 07:04:43 Test Error = 0.61401145166723 
2016-12-13 07:04:43 Test Loss = 0.012666674570586 
2016-12-13 07:04:43 -------------------LR------------------- 
2016-12-13 07:04:43 0.0001220703125 
2016-12-13 07:04:43 Epoch 395 
2016-12-13 07:10:30 Training Error = 0.57048348173421 
2016-12-13 07:10:30 Training Loss = 0.013019867966712 
2016-12-13 07:10:37 Valid Error = 0.6330962186447 
2016-12-13 07:10:37 Valid Loss = 0.012718712055141 
2016-12-13 07:10:45 Test Error = 0.61199056921522 
2016-12-13 07:10:45 Test Loss = 0.012556917487357 
2016-12-13 07:10:45 -------------------LR------------------- 
2016-12-13 07:10:45 0.0001220703125 
2016-12-13 07:10:45 Epoch 396 
2016-12-13 07:16:28 Training Error = 0.57372888408089 
2016-12-13 07:16:28 Training Loss = 0.013023968526678 
2016-12-13 07:16:35 Valid Error = 0.61624859603145 
2016-12-13 07:16:35 Valid Loss = 0.012702804171888 
2016-12-13 07:16:43 Test Error = 0.59649713708319 
2016-12-13 07:16:43 Test Loss = 0.012556977553322 
2016-12-13 07:16:43 -------------------LR------------------- 
2016-12-13 07:16:43 0.0001220703125 
2016-12-13 07:16:43 Epoch 397 
2016-12-13 07:22:25 Training Error = 0.57010901223267 
2016-12-13 07:22:25 Training Loss = 0.012998302948455 
2016-12-13 07:22:32 Valid Error = 0.63496817671284 
2016-12-13 07:22:32 Valid Loss = 0.012739097767262 
2016-12-13 07:22:40 Test Error = 0.62243179521724 
2016-12-13 07:22:40 Test Loss = 0.012591785259032 
2016-12-13 07:22:40 -------------------LR------------------- 
2016-12-13 07:22:40 0.0001220703125 
2016-12-13 07:22:40 Epoch 398 
2016-12-13 07:28:35 Training Error = 0.57110759757011 
2016-12-13 07:28:35 Training Loss = 0.01301972262435 
2016-12-13 07:28:42 Valid Error = 0.61400224634968 
2016-12-13 07:28:42 Valid Loss = 0.012800891851667 
2016-12-13 07:28:50 Test Error = 0.5998652745032 
2016-12-13 07:28:50 Test Loss = 0.012703844751574 
2016-12-13 07:28:50 -------------------LR------------------- 
2016-12-13 07:28:50 0.0001220703125 
2016-12-13 07:28:50 Epoch 399 
2016-12-13 07:34:35 Training Error = 0.57385370724807 
2016-12-13 07:34:35 Training Loss = 0.013014399580565 
2016-12-13 07:34:42 Valid Error = 0.60314488955447 
2016-12-13 07:34:42 Valid Loss = 0.01282538084572 
2016-12-13 07:34:50 Test Error = 0.58403502862917 
2016-12-13 07:34:50 Test Loss = 0.01269688320518 
2016-12-13 07:34:50 -------------------LR------------------- 
2016-12-13 07:34:50 0.0001220703125 
2016-12-13 07:34:50 Epoch 400 
2016-12-13 07:40:40 Training Error = 0.57335441457935 
2016-12-13 07:40:40 Training Loss = 0.013022603799868 
2016-12-13 07:40:47 Valid Error = 0.63122426057656 
2016-12-13 07:40:47 Valid Loss = 0.012742223352088 
2016-12-13 07:40:55 Test Error = 0.61940047153924 
2016-12-13 07:40:55 Test Loss = 0.012620123391754 
2016-12-13 07:40:55 -------------------LR------------------- 
2016-12-13 07:40:55 6.103515625e-05 
2016-12-13 07:40:55 Epoch 401 
2016-12-13 07:46:41 Training Error = 0.57347923774653 
2016-12-13 07:46:41 Training Loss = 0.01301207646273 
2016-12-13 07:46:48 Valid Error = 0.60763758891801 
2016-12-13 07:46:48 Valid Loss = 0.012659572338199 
2016-12-13 07:46:56 Test Error = 0.58942404850118 
2016-12-13 07:46:56 Test Loss = 0.012539639108122 
2016-12-13 07:46:56 -------------------LR------------------- 
2016-12-13 07:46:56 6.103515625e-05 
2016-12-13 07:46:56 Epoch 402 
2016-12-13 07:52:46 Training Error = 0.57314637596738 
2016-12-13 07:52:46 Training Loss = 0.013014611954127 
2016-12-13 07:52:54 Valid Error = 0.60202171471359 
2016-12-13 07:52:54 Valid Loss = 0.012729618257913 
2016-12-13 07:53:01 Test Error = 0.58369821488717 
2016-12-13 07:53:01 Test Loss = 0.012563313741608 
2016-12-13 07:53:01 -------------------LR------------------- 
2016-12-13 07:53:01 6.103515625e-05 
2016-12-13 07:53:01 Epoch 403 
2016-12-13 07:58:52 Training Error = 0.57514354664226 
2016-12-13 07:58:52 Training Loss = 0.013037827484224 
2016-12-13 07:58:59 Valid Error = 0.60950954698615 
2016-12-13 07:58:59 Valid Loss = 0.012616315929924 
2016-12-13 07:59:07 Test Error = 0.59279218592119 
2016-12-13 07:59:07 Test Loss = 0.012466356326005 
2016-12-13 07:59:07 -------------------LR------------------- 
2016-12-13 07:59:07 6.103515625e-05 
2016-12-13 07:59:07 Epoch 404 
2016-12-13 08:04:49 Training Error = 0.57635017059166 
2016-12-13 08:04:49 Training Loss = 0.013018685753657 
2016-12-13 08:04:56 Valid Error = 0.61849494571322 
2016-12-13 08:04:56 Valid Loss = 0.012712975057224 
2016-12-13 08:05:04 Test Error = 0.59750757830919 
2016-12-13 08:05:04 Test Loss = 0.012573931592576 
2016-12-13 08:05:04 -------------------LR------------------- 
2016-12-13 08:05:04 6.103515625e-05 
2016-12-13 08:05:04 Epoch 405 
2016-12-13 08:10:51 Training Error = 0.57476907714072 
2016-12-13 08:10:51 Training Loss = 0.013033828013291 
2016-12-13 08:10:58 Valid Error = 0.61175589666791 
2016-12-13 08:10:58 Valid Loss = 0.012718004158423 
2016-12-13 08:11:05 Test Error = 0.58740316604917 
2016-12-13 08:11:05 Test Loss = 0.012607778226131 
2016-12-13 08:11:05 -------------------LR------------------- 
2016-12-13 08:11:05 6.103515625e-05 
2016-12-13 08:11:06 Epoch 406 
2016-12-13 08:16:55 Training Error = 0.57277190646584 
2016-12-13 08:16:55 Training Loss = 0.013012245263277 
2016-12-13 08:17:02 Valid Error = 0.60651441407712 
2016-12-13 08:17:02 Valid Loss = 0.012757403206825 
2016-12-13 08:17:10 Test Error = 0.58672953856517 
2016-12-13 08:17:10 Test Loss = 0.012628271490422 
2016-12-13 08:17:10 -------------------LR------------------- 
2016-12-13 08:17:10 6.103515625e-05 
2016-12-13 08:17:10 Epoch 407 
2016-12-13 08:22:59 Training Error = 0.57152367479404 
2016-12-13 08:22:59 Training Loss = 0.013017767871674 
2016-12-13 08:23:06 Valid Error = 0.60277049794085 
2016-12-13 08:23:06 Valid Loss = 0.01260932148655 
2016-12-13 08:23:14 Test Error = 0.58976086224318 
2016-12-13 08:23:14 Test Loss = 0.012464945637588 
2016-12-13 08:23:14 -------------------LR------------------- 
2016-12-13 08:23:14 6.103515625e-05 
2016-12-13 08:23:14 Epoch 408 
2016-12-13 08:29:00 Training Error = 0.57035865856703 
2016-12-13 08:29:00 Training Loss = 0.013011185354787 
2016-12-13 08:29:07 Valid Error = 0.63459378509921 
2016-12-13 08:29:07 Valid Loss = 0.012710726026922 
2016-12-13 08:29:15 Test Error = 0.61603233411923 
2016-12-13 08:29:15 Test Loss = 0.012524632041336 
2016-12-13 08:29:15 -------------------LR------------------- 
2016-12-13 08:29:15 6.103515625e-05 
2016-12-13 08:29:15 Epoch 409 
2016-12-13 08:35:09 Training Error = 0.57173171340601 
2016-12-13 08:35:09 Training Loss = 0.013028194608476 
2016-12-13 08:35:16 Valid Error = 0.62748034444028 
2016-12-13 08:35:16 Valid Loss = 0.012828969356757 
2016-12-13 08:35:24 Test Error = 0.60794880431122 
2016-12-13 08:35:24 Test Loss = 0.012659574508667 
2016-12-13 08:35:24 -------------------LR------------------- 
2016-12-13 08:35:24 6.103515625e-05 
2016-12-13 08:35:24 Epoch 410 
2016-12-13 08:41:11 Training Error = 0.5742281767496 
2016-12-13 08:41:11 Training Loss = 0.013003102487376 
2016-12-13 08:41:18 Valid Error = 0.64807188318982 
2016-12-13 08:41:18 Valid Loss = 0.012767525392003 
2016-12-13 08:41:26 Test Error = 0.62310542270125 
2016-12-13 08:41:26 Test Loss = 0.012630366152309 
2016-12-13 08:41:26 -------------------LR------------------- 
2016-12-13 08:41:26 6.103515625e-05 
2016-12-13 08:41:26 Epoch 411 
2016-12-13 08:47:15 Training Error = 0.57023383539985 
2016-12-13 08:47:15 Training Loss = 0.013001491574762 
2016-12-13 08:47:23 Valid Error = 0.60913515537252 
2016-12-13 08:47:23 Valid Loss = 0.012731301323422 
2016-12-13 08:47:30 Test Error = 0.58875042101718 
2016-12-13 08:47:30 Test Loss = 0.012593711276924 
2016-12-13 08:47:30 -------------------LR------------------- 
2016-12-13 08:47:30 6.103515625e-05 
2016-12-13 08:47:30 Epoch 412 
2016-12-13 08:53:23 Training Error = 0.57277190646584 
2016-12-13 08:53:23 Training Loss = 0.013023241432217 
2016-12-13 08:53:31 Valid Error = 0.61924372894047 
2016-12-13 08:53:31 Valid Loss = 0.012691147818072 
2016-12-13 08:53:38 Test Error = 0.60255978443921 
2016-12-13 08:53:38 Test Loss = 0.012532974711049 
2016-12-13 08:53:38 -------------------LR------------------- 
2016-12-13 08:53:38 6.103515625e-05 
2016-12-13 08:53:38 Epoch 413 
2016-12-13 08:59:28 Training Error = 0.57273029874345 
2016-12-13 08:59:28 Training Loss = 0.01303663139004 
2016-12-13 08:59:35 Valid Error = 0.63234743541745 
2016-12-13 08:59:35 Valid Loss = 0.012730962190435 
2016-12-13 08:59:43 Test Error = 0.61300101044123 
2016-12-13 08:59:43 Test Loss = 0.012597689632978 
2016-12-13 08:59:43 -------------------LR------------------- 
2016-12-13 08:59:43 6.103515625e-05 
2016-12-13 08:59:43 Epoch 414 
2016-12-13 09:05:37 Training Error = 0.57019222767746 
2016-12-13 09:05:37 Training Loss = 0.012991931125481 
2016-12-13 09:05:44 Valid Error = 0.62935230250842 
2016-12-13 09:05:44 Valid Loss = 0.01271377284083 
2016-12-13 09:05:52 Test Error = 0.61300101044123 
2016-12-13 09:05:52 Test Loss = 0.012581709045741 
2016-12-13 09:05:52 -------------------LR------------------- 
2016-12-13 09:05:52 6.103515625e-05 
2016-12-13 09:05:52 Epoch 415 
2016-12-13 09:11:42 Training Error = 0.57451943080636 
2016-12-13 09:11:42 Training Loss = 0.013024208003394 
2016-12-13 09:11:49 Valid Error = 0.62935230250842 
2016-12-13 09:11:49 Valid Loss = 0.012740808287591 
2016-12-13 09:11:57 Test Error = 0.61064331424722 
2016-12-13 09:11:57 Test Loss = 0.012610265411135 
2016-12-13 09:11:57 -------------------LR------------------- 
2016-12-13 09:11:57 6.103515625e-05 
2016-12-13 09:11:57 Epoch 416 
2016-12-13 09:17:48 Training Error = 0.57156528251644 
2016-12-13 09:17:48 Training Loss = 0.013033904805558 
2016-12-13 09:17:55 Valid Error = 0.61100711344066 
2016-12-13 09:17:55 Valid Loss = 0.012697306306806 
2016-12-13 09:18:03 Test Error = 0.6022229706972 
2016-12-13 09:18:03 Test Loss = 0.012565038074689 
2016-12-13 09:18:03 -------------------LR------------------- 
2016-12-13 09:18:03 6.103515625e-05 
2016-12-13 09:18:03 Epoch 417 
