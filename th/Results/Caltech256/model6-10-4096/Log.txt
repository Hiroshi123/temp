2016-12-11 13:44:41 [program started on Sun Dec 11 13:44:41 2016] 
2016-12-11 13:44:41 [command line arguments] 
2016-12-11 13:44:41 stcWeights false 
2016-12-11 13:44:41 LR 0.015625 
2016-12-11 13:44:41 batchSize 64 
2016-12-11 13:44:41 network ./Models/Cifar10_Custom 
2016-12-11 13:44:41 stcNeurons true 
2016-12-11 13:44:41 constBatchSize false 
2016-12-11 13:44:41 chartFileName chart1 
2016-12-11 13:44:41 dp_prepro false 
2016-12-11 13:44:41 nGPU 1 
2016-12-11 13:44:41 dataset Caltech256 
2016-12-11 13:44:41 type cuda 
2016-12-11 13:44:41 momentum 0 
2016-12-11 13:44:41 threads 8 
2016-12-11 13:44:41 weightDecay 0 
2016-12-11 13:44:41 runningVal false 
2016-12-11 13:44:41 convLayerN 6 
2016-12-11 13:44:41 LRDecay 0 
2016-12-11 13:44:41 numHid 4096 
2016-12-11 13:44:41 save /dev/shm/clone/temp/th/Results/Caltech256/model6-10-4096 
2016-12-11 13:44:41 augment false 
2016-12-11 13:44:41 epoch -1 
2016-12-11 13:44:41 modelsFolder ./Models/ 
2016-12-11 13:44:41 format rgb 
2016-12-11 13:44:41 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-11 13:44:41 imageFileExtension svg 
2016-12-11 13:44:41 channel 1 
2016-12-11 13:44:41 devid 4 
2016-12-11 13:44:41 visualize 1 
2016-12-11 13:44:41 LRDecayPerEpoch 0.0001 
2016-12-11 13:44:41 optimization adam 
2016-12-11 13:44:41 SBN true 
2016-12-11 13:44:41 normalization simple 
2016-12-11 13:44:41 title model1 
2016-12-11 13:44:41 load  
2016-12-11 13:44:41 whiten true 
2016-12-11 13:44:41 [----------------------] 
2016-12-11 13:44:44 ==> Network 
2016-12-11 13:44:44 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 4096)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(4096 -> 4096)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(4096 -> 255)
  (38): nn.BatchNormalization
} 
2016-12-11 13:44:44 ==>55981437 Parameters 
2016-12-11 13:44:44 ==> Loss 
2016-12-11 13:44:44 SqrtHingeEmbeddingCriterion 
2016-12-11 13:44:44 
==> Starting Training
 
2016-12-11 13:44:44 Epoch 1 
2016-12-11 13:51:28 Training Error = 0.9647582591329 
2016-12-11 13:51:28 Training Loss = 0.115490744242 
2016-12-11 13:51:35 Valid Error = 0.93635342568326 
2016-12-11 13:51:35 Valid Loss = 0.01580601048147 
2016-12-11 13:51:43 Test Error = 0.9491411249579 
2016-12-11 13:51:43 Test Loss = 0.015816662811865 
2016-12-11 13:51:43 -------------------LR------------------- 
2016-12-11 13:51:43 0.015625 
2016-12-11 13:51:43 Epoch 2 
2016-12-11 13:58:12 Training Error = 0.94499459099609 
2016-12-11 13:58:12 Training Loss = 0.015768424358487 
2016-12-11 13:58:19 Valid Error = 0.93635342568326 
2016-12-11 13:58:19 Valid Loss = 0.015701461813552 
2016-12-11 13:58:27 Test Error = 0.9491411249579 
2016-12-11 13:58:27 Test Loss = 0.015718148830288 
2016-12-11 13:58:27 -------------------LR------------------- 
2016-12-11 13:58:27 0.015625 
2016-12-11 13:58:27 Epoch 3 
2016-12-11 14:03:41 Training Error = 0.93421819089623 
2016-12-11 14:03:41 Training Loss = 0.015534800459129 
2016-12-11 14:03:48 Valid Error = 0.95619618120554 
2016-12-11 14:03:48 Valid Loss = 0.015577957209419 
2016-12-11 14:03:55 Test Error = 0.95621421353991 
2016-12-11 14:03:55 Test Loss = 0.01558641655643 
2016-12-11 14:03:55 -------------------LR------------------- 
2016-12-11 14:03:55 0.015625 
2016-12-11 14:03:55 Epoch 4 
2016-12-11 14:09:08 Training Error = 0.92181908962303 
2016-12-11 14:09:08 Training Loss = 0.015405077203516 
2016-12-11 14:09:15 Valid Error = 0.94795956570573 
2016-12-11 14:09:15 Valid Loss = 0.015490775155512 
2016-12-11 14:09:22 Test Error = 0.96564499831593 
2016-12-11 14:09:22 Test Loss = 0.015569352737605 
2016-12-11 14:09:22 -------------------LR------------------- 
2016-12-11 14:09:22 0.015625 
2016-12-11 14:09:22 Epoch 5 
2016-12-11 14:14:36 Training Error = 0.91258217525173 
2016-12-11 14:14:36 Training Loss = 0.015235128604917 
2016-12-11 14:14:43 Valid Error = 0.97154623736428 
2016-12-11 14:14:43 Valid Loss = 0.015727806148146 
2016-12-11 14:14:51 Test Error = 0.97002357696194 
2016-12-11 14:14:51 Test Loss = 0.015690816955662 
2016-12-11 14:14:51 -------------------LR------------------- 
2016-12-11 14:14:51 0.015625 
2016-12-11 14:14:51 Epoch 6 
2016-12-11 14:20:04 Training Error = 0.89298493800449 
2016-12-11 14:20:04 Training Loss = 0.015008196504503 
2016-12-11 14:20:12 Valid Error = 0.93485585922875 
2016-12-11 14:20:12 Valid Loss = 0.015743562295501 
2016-12-11 14:20:19 Test Error = 0.9494779386999 
2016-12-11 14:20:19 Test Loss = 0.015932311056851 
2016-12-11 14:20:19 -------------------LR------------------- 
2016-12-11 14:20:19 0.015625 
2016-12-11 14:20:19 Epoch 7 
2016-12-11 14:25:30 Training Error = 0.86506615627861 
2016-12-11 14:25:30 Training Loss = 0.014768646594899 
2016-12-11 14:25:38 Valid Error = 0.90228378884313 
2016-12-11 14:25:38 Valid Loss = 0.015674881911248 
2016-12-11 14:25:45 Test Error = 0.90771303469182 
2016-12-11 14:25:45 Test Loss = 0.015996205559461 
2016-12-11 14:25:45 -------------------LR------------------- 
2016-12-11 14:25:45 0.015625 
2016-12-11 14:25:45 Epoch 8 
2016-12-11 14:30:53 Training Error = 0.81305650328701 
2016-12-11 14:30:53 Training Loss = 0.014426601054628 
2016-12-11 14:31:01 Valid Error = 0.90116061400225 
2016-12-11 14:31:01 Valid Loss = 0.015406354973649 
2016-12-11 14:31:08 Test Error = 0.90468171101381 
2016-12-11 14:31:08 Test Loss = 0.015356208573693 
2016-12-11 14:31:08 -------------------LR------------------- 
2016-12-11 14:31:08 0.015625 
2016-12-11 14:31:08 Epoch 9 
2016-12-11 14:36:24 Training Error = 0.73046517433636 
2016-12-11 14:36:24 Training Loss = 0.013862604337393 
2016-12-11 14:36:31 Valid Error = 0.73305877948334 
2016-12-11 14:36:31 Valid Loss = 0.014302953171934 
2016-12-11 14:36:39 Test Error = 0.73223307510946 
2016-12-11 14:36:39 Test Loss = 0.014285212163881 
2016-12-11 14:36:39 -------------------LR------------------- 
2016-12-11 14:36:39 0.015625 
2016-12-11 14:36:39 Epoch 10 
2016-12-11 14:41:51 Training Error = 0.64059249396688 
2016-12-11 14:41:51 Training Loss = 0.013375482263382 
2016-12-11 14:41:58 Valid Error = 0.61437663796331 
2016-12-11 14:41:58 Valid Loss = 0.012886495921951 
2016-12-11 14:42:06 Test Error = 0.5988548332772 
2016-12-11 14:42:06 Test Loss = 0.012753719971187 
2016-12-11 14:42:06 -------------------LR------------------- 
2016-12-11 14:42:06 0.015625 
2016-12-11 14:42:06 Epoch 11 
2016-12-11 14:47:17 Training Error = 0.57214779062994 
2016-12-11 14:47:17 Training Loss = 0.013026562406024 
2016-12-11 14:47:24 Valid Error = 0.60876076375889 
2016-12-11 14:47:24 Valid Loss = 0.012734752629036 
2016-12-11 14:47:31 Test Error = 0.59144493095318 
2016-12-11 14:47:31 Test Loss = 0.012613591566153 
2016-12-11 14:47:31 -------------------LR------------------- 
2016-12-11 14:47:31 0.015625 
2016-12-11 14:47:31 Epoch 12 
2016-12-11 14:52:46 Training Error = 0.57476907714072 
2016-12-11 14:52:46 Training Loss = 0.01301094173563 
2016-12-11 14:52:53 Valid Error = 0.64395357543991 
2016-12-11 14:52:53 Valid Loss = 0.012834816181534 
2016-12-11 14:53:01 Test Error = 0.62512630515325 
2016-12-11 14:53:01 Test Loss = 0.012698323759478 
2016-12-11 14:53:01 -------------------LR------------------- 
2016-12-11 14:53:01 0.015625 
2016-12-11 14:53:01 Epoch 13 
2016-12-11 14:58:16 Training Error = 0.57285512191063 
2016-12-11 14:58:16 Training Loss = 0.013010402133606 
2016-12-11 14:58:23 Valid Error = 0.60688880569075 
2016-12-11 14:58:23 Valid Loss = 0.012660848913222 
2016-12-11 14:58:31 Test Error = 0.59312899966319 
2016-12-11 14:58:31 Test Loss = 0.012513109759385 
2016-12-11 14:58:31 -------------------LR------------------- 
2016-12-11 14:58:31 0.015625 
2016-12-11 14:58:31 Epoch 14 
2016-12-11 15:03:43 Training Error = 0.57227261379712 
2016-12-11 15:03:43 Training Loss = 0.01301559166995 
2016-12-11 15:03:50 Valid Error = 0.64020965930363 
2016-12-11 15:03:50 Valid Loss = 0.012803027762331 
2016-12-11 15:03:57 Test Error = 0.61872684405524 
2016-12-11 15:03:57 Test Loss = 0.012661867645416 
2016-12-11 15:03:57 -------------------LR------------------- 
2016-12-11 15:03:57 0.015625 
2016-12-11 15:03:57 Epoch 15 
2016-12-11 15:09:08 Training Error = 0.57252226013148 
2016-12-11 15:09:08 Training Loss = 0.013028944800121 
2016-12-11 15:09:15 Valid Error = 0.59790340696368 
2016-12-11 15:09:15 Valid Loss = 0.012631801887555 
2016-12-11 15:09:23 Test Error = 0.57999326372516 
2016-12-11 15:09:23 Test Loss = 0.012470011778359 
2016-12-11 15:09:23 -------------------LR------------------- 
2016-12-11 15:09:23 0.015625 
2016-12-11 15:09:23 Epoch 16 
2016-12-11 15:14:35 Training Error = 0.57010901223267 
2016-12-11 15:14:35 Training Loss = 0.013038124151354 
2016-12-11 15:14:42 Valid Error = 0.6196181205541 
2016-12-11 15:14:42 Valid Loss = 0.012759027314925 
2016-12-11 15:14:50 Test Error = 0.5988548332772 
2016-12-11 15:14:50 Test Loss = 0.012611122814874 
2016-12-11 15:14:50 -------------------LR------------------- 
2016-12-11 15:14:50 0.015625 
2016-12-11 15:14:50 Epoch 17 
2016-12-11 15:20:06 Training Error = 0.57443621536157 
2016-12-11 15:20:06 Training Loss = 0.013035194719317 
2016-12-11 15:20:13 Valid Error = 0.61175589666791 
2016-12-11 15:20:13 Valid Loss = 0.012819766734945 
2016-12-11 15:20:21 Test Error = 0.59245537217918 
2016-12-11 15:20:21 Test Loss = 0.012723876944372 
2016-12-11 15:20:21 -------------------LR------------------- 
2016-12-11 15:20:21 0.015625 
2016-12-11 15:20:21 Epoch 18 
2016-12-11 15:25:32 Training Error = 0.57035865856703 
2016-12-11 15:25:32 Training Loss = 0.013013308405124 
2016-12-11 15:25:39 Valid Error = 0.64320479221265 
2016-12-11 15:25:39 Valid Loss = 0.012801944345338 
2016-12-11 15:25:47 Test Error = 0.62546311889525 
2016-12-11 15:25:47 Test Loss = 0.012659935816358 
2016-12-11 15:25:47 -------------------LR------------------- 
2016-12-11 15:25:47 0.015625 
2016-12-11 15:25:47 Epoch 19 
2016-12-11 15:31:02 Training Error = 0.57377049180328 
2016-12-11 15:31:02 Training Loss = 0.013026540625148 
2016-12-11 15:31:09 Valid Error = 0.60950954698615 
2016-12-11 15:31:09 Valid Loss = 0.012657516266996 
2016-12-11 15:31:17 Test Error = 0.59009767598518 
2016-12-11 15:31:17 Test Loss = 0.012528873307535 
2016-12-11 15:31:17 -------------------LR------------------- 
2016-12-11 15:31:17 0.015625 
2016-12-11 15:31:17 Epoch 20 
2016-12-11 15:36:33 Training Error = 0.57368727635849 
2016-12-11 15:36:33 Training Loss = 0.013026758933284 
2016-12-11 15:36:40 Valid Error = 0.62935230250842 
2016-12-11 15:36:40 Valid Loss = 0.012790191981828 
2016-12-11 15:36:48 Test Error = 0.61199056921522 
2016-12-11 15:36:48 Test Loss = 0.012660778884347 
2016-12-11 15:36:48 -------------------LR------------------- 
2016-12-11 15:36:48 0.015625 
2016-12-11 15:36:48 Epoch 21 
2016-12-11 15:41:58 Training Error = 0.57193975201797 
2016-12-11 15:41:58 Training Loss = 0.013035028291458 
2016-12-11 15:42:05 Valid Error = 0.63272182703107 
2016-12-11 15:42:05 Valid Loss = 0.012797519882977 
2016-12-11 15:42:13 Test Error = 0.61367463792523 
2016-12-11 15:42:13 Test Loss = 0.012659872287405 
2016-12-11 15:42:13 -------------------LR------------------- 
2016-12-11 15:42:13 0.015625 
2016-12-11 15:42:13 Epoch 22 
2016-12-11 15:47:25 Training Error = 0.57360406091371 
2016-12-11 15:47:25 Training Loss = 0.013036658328344 
2016-12-11 15:47:32 Valid Error = 0.61063272182703 
2016-12-11 15:47:32 Valid Loss = 0.012728822699964 
2016-12-11 15:47:40 Test Error = 0.59346581340519 
2016-12-11 15:47:40 Test Loss = 0.012598353987094 
2016-12-11 15:47:40 -------------------LR------------------- 
2016-12-11 15:47:40 0.015625 
2016-12-11 15:47:40 Epoch 23 
2016-12-11 15:52:52 Training Error = 0.57397853041525 
2016-12-11 15:52:52 Training Loss = 0.013026526988148 
2016-12-11 15:52:59 Valid Error = 0.62411081991763 
2016-12-11 15:52:59 Valid Loss = 0.012647971641435 
2016-12-11 15:53:06 Test Error = 0.60357022566521 
2016-12-11 15:53:06 Test Loss = 0.012510183008104 
2016-12-11 15:53:06 -------------------LR------------------- 
2016-12-11 15:53:06 0.015625 
2016-12-11 15:53:06 Epoch 24 
2016-12-11 15:58:18 Training Error = 0.57443621536157 
2016-12-11 15:58:18 Training Loss = 0.013034065054274 
2016-12-11 15:58:25 Valid Error = 0.63234743541745 
2016-12-11 15:58:25 Valid Loss = 0.012684155893067 
2016-12-11 15:58:32 Test Error = 0.61603233411923 
2016-12-11 15:58:32 Test Loss = 0.012542496221683 
2016-12-11 15:58:32 -------------------LR------------------- 
2016-12-11 15:58:32 0.015625 
2016-12-11 15:58:32 Epoch 25 
2016-12-11 16:03:45 Training Error = 0.57605891653491 
2016-12-11 16:03:45 Training Loss = 0.013028661428444 
2016-12-11 16:03:52 Valid Error = 0.62186447023587 
2016-12-11 16:03:52 Valid Loss = 0.012799783055839 
2016-12-11 16:04:00 Test Error = 0.59447625463119 
2016-12-11 16:04:00 Test Loss = 0.012617613372675 
2016-12-11 16:04:00 -------------------LR------------------- 
2016-12-11 16:04:00 0.015625 
2016-12-11 16:04:00 Epoch 26 
2016-12-11 16:09:10 Training Error = 0.57372888408089 
2016-12-11 16:09:10 Training Loss = 0.013017497840356 
2016-12-11 16:09:17 Valid Error = 0.63796330962186 
2016-12-11 16:09:17 Valid Loss = 0.01279381097096 
2016-12-11 16:09:25 Test Error = 0.61771640282924 
2016-12-11 16:09:25 Test Loss = 0.012671895582973 
2016-12-11 16:09:25 -------------------LR------------------- 
2016-12-11 16:09:25 0.015625 
2016-12-11 16:09:25 Epoch 27 
2016-12-11 16:14:36 Training Error = 0.57356245319131 
2016-12-11 16:14:36 Training Loss = 0.01301828649425 
2016-12-11 16:14:43 Valid Error = 0.59977536503182 
2016-12-11 16:14:43 Valid Loss = 0.012713223844361 
2016-12-11 16:14:51 Test Error = 0.58706635230717 
2016-12-11 16:14:51 Test Loss = 0.012589082459285 
2016-12-11 16:14:51 -------------------LR------------------- 
2016-12-11 16:14:51 0.015625 
2016-12-11 16:14:51 Epoch 28 
2016-12-11 16:20:02 Training Error = 0.57185653657319 
2016-12-11 16:20:02 Training Loss = 0.013012643612137 
2016-12-11 16:20:09 Valid Error = 0.58891800823662 
2016-12-11 16:20:09 Valid Loss = 0.012678295738505 
2016-12-11 16:20:17 Test Error = 0.57527787133715 
2016-12-11 16:20:17 Test Loss = 0.012569718078021 
2016-12-11 16:20:17 -------------------LR------------------- 
2016-12-11 16:20:17 0.015625 
2016-12-11 16:20:17 Epoch 29 
2016-12-11 16:25:28 Training Error = 0.57243904468669 
2016-12-11 16:25:28 Training Loss = 0.013016023262635 
2016-12-11 16:25:35 Valid Error = 0.60539123923624 
2016-12-11 16:25:35 Valid Loss = 0.012764093592977 
2016-12-11 16:25:43 Test Error = 0.58639272482317 
2016-12-11 16:25:43 Test Loss = 0.012647444438178 
2016-12-11 16:25:43 -------------------LR------------------- 
2016-12-11 16:25:43 0.015625 
2016-12-11 16:25:43 Epoch 30 
2016-12-11 16:30:55 Training Error = 0.57073312806857 
2016-12-11 16:30:55 Training Loss = 0.013019197378256 
2016-12-11 16:31:02 Valid Error = 0.64020965930363 
2016-12-11 16:31:02 Valid Loss = 0.012807484950232 
2016-12-11 16:31:10 Test Error = 0.62613674637925 
2016-12-11 16:31:10 Test Loss = 0.012698310948333 
2016-12-11 16:31:10 -------------------LR------------------- 
2016-12-11 16:31:10 0.015625 
2016-12-11 16:31:10 Epoch 31 
2016-12-11 16:36:16 Training Error = 0.57327119913456 
2016-12-11 16:36:16 Training Loss = 0.013029576747583 
2016-12-11 16:36:23 Valid Error = 0.64170722575814 
2016-12-11 16:36:23 Valid Loss = 0.012827137152344 
2016-12-11 16:36:31 Test Error = 0.62108454024924 
2016-12-11 16:36:31 Test Loss = 0.012700660061826 
2016-12-11 16:36:31 -------------------LR------------------- 
2016-12-11 16:36:31 0.015625 
2016-12-11 16:36:31 Epoch 32 
2016-12-11 16:41:41 Training Error = 0.57160689023883 
2016-12-11 16:41:41 Training Loss = 0.013018629764726 
2016-12-11 16:41:48 Valid Error = 0.64020965930363 
2016-12-11 16:41:48 Valid Loss = 0.012781676013765 
2016-12-11 16:41:56 Test Error = 0.61940047153924 
2016-12-11 16:41:56 Test Loss = 0.01266488821406 
2016-12-11 16:41:56 -------------------LR------------------- 
2016-12-11 16:41:56 0.015625 
2016-12-11 16:41:56 Epoch 33 
2016-12-11 16:47:08 Training Error = 0.57256386785387 
2016-12-11 16:47:08 Training Loss = 0.013026408146295 
2016-12-11 16:47:15 Valid Error = 0.62298764507675 
2016-12-11 16:47:15 Valid Loss = 0.012725383050275 
2016-12-11 16:47:23 Test Error = 0.59616032334119 
2016-12-11 16:47:23 Test Loss = 0.012545501738426 
2016-12-11 16:47:23 -------------------LR------------------- 
2016-12-11 16:47:23 0.015625 
2016-12-11 16:47:23 Epoch 34 
2016-12-11 16:52:30 Training Error = 0.57189814429558 
2016-12-11 16:52:30 Training Loss = 0.013004855282711 
2016-12-11 16:52:37 Valid Error = 0.64994384125796 
2016-12-11 16:52:37 Valid Loss = 0.012806958225015 
2016-12-11 16:52:45 Test Error = 0.63118895250926 
2016-12-11 16:52:45 Test Loss = 0.012661943733269 
2016-12-11 16:52:45 -------------------LR------------------- 
2016-12-11 16:52:45 0.015625 
2016-12-11 16:52:45 Epoch 35 
2016-12-11 16:57:55 Training Error = 0.5693184655072 
2016-12-11 16:57:55 Training Loss = 0.013018462837054 
2016-12-11 16:58:02 Valid Error = 0.63197304380382 
2016-12-11 16:58:02 Valid Loss = 0.012736764673534 
2016-12-11 16:58:10 Test Error = 0.61434826540923 
2016-12-11 16:58:10 Test Loss = 0.012578604379494 
2016-12-11 16:58:10 -------------------LR------------------- 
2016-12-11 16:58:10 0.015625 
2016-12-11 16:58:10 Epoch 36 
2016-12-11 17:03:22 Training Error = 0.5692768577848 
2016-12-11 17:03:22 Training Loss = 0.013011556490936 
2016-12-11 17:03:29 Valid Error = 0.63721452639461 
2016-12-11 17:03:29 Valid Loss = 0.012778882897743 
2016-12-11 17:03:36 Test Error = 0.62377905018525 
2016-12-11 17:03:36 Test Loss = 0.01268654414381 
2016-12-11 17:03:36 -------------------LR------------------- 
2016-12-11 17:03:36 0.015625 
2016-12-11 17:03:36 Epoch 37 
2016-12-11 17:08:44 Training Error = 0.5748522925855 
2016-12-11 17:08:44 Training Loss = 0.013031032823423 
2016-12-11 17:08:51 Valid Error = 0.63908648446275 
2016-12-11 17:08:51 Valid Loss = 0.012767062947016 
2016-12-11 17:08:59 Test Error = 0.62175816773324 
2016-12-11 17:08:59 Test Loss = 0.012626521242227 
2016-12-11 17:08:59 -------------------LR------------------- 
2016-12-11 17:08:59 0.015625 
2016-12-11 17:08:59 Epoch 38 
2016-12-11 17:14:08 Training Error = 0.57439460763918 
2016-12-11 17:14:08 Training Loss = 0.013023109387063 
2016-12-11 17:14:15 Valid Error = 0.65144140771247 
2016-12-11 17:14:15 Valid Loss = 0.01270614525799 
2016-12-11 17:14:23 Test Error = 0.62647356012125 
2016-12-11 17:14:23 Test Loss = 0.012527393202609 
2016-12-11 17:14:23 -------------------LR------------------- 
2016-12-11 17:14:23 0.015625 
2016-12-11 17:14:23 Epoch 39 
2016-12-11 17:19:32 Training Error = 0.56960971956395 
2016-12-11 17:19:32 Training Loss = 0.013011841993805 
2016-12-11 17:19:39 Valid Error = 0.61400224634968 
2016-12-11 17:19:39 Valid Loss = 0.012690504809743 
2016-12-11 17:19:47 Test Error = 0.59649713708319 
2016-12-11 17:19:47 Test Loss = 0.012553573734123 
2016-12-11 17:19:47 -------------------LR------------------- 
2016-12-11 17:19:47 0.015625 
2016-12-11 17:19:47 Epoch 40 
2016-12-11 17:24:55 Training Error = 0.57335441457935 
2016-12-11 17:24:55 Training Loss = 0.013020565488206 
2016-12-11 17:25:02 Valid Error = 0.63946087607638 
2016-12-11 17:25:02 Valid Loss = 0.012759040690653 
2016-12-11 17:25:10 Test Error = 0.62074772650724 
2016-12-11 17:25:10 Test Loss = 0.012629966501897 
2016-12-11 17:25:10 -------------------LR------------------- 
2016-12-11 17:25:10 0.015625 
2016-12-11 17:25:10 Epoch 41 
2016-12-11 17:30:19 Training Error = 0.5736456686361 
2016-12-11 17:30:19 Training Loss = 0.013028399624524 
2016-12-11 17:30:26 Valid Error = 0.64395357543991 
2016-12-11 17:30:26 Valid Loss = 0.012765787922233 
2016-12-11 17:30:34 Test Error = 0.62074772650724 
2016-12-11 17:30:34 Test Loss = 0.012639730155891 
2016-12-11 17:30:34 -------------------LR------------------- 
2016-12-11 17:30:34 0.015625 
2016-12-11 17:30:34 Epoch 42 
2016-12-11 17:35:44 Training Error = 0.57385370724807 
2016-12-11 17:35:44 Training Loss = 0.013015975233569 
2016-12-11 17:35:51 Valid Error = 0.62149007862224 
2016-12-11 17:35:51 Valid Loss = 0.012770053539761 
2016-12-11 17:35:58 Test Error = 0.5991916470192 
2016-12-11 17:35:58 Test Loss = 0.012610943436573 
2016-12-11 17:35:58 -------------------LR------------------- 
2016-12-11 17:35:58 0.015625 
2016-12-11 17:35:58 Epoch 43 
2016-12-11 17:41:06 Training Error = 0.57135724390447 
2016-12-11 17:41:06 Training Loss = 0.013007456882181 
2016-12-11 17:41:13 Valid Error = 0.61063272182703 
2016-12-11 17:41:13 Valid Loss = 0.012773684100982 
2016-12-11 17:41:21 Test Error = 0.59211855843718 
2016-12-11 17:41:21 Test Loss = 0.012677134062282 
2016-12-11 17:41:21 -------------------LR------------------- 
2016-12-11 17:41:21 0.015625 
2016-12-11 17:41:21 Epoch 44 
2016-12-11 17:46:31 Training Error = 0.57356245319131 
2016-12-11 17:46:31 Training Loss = 0.013008293307554 
2016-12-11 17:46:38 Valid Error = 0.63459378509921 
2016-12-11 17:46:38 Valid Loss = 0.012785712819651 
2016-12-11 17:46:46 Test Error = 0.62377905018525 
2016-12-11 17:46:46 Test Loss = 0.012654181620057 
2016-12-11 17:46:46 -------------------LR------------------- 
2016-12-11 17:46:46 0.015625 
2016-12-11 17:46:46 Epoch 45 
2016-12-11 17:51:54 Training Error = 0.57293833735541 
2016-12-11 17:51:54 Training Loss = 0.013028650452437 
2016-12-11 17:52:01 Valid Error = 0.6263571695994 
2016-12-11 17:52:01 Valid Loss = 0.012814896830497 
2016-12-11 17:52:09 Test Error = 0.60794880431122 
2016-12-11 17:52:09 Test Loss = 0.012693459441973 
2016-12-11 17:52:09 -------------------LR------------------- 
2016-12-11 17:52:09 0.015625 
2016-12-11 17:52:09 Epoch 46 
2016-12-11 17:57:20 Training Error = 0.57327119913456 
2016-12-11 17:57:20 Training Loss = 0.013024592990539 
2016-12-11 17:57:27 Valid Error = 0.60539123923624 
2016-12-11 17:57:27 Valid Loss = 0.012749211724283 
2016-12-11 17:57:34 Test Error = 0.58437184237117 
2016-12-11 17:57:34 Test Loss = 0.012617672996219 
2016-12-11 17:57:34 -------------------LR------------------- 
2016-12-11 17:57:34 0.015625 
2016-12-11 17:57:34 Epoch 47 
2016-12-11 18:02:44 Training Error = 0.5711908130149 
2016-12-11 18:02:44 Training Loss = 0.013015369126342 
2016-12-11 18:02:51 Valid Error = 0.60539123923624 
2016-12-11 18:02:51 Valid Loss = 0.012756211822502 
2016-12-11 18:02:59 Test Error = 0.58336140114517 
2016-12-11 18:02:59 Test Loss = 0.012607052127868 
2016-12-11 18:02:59 -------------------LR------------------- 
2016-12-11 18:02:59 0.015625 
2016-12-11 18:02:59 Epoch 48 
2016-12-11 18:08:08 Training Error = 0.57443621536157 
2016-12-11 18:08:08 Training Loss = 0.01301988812323 
2016-12-11 18:08:15 Valid Error = 0.64020965930363 
2016-12-11 18:08:15 Valid Loss = 0.01280887244055 
2016-12-11 18:08:22 Test Error = 0.62647356012125 
2016-12-11 18:08:22 Test Loss = 0.012687149261105 
2016-12-11 18:08:22 -------------------LR------------------- 
2016-12-11 18:08:22 0.015625 
2016-12-11 18:08:22 Epoch 49 
2016-12-11 18:13:35 Training Error = 0.57164849796122 
2016-12-11 18:13:35 Training Loss = 0.013007608106606 
2016-12-11 18:13:42 Valid Error = 0.64020965930363 
2016-12-11 18:13:42 Valid Loss = 0.012830358545566 
2016-12-11 18:13:49 Test Error = 0.61771640282924 
2016-12-11 18:13:49 Test Loss = 0.012721006666366 
2016-12-11 18:13:49 -------------------LR------------------- 
2016-12-11 18:13:49 0.015625 
2016-12-11 18:13:49 Epoch 50 
2016-12-11 18:19:00 Training Error = 0.57102438212532 
2016-12-11 18:19:00 Training Loss = 0.013018103460642 
2016-12-11 18:19:07 Valid Error = 0.60464245600899 
2016-12-11 18:19:07 Valid Loss = 0.012636935473374 
2016-12-11 18:19:15 Test Error = 0.58976086224318 
2016-12-11 18:19:15 Test Loss = 0.012486542397357 
2016-12-11 18:19:15 -------------------LR------------------- 
2016-12-11 18:19:15 0.0078125 
2016-12-11 18:19:15 Epoch 51 
2016-12-11 18:24:26 Training Error = 0.57518515436465 
2016-12-11 18:24:26 Training Loss = 0.013027344994868 
2016-12-11 18:24:33 Valid Error = 0.60763758891801 
2016-12-11 18:24:33 Valid Loss = 0.012708201281355 
2016-12-11 18:24:41 Test Error = 0.58740316604917 
2016-12-11 18:24:41 Test Loss = 0.012571424687162 
2016-12-11 18:24:41 -------------------LR------------------- 
2016-12-11 18:24:41 0.0078125 
2016-12-11 18:24:41 Epoch 52 
2016-12-11 18:29:52 Training Error = 0.57064991262378 
2016-12-11 18:29:52 Training Loss = 0.013016484106633 
2016-12-11 18:29:59 Valid Error = 0.6035192811681 
2016-12-11 18:29:59 Valid Loss = 0.012732777838121 
2016-12-11 18:30:07 Test Error = 0.58976086224318 
2016-12-11 18:30:07 Test Loss = 0.01258119401705 
2016-12-11 18:30:07 -------------------LR------------------- 
2016-12-11 18:30:07 0.0078125 
2016-12-11 18:30:07 Epoch 53 
2016-12-11 18:35:14 Training Error = 0.57285512191063 
2016-12-11 18:35:14 Training Loss = 0.0130190033761 
2016-12-11 18:35:22 Valid Error = 0.61812055409959 
2016-12-11 18:35:22 Valid Loss = 0.012724768943278 
2016-12-11 18:35:29 Test Error = 0.5985180195352 
2016-12-11 18:35:29 Test Loss = 0.012566373305466 
2016-12-11 18:35:29 -------------------LR------------------- 
2016-12-11 18:35:29 0.0078125 
2016-12-11 18:35:29 Epoch 54 
2016-12-11 18:40:40 Training Error = 0.570566697179 
2016-12-11 18:40:40 Training Loss = 0.013021347626531 
2016-12-11 18:40:47 Valid Error = 0.63159865219019 
2016-12-11 18:40:47 Valid Loss = 0.012819718742886 
2016-12-11 18:40:54 Test Error = 0.61030650050522 
2016-12-11 18:40:54 Test Loss = 0.012689923268534 
2016-12-11 18:40:54 -------------------LR------------------- 
2016-12-11 18:40:54 0.0078125 
2016-12-11 18:40:55 Epoch 55 
2016-12-11 18:46:09 Training Error = 0.57347923774653 
2016-12-11 18:46:09 Training Loss = 0.013021671785899 
2016-12-11 18:46:16 Valid Error = 0.64470235866717 
2016-12-11 18:46:16 Valid Loss = 0.012794254170339 
2016-12-11 18:46:24 Test Error = 0.62377905018525 
2016-12-11 18:46:24 Test Loss = 0.01266374412874 
2016-12-11 18:46:24 -------------------LR------------------- 
2016-12-11 18:46:24 0.0078125 
2016-12-11 18:46:24 Epoch 56 
2016-12-11 18:51:33 Training Error = 0.57248065240909 
2016-12-11 18:51:33 Training Loss = 0.013013902590253 
2016-12-11 18:51:40 Valid Error = 0.62523399475852 
2016-12-11 18:51:40 Valid Loss = 0.012759756854841 
2016-12-11 18:51:48 Test Error = 0.61468507915123 
2016-12-11 18:51:48 Test Loss = 0.01261608767599 
2016-12-11 18:51:48 -------------------LR------------------- 
2016-12-11 18:51:48 0.0078125 
2016-12-11 18:51:48 Epoch 57 
2016-12-11 18:56:57 Training Error = 0.5748939003079 
2016-12-11 18:56:57 Training Loss = 0.013029740630444 
2016-12-11 18:57:04 Valid Error = 0.6330962186447 
2016-12-11 18:57:04 Valid Loss = 0.012751009837164 
2016-12-11 18:57:12 Test Error = 0.60660154934321 
2016-12-11 18:57:12 Test Loss = 0.0126020004247 
2016-12-11 18:57:12 -------------------LR------------------- 
2016-12-11 18:57:12 0.0078125 
2016-12-11 18:57:12 Epoch 58 
2016-12-11 19:02:20 Training Error = 0.57464425397354 
2016-12-11 19:02:20 Training Loss = 0.013025281482329 
2016-12-11 19:02:27 Valid Error = 0.63272182703107 
2016-12-11 19:02:27 Valid Loss = 0.012722772307392 
2016-12-11 19:02:34 Test Error = 0.60963287302122 
2016-12-11 19:02:34 Test Loss = 0.012565847747765 
2016-12-11 19:02:34 -------------------LR------------------- 
2016-12-11 19:02:34 0.0078125 
2016-12-11 19:02:34 Epoch 59 
2016-12-11 19:07:46 Training Error = 0.57626695514688 
2016-12-11 19:07:46 Training Loss = 0.013034043281297 
2016-12-11 19:07:53 Valid Error = 0.6061400224635 
2016-12-11 19:07:53 Valid Loss = 0.012651050841754 
2016-12-11 19:08:01 Test Error = 0.57864600875716 
2016-12-11 19:08:01 Test Loss = 0.012499699781575 
2016-12-11 19:08:01 -------------------LR------------------- 
2016-12-11 19:08:01 0.0078125 
2016-12-11 19:08:01 Epoch 60 
2016-12-11 19:13:13 Training Error = 0.57572605475576 
2016-12-11 19:13:13 Training Loss = 0.013024086671249 
2016-12-11 19:13:20 Valid Error = 0.60576563084987 
2016-12-11 19:13:20 Valid Loss = 0.012680960073823 
2016-12-11 19:13:27 Test Error = 0.58369821488717 
2016-12-11 19:13:27 Test Loss = 0.012528741589874 
2016-12-11 19:13:27 -------------------LR------------------- 
2016-12-11 19:13:27 0.0078125 
2016-12-11 19:13:27 Epoch 61 
2016-12-11 19:18:33 Training Error = 0.57535158525422 
2016-12-11 19:18:33 Training Loss = 0.01302148842742 
2016-12-11 19:18:41 Valid Error = 0.62074129539498 
2016-12-11 19:18:41 Valid Loss = 0.012717486580708 
2016-12-11 19:18:48 Test Error = 0.60458066689121 
2016-12-11 19:18:48 Test Loss = 0.012585999747838 
2016-12-11 19:18:48 -------------------LR------------------- 
2016-12-11 19:18:48 0.0078125 
2016-12-11 19:18:48 Epoch 62 
2016-12-11 19:24:00 Training Error = 0.57277190646584 
2016-12-11 19:24:00 Training Loss = 0.013021914662137 
2016-12-11 19:24:07 Valid Error = 0.62261325346312 
2016-12-11 19:24:07 Valid Loss = 0.012767892300468 
2016-12-11 19:24:15 Test Error = 0.5995284607612 
2016-12-11 19:24:15 Test Loss = 0.012656987279765 
2016-12-11 19:24:15 -------------------LR------------------- 
2016-12-11 19:24:15 0.0078125 
2016-12-11 19:24:15 Epoch 63 
2016-12-11 19:29:27 Training Error = 0.57293833735541 
2016-12-11 19:29:27 Training Loss = 0.013022234093827 
2016-12-11 19:29:34 Valid Error = 0.62860351928117 
2016-12-11 19:29:34 Valid Loss = 0.012746051571912 
2016-12-11 19:29:42 Test Error = 0.61670596160323 
2016-12-11 19:29:42 Test Loss = 0.012608933291636 
2016-12-11 19:29:42 -------------------LR------------------- 
2016-12-11 19:29:42 0.0078125 
2016-12-11 19:29:42 Epoch 64 
2016-12-11 19:34:49 Training Error = 0.56969293500874 
2016-12-11 19:34:49 Training Loss = 0.013011914802044 
2016-12-11 19:34:56 Valid Error = 0.6263571695994 
2016-12-11 19:34:56 Valid Loss = 0.012810076216368 
2016-12-11 19:35:04 Test Error = 0.60862243179522 
2016-12-11 19:35:04 Test Loss = 0.012679149790809 
2016-12-11 19:35:04 -------------------LR------------------- 
2016-12-11 19:35:04 0.0078125 
2016-12-11 19:35:04 Epoch 65 
2016-12-11 19:40:15 Training Error = 0.57693267870517 
2016-12-11 19:40:15 Training Loss = 0.013029677626861 
2016-12-11 19:40:22 Valid Error = 0.65518532384875 
2016-12-11 19:40:22 Valid Loss = 0.012744006449009 
2016-12-11 19:40:30 Test Error = 0.62984169754126 
2016-12-11 19:40:30 Test Loss = 0.012603289084182 
2016-12-11 19:40:30 -------------------LR------------------- 
2016-12-11 19:40:30 0.0078125 
2016-12-11 19:40:30 Epoch 66 
2016-12-11 19:45:37 Training Error = 0.57281351418823 
2016-12-11 19:45:37 Training Loss = 0.01302823598945 
2016-12-11 19:45:44 Valid Error = 0.6263571695994 
2016-12-11 19:45:44 Valid Loss = 0.012707011553368 
2016-12-11 19:45:52 Test Error = 0.5981812057932 
2016-12-11 19:45:52 Test Loss = 0.012557587342308 
2016-12-11 19:45:52 -------------------LR------------------- 
2016-12-11 19:45:52 0.0078125 
2016-12-11 19:45:52 Epoch 67 
2016-12-11 19:51:02 Training Error = 0.57094116668054 
2016-12-11 19:51:02 Training Loss = 0.013005276451275 
2016-12-11 19:51:09 Valid Error = 0.63684013478098 
2016-12-11 19:51:09 Valid Loss = 0.012767238592503 
2016-12-11 19:51:17 Test Error = 0.61434826540923 
2016-12-11 19:51:17 Test Loss = 0.012609592958147 
2016-12-11 19:51:17 -------------------LR------------------- 
2016-12-11 19:51:17 0.0078125 
2016-12-11 19:51:17 Epoch 68 
2016-12-11 19:56:27 Training Error = 0.56998418906549 
2016-12-11 19:56:27 Training Loss = 0.013015520719813 
2016-12-11 19:56:34 Valid Error = 0.65930363159865 
2016-12-11 19:56:34 Valid Loss = 0.012882125926846 
2016-12-11 19:56:41 Test Error = 0.63859885483328 
2016-12-11 19:56:41 Test Loss = 0.012753012499214 
2016-12-11 19:56:41 -------------------LR------------------- 
2016-12-11 19:56:41 0.0078125 
2016-12-11 19:56:41 Epoch 69 
2016-12-11 20:01:47 Training Error = 0.57148206707165 
2016-12-11 20:01:47 Training Loss = 0.013027357689141 
2016-12-11 20:01:54 Valid Error = 0.60127293148633 
2016-12-11 20:01:54 Valid Loss = 0.012743148711445 
2016-12-11 20:02:02 Test Error = 0.58841360727518 
2016-12-11 20:02:02 Test Loss = 0.012614872383783 
2016-12-11 20:02:02 -------------------LR------------------- 
2016-12-11 20:02:02 0.0078125 
2016-12-11 20:02:02 Epoch 70 
2016-12-11 20:07:12 Training Error = 0.5767246400932 
2016-12-11 20:07:12 Training Loss = 0.013031929698311 
2016-12-11 20:07:19 Valid Error = 0.60988393859978 
2016-12-11 20:07:19 Valid Loss = 0.012841180017074 
2016-12-11 20:07:27 Test Error = 0.59009767598518 
2016-12-11 20:07:27 Test Loss = 0.012719186683372 
2016-12-11 20:07:27 -------------------LR------------------- 
2016-12-11 20:07:27 0.0078125 
2016-12-11 20:07:27 Epoch 71 
2016-12-11 20:12:35 Training Error = 0.5748939003079 
2016-12-11 20:12:35 Training Loss = 0.013033372705274 
2016-12-11 20:12:42 Valid Error = 0.63758891800824 
2016-12-11 20:12:42 Valid Loss = 0.012811938669631 
2016-12-11 20:12:50 Test Error = 0.62142135399124 
2016-12-11 20:12:50 Test Loss = 0.012671241687843 
2016-12-11 20:12:50 -------------------LR------------------- 
2016-12-11 20:12:50 0.0078125 
2016-12-11 20:12:50 Epoch 72 
2016-12-11 20:18:00 Training Error = 0.57460264625114 
2016-12-11 20:18:00 Training Loss = 0.013026296637822 
2016-12-11 20:18:07 Valid Error = 0.60164732309996 
2016-12-11 20:18:07 Valid Loss = 0.012744220066599 
2016-12-11 20:18:15 Test Error = 0.58504546985517 
2016-12-11 20:18:15 Test Loss = 0.012627036763471 
2016-12-11 20:18:15 -------------------LR------------------- 
2016-12-11 20:18:15 0.0078125 
2016-12-11 20:18:15 Epoch 73 
2016-12-11 20:23:26 Training Error = 0.57297994507781 
2016-12-11 20:23:26 Training Loss = 0.013017872322638 
2016-12-11 20:23:33 Valid Error = 0.60426806439536 
2016-12-11 20:23:33 Valid Loss = 0.012785814834687 
2016-12-11 20:23:41 Test Error = 0.58908723475918 
2016-12-11 20:23:41 Test Loss = 0.012652231471858 
2016-12-11 20:23:41 -------------------LR------------------- 
2016-12-11 20:23:41 0.0078125 
2016-12-11 20:23:41 Epoch 74 
2016-12-11 20:28:48 Training Error = 0.57680785553799 
2016-12-11 20:28:48 Training Loss = 0.013038961342318 
2016-12-11 20:28:55 Valid Error = 0.60426806439536 
2016-12-11 20:28:55 Valid Loss = 0.0125607035509 
2016-12-11 20:29:03 Test Error = 0.58672953856517 
2016-12-11 20:29:03 Test Loss = 0.012435749193207 
2016-12-11 20:29:03 -------------------LR------------------- 
2016-12-11 20:29:03 0.0078125 
2016-12-11 20:29:03 Epoch 75 
2016-12-11 20:34:13 Training Error = 0.57501872347508 
2016-12-11 20:34:13 Training Loss = 0.013025079139999 
2016-12-11 20:34:20 Valid Error = 0.63946087607638 
2016-12-11 20:34:20 Valid Loss = 0.012705155741077 
2016-12-11 20:34:28 Test Error = 0.62007409902324 
2016-12-11 20:34:28 Test Loss = 0.01256827014339 
2016-12-11 20:34:28 -------------------LR------------------- 
2016-12-11 20:34:28 0.0078125 
2016-12-11 20:34:28 Epoch 76 
2016-12-11 20:39:39 Training Error = 0.57381209952567 
2016-12-11 20:39:39 Training Loss = 0.013026069652499 
2016-12-11 20:39:46 Valid Error = 0.62186447023587 
2016-12-11 20:39:46 Valid Loss = 0.012744717754548 
2016-12-11 20:39:54 Test Error = 0.6012125294712 
2016-12-11 20:39:54 Test Loss = 0.012613794234478 
2016-12-11 20:39:54 -------------------LR------------------- 
2016-12-11 20:39:54 0.0078125 
2016-12-11 20:39:54 Epoch 77 
2016-12-11 20:45:01 Training Error = 0.57356245319131 
2016-12-11 20:45:01 Training Loss = 0.0130266051545 
2016-12-11 20:45:08 Valid Error = 0.60950954698615 
2016-12-11 20:45:08 Valid Loss = 0.012744260298935 
2016-12-11 20:45:16 Test Error = 0.58942404850118 
2016-12-11 20:45:16 Test Loss = 0.012591078723626 
2016-12-11 20:45:16 -------------------LR------------------- 
2016-12-11 20:45:16 0.0078125 
2016-12-11 20:45:16 Epoch 78 
2016-12-11 20:50:29 Training Error = 0.5730215528002 
2016-12-11 20:50:29 Training Loss = 0.013027694085094 
2016-12-11 20:50:36 Valid Error = 0.62336203669038 
2016-12-11 20:50:36 Valid Loss = 0.012779646497931 
2016-12-11 20:50:44 Test Error = 0.60727517682721 
2016-12-11 20:50:44 Test Loss = 0.012637811908237 
2016-12-11 20:50:44 -------------------LR------------------- 
2016-12-11 20:50:44 0.0078125 
2016-12-11 20:50:44 Epoch 79 
2016-12-11 20:55:51 Training Error = 0.57497711575268 
2016-12-11 20:55:51 Training Loss = 0.013024398843573 
2016-12-11 20:55:59 Valid Error = 0.62485960314489 
2016-12-11 20:55:59 Valid Loss = 0.012915822183484 
2016-12-11 20:56:06 Test Error = 0.61468507915123 
2016-12-11 20:56:06 Test Loss = 0.012790144834013 
2016-12-11 20:56:06 -------------------LR------------------- 
2016-12-11 20:56:06 0.0078125 
2016-12-11 20:56:06 Epoch 80 
2016-12-11 21:01:16 Training Error = 0.57089955895814 
2016-12-11 21:01:16 Training Loss = 0.013022459936322 
2016-12-11 21:01:23 Valid Error = 0.62748034444028 
2016-12-11 21:01:23 Valid Loss = 0.012743056614057 
2016-12-11 21:01:31 Test Error = 0.5995284607612 
2016-12-11 21:01:31 Test Loss = 0.012586114072581 
2016-12-11 21:01:31 -------------------LR------------------- 
2016-12-11 21:01:31 0.0078125 
2016-12-11 21:01:31 Epoch 81 
2016-12-11 21:06:43 Training Error = 0.57314637596738 
2016-12-11 21:06:43 Training Loss = 0.013038329502659 
2016-12-11 21:06:50 Valid Error = 0.60127293148633 
2016-12-11 21:06:50 Valid Loss = 0.012721197573446 
2016-12-11 21:06:58 Test Error = 0.58268777366117 
2016-12-11 21:06:58 Test Loss = 0.012584732850592 
2016-12-11 21:06:58 -------------------LR------------------- 
2016-12-11 21:06:58 0.0078125 
2016-12-11 21:06:58 Epoch 82 
2016-12-11 21:12:07 Training Error = 0.57314637596738 
2016-12-11 21:12:07 Training Loss = 0.01302751194726 
2016-12-11 21:12:14 Valid Error = 0.58517409210034 
2016-12-11 21:12:14 Valid Loss = 0.012655420319638 
2016-12-11 21:12:22 Test Error = 0.57089929269114 
2016-12-11 21:12:22 Test Loss = 0.012511772345144 
2016-12-11 21:12:22 -------------------LR------------------- 
2016-12-11 21:12:22 0.0078125 
2016-12-11 21:12:22 Epoch 83 
2016-12-11 21:17:27 Training Error = 0.57539319297662 
2016-12-11 21:17:27 Training Loss = 0.013021683464015 
2016-12-11 21:17:34 Valid Error = 0.60763758891801 
2016-12-11 21:17:34 Valid Loss = 0.012724147218652 
2016-12-11 21:17:42 Test Error = 0.58437184237117 
2016-12-11 21:17:42 Test Loss = 0.012567557304265 
2016-12-11 21:17:42 -------------------LR------------------- 
2016-12-11 21:17:42 0.0078125 
2016-12-11 21:17:42 Epoch 84 
2016-12-11 21:22:49 Training Error = 0.57318798368977 
2016-12-11 21:22:49 Training Loss = 0.013014901944788 
2016-12-11 21:22:56 Valid Error = 0.61213028828154 
2016-12-11 21:22:56 Valid Loss = 0.01276386769283 
2016-12-11 21:23:04 Test Error = 0.58706635230717 
2016-12-11 21:23:04 Test Loss = 0.012615101234586 
2016-12-11 21:23:04 -------------------LR------------------- 
2016-12-11 21:23:04 0.0078125 
2016-12-11 21:23:04 Epoch 85 
2016-12-11 21:28:13 Training Error = 0.57285512191063 
2016-12-11 21:28:13 Training Loss = 0.013015870318483 
2016-12-11 21:28:20 Valid Error = 0.60501684762261 
2016-12-11 21:28:20 Valid Loss = 0.012642277574682 
2016-12-11 21:28:28 Test Error = 0.58875042101718 
2016-12-11 21:28:28 Test Loss = 0.012498912827194 
2016-12-11 21:28:28 -------------------LR------------------- 
2016-12-11 21:28:28 0.0078125 
2016-12-11 21:28:28 Epoch 86 
2016-12-11 21:33:35 Training Error = 0.57514354664226 
2016-12-11 21:33:35 Training Loss = 0.013039015318976 
2016-12-11 21:33:42 Valid Error = 0.64395357543991 
2016-12-11 21:33:42 Valid Loss = 0.012826067588515 
2016-12-11 21:33:50 Test Error = 0.62209498147524 
2016-12-11 21:33:50 Test Loss = 0.012691482980002 
2016-12-11 21:33:50 -------------------LR------------------- 
2016-12-11 21:33:50 0.0078125 
2016-12-11 21:33:50 Epoch 87 
2016-12-11 21:39:00 Training Error = 0.57456103852875 
2016-12-11 21:39:00 Training Loss = 0.013027320465967 
2016-12-11 21:39:07 Valid Error = 0.6128790715088 
2016-12-11 21:39:07 Valid Loss = 0.012685565593537 
2016-12-11 21:39:14 Test Error = 0.59211855843718 
2016-12-11 21:39:14 Test Loss = 0.012527068347796 
2016-12-11 21:39:14 -------------------LR------------------- 
2016-12-11 21:39:14 0.0078125 
2016-12-11 21:39:14 Epoch 88 
2016-12-11 21:44:22 Training Error = 0.57210618290755 
2016-12-11 21:44:22 Training Loss = 0.013017966759337 
2016-12-11 21:44:29 Valid Error = 0.61886933732684 
2016-12-11 21:44:29 Valid Loss = 0.012773646241133 
2016-12-11 21:44:37 Test Error = 0.59750757830919 
2016-12-11 21:44:37 Test Loss = 0.012641389121102 
2016-12-11 21:44:37 -------------------LR------------------- 
2016-12-11 21:44:37 0.0078125 
2016-12-11 21:44:37 Epoch 89 
2016-12-11 21:49:47 Training Error = 0.57064991262378 
2016-12-11 21:49:47 Training Loss = 0.013019407527304 
2016-12-11 21:49:54 Valid Error = 0.59790340696368 
2016-12-11 21:49:54 Valid Loss = 0.012831621574347 
2016-12-11 21:50:02 Test Error = 0.58504546985517 
2016-12-11 21:50:02 Test Loss = 0.012724590672321 
2016-12-11 21:50:02 -------------------LR------------------- 
2016-12-11 21:50:02 0.0078125 
2016-12-11 21:50:02 Epoch 90 
2016-12-11 21:55:14 Training Error = 0.57493550803029 
2016-12-11 21:55:14 Training Loss = 0.013041773376068 
2016-12-11 21:55:21 Valid Error = 0.61325346312243 
2016-12-11 21:55:21 Valid Loss = 0.012814605106038 
2016-12-11 21:55:28 Test Error = 0.59514988211519 
2016-12-11 21:55:28 Test Loss = 0.012710332031791 
2016-12-11 21:55:28 -------------------LR------------------- 
2016-12-11 21:55:28 0.0078125 
2016-12-11 21:55:28 Epoch 91 
2016-12-11 22:00:39 Training Error = 0.57397853041525 
2016-12-11 22:00:39 Training Loss = 0.013030169503482 
2016-12-11 22:00:46 Valid Error = 0.64844627480344 
2016-12-11 22:00:46 Valid Loss = 0.012864556903101 
2016-12-11 22:00:53 Test Error = 0.63253620747727 
2016-12-11 22:00:53 Test Loss = 0.012738029905692 
2016-12-11 22:00:53 -------------------LR------------------- 
2016-12-11 22:00:53 0.0078125 
2016-12-11 22:00:53 Epoch 92 
2016-12-11 22:06:04 Training Error = 0.57040026628942 
2016-12-11 22:06:04 Training Loss = 0.013022770417881 
2016-12-11 22:06:11 Valid Error = 0.6128790715088 
2016-12-11 22:06:11 Valid Loss = 0.012735696909555 
2016-12-11 22:06:19 Test Error = 0.59346581340519 
2016-12-11 22:06:19 Test Loss = 0.012603958422709 
2016-12-11 22:06:19 -------------------LR------------------- 
2016-12-11 22:06:19 0.0078125 
2016-12-11 22:06:19 Epoch 93 
2016-12-11 22:11:27 Training Error = 0.57306316052259 
2016-12-11 22:11:27 Training Loss = 0.013025418757023 
2016-12-11 22:11:34 Valid Error = 0.62223886184949 
2016-12-11 22:11:34 Valid Loss = 0.01275888875393 
2016-12-11 22:11:42 Test Error = 0.60929605927922 
2016-12-11 22:11:42 Test Loss = 0.012644295835276 
2016-12-11 22:11:42 -------------------LR------------------- 
2016-12-11 22:11:42 0.0078125 
2016-12-11 22:11:42 Epoch 94 
2016-12-11 22:16:48 Training Error = 0.57410335358242 
2016-12-11 22:16:48 Training Loss = 0.013023520435461 
2016-12-11 22:16:55 Valid Error = 0.62111568700861 
2016-12-11 22:16:55 Valid Loss = 0.012756776510823 
2016-12-11 22:17:02 Test Error = 0.6005389019872 
2016-12-11 22:17:02 Test Loss = 0.012626992962885 
2016-12-11 22:17:02 -------------------LR------------------- 
2016-12-11 22:17:02 0.0078125 
2016-12-11 22:17:02 Epoch 95 
2016-12-11 22:22:10 Training Error = 0.57934592660398 
2016-12-11 22:22:10 Training Loss = 0.013025622091228 
2016-12-11 22:22:17 Valid Error = 0.62036690378136 
2016-12-11 22:22:17 Valid Loss = 0.012813504591889 
2016-12-11 22:22:25 Test Error = 0.60727517682721 
2016-12-11 22:22:25 Test Loss = 0.012689382511723 
2016-12-11 22:22:25 -------------------LR------------------- 
2016-12-11 22:22:25 0.0078125 
2016-12-11 22:22:25 Epoch 96 
2016-12-11 22:27:29 Training Error = 0.57331280685695 
2016-12-11 22:27:29 Training Loss = 0.013021434391667 
2016-12-11 22:27:36 Valid Error = 0.61662298764508 
2016-12-11 22:27:36 Valid Loss = 0.012767985003648 
2016-12-11 22:27:44 Test Error = 0.59548669585719 
2016-12-11 22:27:44 Test Loss = 0.012622271817477 
2016-12-11 22:27:44 -------------------LR------------------- 
2016-12-11 22:27:44 0.0078125 
2016-12-11 22:27:44 Epoch 97 
2016-12-11 22:32:52 Training Error = 0.5730215528002 
2016-12-11 22:32:52 Training Loss = 0.013026615571161 
2016-12-11 22:33:00 Valid Error = 0.64956944964433 
2016-12-11 22:33:00 Valid Loss = 0.012740076409763 
2016-12-11 22:33:07 Test Error = 0.62411586392725 
2016-12-11 22:33:07 Test Loss = 0.012573401493682 
2016-12-11 22:33:07 -------------------LR------------------- 
2016-12-11 22:33:07 0.0078125 
2016-12-11 22:33:07 Epoch 98 
2016-12-11 22:38:21 Training Error = 0.56969293500874 
2016-12-11 22:38:21 Training Loss = 0.013018634694992 
2016-12-11 22:38:28 Valid Error = 0.64470235866717 
2016-12-11 22:38:28 Valid Loss = 0.012708387281665 
2016-12-11 22:38:36 Test Error = 0.62613674637925 
2016-12-11 22:38:36 Test Loss = 0.012549853605383 
2016-12-11 22:38:36 -------------------LR------------------- 
2016-12-11 22:38:36 0.0078125 
2016-12-11 22:38:36 Epoch 99 
2016-12-11 22:43:41 Training Error = 0.57481068486311 
2016-12-11 22:43:41 Training Loss = 0.013033081906018 
2016-12-11 22:43:48 Valid Error = 0.64432796705354 
2016-12-11 22:43:48 Valid Loss = 0.01282821091693 
2016-12-11 22:43:55 Test Error = 0.62344223644325 
2016-12-11 22:43:55 Test Loss = 0.012695128566979 
2016-12-11 22:43:55 -------------------LR------------------- 
2016-12-11 22:43:55 0.0078125 
2016-12-11 22:43:56 Epoch 100 
2016-12-11 22:49:07 Training Error = 0.57530997753183 
2016-12-11 22:49:07 Training Loss = 0.013033406111901 
2016-12-11 22:49:14 Valid Error = 0.59378509921378 
2016-12-11 22:49:14 Valid Loss = 0.012695001468359 
2016-12-11 22:49:22 Test Error = 0.57494105759515 
2016-12-11 22:49:22 Test Loss = 0.01255753696666 
2016-12-11 22:49:22 -------------------LR------------------- 
2016-12-11 22:49:22 0.00390625 
2016-12-11 22:49:22 Epoch 101 
2016-12-11 22:54:31 Training Error = 0.56998418906549 
2016-12-11 22:54:31 Training Loss = 0.013024038264069 
2016-12-11 22:54:38 Valid Error = 0.62298764507675 
2016-12-11 22:54:38 Valid Loss = 0.01275340571393 
2016-12-11 22:54:45 Test Error = 0.61401145166723 
2016-12-11 22:54:45 Test Loss = 0.012679895333365 
2016-12-11 22:54:45 -------------------LR------------------- 
2016-12-11 22:54:45 0.00390625 
2016-12-11 22:54:46 Epoch 102 
2016-12-11 22:59:51 Training Error = 0.57451943080636 
2016-12-11 22:59:51 Training Loss = 0.013023203705866 
2016-12-11 22:59:58 Valid Error = 0.62860351928117 
2016-12-11 22:59:58 Valid Loss = 0.012620803989519 
2016-12-11 23:00:06 Test Error = 0.61569552037723 
2016-12-11 23:00:06 Test Loss = 0.012482570521673 
2016-12-11 23:00:06 -------------------LR------------------- 
2016-12-11 23:00:06 0.00390625 
2016-12-11 23:00:06 Epoch 103 
2016-12-11 23:05:18 Training Error = 0.57456103852875 
2016-12-11 23:05:18 Training Loss = 0.013021700712195 
2016-12-11 23:05:25 Valid Error = 0.61213028828154 
2016-12-11 23:05:25 Valid Loss = 0.012760582089952 
2016-12-11 23:05:33 Test Error = 0.58706635230717 
2016-12-11 23:05:33 Test Loss = 0.012643377218139 
2016-12-11 23:05:33 -------------------LR------------------- 
2016-12-11 23:05:33 0.00390625 
2016-12-11 23:05:33 Epoch 104 
