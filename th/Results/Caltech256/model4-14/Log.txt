2016-12-10 06:06:30 [program started on Sat Dec 10 06:06:30 2016] 
2016-12-10 06:06:30 [command line arguments] 
2016-12-10 06:06:30 stcWeights false 
2016-12-10 06:06:30 LR 0.015625 
2016-12-10 06:06:30 batchSize 100 
2016-12-10 06:06:30 network ./Models/Cifar10_Custom 
2016-12-10 06:06:30 stcNeurons true 
2016-12-10 06:06:30 constBatchSize false 
2016-12-10 06:06:30 chartFileName chart1 
2016-12-10 06:06:30 dp_prepro false 
2016-12-10 06:06:30 nGPU 1 
2016-12-10 06:06:30 dataset Caltech256 
2016-12-10 06:06:30 type cuda 
2016-12-10 06:06:30 momentum 0 
2016-12-10 06:06:30 threads 8 
2016-12-10 06:06:30 weightDecay 0 
2016-12-10 06:06:30 runningVal false 
2016-12-10 06:06:30 convLayerN 4 
2016-12-10 06:06:30 LRDecay 0 
2016-12-10 06:06:30 numHid 1024 
2016-12-10 06:06:30 save /dev/shm/clone/temp/th/Results/Caltech256/model4-14 
2016-12-10 06:06:30 augment false 
2016-12-10 06:06:30 epoch -1 
2016-12-10 06:06:30 modelsFolder ./Models/ 
2016-12-10 06:06:30 format rgb 
2016-12-10 06:06:30 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 06:06:30 imageFileExtension svg 
2016-12-10 06:06:30 channel 1.4 
2016-12-10 06:06:30 devid 15 
2016-12-10 06:06:30 visualize 1 
2016-12-10 06:06:30 LRDecayPerEpoch 0.0001 
2016-12-10 06:06:30 optimization adam 
2016-12-10 06:06:30 SBN true 
2016-12-10 06:06:30 normalization simple 
2016-12-10 06:06:30 title model1 
2016-12-10 06:06:30 load  
2016-12-10 06:06:30 whiten true 
2016-12-10 06:06:30 [----------------------] 
2016-12-10 06:06:33 ==> Network 
2016-12-10 06:06:33 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 179, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(179 -> 179, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(179 -> 358, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(358 -> 358, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): nn.View(22912)
  (20): BinaryLinear(22912 -> 1024)
  (21): BatchNormalizationShiftPow2
  (22): nn.HardTanh
  (23): BinarizedNeurons
  (24): BinaryLinear(1024 -> 1024)
  (25): BatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): BinaryLinear(1024 -> 255)
  (29): nn.BatchNormalization
} 
2016-12-10 06:06:33 ==>26805131 Parameters 
2016-12-10 06:06:33 ==> Loss 
2016-12-10 06:06:33 SqrtHingeEmbeddingCriterion 
2016-12-10 06:06:33 
==> Starting Training
 
2016-12-10 06:06:33 Epoch 1 
2016-12-10 06:12:06 Training Error = 0.98044437047516 
2016-12-10 06:12:06 Training Loss = 0.16954864013869 
2016-12-10 06:12:14 Valid Error = 0.93934855859229 
2016-12-10 06:12:14 Valid Loss = 0.016491111593289 
2016-12-10 06:12:23 Test Error = 0.9514988211519 
2016-12-10 06:12:23 Test Loss = 0.016526942774982 
2016-12-10 06:12:23 -------------------LR------------------- 
2016-12-10 06:12:23 0.015625 
2016-12-10 06:12:23 Epoch 2 
2016-12-10 06:17:36 Training Error = 0.94823999334276 
2016-12-10 06:17:36 Training Loss = 0.016118973432716 
2016-12-10 06:17:44 Valid Error = 0.92923998502434 
2016-12-10 06:17:44 Valid Loss = 0.015780383742405 
2016-12-10 06:17:52 Test Error = 0.94173122263388 
2016-12-10 06:17:52 Test Loss = 0.015820543839835 
2016-12-10 06:17:52 -------------------LR------------------- 
2016-12-10 06:17:52 0.015625 
2016-12-10 06:17:53 Epoch 3 
2016-12-10 06:23:04 Training Error = 0.93263709744529 
2016-12-10 06:23:04 Training Loss = 0.015667045336316 
2016-12-10 06:23:12 Valid Error = 0.92923998502434 
2016-12-10 06:23:12 Valid Loss = 0.015545538442638 
2016-12-10 06:23:21 Test Error = 0.94173122263388 
2016-12-10 06:23:21 Test Loss = 0.015609508720587 
2016-12-10 06:23:21 -------------------LR------------------- 
2016-12-10 06:23:21 0.015625 
2016-12-10 06:23:21 Epoch 4 
2016-12-10 06:28:50 Training Error = 0.92057085795124 
2016-12-10 06:28:50 Training Loss = 0.0154575603455 
2016-12-10 06:28:58 Valid Error = 0.92399850243355 
2016-12-10 06:28:58 Valid Loss = 0.015593974996711 
2016-12-10 06:29:07 Test Error = 0.93869989895588 
2016-12-10 06:29:07 Test Loss = 0.015686949915234 
2016-12-10 06:29:07 -------------------LR------------------- 
2016-12-10 06:29:07 0.015625 
2016-12-10 06:29:07 Epoch 5 
2016-12-10 06:34:29 Training Error = 0.91199966713822 
2016-12-10 06:34:29 Training Loss = 0.0151919348162 
2016-12-10 06:34:37 Valid Error = 0.92886559341071 
2016-12-10 06:34:37 Valid Loss = 0.015522140423489 
2016-12-10 06:34:46 Test Error = 0.94644661502189 
2016-12-10 06:34:46 Test Loss = 0.015542433210299 
2016-12-10 06:34:46 -------------------LR------------------- 
2016-12-10 06:34:46 0.015625 
2016-12-10 06:34:46 Epoch 6 
2016-12-10 06:40:13 Training Error = 0.87967046683865 
2016-12-10 06:40:13 Training Loss = 0.014888259590694 
2016-12-10 06:40:21 Valid Error = 0.8858105578435 
2016-12-10 06:40:21 Valid Loss = 0.015129763657631 
2016-12-10 06:40:30 Test Error = 0.89693499494779 
2016-12-10 06:40:30 Test Loss = 0.015299631632568 
2016-12-10 06:40:30 -------------------LR------------------- 
2016-12-10 06:40:30 0.015625 
2016-12-10 06:40:30 Epoch 7 
2016-12-10 06:45:53 Training Error = 0.8397270533411 
2016-12-10 06:45:53 Training Loss = 0.014530516339002 
2016-12-10 06:46:01 Valid Error = 0.836016473231 
2016-12-10 06:46:01 Valid Loss = 0.01491034681451 
2016-12-10 06:46:10 Test Error = 0.83563489390367 
2016-12-10 06:46:10 Test Loss = 0.015071959160525 
2016-12-10 06:46:10 -------------------LR------------------- 
2016-12-10 06:46:10 0.015625 
2016-12-10 06:46:10 Epoch 8 
2016-12-10 06:51:55 Training Error = 0.78730132312557 
2016-12-10 06:51:55 Training Loss = 0.014147873012072 
2016-12-10 06:52:03 Valid Error = 0.79595657057282 
2016-12-10 06:52:03 Valid Loss = 0.014349528288833 
2016-12-10 06:52:12 Test Error = 0.7999326372516 
2016-12-10 06:52:12 Test Loss = 0.014469076166047 
2016-12-10 06:52:12 -------------------LR------------------- 
2016-12-10 06:52:12 0.015625 
2016-12-10 06:52:12 Epoch 9 
2016-12-10 06:58:14 Training Error = 0.7190646584006 
2016-12-10 06:58:14 Training Loss = 0.013725704593943 
2016-12-10 06:58:22 Valid Error = 0.67989517034818 
2016-12-10 06:58:22 Valid Loss = 0.013257388068839 
2016-12-10 06:58:31 Test Error = 0.68743684742337 
2016-12-10 06:58:31 Test Loss = 0.013343028223577 
2016-12-10 06:58:31 -------------------LR------------------- 
2016-12-10 06:58:31 0.015625 
2016-12-10 06:58:31 Epoch 10 
2016-12-10 07:04:38 Training Error = 0.63934426229508 
2016-12-10 07:04:38 Training Loss = 0.013328552463422 
2016-12-10 07:04:46 Valid Error = 0.62186447023587 
2016-12-10 07:04:46 Valid Loss = 0.013020122264118 
2016-12-10 07:04:55 Test Error = 0.63051532502526 
2016-12-10 07:04:55 Test Loss = 0.013041079678092 
2016-12-10 07:04:55 -------------------LR------------------- 
2016-12-10 07:04:55 0.015625 
2016-12-10 07:04:55 Epoch 11 
2016-12-10 07:11:04 Training Error = 0.59332612132812 
2016-12-10 07:11:04 Training Loss = 0.013097542110136 
2016-12-10 07:11:12 Valid Error = 0.61213028828154 
2016-12-10 07:11:12 Valid Loss = 0.012976065411238 
2016-12-10 07:11:20 Test Error = 0.61906365779724 
2016-12-10 07:11:20 Test Loss = 0.013073556936845 
2016-12-10 07:11:20 -------------------LR------------------- 
2016-12-10 07:11:20 0.015625 
2016-12-10 07:11:21 Epoch 12 
2016-12-10 07:17:28 Training Error = 0.59453274527752 
2016-12-10 07:17:28 Training Loss = 0.013101419721253 
2016-12-10 07:17:35 Valid Error = 0.60876076375889 
2016-12-10 07:17:35 Valid Loss = 0.012874140044633 
2016-12-10 07:17:44 Test Error = 0.61401145166723 
2016-12-10 07:17:44 Test Loss = 0.012966598475764 
2016-12-10 07:17:44 -------------------LR------------------- 
2016-12-10 07:17:44 0.015625 
2016-12-10 07:17:44 Epoch 13 
2016-12-10 07:23:52 Training Error = 0.59137055837563 
2016-12-10 07:23:52 Training Loss = 0.013103960037131 
2016-12-10 07:24:00 Valid Error = 0.59415949082741 
2016-12-10 07:24:00 Valid Loss = 0.012858964366316 
2016-12-10 07:24:09 Test Error = 0.6002020882452 
2016-12-10 07:24:09 Test Loss = 0.012968315476749 
2016-12-10 07:24:09 -------------------LR------------------- 
2016-12-10 07:24:09 0.015625 
2016-12-10 07:24:09 Epoch 14 
2016-12-10 07:30:24 Training Error = 0.5897478572023 
2016-12-10 07:30:24 Training Loss = 0.013098370770601 
2016-12-10 07:30:32 Valid Error = 0.60950954698615 
2016-12-10 07:30:32 Valid Loss = 0.012894426133585 
2016-12-10 07:30:41 Test Error = 0.61670596160323 
2016-12-10 07:30:41 Test Loss = 0.012985748748909 
2016-12-10 07:30:41 -------------------LR------------------- 
2016-12-10 07:30:41 0.015625 
2016-12-10 07:30:41 Epoch 15 
2016-12-10 07:36:47 Training Error = 0.58966464175751 
2016-12-10 07:36:47 Training Loss = 0.013088779832216 
2016-12-10 07:36:55 Valid Error = 0.59415949082741 
2016-12-10 07:36:55 Valid Loss = 0.012860039740506 
2016-12-10 07:37:04 Test Error = 0.5991916470192 
2016-12-10 07:37:04 Test Loss = 0.01296258203236 
2016-12-10 07:37:04 -------------------LR------------------- 
2016-12-10 07:37:04 0.015625 
2016-12-10 07:37:04 Epoch 16 
2016-12-10 07:43:16 Training Error = 0.59091287342931 
2016-12-10 07:43:16 Training Loss = 0.013094631459627 
2016-12-10 07:43:24 Valid Error = 0.61362785473605 
2016-12-10 07:43:24 Valid Loss = 0.012914940441219 
2016-12-10 07:43:33 Test Error = 0.62108454024924 
2016-12-10 07:43:33 Test Loss = 0.012992999675173 
2016-12-10 07:43:33 -------------------LR------------------- 
2016-12-10 07:43:33 0.015625 
2016-12-10 07:43:33 Epoch 17 
2016-12-10 07:49:40 Training Error = 0.59174502787717 
2016-12-10 07:49:40 Training Loss = 0.013097024273075 
2016-12-10 07:49:48 Valid Error = 0.59977536503182 
2016-12-10 07:49:48 Valid Loss = 0.012873575375638 
2016-12-10 07:49:57 Test Error = 0.60424385314921 
2016-12-10 07:49:57 Test Loss = 0.012962647340613 
2016-12-10 07:49:57 -------------------LR------------------- 
2016-12-10 07:49:57 0.015625 
2016-12-10 07:49:57 Epoch 18 
2016-12-10 07:55:55 Training Error = 0.58808354830657 
2016-12-10 07:55:55 Training Loss = 0.013084501060863 
2016-12-10 07:56:03 Valid Error = 0.60277049794085 
2016-12-10 07:56:03 Valid Loss = 0.012887107054007 
2016-12-10 07:56:12 Test Error = 0.60626473560121 
2016-12-10 07:56:12 Test Loss = 0.012981282070485 
2016-12-10 07:56:12 -------------------LR------------------- 
2016-12-10 07:56:12 0.015625 
2016-12-10 07:56:12 Epoch 19 
2016-12-10 08:01:45 Training Error = 0.58953981859033 
2016-12-10 08:01:45 Training Loss = 0.013095559306055 
2016-12-10 08:01:53 Valid Error = 0.60127293148633 
2016-12-10 08:01:53 Valid Loss = 0.012865184798723 
2016-12-10 08:02:02 Test Error = 0.60592792185921 
2016-12-10 08:02:02 Test Loss = 0.012960487350546 
2016-12-10 08:02:02 -------------------LR------------------- 
2016-12-10 08:02:02 0.015625 
2016-12-10 08:02:02 Epoch 20 
2016-12-10 08:07:38 Training Error = 0.58953981859033 
2016-12-10 08:07:38 Training Loss = 0.013086409296117 
2016-12-10 08:07:46 Valid Error = 0.60576563084987 
2016-12-10 08:07:46 Valid Loss = 0.012853376902323 
2016-12-10 08:07:55 Test Error = 0.60996968676322 
2016-12-10 08:07:55 Test Loss = 0.012959008756108 
2016-12-10 08:07:55 -------------------LR------------------- 
2016-12-10 08:07:55 0.015625 
2016-12-10 08:07:55 Epoch 21 
2016-12-10 08:13:23 Training Error = 0.59120412748606 
2016-12-10 08:13:23 Training Loss = 0.013088603968405 
2016-12-10 08:13:31 Valid Error = 0.59415949082741 
2016-12-10 08:13:31 Valid Loss = 0.012850270226791 
2016-12-10 08:13:40 Test Error = 0.6005389019872 
2016-12-10 08:13:40 Test Loss = 0.012957020339178 
2016-12-10 08:13:40 -------------------LR------------------- 
2016-12-10 08:13:40 0.015625 
2016-12-10 08:13:40 Epoch 22 
2016-12-10 08:19:11 Training Error = 0.58999750353666 
2016-12-10 08:19:11 Training Loss = 0.013089371944827 
2016-12-10 08:19:19 Valid Error = 0.61886933732684 
2016-12-10 08:19:19 Valid Loss = 0.012857896756446 
2016-12-10 08:19:28 Test Error = 0.62512630515325 
2016-12-10 08:19:28 Test Loss = 0.012960021548873 
2016-12-10 08:19:28 -------------------LR------------------- 
2016-12-10 08:19:28 0.015625 
2016-12-10 08:19:28 Epoch 23 
2016-12-10 08:24:59 Training Error = 0.59074644253974 
2016-12-10 08:24:59 Training Loss = 0.013076360931738 
2016-12-10 08:25:07 Valid Error = 0.59528266566829 
2016-12-10 08:25:07 Valid Loss = 0.012873135513851 
2016-12-10 08:25:16 Test Error = 0.6012125294712 
2016-12-10 08:25:16 Test Loss = 0.012988608500654 
2016-12-10 08:25:16 -------------------LR------------------- 
2016-12-10 08:25:16 0.015625 
2016-12-10 08:25:16 Epoch 24 
2016-12-10 08:30:45 Training Error = 0.59174502787717 
2016-12-10 08:30:45 Training Loss = 0.013095059649231 
2016-12-10 08:30:53 Valid Error = 0.59228753275927 
2016-12-10 08:30:53 Valid Loss = 0.012838109482423 
2016-12-10 08:31:02 Test Error = 0.59514988211519 
2016-12-10 08:31:02 Test Loss = 0.012941069739717 
2016-12-10 08:31:02 -------------------LR------------------- 
2016-12-10 08:31:02 0.015625 
2016-12-10 08:31:02 Epoch 25 
2016-12-10 08:36:33 Training Error = 0.59107930431888 
2016-12-10 08:36:33 Training Loss = 0.013097376955162 
2016-12-10 08:36:41 Valid Error = 0.60202171471359 
2016-12-10 08:36:41 Valid Loss = 0.012841774829377 
2016-12-10 08:36:50 Test Error = 0.60626473560121 
2016-12-10 08:36:50 Test Loss = 0.012940332215101 
2016-12-10 08:36:50 -------------------LR------------------- 
2016-12-10 08:36:50 0.015625 
2016-12-10 08:36:50 Epoch 26 
2016-12-10 08:42:22 Training Error = 0.59008071898144 
2016-12-10 08:42:22 Training Loss = 0.013079892964841 
2016-12-10 08:42:30 Valid Error = 0.59752901535006 
2016-12-10 08:42:30 Valid Loss = 0.012864799504428 
2016-12-10 08:42:39 Test Error = 0.60289659818121 
2016-12-10 08:42:39 Test Loss = 0.012968112625768 
2016-12-10 08:42:39 -------------------LR------------------- 
2016-12-10 08:42:39 0.015625 
2016-12-10 08:42:39 Epoch 27 
2016-12-10 08:48:11 Training Error = 0.58829158691853 
2016-12-10 08:48:11 Training Loss = 0.013073196065642 
2016-12-10 08:48:19 Valid Error = 0.59228753275927 
2016-12-10 08:48:19 Valid Loss = 0.01284576012723 
2016-12-10 08:48:28 Test Error = 0.5978443920512 
2016-12-10 08:48:28 Test Loss = 0.012923046380105 
2016-12-10 08:48:28 -------------------LR------------------- 
2016-12-10 08:48:28 0.015625 
2016-12-10 08:48:28 Epoch 28 
2016-12-10 08:53:59 Training Error = 0.59012232670384 
2016-12-10 08:53:59 Training Loss = 0.013086043587898 
2016-12-10 08:54:07 Valid Error = 0.61587420441782 
2016-12-10 08:54:07 Valid Loss = 0.012930487188714 
2016-12-10 08:54:15 Test Error = 0.62175816773324 
2016-12-10 08:54:15 Test Loss = 0.013037478946716 
2016-12-10 08:54:15 -------------------LR------------------- 
2016-12-10 08:54:15 0.015625 
2016-12-10 08:54:15 Epoch 29 
2016-12-10 08:59:42 Training Error = 0.58887409503204 
2016-12-10 08:59:42 Training Loss = 0.013077415788321 
2016-12-10 08:59:50 Valid Error = 0.59116435791838 
2016-12-10 08:59:50 Valid Loss = 0.012883493433392 
2016-12-10 08:59:59 Test Error = 0.5981812057932 
2016-12-10 08:59:59 Test Loss = 0.012991164124801 
2016-12-10 08:59:59 -------------------LR------------------- 
2016-12-10 08:59:59 0.015625 
2016-12-10 08:59:59 Epoch 30 
2016-12-10 09:05:34 Training Error = 0.59003911125905 
2016-12-10 09:05:34 Training Loss = 0.013102355887802 
2016-12-10 09:05:42 Valid Error = 0.60576563084987 
2016-12-10 09:05:42 Valid Loss = 0.01289824083366 
2016-12-10 09:05:51 Test Error = 0.60996968676322 
2016-12-10 09:05:51 Test Loss = 0.012988384230999 
2016-12-10 09:05:51 -------------------LR------------------- 
2016-12-10 09:05:51 0.015625 
2016-12-10 09:05:51 Epoch 31 
2016-12-10 09:11:18 Training Error = 0.59195306648914 
2016-12-10 09:11:18 Training Loss = 0.013094930591249 
2016-12-10 09:11:26 Valid Error = 0.62972669412205 
2016-12-10 09:11:26 Valid Loss = 0.012996863099371 
2016-12-10 09:11:34 Test Error = 0.63624115863927 
2016-12-10 09:11:34 Test Loss = 0.01308628705274 
2016-12-10 09:11:34 -------------------LR------------------- 
2016-12-10 09:11:34 0.015625 
2016-12-10 09:11:34 Epoch 32 
2016-12-10 09:17:01 Training Error = 0.59153698926521 
2016-12-10 09:17:01 Training Loss = 0.013098045123139 
2016-12-10 09:17:09 Valid Error = 0.62111568700861 
2016-12-10 09:17:09 Valid Loss = 0.012966029579549 
2016-12-10 09:17:18 Test Error = 0.62782081508926 
2016-12-10 09:17:18 Test Loss = 0.013067537475366 
2016-12-10 09:17:18 -------------------LR------------------- 
2016-12-10 09:17:18 0.015625 
2016-12-10 09:17:18 Epoch 33 
2016-12-10 09:22:48 Training Error = 0.59170342015478 
2016-12-10 09:22:48 Training Loss = 0.013096251096686 
2016-12-10 09:22:56 Valid Error = 0.6061400224635 
2016-12-10 09:22:56 Valid Loss = 0.012833080310906 
2016-12-10 09:23:05 Test Error = 0.61098012798922 
2016-12-10 09:23:05 Test Loss = 0.012941012645222 
2016-12-10 09:23:05 -------------------LR------------------- 
2016-12-10 09:23:05 0.015625 
2016-12-10 09:23:05 Epoch 34 
2016-12-10 09:28:35 Training Error = 0.59199467421153 
2016-12-10 09:28:35 Training Loss = 0.013084700599469 
2016-12-10 09:28:42 Valid Error = 0.62485960314489 
2016-12-10 09:28:42 Valid Loss = 0.012905916290953 
2016-12-10 09:28:51 Test Error = 0.63118895250926 
2016-12-10 09:28:51 Test Loss = 0.01300361284417 
2016-12-10 09:28:51 -------------------LR------------------- 
2016-12-10 09:28:51 0.015625 
2016-12-10 09:28:51 Epoch 35 
2016-12-10 09:34:18 Training Error = 0.5909960888741 
2016-12-10 09:34:18 Training Loss = 0.013103721865593 
2016-12-10 09:34:26 Valid Error = 0.59790340696368 
2016-12-10 09:34:26 Valid Loss = 0.012804474752523 
2016-12-10 09:34:35 Test Error = 0.60458066689121 
2016-12-10 09:34:35 Test Loss = 0.012903770025451 
2016-12-10 09:34:35 -------------------LR------------------- 
2016-12-10 09:34:35 0.015625 
2016-12-10 09:34:35 Epoch 36 
2016-12-10 09:40:06 Training Error = 0.59120412748606 
2016-12-10 09:40:06 Training Loss = 0.013104570679049 
2016-12-10 09:40:14 Valid Error = 0.62485960314489 
2016-12-10 09:40:14 Valid Loss = 0.012949336768657 
2016-12-10 09:40:23 Test Error = 0.63118895250926 
2016-12-10 09:40:23 Test Loss = 0.0130531733049 
2016-12-10 09:40:23 -------------------LR------------------- 
2016-12-10 09:40:23 0.015625 
2016-12-10 09:40:23 Epoch 37 
2016-12-10 09:45:52 Training Error = 0.59132895065324 
2016-12-10 09:45:52 Training Loss = 0.013088259556634 
2016-12-10 09:46:00 Valid Error = 0.62111568700861 
2016-12-10 09:46:00 Valid Loss = 0.012913055056896 
2016-12-10 09:46:09 Test Error = 0.62782081508926 
2016-12-10 09:46:09 Test Loss = 0.013006321049848 
2016-12-10 09:46:09 -------------------LR------------------- 
2016-12-10 09:46:09 0.015625 
2016-12-10 09:46:09 Epoch 38 
2016-12-10 09:51:32 Training Error = 0.58958142631272 
2016-12-10 09:51:32 Training Loss = 0.013076379682024 
2016-12-10 09:51:40 Valid Error = 0.61175589666791 
2016-12-10 09:51:40 Valid Loss = 0.012896411144924 
2016-12-10 09:51:48 Test Error = 0.61872684405524 
2016-12-10 09:51:48 Test Loss = 0.012981790318678 
2016-12-10 09:51:48 -------------------LR------------------- 
2016-12-10 09:51:48 0.015625 
2016-12-10 09:51:48 Epoch 39 
2016-12-10 09:57:19 Training Error = 0.59074644253974 
2016-12-10 09:57:19 Training Loss = 0.013094901879193 
2016-12-10 09:57:27 Valid Error = 0.60763758891801 
2016-12-10 09:57:27 Valid Loss = 0.012957184594845 
2016-12-10 09:57:36 Test Error = 0.61300101044123 
2016-12-10 09:57:36 Test Loss = 0.01303962594 
2016-12-10 09:57:36 -------------------LR------------------- 
2016-12-10 09:57:36 0.015625 
2016-12-10 09:57:36 Epoch 40 
2016-12-10 10:03:12 Training Error = 0.59336772905051 
2016-12-10 10:03:12 Training Loss = 0.013087089025011 
2016-12-10 10:03:20 Valid Error = 0.60202171471359 
2016-12-10 10:03:20 Valid Loss = 0.012809960255898 
2016-12-10 10:03:29 Test Error = 0.60458066689121 
2016-12-10 10:03:29 Test Loss = 0.012896809300918 
2016-12-10 10:03:29 -------------------LR------------------- 
2016-12-10 10:03:29 0.015625 
2016-12-10 10:03:29 Epoch 41 
2016-12-10 10:08:59 Training Error = 0.59178663559957 
2016-12-10 10:08:59 Training Loss = 0.01309964153817 
2016-12-10 10:09:07 Valid Error = 0.59415949082741 
2016-12-10 10:09:07 Valid Loss = 0.012857901902485 
2016-12-10 10:09:16 Test Error = 0.6008757157292 
2016-12-10 10:09:16 Test Loss = 0.012967766245909 
2016-12-10 10:09:16 -------------------LR------------------- 
2016-12-10 10:09:16 0.015625 
2016-12-10 10:09:16 Epoch 42 
2016-12-10 10:14:49 Training Error = 0.59132895065324 
2016-12-10 10:14:49 Training Loss = 0.013092489228523 
2016-12-10 10:14:57 Valid Error = 0.63122426057656 
2016-12-10 10:14:57 Valid Loss = 0.012881000918229 
2016-12-10 10:15:06 Test Error = 0.63523071741327 
2016-12-10 10:15:06 Test Loss = 0.012975913152309 
2016-12-10 10:15:06 -------------------LR------------------- 
2016-12-10 10:15:06 0.015625 
2016-12-10 10:15:06 Epoch 43 
2016-12-10 10:20:41 Training Error = 0.58991428809187 
2016-12-10 10:20:41 Training Loss = 0.013097306933439 
2016-12-10 10:20:49 Valid Error = 0.59378509921378 
2016-12-10 10:20:49 Valid Loss = 0.012877648836632 
2016-12-10 10:20:57 Test Error = 0.6005389019872 
2016-12-10 10:20:57 Test Loss = 0.012984478673043 
2016-12-10 10:20:57 -------------------LR------------------- 
2016-12-10 10:20:57 0.015625 
2016-12-10 10:20:57 Epoch 44 
2016-12-10 10:26:28 Training Error = 0.59053840392777 
2016-12-10 10:26:28 Training Loss = 0.013086962126002 
2016-12-10 10:26:36 Valid Error = 0.60539123923624 
2016-12-10 10:26:36 Valid Loss = 0.012850586885175 
2016-12-10 10:26:44 Test Error = 0.61098012798922 
2016-12-10 10:26:44 Test Loss = 0.012957945011678 
2016-12-10 10:26:44 -------------------LR------------------- 
2016-12-10 10:26:44 0.015625 
2016-12-10 10:26:44 Epoch 45 
2016-12-10 10:32:18 Training Error = 0.58966464175751 
2016-12-10 10:32:18 Training Loss = 0.01307702095778 
2016-12-10 10:32:26 Valid Error = 0.59827779857731 
2016-12-10 10:32:26 Valid Loss = 0.012824047086555 
2016-12-10 10:32:34 Test Error = 0.6015493432132 
2016-12-10 10:32:34 Test Loss = 0.012931229712763 
2016-12-10 10:32:34 -------------------LR------------------- 
2016-12-10 10:32:34 0.015625 
2016-12-10 10:32:34 Epoch 46 
2016-12-10 10:38:07 Training Error = 0.59386702171923 
2016-12-10 10:38:07 Training Loss = 0.013094455665484 
2016-12-10 10:38:15 Valid Error = 0.59603144889554 
2016-12-10 10:38:15 Valid Loss = 0.012871744807898 
2016-12-10 10:38:24 Test Error = 0.6018861569552 
2016-12-10 10:38:24 Test Loss = 0.012996653987635 
2016-12-10 10:38:24 -------------------LR------------------- 
2016-12-10 10:38:24 0.015625 
2016-12-10 10:38:24 Epoch 47 
2016-12-10 10:43:56 Training Error = 0.58983107264708 
2016-12-10 10:43:56 Training Loss = 0.013095656223066 
2016-12-10 10:44:04 Valid Error = 0.59228753275927 
2016-12-10 10:44:04 Valid Loss = 0.012853781752565 
2016-12-10 10:44:13 Test Error = 0.5978443920512 
2016-12-10 10:44:13 Test Loss = 0.012950662925513 
2016-12-10 10:44:13 -------------------LR------------------- 
2016-12-10 10:44:13 0.015625 
2016-12-10 10:44:13 Epoch 48 
2016-12-10 10:49:49 Training Error = 0.59211949737871 
2016-12-10 10:49:49 Training Loss = 0.013092402585546 
2016-12-10 10:49:57 Valid Error = 0.59790340696368 
2016-12-10 10:49:57 Valid Loss = 0.012833192158437 
2016-12-10 10:50:05 Test Error = 0.60390703940721 
2016-12-10 10:50:05 Test Loss = 0.012944721652861 
2016-12-10 10:50:05 -------------------LR------------------- 
2016-12-10 10:50:05 0.015625 
2016-12-10 10:50:05 Epoch 49 
2016-12-10 10:55:33 Training Error = 0.59082965798452 
2016-12-10 10:55:33 Training Loss = 0.013102132403178 
2016-12-10 10:55:41 Valid Error = 0.59640584050917 
2016-12-10 10:55:41 Valid Loss = 0.012850109561498 
2016-12-10 10:55:50 Test Error = 0.6022229706972 
2016-12-10 10:55:50 Test Loss = 0.012940646663809 
2016-12-10 10:55:50 -------------------LR------------------- 
2016-12-10 10:55:50 0.015625 
2016-12-10 10:55:50 Epoch 50 
2016-12-10 11:01:34 Training Error = 0.59020554214862 
2016-12-10 11:01:34 Training Loss = 0.013095904639719 
2016-12-10 11:01:42 Valid Error = 0.58667165855485 
2016-12-10 11:01:42 Valid Loss = 0.01285654317152 
2016-12-10 11:01:51 Test Error = 0.59413944088919 
2016-12-10 11:01:51 Test Loss = 0.012963898041561 
2016-12-10 11:01:51 -------------------LR------------------- 
2016-12-10 11:01:51 0.0078125 
2016-12-10 11:01:51 Epoch 51 
2016-12-10 11:07:20 Training Error = 0.59386702171923 
2016-12-10 11:07:20 Training Loss = 0.013098214849024 
2016-12-10 11:07:28 Valid Error = 0.59603144889554 
2016-12-10 11:07:28 Valid Loss = 0.012807929698712 
2016-12-10 11:07:37 Test Error = 0.5991916470192 
2016-12-10 11:07:37 Test Loss = 0.012905202720666 
2016-12-10 11:07:37 -------------------LR------------------- 
2016-12-10 11:07:37 0.0078125 
2016-12-10 11:07:37 Epoch 52 
2016-12-10 11:13:13 Training Error = 0.59440792211034 
2016-12-10 11:13:13 Training Loss = 0.013091943184753 
2016-12-10 11:13:21 Valid Error = 0.60164732309996 
2016-12-10 11:13:21 Valid Loss = 0.01276823064062 
2016-12-10 11:13:30 Test Error = 0.60424385314921 
2016-12-10 11:13:30 Test Loss = 0.012866095695702 
2016-12-10 11:13:30 -------------------LR------------------- 
2016-12-10 11:13:30 0.0078125 
2016-12-10 11:13:30 Epoch 53 
2016-12-10 11:18:58 Training Error = 0.58924856453358 
2016-12-10 11:18:58 Training Loss = 0.01309550332408 
2016-12-10 11:19:06 Valid Error = 0.61100711344066 
2016-12-10 11:19:06 Valid Loss = 0.012924021766645 
2016-12-10 11:19:15 Test Error = 0.61839003031324 
2016-12-10 11:19:15 Test Loss = 0.01301715705469 
2016-12-10 11:19:15 -------------------LR------------------- 
2016-12-10 11:19:15 0.0078125 
2016-12-10 11:19:15 Epoch 54 
2016-12-10 11:24:46 Training Error = 0.59049679620538 
2016-12-10 11:24:46 Training Loss = 0.013094396066624 
2016-12-10 11:24:54 Valid Error = 0.62673156121303 
2016-12-10 11:24:54 Valid Loss = 0.012866792127759 
2016-12-10 11:25:03 Test Error = 0.63186257999326 
2016-12-10 11:25:03 Test Loss = 0.012962874498699 
2016-12-10 11:25:03 -------------------LR------------------- 
2016-12-10 11:25:03 0.0078125 
2016-12-10 11:25:03 Epoch 55 
2016-12-10 11:30:18 Training Error = 0.58887409503204 
2016-12-10 11:30:18 Training Loss = 0.013098544020335 
2016-12-10 11:30:26 Valid Error = 0.59191314114564 
2016-12-10 11:30:26 Valid Loss = 0.012850599618859 
2016-12-10 11:30:35 Test Error = 0.59616032334119 
2016-12-10 11:30:35 Test Loss = 0.012972463756553 
2016-12-10 11:30:35 -------------------LR------------------- 
2016-12-10 11:30:35 0.0078125 
2016-12-10 11:30:35 Epoch 56 
2016-12-10 11:35:54 Training Error = 0.58978946492469 
2016-12-10 11:35:54 Training Loss = 0.013097559191316 
2016-12-10 11:36:02 Valid Error = 0.64283040059903 
2016-12-10 11:36:02 Valid Loss = 0.012892925429254 
2016-12-10 11:36:10 Test Error = 0.6480296396093 
2016-12-10 11:36:10 Test Loss = 0.012988545975031 
2016-12-10 11:36:10 -------------------LR------------------- 
2016-12-10 11:36:10 0.0078125 
2016-12-10 11:36:10 Epoch 57 
2016-12-10 11:41:25 Training Error = 0.59166181243239 
2016-12-10 11:41:25 Training Loss = 0.013093083719627 
2016-12-10 11:41:33 Valid Error = 0.62373642830401 
2016-12-10 11:41:33 Valid Loss = 0.01289827996678 
2016-12-10 11:41:42 Test Error = 0.63118895250926 
2016-12-10 11:41:42 Test Loss = 0.012992762101161 
2016-12-10 11:41:42 -------------------LR------------------- 
2016-12-10 11:41:42 0.0078125 
2016-12-10 11:41:42 Epoch 58 
2016-12-10 11:46:56 Training Error = 0.59045518848298 
2016-12-10 11:46:56 Training Loss = 0.013089516290298 
2016-12-10 11:47:04 Valid Error = 0.60089853987271 
2016-12-10 11:47:04 Valid Loss = 0.012872767942582 
2016-12-10 11:47:13 Test Error = 0.60727517682721 
2016-12-10 11:47:13 Test Loss = 0.012961754906262 
2016-12-10 11:47:13 -------------------LR------------------- 
2016-12-10 11:47:13 0.0078125 
2016-12-10 11:47:13 Epoch 59 
2016-12-10 11:52:28 Training Error = 0.59070483481734 
2016-12-10 11:52:28 Training Loss = 0.013104005214165 
2016-12-10 11:52:36 Valid Error = 0.59603144889554 
2016-12-10 11:52:36 Valid Loss = 0.012878885080258 
2016-12-10 11:52:45 Test Error = 0.6015493432132 
2016-12-10 11:52:45 Test Loss = 0.012984240550368 
2016-12-10 11:52:45 -------------------LR------------------- 
2016-12-10 11:52:45 0.0078125 
2016-12-10 11:52:45 Epoch 60 
2016-12-10 11:58:04 Training Error = 0.58841641008571 
2016-12-10 11:58:04 Training Loss = 0.013099320186891 
2016-12-10 11:58:12 Valid Error = 0.63721452639461 
2016-12-10 11:58:12 Valid Loss = 0.01297770404602 
2016-12-10 11:58:20 Test Error = 0.64466150218929 
2016-12-10 11:58:20 Test Loss = 0.013079480201322 
2016-12-10 11:58:20 -------------------LR------------------- 
2016-12-10 11:58:20 0.0078125 
2016-12-10 11:58:20 Epoch 61 
2016-12-10 12:03:38 Training Error = 0.5897062494799 
2016-12-10 12:03:38 Training Loss = 0.013097754846634 
2016-12-10 12:03:46 Valid Error = 0.59640584050917 
2016-12-10 12:03:46 Valid Loss = 0.012872311531438 
2016-12-10 12:03:55 Test Error = 0.5995284607612 
2016-12-10 12:03:55 Test Loss = 0.012967310650294 
2016-12-10 12:03:55 -------------------LR------------------- 
2016-12-10 12:03:55 0.0078125 
2016-12-10 12:03:55 Epoch 62 
2016-12-10 12:09:14 Training Error = 0.59103769659649 
2016-12-10 12:09:14 Training Loss = 0.013091318103774 
2016-12-10 12:09:21 Valid Error = 0.6061400224635 
2016-12-10 12:09:21 Valid Loss = 0.0128461785321 
2016-12-10 12:09:30 Test Error = 0.60828561805322 
2016-12-10 12:09:30 Test Loss = 0.012948949103768 
2016-12-10 12:09:30 -------------------LR------------------- 
2016-12-10 12:09:30 0.0078125 
2016-12-10 12:09:30 Epoch 63 
2016-12-10 12:14:43 Training Error = 0.58924856453358 
2016-12-10 12:14:43 Training Loss = 0.013079035729611 
2016-12-10 12:14:51 Valid Error = 0.61849494571322 
2016-12-10 12:14:51 Valid Loss = 0.012945729074446 
2016-12-10 12:14:59 Test Error = 0.62344223644325 
2016-12-10 12:14:59 Test Loss = 0.0130408946312 
2016-12-10 12:14:59 -------------------LR------------------- 
2016-12-10 12:14:59 0.0078125 
2016-12-10 12:15:00 Epoch 64 
2016-12-10 12:20:16 Training Error = 0.59191145876675 
2016-12-10 12:20:16 Training Loss = 0.013087718256995 
2016-12-10 12:20:24 Valid Error = 0.60651441407712 
2016-12-10 12:20:24 Valid Loss = 0.012864142769218 
2016-12-10 12:20:33 Test Error = 0.61266419669923 
2016-12-10 12:20:33 Test Loss = 0.012962541228361 
2016-12-10 12:20:33 -------------------LR------------------- 
2016-12-10 12:20:33 0.0078125 
2016-12-10 12:20:33 Epoch 65 
2016-12-10 12:25:49 Training Error = 0.59241075143547 
2016-12-10 12:25:49 Training Loss = 0.013083306137027 
2016-12-10 12:25:57 Valid Error = 0.59415949082741 
2016-12-10 12:25:57 Valid Loss = 0.012878633647903 
2016-12-10 12:26:05 Test Error = 0.5995284607612 
2016-12-10 12:26:05 Test Loss = 0.012979742914973 
2016-12-10 12:26:05 -------------------LR------------------- 
2016-12-10 12:26:05 0.0078125 
2016-12-10 12:26:06 Epoch 66 
2016-12-10 12:31:20 Training Error = 0.58991428809187 
2016-12-10 12:31:20 Training Loss = 0.013086381579712 
2016-12-10 12:31:28 Valid Error = 0.6263571695994 
2016-12-10 12:31:28 Valid Loss = 0.0128609813901 
2016-12-10 12:31:37 Test Error = 0.62883125631526 
2016-12-10 12:31:37 Test Loss = 0.012967652906219 
2016-12-10 12:31:37 -------------------LR------------------- 
2016-12-10 12:31:37 0.0078125 
2016-12-10 12:31:37 Epoch 67 
2016-12-10 12:36:54 Training Error = 0.59116251976367 
2016-12-10 12:36:54 Training Loss = 0.013100768316349 
2016-12-10 12:37:02 Valid Error = 0.59865219019094 
2016-12-10 12:37:02 Valid Loss = 0.012869840069899 
2016-12-10 12:37:10 Test Error = 0.60357022566521 
2016-12-10 12:37:10 Test Loss = 0.012967168833892 
2016-12-10 12:37:10 -------------------LR------------------- 
2016-12-10 12:37:10 0.0078125 
2016-12-10 12:37:11 Epoch 68 
2016-12-10 12:42:31 Training Error = 0.59107930431888 
2016-12-10 12:42:31 Training Loss = 0.013095917118732 
2016-12-10 12:42:39 Valid Error = 0.58704605016848 
2016-12-10 12:42:39 Valid Loss = 0.012832478503404 
2016-12-10 12:42:48 Test Error = 0.59144493095318 
2016-12-10 12:42:48 Test Loss = 0.012931183138261 
2016-12-10 12:42:48 -------------------LR------------------- 
2016-12-10 12:42:48 0.0078125 
2016-12-10 12:42:48 Epoch 69 
