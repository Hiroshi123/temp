2016-12-10 06:48:51 [program started on Sat Dec 10 06:48:51 2016] 
2016-12-10 06:48:51 [command line arguments] 
2016-12-10 06:48:51 stcWeights false 
2016-12-10 06:48:51 LR 0.015625 
2016-12-10 06:48:51 batchSize 64 
2016-12-10 06:48:51 network ./Models/Cifar10_Custom 
2016-12-10 06:48:51 stcNeurons true 
2016-12-10 06:48:51 constBatchSize false 
2016-12-10 06:48:51 chartFileName chart1 
2016-12-10 06:48:51 dp_prepro false 
2016-12-10 06:48:51 nGPU 1 
2016-12-10 06:48:51 dataset Caltech256 
2016-12-10 06:48:51 type cuda 
2016-12-10 06:48:51 momentum 0 
2016-12-10 06:48:51 threads 8 
2016-12-10 06:48:51 weightDecay 0 
2016-12-10 06:48:51 runningVal false 
2016-12-10 06:48:51 convLayerN 4 
2016-12-10 06:48:51 LRDecay 0 
2016-12-10 06:48:51 numHid 1024 
2016-12-10 06:48:51 save /dev/shm/clone/temp/th/Results/Caltech256/model4-20 
2016-12-10 06:48:51 augment false 
2016-12-10 06:48:51 epoch -1 
2016-12-10 06:48:51 modelsFolder ./Models/ 
2016-12-10 06:48:51 format rgb 
2016-12-10 06:48:51 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech256 
2016-12-10 06:48:51 imageFileExtension svg 
2016-12-10 06:48:51 channel 2 
2016-12-10 06:48:51 devid 1 
2016-12-10 06:48:51 visualize 1 
2016-12-10 06:48:51 LRDecayPerEpoch 0.0001 
2016-12-10 06:48:51 optimization adam 
2016-12-10 06:48:51 SBN true 
2016-12-10 06:48:51 normalization simple 
2016-12-10 06:48:51 title model1 
2016-12-10 06:48:51 load  
2016-12-10 06:48:51 whiten true 
2016-12-10 06:48:51 [----------------------] 
2016-12-10 06:48:53 ==> Network 
2016-12-10 06:48:53 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 256, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): nn.View(32768)
  (20): BinaryLinear(32768 -> 1024)
  (21): BatchNormalizationShiftPow2
  (22): nn.HardTanh
  (23): BinarizedNeurons
  (24): BinaryLinear(1024 -> 1024)
  (25): BatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): BinaryLinear(1024 -> 255)
  (29): nn.BatchNormalization
} 
2016-12-10 06:48:53 ==>39011325 Parameters 
2016-12-10 06:48:53 ==> Loss 
2016-12-10 06:48:53 SqrtHingeEmbeddingCriterion 
2016-12-10 06:48:53 
==> Starting Training
 
2016-12-10 06:48:53 Epoch 1 
2016-12-10 06:57:54 Training Error = 0.95443954397936 
2016-12-10 06:57:54 Training Loss = 0.11150781258507 
2016-12-10 06:58:05 Valid Error = 0.93934855859229 
2016-12-10 06:58:05 Valid Loss = 0.015683306822521 
2016-12-10 06:58:18 Test Error = 0.9514988211519 
2016-12-10 06:58:18 Test Loss = 0.015700160814714 
2016-12-10 06:58:18 -------------------LR------------------- 
2016-12-10 06:58:18 0.015625 
2016-12-10 06:58:18 Epoch 2 
2016-12-10 07:07:21 Training Error = 0.90005825081135 
2016-12-10 07:07:21 Training Loss = 0.015237658953514 
2016-12-10 07:07:32 Valid Error = 0.95844253088731 
2016-12-10 07:07:32 Valid Loss = 0.015743201035724 
2016-12-10 07:07:45 Test Error = 0.95756146850792 
2016-12-10 07:07:45 Test Loss = 0.015751583813925 
2016-12-10 07:07:45 -------------------LR------------------- 
2016-12-10 07:07:45 0.015625 
2016-12-10 07:07:45 Epoch 3 
2016-12-10 07:16:52 Training Error = 0.86061412998252 
2016-12-10 07:16:52 Training Loss = 0.014727147199083 
2016-12-10 07:17:03 Valid Error = 0.8588543616623 
2016-12-10 07:17:03 Valid Loss = 0.014946872028015 
2016-12-10 07:17:16 Test Error = 0.86763219939374 
2016-12-10 07:17:16 Test Loss = 0.015125309957282 
2016-12-10 07:17:16 -------------------LR------------------- 
2016-12-10 07:17:16 0.015625 
2016-12-10 07:17:16 Epoch 4 
2016-12-10 07:26:29 Training Error = 0.76782890904552 
2016-12-10 07:26:29 Training Loss = 0.014190944326345 
2016-12-10 07:26:40 Valid Error = 0.72332459752902 
2016-12-10 07:26:40 Valid Loss = 0.014357236350684 
2016-12-10 07:26:53 Test Error = 0.71505557426743 
2016-12-10 07:26:53 Test Loss = 0.014330322817857 
2016-12-10 07:26:53 -------------------LR------------------- 
2016-12-10 07:26:53 0.015625 
2016-12-10 07:26:54 Epoch 5 
2016-12-10 07:36:00 Training Error = 0.65910793043189 
2016-12-10 07:36:00 Training Loss = 0.013595597679453 
2016-12-10 07:36:12 Valid Error = 0.54548858105578 
2016-12-10 07:36:12 Valid Loss = 0.012641716746567 
2016-12-10 07:36:25 Test Error = 0.54227012462108 
2016-12-10 07:36:25 Test Loss = 0.012581982063163 
2016-12-10 07:36:25 -------------------LR------------------- 
2016-12-10 07:36:25 0.015625 
2016-12-10 07:36:25 Epoch 6 
2016-12-10 07:45:34 Training Error = 0.5463926104685 
2016-12-10 07:45:34 Training Loss = 0.013119628063497 
2016-12-10 07:45:45 Valid Error = 0.43728940471733 
2016-12-10 07:45:45 Valid Loss = 0.011507778705596 
2016-12-10 07:45:58 Test Error = 0.43651060963287 
2016-12-10 07:45:58 Test Loss = 0.011403283904978 
2016-12-10 07:45:58 -------------------LR------------------- 
2016-12-10 07:45:58 0.015625 
2016-12-10 07:45:59 Epoch 7 
2016-12-10 07:55:07 Training Error = 0.44765748522926 
2016-12-10 07:55:07 Training Loss = 0.012682903773091 
2016-12-10 07:55:19 Valid Error = 0.62411081991763 
2016-12-10 07:55:19 Valid Loss = 0.014149144521063 
2016-12-10 07:55:32 Test Error = 0.60996968676322 
2016-12-10 07:55:32 Test Loss = 0.01392699165567 
2016-12-10 07:55:32 -------------------LR------------------- 
2016-12-10 07:55:32 0.015625 
2016-12-10 07:55:32 Epoch 8 
2016-12-10 08:03:51 Training Error = 0.37134892235999 
2016-12-10 08:03:51 Training Loss = 0.012329753706267 
2016-12-10 08:04:02 Valid Error = 0.27704979408461 
2016-12-10 08:04:02 Valid Loss = 0.0094172176218839 
2016-12-10 08:04:15 Test Error = 0.27955540586056 
2016-12-10 08:04:15 Test Loss = 0.0093805854974014 
2016-12-10 08:04:15 -------------------LR------------------- 
2016-12-10 08:04:15 0.015625 
2016-12-10 08:04:15 Epoch 9 
2016-12-10 08:12:31 Training Error = 0.31829907630856 
2016-12-10 08:12:31 Training Loss = 0.012021112256689 
2016-12-10 08:12:43 Valid Error = 0.25121677274429 
2016-12-10 08:12:43 Valid Loss = 0.0088078463385651 
2016-12-10 08:12:56 Test Error = 0.2482317278545 
2016-12-10 08:12:56 Test Loss = 0.0087378971866135 
2016-12-10 08:12:56 -------------------LR------------------- 
2016-12-10 08:12:56 0.015625 
2016-12-10 08:12:56 Epoch 10 
2016-12-10 08:21:21 Training Error = 0.27702421569443 
2016-12-10 08:21:21 Training Loss = 0.011766525022723 
2016-12-10 08:21:32 Valid Error = 0.22276301010857 
2016-12-10 08:21:32 Valid Loss = 0.0080817115923303 
2016-12-10 08:21:45 Test Error = 0.22061300101044 
2016-12-10 08:21:45 Test Loss = 0.0080391028547068 
2016-12-10 08:21:45 -------------------LR------------------- 
2016-12-10 08:21:45 0.015625 
2016-12-10 08:21:45 Epoch 11 
2016-12-10 08:30:13 Training Error = 0.25035366564034 
2016-12-10 08:30:13 Training Loss = 0.011550543004245 
2016-12-10 08:30:24 Valid Error = 0.21040808685885 
2016-12-10 08:30:24 Valid Loss = 0.0078173556678696 
2016-12-10 08:30:37 Test Error = 0.20815089255642 
2016-12-10 08:30:37 Test Loss = 0.0078146781989023 
2016-12-10 08:30:37 -------------------LR------------------- 
2016-12-10 08:30:37 0.015625 
2016-12-10 08:30:37 Epoch 12 
2016-12-10 08:39:05 Training Error = 0.25201797453607 
2016-12-10 08:39:05 Training Loss = 0.011535275878665 
2016-12-10 08:39:17 Valid Error = 0.20816173717709 
2016-12-10 08:39:17 Valid Loss = 0.0079139422240245 
2016-12-10 08:39:30 Test Error = 0.20478275513641 
2016-12-10 08:39:30 Test Loss = 0.0078953661785356 
2016-12-10 08:39:30 -------------------LR------------------- 
2016-12-10 08:39:30 0.015625 
2016-12-10 08:39:30 Epoch 13 
2016-12-10 08:48:02 Training Error = 0.25189315136889 
2016-12-10 08:48:02 Training Loss = 0.011538151481049 
2016-12-10 08:48:14 Valid Error = 0.21040808685885 
2016-12-10 08:48:14 Valid Loss = 0.0079138749501232 
2016-12-10 08:48:27 Test Error = 0.20815089255642 
2016-12-10 08:48:27 Test Loss = 0.007917143250387 
2016-12-10 08:48:27 -------------------LR------------------- 
2016-12-10 08:48:27 0.015625 
2016-12-10 08:48:27 Epoch 14 
2016-12-10 08:56:52 Training Error = 0.25135225097778 
2016-12-10 08:56:52 Training Loss = 0.011535716404514 
2016-12-10 08:57:04 Valid Error = 0.20816173717709 
2016-12-10 08:57:04 Valid Loss = 0.0079059458234577 
2016-12-10 08:57:17 Test Error = 0.20579319636241 
2016-12-10 08:57:17 Test Loss = 0.0079121371978613 
2016-12-10 08:57:17 -------------------LR------------------- 
2016-12-10 08:57:17 0.015625 
2016-12-10 08:57:17 Epoch 15 
2016-12-10 09:05:42 Training Error = 0.24943829574769 
2016-12-10 09:05:42 Training Loss = 0.011528509055598 
2016-12-10 09:05:54 Valid Error = 0.21040808685885 
2016-12-10 09:05:54 Valid Loss = 0.0078561533287682 
2016-12-10 09:06:07 Test Error = 0.20815089255642 
2016-12-10 09:06:07 Test Loss = 0.0078526011432366 
2016-12-10 09:06:07 -------------------LR------------------- 
2016-12-10 09:06:07 0.015625 
2016-12-10 09:06:07 Epoch 16 
2016-12-10 09:14:32 Training Error = 0.24923025713572 
2016-12-10 09:14:32 Training Loss = 0.011525675024342 
2016-12-10 09:14:44 Valid Error = 0.20928491201797 
2016-12-10 09:14:44 Valid Loss = 0.0079206676501816 
2016-12-10 09:14:57 Test Error = 0.20714045133041 
2016-12-10 09:14:57 Test Loss = 0.0079111425457868 
2016-12-10 09:14:57 -------------------LR------------------- 
2016-12-10 09:14:57 0.015625 
2016-12-10 09:14:57 Epoch 17 
2016-12-10 09:23:23 Training Error = 0.25131064325539 
2016-12-10 09:23:23 Training Loss = 0.011552820227863 
2016-12-10 09:23:35 Valid Error = 0.21677274429053 
2016-12-10 09:23:35 Valid Loss = 0.0079115972088946 
2016-12-10 09:23:48 Test Error = 0.21522398113843 
2016-12-10 09:23:48 Test Loss = 0.0078655573276365 
2016-12-10 09:23:48 -------------------LR------------------- 
2016-12-10 09:23:48 0.015625 
2016-12-10 09:23:48 Epoch 18 
2016-12-10 09:32:15 Training Error = 0.25089456603146 
2016-12-10 09:32:15 Training Loss = 0.011544478287881 
2016-12-10 09:32:26 Valid Error = 0.2163983526769 
2016-12-10 09:32:26 Valid Loss = 0.0079563391858253 
2016-12-10 09:32:39 Test Error = 0.21623442236443 
2016-12-10 09:32:39 Test Loss = 0.0079251818030289 
2016-12-10 09:32:39 -------------------LR------------------- 
2016-12-10 09:32:39 0.015625 
2016-12-10 09:32:39 Epoch 19 
2016-12-10 09:41:08 Training Error = 0.2499791961388 
2016-12-10 09:41:08 Training Loss = 0.011539760850924 
2016-12-10 09:41:19 Valid Error = 0.21153126169974 
2016-12-10 09:41:19 Valid Loss = 0.007886296850655 
2016-12-10 09:41:32 Test Error = 0.20815089255642 
2016-12-10 09:41:32 Test Loss = 0.007863756322244 
2016-12-10 09:41:32 -------------------LR------------------- 
2016-12-10 09:41:32 0.015625 
2016-12-10 09:41:32 Epoch 20 
2016-12-10 09:50:06 Training Error = 0.25147707414496 
2016-12-10 09:50:06 Training Loss = 0.011556724253109 
2016-12-10 09:50:18 Valid Error = 0.21190565331337 
2016-12-10 09:50:18 Valid Loss = 0.007899196245679 
2016-12-10 09:50:31 Test Error = 0.20916133378242 
2016-12-10 09:50:31 Test Loss = 0.0078884882801615 
2016-12-10 09:50:31 -------------------LR------------------- 
2016-12-10 09:50:31 0.015625 
2016-12-10 09:50:31 Epoch 21 
2016-12-10 09:59:00 Training Error = 0.24985437297162 
2016-12-10 09:59:00 Training Loss = 0.011525220214968 
2016-12-10 09:59:12 Valid Error = 0.21040808685885 
2016-12-10 09:59:12 Valid Loss = 0.0078933101723262 
2016-12-10 09:59:25 Test Error = 0.20815089255642 
2016-12-10 09:59:25 Test Loss = 0.0078872801590125 
2016-12-10 09:59:25 -------------------LR------------------- 
2016-12-10 09:59:25 0.015625 
2016-12-10 09:59:25 Epoch 22 
2016-12-10 10:07:52 Training Error = 0.25047848880752 
2016-12-10 10:07:52 Training Loss = 0.011552802913569 
2016-12-10 10:08:04 Valid Error = 0.20816173717709 
2016-12-10 10:08:04 Valid Loss = 0.0078954802270957 
2016-12-10 10:08:17 Test Error = 0.20478275513641 
2016-12-10 10:08:17 Test Loss = 0.0078736954359994 
2016-12-10 10:08:17 -------------------LR------------------- 
2016-12-10 10:08:17 0.015625 
2016-12-10 10:08:17 Epoch 23 
2016-12-10 10:16:46 Training Error = 0.24835649496547 
2016-12-10 10:16:46 Training Loss = 0.011517153603861 
2016-12-10 10:16:57 Valid Error = 0.21415200299513 
2016-12-10 10:16:57 Valid Loss = 0.0079010012084116 
2016-12-10 10:17:10 Test Error = 0.21252947120243 
2016-12-10 10:17:10 Test Loss = 0.0078814396100289 
2016-12-10 10:17:10 -------------------LR------------------- 
2016-12-10 10:17:10 0.015625 
2016-12-10 10:17:10 Epoch 24 
2016-12-10 10:25:48 Training Error = 0.24927186485812 
2016-12-10 10:25:48 Training Loss = 0.01153582283206 
2016-12-10 10:25:59 Valid Error = 0.21415200299513 
2016-12-10 10:25:59 Valid Loss = 0.0079442102273409 
2016-12-10 10:26:12 Test Error = 0.21252947120243 
2016-12-10 10:26:12 Test Loss = 0.0079158761359077 
2016-12-10 10:26:12 -------------------LR------------------- 
2016-12-10 10:26:12 0.015625 
2016-12-10 10:26:12 Epoch 25 
2016-12-10 10:34:46 Training Error = 0.24977115752684 
2016-12-10 10:34:46 Training Loss = 0.011519540332748 
2016-12-10 10:34:58 Valid Error = 0.21939348558592 
2016-12-10 10:34:58 Valid Loss = 0.0079786121060179 
2016-12-10 10:35:11 Test Error = 0.21926574604244 
2016-12-10 10:35:11 Test Loss = 0.0079336066614055 
2016-12-10 10:35:11 -------------------LR------------------- 
2016-12-10 10:35:11 0.015625 
2016-12-10 10:35:11 Epoch 26 
2016-12-10 10:43:45 Training Error = 0.2499791961388 
2016-12-10 10:43:45 Training Loss = 0.01153746583704 
2016-12-10 10:43:56 Valid Error = 0.21415200299513 
2016-12-10 10:43:56 Valid Loss = 0.0078322708996293 
2016-12-10 10:44:09 Test Error = 0.21252947120243 
2016-12-10 10:44:09 Test Loss = 0.0078302796236117 
2016-12-10 10:44:09 -------------------LR------------------- 
2016-12-10 10:44:09 0.015625 
2016-12-10 10:44:09 Epoch 27 
2016-12-10 10:52:42 Training Error = 0.25097778147624 
2016-12-10 10:52:42 Training Loss = 0.011545811130324 
2016-12-10 10:52:54 Valid Error = 0.21415200299513 
2016-12-10 10:52:54 Valid Loss = 0.0079373845248976 
2016-12-10 10:53:07 Test Error = 0.21252947120243 
2016-12-10 10:53:07 Test Loss = 0.0079183128812087 
2016-12-10 10:53:07 -------------------LR------------------- 
2016-12-10 10:53:07 0.015625 
2016-12-10 10:53:07 Epoch 28 
2016-12-10 11:01:46 Training Error = 0.2524756594824 
2016-12-10 11:01:46 Training Loss = 0.011549029387522 
2016-12-10 11:01:58 Valid Error = 0.20816173717709 
2016-12-10 11:01:58 Valid Loss = 0.0079042746364865 
2016-12-10 11:02:11 Test Error = 0.20478275513641 
2016-12-10 11:02:11 Test Loss = 0.007875778638675 
2016-12-10 11:02:11 -------------------LR------------------- 
2016-12-10 11:02:11 0.015625 
2016-12-10 11:02:11 Epoch 29 
2016-12-10 11:10:41 Training Error = 0.25131064325539 
2016-12-10 11:10:41 Training Loss = 0.011533449974355 
2016-12-10 11:10:52 Valid Error = 0.21003369524523 
2016-12-10 11:10:52 Valid Loss = 0.0079305841868433 
2016-12-10 11:11:05 Test Error = 0.20781407881442 
2016-12-10 11:11:05 Test Loss = 0.0078791709147148 
2016-12-10 11:11:05 -------------------LR------------------- 
2016-12-10 11:11:05 0.015625 
2016-12-10 11:11:05 Epoch 30 
2016-12-10 11:19:44 Training Error = 0.24764916368478 
2016-12-10 11:19:44 Training Loss = 0.011539748814148 
2016-12-10 11:19:56 Valid Error = 0.21415200299513 
2016-12-10 11:19:56 Valid Loss = 0.0078515570863348 
2016-12-10 11:20:09 Test Error = 0.21252947120243 
2016-12-10 11:20:09 Test Loss = 0.0078451095814997 
2016-12-10 11:20:09 -------------------LR------------------- 
2016-12-10 11:20:09 0.015625 
2016-12-10 11:20:09 Epoch 31 
2016-12-10 11:28:38 Training Error = 0.24918864941333 
2016-12-10 11:28:38 Training Loss = 0.011523415171479 
2016-12-10 11:28:50 Valid Error = 0.20554099588169 
2016-12-10 11:28:50 Valid Loss = 0.0079024640612999 
2016-12-10 11:29:03 Test Error = 0.2017514314584 
2016-12-10 11:29:03 Test Loss = 0.0079007644259437 
2016-12-10 11:29:03 -------------------LR------------------- 
2016-12-10 11:29:03 0.015625 
2016-12-10 11:29:03 Epoch 32 
2016-12-10 11:37:12 Training Error = 0.24906382624615 
2016-12-10 11:37:12 Training Loss = 0.011544743051336 
2016-12-10 11:37:24 Valid Error = 0.21040808685885 
2016-12-10 11:37:24 Valid Loss = 0.0079380081201842 
2016-12-10 11:37:36 Test Error = 0.20848770629842 
2016-12-10 11:37:36 Test Loss = 0.0078815312789389 
2016-12-10 11:37:36 -------------------LR------------------- 
2016-12-10 11:37:36 0.015625 
2016-12-10 11:37:36 Epoch 33 
2016-12-10 11:45:47 Training Error = 0.24881417991179 
2016-12-10 11:45:47 Training Loss = 0.011532521488482 
2016-12-10 11:45:58 Valid Error = 0.21040808685885 
2016-12-10 11:45:58 Valid Loss = 0.0079035446522908 
2016-12-10 11:46:11 Test Error = 0.20815089255642 
2016-12-10 11:46:11 Test Loss = 0.0078653921494148 
2016-12-10 11:46:11 -------------------LR------------------- 
2016-12-10 11:46:11 0.015625 
2016-12-10 11:46:11 Epoch 34 
2016-12-10 11:54:18 Training Error = 0.25027045019556 
2016-12-10 11:54:18 Training Loss = 0.011535490142216 
2016-12-10 11:54:30 Valid Error = 0.21115687008611 
2016-12-10 11:54:30 Valid Loss = 0.0079022641400959 
2016-12-10 11:54:43 Test Error = 0.20848770629842 
2016-12-10 11:54:43 Test Loss = 0.0078666451398064 
2016-12-10 11:54:43 -------------------LR------------------- 
2016-12-10 11:54:43 0.015625 
2016-12-10 11:54:43 Epoch 35 
2016-12-10 12:02:52 Training Error = 0.24839810268786 
2016-12-10 12:02:52 Training Loss = 0.011535482192736 
2016-12-10 12:03:04 Valid Error = 0.21452639460876 
2016-12-10 12:03:04 Valid Loss = 0.0078997434607696 
2016-12-10 12:03:17 Test Error = 0.21286628494443 
2016-12-10 12:03:17 Test Loss = 0.0078881008882646 
2016-12-10 12:03:17 -------------------LR------------------- 
2016-12-10 12:03:17 0.015625 
2016-12-10 12:03:17 Epoch 36 
2016-12-10 12:11:23 Training Error = 0.24923025713572 
2016-12-10 12:11:23 Training Loss = 0.011532823229665 
2016-12-10 12:11:34 Valid Error = 0.21153126169974 
2016-12-10 12:11:34 Valid Loss = 0.0078800296874387 
2016-12-10 12:11:47 Test Error = 0.20949814752442 
2016-12-10 12:11:47 Test Loss = 0.0078672318444632 
2016-12-10 12:11:47 -------------------LR------------------- 
2016-12-10 12:11:47 0.015625 
2016-12-10 12:11:47 Epoch 37 
2016-12-10 12:19:57 Training Error = 0.25118582008821 
2016-12-10 12:19:57 Training Loss = 0.011535186247754 
2016-12-10 12:20:08 Valid Error = 0.21415200299513 
2016-12-10 12:20:08 Valid Loss = 0.0078786811856653 
2016-12-10 12:20:21 Test Error = 0.21252947120243 
2016-12-10 12:20:21 Test Loss = 0.0078666653269074 
2016-12-10 12:20:21 -------------------LR------------------- 
2016-12-10 12:20:21 0.015625 
2016-12-10 12:20:21 Epoch 38 
2016-12-10 12:28:29 Training Error = 0.25068652741949 
2016-12-10 12:28:29 Training Loss = 0.011538462417076 
2016-12-10 12:28:41 Valid Error = 0.21415200299513 
2016-12-10 12:28:41 Valid Loss = 0.0078925343234474 
2016-12-10 12:28:54 Test Error = 0.21252947120243 
2016-12-10 12:28:54 Test Loss = 0.0078856559692943 
2016-12-10 12:28:54 -------------------LR------------------- 
2016-12-10 12:28:54 0.015625 
2016-12-10 12:28:54 Epoch 39 
2016-12-10 12:37:00 Training Error = 0.25035366564034 
2016-12-10 12:37:00 Training Loss = 0.011547487848519 
2016-12-10 12:37:12 Valid Error = 0.21078247847248 
2016-12-10 12:37:12 Valid Loss = 0.0079223931490538 
2016-12-10 12:37:25 Test Error = 0.20747726507241 
2016-12-10 12:37:25 Test Loss = 0.007896908684875 
2016-12-10 12:37:25 -------------------LR------------------- 
2016-12-10 12:37:25 0.015625 
2016-12-10 12:37:25 Epoch 40 
2016-12-10 12:45:37 Training Error = 0.2493550803029 
2016-12-10 12:45:37 Training Loss = 0.011519220201875 
2016-12-10 12:45:49 Valid Error = 0.21415200299513 
2016-12-10 12:45:49 Valid Loss = 0.0079035432204626 
2016-12-10 12:46:02 Test Error = 0.21252947120243 
2016-12-10 12:46:02 Test Loss = 0.0078992852265506 
2016-12-10 12:46:02 -------------------LR------------------- 
2016-12-10 12:46:02 0.015625 
2016-12-10 12:46:02 Epoch 41 
