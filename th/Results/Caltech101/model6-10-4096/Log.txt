2016-12-11 13:47:59 [program started on Sun Dec 11 13:47:59 2016] 
2016-12-11 13:47:59 [command line arguments] 
2016-12-11 13:47:59 stcWeights false 
2016-12-11 13:47:59 LR 0.015625 
2016-12-11 13:47:59 batchSize 64 
2016-12-11 13:47:59 network ./Models/Cifar10_Custom 
2016-12-11 13:47:59 stcNeurons true 
2016-12-11 13:47:59 constBatchSize false 
2016-12-11 13:47:59 chartFileName chart1 
2016-12-11 13:47:59 dp_prepro false 
2016-12-11 13:47:59 nGPU 1 
2016-12-11 13:47:59 dataset Caltech101 
2016-12-11 13:47:59 type cuda 
2016-12-11 13:47:59 momentum 0 
2016-12-11 13:47:59 threads 8 
2016-12-11 13:47:59 weightDecay 0 
2016-12-11 13:47:59 runningVal false 
2016-12-11 13:47:59 convLayerN 6 
2016-12-11 13:47:59 LRDecay 0 
2016-12-11 13:47:59 numHid 4096 
2016-12-11 13:47:59 save /dev/shm/clone/temp/th/Results/Caltech101/model6-10-4096 
2016-12-11 13:47:59 augment false 
2016-12-11 13:47:59 epoch -1 
2016-12-11 13:47:59 modelsFolder ./Models/ 
2016-12-11 13:47:59 format rgb 
2016-12-11 13:47:59 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-11 13:47:59 imageFileExtension svg 
2016-12-11 13:47:59 channel 1 
2016-12-11 13:47:59 devid 5 
2016-12-11 13:47:59 visualize 1 
2016-12-11 13:47:59 LRDecayPerEpoch 0.0001 
2016-12-11 13:47:59 optimization adam 
2016-12-11 13:47:59 SBN true 
2016-12-11 13:47:59 normalization simple 
2016-12-11 13:47:59 title model1 
2016-12-11 13:47:59 load  
2016-12-11 13:47:59 whiten true 
2016-12-11 13:47:59 [----------------------] 
2016-12-11 13:48:03 ==> Network 
2016-12-11 13:48:03 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 4096)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(4096 -> 4096)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(4096 -> 102)
  (38): nn.BatchNormalization
} 
2016-12-11 13:48:03 ==>55354290 Parameters 
2016-12-11 13:48:03 ==> Loss 
2016-12-11 13:48:03 SqrtHingeEmbeddingCriterion 
2016-12-11 13:48:03 
==> Starting Training
 
2016-12-11 13:48:03 Epoch 1 
2016-12-11 13:50:14 Training Error = 0.74645605508303 
2016-12-11 13:50:14 Training Loss = 0.28313572271367 
2016-12-11 13:50:16 Valid Error = 0.7314702308627 
2016-12-11 13:50:16 Valid Loss = 0.038668971543578 
2016-12-11 13:50:18 Test Error = 0.76091703056769 
2016-12-11 13:50:18 Test Loss = 0.039504130026873 
2016-12-11 13:50:18 -------------------LR------------------- 
2016-12-11 13:50:18 0.015625 
2016-12-11 13:50:18 Epoch 2 
2016-12-11 13:52:22 Training Error = 0.6479006345349 
2016-12-11 13:52:22 Training Loss = 0.030346250582247 
2016-12-11 13:52:24 Valid Error = 0.90886998784933 
2016-12-11 13:52:24 Valid Loss = 0.037662526300279 
2016-12-11 13:52:26 Test Error = 0.92467248908297 
2016-12-11 13:52:26 Test Loss = 0.03828973729626 
2016-12-11 13:52:26 -------------------LR------------------- 
2016-12-11 13:52:26 0.015625 
2016-12-11 13:52:26 Epoch 3 
2016-12-11 13:54:46 Training Error = 0.63588497367355 
2016-12-11 13:54:46 Training Loss = 0.028536411001608 
2016-12-11 13:54:48 Valid Error = 0.61603888213852 
2016-12-11 13:54:48 Valid Loss = 0.028736494814403 
2016-12-11 13:54:51 Test Error = 0.65065502183406 
2016-12-11 13:54:51 Test Loss = 0.029848884632385 
2016-12-11 13:54:51 -------------------LR------------------- 
2016-12-11 13:54:51 0.015625 
2016-12-11 13:54:51 Epoch 4 
2016-12-11 13:56:51 Training Error = 0.59430268664777 
2016-12-11 13:56:51 Training Loss = 0.027269657026057 
2016-12-11 13:56:53 Valid Error = 0.59538274605103 
2016-12-11 13:56:53 Valid Loss = 0.028651505737299 
2016-12-11 13:56:55 Test Error = 0.632096069869 
2016-12-11 13:56:55 Test Loss = 0.031121022031198 
2016-12-11 13:56:55 -------------------LR------------------- 
2016-12-11 13:56:55 0.015625 
2016-12-11 13:56:55 Epoch 5 
2016-12-11 13:58:41 Training Error = 0.55407047387606 
2016-12-11 13:58:41 Training Loss = 0.026195247127727 
2016-12-11 13:58:43 Valid Error = 0.55528554070474 
2016-12-11 13:58:43 Valid Loss = 0.025192502093188 
2016-12-11 13:58:45 Test Error = 0.60480349344978 
2016-12-11 13:58:45 Test Loss = 0.026964964025161 
2016-12-11 13:58:45 -------------------LR------------------- 
2016-12-11 13:58:45 0.015625 
2016-12-11 13:58:45 Epoch 6 
2016-12-11 14:00:26 Training Error = 0.51059808289456 
2016-12-11 14:00:26 Training Loss = 0.025019901132873 
2016-12-11 14:00:28 Valid Error = 0.59173754556501 
2016-12-11 14:00:28 Valid Loss = 0.026880928104541 
2016-12-11 14:00:30 Test Error = 0.62772925764192 
2016-12-11 14:00:30 Test Loss = 0.028150086776883 
2016-12-11 14:00:30 -------------------LR------------------- 
2016-12-11 14:00:30 0.015625 
2016-12-11 14:00:30 Epoch 7 
2016-12-11 14:02:10 Training Error = 0.45254488996895 
2016-12-11 14:02:10 Training Loss = 0.023512139163784 
2016-12-11 14:02:12 Valid Error = 0.43985419198056 
2016-12-11 14:02:12 Valid Loss = 0.025086744122915 
2016-12-11 14:02:14 Test Error = 0.48034934497817 
2016-12-11 14:02:14 Test Loss = 0.027736211508707 
2016-12-11 14:02:14 -------------------LR------------------- 
2016-12-11 14:02:14 0.015625 
2016-12-11 14:02:14 Epoch 8 
2016-12-11 14:03:51 Training Error = 0.38342108815985 
2016-12-11 14:03:51 Training Loss = 0.022077290161218 
2016-12-11 14:03:54 Valid Error = 0.55650060753341 
2016-12-11 14:03:54 Valid Loss = 0.027295306250994 
2016-12-11 14:03:56 Test Error = 0.58842794759825 
2016-12-11 14:03:56 Test Loss = 0.028339790955089 
2016-12-11 14:03:56 -------------------LR------------------- 
2016-12-11 14:03:56 0.015625 
2016-12-11 14:03:56 Epoch 9 
2016-12-11 14:05:33 Training Error = 0.31456730120157 
2016-12-11 14:05:33 Training Loss = 0.020773424268465 
2016-12-11 14:05:35 Valid Error = 0.29161603888214 
2016-12-11 14:05:35 Valid Loss = 0.020784619064402 
2016-12-11 14:05:37 Test Error = 0.31004366812227 
2016-12-11 14:05:37 Test Loss = 0.023643036418491 
2016-12-11 14:05:37 -------------------LR------------------- 
2016-12-11 14:05:37 0.015625 
2016-12-11 14:05:37 Epoch 10 
2016-12-11 14:07:19 Training Error = 0.26582962062913 
2016-12-11 14:07:19 Training Loss = 0.019719443317429 
2016-12-11 14:07:21 Valid Error = 0.24665856622114 
2016-12-11 14:07:21 Valid Loss = 0.019440748224725 
2016-12-11 14:07:23 Test Error = 0.25 
2016-12-11 14:07:23 Test Loss = 0.020284779071808 
2016-12-11 14:07:23 -------------------LR------------------- 
2016-12-11 14:07:23 0.015625 
2016-12-11 14:07:23 Epoch 11 
2016-12-11 14:09:03 Training Error = 0.23896314297286 
2016-12-11 14:09:03 Training Loss = 0.019075999496968 
2016-12-11 14:09:05 Valid Error = 0.23936816524909 
2016-12-11 14:09:05 Valid Loss = 0.016283797598271 
2016-12-11 14:09:07 Test Error = 0.22489082969432 
2016-12-11 14:09:07 Test Loss = 0.016822290638693 
2016-12-11 14:09:07 -------------------LR------------------- 
2016-12-11 14:09:07 0.015625 
2016-12-11 14:09:07 Epoch 12 
2016-12-11 14:10:47 Training Error = 0.23653300931551 
2016-12-11 14:10:47 Training Loss = 0.018976038469899 
2016-12-11 14:10:49 Valid Error = 0.24544349939247 
2016-12-11 14:10:49 Valid Loss = 0.01634474098805 
2016-12-11 14:10:52 Test Error = 0.22489082969432 
2016-12-11 14:10:52 Test Loss = 0.01688968828301 
2016-12-11 14:10:52 -------------------LR------------------- 
2016-12-11 14:10:52 0.015625 
2016-12-11 14:10:52 Epoch 13 
2016-12-11 14:12:30 Training Error = 0.2395031726745 
2016-12-11 14:12:30 Training Loss = 0.019124799816585 
2016-12-11 14:12:32 Valid Error = 0.23329283110571 
2016-12-11 14:12:32 Valid Loss = 0.01662040663962 
2016-12-11 14:12:34 Test Error = 0.22161572052402 
2016-12-11 14:12:34 Test Loss = 0.017204687096714 
2016-12-11 14:12:34 -------------------LR------------------- 
2016-12-11 14:12:34 0.015625 
2016-12-11 14:12:34 Epoch 14 
2016-12-11 14:14:11 Training Error = 0.23923315782368 
2016-12-11 14:14:11 Training Loss = 0.019055785540076 
2016-12-11 14:14:14 Valid Error = 0.24544349939247 
2016-12-11 14:14:14 Valid Loss = 0.016424108166174 
2016-12-11 14:14:16 Test Error = 0.22489082969432 
2016-12-11 14:14:16 Test Loss = 0.017015711559969 
2016-12-11 14:14:16 -------------------LR------------------- 
2016-12-11 14:14:16 0.015625 
2016-12-11 14:14:16 Epoch 15 
2016-12-11 14:15:53 Training Error = 0.24071823950317 
2016-12-11 14:15:53 Training Loss = 0.019031160808816 
2016-12-11 14:15:56 Valid Error = 0.23936816524909 
2016-12-11 14:15:56 Valid Loss = 0.01648050648153 
2016-12-11 14:15:58 Test Error = 0.22489082969432 
2016-12-11 14:15:58 Test Loss = 0.017054404480005 
2016-12-11 14:15:58 -------------------LR------------------- 
2016-12-11 14:15:58 0.015625 
2016-12-11 14:15:58 Epoch 16 
2016-12-11 14:17:37 Training Error = 0.24058323207776 
2016-12-11 14:17:37 Training Loss = 0.019188713993664 
2016-12-11 14:17:39 Valid Error = 0.23086269744836 
2016-12-11 14:17:39 Valid Loss = 0.016414661538563 
2016-12-11 14:17:41 Test Error = 0.22052401746725 
2016-12-11 14:17:41 Test Loss = 0.016994664606705 
2016-12-11 14:17:41 -------------------LR------------------- 
2016-12-11 14:17:41 0.015625 
2016-12-11 14:17:41 Epoch 17 
2016-12-11 14:19:20 Training Error = 0.24152828405562 
2016-12-11 14:19:20 Training Loss = 0.019124814578409 
2016-12-11 14:19:23 Valid Error = 0.22843256379101 
2016-12-11 14:19:23 Valid Loss = 0.016471336281187 
2016-12-11 14:19:25 Test Error = 0.20960698689956 
2016-12-11 14:19:25 Test Loss = 0.016986434070113 
2016-12-11 14:19:25 -------------------LR------------------- 
2016-12-11 14:19:25 0.015625 
2016-12-11 14:19:25 Epoch 18 
2016-12-11 14:20:58 Training Error = 0.23734305386796 
2016-12-11 14:20:58 Training Loss = 0.018955312281598 
2016-12-11 14:21:00 Valid Error = 0.22964763061968 
2016-12-11 14:21:00 Valid Loss = 0.016562194448594 
2016-12-11 14:21:03 Test Error = 0.22489082969432 
2016-12-11 14:21:03 Test Loss = 0.017111320916344 
2016-12-11 14:21:03 -------------------LR------------------- 
2016-12-11 14:21:03 0.015625 
2016-12-11 14:21:03 Epoch 19 
2016-12-11 14:22:42 Training Error = 0.24044822465236 
2016-12-11 14:22:42 Training Loss = 0.019071666915272 
2016-12-11 14:22:44 Valid Error = 0.23086269744836 
2016-12-11 14:22:44 Valid Loss = 0.016450871969142 
2016-12-11 14:22:47 Test Error = 0.22052401746725 
2016-12-11 14:22:47 Test Loss = 0.017007444746354 
2016-12-11 14:22:47 -------------------LR------------------- 
2016-12-11 14:22:47 0.015625 
2016-12-11 14:22:47 Epoch 20 
2016-12-11 14:24:27 Training Error = 0.23815309842041 
2016-12-11 14:24:27 Training Loss = 0.019109175863863 
2016-12-11 14:24:29 Valid Error = 0.2138517618469 
2016-12-11 14:24:29 Valid Loss = 0.016331018418192 
2016-12-11 14:24:32 Test Error = 0.20196506550218 
2016-12-11 14:24:32 Test Loss = 0.016877202473435 
2016-12-11 14:24:32 -------------------LR------------------- 
2016-12-11 14:24:32 0.015625 
2016-12-11 14:24:32 Epoch 21 
2016-12-11 14:26:09 Training Error = 0.2427433508843 
2016-12-11 14:26:09 Training Loss = 0.019174866020639 
2016-12-11 14:26:11 Valid Error = 0.23329283110571 
2016-12-11 14:26:11 Valid Loss = 0.016542906934761 
2016-12-11 14:26:14 Test Error = 0.22816593886463 
2016-12-11 14:26:14 Test Loss = 0.017163597353144 
2016-12-11 14:26:14 -------------------LR------------------- 
2016-12-11 14:26:14 0.015625 
2016-12-11 14:26:14 Epoch 22 
2016-12-11 14:27:54 Training Error = 0.24098825435399 
2016-12-11 14:27:54 Training Loss = 0.019091828271684 
2016-12-11 14:27:56 Valid Error = 0.23693803159174 
2016-12-11 14:27:56 Valid Loss = 0.016788593493223 
2016-12-11 14:27:58 Test Error = 0.21397379912664 
2016-12-11 14:27:58 Test Loss = 0.017372434778151 
2016-12-11 14:27:58 -------------------LR------------------- 
2016-12-11 14:27:58 0.015625 
2016-12-11 14:27:58 Epoch 23 
2016-12-11 14:29:32 Training Error = 0.23599297961388 
2016-12-11 14:29:32 Training Loss = 0.018963789101456 
2016-12-11 14:29:34 Valid Error = 0.23572296476306 
2016-12-11 14:29:34 Valid Loss = 0.016405924730106 
2016-12-11 14:29:37 Test Error = 0.22707423580786 
2016-12-11 14:29:37 Test Loss = 0.016989785175697 
2016-12-11 14:29:37 -------------------LR------------------- 
2016-12-11 14:29:37 0.015625 
2016-12-11 14:29:37 Epoch 24 
2016-12-11 14:31:15 Training Error = 0.2363980018901 
2016-12-11 14:31:15 Training Loss = 0.019002904896324 
2016-12-11 14:31:18 Valid Error = 0.23329283110571 
2016-12-11 14:31:18 Valid Loss = 0.01641217544869 
2016-12-11 14:31:20 Test Error = 0.21943231441048 
2016-12-11 14:31:20 Test Loss = 0.017051174157585 
2016-12-11 14:31:20 -------------------LR------------------- 
2016-12-11 14:31:20 0.015625 
2016-12-11 14:31:20 Epoch 25 
2016-12-11 14:33:00 Training Error = 0.24044822465236 
2016-12-11 14:33:00 Training Loss = 0.019077961084901 
2016-12-11 14:33:02 Valid Error = 0.23086269744836 
2016-12-11 14:33:02 Valid Loss = 0.016473957013973 
2016-12-11 14:33:04 Test Error = 0.22052401746725 
2016-12-11 14:33:04 Test Loss = 0.017041425533544 
2016-12-11 14:33:04 -------------------LR------------------- 
2016-12-11 14:33:04 0.015625 
2016-12-11 14:33:04 Epoch 26 
2016-12-11 14:34:44 Training Error = 0.23747806129337 
2016-12-11 14:34:44 Training Loss = 0.01909734821631 
2016-12-11 14:34:46 Valid Error = 0.24422843256379 
2016-12-11 14:34:46 Valid Loss = 0.016530648971902 
2016-12-11 14:34:48 Test Error = 0.24126637554585 
2016-12-11 14:34:48 Test Loss = 0.017119760201647 
2016-12-11 14:34:48 -------------------LR------------------- 
2016-12-11 14:34:48 0.015625 
2016-12-11 14:34:48 Epoch 27 
2016-12-11 14:36:26 Training Error = 0.23855812069664 
2016-12-11 14:36:26 Training Loss = 0.018933315087892 
2016-12-11 14:36:28 Valid Error = 0.23693803159174 
2016-12-11 14:36:28 Valid Loss = 0.016426465049719 
2016-12-11 14:36:31 Test Error = 0.21397379912664 
2016-12-11 14:36:31 Test Loss = 0.017018359876147 
2016-12-11 14:36:31 -------------------LR------------------- 
2016-12-11 14:36:31 0.015625 
2016-12-11 14:36:31 Epoch 28 
2016-12-11 14:38:06 Training Error = 0.24233832860807 
2016-12-11 14:38:06 Training Loss = 0.019206612882718 
2016-12-11 14:38:08 Valid Error = 0.23086269744836 
2016-12-11 14:38:08 Valid Loss = 0.016297084938985 
2016-12-11 14:38:11 Test Error = 0.22052401746725 
2016-12-11 14:38:11 Test Loss = 0.016856356477426 
2016-12-11 14:38:11 -------------------LR------------------- 
2016-12-11 14:38:11 0.015625 
2016-12-11 14:38:11 Epoch 29 
2016-12-11 14:39:48 Training Error = 0.2363980018901 
2016-12-11 14:39:48 Training Loss = 0.018972733258453 
2016-12-11 14:39:50 Valid Error = 0.23086269744836 
2016-12-11 14:39:50 Valid Loss = 0.016563329651868 
2016-12-11 14:39:52 Test Error = 0.22052401746725 
2016-12-11 14:39:53 Test Loss = 0.017132541260688 
2016-12-11 14:39:53 -------------------LR------------------- 
2016-12-11 14:39:53 0.015625 
2016-12-11 14:39:53 Epoch 30 
2016-12-11 14:41:32 Training Error = 0.23882813554746 
2016-12-11 14:41:32 Training Loss = 0.018985266885523 
2016-12-11 14:41:35 Valid Error = 0.23329283110571 
2016-12-11 14:41:35 Valid Loss = 0.016520917158991 
2016-12-11 14:41:37 Test Error = 0.22161572052402 
2016-12-11 14:41:37 Test Loss = 0.017074707645217 
2016-12-11 14:41:37 -------------------LR------------------- 
2016-12-11 14:41:37 0.015625 
2016-12-11 14:41:37 Epoch 31 
2016-12-11 14:43:15 Training Error = 0.23909815039827 
2016-12-11 14:43:15 Training Loss = 0.019078608774689 
2016-12-11 14:43:17 Valid Error = 0.24179829890644 
2016-12-11 14:43:17 Valid Loss = 0.016561864765358 
2016-12-11 14:43:20 Test Error = 0.2325327510917 
2016-12-11 14:43:20 Test Loss = 0.017137725664899 
2016-12-11 14:43:20 -------------------LR------------------- 
2016-12-11 14:43:20 0.015625 
2016-12-11 14:43:20 Epoch 32 
2016-12-11 14:44:56 Training Error = 0.2363980018901 
2016-12-11 14:44:56 Training Loss = 0.019043350488369 
2016-12-11 14:44:59 Valid Error = 0.23572296476306 
2016-12-11 14:44:59 Valid Loss = 0.016482003518425 
2016-12-11 14:45:01 Test Error = 0.22816593886463 
2016-12-11 14:45:01 Test Loss = 0.017039755559435 
2016-12-11 14:45:01 -------------------LR------------------- 
2016-12-11 14:45:01 0.015625 
2016-12-11 14:45:01 Epoch 33 
2016-12-11 14:46:40 Training Error = 0.2378830835696 
2016-12-11 14:46:40 Training Loss = 0.018909481288395 
2016-12-11 14:46:42 Valid Error = 0.22235722964763 
2016-12-11 14:46:42 Valid Loss = 0.016284222261546 
2016-12-11 14:46:44 Test Error = 0.20633187772926 
2016-12-11 14:46:44 Test Loss = 0.01687894559374 
2016-12-11 14:46:44 -------------------LR------------------- 
2016-12-11 14:46:44 0.015625 
2016-12-11 14:46:44 Epoch 34 
2016-12-11 14:48:21 Training Error = 0.23909815039827 
2016-12-11 14:48:21 Training Loss = 0.018935650814309 
2016-12-11 14:48:23 Valid Error = 0.22478736330498 
2016-12-11 14:48:23 Valid Loss = 0.016572704989283 
2016-12-11 14:48:26 Test Error = 0.21724890829694 
2016-12-11 14:48:26 Test Loss = 0.017163834836748 
2016-12-11 14:48:26 -------------------LR------------------- 
2016-12-11 14:48:26 0.015625 
2016-12-11 14:48:26 Epoch 35 
2016-12-11 14:50:06 Training Error = 0.23774807614419 
2016-12-11 14:50:06 Training Loss = 0.019055713823803 
2016-12-11 14:50:08 Valid Error = 0.24422843256379 
2016-12-11 14:50:08 Valid Loss = 0.016491606826238 
2016-12-11 14:50:11 Test Error = 0.24126637554585 
2016-12-11 14:50:11 Test Loss = 0.01703152206209 
2016-12-11 14:50:11 -------------------LR------------------- 
2016-12-11 14:50:11 0.015625 
2016-12-11 14:50:11 Epoch 36 
2016-12-11 14:51:49 Training Error = 0.23963818009991 
2016-12-11 14:51:49 Training Loss = 0.01897675438095 
2016-12-11 14:51:51 Valid Error = 0.23329283110571 
2016-12-11 14:51:51 Valid Loss = 0.016573535890944 
2016-12-11 14:51:54 Test Error = 0.22161572052402 
2016-12-11 14:51:54 Test Loss = 0.01716093884574 
2016-12-11 14:51:54 -------------------LR------------------- 
2016-12-11 14:51:54 0.015625 
2016-12-11 14:51:54 Epoch 37 
2016-12-11 14:53:30 Training Error = 0.24044822465236 
2016-12-11 14:53:30 Training Loss = 0.019124534502689 
2016-12-11 14:53:33 Valid Error = 0.23329283110571 
2016-12-11 14:53:33 Valid Loss = 0.016363687701927 
2016-12-11 14:53:35 Test Error = 0.21943231441048 
2016-12-11 14:53:35 Test Loss = 0.016906191835216 
2016-12-11 14:53:35 -------------------LR------------------- 
2016-12-11 14:53:35 0.015625 
2016-12-11 14:53:35 Epoch 38 
2016-12-11 14:55:16 Training Error = 0.23828810584582 
2016-12-11 14:55:16 Training Loss = 0.018989463160383 
2016-12-11 14:55:18 Valid Error = 0.23693803159174 
2016-12-11 14:55:18 Valid Loss = 0.016433665812236 
2016-12-11 14:55:20 Test Error = 0.21397379912664 
2016-12-11 14:55:20 Test Loss = 0.016992279859929 
2016-12-11 14:55:20 -------------------LR------------------- 
2016-12-11 14:55:20 0.015625 
2016-12-11 14:55:20 Epoch 39 
2016-12-11 14:56:58 Training Error = 0.2363980018901 
2016-12-11 14:56:58 Training Loss = 0.019083181680241 
2016-12-11 14:57:00 Valid Error = 0.23086269744836 
2016-12-11 14:57:00 Valid Loss = 0.016526057706127 
2016-12-11 14:57:02 Test Error = 0.22707423580786 
2016-12-11 14:57:02 Test Loss = 0.017061123910293 
2016-12-11 14:57:02 -------------------LR------------------- 
2016-12-11 14:57:02 0.015625 
2016-12-11 14:57:02 Epoch 40 
2016-12-11 14:58:42 Training Error = 0.23842311327123 
2016-12-11 14:58:42 Training Loss = 0.019054370646385 
2016-12-11 14:58:44 Valid Error = 0.23086269744836 
2016-12-11 14:58:44 Valid Loss = 0.016523035529152 
2016-12-11 14:58:47 Test Error = 0.22052401746725 
2016-12-11 14:58:47 Test Loss = 0.017055361722809 
2016-12-11 14:58:47 -------------------LR------------------- 
2016-12-11 14:58:47 0.015625 
2016-12-11 14:58:47 Epoch 41 
2016-12-11 15:00:23 Training Error = 0.24098825435399 
2016-12-11 15:00:23 Training Loss = 0.019036277383705 
2016-12-11 15:00:26 Valid Error = 0.23693803159174 
2016-12-11 15:00:26 Valid Loss = 0.016455312342731 
2016-12-11 15:00:28 Test Error = 0.21397379912664 
2016-12-11 15:00:28 Test Loss = 0.017050510216383 
2016-12-11 15:00:28 -------------------LR------------------- 
2016-12-11 15:00:28 0.015625 
2016-12-11 15:00:28 Epoch 42 
2016-12-11 15:02:07 Training Error = 0.23572296476306 
2016-12-11 15:02:07 Training Loss = 0.019053802397732 
2016-12-11 15:02:09 Valid Error = 0.23936816524909 
2016-12-11 15:02:09 Valid Loss = 0.016402260547441 
2016-12-11 15:02:11 Test Error = 0.23144104803493 
2016-12-11 15:02:11 Test Loss = 0.016883105062971 
2016-12-11 15:02:11 -------------------LR------------------- 
2016-12-11 15:02:11 0.015625 
2016-12-11 15:02:11 Epoch 43 
2016-12-11 15:03:50 Training Error = 0.24017820980154 
2016-12-11 15:03:50 Training Loss = 0.018999007978681 
2016-12-11 15:03:52 Valid Error = 0.23086269744836 
2016-12-11 15:03:52 Valid Loss = 0.016344248798998 
2016-12-11 15:03:55 Test Error = 0.22052401746725 
2016-12-11 15:03:55 Test Loss = 0.016934349100574 
2016-12-11 15:03:55 -------------------LR------------------- 
2016-12-11 15:03:55 0.015625 
2016-12-11 15:03:55 Epoch 44 
2016-12-11 15:05:30 Training Error = 0.23909815039827 
2016-12-11 15:05:30 Training Loss = 0.019119894998616 
2016-12-11 15:05:32 Valid Error = 0.23086269744836 
2016-12-11 15:05:32 Valid Loss = 0.016441511684495 
2016-12-11 15:05:35 Test Error = 0.22052401746725 
2016-12-11 15:05:35 Test Loss = 0.017046439320433 
2016-12-11 15:05:35 -------------------LR------------------- 
2016-12-11 15:05:35 0.015625 
2016-12-11 15:05:35 Epoch 45 
2016-12-11 15:07:15 Training Error = 0.23990819495072 
2016-12-11 15:07:15 Training Loss = 0.019025256345077 
2016-12-11 15:07:17 Valid Error = 0.24544349939247 
2016-12-11 15:07:17 Valid Loss = 0.016502538504431 
2016-12-11 15:07:19 Test Error = 0.22489082969432 
2016-12-11 15:07:19 Test Loss = 0.017089301371107 
2016-12-11 15:07:19 -------------------LR------------------- 
2016-12-11 15:07:19 0.015625 
2016-12-11 15:07:19 Epoch 46 
2016-12-11 15:08:57 Training Error = 0.23855812069664 
2016-12-11 15:08:57 Training Loss = 0.018972756046964 
2016-12-11 15:08:59 Valid Error = 0.22478736330498 
2016-12-11 15:08:59 Valid Loss = 0.016384900941879 
2016-12-11 15:09:02 Test Error = 0.21724890829694 
2016-12-11 15:09:02 Test Loss = 0.016920502809138 
2016-12-11 15:09:02 -------------------LR------------------- 
2016-12-11 15:09:02 0.015625 
2016-12-11 15:09:02 Epoch 47 
2016-12-11 15:10:40 Training Error = 0.23761306871878 
2016-12-11 15:10:40 Training Loss = 0.019041931742966 
2016-12-11 15:10:42 Valid Error = 0.23936816524909 
2016-12-11 15:10:42 Valid Loss = 0.016411882319373 
2016-12-11 15:10:45 Test Error = 0.23144104803493 
2016-12-11 15:10:45 Test Loss = 0.017040612308028 
2016-12-11 15:10:45 -------------------LR------------------- 
2016-12-11 15:10:45 0.015625 
2016-12-11 15:10:45 Epoch 48 
2016-12-11 15:12:24 Training Error = 0.24233832860807 
2016-12-11 15:12:24 Training Loss = 0.019097846938859 
2016-12-11 15:12:26 Valid Error = 0.22478736330498 
2016-12-11 15:12:26 Valid Loss = 0.016422368732153 
2016-12-11 15:12:29 Test Error = 0.21724890829694 
2016-12-11 15:12:29 Test Loss = 0.01703947244906 
2016-12-11 15:12:29 -------------------LR------------------- 
2016-12-11 15:12:29 0.015625 
2016-12-11 15:12:29 Epoch 49 
2016-12-11 15:14:06 Training Error = 0.24152828405562 
2016-12-11 15:14:06 Training Loss = 0.019101559032413 
2016-12-11 15:14:08 Valid Error = 0.23329283110571 
2016-12-11 15:14:08 Valid Loss = 0.016462363785519 
2016-12-11 15:14:10 Test Error = 0.21724890829694 
2016-12-11 15:14:10 Test Loss = 0.017005872383616 
2016-12-11 15:14:10 -------------------LR------------------- 
2016-12-11 15:14:10 0.015625 
2016-12-11 15:14:10 Epoch 50 
2016-12-11 15:15:47 Training Error = 0.23869312812205 
2016-12-11 15:15:47 Training Loss = 0.019043675321378 
2016-12-11 15:15:49 Valid Error = 0.24179829890644 
2016-12-11 15:15:49 Valid Loss = 0.016600940125511 
2016-12-11 15:15:52 Test Error = 0.23034934497817 
2016-12-11 15:15:52 Test Loss = 0.017203401101181 
2016-12-11 15:15:52 -------------------LR------------------- 
2016-12-11 15:15:52 0.0078125 
2016-12-11 15:15:52 Epoch 51 
2016-12-11 15:17:33 Training Error = 0.2395031726745 
2016-12-11 15:17:33 Training Loss = 0.019159623002417 
2016-12-11 15:17:35 Valid Error = 0.23693803159174 
2016-12-11 15:17:35 Valid Loss = 0.016534273377273 
2016-12-11 15:17:37 Test Error = 0.22052401746725 
2016-12-11 15:17:37 Test Loss = 0.017171135899288 
2016-12-11 15:17:37 -------------------LR------------------- 
2016-12-11 15:17:37 0.0078125 
2016-12-11 15:17:37 Epoch 52 
2016-12-11 15:19:18 Training Error = 0.23572296476306 
2016-12-11 15:19:18 Training Loss = 0.018977131742412 
2016-12-11 15:19:20 Valid Error = 0.22843256379101 
2016-12-11 15:19:20 Valid Loss = 0.016195278432198 
2016-12-11 15:19:23 Test Error = 0.20960698689956 
2016-12-11 15:19:23 Test Loss = 0.016737870359732 
2016-12-11 15:19:23 -------------------LR------------------- 
2016-12-11 15:19:23 0.0078125 
2016-12-11 15:19:23 Epoch 53 
2016-12-11 15:21:03 Training Error = 0.23693803159174 
2016-12-11 15:21:03 Training Loss = 0.018962270476064 
2016-12-11 15:21:05 Valid Error = 0.23815309842041 
2016-12-11 15:21:05 Valid Loss = 0.016570693932001 
2016-12-11 15:21:08 Test Error = 0.22707423580786 
2016-12-11 15:21:08 Test Loss = 0.017159298089595 
2016-12-11 15:21:08 -------------------LR------------------- 
2016-12-11 15:21:08 0.0078125 
2016-12-11 15:21:08 Epoch 54 
2016-12-11 15:22:45 Training Error = 0.23720804644255 
2016-12-11 15:22:45 Training Loss = 0.018976584727908 
2016-12-11 15:22:47 Valid Error = 0.23572296476306 
2016-12-11 15:22:47 Valid Loss = 0.016237193186653 
2016-12-11 15:22:49 Test Error = 0.21834061135371 
2016-12-11 15:22:49 Test Loss = 0.01685356205585 
2016-12-11 15:22:49 -------------------LR------------------- 
2016-12-11 15:22:49 0.0078125 
2016-12-11 15:22:49 Epoch 55 
2016-12-11 15:24:27 Training Error = 0.24193330633185 
2016-12-11 15:24:27 Training Loss = 0.019119145065465 
2016-12-11 15:24:29 Valid Error = 0.23329283110571 
2016-12-11 15:24:29 Valid Loss = 0.016455579662166 
2016-12-11 15:24:32 Test Error = 0.21724890829694 
2016-12-11 15:24:32 Test Loss = 0.01699722032921 
2016-12-11 15:24:32 -------------------LR------------------- 
2016-12-11 15:24:32 0.0078125 
2016-12-11 15:24:32 Epoch 56 
2016-12-11 15:26:10 Training Error = 0.24152828405562 
2016-12-11 15:26:10 Training Loss = 0.019126039801431 
2016-12-11 15:26:13 Valid Error = 0.22843256379101 
2016-12-11 15:26:13 Valid Loss = 0.01643375794812 
2016-12-11 15:26:15 Test Error = 0.20960698689956 
2016-12-11 15:26:15 Test Loss = 0.017027846457911 
2016-12-11 15:26:15 -------------------LR------------------- 
2016-12-11 15:26:15 0.0078125 
2016-12-11 15:26:15 Epoch 57 
2016-12-11 15:27:55 Training Error = 0.23909815039827 
2016-12-11 15:27:55 Training Loss = 0.019024935608799 
2016-12-11 15:27:58 Valid Error = 0.24908869987849 
2016-12-11 15:27:58 Valid Loss = 0.016373034398382 
2016-12-11 15:28:00 Test Error = 0.24235807860262 
2016-12-11 15:28:00 Test Loss = 0.016961168588377 
2016-12-11 15:28:00 -------------------LR------------------- 
2016-12-11 15:28:00 0.0078125 
2016-12-11 15:28:00 Epoch 58 
2016-12-11 15:29:40 Training Error = 0.23545294991225 
2016-12-11 15:29:40 Training Loss = 0.019021355576151 
2016-12-11 15:29:42 Valid Error = 0.23936816524909 
2016-12-11 15:29:42 Valid Loss = 0.016828075385986 
2016-12-11 15:29:44 Test Error = 0.23144104803493 
2016-12-11 15:29:44 Test Loss = 0.017439714490978 
2016-12-11 15:29:44 -------------------LR------------------- 
2016-12-11 15:29:44 0.0078125 
2016-12-11 15:29:44 Epoch 59 
2016-12-11 15:31:18 Training Error = 0.24341838801134 
2016-12-11 15:31:18 Training Loss = 0.019056515334912 
2016-12-11 15:31:20 Valid Error = 0.23329283110571 
2016-12-11 15:31:20 Valid Loss = 0.01637673611571 
2016-12-11 15:31:23 Test Error = 0.22161572052402 
2016-12-11 15:31:23 Test Loss = 0.016973487645193 
2016-12-11 15:31:23 -------------------LR------------------- 
2016-12-11 15:31:23 0.0078125 
2016-12-11 15:31:23 Epoch 60 
2016-12-11 15:33:04 Training Error = 0.23572296476306 
2016-12-11 15:33:04 Training Loss = 0.018941346049779 
2016-12-11 15:33:06 Valid Error = 0.23086269744836 
2016-12-11 15:33:06 Valid Loss = 0.016229649368471 
2016-12-11 15:33:09 Test Error = 0.22052401746725 
2016-12-11 15:33:09 Test Loss = 0.01682955173106 
2016-12-11 15:33:09 -------------------LR------------------- 
2016-12-11 15:33:09 0.0078125 
2016-12-11 15:33:09 Epoch 61 
2016-12-11 15:34:49 Training Error = 0.23680302416633 
2016-12-11 15:34:49 Training Loss = 0.018945504958659 
2016-12-11 15:34:52 Valid Error = 0.22721749696233 
2016-12-11 15:34:52 Valid Loss = 0.016583031475601 
2016-12-11 15:34:54 Test Error = 0.21397379912664 
2016-12-11 15:34:54 Test Loss = 0.017157242329292 
2016-12-11 15:34:54 -------------------LR------------------- 
2016-12-11 15:34:54 0.0078125 
2016-12-11 15:34:54 Epoch 62 
2016-12-11 15:36:32 Training Error = 0.23680302416633 
2016-12-11 15:36:32 Training Loss = 0.018924421563288 
2016-12-11 15:36:34 Valid Error = 0.23936816524909 
2016-12-11 15:36:34 Valid Loss = 0.016421558403207 
2016-12-11 15:36:36 Test Error = 0.22489082969432 
2016-12-11 15:36:36 Test Loss = 0.016919534175225 
2016-12-11 15:36:36 -------------------LR------------------- 
2016-12-11 15:36:36 0.0078125 
2016-12-11 15:36:36 Epoch 63 
2016-12-11 15:38:15 Training Error = 0.2411232617794 
2016-12-11 15:38:15 Training Loss = 0.019171910642748 
2016-12-11 15:38:18 Valid Error = 0.23086269744836 
2016-12-11 15:38:18 Valid Loss = 0.016389710874072 
2016-12-11 15:38:20 Test Error = 0.22052401746725 
2016-12-11 15:38:20 Test Loss = 0.016998849086512 
2016-12-11 15:38:20 -------------------LR------------------- 
2016-12-11 15:38:20 0.0078125 
2016-12-11 15:38:20 Epoch 64 
2016-12-11 15:39:55 Training Error = 0.23936816524909 
2016-12-11 15:39:55 Training Loss = 0.019063018150381 
2016-12-11 15:39:57 Valid Error = 0.25273390036452 
2016-12-11 15:39:57 Valid Loss = 0.01632618762233 
2016-12-11 15:39:59 Test Error = 0.24563318777293 
2016-12-11 15:39:59 Test Loss = 0.016935505773507 
2016-12-11 15:39:59 -------------------LR------------------- 
2016-12-11 15:39:59 0.0078125 
2016-12-11 15:39:59 Epoch 65 
2016-12-11 15:41:40 Training Error = 0.23882813554746 
2016-12-11 15:41:40 Training Loss = 0.019026399130356 
2016-12-11 15:41:42 Valid Error = 0.24179829890644 
2016-12-11 15:41:42 Valid Loss = 0.016378416119984 
2016-12-11 15:41:44 Test Error = 0.22379912663755 
2016-12-11 15:41:44 Test Loss = 0.016959841142293 
2016-12-11 15:41:44 -------------------LR------------------- 
2016-12-11 15:41:44 0.0078125 
2016-12-11 15:41:44 Epoch 66 
2016-12-11 15:43:24 Training Error = 0.23882813554746 
2016-12-11 15:43:24 Training Loss = 0.019097776218097 
2016-12-11 15:43:26 Valid Error = 0.23693803159174 
2016-12-11 15:43:26 Valid Loss = 0.016517965299642 
2016-12-11 15:43:28 Test Error = 0.21397379912664 
2016-12-11 15:43:28 Test Loss = 0.01711101733002 
2016-12-11 15:43:28 -------------------LR------------------- 
2016-12-11 15:43:28 0.0078125 
2016-12-11 15:43:28 Epoch 67 
2016-12-11 15:45:08 Training Error = 0.23707303901715 
2016-12-11 15:45:08 Training Loss = 0.01897412664275 
2016-12-11 15:45:10 Valid Error = 0.23572296476306 
2016-12-11 15:45:10 Valid Loss = 0.016419104857649 
2016-12-11 15:45:12 Test Error = 0.22816593886463 
2016-12-11 15:45:12 Test Loss = 0.01697291296292 
2016-12-11 15:45:12 -------------------LR------------------- 
2016-12-11 15:45:12 0.0078125 
2016-12-11 15:45:12 Epoch 68 
2016-12-11 15:46:50 Training Error = 0.23653300931551 
2016-12-11 15:46:50 Training Loss = 0.018910185557921 
2016-12-11 15:46:53 Valid Error = 0.23086269744836 
2016-12-11 15:46:53 Valid Loss = 0.016595339024817 
2016-12-11 15:46:55 Test Error = 0.21069868995633 
2016-12-11 15:46:55 Test Loss = 0.017135943010742 
2016-12-11 15:46:55 -------------------LR------------------- 
2016-12-11 15:46:55 0.0078125 
2016-12-11 15:46:55 Epoch 69 
2016-12-11 15:48:28 Training Error = 0.23734305386796 
2016-12-11 15:48:28 Training Loss = 0.019112529358689 
2016-12-11 15:48:30 Valid Error = 0.24665856622114 
2016-12-11 15:48:30 Valid Loss = 0.016756051016266 
2016-12-11 15:48:33 Test Error = 0.23799126637555 
2016-12-11 15:48:33 Test Loss = 0.017285715692184 
2016-12-11 15:48:33 -------------------LR------------------- 
2016-12-11 15:48:33 0.0078125 
2016-12-11 15:48:33 Epoch 70 
2016-12-11 15:50:14 Training Error = 0.23990819495072 
2016-12-11 15:50:14 Training Loss = 0.019051087659885 
2016-12-11 15:50:16 Valid Error = 0.23086269744836 
2016-12-11 15:50:16 Valid Loss = 0.016434004794549 
2016-12-11 15:50:18 Test Error = 0.22052401746725 
2016-12-11 15:50:18 Test Loss = 0.01697012932472 
2016-12-11 15:50:18 -------------------LR------------------- 
2016-12-11 15:50:18 0.0078125 
2016-12-11 15:50:18 Epoch 71 
2016-12-11 15:51:57 Training Error = 0.24031321722695 
2016-12-11 15:51:57 Training Loss = 0.01904315504399 
2016-12-11 15:52:00 Valid Error = 0.23086269744836 
2016-12-11 15:52:00 Valid Loss = 0.016569573879569 
2016-12-11 15:52:02 Test Error = 0.22052401746725 
2016-12-11 15:52:02 Test Loss = 0.017126885971992 
2016-12-11 15:52:02 -------------------LR------------------- 
2016-12-11 15:52:02 0.0078125 
2016-12-11 15:52:02 Epoch 72 
2016-12-11 15:53:41 Training Error = 0.23855812069664 
2016-12-11 15:53:41 Training Loss = 0.019015823906397 
2016-12-11 15:53:43 Valid Error = 0.22114216281896 
2016-12-11 15:53:43 Valid Loss = 0.0163429135389 
2016-12-11 15:53:46 Test Error = 0.20305676855895 
2016-12-11 15:53:46 Test Loss = 0.016932791744182 
2016-12-11 15:53:46 -------------------LR------------------- 
2016-12-11 15:53:46 0.0078125 
2016-12-11 15:53:46 Epoch 73 
2016-12-11 15:55:22 Training Error = 0.24166329148103 
2016-12-11 15:55:22 Training Loss = 0.01908831296422 
2016-12-11 15:55:24 Valid Error = 0.23936816524909 
2016-12-11 15:55:24 Valid Loss = 0.016426714021091 
2016-12-11 15:55:26 Test Error = 0.23144104803493 
2016-12-11 15:55:26 Test Loss = 0.016990441870845 
2016-12-11 15:55:26 -------------------LR------------------- 
2016-12-11 15:55:26 0.0078125 
2016-12-11 15:55:26 Epoch 74 
2016-12-11 15:57:04 Training Error = 0.24341838801134 
2016-12-11 15:57:04 Training Loss = 0.019178044122369 
2016-12-11 15:57:06 Valid Error = 0.24179829890644 
2016-12-11 15:57:06 Valid Loss = 0.016622647710515 
2016-12-11 15:57:08 Test Error = 0.24235807860262 
2016-12-11 15:57:08 Test Loss = 0.017185011985255 
2016-12-11 15:57:08 -------------------LR------------------- 
2016-12-11 15:57:08 0.0078125 
2016-12-11 15:57:08 Epoch 75 
2016-12-11 15:58:48 Training Error = 0.24206831375726 
2016-12-11 15:58:48 Training Loss = 0.019036712990309 
2016-12-11 15:58:51 Valid Error = 0.22478736330498 
2016-12-11 15:58:51 Valid Loss = 0.016500154995353 
2016-12-11 15:58:53 Test Error = 0.21724890829694 
2016-12-11 15:58:53 Test Loss = 0.017036456563114 
2016-12-11 15:58:53 -------------------LR------------------- 
2016-12-11 15:58:53 0.0078125 
2016-12-11 15:58:53 Epoch 76 
2016-12-11 16:00:32 Training Error = 0.23612798703929 
2016-12-11 16:00:32 Training Loss = 0.01901109158931 
2016-12-11 16:00:34 Valid Error = 0.22357229647631 
2016-12-11 16:00:34 Valid Loss = 0.016517578805243 
2016-12-11 16:00:37 Test Error = 0.21397379912664 
2016-12-11 16:00:37 Test Loss = 0.017082307385463 
2016-12-11 16:00:37 -------------------LR------------------- 
2016-12-11 16:00:37 0.0078125 
2016-12-11 16:00:37 Epoch 77 
2016-12-11 16:02:17 Training Error = 0.23423788308357 
2016-12-11 16:02:17 Training Loss = 0.01911068066142 
2016-12-11 16:02:19 Valid Error = 0.22843256379101 
2016-12-11 16:02:19 Valid Loss = 0.016652370159573 
2016-12-11 16:02:21 Test Error = 0.20960698689956 
2016-12-11 16:02:21 Test Loss = 0.017219664068783 
2016-12-11 16:02:21 -------------------LR------------------- 
2016-12-11 16:02:21 0.0078125 
2016-12-11 16:02:21 Epoch 78 
2016-12-11 16:03:58 Training Error = 0.23450789793439 
2016-12-11 16:03:58 Training Loss = 0.019002654534393 
2016-12-11 16:04:00 Valid Error = 0.23572296476306 
2016-12-11 16:04:00 Valid Loss = 0.016270951011553 
2016-12-11 16:04:02 Test Error = 0.21834061135371 
2016-12-11 16:04:02 Test Loss = 0.016816454307706 
2016-12-11 16:04:02 -------------------LR------------------- 
2016-12-11 16:04:02 0.0078125 
2016-12-11 16:04:02 Epoch 79 
2016-12-11 16:05:39 Training Error = 0.2362629944647 
2016-12-11 16:05:39 Training Loss = 0.019024578100332 
2016-12-11 16:05:41 Valid Error = 0.22478736330498 
2016-12-11 16:05:41 Valid Loss = 0.01630062154499 
2016-12-11 16:05:44 Test Error = 0.21724890829694 
2016-12-11 16:05:44 Test Loss = 0.01691218078526 
2016-12-11 16:05:44 -------------------LR------------------- 
2016-12-11 16:05:44 0.0078125 
2016-12-11 16:05:44 Epoch 80 
2016-12-11 16:07:23 Training Error = 0.24463345484002 
2016-12-11 16:07:23 Training Loss = 0.019205746303227 
2016-12-11 16:07:25 Valid Error = 0.22843256379101 
2016-12-11 16:07:25 Valid Loss = 0.016342611967022 
2016-12-11 16:07:28 Test Error = 0.20960698689956 
2016-12-11 16:07:28 Test Loss = 0.016950505091474 
2016-12-11 16:07:28 -------------------LR------------------- 
2016-12-11 16:07:28 0.0078125 
2016-12-11 16:07:28 Epoch 81 
2016-12-11 16:09:06 Training Error = 0.24260834345889 
2016-12-11 16:09:06 Training Loss = 0.019101867161236 
2016-12-11 16:09:09 Valid Error = 0.23572296476306 
2016-12-11 16:09:09 Valid Loss = 0.016537543351997 
2016-12-11 16:09:11 Test Error = 0.23034934497817 
2016-12-11 16:09:11 Test Loss = 0.017136818910736 
2016-12-11 16:09:11 -------------------LR------------------- 
2016-12-11 16:09:11 0.0078125 
2016-12-11 16:09:11 Epoch 82 
2016-12-11 16:10:49 Training Error = 0.23828810584582 
2016-12-11 16:10:49 Training Loss = 0.019058820525234 
2016-12-11 16:10:51 Valid Error = 0.24422843256379 
2016-12-11 16:10:51 Valid Loss = 0.016405303212133 
2016-12-11 16:10:53 Test Error = 0.23471615720524 
2016-12-11 16:10:53 Test Loss = 0.016923239729763 
2016-12-11 16:10:53 -------------------LR------------------- 
2016-12-11 16:10:53 0.0078125 
2016-12-11 16:10:53 Epoch 83 
2016-12-11 16:12:33 Training Error = 0.2362629944647 
2016-12-11 16:12:33 Training Loss = 0.019153310333508 
2016-12-11 16:12:35 Valid Error = 0.22478736330498 
2016-12-11 16:12:35 Valid Loss = 0.016407191570315 
2016-12-11 16:12:38 Test Error = 0.21724890829694 
2016-12-11 16:12:38 Test Loss = 0.017051465043835 
2016-12-11 16:12:38 -------------------LR------------------- 
2016-12-11 16:12:38 0.0078125 
2016-12-11 16:12:38 Epoch 84 
2016-12-11 16:14:16 Training Error = 0.24004320237613 
2016-12-11 16:14:16 Training Loss = 0.019131106558299 
2016-12-11 16:14:18 Valid Error = 0.23086269744836 
2016-12-11 16:14:18 Valid Loss = 0.016430363642995 
2016-12-11 16:14:21 Test Error = 0.22052401746725 
2016-12-11 16:14:21 Test Loss = 0.016982684680839 
2016-12-11 16:14:21 -------------------LR------------------- 
2016-12-11 16:14:21 0.0078125 
2016-12-11 16:14:21 Epoch 85 
2016-12-11 16:15:57 Training Error = 0.23450789793439 
2016-12-11 16:15:57 Training Loss = 0.018951051097414 
2016-12-11 16:16:00 Valid Error = 0.22964763061968 
2016-12-11 16:16:00 Valid Loss = 0.016469116186746 
2016-12-11 16:16:02 Test Error = 0.22489082969432 
2016-12-11 16:16:02 Test Loss = 0.017036843782936 
2016-12-11 16:16:02 -------------------LR------------------- 
2016-12-11 16:16:02 0.0078125 
2016-12-11 16:16:02 Epoch 86 
2016-12-11 16:17:42 Training Error = 0.24004320237613 
2016-12-11 16:17:42 Training Loss = 0.019099618685274 
2016-12-11 16:17:45 Valid Error = 0.24058323207776 
2016-12-11 16:17:45 Valid Loss = 0.016585312858295 
2016-12-11 16:17:47 Test Error = 0.22489082969432 
2016-12-11 16:17:47 Test Loss = 0.017146753579183 
2016-12-11 16:17:47 -------------------LR------------------- 
2016-12-11 16:17:47 0.0078125 
2016-12-11 16:17:47 Epoch 87 
2016-12-11 16:19:24 Training Error = 0.24004320237613 
2016-12-11 16:19:24 Training Loss = 0.019051476967485 
2016-12-11 16:19:27 Valid Error = 0.24787363304982 
2016-12-11 16:19:27 Valid Loss = 0.016587642586707 
2016-12-11 16:19:29 Test Error = 0.23580786026201 
2016-12-11 16:19:29 Test Loss = 0.017144354776619 
2016-12-11 16:19:29 -------------------LR------------------- 
2016-12-11 16:19:29 0.0078125 
2016-12-11 16:19:29 Epoch 88 
2016-12-11 16:21:06 Training Error = 0.23842311327123 
2016-12-11 16:21:06 Training Loss = 0.019000972192158 
2016-12-11 16:21:08 Valid Error = 0.23329283110571 
2016-12-11 16:21:08 Valid Loss = 0.016413944788828 
2016-12-11 16:21:11 Test Error = 0.22816593886463 
2016-12-11 16:21:11 Test Loss = 0.016976998382145 
2016-12-11 16:21:11 -------------------LR------------------- 
2016-12-11 16:21:11 0.0078125 
2016-12-11 16:21:11 Epoch 89 
2016-12-11 16:22:48 Training Error = 0.23491292021061 
2016-12-11 16:22:48 Training Loss = 0.019045562492896 
2016-12-11 16:22:50 Valid Error = 0.22843256379101 
2016-12-11 16:22:50 Valid Loss = 0.01657920743676 
2016-12-11 16:22:53 Test Error = 0.20960698689956 
2016-12-11 16:22:53 Test Loss = 0.017160402653264 
2016-12-11 16:22:53 -------------------LR------------------- 
2016-12-11 16:22:53 0.0078125 
2016-12-11 16:22:53 Epoch 90 
2016-12-11 16:24:32 Training Error = 0.24247333603348 
2016-12-11 16:24:32 Training Loss = 0.019127355474734 
2016-12-11 16:24:34 Valid Error = 0.22964763061968 
2016-12-11 16:24:34 Valid Loss = 0.016593537951111 
2016-12-11 16:24:36 Test Error = 0.22707423580786 
2016-12-11 16:24:36 Test Loss = 0.017213696903653 
2016-12-11 16:24:36 -------------------LR------------------- 
2016-12-11 16:24:36 0.0078125 
2016-12-11 16:24:36 Epoch 91 
2016-12-11 16:26:13 Training Error = 0.24004320237613 
2016-12-11 16:26:13 Training Loss = 0.019056582341155 
2016-12-11 16:26:15 Valid Error = 0.25516403402187 
2016-12-11 16:26:15 Valid Loss = 0.016671353326026 
2016-12-11 16:26:18 Test Error = 0.24344978165939 
2016-12-11 16:26:18 Test Loss = 0.017286700111589 
2016-12-11 16:26:18 -------------------LR------------------- 
2016-12-11 16:26:18 0.0078125 
2016-12-11 16:26:18 Epoch 92 
2016-12-11 16:27:57 Training Error = 0.23774807614419 
2016-12-11 16:27:57 Training Loss = 0.019098858268813 
2016-12-11 16:27:59 Valid Error = 0.24544349939247 
2016-12-11 16:27:59 Valid Loss = 0.016370344286215 
2016-12-11 16:28:02 Test Error = 0.22489082969432 
2016-12-11 16:28:02 Test Loss = 0.016956647128062 
2016-12-11 16:28:02 -------------------LR------------------- 
2016-12-11 16:28:02 0.0078125 
2016-12-11 16:28:02 Epoch 93 
2016-12-11 16:29:41 Training Error = 0.23842311327123 
2016-12-11 16:29:41 Training Loss = 0.019078458592643 
2016-12-11 16:29:43 Valid Error = 0.23450789793439 
2016-12-11 16:29:43 Valid Loss = 0.016643618819777 
2016-12-11 16:29:46 Test Error = 0.23471615720524 
2016-12-11 16:29:46 Test Loss = 0.017248241574157 
2016-12-11 16:29:46 -------------------LR------------------- 
2016-12-11 16:29:46 0.0078125 
2016-12-11 16:29:46 Epoch 94 
2016-12-11 16:31:22 Training Error = 0.23909815039827 
2016-12-11 16:31:22 Training Loss = 0.019073477951809 
2016-12-11 16:31:24 Valid Error = 0.23693803159174 
2016-12-11 16:31:24 Valid Loss = 0.016330664858772 
2016-12-11 16:31:27 Test Error = 0.21397379912664 
2016-12-11 16:31:27 Test Loss = 0.016912738030253 
2016-12-11 16:31:27 -------------------LR------------------- 
2016-12-11 16:31:27 0.0078125 
2016-12-11 16:31:27 Epoch 95 
2016-12-11 16:33:03 Training Error = 0.23572296476306 
2016-12-11 16:33:03 Training Loss = 0.019028491038551 
2016-12-11 16:33:06 Valid Error = 0.23936816524909 
2016-12-11 16:33:06 Valid Loss = 0.016316270524217 
2016-12-11 16:33:08 Test Error = 0.22161572052402 
2016-12-11 16:33:08 Test Loss = 0.016884238314784 
2016-12-11 16:33:08 -------------------LR------------------- 
2016-12-11 16:33:08 0.0078125 
2016-12-11 16:33:08 Epoch 96 
2016-12-11 16:34:44 Training Error = 0.24206831375726 
2016-12-11 16:34:44 Training Loss = 0.019051915907252 
2016-12-11 16:34:47 Valid Error = 0.23572296476306 
2016-12-11 16:34:47 Valid Loss = 0.016570785044643 
2016-12-11 16:34:49 Test Error = 0.23034934497817 
2016-12-11 16:34:49 Test Loss = 0.017205211383845 
2016-12-11 16:34:49 -------------------LR------------------- 
2016-12-11 16:34:49 0.0078125 
2016-12-11 16:34:49 Epoch 97 
2016-12-11 16:36:27 Training Error = 0.23923315782368 
2016-12-11 16:36:27 Training Loss = 0.01902365815422 
2016-12-11 16:36:29 Valid Error = 0.23572296476306 
2016-12-11 16:36:29 Valid Loss = 0.01648272000009 
2016-12-11 16:36:31 Test Error = 0.22816593886463 
2016-12-11 16:36:31 Test Loss = 0.017097670954037 
2016-12-11 16:36:31 -------------------LR------------------- 
2016-12-11 16:36:31 0.0078125 
2016-12-11 16:36:31 Epoch 98 
2016-12-11 16:38:11 Training Error = 0.23653300931551 
2016-12-11 16:38:11 Training Loss = 0.019097000495325 
2016-12-11 16:38:13 Valid Error = 0.24422843256379 
2016-12-11 16:38:13 Valid Loss = 0.01646038430979 
2016-12-11 16:38:16 Test Error = 0.23471615720524 
2016-12-11 16:38:16 Test Loss = 0.017080616686079 
2016-12-11 16:38:16 -------------------LR------------------- 
2016-12-11 16:38:16 0.0078125 
2016-12-11 16:38:16 Epoch 99 
2016-12-11 16:39:55 Training Error = 0.24058323207776 
2016-12-11 16:39:55 Training Loss = 0.019108638716799 
2016-12-11 16:39:58 Valid Error = 0.23329283110571 
2016-12-11 16:39:58 Valid Loss = 0.016410596276219 
2016-12-11 16:40:00 Test Error = 0.21724890829694 
2016-12-11 16:40:00 Test Loss = 0.016971483215008 
2016-12-11 16:40:00 -------------------LR------------------- 
2016-12-11 16:40:00 0.0078125 
2016-12-11 16:40:00 Epoch 100 
2016-12-11 16:41:36 Training Error = 0.23693803159174 
2016-12-11 16:41:36 Training Loss = 0.018982387920215 
2016-12-11 16:41:38 Valid Error = 0.22478736330498 
2016-12-11 16:41:38 Valid Loss = 0.016544634547561 
2016-12-11 16:41:41 Test Error = 0.21724890829694 
2016-12-11 16:41:41 Test Loss = 0.017079149508009 
2016-12-11 16:41:41 -------------------LR------------------- 
2016-12-11 16:41:41 0.00390625 
2016-12-11 16:41:41 Epoch 101 
2016-12-11 16:43:16 Training Error = 0.2378830835696 
2016-12-11 16:43:16 Training Loss = 0.019064972203595 
2016-12-11 16:43:19 Valid Error = 0.22478736330498 
2016-12-11 16:43:19 Valid Loss = 0.016469055550687 
2016-12-11 16:43:21 Test Error = 0.21724890829694 
2016-12-11 16:43:21 Test Loss = 0.017002790628695 
2016-12-11 16:43:21 -------------------LR------------------- 
2016-12-11 16:43:21 0.00390625 
2016-12-11 16:43:21 Epoch 102 
2016-12-11 16:45:00 Training Error = 0.23599297961388 
2016-12-11 16:45:00 Training Loss = 0.018990219757073 
2016-12-11 16:45:02 Valid Error = 0.22478736330498 
2016-12-11 16:45:02 Valid Loss = 0.016218488485778 
2016-12-11 16:45:04 Test Error = 0.21724890829694 
2016-12-11 16:45:04 Test Loss = 0.016778982308955 
2016-12-11 16:45:04 -------------------LR------------------- 
2016-12-11 16:45:04 0.00390625 
2016-12-11 16:45:04 Epoch 103 
2016-12-11 16:46:44 Training Error = 0.23558795733765 
2016-12-11 16:46:44 Training Loss = 0.019025614410036 
2016-12-11 16:46:46 Valid Error = 0.23450789793439 
2016-12-11 16:46:46 Valid Loss = 0.016251558775636 
2016-12-11 16:46:48 Test Error = 0.22270742358079 
2016-12-11 16:46:48 Test Loss = 0.016809146170523 
2016-12-11 16:46:48 -------------------LR------------------- 
2016-12-11 16:46:48 0.00390625 
2016-12-11 16:46:48 Epoch 104 
2016-12-11 16:48:27 Training Error = 0.23734305386796 
2016-12-11 16:48:27 Training Loss = 0.018910379709035 
2016-12-11 16:48:29 Valid Error = 0.24544349939247 
2016-12-11 16:48:29 Valid Loss = 0.016520192656484 
2016-12-11 16:48:31 Test Error = 0.24454148471616 
2016-12-11 16:48:31 Test Loss = 0.017140186549791 
2016-12-11 16:48:31 -------------------LR------------------- 
2016-12-11 16:48:31 0.00390625 
2016-12-11 16:48:31 Epoch 105 
2016-12-11 16:50:05 Training Error = 0.23923315782368 
2016-12-11 16:50:05 Training Loss = 0.018986653308313 
2016-12-11 16:50:08 Valid Error = 0.22478736330498 
2016-12-11 16:50:08 Valid Loss = 0.01641945328615 
2016-12-11 16:50:10 Test Error = 0.21724890829694 
2016-12-11 16:50:10 Test Loss = 0.016994673442217 
2016-12-11 16:50:10 -------------------LR------------------- 
2016-12-11 16:50:10 0.00390625 
2016-12-11 16:50:10 Epoch 106 
2016-12-11 16:51:49 Training Error = 0.23774807614419 
2016-12-11 16:51:49 Training Loss = 0.018991239323363 
2016-12-11 16:51:51 Valid Error = 0.23936816524909 
2016-12-11 16:51:51 Valid Loss = 0.016603864677711 
2016-12-11 16:51:54 Test Error = 0.23144104803493 
2016-12-11 16:51:54 Test Loss = 0.017155839648901 
2016-12-11 16:51:54 -------------------LR------------------- 
2016-12-11 16:51:54 0.00390625 
2016-12-11 16:51:54 Epoch 107 
2016-12-11 16:53:32 Training Error = 0.238018090995 
2016-12-11 16:53:32 Training Loss = 0.018942359959188 
2016-12-11 16:53:34 Valid Error = 0.22843256379101 
2016-12-11 16:53:34 Valid Loss = 0.016355500885869 
2016-12-11 16:53:37 Test Error = 0.20960698689956 
2016-12-11 16:53:37 Test Loss = 0.016937093111425 
2016-12-11 16:53:37 -------------------LR------------------- 
2016-12-11 16:53:37 0.00390625 
2016-12-11 16:53:37 Epoch 108 
2016-12-11 16:55:16 Training Error = 0.24058323207776 
2016-12-11 16:55:16 Training Loss = 0.019030303277247 
2016-12-11 16:55:18 Valid Error = 0.22600243013366 
2016-12-11 16:55:18 Valid Loss = 0.016271641585262 
2016-12-11 16:55:20 Test Error = 0.20742358078603 
2016-12-11 16:55:20 Test Loss = 0.016892579770556 
2016-12-11 16:55:20 -------------------LR------------------- 
2016-12-11 16:55:20 0.00390625 
2016-12-11 16:55:20 Epoch 109 
2016-12-11 16:57:00 Training Error = 0.23693803159174 
2016-12-11 16:57:00 Training Loss = 0.019064295289414 
2016-12-11 16:57:02 Valid Error = 0.23329283110571 
2016-12-11 16:57:02 Valid Loss = 0.016449918996057 
2016-12-11 16:57:05 Test Error = 0.21943231441048 
2016-12-11 16:57:05 Test Loss = 0.017052803397958 
2016-12-11 16:57:05 -------------------LR------------------- 
2016-12-11 16:57:05 0.00390625 
2016-12-11 16:57:05 Epoch 110 
2016-12-11 16:58:39 Training Error = 0.23585797218847 
2016-12-11 16:58:39 Training Loss = 0.018997752853014 
2016-12-11 16:58:41 Valid Error = 0.23572296476306 
2016-12-11 16:58:41 Valid Loss = 0.016536044069202 
2016-12-11 16:58:44 Test Error = 0.21834061135371 
2016-12-11 16:58:44 Test Loss = 0.017146024485819 
2016-12-11 16:58:44 -------------------LR------------------- 
2016-12-11 16:58:44 0.00390625 
2016-12-11 16:58:44 Epoch 111 
2016-12-11 17:00:24 Training Error = 0.24058323207776 
2016-12-11 17:00:24 Training Loss = 0.01921474401763 
2016-12-11 17:00:26 Valid Error = 0.24787363304982 
2016-12-11 17:00:26 Valid Loss = 0.016600045493547 
2016-12-11 17:00:29 Test Error = 0.23580786026201 
2016-12-11 17:00:29 Test Loss = 0.017146860026067 
2016-12-11 17:00:29 -------------------LR------------------- 
2016-12-11 17:00:29 0.00390625 
2016-12-11 17:00:29 Epoch 112 
2016-12-11 17:02:06 Training Error = 0.23909815039827 
2016-12-11 17:02:06 Training Loss = 0.019108702127496 
2016-12-11 17:02:08 Valid Error = 0.22235722964763 
2016-12-11 17:02:08 Valid Loss = 0.016516764525538 
2016-12-11 17:02:10 Test Error = 0.20633187772926 
2016-12-11 17:02:10 Test Loss = 0.01707766233706 
2016-12-11 17:02:10 -------------------LR------------------- 
2016-12-11 17:02:10 0.00390625 
2016-12-11 17:02:10 Epoch 113 
2016-12-11 17:03:48 Training Error = 0.23855812069664 
2016-12-11 17:03:48 Training Loss = 0.019085547654002 
2016-12-11 17:03:50 Valid Error = 0.24787363304982 
2016-12-11 17:03:50 Valid Loss = 0.016690414499128 
2016-12-11 17:03:52 Test Error = 0.23580786026201 
2016-12-11 17:03:52 Test Loss = 0.017254182466494 
2016-12-11 17:03:52 -------------------LR------------------- 
2016-12-11 17:03:52 0.00390625 
2016-12-11 17:03:52 Epoch 114 
2016-12-11 17:05:31 Training Error = 0.23828810584582 
2016-12-11 17:05:31 Training Loss = 0.019104715203307 
2016-12-11 17:05:33 Valid Error = 0.24179829890644 
2016-12-11 17:05:33 Valid Loss = 0.016367725062138 
2016-12-11 17:05:35 Test Error = 0.22379912663755 
2016-12-11 17:05:35 Test Loss = 0.017010994019851 
2016-12-11 17:05:35 -------------------LR------------------- 
2016-12-11 17:05:35 0.00390625 
2016-12-11 17:05:35 Epoch 115 
2016-12-11 17:07:12 Training Error = 0.24004320237613 
2016-12-11 17:07:12 Training Loss = 0.0190548360268 
2016-12-11 17:07:14 Valid Error = 0.23936816524909 
2016-12-11 17:07:14 Valid Loss = 0.016207714842848 
2016-12-11 17:07:16 Test Error = 0.23144104803493 
2016-12-11 17:07:16 Test Loss = 0.016810084542418 
2016-12-11 17:07:16 -------------------LR------------------- 
2016-12-11 17:07:16 0.00390625 
2016-12-11 17:07:16 Epoch 116 
2016-12-11 17:08:53 Training Error = 0.23774807614419 
2016-12-11 17:08:53 Training Loss = 0.019001223788189 
2016-12-11 17:08:56 Valid Error = 0.25030376670717 
2016-12-11 17:08:56 Valid Loss = 0.016874784979002 
2016-12-11 17:08:58 Test Error = 0.2325327510917 
2016-12-11 17:08:58 Test Loss = 0.017426270986694 
2016-12-11 17:08:58 -------------------LR------------------- 
2016-12-11 17:08:58 0.00390625 
2016-12-11 17:08:58 Epoch 117 
2016-12-11 17:10:37 Training Error = 0.23923315782368 
2016-12-11 17:10:37 Training Loss = 0.01909157694211 
2016-12-11 17:10:39 Valid Error = 0.23572296476306 
2016-12-11 17:10:39 Valid Loss = 0.01647756906035 
2016-12-11 17:10:41 Test Error = 0.22707423580786 
2016-12-11 17:10:41 Test Loss = 0.017013597877976 
2016-12-11 17:10:41 -------------------LR------------------- 
2016-12-11 17:10:41 0.00390625 
2016-12-11 17:10:41 Epoch 118 
2016-12-11 17:12:19 Training Error = 0.23923315782368 
2016-12-11 17:12:19 Training Loss = 0.019070347253276 
2016-12-11 17:12:21 Valid Error = 0.24179829890644 
2016-12-11 17:12:21 Valid Loss = 0.016380844509489 
2016-12-11 17:12:24 Test Error = 0.22161572052402 
2016-12-11 17:12:24 Test Loss = 0.016978519009609 
2016-12-11 17:12:24 -------------------LR------------------- 
2016-12-11 17:12:24 0.00390625 
2016-12-11 17:12:24 Epoch 119 
2016-12-11 17:14:00 Training Error = 0.24017820980154 
2016-12-11 17:14:00 Training Loss = 0.019195253084852 
2016-12-11 17:14:02 Valid Error = 0.24301336573512 
2016-12-11 17:14:02 Valid Loss = 0.016410950085729 
2016-12-11 17:14:04 Test Error = 0.22598253275109 
2016-12-11 17:14:04 Test Loss = 0.017028539071675 
2016-12-11 17:14:04 -------------------LR------------------- 
2016-12-11 17:14:04 0.00390625 
2016-12-11 17:14:04 Epoch 120 
2016-12-11 17:15:40 Training Error = 0.2378830835696 
2016-12-11 17:15:40 Training Loss = 0.019060973022438 
2016-12-11 17:15:42 Valid Error = 0.22478736330498 
2016-12-11 17:15:42 Valid Loss = 0.016444040487353 
2016-12-11 17:15:45 Test Error = 0.21724890829694 
2016-12-11 17:15:45 Test Loss = 0.017049887414072 
2016-12-11 17:15:45 -------------------LR------------------- 
2016-12-11 17:15:45 0.00390625 
2016-12-11 17:15:45 Epoch 121 
2016-12-11 17:17:22 Training Error = 0.23828810584582 
2016-12-11 17:17:22 Training Loss = 0.01910446076158 
2016-12-11 17:17:24 Valid Error = 0.23936816524909 
2016-12-11 17:17:24 Valid Loss = 0.016568073723912 
2016-12-11 17:17:27 Test Error = 0.22489082969432 
2016-12-11 17:17:27 Test Loss = 0.017127659788319 
2016-12-11 17:17:27 -------------------LR------------------- 
2016-12-11 17:17:27 0.00390625 
2016-12-11 17:17:27 Epoch 122 
2016-12-11 17:19:05 Training Error = 0.24004320237613 
2016-12-11 17:19:05 Training Loss = 0.019144252032882 
2016-12-11 17:19:07 Valid Error = 0.23815309842041 
2016-12-11 17:19:07 Valid Loss = 0.016452872099315 
2016-12-11 17:19:10 Test Error = 0.23580786026201 
2016-12-11 17:19:10 Test Loss = 0.017060431795183 
2016-12-11 17:19:10 -------------------LR------------------- 
2016-12-11 17:19:10 0.00390625 
2016-12-11 17:19:10 Epoch 123 
2016-12-11 17:20:47 Training Error = 0.23896314297286 
2016-12-11 17:20:47 Training Loss = 0.018965740549062 
2016-12-11 17:20:49 Valid Error = 0.22478736330498 
2016-12-11 17:20:49 Valid Loss = 0.016385781774792 
2016-12-11 17:20:52 Test Error = 0.21724890829694 
2016-12-11 17:20:52 Test Loss = 0.016953070989621 
2016-12-11 17:20:52 -------------------LR------------------- 
2016-12-11 17:20:52 0.00390625 
2016-12-11 17:20:52 Epoch 124 
2016-12-11 17:22:30 Training Error = 0.23869312812205 
2016-12-11 17:22:30 Training Loss = 0.018997342028945 
2016-12-11 17:22:32 Valid Error = 0.24422843256379 
2016-12-11 17:22:32 Valid Loss = 0.016480613393939 
2016-12-11 17:22:35 Test Error = 0.23908296943231 
2016-12-11 17:22:35 Test Loss = 0.017017334504844 
2016-12-11 17:22:35 -------------------LR------------------- 
2016-12-11 17:22:35 0.00390625 
2016-12-11 17:22:35 Epoch 125 
2016-12-11 17:24:10 Training Error = 0.23396786823275 
2016-12-11 17:24:10 Training Loss = 0.01903249488665 
2016-12-11 17:24:13 Valid Error = 0.22964763061968 
2016-12-11 17:24:13 Valid Loss = 0.016812576545408 
2016-12-11 17:24:15 Test Error = 0.22489082969432 
2016-12-11 17:24:15 Test Loss = 0.017364614321515 
2016-12-11 17:24:15 -------------------LR------------------- 
2016-12-11 17:24:15 0.00390625 
2016-12-11 17:24:15 Epoch 126 
2016-12-11 17:25:52 Training Error = 0.23585797218847 
2016-12-11 17:25:52 Training Loss = 0.019055317837872 
2016-12-11 17:25:54 Valid Error = 0.23329283110571 
2016-12-11 17:25:54 Valid Loss = 0.016246022541272 
2016-12-11 17:25:57 Test Error = 0.22161572052402 
2016-12-11 17:25:57 Test Loss = 0.016928400136287 
2016-12-11 17:25:57 -------------------LR------------------- 
2016-12-11 17:25:57 0.00390625 
2016-12-11 17:25:57 Epoch 127 
2016-12-11 17:27:35 Training Error = 0.23882813554746 
2016-12-11 17:27:35 Training Loss = 0.019027622753571 
2016-12-11 17:27:37 Valid Error = 0.24179829890644 
2016-12-11 17:27:37 Valid Loss = 0.016496970760435 
2016-12-11 17:27:39 Test Error = 0.22816593886463 
2016-12-11 17:27:39 Test Loss = 0.017086410366632 
2016-12-11 17:27:39 -------------------LR------------------- 
2016-12-11 17:27:39 0.00390625 
2016-12-11 17:27:39 Epoch 128 
2016-12-11 17:29:15 Training Error = 0.2411232617794 
2016-12-11 17:29:15 Training Loss = 0.019117499210957 
2016-12-11 17:29:17 Valid Error = 0.23572296476306 
2016-12-11 17:29:17 Valid Loss = 0.01645722079143 
2016-12-11 17:29:19 Test Error = 0.23034934497817 
2016-12-11 17:29:19 Test Loss = 0.017080558031992 
2016-12-11 17:29:19 -------------------LR------------------- 
2016-12-11 17:29:19 0.00390625 
2016-12-11 17:29:19 Epoch 129 
2016-12-11 17:30:56 Training Error = 0.23491292021061 
2016-12-11 17:30:56 Training Loss = 0.019098440772416 
2016-12-11 17:30:58 Valid Error = 0.24179829890644 
2016-12-11 17:30:58 Valid Loss = 0.0165329113478 
2016-12-11 17:31:00 Test Error = 0.22161572052402 
2016-12-11 17:31:00 Test Loss = 0.017150589734121 
2016-12-11 17:31:00 -------------------LR------------------- 
2016-12-11 17:31:00 0.00390625 
2016-12-11 17:31:00 Epoch 130 
2016-12-11 17:32:39 Training Error = 0.23936816524909 
2016-12-11 17:32:39 Training Loss = 0.019053854818787 
2016-12-11 17:32:41 Valid Error = 0.23693803159174 
2016-12-11 17:32:41 Valid Loss = 0.0164638384909 
2016-12-11 17:32:43 Test Error = 0.21397379912664 
2016-12-11 17:32:43 Test Loss = 0.017000571154301 
2016-12-11 17:32:43 -------------------LR------------------- 
2016-12-11 17:32:43 0.00390625 
2016-12-11 17:32:43 Epoch 131 
2016-12-11 17:34:22 Training Error = 0.24004320237613 
2016-12-11 17:34:22 Training Loss = 0.019150343919029 
2016-12-11 17:34:24 Valid Error = 0.23086269744836 
2016-12-11 17:34:24 Valid Loss = 0.01634359707578 
2016-12-11 17:34:26 Test Error = 0.21724890829694 
2016-12-11 17:34:26 Test Loss = 0.016979254569883 
2016-12-11 17:34:26 -------------------LR------------------- 
2016-12-11 17:34:26 0.00390625 
2016-12-11 17:34:26 Epoch 132 
2016-12-11 17:36:04 Training Error = 0.23882813554746 
2016-12-11 17:36:04 Training Loss = 0.019079879030887 
2016-12-11 17:36:06 Valid Error = 0.21506682867558 
2016-12-11 17:36:06 Valid Loss = 0.016514644630322 
2016-12-11 17:36:08 Test Error = 0.20742358078603 
2016-12-11 17:36:08 Test Loss = 0.017156291615729 
2016-12-11 17:36:08 -------------------LR------------------- 
2016-12-11 17:36:08 0.00390625 
2016-12-11 17:36:08 Epoch 133 
2016-12-11 17:37:46 Training Error = 0.23882813554746 
2016-12-11 17:37:46 Training Loss = 0.019057341487503 
2016-12-11 17:37:48 Valid Error = 0.24908869987849 
2016-12-11 17:37:48 Valid Loss = 0.016669487564158 
2016-12-11 17:37:51 Test Error = 0.24235807860262 
2016-12-11 17:37:51 Test Loss = 0.017252308356217 
2016-12-11 17:37:51 -------------------LR------------------- 
2016-12-11 17:37:51 0.00390625 
2016-12-11 17:37:51 Epoch 134 
2016-12-11 17:39:30 Training Error = 0.2362629944647 
2016-12-11 17:39:30 Training Loss = 0.018931939138767 
2016-12-11 17:39:32 Valid Error = 0.23936816524909 
2016-12-11 17:39:32 Valid Loss = 0.016544203517631 
2016-12-11 17:39:35 Test Error = 0.23144104803493 
2016-12-11 17:39:35 Test Loss = 0.017072445364559 
2016-12-11 17:39:35 -------------------LR------------------- 
2016-12-11 17:39:35 0.00390625 
2016-12-11 17:39:35 Epoch 135 
2016-12-11 17:41:10 Training Error = 0.24139327663021 
2016-12-11 17:41:10 Training Loss = 0.019098862745399 
2016-12-11 17:41:12 Valid Error = 0.23329283110571 
2016-12-11 17:41:12 Valid Loss = 0.016588538129127 
2016-12-11 17:41:15 Test Error = 0.21943231441048 
2016-12-11 17:41:15 Test Loss = 0.017100722789764 
2016-12-11 17:41:15 -------------------LR------------------- 
2016-12-11 17:41:15 0.00390625 
2016-12-11 17:41:15 Epoch 136 
2016-12-11 17:42:52 Training Error = 0.23653300931551 
2016-12-11 17:42:52 Training Loss = 0.019105583461491 
2016-12-11 17:42:55 Valid Error = 0.23936816524909 
2016-12-11 17:42:55 Valid Loss = 0.016532413617551 
2016-12-11 17:42:57 Test Error = 0.22489082969432 
2016-12-11 17:42:57 Test Loss = 0.017148534176396 
2016-12-11 17:42:57 -------------------LR------------------- 
2016-12-11 17:42:57 0.00390625 
2016-12-11 17:42:57 Epoch 137 
2016-12-11 17:44:34 Training Error = 0.2378830835696 
2016-12-11 17:44:34 Training Loss = 0.019114373447109 
2016-12-11 17:44:36 Valid Error = 0.23936816524909 
2016-12-11 17:44:36 Valid Loss = 0.016600140203881 
2016-12-11 17:44:38 Test Error = 0.22489082969432 
2016-12-11 17:44:38 Test Loss = 0.017198962651047 
2016-12-11 17:44:38 -------------------LR------------------- 
2016-12-11 17:44:38 0.00390625 
2016-12-11 17:44:38 Epoch 138 
2016-12-11 17:46:17 Training Error = 0.23842311327123 
2016-12-11 17:46:17 Training Loss = 0.01894143014778 
2016-12-11 17:46:19 Valid Error = 0.23572296476306 
2016-12-11 17:46:19 Valid Loss = 0.016522060069269 
2016-12-11 17:46:22 Test Error = 0.23034934497817 
2016-12-11 17:46:22 Test Loss = 0.017106353457457 
2016-12-11 17:46:22 -------------------LR------------------- 
2016-12-11 17:46:22 0.00390625 
2016-12-11 17:46:22 Epoch 139 
2016-12-11 17:47:58 Training Error = 0.24017820980154 
2016-12-11 17:47:58 Training Loss = 0.019065601563666 
2016-12-11 17:48:00 Valid Error = 0.24179829890644 
2016-12-11 17:48:00 Valid Loss = 0.016295598754009 
2016-12-11 17:48:03 Test Error = 0.22161572052402 
2016-12-11 17:48:03 Test Loss = 0.016859736349068 
2016-12-11 17:48:03 -------------------LR------------------- 
2016-12-11 17:48:03 0.00390625 
2016-12-11 17:48:03 Epoch 140 
2016-12-11 17:49:40 Training Error = 0.23977318752531 
2016-12-11 17:49:40 Training Loss = 0.019035476058237 
2016-12-11 17:49:42 Valid Error = 0.23693803159174 
2016-12-11 17:49:42 Valid Loss = 0.016491315066692 
2016-12-11 17:49:45 Test Error = 0.21397379912664 
2016-12-11 17:49:45 Test Loss = 0.017039870125016 
2016-12-11 17:49:45 -------------------LR------------------- 
2016-12-11 17:49:45 0.00390625 
2016-12-11 17:49:45 Epoch 141 
2016-12-11 17:51:23 Training Error = 0.23531794248684 
2016-12-11 17:51:23 Training Loss = 0.019026679907264 
2016-12-11 17:51:25 Valid Error = 0.23086269744836 
2016-12-11 17:51:25 Valid Loss = 0.016435945880735 
2016-12-11 17:51:28 Test Error = 0.22052401746725 
2016-12-11 17:51:28 Test Loss = 0.016955878532011 
2016-12-11 17:51:28 -------------------LR------------------- 
2016-12-11 17:51:28 0.00390625 
2016-12-11 17:51:28 Epoch 142 
2016-12-11 17:53:02 Training Error = 0.24058323207776 
2016-12-11 17:53:02 Training Loss = 0.019111519736582 
2016-12-11 17:53:05 Valid Error = 0.24544349939247 
2016-12-11 17:53:05 Valid Loss = 0.01632611099199 
2016-12-11 17:53:07 Test Error = 0.22489082969432 
2016-12-11 17:53:07 Test Loss = 0.016917442901462 
2016-12-11 17:53:07 -------------------LR------------------- 
2016-12-11 17:53:07 0.00390625 
2016-12-11 17:53:07 Epoch 143 
2016-12-11 17:54:46 Training Error = 0.2347779127852 
2016-12-11 17:54:46 Training Loss = 0.018951356746033 
2016-12-11 17:54:49 Valid Error = 0.24908869987849 
2016-12-11 17:54:49 Valid Loss = 0.016602474321117 
2016-12-11 17:54:51 Test Error = 0.24235807860262 
2016-12-11 17:54:51 Test Loss = 0.017202072579876 
2016-12-11 17:54:51 -------------------LR------------------- 
2016-12-11 17:54:51 0.00390625 
2016-12-11 17:54:51 Epoch 144 
2016-12-11 17:56:30 Training Error = 0.23990819495072 
2016-12-11 17:56:30 Training Loss = 0.019141046162083 
2016-12-11 17:56:32 Valid Error = 0.24179829890644 
2016-12-11 17:56:32 Valid Loss = 0.016276130842342 
2016-12-11 17:56:34 Test Error = 0.22816593886463 
2016-12-11 17:56:34 Test Loss = 0.016866534878226 
2016-12-11 17:56:34 -------------------LR------------------- 
2016-12-11 17:56:34 0.00390625 
2016-12-11 17:56:34 Epoch 145 
2016-12-11 17:58:10 Training Error = 0.24031321722695 
2016-12-11 17:58:10 Training Loss = 0.018987079706649 
2016-12-11 17:58:12 Valid Error = 0.23693803159174 
2016-12-11 17:58:12 Valid Loss = 0.016593024300136 
2016-12-11 17:58:14 Test Error = 0.21397379912664 
2016-12-11 17:58:14 Test Loss = 0.017126714762519 
2016-12-11 17:58:14 -------------------LR------------------- 
2016-12-11 17:58:14 0.00390625 
2016-12-11 17:58:14 Epoch 146 
2016-12-11 17:59:51 Training Error = 0.23774807614419 
2016-12-11 17:59:51 Training Loss = 0.019110084088277 
2016-12-11 17:59:53 Valid Error = 0.23936816524909 
2016-12-11 17:59:53 Valid Loss = 0.016912808347007 
2016-12-11 17:59:55 Test Error = 0.22489082969432 
2016-12-11 17:59:55 Test Loss = 0.017489852796193 
2016-12-11 17:59:55 -------------------LR------------------- 
2016-12-11 17:59:55 0.00390625 
2016-12-11 17:59:55 Epoch 147 
2016-12-11 18:01:32 Training Error = 0.23585797218847 
2016-12-11 18:01:32 Training Loss = 0.019016965724675 
2016-12-11 18:01:34 Valid Error = 0.23086269744836 
2016-12-11 18:01:34 Valid Loss = 0.016502525816888 
2016-12-11 18:01:37 Test Error = 0.21069868995633 
2016-12-11 18:01:37 Test Loss = 0.017089299812816 
2016-12-11 18:01:37 -------------------LR------------------- 
2016-12-11 18:01:37 0.00390625 
2016-12-11 18:01:37 Epoch 148 
2016-12-11 18:03:15 Training Error = 0.23963818009991 
2016-12-11 18:03:15 Training Loss = 0.018973557978228 
2016-12-11 18:03:17 Valid Error = 0.24179829890644 
2016-12-11 18:03:17 Valid Loss = 0.016391734811777 
2016-12-11 18:03:19 Test Error = 0.22816593886463 
2016-12-11 18:03:19 Test Loss = 0.016983308231129 
2016-12-11 18:03:19 -------------------LR------------------- 
2016-12-11 18:03:19 0.00390625 
2016-12-11 18:03:19 Epoch 149 
2016-12-11 18:04:59 Training Error = 0.23761306871878 
2016-12-11 18:04:59 Training Loss = 0.01902803240742 
2016-12-11 18:05:01 Valid Error = 0.23693803159174 
2016-12-11 18:05:01 Valid Loss = 0.016416395477155 
2016-12-11 18:05:03 Test Error = 0.21397379912664 
2016-12-11 18:05:03 Test Loss = 0.016975973712073 
2016-12-11 18:05:03 -------------------LR------------------- 
2016-12-11 18:05:03 0.00390625 
2016-12-11 18:05:03 Epoch 150 
2016-12-11 18:06:39 Training Error = 0.238018090995 
2016-12-11 18:06:39 Training Loss = 0.019034174538603 
2016-12-11 18:06:42 Valid Error = 0.22964763061968 
2016-12-11 18:06:42 Valid Loss = 0.01668728266203 
2016-12-11 18:06:44 Test Error = 0.22707423580786 
2016-12-11 18:06:44 Test Loss = 0.017361817063849 
2016-12-11 18:06:44 -------------------LR------------------- 
2016-12-11 18:06:44 0.001953125 
2016-12-11 18:06:44 Epoch 151 
2016-12-11 18:08:20 Training Error = 0.24004320237613 
2016-12-11 18:08:20 Training Loss = 0.019132259209088 
2016-12-11 18:08:22 Valid Error = 0.23693803159174 
2016-12-11 18:08:22 Valid Loss = 0.016421940149176 
2016-12-11 18:08:25 Test Error = 0.21397379912664 
2016-12-11 18:08:25 Test Loss = 0.017013717243095 
2016-12-11 18:08:25 -------------------LR------------------- 
2016-12-11 18:08:25 0.001953125 
2016-12-11 18:08:25 Epoch 152 
2016-12-11 18:10:04 Training Error = 0.24206831375726 
2016-12-11 18:10:04 Training Loss = 0.019237219535116 
2016-12-11 18:10:06 Valid Error = 0.22478736330498 
2016-12-11 18:10:06 Valid Loss = 0.01652361170902 
2016-12-11 18:10:09 Test Error = 0.21724890829694 
2016-12-11 18:10:09 Test Loss = 0.017104755086836 
2016-12-11 18:10:09 -------------------LR------------------- 
2016-12-11 18:10:09 0.001953125 
2016-12-11 18:10:09 Epoch 153 
2016-12-11 18:11:46 Training Error = 0.24220332118267 
2016-12-11 18:11:46 Training Loss = 0.019137665686408 
2016-12-11 18:11:49 Valid Error = 0.23936816524909 
2016-12-11 18:11:49 Valid Loss = 0.016607446736242 
2016-12-11 18:11:51 Test Error = 0.22489082969432 
2016-12-11 18:11:51 Test Loss = 0.017163033080257 
2016-12-11 18:11:51 -------------------LR------------------- 
2016-12-11 18:11:51 0.001953125 
2016-12-11 18:11:51 Epoch 154 
2016-12-11 18:13:30 Training Error = 0.23747806129337 
2016-12-11 18:13:30 Training Loss = 0.019036363995995 
2016-12-11 18:13:32 Valid Error = 0.25030376670717 
2016-12-11 18:13:32 Valid Loss = 0.016729541696444 
2016-12-11 18:13:34 Test Error = 0.2325327510917 
2016-12-11 18:13:34 Test Loss = 0.017262487816655 
2016-12-11 18:13:34 -------------------LR------------------- 
2016-12-11 18:13:34 0.001953125 
2016-12-11 18:13:34 Epoch 155 
2016-12-11 18:15:10 Training Error = 0.23909815039827 
2016-12-11 18:15:10 Training Loss = 0.019041945923217 
2016-12-11 18:15:12 Valid Error = 0.23815309842041 
2016-12-11 18:15:12 Valid Loss = 0.016595211850261 
2016-12-11 18:15:14 Test Error = 0.23580786026201 
2016-12-11 18:15:14 Test Loss = 0.017103860783421 
2016-12-11 18:15:14 -------------------LR------------------- 
2016-12-11 18:15:14 0.001953125 
2016-12-11 18:15:14 Epoch 156 
2016-12-11 18:16:51 Training Error = 0.24382341028757 
2016-12-11 18:16:51 Training Loss = 0.019069768649288 
2016-12-11 18:16:53 Valid Error = 0.23572296476306 
2016-12-11 18:16:53 Valid Loss = 0.016252276635245 
2016-12-11 18:16:55 Test Error = 0.22052401746725 
2016-12-11 18:16:55 Test Loss = 0.016868231218625 
2016-12-11 18:16:55 -------------------LR------------------- 
2016-12-11 18:16:55 0.001953125 
2016-12-11 18:16:55 Epoch 157 
2016-12-11 18:18:33 Training Error = 0.23977318752531 
2016-12-11 18:18:33 Training Loss = 0.019092420456345 
2016-12-11 18:18:36 Valid Error = 0.23329283110571 
2016-12-11 18:18:36 Valid Loss = 0.016359574682311 
2016-12-11 18:18:38 Test Error = 0.21724890829694 
2016-12-11 18:18:38 Test Loss = 0.016939182125665 
2016-12-11 18:18:38 -------------------LR------------------- 
2016-12-11 18:18:38 0.001953125 
2016-12-11 18:18:38 Epoch 158 
2016-12-11 18:20:16 Training Error = 0.24260834345889 
2016-12-11 18:20:16 Training Loss = 0.019085607057143 
2016-12-11 18:20:18 Valid Error = 0.23815309842041 
2016-12-11 18:20:18 Valid Loss = 0.016601928215728 
2016-12-11 18:20:21 Test Error = 0.23144104803493 
2016-12-11 18:20:21 Test Loss = 0.017103822511785 
2016-12-11 18:20:21 -------------------LR------------------- 
2016-12-11 18:20:21 0.001953125 
2016-12-11 18:20:21 Epoch 159 
2016-12-11 18:22:00 Training Error = 0.23599297961388 
2016-12-11 18:22:00 Training Loss = 0.019098671287139 
2016-12-11 18:22:02 Valid Error = 0.23572296476306 
2016-12-11 18:22:02 Valid Loss = 0.016360307181141 
2016-12-11 18:22:04 Test Error = 0.22816593886463 
2016-12-11 18:22:04 Test Loss = 0.017023480468326 
2016-12-11 18:22:04 -------------------LR------------------- 
2016-12-11 18:22:04 0.001953125 
2016-12-11 18:22:04 Epoch 160 
2016-12-11 18:23:41 Training Error = 0.23761306871878 
2016-12-11 18:23:41 Training Loss = 0.019028178521459 
2016-12-11 18:23:43 Valid Error = 0.25030376670717 
2016-12-11 18:23:43 Valid Loss = 0.016645695163474 
2016-12-11 18:23:45 Test Error = 0.23471615720524 
2016-12-11 18:23:45 Test Loss = 0.017201730940077 
2016-12-11 18:23:45 -------------------LR------------------- 
2016-12-11 18:23:45 0.001953125 
2016-12-11 18:23:45 Epoch 161 
2016-12-11 18:25:23 Training Error = 0.23747806129337 
2016-12-11 18:25:23 Training Loss = 0.019175280090196 
2016-12-11 18:25:25 Valid Error = 0.24058323207776 
2016-12-11 18:25:25 Valid Loss = 0.016264986483531 
2016-12-11 18:25:28 Test Error = 0.22816593886463 
2016-12-11 18:25:28 Test Loss = 0.016849980712716 
2016-12-11 18:25:28 -------------------LR------------------- 
2016-12-11 18:25:28 0.001953125 
2016-12-11 18:25:28 Epoch 162 
2016-12-11 18:27:05 Training Error = 0.23869312812205 
2016-12-11 18:27:05 Training Loss = 0.019165154182775 
2016-12-11 18:27:08 Valid Error = 0.22478736330498 
2016-12-11 18:27:08 Valid Loss = 0.016472895183338 
2016-12-11 18:27:10 Test Error = 0.21724890829694 
2016-12-11 18:27:10 Test Loss = 0.017016016689001 
2016-12-11 18:27:10 -------------------LR------------------- 
2016-12-11 18:27:10 0.001953125 
2016-12-11 18:27:10 Epoch 163 
2016-12-11 18:28:48 Training Error = 0.23963818009991 
2016-12-11 18:28:48 Training Loss = 0.018926098800847 
2016-12-11 18:28:50 Valid Error = 0.24544349939247 
2016-12-11 18:28:50 Valid Loss = 0.016369533844483 
2016-12-11 18:28:52 Test Error = 0.22489082969432 
2016-12-11 18:28:52 Test Loss = 0.016924723488053 
2016-12-11 18:28:52 -------------------LR------------------- 
2016-12-11 18:28:52 0.001953125 
2016-12-11 18:28:52 Epoch 164 
2016-12-11 18:30:28 Training Error = 0.23882813554746 
2016-12-11 18:30:28 Training Loss = 0.01904108595003 
2016-12-11 18:30:31 Valid Error = 0.24665856622114 
2016-12-11 18:30:31 Valid Loss = 0.016336393228827 
2016-12-11 18:30:33 Test Error = 0.23144104803493 
2016-12-11 18:30:33 Test Loss = 0.016949943857255 
2016-12-11 18:30:33 -------------------LR------------------- 
2016-12-11 18:30:33 0.001953125 
2016-12-11 18:30:33 Epoch 165 
2016-12-11 18:32:07 Training Error = 0.23734305386796 
2016-12-11 18:32:07 Training Loss = 0.018984334968621 
2016-12-11 18:32:10 Valid Error = 0.24058323207776 
2016-12-11 18:32:10 Valid Loss = 0.016392097606526 
2016-12-11 18:32:12 Test Error = 0.22161572052402 
2016-12-11 18:32:12 Test Loss = 0.016959819295048 
2016-12-11 18:32:12 -------------------LR------------------- 
2016-12-11 18:32:12 0.001953125 
2016-12-11 18:32:12 Epoch 166 
2016-12-11 18:33:50 Training Error = 0.23585797218847 
2016-12-11 18:33:50 Training Loss = 0.019011567260108 
2016-12-11 18:33:52 Valid Error = 0.23329283110571 
2016-12-11 18:33:52 Valid Loss = 0.016459789873395 
2016-12-11 18:33:55 Test Error = 0.21943231441048 
2016-12-11 18:33:55 Test Loss = 0.017086699305017 
2016-12-11 18:33:55 -------------------LR------------------- 
2016-12-11 18:33:55 0.001953125 
2016-12-11 18:33:55 Epoch 167 
2016-12-11 18:35:33 Training Error = 0.2411232617794 
2016-12-11 18:35:33 Training Loss = 0.019126155999962 
2016-12-11 18:35:35 Valid Error = 0.23329283110571 
2016-12-11 18:35:35 Valid Loss = 0.016428374377818 
2016-12-11 18:35:37 Test Error = 0.21943231441048 
2016-12-11 18:35:37 Test Loss = 0.017042390739217 
2016-12-11 18:35:37 -------------------LR------------------- 
2016-12-11 18:35:37 0.001953125 
2016-12-11 18:35:37 Epoch 168 
2016-12-11 18:37:17 Training Error = 0.24125826920481 
2016-12-11 18:37:17 Training Loss = 0.018978919273173 
2016-12-11 18:37:19 Valid Error = 0.23693803159174 
2016-12-11 18:37:19 Valid Loss = 0.016473247958165 
2016-12-11 18:37:22 Test Error = 0.21397379912664 
2016-12-11 18:37:22 Test Loss = 0.017019575842066 
2016-12-11 18:37:22 -------------------LR------------------- 
2016-12-11 18:37:22 0.001953125 
2016-12-11 18:37:22 Epoch 169 
2016-12-11 18:39:00 Training Error = 0.24355339543675 
2016-12-11 18:39:00 Training Loss = 0.01907509859891 
2016-12-11 18:39:02 Valid Error = 0.22235722964763 
2016-12-11 18:39:02 Valid Loss = 0.016427530257378 
2016-12-11 18:39:05 Test Error = 0.21615720524017 
2016-12-11 18:39:05 Test Loss = 0.016981676107918 
2016-12-11 18:39:05 -------------------LR------------------- 
2016-12-11 18:39:05 0.001953125 
2016-12-11 18:39:05 Epoch 170 
2016-12-11 18:40:43 Training Error = 0.24031321722695 
2016-12-11 18:40:43 Training Loss = 0.019088966741118 
2016-12-11 18:40:45 Valid Error = 0.24787363304982 
2016-12-11 18:40:45 Valid Loss = 0.016670461324087 
2016-12-11 18:40:47 Test Error = 0.23580786026201 
2016-12-11 18:40:47 Test Loss = 0.017220654207117 
2016-12-11 18:40:47 -------------------LR------------------- 
2016-12-11 18:40:47 0.001953125 
2016-12-11 18:40:47 Epoch 171 
2016-12-11 18:42:25 Training Error = 0.24287835830971 
2016-12-11 18:42:25 Training Loss = 0.019130598424265 
2016-12-11 18:42:28 Valid Error = 0.24908869987849 
2016-12-11 18:42:28 Valid Loss = 0.016602543785496 
2016-12-11 18:42:30 Test Error = 0.24890829694323 
2016-12-11 18:42:30 Test Loss = 0.017216092807795 
2016-12-11 18:42:30 -------------------LR------------------- 
2016-12-11 18:42:30 0.001953125 
2016-12-11 18:42:30 Epoch 172 
2016-12-11 18:44:10 Training Error = 0.23977318752531 
2016-12-11 18:44:10 Training Loss = 0.018953947158767 
2016-12-11 18:44:12 Valid Error = 0.23329283110571 
2016-12-11 18:44:12 Valid Loss = 0.016833269342741 
2016-12-11 18:44:14 Test Error = 0.21943231441048 
2016-12-11 18:44:14 Test Loss = 0.017372700139588 
2016-12-11 18:44:14 -------------------LR------------------- 
2016-12-11 18:44:14 0.001953125 
2016-12-11 18:44:14 Epoch 173 
2016-12-11 18:45:53 Training Error = 0.24220332118267 
2016-12-11 18:45:53 Training Loss = 0.019103772467613 
2016-12-11 18:45:55 Valid Error = 0.24058323207776 
2016-12-11 18:45:55 Valid Loss = 0.016497496072441 
2016-12-11 18:45:58 Test Error = 0.21506550218341 
2016-12-11 18:45:58 Test Loss = 0.017051671236948 
2016-12-11 18:45:58 -------------------LR------------------- 
2016-12-11 18:45:58 0.001953125 
2016-12-11 18:45:58 Epoch 174 
2016-12-11 18:47:33 Training Error = 0.24341838801134 
2016-12-11 18:47:33 Training Loss = 0.019126917968213 
2016-12-11 18:47:35 Valid Error = 0.25759416767922 
2016-12-11 18:47:35 Valid Loss = 0.016473297258471 
2016-12-11 18:47:37 Test Error = 0.24672489082969 
2016-12-11 18:47:37 Test Loss = 0.017065114413991 
2016-12-11 18:47:37 -------------------LR------------------- 
2016-12-11 18:47:37 0.001953125 
2016-12-11 18:47:37 Epoch 175 
2016-12-11 18:49:15 Training Error = 0.24179829890644 
2016-12-11 18:49:15 Training Loss = 0.018911901710677 
2016-12-11 18:49:17 Valid Error = 0.23086269744836 
2016-12-11 18:49:17 Valid Loss = 0.016401382035619 
2016-12-11 18:49:19 Test Error = 0.21069868995633 
2016-12-11 18:49:19 Test Loss = 0.016975901048947 
2016-12-11 18:49:19 -------------------LR------------------- 
2016-12-11 18:49:19 0.001953125 
2016-12-11 18:49:19 Epoch 176 
2016-12-11 18:50:57 Training Error = 0.23909815039827 
2016-12-11 18:50:57 Training Loss = 0.01903157080222 
2016-12-11 18:51:00 Valid Error = 0.21749696233293 
2016-12-11 18:51:00 Valid Loss = 0.016355127598807 
2016-12-11 18:51:02 Test Error = 0.20851528384279 
2016-12-11 18:51:02 Test Loss = 0.016927030351427 
2016-12-11 18:51:02 -------------------LR------------------- 
2016-12-11 18:51:02 0.001953125 
2016-12-11 18:51:02 Epoch 177 
2016-12-11 18:52:40 Training Error = 0.23693803159174 
2016-12-11 18:52:40 Training Loss = 0.019071841814042 
2016-12-11 18:52:42 Valid Error = 0.24179829890644 
2016-12-11 18:52:42 Valid Loss = 0.016368764739427 
2016-12-11 18:52:45 Test Error = 0.22379912663755 
2016-12-11 18:52:45 Test Loss = 0.016940348195095 
2016-12-11 18:52:45 -------------------LR------------------- 
2016-12-11 18:52:45 0.001953125 
2016-12-11 18:52:45 Epoch 178 
2016-12-11 18:54:23 Training Error = 0.23936816524909 
2016-12-11 18:54:23 Training Loss = 0.019045501754903 
2016-12-11 18:54:25 Valid Error = 0.23086269744836 
2016-12-11 18:54:25 Valid Loss = 0.01658817412643 
2016-12-11 18:54:28 Test Error = 0.21724890829694 
2016-12-11 18:54:28 Test Loss = 0.017163273867439 
2016-12-11 18:54:28 -------------------LR------------------- 
2016-12-11 18:54:28 0.001953125 
2016-12-11 18:54:28 Epoch 179 
2016-12-11 18:56:04 Training Error = 0.24044822465236 
2016-12-11 18:56:04 Training Loss = 0.019108194494005 
2016-12-11 18:56:07 Valid Error = 0.23936816524909 
2016-12-11 18:56:07 Valid Loss = 0.016524036669787 
2016-12-11 18:56:09 Test Error = 0.23144104803493 
2016-12-11 18:56:09 Test Loss = 0.017087500048619 
2016-12-11 18:56:09 -------------------LR------------------- 
2016-12-11 18:56:09 0.001953125 
2016-12-11 18:56:09 Epoch 180 
2016-12-11 18:57:48 Training Error = 0.24085324692858 
2016-12-11 18:57:48 Training Loss = 0.01900420006239 
2016-12-11 18:57:50 Valid Error = 0.23086269744836 
2016-12-11 18:57:50 Valid Loss = 0.016244501353585 
2016-12-11 18:57:53 Test Error = 0.22052401746725 
2016-12-11 18:57:53 Test Loss = 0.01682532380609 
2016-12-11 18:57:53 -------------------LR------------------- 
2016-12-11 18:57:53 0.001953125 
2016-12-11 18:57:53 Epoch 181 
2016-12-11 18:59:29 Training Error = 0.24328338058593 
2016-12-11 18:59:29 Training Loss = 0.019069858924005 
2016-12-11 18:59:31 Valid Error = 0.23936816524909 
2016-12-11 18:59:31 Valid Loss = 0.016446525091401 
2016-12-11 18:59:34 Test Error = 0.23144104803493 
2016-12-11 18:59:34 Test Loss = 0.017043508252287 
2016-12-11 18:59:34 -------------------LR------------------- 
2016-12-11 18:59:34 0.001953125 
2016-12-11 18:59:34 Epoch 182 
2016-12-11 19:01:12 Training Error = 0.23923315782368 
2016-12-11 19:01:12 Training Loss = 0.01896865956163 
2016-12-11 19:01:14 Valid Error = 0.22235722964763 
2016-12-11 19:01:14 Valid Loss = 0.016384101750902 
2016-12-11 19:01:17 Test Error = 0.21615720524017 
2016-12-11 19:01:17 Test Loss = 0.016936540338728 
2016-12-11 19:01:17 -------------------LR------------------- 
2016-12-11 19:01:17 0.001953125 
2016-12-11 19:01:17 Epoch 183 
2016-12-11 19:02:53 Training Error = 0.23747806129337 
2016-12-11 19:02:53 Training Loss = 0.018973371187983 
2016-12-11 19:02:56 Valid Error = 0.24787363304982 
2016-12-11 19:02:56 Valid Loss = 0.016587360500554 
2016-12-11 19:02:58 Test Error = 0.23580786026201 
2016-12-11 19:02:58 Test Loss = 0.017192310258454 
2016-12-11 19:02:58 -------------------LR------------------- 
2016-12-11 19:02:58 0.001953125 
2016-12-11 19:02:58 Epoch 184 
2016-12-11 19:04:38 Training Error = 0.23747806129337 
2016-12-11 19:04:38 Training Loss = 0.019069246700066 
2016-12-11 19:04:40 Valid Error = 0.23086269744836 
2016-12-11 19:04:40 Valid Loss = 0.016577395622285 
2016-12-11 19:04:42 Test Error = 0.22052401746725 
2016-12-11 19:04:42 Test Loss = 0.017081442393509 
2016-12-11 19:04:42 -------------------LR------------------- 
2016-12-11 19:04:42 0.001953125 
2016-12-11 19:04:42 Epoch 185 
2016-12-11 19:06:22 Training Error = 0.23747806129337 
2016-12-11 19:06:22 Training Loss = 0.019110468250043 
2016-12-11 19:06:24 Valid Error = 0.22843256379101 
2016-12-11 19:06:24 Valid Loss = 0.01646381744089 
2016-12-11 19:06:27 Test Error = 0.20960698689956 
2016-12-11 19:06:27 Test Loss = 0.016951064751818 
2016-12-11 19:06:27 -------------------LR------------------- 
2016-12-11 19:06:27 0.001953125 
2016-12-11 19:06:27 Epoch 186 
2016-12-11 19:08:02 Training Error = 0.23842311327123 
2016-12-11 19:08:02 Training Loss = 0.019095692022116 
2016-12-11 19:08:04 Valid Error = 0.22478736330498 
2016-12-11 19:08:04 Valid Loss = 0.016538438860092 
2016-12-11 19:08:06 Test Error = 0.21724890829694 
2016-12-11 19:08:06 Test Loss = 0.017143810122621 
2016-12-11 19:08:06 -------------------LR------------------- 
2016-12-11 19:08:06 0.001953125 
2016-12-11 19:08:06 Epoch 187 
2016-12-11 19:09:45 Training Error = 0.23774807614419 
2016-12-11 19:09:45 Training Loss = 0.018958422530343 
2016-12-11 19:09:47 Valid Error = 0.23693803159174 
2016-12-11 19:09:47 Valid Loss = 0.016469646956586 
2016-12-11 19:09:50 Test Error = 0.21397379912664 
2016-12-11 19:09:50 Test Loss = 0.0170599694813 
2016-12-11 19:09:50 -------------------LR------------------- 
2016-12-11 19:09:50 0.001953125 
2016-12-11 19:09:50 Epoch 188 
2016-12-11 19:11:25 Training Error = 0.23855812069664 
2016-12-11 19:11:25 Training Loss = 0.019051778900085 
2016-12-11 19:11:27 Valid Error = 0.24787363304982 
2016-12-11 19:11:27 Valid Loss = 0.016326093882931 
2016-12-11 19:11:30 Test Error = 0.23580786026201 
2016-12-11 19:11:30 Test Loss = 0.016916903701483 
2016-12-11 19:11:30 -------------------LR------------------- 
2016-12-11 19:11:30 0.001953125 
2016-12-11 19:11:30 Epoch 189 
2016-12-11 19:13:09 Training Error = 0.24017820980154 
2016-12-11 19:13:09 Training Loss = 0.019140504217957 
2016-12-11 19:13:11 Valid Error = 0.23693803159174 
2016-12-11 19:13:11 Valid Loss = 0.016272818069636 
2016-12-11 19:13:14 Test Error = 0.21397379912664 
2016-12-11 19:13:14 Test Loss = 0.01680974830989 
2016-12-11 19:13:14 -------------------LR------------------- 
2016-12-11 19:13:14 0.001953125 
2016-12-11 19:13:14 Epoch 190 
2016-12-11 19:14:53 Training Error = 0.23585797218847 
2016-12-11 19:14:53 Training Loss = 0.019082050553637 
2016-12-11 19:14:55 Valid Error = 0.23572296476306 
2016-12-11 19:14:55 Valid Loss = 0.016747559351014 
2016-12-11 19:14:57 Test Error = 0.21834061135371 
2016-12-11 19:14:57 Test Loss = 0.017250941438613 
2016-12-11 19:14:57 -------------------LR------------------- 
2016-12-11 19:14:57 0.001953125 
2016-12-11 19:14:57 Epoch 191 
2016-12-11 19:16:33 Training Error = 0.24098825435399 
2016-12-11 19:16:33 Training Loss = 0.019126620289474 
2016-12-11 19:16:35 Valid Error = 0.23936816524909 
2016-12-11 19:16:35 Valid Loss = 0.016394545849534 
2016-12-11 19:16:37 Test Error = 0.22489082969432 
2016-12-11 19:16:37 Test Loss = 0.016990753077214 
2016-12-11 19:16:37 -------------------LR------------------- 
2016-12-11 19:16:37 0.001953125 
2016-12-11 19:16:37 Epoch 192 
2016-12-11 19:18:12 Training Error = 0.23518293506143 
2016-12-11 19:18:12 Training Loss = 0.019072150976748 
2016-12-11 19:18:14 Valid Error = 0.23936816524909 
2016-12-11 19:18:14 Valid Loss = 0.016377345567277 
2016-12-11 19:18:16 Test Error = 0.22489082969432 
2016-12-11 19:18:16 Test Loss = 0.016923369582182 
2016-12-11 19:18:16 -------------------LR------------------- 
2016-12-11 19:18:16 0.001953125 
2016-12-11 19:18:16 Epoch 193 
2016-12-11 19:19:53 Training Error = 0.23909815039827 
2016-12-11 19:19:53 Training Loss = 0.019045469531327 
2016-12-11 19:19:56 Valid Error = 0.24422843256379 
2016-12-11 19:19:56 Valid Loss = 0.016601895586414 
2016-12-11 19:19:58 Test Error = 0.2325327510917 
2016-12-11 19:19:58 Test Loss = 0.017173959273918 
2016-12-11 19:19:58 -------------------LR------------------- 
2016-12-11 19:19:58 0.001953125 
2016-12-11 19:19:58 Epoch 194 
2016-12-11 19:21:37 Training Error = 0.24314837316052 
2016-12-11 19:21:37 Training Loss = 0.019106565227925 
2016-12-11 19:21:39 Valid Error = 0.23329283110571 
2016-12-11 19:21:39 Valid Loss = 0.016332066361508 
2016-12-11 19:21:42 Test Error = 0.21943231441048 
2016-12-11 19:21:42 Test Loss = 0.016891226347755 
2016-12-11 19:21:42 -------------------LR------------------- 
2016-12-11 19:21:42 0.001953125 
2016-12-11 19:21:42 Epoch 195 
2016-12-11 19:23:21 Training Error = 0.23882813554746 
2016-12-11 19:23:21 Training Loss = 0.018996384559509 
2016-12-11 19:23:23 Valid Error = 0.24058323207776 
2016-12-11 19:23:23 Valid Loss = 0.016470661615126 
2016-12-11 19:23:25 Test Error = 0.22816593886463 
2016-12-11 19:23:25 Test Loss = 0.017071681271971 
2016-12-11 19:23:25 -------------------LR------------------- 
2016-12-11 19:23:25 0.001953125 
2016-12-11 19:23:25 Epoch 196 
2016-12-11 19:25:00 Training Error = 0.23828810584582 
2016-12-11 19:25:00 Training Loss = 0.019004725057097 
2016-12-11 19:25:02 Valid Error = 0.23329283110571 
2016-12-11 19:25:02 Valid Loss = 0.016438320237848 
2016-12-11 19:25:05 Test Error = 0.21943231441048 
2016-12-11 19:25:05 Test Loss = 0.017024608951768 
2016-12-11 19:25:05 -------------------LR------------------- 
2016-12-11 19:25:05 0.001953125 
2016-12-11 19:25:05 Epoch 197 
2016-12-11 19:26:39 Training Error = 0.23275280140408 
2016-12-11 19:26:39 Training Loss = 0.019008734236242 
2016-12-11 19:26:41 Valid Error = 0.22478736330498 
2016-12-11 19:26:41 Valid Loss = 0.016456312726558 
2016-12-11 19:26:44 Test Error = 0.21724890829694 
2016-12-11 19:26:44 Test Loss = 0.017031515673095 
2016-12-11 19:26:44 -------------------LR------------------- 
2016-12-11 19:26:44 0.001953125 
2016-12-11 19:26:44 Epoch 198 
2016-12-11 19:28:23 Training Error = 0.23896314297286 
2016-12-11 19:28:23 Training Loss = 0.019088168921805 
2016-12-11 19:28:25 Valid Error = 0.24908869987849 
2016-12-11 19:28:25 Valid Loss = 0.016947614038398 
2016-12-11 19:28:27 Test Error = 0.24235807860262 
2016-12-11 19:28:27 Test Loss = 0.017503819418888 
2016-12-11 19:28:27 -------------------LR------------------- 
2016-12-11 19:28:27 0.001953125 
2016-12-11 19:28:27 Epoch 199 
2016-12-11 19:30:05 Training Error = 0.23977318752531 
2016-12-11 19:30:05 Training Loss = 0.019030335141119 
2016-12-11 19:30:07 Valid Error = 0.23693803159174 
2016-12-11 19:30:07 Valid Loss = 0.016374291514527 
2016-12-11 19:30:09 Test Error = 0.22052401746725 
2016-12-11 19:30:09 Test Loss = 0.016967520776138 
2016-12-11 19:30:09 -------------------LR------------------- 
2016-12-11 19:30:09 0.001953125 
2016-12-11 19:30:09 Epoch 200 
2016-12-11 19:31:48 Training Error = 0.23882813554746 
2016-12-11 19:31:48 Training Loss = 0.019010150820845 
2016-12-11 19:31:50 Valid Error = 0.24179829890644 
2016-12-11 19:31:50 Valid Loss = 0.016636803378036 
2016-12-11 19:31:52 Test Error = 0.2325327510917 
2016-12-11 19:31:52 Test Loss = 0.017206297840168 
2016-12-11 19:31:52 -------------------LR------------------- 
2016-12-11 19:31:52 0.0009765625 
2016-12-11 19:31:52 Epoch 201 
2016-12-11 19:33:27 Training Error = 0.24139327663021 
2016-12-11 19:33:27 Training Loss = 0.019080279594585 
2016-12-11 19:33:29 Valid Error = 0.23086269744836 
2016-12-11 19:33:29 Valid Loss = 0.016594566609754 
2016-12-11 19:33:32 Test Error = 0.22052401746725 
2016-12-11 19:33:32 Test Loss = 0.017198197888393 
2016-12-11 19:33:32 -------------------LR------------------- 
2016-12-11 19:33:32 0.0009765625 
2016-12-11 19:33:32 Epoch 202 
2016-12-11 19:35:09 Training Error = 0.238018090995 
2016-12-11 19:35:09 Training Loss = 0.018962044462579 
2016-12-11 19:35:11 Valid Error = 0.22843256379101 
2016-12-11 19:35:11 Valid Loss = 0.016461588145447 
2016-12-11 19:35:14 Test Error = 0.20960698689956 
2016-12-11 19:35:14 Test Loss = 0.017041541750914 
2016-12-11 19:35:14 -------------------LR------------------- 
2016-12-11 19:35:14 0.0009765625 
2016-12-11 19:35:14 Epoch 203 
2016-12-11 19:36:51 Training Error = 0.23666801674092 
2016-12-11 19:36:51 Training Loss = 0.018987282189706 
2016-12-11 19:36:53 Valid Error = 0.23086269744836 
2016-12-11 19:36:53 Valid Loss = 0.01638212877096 
2016-12-11 19:36:55 Test Error = 0.22052401746725 
2016-12-11 19:36:55 Test Loss = 0.016980696285472 
2016-12-11 19:36:55 -------------------LR------------------- 
2016-12-11 19:36:55 0.0009765625 
2016-12-11 19:36:55 Epoch 204 
2016-12-11 19:38:34 Training Error = 0.23693803159174 
2016-12-11 19:38:34 Training Loss = 0.018983883302213 
2016-12-11 19:38:36 Valid Error = 0.23086269744836 
2016-12-11 19:38:36 Valid Loss = 0.016483423459126 
2016-12-11 19:38:39 Test Error = 0.21724890829694 
2016-12-11 19:38:39 Test Loss = 0.017004907910341 
2016-12-11 19:38:39 -------------------LR------------------- 
2016-12-11 19:38:39 0.0009765625 
2016-12-11 19:38:39 Epoch 205 
2016-12-11 19:40:17 Training Error = 0.23923315782368 
2016-12-11 19:40:17 Training Loss = 0.019044706836379 
2016-12-11 19:40:19 Valid Error = 0.22478736330498 
2016-12-11 19:40:19 Valid Loss = 0.016296552013145 
2016-12-11 19:40:22 Test Error = 0.21724890829694 
2016-12-11 19:40:22 Test Loss = 0.016864698042277 
2016-12-11 19:40:22 -------------------LR------------------- 
2016-12-11 19:40:22 0.0009765625 
2016-12-11 19:40:22 Epoch 206 
2016-12-11 19:41:54 Training Error = 0.24179829890644 
2016-12-11 19:41:54 Training Loss = 0.019013900467306 
2016-12-11 19:41:56 Valid Error = 0.22357229647631 
2016-12-11 19:41:56 Valid Loss = 0.016366376195869 
2016-12-11 19:41:58 Test Error = 0.21397379912664 
2016-12-11 19:41:58 Test Loss = 0.01690290270288 
2016-12-11 19:41:58 -------------------LR------------------- 
2016-12-11 19:41:58 0.0009765625 
2016-12-11 19:41:58 Epoch 207 
2016-12-11 19:43:36 Training Error = 0.24098825435399 
2016-12-11 19:43:36 Training Loss = 0.019007893171557 
2016-12-11 19:43:39 Valid Error = 0.25273390036452 
2016-12-11 19:43:39 Valid Loss = 0.016517324939965 
2016-12-11 19:43:41 Test Error = 0.24563318777293 
2016-12-11 19:43:41 Test Loss = 0.017105709929871 
2016-12-11 19:43:41 -------------------LR------------------- 
2016-12-11 19:43:41 0.0009765625 
2016-12-11 19:43:41 Epoch 208 
2016-12-11 19:45:21 Training Error = 0.24260834345889 
2016-12-11 19:45:21 Training Loss = 0.019088173138367 
2016-12-11 19:45:23 Valid Error = 0.22235722964763 
2016-12-11 19:45:23 Valid Loss = 0.016366607566176 
2016-12-11 19:45:25 Test Error = 0.20633187772926 
2016-12-11 19:45:25 Test Loss = 0.016976339614469 
2016-12-11 19:45:25 -------------------LR------------------- 
2016-12-11 19:45:25 0.0009765625 
2016-12-11 19:45:25 Epoch 209 
2016-12-11 19:47:04 Training Error = 0.23761306871878 
2016-12-11 19:47:04 Training Loss = 0.018999765119644 
2016-12-11 19:47:06 Valid Error = 0.23329283110571 
2016-12-11 19:47:06 Valid Loss = 0.016654805370144 
2016-12-11 19:47:08 Test Error = 0.21724890829694 
2016-12-11 19:47:08 Test Loss = 0.01720478366403 
2016-12-11 19:47:08 -------------------LR------------------- 
2016-12-11 19:47:08 0.0009765625 
2016-12-11 19:47:08 Epoch 210 
2016-12-11 19:48:50 Training Error = 0.24044822465236 
2016-12-11 19:48:50 Training Loss = 0.019001214488387 
2016-12-11 19:48:52 Valid Error = 0.23936816524909 
2016-12-11 19:48:52 Valid Loss = 0.016430944940705 
2016-12-11 19:48:54 Test Error = 0.22489082969432 
2016-12-11 19:48:54 Test Loss = 0.017009839372697 
2016-12-11 19:48:54 -------------------LR------------------- 
2016-12-11 19:48:54 0.0009765625 
2016-12-11 19:48:54 Epoch 211 
2016-12-11 19:50:29 Training Error = 0.24017820980154 
2016-12-11 19:50:29 Training Loss = 0.019142901208847 
2016-12-11 19:50:31 Valid Error = 0.24179829890644 
2016-12-11 19:50:31 Valid Loss = 0.016548994434856 
2016-12-11 19:50:33 Test Error = 0.22816593886463 
2016-12-11 19:50:33 Test Loss = 0.01714070408952 
2016-12-11 19:50:33 -------------------LR------------------- 
2016-12-11 19:50:33 0.0009765625 
2016-12-11 19:50:33 Epoch 212 
2016-12-11 19:52:10 Training Error = 0.24031321722695 
2016-12-11 19:52:10 Training Loss = 0.019143658353454 
2016-12-11 19:52:12 Valid Error = 0.23329283110571 
2016-12-11 19:52:12 Valid Loss = 0.016696967252174 
2016-12-11 19:52:15 Test Error = 0.21724890829694 
2016-12-11 19:52:15 Test Loss = 0.017225812432034 
2016-12-11 19:52:15 -------------------LR------------------- 
2016-12-11 19:52:15 0.0009765625 
2016-12-11 19:52:15 Epoch 213 
2016-12-11 19:53:54 Training Error = 0.24017820980154 
2016-12-11 19:53:54 Training Loss = 0.019071685628702 
2016-12-11 19:53:56 Valid Error = 0.23693803159174 
2016-12-11 19:53:56 Valid Loss = 0.016554190470786 
2016-12-11 19:53:58 Test Error = 0.22052401746725 
2016-12-11 19:53:58 Test Loss = 0.017110817401238 
2016-12-11 19:53:58 -------------------LR------------------- 
2016-12-11 19:53:58 0.0009765625 
2016-12-11 19:53:58 Epoch 214 
2016-12-11 19:55:36 Training Error = 0.23572296476306 
2016-12-11 19:55:36 Training Loss = 0.019064097900958 
2016-12-11 19:55:39 Valid Error = 0.23329283110571 
2016-12-11 19:55:39 Valid Loss = 0.016642787978595 
2016-12-11 19:55:41 Test Error = 0.21943231441048 
2016-12-11 19:55:41 Test Loss = 0.017209638629863 
2016-12-11 19:55:41 -------------------LR------------------- 
2016-12-11 19:55:41 0.0009765625 
2016-12-11 19:55:41 Epoch 215 
2016-12-11 19:57:15 Training Error = 0.23842311327123 
2016-12-11 19:57:15 Training Loss = 0.019070952769731 
2016-12-11 19:57:17 Valid Error = 0.23936816524909 
2016-12-11 19:57:17 Valid Loss = 0.016497867834449 
2016-12-11 19:57:20 Test Error = 0.22489082969432 
2016-12-11 19:57:20 Test Loss = 0.017076492870555 
2016-12-11 19:57:20 -------------------LR------------------- 
2016-12-11 19:57:20 0.0009765625 
2016-12-11 19:57:20 Epoch 216 
2016-12-11 19:58:56 Training Error = 0.24044822465236 
2016-12-11 19:58:56 Training Loss = 0.019007577134805 
2016-12-11 19:58:58 Valid Error = 0.22235722964763 
2016-12-11 19:58:58 Valid Loss = 0.016579233923355 
2016-12-11 19:59:00 Test Error = 0.20633187772926 
2016-12-11 19:59:00 Test Loss = 0.017135873962851 
2016-12-11 19:59:00 -------------------LR------------------- 
2016-12-11 19:59:00 0.0009765625 
2016-12-11 19:59:00 Epoch 217 
2016-12-11 20:00:40 Training Error = 0.24017820980154 
2016-12-11 20:00:40 Training Loss = 0.019068930514331 
2016-12-11 20:00:42 Valid Error = 0.23572296476306 
2016-12-11 20:00:42 Valid Loss = 0.01656062182912 
2016-12-11 20:00:45 Test Error = 0.23034934497817 
2016-12-11 20:00:45 Test Loss = 0.017132291965235 
2016-12-11 20:00:45 -------------------LR------------------- 
2016-12-11 20:00:45 0.0009765625 
2016-12-11 20:00:45 Epoch 218 
2016-12-11 20:02:21 Training Error = 0.2411232617794 
2016-12-11 20:02:21 Training Loss = 0.019110046280704 
2016-12-11 20:02:23 Valid Error = 0.22843256379101 
2016-12-11 20:02:23 Valid Loss = 0.016271625795303 
2016-12-11 20:02:26 Test Error = 0.20960698689956 
2016-12-11 20:02:26 Test Loss = 0.016802796304615 
2016-12-11 20:02:26 -------------------LR------------------- 
2016-12-11 20:02:26 0.0009765625 
2016-12-11 20:02:26 Epoch 219 
2016-12-11 20:04:05 Training Error = 0.23774807614419 
2016-12-11 20:04:05 Training Loss = 0.018949711117251 
2016-12-11 20:04:07 Valid Error = 0.22478736330498 
2016-12-11 20:04:07 Valid Loss = 0.016494594047904 
2016-12-11 20:04:09 Test Error = 0.21724890829694 
2016-12-11 20:04:09 Test Loss = 0.017040126650941 
2016-12-11 20:04:09 -------------------LR------------------- 
2016-12-11 20:04:09 0.0009765625 
2016-12-11 20:04:09 Epoch 220 
2016-12-11 20:05:46 Training Error = 0.24139327663021 
2016-12-11 20:05:46 Training Loss = 0.019091698803953 
2016-12-11 20:05:49 Valid Error = 0.23815309842041 
2016-12-11 20:05:49 Valid Loss = 0.016475188253218 
2016-12-11 20:05:51 Test Error = 0.2292576419214 
2016-12-11 20:05:51 Test Loss = 0.017096215572233 
2016-12-11 20:05:51 -------------------LR------------------- 
2016-12-11 20:05:51 0.0009765625 
2016-12-11 20:05:51 Epoch 221 
2016-12-11 20:07:27 Training Error = 0.24058323207776 
2016-12-11 20:07:27 Training Loss = 0.018940888879975 
2016-12-11 20:07:29 Valid Error = 0.24422843256379 
2016-12-11 20:07:29 Valid Loss = 0.016400280752971 
2016-12-11 20:07:31 Test Error = 0.2325327510917 
2016-12-11 20:07:31 Test Loss = 0.016977850642859 
2016-12-11 20:07:31 -------------------LR------------------- 
2016-12-11 20:07:31 0.0009765625 
2016-12-11 20:07:31 Epoch 222 
2016-12-11 20:09:10 Training Error = 0.24058323207776 
2016-12-11 20:09:10 Training Loss = 0.019159420541011 
2016-12-11 20:09:13 Valid Error = 0.23329283110571 
2016-12-11 20:09:13 Valid Loss = 0.016608467414908 
2016-12-11 20:09:15 Test Error = 0.21943231441048 
2016-12-11 20:09:15 Test Loss = 0.017190272371753 
2016-12-11 20:09:15 -------------------LR------------------- 
2016-12-11 20:09:15 0.0009765625 
2016-12-11 20:09:15 Epoch 223 
2016-12-11 20:10:53 Training Error = 0.23909815039827 
2016-12-11 20:10:53 Training Loss = 0.01897752714184 
2016-12-11 20:10:55 Valid Error = 0.23693803159174 
2016-12-11 20:10:55 Valid Loss = 0.016450375646259 
2016-12-11 20:10:58 Test Error = 0.21397379912664 
2016-12-11 20:10:58 Test Loss = 0.017015145978117 
2016-12-11 20:10:58 -------------------LR------------------- 
2016-12-11 20:10:58 0.0009765625 
2016-12-11 20:10:58 Epoch 224 
2016-12-11 20:12:33 Training Error = 0.23761306871878 
2016-12-11 20:12:33 Training Loss = 0.01900066807925 
2016-12-11 20:12:35 Valid Error = 0.23936816524909 
2016-12-11 20:12:35 Valid Loss = 0.016450881593498 
2016-12-11 20:12:38 Test Error = 0.22489082969432 
2016-12-11 20:12:38 Test Loss = 0.017044623459087 
2016-12-11 20:12:38 -------------------LR------------------- 
2016-12-11 20:12:38 0.0009765625 
2016-12-11 20:12:38 Epoch 225 
2016-12-11 20:14:15 Training Error = 0.24139327663021 
2016-12-11 20:14:15 Training Loss = 0.019152408173269 
2016-12-11 20:14:17 Valid Error = 0.23086269744836 
2016-12-11 20:14:17 Valid Loss = 0.016587570510283 
2016-12-11 20:14:19 Test Error = 0.22052401746725 
2016-12-11 20:14:19 Test Loss = 0.01718906189102 
2016-12-11 20:14:19 -------------------LR------------------- 
2016-12-11 20:14:19 0.0009765625 
2016-12-11 20:14:19 Epoch 226 
2016-12-11 20:15:54 Training Error = 0.23896314297286 
2016-12-11 20:15:54 Training Loss = 0.018967896746208 
2016-12-11 20:15:56 Valid Error = 0.25151883353584 
2016-12-11 20:15:56 Valid Loss = 0.016699482569818 
2016-12-11 20:15:59 Test Error = 0.25 
2016-12-11 20:15:59 Test Loss = 0.017259106464635 
2016-12-11 20:15:59 -------------------LR------------------- 
2016-12-11 20:15:59 0.0009765625 
2016-12-11 20:15:59 Epoch 227 
2016-12-11 20:17:38 Training Error = 0.24260834345889 
2016-12-11 20:17:38 Training Loss = 0.019170212329455 
2016-12-11 20:17:40 Valid Error = 0.24422843256379 
2016-12-11 20:17:40 Valid Loss = 0.016324864255373 
2016-12-11 20:17:43 Test Error = 0.23471615720524 
2016-12-11 20:17:43 Test Loss = 0.016917562204249 
2016-12-11 20:17:43 -------------------LR------------------- 
2016-12-11 20:17:43 0.0009765625 
2016-12-11 20:17:43 Epoch 228 
2016-12-11 20:19:20 Training Error = 0.238018090995 
2016-12-11 20:19:20 Training Loss = 0.019036442469913 
2016-12-11 20:19:22 Valid Error = 0.24179829890644 
2016-12-11 20:19:22 Valid Loss = 0.016524155828405 
2016-12-11 20:19:24 Test Error = 0.22816593886463 
2016-12-11 20:19:24 Test Loss = 0.017112830059201 
2016-12-11 20:19:24 -------------------LR------------------- 
2016-12-11 20:19:24 0.0009765625 
2016-12-11 20:19:24 Epoch 229 
2016-12-11 20:21:01 Training Error = 0.23963818009991 
2016-12-11 20:21:01 Training Loss = 0.019126752205469 
2016-12-11 20:21:03 Valid Error = 0.22843256379101 
2016-12-11 20:21:03 Valid Loss = 0.016250850533844 
2016-12-11 20:21:06 Test Error = 0.20960698689956 
2016-12-11 20:21:06 Test Loss = 0.016774364296907 
2016-12-11 20:21:06 -------------------LR------------------- 
2016-12-11 20:21:06 0.0009765625 
2016-12-11 20:21:06 Epoch 230 
2016-12-11 20:22:44 Training Error = 0.2347779127852 
2016-12-11 20:22:44 Training Loss = 0.018968348490645 
2016-12-11 20:22:46 Valid Error = 0.23936816524909 
2016-12-11 20:22:46 Valid Loss = 0.01642038753849 
2016-12-11 20:22:49 Test Error = 0.22489082969432 
2016-12-11 20:22:49 Test Loss = 0.016947063231001 
2016-12-11 20:22:49 -------------------LR------------------- 
2016-12-11 20:22:49 0.0009765625 
2016-12-11 20:22:49 Epoch 231 
2016-12-11 20:24:24 Training Error = 0.24058323207776 
2016-12-11 20:24:24 Training Loss = 0.018982543345416 
2016-12-11 20:24:27 Valid Error = 0.23815309842041 
2016-12-11 20:24:27 Valid Loss = 0.016457120337212 
2016-12-11 20:24:29 Test Error = 0.23580786026201 
2016-12-11 20:24:29 Test Loss = 0.017040105504927 
2016-12-11 20:24:29 -------------------LR------------------- 
2016-12-11 20:24:29 0.0009765625 
2016-12-11 20:24:29 Epoch 232 
2016-12-11 20:26:07 Training Error = 0.23977318752531 
2016-12-11 20:26:07 Training Loss = 0.018985358637859 
2016-12-11 20:26:10 Valid Error = 0.24058323207776 
2016-12-11 20:26:10 Valid Loss = 0.01662478860507 
2016-12-11 20:26:12 Test Error = 0.21506550218341 
2016-12-11 20:26:12 Test Loss = 0.017286036902783 
2016-12-11 20:26:12 -------------------LR------------------- 
2016-12-11 20:26:12 0.0009765625 
2016-12-11 20:26:12 Epoch 233 
2016-12-11 20:27:49 Training Error = 0.24098825435399 
2016-12-11 20:27:49 Training Loss = 0.019101789261388 
2016-12-11 20:27:52 Valid Error = 0.23086269744836 
2016-12-11 20:27:52 Valid Loss = 0.016620315030068 
2016-12-11 20:27:54 Test Error = 0.21069868995633 
2016-12-11 20:27:54 Test Loss = 0.017190871643864 
2016-12-11 20:27:54 -------------------LR------------------- 
2016-12-11 20:27:54 0.0009765625 
2016-12-11 20:27:54 Epoch 234 
2016-12-11 20:29:31 Training Error = 0.23585797218847 
2016-12-11 20:29:31 Training Loss = 0.019122042773786 
2016-12-11 20:29:33 Valid Error = 0.22843256379101 
2016-12-11 20:29:33 Valid Loss = 0.016160053438927 
2016-12-11 20:29:36 Test Error = 0.20960698689956 
2016-12-11 20:29:36 Test Loss = 0.016749306363997 
2016-12-11 20:29:36 -------------------LR------------------- 
2016-12-11 20:29:36 0.0009765625 
2016-12-11 20:29:36 Epoch 235 
2016-12-11 20:31:14 Training Error = 0.23572296476306 
2016-12-11 20:31:14 Training Loss = 0.01899673763512 
2016-12-11 20:31:16 Valid Error = 0.22843256379101 
2016-12-11 20:31:16 Valid Loss = 0.016528788911419 
2016-12-11 20:31:19 Test Error = 0.20960698689956 
2016-12-11 20:31:19 Test Loss = 0.017149756250818 
2016-12-11 20:31:19 -------------------LR------------------- 
2016-12-11 20:31:19 0.0009765625 
2016-12-11 20:31:19 Epoch 236 
2016-12-11 20:32:56 Training Error = 0.2363980018901 
2016-12-11 20:32:56 Training Loss = 0.018973674190908 
2016-12-11 20:32:58 Valid Error = 0.23572296476306 
2016-12-11 20:32:58 Valid Loss = 0.016316356147969 
2016-12-11 20:33:00 Test Error = 0.22816593886463 
2016-12-11 20:33:00 Test Loss = 0.016874212190217 
2016-12-11 20:33:00 -------------------LR------------------- 
2016-12-11 20:33:00 0.0009765625 
2016-12-11 20:33:00 Epoch 237 
2016-12-11 20:34:37 Training Error = 0.23693803159174 
2016-12-11 20:34:37 Training Loss = 0.018874701046109 
2016-12-11 20:34:39 Valid Error = 0.24422843256379 
2016-12-11 20:34:39 Valid Loss = 0.016426480156428 
2016-12-11 20:34:41 Test Error = 0.23908296943231 
2016-12-11 20:34:41 Test Loss = 0.017051408462275 
2016-12-11 20:34:41 -------------------LR------------------- 
2016-12-11 20:34:41 0.0009765625 
2016-12-11 20:34:41 Epoch 238 
2016-12-11 20:36:18 Training Error = 0.2378830835696 
2016-12-11 20:36:18 Training Loss = 0.018972347276942 
2016-12-11 20:36:20 Valid Error = 0.23936816524909 
2016-12-11 20:36:20 Valid Loss = 0.016514437181966 
2016-12-11 20:36:23 Test Error = 0.22489082969432 
2016-12-11 20:36:23 Test Loss = 0.017079623135087 
2016-12-11 20:36:23 -------------------LR------------------- 
2016-12-11 20:36:23 0.0009765625 
2016-12-11 20:36:23 Epoch 239 
2016-12-11 20:38:01 Training Error = 0.24017820980154 
2016-12-11 20:38:01 Training Loss = 0.019002013027753 
2016-12-11 20:38:03 Valid Error = 0.24422843256379 
2016-12-11 20:38:03 Valid Loss = 0.016476021881344 
2016-12-11 20:38:06 Test Error = 0.2325327510917 
2016-12-11 20:38:06 Test Loss = 0.017038803973229 
2016-12-11 20:38:06 -------------------LR------------------- 
2016-12-11 20:38:06 0.0009765625 
2016-12-11 20:38:06 Epoch 240 
2016-12-11 20:39:44 Training Error = 0.2347779127852 
2016-12-11 20:39:44 Training Loss = 0.019049604639464 
2016-12-11 20:39:46 Valid Error = 0.23936816524909 
2016-12-11 20:39:46 Valid Loss = 0.016731890037719 
2016-12-11 20:39:49 Test Error = 0.23144104803493 
2016-12-11 20:39:49 Test Loss = 0.017315330115798 
2016-12-11 20:39:49 -------------------LR------------------- 
2016-12-11 20:39:49 0.0009765625 
2016-12-11 20:39:49 Epoch 241 
2016-12-11 20:41:25 Training Error = 0.24017820980154 
2016-12-11 20:41:25 Training Loss = 0.019042622256469 
2016-12-11 20:41:27 Valid Error = 0.22235722964763 
2016-12-11 20:41:27 Valid Loss = 0.016411870635456 
2016-12-11 20:41:30 Test Error = 0.20633187772926 
2016-12-11 20:41:30 Test Loss = 0.016972460637685 
2016-12-11 20:41:30 -------------------LR------------------- 
2016-12-11 20:41:30 0.0009765625 
2016-12-11 20:41:30 Epoch 242 
2016-12-11 20:43:09 Training Error = 0.23693803159174 
2016-12-11 20:43:09 Training Loss = 0.019065626335268 
2016-12-11 20:43:11 Valid Error = 0.23693803159174 
2016-12-11 20:43:11 Valid Loss = 0.016270507643878 
2016-12-11 20:43:13 Test Error = 0.21834061135371 
2016-12-11 20:43:13 Test Loss = 0.016821988704158 
2016-12-11 20:43:13 -------------------LR------------------- 
2016-12-11 20:43:13 0.0009765625 
2016-12-11 20:43:13 Epoch 243 
2016-12-11 20:44:49 Training Error = 0.23896314297286 
2016-12-11 20:44:49 Training Loss = 0.019028276010419 
2016-12-11 20:44:52 Valid Error = 0.23815309842041 
2016-12-11 20:44:52 Valid Loss = 0.016413861523763 
2016-12-11 20:44:54 Test Error = 0.22707423580786 
2016-12-11 20:44:54 Test Loss = 0.017012178025214 
2016-12-11 20:44:54 -------------------LR------------------- 
2016-12-11 20:44:54 0.0009765625 
2016-12-11 20:44:54 Epoch 244 
2016-12-11 20:46:32 Training Error = 0.23275280140408 
2016-12-11 20:46:32 Training Loss = 0.019073584497694 
2016-12-11 20:46:35 Valid Error = 0.23207776427704 
2016-12-11 20:46:35 Valid Loss = 0.016781899124184 
2016-12-11 20:46:37 Test Error = 0.22379912663755 
2016-12-11 20:46:37 Test Loss = 0.017403529407152 
2016-12-11 20:46:37 -------------------LR------------------- 
2016-12-11 20:46:37 0.0009765625 
2016-12-11 20:46:37 Epoch 245 
2016-12-11 20:48:15 Training Error = 0.23842311327123 
2016-12-11 20:48:15 Training Loss = 0.019102838556258 
2016-12-11 20:48:18 Valid Error = 0.23693803159174 
2016-12-11 20:48:18 Valid Loss = 0.016295535476483 
2016-12-11 20:48:20 Test Error = 0.21397379912664 
2016-12-11 20:48:20 Test Loss = 0.016808991712682 
2016-12-11 20:48:20 -------------------LR------------------- 
2016-12-11 20:48:20 0.0009765625 
2016-12-11 20:48:20 Epoch 246 
2016-12-11 20:49:56 Training Error = 0.23815309842041 
2016-12-11 20:49:56 Training Loss = 0.019064577207174 
2016-12-11 20:49:59 Valid Error = 0.24058323207776 
2016-12-11 20:49:59 Valid Loss = 0.016406013918858 
2016-12-11 20:50:01 Test Error = 0.22489082969432 
2016-12-11 20:50:01 Test Loss = 0.017010624658049 
2016-12-11 20:50:01 -------------------LR------------------- 
2016-12-11 20:50:01 0.0009765625 
2016-12-11 20:50:01 Epoch 247 
2016-12-11 20:51:34 Training Error = 0.23585797218847 
2016-12-11 20:51:34 Training Loss = 0.018989726962363 
2016-12-11 20:51:36 Valid Error = 0.24179829890644 
2016-12-11 20:51:36 Valid Loss = 0.016554101187229 
2016-12-11 20:51:39 Test Error = 0.22161572052402 
2016-12-11 20:51:39 Test Loss = 0.017175752680286 
2016-12-11 20:51:39 -------------------LR------------------- 
2016-12-11 20:51:39 0.0009765625 
2016-12-11 20:51:39 Epoch 248 
2016-12-11 20:53:16 Training Error = 0.24125826920481 
2016-12-11 20:53:16 Training Loss = 0.019098811148362 
2016-12-11 20:53:18 Valid Error = 0.22478736330498 
2016-12-11 20:53:18 Valid Loss = 0.016471648139423 
2016-12-11 20:53:21 Test Error = 0.21724890829694 
2016-12-11 20:53:21 Test Loss = 0.017116887647342 
2016-12-11 20:53:21 -------------------LR------------------- 
2016-12-11 20:53:21 0.0009765625 
2016-12-11 20:53:21 Epoch 249 
2016-12-11 20:55:00 Training Error = 0.23734305386796 
2016-12-11 20:55:00 Training Loss = 0.019010217306395 
2016-12-11 20:55:02 Valid Error = 0.23329283110571 
2016-12-11 20:55:02 Valid Loss = 0.016598413155008 
2016-12-11 20:55:05 Test Error = 0.21724890829694 
2016-12-11 20:55:05 Test Loss = 0.017176101129819 
2016-12-11 20:55:05 -------------------LR------------------- 
2016-12-11 20:55:05 0.0009765625 
2016-12-11 20:55:05 Epoch 250 
2016-12-11 20:56:43 Training Error = 0.23747806129337 
2016-12-11 20:56:43 Training Loss = 0.019005203485702 
2016-12-11 20:56:45 Valid Error = 0.24179829890644 
2016-12-11 20:56:45 Valid Loss = 0.016378978244173 
2016-12-11 20:56:48 Test Error = 0.23034934497817 
2016-12-11 20:56:48 Test Loss = 0.016984705254923 
2016-12-11 20:56:48 -------------------LR------------------- 
2016-12-11 20:56:48 0.00048828125 
2016-12-11 20:56:48 Epoch 251 
2016-12-11 20:58:26 Training Error = 0.23666801674092 
2016-12-11 20:58:26 Training Loss = 0.019020702201187 
2016-12-11 20:58:29 Valid Error = 0.24422843256379 
2016-12-11 20:58:29 Valid Loss = 0.016299773493405 
2016-12-11 20:58:31 Test Error = 0.23471615720524 
2016-12-11 20:58:31 Test Loss = 0.016877286590003 
2016-12-11 20:58:31 -------------------LR------------------- 
2016-12-11 20:58:31 0.00048828125 
2016-12-11 20:58:31 Epoch 252 
2016-12-11 21:00:06 Training Error = 0.2363980018901 
2016-12-11 21:00:06 Training Loss = 0.018937405142702 
2016-12-11 21:00:08 Valid Error = 0.23450789793439 
2016-12-11 21:00:08 Valid Loss = 0.016308804673454 
2016-12-11 21:00:10 Test Error = 0.22161572052402 
2016-12-11 21:00:10 Test Loss = 0.016933690831552 
2016-12-11 21:00:10 -------------------LR------------------- 
2016-12-11 21:00:10 0.00048828125 
2016-12-11 21:00:10 Epoch 253 
2016-12-11 21:01:46 Training Error = 0.23558795733765 
2016-12-11 21:01:46 Training Loss = 0.019040447914175 
2016-12-11 21:01:49 Valid Error = 0.23086269744836 
2016-12-11 21:01:49 Valid Loss = 0.016487147506333 
2016-12-11 21:01:51 Test Error = 0.22052401746725 
2016-12-11 21:01:51 Test Loss = 0.017117764825135 
2016-12-11 21:01:51 -------------------LR------------------- 
2016-12-11 21:01:51 0.00048828125 
2016-12-11 21:01:51 Epoch 254 
2016-12-11 21:03:29 Training Error = 0.2378830835696 
2016-12-11 21:03:29 Training Loss = 0.018972955283247 
2016-12-11 21:03:31 Valid Error = 0.23936816524909 
2016-12-11 21:03:31 Valid Loss = 0.016447973184325 
2016-12-11 21:03:34 Test Error = 0.22489082969432 
2016-12-11 21:03:34 Test Loss = 0.017009271468992 
2016-12-11 21:03:34 -------------------LR------------------- 
2016-12-11 21:03:34 0.00048828125 
2016-12-11 21:03:34 Epoch 255 
2016-12-11 21:05:13 Training Error = 0.24220332118267 
2016-12-11 21:05:13 Training Loss = 0.019046662418659 
2016-12-11 21:05:15 Valid Error = 0.24422843256379 
2016-12-11 21:05:15 Valid Loss = 0.016281129108213 
2016-12-11 21:05:18 Test Error = 0.24126637554585 
2016-12-11 21:05:18 Test Loss = 0.016852625055251 
2016-12-11 21:05:18 -------------------LR------------------- 
2016-12-11 21:05:18 0.00048828125 
2016-12-11 21:05:18 Epoch 256 
2016-12-11 21:06:54 Training Error = 0.24031321722695 
2016-12-11 21:06:54 Training Loss = 0.018974669239404 
2016-12-11 21:06:56 Valid Error = 0.23936816524909 
2016-12-11 21:06:56 Valid Loss = 0.016399987268951 
2016-12-11 21:06:59 Test Error = 0.22489082969432 
2016-12-11 21:06:59 Test Loss = 0.01693229947994 
2016-12-11 21:06:59 -------------------LR------------------- 
2016-12-11 21:06:59 0.00048828125 
2016-12-11 21:06:59 Epoch 257 
2016-12-11 21:08:34 Training Error = 0.238018090995 
2016-12-11 21:08:34 Training Loss = 0.019074168021147 
2016-12-11 21:08:37 Valid Error = 0.22721749696233 
2016-12-11 21:08:37 Valid Loss = 0.016193478296736 
2016-12-11 21:08:39 Test Error = 0.21397379912664 
2016-12-11 21:08:39 Test Loss = 0.016769494589637 
2016-12-11 21:08:39 -------------------LR------------------- 
2016-12-11 21:08:39 0.00048828125 
2016-12-11 21:08:39 Epoch 258 
2016-12-11 21:10:18 Training Error = 0.23572296476306 
2016-12-11 21:10:18 Training Loss = 0.018977032897164 
2016-12-11 21:10:20 Valid Error = 0.24179829890644 
2016-12-11 21:10:20 Valid Loss = 0.016662396883484 
2016-12-11 21:10:23 Test Error = 0.22161572052402 
2016-12-11 21:10:23 Test Loss = 0.017243637025746 
2016-12-11 21:10:23 -------------------LR------------------- 
2016-12-11 21:10:23 0.00048828125 
2016-12-11 21:10:23 Epoch 259 
2016-12-11 21:11:59 Training Error = 0.24139327663021 
2016-12-11 21:11:59 Training Loss = 0.019148274104802 
2016-12-11 21:12:02 Valid Error = 0.23936816524909 
2016-12-11 21:12:02 Valid Loss = 0.016430054284018 
2016-12-11 21:12:04 Test Error = 0.23144104803493 
2016-12-11 21:12:04 Test Loss = 0.01696475437264 
2016-12-11 21:12:04 -------------------LR------------------- 
2016-12-11 21:12:04 0.00048828125 
2016-12-11 21:12:04 Epoch 260 
2016-12-11 21:13:42 Training Error = 0.23342783853112 
2016-12-11 21:13:42 Training Loss = 0.018953928421328 
2016-12-11 21:13:44 Valid Error = 0.22600243013366 
2016-12-11 21:13:44 Valid Loss = 0.016602693450119 
2016-12-11 21:13:47 Test Error = 0.21288209606987 
2016-12-11 21:13:47 Test Loss = 0.017239291636772 
2016-12-11 21:13:47 -------------------LR------------------- 
2016-12-11 21:13:47 0.00048828125 
2016-12-11 21:13:47 Epoch 261 
2016-12-11 21:15:24 Training Error = 0.23828810584582 
2016-12-11 21:15:24 Training Loss = 0.019040775030816 
2016-12-11 21:15:26 Valid Error = 0.24787363304982 
2016-12-11 21:15:26 Valid Loss = 0.0165745707724 
2016-12-11 21:15:28 Test Error = 0.23580786026201 
2016-12-11 21:15:28 Test Loss = 0.017089846367929 
2016-12-11 21:15:28 -------------------LR------------------- 
2016-12-11 21:15:28 0.00048828125 
2016-12-11 21:15:28 Epoch 262 
2016-12-11 21:17:04 Training Error = 0.23653300931551 
2016-12-11 21:17:04 Training Loss = 0.01902528791141 
2016-12-11 21:17:06 Valid Error = 0.23815309842041 
2016-12-11 21:17:06 Valid Loss = 0.016560182219324 
2016-12-11 21:17:08 Test Error = 0.22707423580786 
2016-12-11 21:17:08 Test Loss = 0.01714288311067 
2016-12-11 21:17:08 -------------------LR------------------- 
2016-12-11 21:17:08 0.00048828125 
2016-12-11 21:17:08 Epoch 263 
2016-12-11 21:18:45 Training Error = 0.24179829890644 
2016-12-11 21:18:45 Training Loss = 0.01907299882073 
2016-12-11 21:18:48 Valid Error = 0.23936816524909 
2016-12-11 21:18:48 Valid Loss = 0.016361185426528 
2016-12-11 21:18:50 Test Error = 0.22489082969432 
2016-12-11 21:18:50 Test Loss = 0.016892075117897 
2016-12-11 21:18:50 -------------------LR------------------- 
2016-12-11 21:18:50 0.00048828125 
2016-12-11 21:18:50 Epoch 264 
2016-12-11 21:20:28 Training Error = 0.23936816524909 
2016-12-11 21:20:28 Training Loss = 0.019131710232929 
2016-12-11 21:20:30 Valid Error = 0.23329283110571 
2016-12-11 21:20:30 Valid Loss = 0.016446971406208 
2016-12-11 21:20:32 Test Error = 0.21943231441048 
2016-12-11 21:20:32 Test Loss = 0.016989169292201 
2016-12-11 21:20:32 -------------------LR------------------- 
2016-12-11 21:20:32 0.00048828125 
2016-12-11 21:20:32 Epoch 265 
2016-12-11 21:22:08 Training Error = 0.23882813554746 
2016-12-11 21:22:08 Training Loss = 0.019108238621489 
2016-12-11 21:22:10 Valid Error = 0.23572296476306 
2016-12-11 21:22:10 Valid Loss = 0.016467587148213 
2016-12-11 21:22:12 Test Error = 0.21506550218341 
2016-12-11 21:22:12 Test Loss = 0.016969272295634 
2016-12-11 21:22:12 -------------------LR------------------- 
2016-12-11 21:22:12 0.00048828125 
2016-12-11 21:22:12 Epoch 266 
2016-12-11 21:23:49 Training Error = 0.24233832860807 
2016-12-11 21:23:49 Training Loss = 0.018981044620823 
2016-12-11 21:23:52 Valid Error = 0.24179829890644 
2016-12-11 21:23:52 Valid Loss = 0.016541654429742 
2016-12-11 21:23:54 Test Error = 0.23034934497817 
2016-12-11 21:23:54 Test Loss = 0.017144936284209 
2016-12-11 21:23:54 -------------------LR------------------- 
2016-12-11 21:23:54 0.00048828125 
2016-12-11 21:23:54 Epoch 267 
2016-12-11 21:25:28 Training Error = 0.23761306871878 
2016-12-11 21:25:28 Training Loss = 0.019110626582893 
2016-12-11 21:25:31 Valid Error = 0.22843256379101 
2016-12-11 21:25:31 Valid Loss = 0.016389930133841 
2016-12-11 21:25:33 Test Error = 0.20960698689956 
2016-12-11 21:25:33 Test Loss = 0.016936449973412 
2016-12-11 21:25:33 -------------------LR------------------- 
2016-12-11 21:25:33 0.00048828125 
2016-12-11 21:25:33 Epoch 268 
2016-12-11 21:27:11 Training Error = 0.23936816524909 
2016-12-11 21:27:11 Training Loss = 0.019059399717869 
2016-12-11 21:27:14 Valid Error = 0.24787363304982 
2016-12-11 21:27:14 Valid Loss = 0.016457523142999 
2016-12-11 21:27:16 Test Error = 0.23580786026201 
2016-12-11 21:27:16 Test Loss = 0.017023245181913 
2016-12-11 21:27:16 -------------------LR------------------- 
2016-12-11 21:27:16 0.00048828125 
2016-12-11 21:27:16 Epoch 269 
2016-12-11 21:28:53 Training Error = 0.23936816524909 
2016-12-11 21:28:53 Training Loss = 0.019086336754443 
2016-12-11 21:28:55 Valid Error = 0.23572296476306 
2016-12-11 21:28:55 Valid Loss = 0.016605601439207 
2016-12-11 21:28:58 Test Error = 0.23034934497817 
2016-12-11 21:28:58 Test Loss = 0.017109115856146 
2016-12-11 21:28:58 -------------------LR------------------- 
2016-12-11 21:28:58 0.00048828125 
2016-12-11 21:28:58 Epoch 270 
2016-12-11 21:30:35 Training Error = 0.23653300931551 
2016-12-11 21:30:35 Training Loss = 0.01901139910655 
2016-12-11 21:30:38 Valid Error = 0.23693803159174 
2016-12-11 21:30:38 Valid Loss = 0.016530736310319 
2016-12-11 21:30:40 Test Error = 0.21397379912664 
2016-12-11 21:30:40 Test Loss = 0.017056427173365 
2016-12-11 21:30:40 -------------------LR------------------- 
2016-12-11 21:30:40 0.00048828125 
2016-12-11 21:30:40 Epoch 271 
2016-12-11 21:32:18 Training Error = 0.24044822465236 
2016-12-11 21:32:18 Training Loss = 0.019077263722648 
2016-12-11 21:32:21 Valid Error = 0.22114216281896 
2016-12-11 21:32:21 Valid Loss = 0.016264687917629 
2016-12-11 21:32:23 Test Error = 0.21069868995633 
2016-12-11 21:32:23 Test Loss = 0.016812295508541 
2016-12-11 21:32:23 -------------------LR------------------- 
2016-12-11 21:32:23 0.00048828125 
2016-12-11 21:32:23 Epoch 272 
2016-12-11 21:33:57 Training Error = 0.23612798703929 
2016-12-11 21:33:57 Training Loss = 0.018958309879125 
2016-12-11 21:33:59 Valid Error = 0.25030376670717 
2016-12-11 21:33:59 Valid Loss = 0.016483693995398 
2016-12-11 21:34:02 Test Error = 0.2325327510917 
2016-12-11 21:34:02 Test Loss = 0.01706285660563 
2016-12-11 21:34:02 -------------------LR------------------- 
2016-12-11 21:34:02 0.00048828125 
2016-12-11 21:34:02 Epoch 273 
2016-12-11 21:35:40 Training Error = 0.2411232617794 
2016-12-11 21:35:40 Training Loss = 0.019092177077786 
2016-12-11 21:35:42 Valid Error = 0.24422843256379 
2016-12-11 21:35:42 Valid Loss = 0.016677329134225 
2016-12-11 21:35:45 Test Error = 0.23471615720524 
2016-12-11 21:35:45 Test Loss = 0.017281631114436 
2016-12-11 21:35:45 -------------------LR------------------- 
2016-12-11 21:35:45 0.00048828125 
2016-12-11 21:35:45 Epoch 274 
2016-12-11 21:37:22 Training Error = 0.24139327663021 
2016-12-11 21:37:22 Training Loss = 0.019015693209711 
2016-12-11 21:37:24 Valid Error = 0.22843256379101 
2016-12-11 21:37:24 Valid Loss = 0.016413418340794 
2016-12-11 21:37:27 Test Error = 0.20960698689956 
2016-12-11 21:37:27 Test Loss = 0.016976348153906 
2016-12-11 21:37:27 -------------------LR------------------- 
2016-12-11 21:37:27 0.00048828125 
2016-12-11 21:37:27 Epoch 275 
2016-12-11 21:39:02 Training Error = 0.23855812069664 
2016-12-11 21:39:02 Training Loss = 0.019041243341388 
2016-12-11 21:39:04 Valid Error = 0.22843256379101 
2016-12-11 21:39:04 Valid Loss = 0.016765221087478 
2016-12-11 21:39:07 Test Error = 0.22816593886463 
2016-12-11 21:39:07 Test Loss = 0.017357235624899 
2016-12-11 21:39:07 -------------------LR------------------- 
2016-12-11 21:39:07 0.00048828125 
2016-12-11 21:39:07 Epoch 276 
2016-12-11 21:40:45 Training Error = 0.24058323207776 
2016-12-11 21:40:45 Training Loss = 0.018962231305987 
2016-12-11 21:40:47 Valid Error = 0.23936816524909 
2016-12-11 21:40:47 Valid Loss = 0.016530369558273 
2016-12-11 21:40:50 Test Error = 0.23144104803493 
2016-12-11 21:40:50 Test Loss = 0.017119430311365 
2016-12-11 21:40:50 -------------------LR------------------- 
2016-12-11 21:40:50 0.00048828125 
2016-12-11 21:40:50 Epoch 277 
2016-12-11 21:42:24 Training Error = 0.23504792763602 
2016-12-11 21:42:24 Training Loss = 0.018923875595958 
2016-12-11 21:42:26 Valid Error = 0.23086269744836 
2016-12-11 21:42:26 Valid Loss = 0.016436353747155 
2016-12-11 21:42:29 Test Error = 0.21724890829694 
2016-12-11 21:42:29 Test Loss = 0.017005130185021 
2016-12-11 21:42:29 -------------------LR------------------- 
2016-12-11 21:42:29 0.00048828125 
2016-12-11 21:42:29 Epoch 278 
2016-12-11 21:44:08 Training Error = 0.23680302416633 
2016-12-11 21:44:08 Training Loss = 0.019012206004011 
2016-12-11 21:44:10 Valid Error = 0.22478736330498 
2016-12-11 21:44:10 Valid Loss = 0.016620349539139 
2016-12-11 21:44:12 Test Error = 0.21724890829694 
2016-12-11 21:44:12 Test Loss = 0.017127018239763 
2016-12-11 21:44:12 -------------------LR------------------- 
2016-12-11 21:44:12 0.00048828125 
2016-12-11 21:44:12 Epoch 279 
2016-12-11 21:45:47 Training Error = 0.23842311327123 
2016-12-11 21:45:47 Training Loss = 0.019031016401123 
2016-12-11 21:45:49 Valid Error = 0.23329283110571 
2016-12-11 21:45:49 Valid Loss = 0.016530428252461 
2016-12-11 21:45:52 Test Error = 0.22161572052402 
2016-12-11 21:45:52 Test Loss = 0.017104506149791 
2016-12-11 21:45:52 -------------------LR------------------- 
2016-12-11 21:45:52 0.00048828125 
2016-12-11 21:45:52 Epoch 280 
2016-12-11 21:47:30 Training Error = 0.23734305386796 
2016-12-11 21:47:30 Training Loss = 0.019038534790118 
2016-12-11 21:47:32 Valid Error = 0.23815309842041 
2016-12-11 21:47:32 Valid Loss = 0.016343659707651 
2016-12-11 21:47:35 Test Error = 0.2292576419214 
2016-12-11 21:47:35 Test Loss = 0.016907406632417 
2016-12-11 21:47:35 -------------------LR------------------- 
2016-12-11 21:47:35 0.00048828125 
2016-12-11 21:47:35 Epoch 281 
2016-12-11 21:49:12 Training Error = 0.24125826920481 
2016-12-11 21:49:12 Training Loss = 0.019129054897581 
2016-12-11 21:49:15 Valid Error = 0.21992709599028 
2016-12-11 21:49:15 Valid Loss = 0.016560803554226 
2016-12-11 21:49:17 Test Error = 0.20524017467249 
2016-12-11 21:49:17 Test Loss = 0.017112985265021 
2016-12-11 21:49:17 -------------------LR------------------- 
2016-12-11 21:49:17 0.00048828125 
2016-12-11 21:49:17 Epoch 282 
2016-12-11 21:50:53 Training Error = 0.23666801674092 
2016-12-11 21:50:53 Training Loss = 0.019034338670457 
2016-12-11 21:50:55 Valid Error = 0.23086269744836 
2016-12-11 21:50:55 Valid Loss = 0.016512232040584 
2016-12-11 21:50:57 Test Error = 0.21069868995633 
2016-12-11 21:50:57 Test Loss = 0.017104245541142 
2016-12-11 21:50:57 -------------------LR------------------- 
2016-12-11 21:50:57 0.00048828125 
2016-12-11 21:50:57 Epoch 283 
2016-12-11 21:52:35 Training Error = 0.23828810584582 
2016-12-11 21:52:35 Training Loss = 0.019028747718035 
2016-12-11 21:52:37 Valid Error = 0.23329283110571 
2016-12-11 21:52:37 Valid Loss = 0.016539824102112 
2016-12-11 21:52:40 Test Error = 0.22816593886463 
2016-12-11 21:52:40 Test Loss = 0.017040229420257 
2016-12-11 21:52:40 -------------------LR------------------- 
2016-12-11 21:52:40 0.00048828125 
2016-12-11 21:52:40 Epoch 284 
2016-12-11 21:54:17 Training Error = 0.23693803159174 
2016-12-11 21:54:17 Training Loss = 0.01897373683868 
2016-12-11 21:54:19 Valid Error = 0.22478736330498 
2016-12-11 21:54:19 Valid Loss = 0.01628568061304 
2016-12-11 21:54:21 Test Error = 0.21724890829694 
2016-12-11 21:54:21 Test Loss = 0.016821027659123 
2016-12-11 21:54:21 -------------------LR------------------- 
2016-12-11 21:54:21 0.00048828125 
2016-12-11 21:54:21 Epoch 285 
2016-12-11 21:56:00 Training Error = 0.23774807614419 
2016-12-11 21:56:00 Training Loss = 0.019078538911388 
2016-12-11 21:56:02 Valid Error = 0.23086269744836 
2016-12-11 21:56:02 Valid Loss = 0.016512289495768 
2016-12-11 21:56:04 Test Error = 0.22052401746725 
2016-12-11 21:56:04 Test Loss = 0.017032193171433 
2016-12-11 21:56:04 -------------------LR------------------- 
2016-12-11 21:56:04 0.00048828125 
2016-12-11 21:56:04 Epoch 286 
2016-12-11 21:57:42 Training Error = 0.23761306871878 
2016-12-11 21:57:42 Training Loss = 0.019067620025876 
2016-12-11 21:57:44 Valid Error = 0.24179829890644 
2016-12-11 21:57:44 Valid Loss = 0.016480464626696 
2016-12-11 21:57:47 Test Error = 0.22379912663755 
2016-12-11 21:57:47 Test Loss = 0.017048555293114 
2016-12-11 21:57:47 -------------------LR------------------- 
2016-12-11 21:57:47 0.00048828125 
2016-12-11 21:57:47 Epoch 287 
2016-12-11 21:59:23 Training Error = 0.23531794248684 
2016-12-11 21:59:23 Training Loss = 0.019082251388441 
2016-12-11 21:59:25 Valid Error = 0.23815309842041 
2016-12-11 21:59:25 Valid Loss = 0.016698424758595 
2016-12-11 21:59:27 Test Error = 0.23799126637555 
2016-12-11 21:59:27 Test Loss = 0.017324566763211 
2016-12-11 21:59:27 -------------------LR------------------- 
2016-12-11 21:59:27 0.00048828125 
2016-12-11 21:59:27 Epoch 288 
2016-12-11 22:01:03 Training Error = 0.23909815039827 
2016-12-11 22:01:03 Training Loss = 0.019086029516092 
2016-12-11 22:01:06 Valid Error = 0.23086269744836 
2016-12-11 22:01:06 Valid Loss = 0.016502650941692 
2016-12-11 22:01:08 Test Error = 0.22052401746725 
2016-12-11 22:01:08 Test Loss = 0.017090155860178 
2016-12-11 22:01:08 -------------------LR------------------- 
2016-12-11 22:01:08 0.00048828125 
2016-12-11 22:01:08 Epoch 289 
2016-12-11 22:02:47 Training Error = 0.24044822465236 
2016-12-11 22:02:47 Training Loss = 0.019122666720923 
2016-12-11 22:02:49 Valid Error = 0.22114216281896 
2016-12-11 22:02:49 Valid Loss = 0.016161247885605 
2016-12-11 22:02:52 Test Error = 0.21069868995633 
2016-12-11 22:02:52 Test Loss = 0.016742640414269 
2016-12-11 22:02:52 -------------------LR------------------- 
2016-12-11 22:02:52 0.00048828125 
2016-12-11 22:02:52 Epoch 290 
2016-12-11 22:04:32 Training Error = 0.23828810584582 
2016-12-11 22:04:32 Training Loss = 0.01902741888593 
2016-12-11 22:04:34 Valid Error = 0.24787363304982 
2016-12-11 22:04:34 Valid Loss = 0.016357314763173 
2016-12-11 22:04:37 Test Error = 0.24235807860262 
2016-12-11 22:04:37 Test Loss = 0.017046921409033 
2016-12-11 22:04:37 -------------------LR------------------- 
2016-12-11 22:04:37 0.00048828125 
2016-12-11 22:04:37 Epoch 291 
2016-12-11 22:06:14 Training Error = 0.23423788308357 
2016-12-11 22:06:14 Training Loss = 0.019007520872326 
2016-12-11 22:06:16 Valid Error = 0.23450789793439 
2016-12-11 22:06:16 Valid Loss = 0.016358222909773 
2016-12-11 22:06:19 Test Error = 0.23471615720524 
2016-12-11 22:06:19 Test Loss = 0.016936559568044 
2016-12-11 22:06:19 -------------------LR------------------- 
2016-12-11 22:06:19 0.00048828125 
2016-12-11 22:06:19 Epoch 292 
2016-12-11 22:07:54 Training Error = 0.23977318752531 
2016-12-11 22:07:54 Training Loss = 0.019020079310012 
2016-12-11 22:07:56 Valid Error = 0.23086269744836 
2016-12-11 22:07:56 Valid Loss = 0.016327275720526 
2016-12-11 22:07:59 Test Error = 0.22052401746725 
2016-12-11 22:07:59 Test Loss = 0.016918399863773 
2016-12-11 22:07:59 -------------------LR------------------- 
2016-12-11 22:07:59 0.00048828125 
2016-12-11 22:07:59 Epoch 293 
2016-12-11 22:09:35 Training Error = 0.24031321722695 
2016-12-11 22:09:35 Training Loss = 0.019085066166193 
2016-12-11 22:09:37 Valid Error = 0.23815309842041 
2016-12-11 22:09:37 Valid Loss = 0.016540665545124 
2016-12-11 22:09:40 Test Error = 0.22707423580786 
2016-12-11 22:09:40 Test Loss = 0.017108508231593 
2016-12-11 22:09:40 -------------------LR------------------- 
2016-12-11 22:09:40 0.00048828125 
2016-12-11 22:09:40 Epoch 294 
2016-12-11 22:11:17 Training Error = 0.23896314297286 
2016-12-11 22:11:17 Training Loss = 0.019005116657761 
2016-12-11 22:11:19 Valid Error = 0.23693803159174 
2016-12-11 22:11:19 Valid Loss = 0.016359590820434 
2016-12-11 22:11:21 Test Error = 0.21397379912664 
2016-12-11 22:11:21 Test Loss = 0.016931818637973 
2016-12-11 22:11:21 -------------------LR------------------- 
2016-12-11 22:11:21 0.00048828125 
2016-12-11 22:11:21 Epoch 295 
2016-12-11 22:12:59 Training Error = 0.23774807614419 
2016-12-11 22:12:59 Training Loss = 0.01900894229322 
2016-12-11 22:13:01 Valid Error = 0.25151883353584 
2016-12-11 22:13:01 Valid Loss = 0.016445260817469 
2016-12-11 22:13:04 Test Error = 0.24454148471616 
2016-12-11 22:13:04 Test Loss = 0.017069081184911 
2016-12-11 22:13:04 -------------------LR------------------- 
2016-12-11 22:13:04 0.00048828125 
2016-12-11 22:13:04 Epoch 296 
2016-12-11 22:14:41 Training Error = 0.23869312812205 
2016-12-11 22:14:41 Training Loss = 0.019049481553811 
2016-12-11 22:14:44 Valid Error = 0.23086269744836 
2016-12-11 22:14:44 Valid Loss = 0.01643722583838 
2016-12-11 22:14:46 Test Error = 0.22052401746725 
2016-12-11 22:14:46 Test Loss = 0.016983048495124 
2016-12-11 22:14:46 -------------------LR------------------- 
2016-12-11 22:14:46 0.00048828125 
2016-12-11 22:14:46 Epoch 297 
2016-12-11 22:16:22 Training Error = 0.23855812069664 
2016-12-11 22:16:22 Training Loss = 0.019089502165759 
2016-12-11 22:16:24 Valid Error = 0.24058323207776 
2016-12-11 22:16:24 Valid Loss = 0.016531529608666 
2016-12-11 22:16:27 Test Error = 0.22816593886463 
2016-12-11 22:16:27 Test Loss = 0.017137319620918 
2016-12-11 22:16:27 -------------------LR------------------- 
2016-12-11 22:16:27 0.00048828125 
2016-12-11 22:16:27 Epoch 298 
2016-12-11 22:18:04 Training Error = 0.2363980018901 
2016-12-11 22:18:04 Training Loss = 0.018995105099545 
2016-12-11 22:18:06 Valid Error = 0.24787363304982 
2016-12-11 22:18:06 Valid Loss = 0.016747017951556 
2016-12-11 22:18:08 Test Error = 0.23580786026201 
2016-12-11 22:18:08 Test Loss = 0.017303822663874 
2016-12-11 22:18:08 -------------------LR------------------- 
2016-12-11 22:18:08 0.00048828125 
2016-12-11 22:18:08 Epoch 299 
2016-12-11 22:19:47 Training Error = 0.24071823950317 
2016-12-11 22:19:47 Training Loss = 0.01910064138601 
2016-12-11 22:19:50 Valid Error = 0.23086269744836 
2016-12-11 22:19:50 Valid Loss = 0.016365260218423 
2016-12-11 22:19:52 Test Error = 0.22052401746725 
2016-12-11 22:19:52 Test Loss = 0.016907547205881 
2016-12-11 22:19:52 -------------------LR------------------- 
2016-12-11 22:19:52 0.00048828125 
2016-12-11 22:19:52 Epoch 300 
2016-12-11 22:21:30 Training Error = 0.23923315782368 
2016-12-11 22:21:30 Training Loss = 0.019009362734136 
2016-12-11 22:21:32 Valid Error = 0.23693803159174 
2016-12-11 22:21:32 Valid Loss = 0.016627806975128 
2016-12-11 22:21:34 Test Error = 0.21397379912664 
2016-12-11 22:21:34 Test Loss = 0.017188679533067 
2016-12-11 22:21:34 -------------------LR------------------- 
2016-12-11 22:21:34 0.000244140625 
2016-12-11 22:21:34 Epoch 301 
2016-12-11 22:23:12 Training Error = 0.24058323207776 
2016-12-11 22:23:12 Training Loss = 0.019069953430932 
2016-12-11 22:23:14 Valid Error = 0.22843256379101 
2016-12-11 22:23:14 Valid Loss = 0.01641043793856 
2016-12-11 22:23:16 Test Error = 0.20960698689956 
2016-12-11 22:23:16 Test Loss = 0.016995117492925 
2016-12-11 22:23:17 -------------------LR------------------- 
2016-12-11 22:23:17 0.000244140625 
2016-12-11 22:23:17 Epoch 302 
2016-12-11 22:24:51 Training Error = 0.23909815039827 
2016-12-11 22:24:51 Training Loss = 0.019038312279787 
2016-12-11 22:24:53 Valid Error = 0.23572296476306 
2016-12-11 22:24:53 Valid Loss = 0.016335591332634 
2016-12-11 22:24:55 Test Error = 0.22816593886463 
2016-12-11 22:24:55 Test Loss = 0.016969389245401 
2016-12-11 22:24:55 -------------------LR------------------- 
2016-12-11 22:24:55 0.000244140625 
2016-12-11 22:24:55 Epoch 303 
2016-12-11 22:26:33 Training Error = 0.23855812069664 
2016-12-11 22:26:33 Training Loss = 0.01903467900142 
2016-12-11 22:26:35 Valid Error = 0.23693803159174 
2016-12-11 22:26:35 Valid Loss = 0.016452131658102 
2016-12-11 22:26:38 Test Error = 0.22052401746725 
2016-12-11 22:26:38 Test Loss = 0.01704049813202 
2016-12-11 22:26:38 -------------------LR------------------- 
2016-12-11 22:26:38 0.000244140625 
2016-12-11 22:26:38 Epoch 304 
2016-12-11 22:28:15 Training Error = 0.23680302416633 
2016-12-11 22:28:15 Training Loss = 0.019050758273117 
2016-12-11 22:28:17 Valid Error = 0.23936816524909 
2016-12-11 22:28:17 Valid Loss = 0.016449591481896 
2016-12-11 22:28:19 Test Error = 0.22489082969432 
2016-12-11 22:28:19 Test Loss = 0.017092478275299 
2016-12-11 22:28:19 -------------------LR------------------- 
2016-12-11 22:28:19 0.000244140625 
2016-12-11 22:28:19 Epoch 305 
2016-12-11 22:29:58 Training Error = 0.2411232617794 
2016-12-11 22:29:58 Training Loss = 0.019140643505539 
2016-12-11 22:30:00 Valid Error = 0.23936816524909 
2016-12-11 22:30:00 Valid Loss = 0.016258536755883 
2016-12-11 22:30:02 Test Error = 0.23144104803493 
2016-12-11 22:30:02 Test Loss = 0.016854457543566 
2016-12-11 22:30:02 -------------------LR------------------- 
2016-12-11 22:30:02 0.000244140625 
2016-12-11 22:30:02 Epoch 306 
2016-12-11 22:31:39 Training Error = 0.24058323207776 
2016-12-11 22:31:39 Training Loss = 0.019028508379615 
2016-12-11 22:31:41 Valid Error = 0.22235722964763 
2016-12-11 22:31:41 Valid Loss = 0.016250005198918 
2016-12-11 22:31:44 Test Error = 0.20633187772926 
2016-12-11 22:31:44 Test Loss = 0.016822318189284 
2016-12-11 22:31:44 -------------------LR------------------- 
2016-12-11 22:31:44 0.000244140625 
2016-12-11 22:31:44 Epoch 307 
2016-12-11 22:33:17 Training Error = 0.23653300931551 
2016-12-11 22:33:17 Training Loss = 0.018949565591859 
2016-12-11 22:33:19 Valid Error = 0.23572296476306 
2016-12-11 22:33:19 Valid Loss = 0.016568626074998 
2016-12-11 22:33:22 Test Error = 0.23034934497817 
2016-12-11 22:33:22 Test Loss = 0.017139575419083 
2016-12-11 22:33:22 -------------------LR------------------- 
2016-12-11 22:33:22 0.000244140625 
2016-12-11 22:33:22 Epoch 308 
2016-12-11 22:35:00 Training Error = 0.24368840286216 
2016-12-11 22:35:00 Training Loss = 0.019051824559209 
2016-12-11 22:35:02 Valid Error = 0.23086269744836 
2016-12-11 22:35:02 Valid Loss = 0.016509165937773 
2016-12-11 22:35:04 Test Error = 0.21069868995633 
2016-12-11 22:35:04 Test Loss = 0.017066523608039 
2016-12-11 22:35:04 -------------------LR------------------- 
2016-12-11 22:35:04 0.000244140625 
2016-12-11 22:35:04 Epoch 309 
2016-12-11 22:36:43 Training Error = 0.23963818009991 
2016-12-11 22:36:43 Training Loss = 0.019008263936362 
2016-12-11 22:36:45 Valid Error = 0.23572296476306 
2016-12-11 22:36:45 Valid Loss = 0.016467908846569 
2016-12-11 22:36:47 Test Error = 0.23034934497817 
2016-12-11 22:36:47 Test Loss = 0.017040297517589 
2016-12-11 22:36:47 -------------------LR------------------- 
2016-12-11 22:36:47 0.000244140625 
2016-12-11 22:36:47 Epoch 310 
2016-12-11 22:38:28 Training Error = 0.23612798703929 
2016-12-11 22:38:28 Training Loss = 0.019064500264679 
2016-12-11 22:38:30 Valid Error = 0.23936816524909 
2016-12-11 22:38:30 Valid Loss = 0.01655686719091 
2016-12-11 22:38:32 Test Error = 0.22489082969432 
2016-12-11 22:38:32 Test Loss = 0.017171102473938 
2016-12-11 22:38:32 -------------------LR------------------- 
2016-12-11 22:38:32 0.000244140625 
2016-12-11 22:38:32 Epoch 311 
2016-12-11 22:40:08 Training Error = 0.24017820980154 
2016-12-11 22:40:08 Training Loss = 0.019097402137922 
2016-12-11 22:40:10 Valid Error = 0.23936816524909 
2016-12-11 22:40:10 Valid Loss = 0.016408862103884 
2016-12-11 22:40:13 Test Error = 0.22489082969432 
2016-12-11 22:40:13 Test Loss = 0.016986275233474 
2016-12-11 22:40:13 -------------------LR------------------- 
2016-12-11 22:40:13 0.000244140625 
2016-12-11 22:40:13 Epoch 312 
2016-12-11 22:41:49 Training Error = 0.23869312812205 
2016-12-11 22:41:49 Training Loss = 0.019034159656306 
2016-12-11 22:41:51 Valid Error = 0.23693803159174 
2016-12-11 22:41:51 Valid Loss = 0.016372749206543 
2016-12-11 22:41:53 Test Error = 0.21397379912664 
2016-12-11 22:41:53 Test Loss = 0.016940149668775 
2016-12-11 22:41:53 -------------------LR------------------- 
2016-12-11 22:41:53 0.000244140625 
2016-12-11 22:41:53 Epoch 313 
2016-12-11 22:43:30 Training Error = 0.24017820980154 
2016-12-11 22:43:30 Training Loss = 0.019088290684183 
2016-12-11 22:43:32 Valid Error = 0.23329283110571 
2016-12-11 22:43:32 Valid Loss = 0.016464449670209 
2016-12-11 22:43:35 Test Error = 0.21943231441048 
2016-12-11 22:43:35 Test Loss = 0.017021015874701 
2016-12-11 22:43:35 -------------------LR------------------- 
2016-12-11 22:43:35 0.000244140625 
2016-12-11 22:43:35 Epoch 314 
2016-12-11 22:45:13 Training Error = 0.23869312812205 
2016-12-11 22:45:13 Training Loss = 0.019029786933244 
2016-12-11 22:45:15 Valid Error = 0.23329283110571 
2016-12-11 22:45:15 Valid Loss = 0.016463913584743 
2016-12-11 22:45:17 Test Error = 0.21943231441048 
2016-12-11 22:45:17 Test Loss = 0.01701448950113 
2016-12-11 22:45:17 -------------------LR------------------- 
2016-12-11 22:45:17 0.000244140625 
2016-12-11 22:45:17 Epoch 315 
2016-12-11 22:46:54 Training Error = 0.24085324692858 
2016-12-11 22:46:54 Training Loss = 0.019075363041413 
2016-12-11 22:46:56 Valid Error = 0.23086269744836 
2016-12-11 22:46:56 Valid Loss = 0.016643842850859 
2016-12-11 22:46:59 Test Error = 0.21724890829694 
2016-12-11 22:46:59 Test Loss = 0.017133851160411 
2016-12-11 22:46:59 -------------------LR------------------- 
2016-12-11 22:46:59 0.000244140625 
2016-12-11 22:46:59 Epoch 316 
2016-12-11 22:48:35 Training Error = 0.23680302416633 
2016-12-11 22:48:35 Training Loss = 0.019080543534615 
2016-12-11 22:48:37 Valid Error = 0.24301336573512 
2016-12-11 22:48:37 Valid Loss = 0.016456742447197 
2016-12-11 22:48:40 Test Error = 0.22598253275109 
2016-12-11 22:48:40 Test Loss = 0.017028201000363 
2016-12-11 22:48:40 -------------------LR------------------- 
2016-12-11 22:48:40 0.000244140625 
2016-12-11 22:48:40 Epoch 317 
2016-12-11 22:50:17 Training Error = 0.2395031726745 
2016-12-11 22:50:17 Training Loss = 0.018982116025953 
2016-12-11 22:50:19 Valid Error = 0.23086269744836 
2016-12-11 22:50:19 Valid Loss = 0.016412350478591 
2016-12-11 22:50:21 Test Error = 0.22052401746725 
2016-12-11 22:50:21 Test Loss = 0.016988975238177 
2016-12-11 22:50:21 -------------------LR------------------- 
2016-12-11 22:50:21 0.000244140625 
2016-12-11 22:50:21 Epoch 318 
2016-12-11 22:51:57 Training Error = 0.23923315782368 
2016-12-11 22:51:57 Training Loss = 0.019051041115862 
2016-12-11 22:51:59 Valid Error = 0.23936816524909 
2016-12-11 22:51:59 Valid Loss = 0.016312281563664 
2016-12-11 22:52:02 Test Error = 0.23144104803493 
2016-12-11 22:52:02 Test Loss = 0.016867582065607 
2016-12-11 22:52:02 -------------------LR------------------- 
2016-12-11 22:52:02 0.000244140625 
2016-12-11 22:52:02 Epoch 319 
2016-12-11 22:53:40 Training Error = 0.23882813554746 
2016-12-11 22:53:40 Training Loss = 0.019068689725731 
2016-12-11 22:53:43 Valid Error = 0.23936816524909 
2016-12-11 22:53:43 Valid Loss = 0.016359253230776 
2016-12-11 22:53:45 Test Error = 0.23144104803493 
2016-12-11 22:53:45 Test Loss = 0.016900471098283 
2016-12-11 22:53:45 -------------------LR------------------- 
2016-12-11 22:53:45 0.000244140625 
2016-12-11 22:53:45 Epoch 320 
2016-12-11 22:55:23 Training Error = 0.23936816524909 
2016-12-11 22:55:23 Training Loss = 0.019052512907839 
2016-12-11 22:55:25 Valid Error = 0.23572296476306 
2016-12-11 22:55:25 Valid Loss = 0.01657486614435 
2016-12-11 22:55:27 Test Error = 0.22052401746725 
2016-12-11 22:55:27 Test Loss = 0.017104213751999 
2016-12-11 22:55:27 -------------------LR------------------- 
2016-12-11 22:55:27 0.000244140625 
2016-12-11 22:55:27 Epoch 321 
2016-12-11 22:57:05 Training Error = 0.24220332118267 
2016-12-11 22:57:05 Training Loss = 0.019102154522798 
2016-12-11 22:57:07 Valid Error = 0.23086269744836 
2016-12-11 22:57:07 Valid Loss = 0.016642057856431 
2016-12-11 22:57:09 Test Error = 0.22052401746725 
2016-12-11 22:57:09 Test Loss = 0.017202116383447 
2016-12-11 22:57:09 -------------------LR------------------- 
2016-12-11 22:57:09 0.000244140625 
2016-12-11 22:57:09 Epoch 322 
2016-12-11 22:58:48 Training Error = 0.23747806129337 
2016-12-11 22:58:48 Training Loss = 0.019026748295948 
2016-12-11 22:58:51 Valid Error = 0.22478736330498 
2016-12-11 22:58:51 Valid Loss = 0.016592472926524 
2016-12-11 22:58:53 Test Error = 0.20524017467249 
2016-12-11 22:58:53 Test Loss = 0.017215774760527 
2016-12-11 22:58:53 -------------------LR------------------- 
2016-12-11 22:58:53 0.000244140625 
2016-12-11 22:58:53 Epoch 323 
2016-12-11 23:00:27 Training Error = 0.23869312812205 
2016-12-11 23:00:27 Training Loss = 0.018954279211379 
2016-12-11 23:00:30 Valid Error = 0.22478736330498 
2016-12-11 23:00:30 Valid Loss = 0.016487070032554 
2016-12-11 23:00:32 Test Error = 0.21724890829694 
2016-12-11 23:00:32 Test Loss = 0.017041134849872 
2016-12-11 23:00:32 -------------------LR------------------- 
2016-12-11 23:00:32 0.000244140625 
2016-12-11 23:00:32 Epoch 324 
2016-12-11 23:02:09 Training Error = 0.24017820980154 
2016-12-11 23:02:09 Training Loss = 0.019019918985711 
2016-12-11 23:02:12 Valid Error = 0.23086269744836 
2016-12-11 23:02:12 Valid Loss = 0.016484447764906 
2016-12-11 23:02:14 Test Error = 0.22052401746725 
2016-12-11 23:02:14 Test Loss = 0.01704823501749 
2016-12-11 23:02:14 -------------------LR------------------- 
2016-12-11 23:02:14 0.000244140625 
2016-12-11 23:02:14 Epoch 325 
2016-12-11 23:03:50 Training Error = 0.2395031726745 
2016-12-11 23:03:50 Training Loss = 0.019041141328038 
2016-12-11 23:03:52 Valid Error = 0.23693803159174 
2016-12-11 23:03:52 Valid Loss = 0.01654679283559 
2016-12-11 23:03:54 Test Error = 0.21397379912664 
2016-12-11 23:03:54 Test Loss = 0.017121979099473 
2016-12-11 23:03:54 -------------------LR------------------- 
2016-12-11 23:03:54 0.000244140625 
2016-12-11 23:03:54 Epoch 326 
2016-12-11 23:05:32 Training Error = 0.23761306871878 
2016-12-11 23:05:32 Training Loss = 0.019123253224694 
2016-12-11 23:05:34 Valid Error = 0.22600243013366 
2016-12-11 23:05:34 Valid Loss = 0.01628607917221 
2016-12-11 23:05:36 Test Error = 0.21397379912664 
2016-12-11 23:05:36 Test Loss = 0.01686113304562 
2016-12-11 23:05:36 -------------------LR------------------- 
2016-12-11 23:05:36 0.000244140625 
2016-12-11 23:05:36 Epoch 327 
2016-12-11 23:07:15 Training Error = 0.23990819495072 
2016-12-11 23:07:15 Training Loss = 0.019039317202368 
2016-12-11 23:07:17 Valid Error = 0.23329283110571 
2016-12-11 23:07:17 Valid Loss = 0.016289012368023 
2016-12-11 23:07:20 Test Error = 0.21943231441048 
2016-12-11 23:07:20 Test Loss = 0.016925486474255 
2016-12-11 23:07:20 -------------------LR------------------- 
2016-12-11 23:07:20 0.000244140625 
2016-12-11 23:07:20 Epoch 328 
2016-12-11 23:08:56 Training Error = 0.23842311327123 
2016-12-11 23:08:56 Training Loss = 0.019024975644912 
2016-12-11 23:08:58 Valid Error = 0.25273390036452 
2016-12-11 23:08:58 Valid Loss = 0.01650646467456 
2016-12-11 23:09:01 Test Error = 0.24563318777293 
2016-12-11 23:09:01 Test Loss = 0.01709171086355 
2016-12-11 23:09:01 -------------------LR------------------- 
2016-12-11 23:09:01 0.000244140625 
2016-12-11 23:09:01 Epoch 329 
