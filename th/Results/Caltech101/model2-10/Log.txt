2016-12-09 23:10:37 [program started on Fri Dec  9 23:10:37 2016] 
2016-12-09 23:10:37 [command line arguments] 
2016-12-09 23:10:37 stcWeights false 
2016-12-09 23:10:37 LR 0.015625 
2016-12-09 23:10:37 batchSize 300 
2016-12-09 23:10:37 network ./Models/Cifar10_Custom 
2016-12-09 23:10:37 stcNeurons true 
2016-12-09 23:10:37 constBatchSize false 
2016-12-09 23:10:37 chartFileName chart1 
2016-12-09 23:10:37 dp_prepro false 
2016-12-09 23:10:37 nGPU 1 
2016-12-09 23:10:37 dataset Caltech101 
2016-12-09 23:10:37 type cuda 
2016-12-09 23:10:37 momentum 0 
2016-12-09 23:10:37 threads 8 
2016-12-09 23:10:37 weightDecay 0 
2016-12-09 23:10:37 runningVal false 
2016-12-09 23:10:37 convLayerN 2 
2016-12-09 23:10:37 LRDecay 0 
2016-12-09 23:10:37 numHid 1024 
2016-12-09 23:10:37 save /dev/shm/clone/temp/th/Results/Caltech101/model2-10 
2016-12-09 23:10:37 augment false 
2016-12-09 23:10:37 epoch -1 
2016-12-09 23:10:37 modelsFolder ./Models/ 
2016-12-09 23:10:37 format rgb 
2016-12-09 23:10:37 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-09 23:10:37 imageFileExtension svg 
2016-12-09 23:10:37 channel 1 
2016-12-09 23:10:37 devid 14 
2016-12-09 23:10:37 visualize 1 
2016-12-09 23:10:37 LRDecayPerEpoch 0.0001 
2016-12-09 23:10:37 optimization adam 
2016-12-09 23:10:37 SBN true 
2016-12-09 23:10:37 normalization simple 
2016-12-09 23:10:37 title model1 
2016-12-09 23:10:37 load  
2016-12-09 23:10:37 whiten true 
2016-12-09 23:10:37 [----------------------] 
2016-12-09 23:10:39 ==> Network 
2016-12-09 23:10:39 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): nn.View(32768)
  (11): BinaryLinear(32768 -> 1024)
  (12): BatchNormalizationShiftPow2
  (13): nn.HardTanh
  (14): BinarizedNeurons
  (15): BinaryLinear(1024 -> 1024)
  (16): BatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): BinaryLinear(1024 -> 102)
  (20): nn.BatchNormalization
} 
2016-12-09 23:10:39 ==>34865586 Parameters 
2016-12-09 23:10:39 ==> Loss 
2016-12-09 23:10:39 SqrtHingeEmbeddingCriterion 
2016-12-09 23:10:39 
==> Starting Training
 
2016-12-09 23:10:39 Epoch 1 
2016-12-09 23:11:16 Training Error = 0.82408532469286 
2016-12-09 23:11:16 Training Loss = 0.80439621006426 
2016-12-09 23:11:17 Valid Error = 0.79829890643985 
2016-12-09 23:11:17 Valid Loss = 0.41950147274826 
2016-12-09 23:11:19 Test Error = 0.82205240174672 
2016-12-09 23:11:19 Test Loss = 0.42469714046304 
2016-12-09 23:11:19 -------------------LR------------------- 
2016-12-09 23:11:19 0.015625 
2016-12-09 23:11:19 Epoch 2 
2016-12-09 23:11:59 Training Error = 0.64020521128662 
2016-12-09 23:11:59 Training Loss = 0.2728363365706 
2016-12-09 23:12:00 Valid Error = 0.7363304981774 
2016-12-09 23:12:00 Valid Loss = 0.14516147520615 
2016-12-09 23:12:01 Test Error = 0.76091703056769 
2016-12-09 23:12:01 Test Loss = 0.14815460834628 
2016-12-09 23:12:01 -------------------LR------------------- 
2016-12-09 23:12:01 0.015625 
2016-12-09 23:12:01 Epoch 3 
2016-12-09 23:12:38 Training Error = 0.59133252328878 
2016-12-09 23:12:38 Training Loss = 0.098022481683787 
2016-12-09 23:12:39 Valid Error = 0.59902794653706 
2016-12-09 23:12:39 Valid Loss = 0.057928979129162 
2016-12-09 23:12:41 Test Error = 0.632096069869 
2016-12-09 23:12:41 Test Loss = 0.060898730739269 
2016-12-09 23:12:41 -------------------LR------------------- 
2016-12-09 23:12:41 0.015625 
2016-12-09 23:12:41 Epoch 4 
2016-12-09 23:13:17 Training Error = 0.55731065208586 
2016-12-09 23:13:17 Training Loss = 0.046574018620365 
2016-12-09 23:13:18 Valid Error = 0.58809234507898 
2016-12-09 23:13:18 Valid Loss = 0.037680966707001 
2016-12-09 23:13:19 Test Error = 0.61681222707424 
2016-12-09 23:13:19 Test Loss = 0.042440312033385 
2016-12-09 23:13:19 -------------------LR------------------- 
2016-12-09 23:13:19 0.015625 
2016-12-09 23:13:19 Epoch 5 
2016-12-09 23:13:54 Training Error = 0.52126366950182 
2016-12-09 23:13:54 Training Loss = 0.031922632478839 
2016-12-09 23:13:55 Valid Error = 0.54313487241798 
2016-12-09 23:13:55 Valid Loss = 0.029195339439499 
2016-12-09 23:13:56 Test Error = 0.58733624454148 
2016-12-09 23:13:56 Test Loss = 0.03273741968317 
2016-12-09 23:13:56 -------------------LR------------------- 
2016-12-09 23:13:56 0.015625 
2016-12-09 23:13:56 Epoch 6 
2016-12-09 23:14:33 Training Error = 0.51275820170109 
2016-12-09 23:14:33 Training Loss = 0.027583039986474 
2016-12-09 23:14:34 Valid Error = 0.55285540704739 
2016-12-09 23:14:34 Valid Loss = 0.029785390585716 
2016-12-09 23:14:35 Test Error = 0.59934497816594 
2016-12-09 23:14:35 Test Loss = 0.035477038427116 
2016-12-09 23:14:35 -------------------LR------------------- 
2016-12-09 23:14:35 0.015625 
2016-12-09 23:14:35 Epoch 7 
2016-12-09 23:15:11 Training Error = 0.50425273390036 
2016-12-09 23:15:11 Training Loss = 0.026122159999549 
2016-12-09 23:15:12 Valid Error = 0.51640340218712 
2016-12-09 23:15:12 Valid Loss = 0.025179487294527 
2016-12-09 23:15:13 Test Error = 0.56441048034935 
2016-12-09 23:15:13 Test Loss = 0.028969530622944 
2016-12-09 23:15:13 -------------------LR------------------- 
2016-12-09 23:15:13 0.015625 
2016-12-09 23:15:13 Epoch 8 
2016-12-09 23:15:49 Training Error = 0.48953692453085 
2016-12-09 23:15:49 Training Loss = 0.024681120417224 
2016-12-09 23:15:50 Valid Error = 0.50668286755772 
2016-12-09 23:15:50 Valid Loss = 0.025511653832355 
2016-12-09 23:15:51 Test Error = 0.5589519650655 
2016-12-09 23:15:51 Test Loss = 0.03025981490129 
2016-12-09 23:15:51 -------------------LR------------------- 
2016-12-09 23:15:51 0.015625 
2016-12-09 23:15:51 Epoch 9 
2016-12-09 23:16:29 Training Error = 0.47374105575807 
2016-12-09 23:16:29 Training Loss = 0.023765322063967 
2016-12-09 23:16:30 Valid Error = 0.49817739975699 
2016-12-09 23:16:30 Valid Loss = 0.027931552710571 
2016-12-09 23:16:31 Test Error = 0.54257641921397 
2016-12-09 23:16:31 Test Loss = 0.034909059720881 
2016-12-09 23:16:31 -------------------LR------------------- 
2016-12-09 23:16:31 0.015625 
2016-12-09 23:16:31 Epoch 10 
2016-12-09 23:17:13 Training Error = 0.45457000135007 
2016-12-09 23:17:13 Training Loss = 0.023295714765446 
2016-12-09 23:17:15 Valid Error = 0.50303766707169 
2016-12-09 23:17:15 Valid Loss = 0.026454402383525 
2016-12-09 23:17:16 Test Error = 0.54148471615721 
2016-12-09 23:17:16 Test Loss = 0.029422089219872 
2016-12-09 23:17:16 -------------------LR------------------- 
2016-12-09 23:17:16 0.015625 
2016-12-09 23:17:16 Epoch 11 
2016-12-09 23:17:53 Training Error = 0.47833130822195 
2016-12-09 23:17:53 Training Loss = 0.023757719527911 
2016-12-09 23:17:54 Valid Error = 0.50303766707169 
2016-12-09 23:17:54 Valid Loss = 0.023528957908269 
2016-12-09 23:17:55 Test Error = 0.53930131004367 
2016-12-09 23:17:55 Test Loss = 0.026982505703284 
2016-12-09 23:17:55 -------------------LR------------------- 
2016-12-09 23:17:55 0.015625 
2016-12-09 23:17:55 Epoch 12 
2016-12-09 23:18:33 Training Error = 0.47617118941542 
2016-12-09 23:18:33 Training Loss = 0.023773874151416 
2016-12-09 23:18:34 Valid Error = 0.50546780072904 
2016-12-09 23:18:34 Valid Loss = 0.023519388384431 
2016-12-09 23:18:35 Test Error = 0.54585152838428 
2016-12-09 23:18:35 Test Loss = 0.027064710933399 
2016-12-09 23:18:35 -------------------LR------------------- 
2016-12-09 23:18:35 0.015625 
2016-12-09 23:18:35 Epoch 13 
2016-12-09 23:19:13 Training Error = 0.47968138247604 
2016-12-09 23:19:13 Training Loss = 0.023798443500027 
2016-12-09 23:19:14 Valid Error = 0.50303766707169 
2016-12-09 23:19:14 Valid Loss = 0.023434336916548 
2016-12-09 23:19:15 Test Error = 0.53930131004367 
2016-12-09 23:19:15 Test Loss = 0.026960601861181 
2016-12-09 23:19:15 -------------------LR------------------- 
2016-12-09 23:19:15 0.015625 
2016-12-09 23:19:15 Epoch 14 
2016-12-09 23:19:52 Training Error = 0.47576616713919 
2016-12-09 23:19:52 Training Loss = 0.02367662312814 
2016-12-09 23:19:53 Valid Error = 0.50303766707169 
2016-12-09 23:19:53 Valid Loss = 0.023541502032089 
2016-12-09 23:19:54 Test Error = 0.53930131004367 
2016-12-09 23:19:54 Test Loss = 0.027008055121291 
2016-12-09 23:19:54 -------------------LR------------------- 
2016-12-09 23:19:54 0.015625 
2016-12-09 23:19:54 Epoch 15 
2016-12-09 23:20:32 Training Error = 0.47644120426623 
2016-12-09 23:20:32 Training Loss = 0.023834927504318 
2016-12-09 23:20:33 Valid Error = 0.50060753341434 
2016-12-09 23:20:33 Valid Loss = 0.023450676422088 
2016-12-09 23:20:35 Test Error = 0.5382096069869 
2016-12-09 23:20:35 Test Loss = 0.026980483570909 
2016-12-09 23:20:35 -------------------LR------------------- 
2016-12-09 23:20:35 0.015625 
2016-12-09 23:20:35 Epoch 16 
2016-12-09 23:21:11 Training Error = 0.47536114486297 
2016-12-09 23:21:11 Training Loss = 0.023754753765089 
2016-12-09 23:21:12 Valid Error = 0.49696233292831 
2016-12-09 23:21:12 Valid Loss = 0.023370268386317 
2016-12-09 23:21:13 Test Error = 0.54148471615721 
2016-12-09 23:21:13 Test Loss = 0.026940709679734 
2016-12-09 23:21:13 -------------------LR------------------- 
2016-12-09 23:21:13 0.015625 
2016-12-09 23:21:13 Epoch 17 
2016-12-09 23:21:51 Training Error = 0.47738625624409 
2016-12-09 23:21:51 Training Loss = 0.023719956822931 
2016-12-09 23:21:52 Valid Error = 0.49453219927096 
2016-12-09 23:21:52 Valid Loss = 0.023383988404536 
2016-12-09 23:21:53 Test Error = 0.53493449781659 
2016-12-09 23:21:53 Test Loss = 0.026993706031562 
2016-12-09 23:21:53 -------------------LR------------------- 
2016-12-09 23:21:53 0.015625 
2016-12-09 23:21:53 Epoch 18 
2016-12-09 23:22:31 Training Error = 0.47684622654246 
2016-12-09 23:22:31 Training Loss = 0.023746473671155 
2016-12-09 23:22:32 Valid Error = 0.49453219927096 
2016-12-09 23:22:32 Valid Loss = 0.023370560655253 
2016-12-09 23:22:34 Test Error = 0.53493449781659 
2016-12-09 23:22:34 Test Loss = 0.026868501177021 
2016-12-09 23:22:34 -------------------LR------------------- 
2016-12-09 23:22:34 0.015625 
2016-12-09 23:22:34 Epoch 19 
2016-12-09 23:23:10 Training Error = 0.47860132307277 
2016-12-09 23:23:10 Training Loss = 0.023801716863385 
2016-12-09 23:23:11 Valid Error = 0.49453219927096 
2016-12-09 23:23:11 Valid Loss = 0.023401066361108 
2016-12-09 23:23:13 Test Error = 0.53493449781659 
2016-12-09 23:23:13 Test Loss = 0.02696987924233 
2016-12-09 23:23:13 -------------------LR------------------- 
2016-12-09 23:23:13 0.015625 
2016-12-09 23:23:13 Epoch 20 
2016-12-09 23:23:57 Training Error = 0.4775212636695 
2016-12-09 23:23:57 Training Loss = 0.023809738046152 
2016-12-09 23:23:58 Valid Error = 0.49453219927096 
2016-12-09 23:23:58 Valid Loss = 0.023279264382189 
2016-12-09 23:24:00 Test Error = 0.53493449781659 
2016-12-09 23:24:00 Test Loss = 0.026911726964065 
2016-12-09 23:24:00 -------------------LR------------------- 
2016-12-09 23:24:00 0.015625 
2016-12-09 23:24:00 Epoch 21 
2016-12-09 23:24:37 Training Error = 0.47995139732685 
2016-12-09 23:24:37 Training Loss = 0.023756721257084 
2016-12-09 23:24:39 Valid Error = 0.49453219927096 
2016-12-09 23:24:39 Valid Loss = 0.02334991059137 
2016-12-09 23:24:40 Test Error = 0.53493449781659 
2016-12-09 23:24:40 Test Loss = 0.026945245928235 
2016-12-09 23:24:40 -------------------LR------------------- 
2016-12-09 23:24:40 0.015625 
2016-12-09 23:24:40 Epoch 22 
2016-12-09 23:25:17 Training Error = 0.4791413527744 
2016-12-09 23:25:17 Training Loss = 0.023711768682389 
2016-12-09 23:25:18 Valid Error = 0.49939246658566 
2016-12-09 23:25:18 Valid Loss = 0.023448183388457 
2016-12-09 23:25:19 Test Error = 0.54257641921397 
2016-12-09 23:25:19 Test Loss = 0.027011837725546 
2016-12-09 23:25:19 -------------------LR------------------- 
2016-12-09 23:25:19 0.015625 
2016-12-09 23:25:19 Epoch 23 
2016-12-09 23:25:57 Training Error = 0.47765627109491 
2016-12-09 23:25:57 Training Loss = 0.023739681057805 
2016-12-09 23:25:58 Valid Error = 0.50546780072904 
2016-12-09 23:25:58 Valid Loss = 0.023438502315368 
2016-12-09 23:25:59 Test Error = 0.54585152838428 
2016-12-09 23:25:59 Test Loss = 0.02700463252909 
2016-12-09 23:25:59 -------------------LR------------------- 
2016-12-09 23:25:59 0.015625 
2016-12-09 23:25:59 Epoch 24 
2016-12-09 23:26:37 Training Error = 0.47846631564736 
2016-12-09 23:26:37 Training Loss = 0.023733925459337 
2016-12-09 23:26:38 Valid Error = 0.50546780072904 
2016-12-09 23:26:38 Valid Loss = 0.023290744786973 
2016-12-09 23:26:39 Test Error = 0.54585152838428 
2016-12-09 23:26:39 Test Loss = 0.026909134613922 
2016-12-09 23:26:39 -------------------LR------------------- 
2016-12-09 23:26:39 0.015625 
2016-12-09 23:26:39 Epoch 25 
2016-12-09 23:27:16 Training Error = 0.47468610773593 
2016-12-09 23:27:16 Training Loss = 0.023675108341594 
2016-12-09 23:27:17 Valid Error = 0.49696233292831 
2016-12-09 23:27:17 Valid Loss = 0.023407694746161 
2016-12-09 23:27:18 Test Error = 0.54148471615721 
2016-12-09 23:27:18 Test Loss = 0.026939538093953 
2016-12-09 23:27:18 -------------------LR------------------- 
2016-12-09 23:27:18 0.015625 
2016-12-09 23:27:19 Epoch 26 
2016-12-09 23:27:57 Training Error = 0.47806129337114 
2016-12-09 23:27:57 Training Loss = 0.023767331490242 
2016-12-09 23:27:58 Valid Error = 0.49817739975699 
2016-12-09 23:27:58 Valid Loss = 0.02326765982542 
2016-12-09 23:27:59 Test Error = 0.53165938864629 
2016-12-09 23:27:59 Test Loss = 0.026809546425452 
2016-12-09 23:27:59 -------------------LR------------------- 
2016-12-09 23:27:59 0.015625 
2016-12-09 23:27:59 Epoch 27 
2016-12-09 23:28:37 Training Error = 0.47711624139328 
2016-12-09 23:28:37 Training Loss = 0.023817826953255 
2016-12-09 23:28:38 Valid Error = 0.49453219927096 
2016-12-09 23:28:38 Valid Loss = 0.023382664562927 
2016-12-09 23:28:39 Test Error = 0.53493449781659 
2016-12-09 23:28:39 Test Loss = 0.026996154021593 
2016-12-09 23:28:39 -------------------LR------------------- 
2016-12-09 23:28:39 0.015625 
2016-12-09 23:28:39 Epoch 28 
2016-12-09 23:29:15 Training Error = 0.47671121911705 
2016-12-09 23:29:15 Training Loss = 0.023736622644345 
2016-12-09 23:29:16 Valid Error = 0.50546780072904 
2016-12-09 23:29:16 Valid Loss = 0.02345817026642 
2016-12-09 23:29:17 Test Error = 0.54585152838428 
2016-12-09 23:29:17 Test Loss = 0.026964809660818 
2016-12-09 23:29:17 -------------------LR------------------- 
2016-12-09 23:29:17 0.015625 
2016-12-09 23:29:17 Epoch 29 
2016-12-09 23:29:54 Training Error = 0.47563115971378 
2016-12-09 23:29:54 Training Loss = 0.02375673307213 
2016-12-09 23:29:55 Valid Error = 0.50303766707169 
2016-12-09 23:29:55 Valid Loss = 0.023417521643643 
2016-12-09 23:29:56 Test Error = 0.53930131004367 
2016-12-09 23:29:56 Test Loss = 0.026968946799733 
2016-12-09 23:29:56 -------------------LR------------------- 
2016-12-09 23:29:56 0.015625 
2016-12-09 23:29:56 Epoch 30 
2016-12-09 23:30:40 Training Error = 0.47968138247604 
2016-12-09 23:30:40 Training Loss = 0.023752970652803 
2016-12-09 23:30:41 Valid Error = 0.50546780072904 
2016-12-09 23:30:41 Valid Loss = 0.023421144325871 
2016-12-09 23:30:42 Test Error = 0.54585152838428 
2016-12-09 23:30:42 Test Loss = 0.026957861262988 
2016-12-09 23:30:42 -------------------LR------------------- 
2016-12-09 23:30:42 0.015625 
2016-12-09 23:30:42 Epoch 31 
2016-12-09 23:31:18 Training Error = 0.4775212636695 
2016-12-09 23:31:18 Training Loss = 0.023722992782253 
2016-12-09 23:31:19 Valid Error = 0.50303766707169 
2016-12-09 23:31:19 Valid Loss = 0.023484147070897 
2016-12-09 23:31:20 Test Error = 0.53930131004367 
2016-12-09 23:31:20 Test Loss = 0.027005811633627 
2016-12-09 23:31:20 -------------------LR------------------- 
2016-12-09 23:31:20 0.015625 
2016-12-09 23:31:20 Epoch 32 
2016-12-09 23:31:57 Training Error = 0.47684622654246 
2016-12-09 23:31:57 Training Loss = 0.023769884217864 
2016-12-09 23:31:58 Valid Error = 0.49453219927096 
2016-12-09 23:31:58 Valid Loss = 0.023491376657338 
2016-12-09 23:31:59 Test Error = 0.53493449781659 
2016-12-09 23:31:59 Test Loss = 0.026957745692309 
2016-12-09 23:31:59 -------------------LR------------------- 
2016-12-09 23:31:59 0.015625 
2016-12-09 23:31:59 Epoch 33 
2016-12-09 23:32:38 Training Error = 0.47738625624409 
2016-12-09 23:32:38 Training Loss = 0.023716013903273 
2016-12-09 23:32:39 Valid Error = 0.49453219927096 
2016-12-09 23:32:39 Valid Loss = 0.023665456061232 
2016-12-09 23:32:40 Test Error = 0.53493449781659 
2016-12-09 23:32:40 Test Loss = 0.02706864070269 
2016-12-09 23:32:40 -------------------LR------------------- 
2016-12-09 23:32:40 0.015625 
2016-12-09 23:32:40 Epoch 34 
2016-12-09 23:33:17 Training Error = 0.47684622654246 
2016-12-09 23:33:17 Training Loss = 0.023768329678971 
2016-12-09 23:33:19 Valid Error = 0.50303766707169 
2016-12-09 23:33:19 Valid Loss = 0.023471292759421 
2016-12-09 23:33:20 Test Error = 0.53930131004367 
2016-12-09 23:33:20 Test Loss = 0.027079992411183 
2016-12-09 23:33:20 -------------------LR------------------- 
2016-12-09 23:33:20 0.015625 
2016-12-09 23:33:20 Epoch 35 
2016-12-09 23:33:58 Training Error = 0.47887133792359 
2016-12-09 23:33:58 Training Loss = 0.023779490946793 
2016-12-09 23:33:59 Valid Error = 0.50546780072904 
2016-12-09 23:33:59 Valid Loss = 0.023336598824806 
2016-12-09 23:34:00 Test Error = 0.54585152838428 
2016-12-09 23:34:00 Test Loss = 0.026920788498486 
2016-12-09 23:34:00 -------------------LR------------------- 
2016-12-09 23:34:00 0.015625 
2016-12-09 23:34:00 Epoch 36 
2016-12-09 23:34:37 Training Error = 0.47711624139328 
2016-12-09 23:34:37 Training Loss = 0.023799806621985 
2016-12-09 23:34:38 Valid Error = 0.49696233292831 
2016-12-09 23:34:38 Valid Loss = 0.023251194379004 
2016-12-09 23:34:40 Test Error = 0.54148471615721 
2016-12-09 23:34:40 Test Loss = 0.026873841636321 
2016-12-09 23:34:40 -------------------LR------------------- 
2016-12-09 23:34:40 0.015625 
2016-12-09 23:34:40 Epoch 37 
2016-12-09 23:35:16 Training Error = 0.47468610773593 
2016-12-09 23:35:16 Training Loss = 0.02371139996113 
2016-12-09 23:35:17 Valid Error = 0.50546780072904 
2016-12-09 23:35:17 Valid Loss = 0.02336444695786 
2016-12-09 23:35:18 Test Error = 0.54585152838428 
2016-12-09 23:35:18 Test Loss = 0.026964518875858 
2016-12-09 23:35:18 -------------------LR------------------- 
2016-12-09 23:35:18 0.015625 
2016-12-09 23:35:18 Epoch 38 
2016-12-09 23:35:57 Training Error = 0.47968138247604 
2016-12-09 23:35:57 Training Loss = 0.023819003839647 
2016-12-09 23:35:58 Valid Error = 0.49210206561361 
2016-12-09 23:35:58 Valid Loss = 0.02345893599207 
2016-12-09 23:35:59 Test Error = 0.52838427947598 
2016-12-09 23:35:59 Test Loss = 0.026987627729092 
2016-12-09 23:35:59 -------------------LR------------------- 
2016-12-09 23:35:59 0.015625 
2016-12-09 23:35:59 Epoch 39 
2016-12-09 23:36:36 Training Error = 0.47765627109491 
2016-12-09 23:36:36 Training Loss = 0.023750888752122 
2016-12-09 23:36:37 Valid Error = 0.49453219927096 
2016-12-09 23:36:37 Valid Loss = 0.023658778097078 
2016-12-09 23:36:38 Test Error = 0.53493449781659 
2016-12-09 23:36:38 Test Loss = 0.027090971430922 
2016-12-09 23:36:38 -------------------LR------------------- 
2016-12-09 23:36:38 0.015625 
2016-12-09 23:36:38 Epoch 40 
2016-12-09 23:37:23 Training Error = 0.47630619684083 
2016-12-09 23:37:23 Training Loss = 0.023768340494977 
2016-12-09 23:37:24 Valid Error = 0.50303766707169 
2016-12-09 23:37:24 Valid Loss = 0.023408571421784 
2016-12-09 23:37:25 Test Error = 0.53930131004367 
2016-12-09 23:37:25 Test Loss = 0.0269694827273 
2016-12-09 23:37:25 -------------------LR------------------- 
2016-12-09 23:37:25 0.015625 
2016-12-09 23:37:25 Epoch 41 
2016-12-09 23:38:01 Training Error = 0.4775212636695 
2016-12-09 23:38:01 Training Loss = 0.023701319454389 
2016-12-09 23:38:02 Valid Error = 0.49453219927096 
2016-12-09 23:38:02 Valid Loss = 0.023331301198405 
2016-12-09 23:38:03 Test Error = 0.53493449781659 
2016-12-09 23:38:03 Test Loss = 0.026901918992498 
2016-12-09 23:38:03 -------------------LR------------------- 
2016-12-09 23:38:03 0.015625 
2016-12-09 23:38:03 Epoch 42 
2016-12-09 23:38:40 Training Error = 0.47698123396787 
2016-12-09 23:38:40 Training Loss = 0.023744286782143 
2016-12-09 23:38:41 Valid Error = 0.49453219927096 
2016-12-09 23:38:41 Valid Loss = 0.02334955359143 
2016-12-09 23:38:42 Test Error = 0.53493449781659 
2016-12-09 23:38:42 Test Loss = 0.026974214214125 
2016-12-09 23:38:42 -------------------LR------------------- 
2016-12-09 23:38:42 0.015625 
2016-12-09 23:38:42 Epoch 43 
2016-12-09 23:39:20 Training Error = 0.47711624139328 
2016-12-09 23:39:20 Training Loss = 0.023770709437227 
2016-12-09 23:39:21 Valid Error = 0.49696233292831 
2016-12-09 23:39:21 Valid Loss = 0.023391550584486 
2016-12-09 23:39:22 Test Error = 0.54148471615721 
2016-12-09 23:39:22 Test Loss = 0.026993204363031 
2016-12-09 23:39:22 -------------------LR------------------- 
2016-12-09 23:39:22 0.015625 
2016-12-09 23:39:22 Epoch 44 
2016-12-09 23:39:59 Training Error = 0.4775212636695 
2016-12-09 23:39:59 Training Loss = 0.02370261740974 
2016-12-09 23:40:00 Valid Error = 0.50303766707169 
2016-12-09 23:40:00 Valid Loss = 0.023426000361661 
2016-12-09 23:40:01 Test Error = 0.53930131004367 
2016-12-09 23:40:01 Test Loss = 0.026988467702679 
2016-12-09 23:40:01 -------------------LR------------------- 
2016-12-09 23:40:01 0.015625 
2016-12-09 23:40:01 Epoch 45 
2016-12-09 23:40:38 Training Error = 0.47738625624409 
2016-12-09 23:40:38 Training Loss = 0.023743962214099 
2016-12-09 23:40:39 Valid Error = 0.49453219927096 
2016-12-09 23:40:39 Valid Loss = 0.023492404389859 
2016-12-09 23:40:40 Test Error = 0.53493449781659 
2016-12-09 23:40:40 Test Loss = 0.026942802153382 
2016-12-09 23:40:40 -------------------LR------------------- 
2016-12-09 23:40:40 0.015625 
2016-12-09 23:40:40 Epoch 46 
2016-12-09 23:41:18 Training Error = 0.47603618199001 
2016-12-09 23:41:18 Training Loss = 0.023691457550289 
2016-12-09 23:41:19 Valid Error = 0.50303766707169 
2016-12-09 23:41:19 Valid Loss = 0.023359660983967 
2016-12-09 23:41:20 Test Error = 0.53930131004367 
2016-12-09 23:41:20 Test Loss = 0.026951038408903 
2016-12-09 23:41:20 -------------------LR------------------- 
2016-12-09 23:41:20 0.015625 
2016-12-09 23:41:20 Epoch 47 
2016-12-09 23:41:57 Training Error = 0.48022141217767 
2016-12-09 23:41:57 Training Loss = 0.023743552887145 
2016-12-09 23:41:58 Valid Error = 0.50303766707169 
2016-12-09 23:41:58 Valid Loss = 0.023309316380681 
2016-12-09 23:41:59 Test Error = 0.53930131004367 
2016-12-09 23:41:59 Test Loss = 0.026849688649957 
2016-12-09 23:41:59 -------------------LR------------------- 
2016-12-09 23:41:59 0.015625 
2016-12-09 23:41:59 Epoch 48 
2016-12-09 23:42:36 Training Error = 0.47684622654246 
2016-12-09 23:42:36 Training Loss = 0.023798917747296 
2016-12-09 23:42:37 Valid Error = 0.50303766707169 
2016-12-09 23:42:37 Valid Loss = 0.023424195857091 
2016-12-09 23:42:38 Test Error = 0.53930131004367 
2016-12-09 23:42:38 Test Loss = 0.026946313124077 
2016-12-09 23:42:38 -------------------LR------------------- 
2016-12-09 23:42:38 0.015625 
2016-12-09 23:42:38 Epoch 49 
2016-12-09 23:43:17 Training Error = 0.47617118941542 
2016-12-09 23:43:17 Training Loss = 0.023783550400412 
2016-12-09 23:43:18 Valid Error = 0.49453219927096 
2016-12-09 23:43:18 Valid Loss = 0.023411557792666 
2016-12-09 23:43:19 Test Error = 0.53493449781659 
2016-12-09 23:43:19 Test Loss = 0.02700050547232 
2016-12-09 23:43:19 -------------------LR------------------- 
2016-12-09 23:43:19 0.015625 
2016-12-09 23:43:19 Epoch 50 
2016-12-09 23:44:02 Training Error = 0.47765627109491 
2016-12-09 23:44:02 Training Loss = 0.023773797895918 
2016-12-09 23:44:03 Valid Error = 0.50789793438639 
2016-12-09 23:44:03 Valid Loss = 0.02346289635422 
2016-12-09 23:44:04 Test Error = 0.54694323144105 
2016-12-09 23:44:04 Test Loss = 0.027010603340623 
2016-12-09 23:44:04 -------------------LR------------------- 
2016-12-09 23:44:04 0.0078125 
2016-12-09 23:44:04 Epoch 51 
2016-12-09 23:44:40 Training Error = 0.47698123396787 
2016-12-09 23:44:40 Training Loss = 0.023820331382336 
2016-12-09 23:44:41 Valid Error = 0.49817739975699 
2016-12-09 23:44:41 Valid Loss = 0.023417563008756 
2016-12-09 23:44:42 Test Error = 0.53165938864629 
2016-12-09 23:44:42 Test Loss = 0.026977242722231 
2016-12-09 23:44:42 -------------------LR------------------- 
2016-12-09 23:44:42 0.0078125 
2016-12-09 23:44:42 Epoch 52 
2016-12-09 23:45:21 Training Error = 0.47455110031052 
2016-12-09 23:45:21 Training Loss = 0.023726600174481 
2016-12-09 23:45:22 Valid Error = 0.49696233292831 
2016-12-09 23:45:22 Valid Loss = 0.023419939913576 
2016-12-09 23:45:23 Test Error = 0.54148471615721 
2016-12-09 23:45:23 Test Loss = 0.026964637789072 
2016-12-09 23:45:23 -------------------LR------------------- 
2016-12-09 23:45:23 0.0078125 
2016-12-09 23:45:23 Epoch 53 
2016-12-09 23:46:01 Training Error = 0.47738625624409 
2016-12-09 23:46:01 Training Loss = 0.023755400612865 
2016-12-09 23:46:02 Valid Error = 0.50303766707169 
2016-12-09 23:46:02 Valid Loss = 0.023341520620212 
2016-12-09 23:46:03 Test Error = 0.53930131004367 
2016-12-09 23:46:03 Test Loss = 0.026932492840524 
2016-12-09 23:46:03 -------------------LR------------------- 
2016-12-09 23:46:03 0.0078125 
2016-12-09 23:46:03 Epoch 54 
2016-12-09 23:46:40 Training Error = 0.47927636019981 
2016-12-09 23:46:40 Training Loss = 0.023758063898704 
2016-12-09 23:46:41 Valid Error = 0.50303766707169 
2016-12-09 23:46:41 Valid Loss = 0.023433043954171 
2016-12-09 23:46:43 Test Error = 0.53930131004367 
2016-12-09 23:46:43 Test Loss = 0.026963874896367 
2016-12-09 23:46:43 -------------------LR------------------- 
2016-12-09 23:46:43 0.0078125 
2016-12-09 23:46:43 Epoch 55 
2016-12-09 23:47:20 Training Error = 0.47779127852032 
2016-12-09 23:47:20 Training Loss = 0.023729789140851 
2016-12-09 23:47:21 Valid Error = 0.49453219927096 
2016-12-09 23:47:21 Valid Loss = 0.023499501783252 
2016-12-09 23:47:22 Test Error = 0.53493449781659 
2016-12-09 23:47:22 Test Loss = 0.02698853071219 
2016-12-09 23:47:22 -------------------LR------------------- 
2016-12-09 23:47:22 0.0078125 
2016-12-09 23:47:23 Epoch 56 
2016-12-09 23:48:00 Training Error = 0.47927636019981 
2016-12-09 23:48:00 Training Loss = 0.023756157341267 
2016-12-09 23:48:01 Valid Error = 0.50546780072904 
2016-12-09 23:48:01 Valid Loss = 0.023462626249638 
2016-12-09 23:48:02 Test Error = 0.54585152838428 
2016-12-09 23:48:02 Test Loss = 0.027034102086148 
2016-12-09 23:48:02 -------------------LR------------------- 
2016-12-09 23:48:02 0.0078125 
2016-12-09 23:48:02 Epoch 57 
2016-12-09 23:48:39 Training Error = 0.47549615228838 
2016-12-09 23:48:39 Training Loss = 0.02377556824615 
2016-12-09 23:48:40 Valid Error = 0.49453219927096 
2016-12-09 23:48:40 Valid Loss = 0.02340330299604 
2016-12-09 23:48:42 Test Error = 0.53493449781659 
2016-12-09 23:48:42 Test Loss = 0.02696008736012 
2016-12-09 23:48:42 -------------------LR------------------- 
2016-12-09 23:48:42 0.0078125 
2016-12-09 23:48:42 Epoch 58 
2016-12-09 23:49:18 Training Error = 0.47981638990144 
2016-12-09 23:49:18 Training Loss = 0.023809216083116 
2016-12-09 23:49:19 Valid Error = 0.49453219927096 
2016-12-09 23:49:19 Valid Loss = 0.02351092476465 
2016-12-09 23:49:20 Test Error = 0.53493449781659 
2016-12-09 23:49:20 Test Loss = 0.027036067372054 
2016-12-09 23:49:20 -------------------LR------------------- 
2016-12-09 23:49:20 0.0078125 
2016-12-09 23:49:20 Epoch 59 
2016-12-09 23:49:59 Training Error = 0.47603618199001 
2016-12-09 23:49:59 Training Loss = 0.023703052198362 
2016-12-09 23:50:00 Valid Error = 0.50546780072904 
2016-12-09 23:50:00 Valid Loss = 0.02334479909903 
2016-12-09 23:50:01 Test Error = 0.54585152838428 
2016-12-09 23:50:01 Test Loss = 0.026990983369304 
2016-12-09 23:50:01 -------------------LR------------------- 
2016-12-09 23:50:01 0.0078125 
2016-12-09 23:50:01 Epoch 60 
2016-12-09 23:50:45 Training Error = 0.48035641960308 
2016-12-09 23:50:45 Training Loss = 0.023795640409744 
2016-12-09 23:50:46 Valid Error = 0.50546780072904 
2016-12-09 23:50:46 Valid Loss = 0.023338333091571 
2016-12-09 23:50:47 Test Error = 0.54585152838428 
2016-12-09 23:50:47 Test Loss = 0.026876413097569 
2016-12-09 23:50:47 -------------------LR------------------- 
2016-12-09 23:50:47 0.0078125 
2016-12-09 23:50:48 Epoch 61 
2016-12-09 23:51:24 Training Error = 0.47738625624409 
2016-12-09 23:51:24 Training Loss = 0.023750338031971 
2016-12-09 23:51:25 Valid Error = 0.50303766707169 
2016-12-09 23:51:25 Valid Loss = 0.023332998148913 
2016-12-09 23:51:26 Test Error = 0.53930131004367 
2016-12-09 23:51:26 Test Loss = 0.026966287692388 
2016-12-09 23:51:26 -------------------LR------------------- 
2016-12-09 23:51:26 0.0078125 
2016-12-09 23:51:26 Epoch 62 
2016-12-09 23:52:03 Training Error = 0.47563115971378 
2016-12-09 23:52:03 Training Loss = 0.023724529746582 
2016-12-09 23:52:05 Valid Error = 0.49696233292831 
2016-12-09 23:52:05 Valid Loss = 0.023353986676849 
2016-12-09 23:52:06 Test Error = 0.53602620087336 
2016-12-09 23:52:06 Test Loss = 0.026891609399147 
2016-12-09 23:52:06 -------------------LR------------------- 
2016-12-09 23:52:06 0.0078125 
2016-12-09 23:52:06 Epoch 63 
2016-12-09 23:52:42 Training Error = 0.47927636019981 
2016-12-09 23:52:42 Training Loss = 0.023758420907827 
2016-12-09 23:52:43 Valid Error = 0.49696233292831 
2016-12-09 23:52:43 Valid Loss = 0.023454556716479 
2016-12-09 23:52:44 Test Error = 0.54148471615721 
2016-12-09 23:52:44 Test Loss = 0.026997943119286 
2016-12-09 23:52:44 -------------------LR------------------- 
2016-12-09 23:52:44 0.0078125 
2016-12-09 23:52:44 Epoch 64 
2016-12-09 23:53:19 Training Error = 0.47617118941542 
2016-12-09 23:53:19 Training Loss = 0.023728297882644 
2016-12-09 23:53:20 Valid Error = 0.49453219927096 
2016-12-09 23:53:20 Valid Loss = 0.023479752282643 
2016-12-09 23:53:21 Test Error = 0.53493449781659 
2016-12-09 23:53:21 Test Loss = 0.026964879511229 
2016-12-09 23:53:21 -------------------LR------------------- 
2016-12-09 23:53:21 0.0078125 
2016-12-09 23:53:21 Epoch 65 
2016-12-09 23:53:59 Training Error = 0.4759011745646 
2016-12-09 23:53:59 Training Loss = 0.023829048615644 
2016-12-09 23:54:00 Valid Error = 0.48845686512758 
2016-12-09 23:54:00 Valid Loss = 0.02335985489672 
2016-12-09 23:54:01 Test Error = 0.53165938864629 
2016-12-09 23:54:01 Test Loss = 0.026902594028735 
2016-12-09 23:54:01 -------------------LR------------------- 
2016-12-09 23:54:01 0.0078125 
2016-12-09 23:54:01 Epoch 66 
2016-12-09 23:54:43 Training Error = 0.47779127852032 
2016-12-09 23:54:43 Training Loss = 0.023750411574796 
2016-12-09 23:54:44 Valid Error = 0.49453219927096 
2016-12-09 23:54:44 Valid Loss = 0.023389363641952 
2016-12-09 23:54:45 Test Error = 0.53493449781659 
2016-12-09 23:54:45 Test Loss = 0.02690391683111 
2016-12-09 23:54:45 -------------------LR------------------- 
2016-12-09 23:54:45 0.0078125 
2016-12-09 23:54:45 Epoch 67 
2016-12-09 23:55:25 Training Error = 0.47792628594573 
2016-12-09 23:55:25 Training Loss = 0.023677303154712 
2016-12-09 23:55:26 Valid Error = 0.50303766707169 
2016-12-09 23:55:26 Valid Loss = 0.023631168768985 
2016-12-09 23:55:27 Test Error = 0.53930131004367 
2016-12-09 23:55:27 Test Loss = 0.027071577349519 
2016-12-09 23:55:27 -------------------LR------------------- 
2016-12-09 23:55:27 0.0078125 
2016-12-09 23:55:27 Epoch 68 
2016-12-09 23:56:07 Training Error = 0.47563115971378 
2016-12-09 23:56:07 Training Loss = 0.023732457262324 
2016-12-09 23:56:08 Valid Error = 0.50546780072904 
2016-12-09 23:56:08 Valid Loss = 0.023399336074624 
2016-12-09 23:56:09 Test Error = 0.54585152838428 
2016-12-09 23:56:09 Test Loss = 0.026986917226143 
2016-12-09 23:56:09 -------------------LR------------------- 
2016-12-09 23:56:09 0.0078125 
2016-12-09 23:56:09 Epoch 69 
2016-12-09 23:56:51 Training Error = 0.47603618199001 
2016-12-09 23:56:51 Training Loss = 0.023724577042613 
2016-12-09 23:56:52 Valid Error = 0.50546780072904 
2016-12-09 23:56:52 Valid Loss = 0.023450118028851 
2016-12-09 23:56:53 Test Error = 0.54585152838428 
2016-12-09 23:56:53 Test Loss = 0.026981438172409 
2016-12-09 23:56:53 -------------------LR------------------- 
2016-12-09 23:56:53 0.0078125 
2016-12-09 23:56:54 Epoch 70 
2016-12-09 23:57:42 Training Error = 0.47725124881869 
2016-12-09 23:57:42 Training Loss = 0.023763000269741 
2016-12-09 23:57:43 Valid Error = 0.50546780072904 
2016-12-09 23:57:43 Valid Loss = 0.023380860773912 
2016-12-09 23:57:44 Test Error = 0.54585152838428 
2016-12-09 23:57:44 Test Loss = 0.026945575039371 
2016-12-09 23:57:44 -------------------LR------------------- 
2016-12-09 23:57:44 0.0078125 
2016-12-09 23:57:44 Epoch 71 
2016-12-09 23:58:27 Training Error = 0.47725124881869 
2016-12-09 23:58:27 Training Loss = 0.023826520810855 
2016-12-09 23:58:28 Valid Error = 0.50546780072904 
2016-12-09 23:58:28 Valid Loss = 0.023440736228205 
2016-12-09 23:58:29 Test Error = 0.54585152838428 
2016-12-09 23:58:29 Test Loss = 0.026981293391558 
2016-12-09 23:58:29 -------------------LR------------------- 
2016-12-09 23:58:29 0.0078125 
2016-12-09 23:58:29 Epoch 72 
2016-12-09 23:59:09 Training Error = 0.47414607803429 
2016-12-09 23:59:09 Training Loss = 0.023729746264188 
2016-12-09 23:59:11 Valid Error = 0.50546780072904 
2016-12-09 23:59:11 Valid Loss = 0.023296282709076 
2016-12-09 23:59:12 Test Error = 0.54585152838428 
2016-12-09 23:59:12 Test Loss = 0.02687494592729 
2016-12-09 23:59:12 -------------------LR------------------- 
2016-12-09 23:59:12 0.0078125 
2016-12-09 23:59:12 Epoch 73 
2016-12-09 23:59:53 Training Error = 0.47954637505063 
2016-12-09 23:59:53 Training Loss = 0.023809749771007 
2016-12-09 23:59:54 Valid Error = 0.50546780072904 
2016-12-09 23:59:54 Valid Loss = 0.02343560956011 
2016-12-09 23:59:55 Test Error = 0.54585152838428 
2016-12-09 23:59:55 Test Loss = 0.026998398374109 
2016-12-09 23:59:55 -------------------LR------------------- 
2016-12-09 23:59:55 0.0078125 
2016-12-09 23:59:55 Epoch 74 
2016-12-10 00:00:35 Training Error = 0.47765627109491 
2016-12-10 00:00:35 Training Loss = 0.023775588844432 
2016-12-10 00:00:36 Valid Error = 0.50546780072904 
2016-12-10 00:00:36 Valid Loss = 0.023525761086341 
2016-12-10 00:00:38 Test Error = 0.54585152838428 
2016-12-10 00:00:38 Test Loss = 0.027039986833248 
2016-12-10 00:00:38 -------------------LR------------------- 
2016-12-10 00:00:38 0.0078125 
2016-12-10 00:00:38 Epoch 75 
2016-12-10 00:01:16 Training Error = 0.47887133792359 
2016-12-10 00:01:16 Training Loss = 0.023755440690132 
2016-12-10 00:01:17 Valid Error = 0.49696233292831 
2016-12-10 00:01:17 Valid Loss = 0.023384391471389 
2016-12-10 00:01:18 Test Error = 0.54148471615721 
2016-12-10 00:01:18 Test Loss = 0.026929686233109 
2016-12-10 00:01:18 -------------------LR------------------- 
2016-12-10 00:01:18 0.0078125 
2016-12-10 00:01:18 Epoch 76 
2016-12-10 00:01:56 Training Error = 0.47576616713919 
2016-12-10 00:01:56 Training Loss = 0.023745347800602 
2016-12-10 00:01:57 Valid Error = 0.50546780072904 
2016-12-10 00:01:57 Valid Loss = 0.023365401900425 
2016-12-10 00:01:58 Test Error = 0.54585152838428 
2016-12-10 00:01:58 Test Loss = 0.026911456966712 
2016-12-10 00:01:58 -------------------LR------------------- 
2016-12-10 00:01:58 0.0078125 
2016-12-10 00:01:58 Epoch 77 
2016-12-10 00:02:35 Training Error = 0.47441609288511 
2016-12-10 00:02:35 Training Loss = 0.023780533133793 
2016-12-10 00:02:36 Valid Error = 0.49696233292831 
2016-12-10 00:02:36 Valid Loss = 0.023472608658356 
2016-12-10 00:02:38 Test Error = 0.54148471615721 
2016-12-10 00:02:38 Test Loss = 0.026997062941782 
2016-12-10 00:02:38 -------------------LR------------------- 
2016-12-10 00:02:38 0.0078125 
2016-12-10 00:02:38 Epoch 78 
2016-12-10 00:03:15 Training Error = 0.47698123396787 
2016-12-10 00:03:15 Training Loss = 0.023830942267645 
2016-12-10 00:03:16 Valid Error = 0.50303766707169 
2016-12-10 00:03:16 Valid Loss = 0.023363905755861 
2016-12-10 00:03:17 Test Error = 0.53930131004367 
2016-12-10 00:03:17 Test Loss = 0.026872283485201 
2016-12-10 00:03:17 -------------------LR------------------- 
2016-12-10 00:03:17 0.0078125 
2016-12-10 00:03:17 Epoch 79 
2016-12-10 00:03:54 Training Error = 0.47725124881869 
2016-12-10 00:03:54 Training Loss = 0.023729528526457 
2016-12-10 00:03:55 Valid Error = 0.50546780072904 
2016-12-10 00:03:55 Valid Loss = 0.023657263941368 
2016-12-10 00:03:57 Test Error = 0.54585152838428 
2016-12-10 00:03:57 Test Loss = 0.027076685709112 
2016-12-10 00:03:57 -------------------LR------------------- 
2016-12-10 00:03:57 0.0078125 
2016-12-10 00:03:57 Epoch 80 
2016-12-10 00:04:41 Training Error = 0.47603618199001 
2016-12-10 00:04:41 Training Loss = 0.023834130935691 
2016-12-10 00:04:42 Valid Error = 0.49453219927096 
2016-12-10 00:04:42 Valid Loss = 0.023462357236279 
2016-12-10 00:04:44 Test Error = 0.53493449781659 
2016-12-10 00:04:44 Test Loss = 0.026973661831002 
2016-12-10 00:04:44 -------------------LR------------------- 
2016-12-10 00:04:44 0.0078125 
2016-12-10 00:04:44 Epoch 81 
2016-12-10 00:05:23 Training Error = 0.47833130822195 
2016-12-10 00:05:23 Training Loss = 0.023766504958481 
2016-12-10 00:05:24 Valid Error = 0.49453219927096 
2016-12-10 00:05:24 Valid Loss = 0.023425821511367 
2016-12-10 00:05:25 Test Error = 0.53493449781659 
2016-12-10 00:05:25 Test Loss = 0.02699102436795 
2016-12-10 00:05:25 -------------------LR------------------- 
2016-12-10 00:05:25 0.0078125 
2016-12-10 00:05:25 Epoch 82 
2016-12-10 00:06:02 Training Error = 0.47846631564736 
2016-12-10 00:06:02 Training Loss = 0.023724260079537 
2016-12-10 00:06:03 Valid Error = 0.50303766707169 
2016-12-10 00:06:03 Valid Loss = 0.023464810323984 
2016-12-10 00:06:04 Test Error = 0.53930131004367 
2016-12-10 00:06:04 Test Loss = 0.027019640285205 
2016-12-10 00:06:04 -------------------LR------------------- 
2016-12-10 00:06:04 0.0078125 
2016-12-10 00:06:04 Epoch 83 
2016-12-10 00:06:41 Training Error = 0.4742810854597 
2016-12-10 00:06:41 Training Loss = 0.023790456517068 
2016-12-10 00:06:42 Valid Error = 0.49817739975699 
2016-12-10 00:06:42 Valid Loss = 0.023447413557303 
2016-12-10 00:06:44 Test Error = 0.53165938864629 
2016-12-10 00:06:44 Test Loss = 0.026987792533987 
2016-12-10 00:06:44 -------------------LR------------------- 
2016-12-10 00:06:44 0.0078125 
2016-12-10 00:06:44 Epoch 84 
2016-12-10 00:07:20 Training Error = 0.47644120426623 
2016-12-10 00:07:20 Training Loss = 0.023766684863318 
2016-12-10 00:07:21 Valid Error = 0.49453219927096 
2016-12-10 00:07:21 Valid Loss = 0.023437897479552 
2016-12-10 00:07:22 Test Error = 0.53493449781659 
2016-12-10 00:07:22 Test Loss = 0.027018397703669 
2016-12-10 00:07:22 -------------------LR------------------- 
2016-12-10 00:07:22 0.0078125 
2016-12-10 00:07:22 Epoch 85 
2016-12-10 00:08:00 Training Error = 0.48116646415553 
2016-12-10 00:08:00 Training Loss = 0.023855657846245 
2016-12-10 00:08:01 Valid Error = 0.50303766707169 
2016-12-10 00:08:01 Valid Loss = 0.023330777566293 
2016-12-10 00:08:02 Test Error = 0.53930131004367 
2016-12-10 00:08:02 Test Loss = 0.026931013702567 
2016-12-10 00:08:02 -------------------LR------------------- 
2016-12-10 00:08:02 0.0078125 
2016-12-10 00:08:02 Epoch 86 
2016-12-10 00:08:39 Training Error = 0.47792628594573 
2016-12-10 00:08:39 Training Loss = 0.023768566103624 
2016-12-10 00:08:40 Valid Error = 0.49453219927096 
2016-12-10 00:08:40 Valid Loss = 0.023352848441578 
2016-12-10 00:08:41 Test Error = 0.53493449781659 
2016-12-10 00:08:41 Test Loss = 0.026899004933102 
2016-12-10 00:08:41 -------------------LR------------------- 
2016-12-10 00:08:41 0.0078125 
2016-12-10 00:08:41 Epoch 87 
2016-12-10 00:09:18 Training Error = 0.47779127852032 
2016-12-10 00:09:18 Training Loss = 0.023761545186297 
2016-12-10 00:09:19 Valid Error = 0.50303766707169 
2016-12-10 00:09:19 Valid Loss = 0.02339175114893 
2016-12-10 00:09:20 Test Error = 0.53930131004367 
2016-12-10 00:09:20 Test Loss = 0.026928566530639 
2016-12-10 00:09:20 -------------------LR------------------- 
2016-12-10 00:09:20 0.0078125 
2016-12-10 00:09:20 Epoch 88 
2016-12-10 00:09:57 Training Error = 0.47711624139328 
2016-12-10 00:09:57 Training Loss = 0.023764102289349 
2016-12-10 00:09:58 Valid Error = 0.50546780072904 
2016-12-10 00:09:58 Valid Loss = 0.023395580391367 
2016-12-10 00:09:59 Test Error = 0.54585152838428 
2016-12-10 00:09:59 Test Loss = 0.026938687695397 
2016-12-10 00:09:59 -------------------LR------------------- 
2016-12-10 00:09:59 0.0078125 
2016-12-10 00:09:59 Epoch 89 
2016-12-10 00:10:36 Training Error = 0.47765627109491 
2016-12-10 00:10:36 Training Loss = 0.023706389781319 
2016-12-10 00:10:37 Valid Error = 0.49696233292831 
2016-12-10 00:10:37 Valid Loss = 0.023465915330613 
2016-12-10 00:10:38 Test Error = 0.54148471615721 
2016-12-10 00:10:38 Test Loss = 0.026968222669527 
2016-12-10 00:10:38 -------------------LR------------------- 
2016-12-10 00:10:38 0.0078125 
2016-12-10 00:10:38 Epoch 90 
2016-12-10 00:11:22 Training Error = 0.47657621169164 
2016-12-10 00:11:22 Training Loss = 0.023697278721224 
2016-12-10 00:11:23 Valid Error = 0.50546780072904 
2016-12-10 00:11:23 Valid Loss = 0.023501176927185 
2016-12-10 00:11:24 Test Error = 0.54585152838428 
2016-12-10 00:11:24 Test Loss = 0.027018076851477 
2016-12-10 00:11:24 -------------------LR------------------- 
2016-12-10 00:11:24 0.0078125 
2016-12-10 00:11:24 Epoch 91 
2016-12-10 00:12:00 Training Error = 0.47833130822195 
2016-12-10 00:12:00 Training Loss = 0.023756576459747 
2016-12-10 00:12:02 Valid Error = 0.50303766707169 
2016-12-10 00:12:02 Valid Loss = 0.023600047398563 
2016-12-10 00:12:03 Test Error = 0.53930131004367 
2016-12-10 00:12:03 Test Loss = 0.027092483043671 
2016-12-10 00:12:03 -------------------LR------------------- 
2016-12-10 00:12:03 0.0078125 
2016-12-10 00:12:03 Epoch 92 
2016-12-10 00:12:40 Training Error = 0.47725124881869 
2016-12-10 00:12:40 Training Loss = 0.023819971639726 
2016-12-10 00:12:41 Valid Error = 0.49453219927096 
2016-12-10 00:12:41 Valid Loss = 0.023618236628845 
2016-12-10 00:12:42 Test Error = 0.53493449781659 
2016-12-10 00:12:42 Test Loss = 0.027082449517219 
2016-12-10 00:12:42 -------------------LR------------------- 
2016-12-10 00:12:42 0.0078125 
2016-12-10 00:12:42 Epoch 93 
2016-12-10 00:13:18 Training Error = 0.47860132307277 
2016-12-10 00:13:18 Training Loss = 0.023771612003634 
2016-12-10 00:13:19 Valid Error = 0.50546780072904 
2016-12-10 00:13:19 Valid Loss = 0.023420044041913 
2016-12-10 00:13:20 Test Error = 0.54585152838428 
2016-12-10 00:13:20 Test Loss = 0.026961808002073 
2016-12-10 00:13:20 -------------------LR------------------- 
2016-12-10 00:13:20 0.0078125 
2016-12-10 00:13:20 Epoch 94 
2016-12-10 00:13:56 Training Error = 0.47495612258674 
2016-12-10 00:13:56 Training Loss = 0.02373559029281 
2016-12-10 00:13:57 Valid Error = 0.50303766707169 
2016-12-10 00:13:57 Valid Loss = 0.023347073661422 
2016-12-10 00:13:58 Test Error = 0.53930131004367 
2016-12-10 00:13:58 Test Loss = 0.026910722816692 
2016-12-10 00:13:58 -------------------LR------------------- 
2016-12-10 00:13:58 0.0078125 
2016-12-10 00:13:58 Epoch 95 
2016-12-10 00:14:34 Training Error = 0.47887133792359 
2016-12-10 00:14:34 Training Loss = 0.023696865695275 
2016-12-10 00:14:35 Valid Error = 0.50303766707169 
2016-12-10 00:14:35 Valid Loss = 0.023750061233723 
2016-12-10 00:14:36 Test Error = 0.53930131004367 
2016-12-10 00:14:36 Test Loss = 0.027101517058665 
2016-12-10 00:14:36 -------------------LR------------------- 
2016-12-10 00:14:36 0.0078125 
2016-12-10 00:14:36 Epoch 96 
2016-12-10 00:15:12 Training Error = 0.47468610773593 
2016-12-10 00:15:12 Training Loss = 0.023759187926119 
2016-12-10 00:15:13 Valid Error = 0.49453219927096 
2016-12-10 00:15:13 Valid Loss = 0.023289264664905 
2016-12-10 00:15:14 Test Error = 0.53493449781659 
2016-12-10 00:15:14 Test Loss = 0.026902300532347 
2016-12-10 00:15:14 -------------------LR------------------- 
2016-12-10 00:15:14 0.0078125 
2016-12-10 00:15:14 Epoch 97 
2016-12-10 00:15:50 Training Error = 0.47833130822195 
2016-12-10 00:15:50 Training Loss = 0.023763405621344 
2016-12-10 00:15:52 Valid Error = 0.50303766707169 
2016-12-10 00:15:52 Valid Loss = 0.023403506455505 
2016-12-10 00:15:53 Test Error = 0.53930131004367 
2016-12-10 00:15:53 Test Loss = 0.026978151478799 
2016-12-10 00:15:53 -------------------LR------------------- 
2016-12-10 00:15:53 0.0078125 
2016-12-10 00:15:53 Epoch 98 
2016-12-10 00:16:29 Training Error = 0.47482111516133 
2016-12-10 00:16:29 Training Loss = 0.023714277004724 
2016-12-10 00:16:30 Valid Error = 0.49696233292831 
2016-12-10 00:16:30 Valid Loss = 0.023522935295219 
2016-12-10 00:16:31 Test Error = 0.54148471615721 
2016-12-10 00:16:31 Test Loss = 0.027103948413936 
2016-12-10 00:16:31 -------------------LR------------------- 
2016-12-10 00:16:31 0.0078125 
2016-12-10 00:16:31 Epoch 99 
2016-12-10 00:17:08 Training Error = 0.47819630079654 
2016-12-10 00:17:08 Training Loss = 0.023777278739493 
2016-12-10 00:17:09 Valid Error = 0.49088699878493 
2016-12-10 00:17:09 Valid Loss = 0.023454601322464 
2016-12-10 00:17:10 Test Error = 0.5382096069869 
2016-12-10 00:17:10 Test Loss = 0.026991315363279 
2016-12-10 00:17:10 -------------------LR------------------- 
2016-12-10 00:17:10 0.0078125 
2016-12-10 00:17:10 Epoch 100 
2016-12-10 00:17:53 Training Error = 0.47657621169164 
2016-12-10 00:17:53 Training Loss = 0.023783088140478 
2016-12-10 00:17:54 Valid Error = 0.50546780072904 
2016-12-10 00:17:54 Valid Loss = 0.023421558284086 
2016-12-10 00:17:55 Test Error = 0.54585152838428 
2016-12-10 00:17:55 Test Loss = 0.026995284448262 
2016-12-10 00:17:55 -------------------LR------------------- 
2016-12-10 00:17:55 0.00390625 
2016-12-10 00:17:55 Epoch 101 
2016-12-10 00:18:31 Training Error = 0.47522613743756 
2016-12-10 00:18:31 Training Loss = 0.023785404954531 
2016-12-10 00:18:32 Valid Error = 0.49453219927096 
2016-12-10 00:18:32 Valid Loss = 0.023556860375891 
2016-12-10 00:18:33 Test Error = 0.53493449781659 
2016-12-10 00:18:33 Test Loss = 0.027061684895185 
2016-12-10 00:18:33 -------------------LR------------------- 
2016-12-10 00:18:33 0.00390625 
2016-12-10 00:18:33 Epoch 102 
2016-12-10 00:19:10 Training Error = 0.47684622654246 
2016-12-10 00:19:10 Training Loss = 0.023743629290649 
2016-12-10 00:19:11 Valid Error = 0.49453219927096 
2016-12-10 00:19:11 Valid Loss = 0.023275233311159 
2016-12-10 00:19:12 Test Error = 0.53493449781659 
2016-12-10 00:19:12 Test Loss = 0.026871394853966 
2016-12-10 00:19:12 -------------------LR------------------- 
2016-12-10 00:19:12 0.00390625 
2016-12-10 00:19:12 Epoch 103 
2016-12-10 00:19:49 Training Error = 0.47657621169164 
2016-12-10 00:19:49 Training Loss = 0.023735819958904 
2016-12-10 00:19:50 Valid Error = 0.50303766707169 
2016-12-10 00:19:50 Valid Loss = 0.023466148050365 
2016-12-10 00:19:52 Test Error = 0.53930131004367 
2016-12-10 00:19:52 Test Loss = 0.027015821925955 
2016-12-10 00:19:52 -------------------LR------------------- 
2016-12-10 00:19:52 0.00390625 
2016-12-10 00:19:52 Epoch 104 
2016-12-10 00:20:28 Training Error = 0.47873633049818 
2016-12-10 00:20:28 Training Loss = 0.023784002281421 
2016-12-10 00:20:29 Valid Error = 0.50303766707169 
2016-12-10 00:20:29 Valid Loss = 0.023395071046527 
2016-12-10 00:20:30 Test Error = 0.53930131004367 
2016-12-10 00:20:30 Test Loss = 0.026951980014253 
2016-12-10 00:20:30 -------------------LR------------------- 
2016-12-10 00:20:30 0.00390625 
2016-12-10 00:20:30 Epoch 105 
2016-12-10 00:21:06 Training Error = 0.47873633049818 
2016-12-10 00:21:06 Training Loss = 0.023733386955467 
2016-12-10 00:21:07 Valid Error = 0.50546780072904 
2016-12-10 00:21:07 Valid Loss = 0.02346239488348 
2016-12-10 00:21:08 Test Error = 0.54585152838428 
2016-12-10 00:21:08 Test Loss = 0.026962279821533 
2016-12-10 00:21:08 -------------------LR------------------- 
2016-12-10 00:21:08 0.00390625 
2016-12-10 00:21:08 Epoch 106 
2016-12-10 00:21:44 Training Error = 0.47603618199001 
2016-12-10 00:21:44 Training Loss = 0.023731920447805 
2016-12-10 00:21:45 Valid Error = 0.50303766707169 
2016-12-10 00:21:45 Valid Loss = 0.023456806994682 
2016-12-10 00:21:46 Test Error = 0.53930131004367 
2016-12-10 00:21:46 Test Loss = 0.02702213038806 
2016-12-10 00:21:46 -------------------LR------------------- 
2016-12-10 00:21:46 0.00390625 
2016-12-10 00:21:46 Epoch 107 
2016-12-10 00:22:23 Training Error = 0.4791413527744 
2016-12-10 00:22:23 Training Loss = 0.023796472050026 
2016-12-10 00:22:24 Valid Error = 0.49453219927096 
2016-12-10 00:22:24 Valid Loss = 0.023441358401352 
2016-12-10 00:22:25 Test Error = 0.53493449781659 
2016-12-10 00:22:25 Test Loss = 0.026949284364975 
2016-12-10 00:22:25 -------------------LR------------------- 
2016-12-10 00:22:25 0.00390625 
2016-12-10 00:22:25 Epoch 108 
2016-12-10 00:23:01 Training Error = 0.47927636019981 
2016-12-10 00:23:01 Training Loss = 0.023745230325415 
2016-12-10 00:23:02 Valid Error = 0.50303766707169 
2016-12-10 00:23:02 Valid Loss = 0.023287678890962 
2016-12-10 00:23:03 Test Error = 0.53930131004367 
2016-12-10 00:23:03 Test Loss = 0.026905449940488 
2016-12-10 00:23:03 -------------------LR------------------- 
2016-12-10 00:23:03 0.00390625 
2016-12-10 00:23:03 Epoch 109 
2016-12-10 00:23:40 Training Error = 0.47819630079654 
2016-12-10 00:23:40 Training Loss = 0.023749100752167 
2016-12-10 00:23:41 Valid Error = 0.50303766707169 
2016-12-10 00:23:41 Valid Loss = 0.023628021552992 
2016-12-10 00:23:42 Test Error = 0.53930131004367 
2016-12-10 00:23:42 Test Loss = 0.027108023447149 
2016-12-10 00:23:42 -------------------LR------------------- 
2016-12-10 00:23:42 0.00390625 
2016-12-10 00:23:42 Epoch 110 
2016-12-10 00:24:26 Training Error = 0.47671121911705 
2016-12-10 00:24:26 Training Loss = 0.023810550961355 
2016-12-10 00:24:27 Valid Error = 0.49817739975699 
2016-12-10 00:24:27 Valid Loss = 0.023354145279884 
2016-12-10 00:24:28 Test Error = 0.53165938864629 
2016-12-10 00:24:28 Test Loss = 0.026898385847316 
2016-12-10 00:24:28 -------------------LR------------------- 
2016-12-10 00:24:28 0.00390625 
2016-12-10 00:24:28 Epoch 111 
2016-12-10 00:25:04 Training Error = 0.47806129337114 
2016-12-10 00:25:04 Training Loss = 0.023730284563393 
2016-12-10 00:25:05 Valid Error = 0.50546780072904 
2016-12-10 00:25:05 Valid Loss = 0.023400019964495 
2016-12-10 00:25:06 Test Error = 0.54585152838428 
2016-12-10 00:25:06 Test Loss = 0.026920367837731 
2016-12-10 00:25:06 -------------------LR------------------- 
2016-12-10 00:25:06 0.00390625 
2016-12-10 00:25:06 Epoch 112 
2016-12-10 00:25:43 Training Error = 0.47806129337114 
2016-12-10 00:25:43 Training Loss = 0.023753227373943 
2016-12-10 00:25:44 Valid Error = 0.48967193195626 
2016-12-10 00:25:44 Valid Loss = 0.023412705339112 
2016-12-10 00:25:45 Test Error = 0.52729257641921 
2016-12-10 00:25:45 Test Loss = 0.026948044627321 
2016-12-10 00:25:45 -------------------LR------------------- 
2016-12-10 00:25:45 0.00390625 
2016-12-10 00:25:45 Epoch 113 
2016-12-10 00:26:21 Training Error = 0.47549615228838 
2016-12-10 00:26:21 Training Loss = 0.023763742678556 
2016-12-10 00:26:22 Valid Error = 0.49817739975699 
2016-12-10 00:26:22 Valid Loss = 0.023418067803851 
2016-12-10 00:26:24 Test Error = 0.53165938864629 
2016-12-10 00:26:24 Test Loss = 0.026931662068647 
2016-12-10 00:26:24 -------------------LR------------------- 
2016-12-10 00:26:24 0.00390625 
2016-12-10 00:26:24 Epoch 114 
2016-12-10 00:26:59 Training Error = 0.47482111516133 
2016-12-10 00:26:59 Training Loss = 0.023753043481036 
2016-12-10 00:27:00 Valid Error = 0.49453219927096 
2016-12-10 00:27:00 Valid Loss = 0.023484821917927 
2016-12-10 00:27:01 Test Error = 0.53493449781659 
2016-12-10 00:27:01 Test Loss = 0.027015612694173 
2016-12-10 00:27:01 -------------------LR------------------- 
2016-12-10 00:27:01 0.00390625 
2016-12-10 00:27:01 Epoch 115 
2016-12-10 00:27:37 Training Error = 0.4775212636695 
2016-12-10 00:27:37 Training Loss = 0.023725739663765 
2016-12-10 00:27:38 Valid Error = 0.49453219927096 
2016-12-10 00:27:38 Valid Loss = 0.023384814087834 
2016-12-10 00:27:40 Test Error = 0.53493449781659 
2016-12-10 00:27:40 Test Loss = 0.027009860651166 
2016-12-10 00:27:40 -------------------LR------------------- 
2016-12-10 00:27:40 0.00390625 
2016-12-10 00:27:40 Epoch 116 
2016-12-10 00:28:17 Training Error = 0.4759011745646 
2016-12-10 00:28:17 Training Loss = 0.023729399791247 
2016-12-10 00:28:18 Valid Error = 0.49453219927096 
2016-12-10 00:28:18 Valid Loss = 0.023394762120039 
2016-12-10 00:28:19 Test Error = 0.53493449781659 
2016-12-10 00:28:19 Test Loss = 0.026919609425115 
2016-12-10 00:28:19 -------------------LR------------------- 
2016-12-10 00:28:19 0.00390625 
2016-12-10 00:28:19 Epoch 117 
2016-12-10 00:28:55 Training Error = 0.47873633049818 
2016-12-10 00:28:55 Training Loss = 0.023828381405471 
2016-12-10 00:28:56 Valid Error = 0.49453219927096 
2016-12-10 00:28:56 Valid Loss = 0.02350597805298 
2016-12-10 00:28:57 Test Error = 0.53493449781659 
2016-12-10 00:28:57 Test Loss = 0.027036279510049 
2016-12-10 00:28:57 -------------------LR------------------- 
2016-12-10 00:28:57 0.00390625 
2016-12-10 00:28:57 Epoch 118 
2016-12-10 00:29:34 Training Error = 0.47927636019981 
2016-12-10 00:29:34 Training Loss = 0.023732419619064 
2016-12-10 00:29:35 Valid Error = 0.50303766707169 
2016-12-10 00:29:35 Valid Loss = 0.023439929781443 
2016-12-10 00:29:37 Test Error = 0.53930131004367 
2016-12-10 00:29:37 Test Loss = 0.026985994717654 
2016-12-10 00:29:37 -------------------LR------------------- 
2016-12-10 00:29:37 0.00390625 
2016-12-10 00:29:37 Epoch 119 
2016-12-10 00:30:14 Training Error = 0.47954637505063 
2016-12-10 00:30:14 Training Loss = 0.023766000998995 
2016-12-10 00:30:15 Valid Error = 0.49453219927096 
2016-12-10 00:30:15 Valid Loss = 0.023485488294559 
2016-12-10 00:30:16 Test Error = 0.53493449781659 
2016-12-10 00:30:16 Test Loss = 0.027022976781808 
2016-12-10 00:30:16 -------------------LR------------------- 
2016-12-10 00:30:16 0.00390625 
2016-12-10 00:30:16 Epoch 120 
2016-12-10 00:30:58 Training Error = 0.47819630079654 
2016-12-10 00:30:58 Training Loss = 0.023783641429922 
2016-12-10 00:31:00 Valid Error = 0.50303766707169 
2016-12-10 00:31:00 Valid Loss = 0.023292549267691 
2016-12-10 00:31:01 Test Error = 0.53930131004367 
2016-12-10 00:31:01 Test Loss = 0.026944237035864 
2016-12-10 00:31:01 -------------------LR------------------- 
2016-12-10 00:31:01 0.00390625 
2016-12-10 00:31:01 Epoch 121 
2016-12-10 00:31:38 Training Error = 0.4742810854597 
2016-12-10 00:31:38 Training Loss = 0.023757637708309 
2016-12-10 00:31:39 Valid Error = 0.50060753341434 
2016-12-10 00:31:39 Valid Loss = 0.023371939946506 
2016-12-10 00:31:40 Test Error = 0.5382096069869 
2016-12-10 00:31:40 Test Loss = 0.026919412394754 
2016-12-10 00:31:40 -------------------LR------------------- 
2016-12-10 00:31:40 0.00390625 
2016-12-10 00:31:40 Epoch 122 
2016-12-10 00:32:17 Training Error = 0.47846631564736 
2016-12-10 00:32:17 Training Loss = 0.023795884699531 
2016-12-10 00:32:18 Valid Error = 0.50546780072904 
2016-12-10 00:32:18 Valid Loss = 0.023347150386938 
2016-12-10 00:32:19 Test Error = 0.54585152838428 
2016-12-10 00:32:19 Test Loss = 0.02689760011006 
2016-12-10 00:32:19 -------------------LR------------------- 
2016-12-10 00:32:19 0.00390625 
2016-12-10 00:32:19 Epoch 123 
2016-12-10 00:32:55 Training Error = 0.4759011745646 
2016-12-10 00:32:55 Training Loss = 0.023746273580835 
2016-12-10 00:32:56 Valid Error = 0.49453219927096 
2016-12-10 00:32:56 Valid Loss = 0.023432145829751 
2016-12-10 00:32:57 Test Error = 0.53493449781659 
2016-12-10 00:32:57 Test Loss = 0.026927455570184 
2016-12-10 00:32:57 -------------------LR------------------- 
2016-12-10 00:32:57 0.00390625 
2016-12-10 00:32:57 Epoch 124 
2016-12-10 00:33:33 Training Error = 0.47671121911705 
2016-12-10 00:33:33 Training Loss = 0.023768958445725 
2016-12-10 00:33:34 Valid Error = 0.50546780072904 
2016-12-10 00:33:34 Valid Loss = 0.023263924535514 
2016-12-10 00:33:35 Test Error = 0.54585152838428 
2016-12-10 00:33:35 Test Loss = 0.026894275760339 
2016-12-10 00:33:35 -------------------LR------------------- 
2016-12-10 00:33:35 0.00390625 
2016-12-10 00:33:35 Epoch 125 
2016-12-10 00:34:12 Training Error = 0.4775212636695 
2016-12-10 00:34:12 Training Loss = 0.023863412079265 
2016-12-10 00:34:13 Valid Error = 0.49696233292831 
2016-12-10 00:34:13 Valid Loss = 0.02342873984776 
2016-12-10 00:34:14 Test Error = 0.54148471615721 
2016-12-10 00:34:14 Test Loss = 0.02699327992458 
2016-12-10 00:34:14 -------------------LR------------------- 
2016-12-10 00:34:14 0.00390625 
2016-12-10 00:34:14 Epoch 126 
2016-12-10 00:34:51 Training Error = 0.4759011745646 
2016-12-10 00:34:51 Training Loss = 0.023781499118485 
2016-12-10 00:34:52 Valid Error = 0.50546780072904 
2016-12-10 00:34:52 Valid Loss = 0.023323642364698 
2016-12-10 00:34:53 Test Error = 0.54585152838428 
2016-12-10 00:34:53 Test Loss = 0.026895034032709 
2016-12-10 00:34:53 -------------------LR------------------- 
2016-12-10 00:34:53 0.00390625 
2016-12-10 00:34:53 Epoch 127 
2016-12-10 00:35:30 Training Error = 0.47563115971378 
2016-12-10 00:35:30 Training Loss = 0.023717358155615 
2016-12-10 00:35:31 Valid Error = 0.49453219927096 
2016-12-10 00:35:31 Valid Loss = 0.0233461293717 
2016-12-10 00:35:32 Test Error = 0.53493449781659 
2016-12-10 00:35:32 Test Loss = 0.026918853497973 
2016-12-10 00:35:32 -------------------LR------------------- 
2016-12-10 00:35:32 0.00390625 
2016-12-10 00:35:32 Epoch 128 
2016-12-10 00:36:08 Training Error = 0.47671121911705 
2016-12-10 00:36:08 Training Loss = 0.023752500125343 
2016-12-10 00:36:09 Valid Error = 0.49696233292831 
2016-12-10 00:36:09 Valid Loss = 0.023640409930039 
2016-12-10 00:36:11 Test Error = 0.54148471615721 
2016-12-10 00:36:11 Test Loss = 0.027058363085479 
2016-12-10 00:36:11 -------------------LR------------------- 
2016-12-10 00:36:11 0.00390625 
2016-12-10 00:36:11 Epoch 129 
2016-12-10 00:36:47 Training Error = 0.4775212636695 
2016-12-10 00:36:47 Training Loss = 0.023755789564703 
2016-12-10 00:36:48 Valid Error = 0.49453219927096 
2016-12-10 00:36:48 Valid Loss = 0.023351042643043 
2016-12-10 00:36:49 Test Error = 0.53493449781659 
2016-12-10 00:36:49 Test Loss = 0.026986642927905 
2016-12-10 00:36:49 -------------------LR------------------- 
2016-12-10 00:36:49 0.00390625 
2016-12-10 00:36:49 Epoch 130 
2016-12-10 00:37:32 Training Error = 0.47873633049818 
2016-12-10 00:37:32 Training Loss = 0.023797179855487 
2016-12-10 00:37:33 Valid Error = 0.50546780072904 
2016-12-10 00:37:33 Valid Loss = 0.023489514592233 
2016-12-10 00:37:34 Test Error = 0.54585152838428 
2016-12-10 00:37:34 Test Loss = 0.027035370145748 
2016-12-10 00:37:34 -------------------LR------------------- 
2016-12-10 00:37:34 0.00390625 
2016-12-10 00:37:34 Epoch 131 
2016-12-10 00:38:11 Training Error = 0.47738625624409 
2016-12-10 00:38:11 Training Loss = 0.023712717198896 
2016-12-10 00:38:12 Valid Error = 0.49453219927096 
2016-12-10 00:38:12 Valid Loss = 0.023513458107947 
2016-12-10 00:38:13 Test Error = 0.53493449781659 
2016-12-10 00:38:13 Test Loss = 0.027001381255443 
2016-12-10 00:38:13 -------------------LR------------------- 
2016-12-10 00:38:13 0.00390625 
2016-12-10 00:38:13 Epoch 132 
2016-12-10 00:38:49 Training Error = 0.47644120426623 
2016-12-10 00:38:49 Training Loss = 0.023748363746729 
2016-12-10 00:38:50 Valid Error = 0.50303766707169 
2016-12-10 00:38:50 Valid Loss = 0.023384805513085 
2016-12-10 00:38:51 Test Error = 0.53930131004367 
2016-12-10 00:38:51 Test Loss = 0.026946997907427 
2016-12-10 00:38:51 -------------------LR------------------- 
2016-12-10 00:38:51 0.00390625 
2016-12-10 00:38:51 Epoch 133 
2016-12-10 00:39:27 Training Error = 0.47441609288511 
2016-12-10 00:39:27 Training Loss = 0.023747715470926 
2016-12-10 00:39:28 Valid Error = 0.50303766707169 
2016-12-10 00:39:28 Valid Loss = 0.023693177200947 
2016-12-10 00:39:29 Test Error = 0.53930131004367 
2016-12-10 00:39:29 Test Loss = 0.027104623302136 
2016-12-10 00:39:29 -------------------LR------------------- 
2016-12-10 00:39:29 0.00390625 
2016-12-10 00:39:29 Epoch 134 
2016-12-10 00:40:05 Training Error = 0.47765627109491 
2016-12-10 00:40:05 Training Loss = 0.023743945041926 
2016-12-10 00:40:07 Valid Error = 0.50303766707169 
2016-12-10 00:40:07 Valid Loss = 0.023418440903806 
2016-12-10 00:40:08 Test Error = 0.53930131004367 
2016-12-10 00:40:08 Test Loss = 0.026960984561958 
2016-12-10 00:40:08 -------------------LR------------------- 
2016-12-10 00:40:08 0.00390625 
2016-12-10 00:40:08 Epoch 135 
2016-12-10 00:40:45 Training Error = 0.47563115971378 
2016-12-10 00:40:45 Training Loss = 0.023718459664139 
2016-12-10 00:40:46 Valid Error = 0.49453219927096 
2016-12-10 00:40:46 Valid Loss = 0.023378695784047 
2016-12-10 00:40:47 Test Error = 0.53493449781659 
2016-12-10 00:40:47 Test Loss = 0.026979188085382 
2016-12-10 00:40:47 -------------------LR------------------- 
2016-12-10 00:40:47 0.00390625 
2016-12-10 00:40:47 Epoch 136 
2016-12-10 00:41:23 Training Error = 0.47765627109491 
2016-12-10 00:41:23 Training Loss = 0.02372767296636 
2016-12-10 00:41:24 Valid Error = 0.50303766707169 
2016-12-10 00:41:24 Valid Loss = 0.023277849271384 
2016-12-10 00:41:25 Test Error = 0.53930131004367 
2016-12-10 00:41:25 Test Loss = 0.026847339440015 
2016-12-10 00:41:25 -------------------LR------------------- 
2016-12-10 00:41:25 0.00390625 
2016-12-10 00:41:25 Epoch 137 
2016-12-10 00:42:00 Training Error = 0.47819630079654 
2016-12-10 00:42:00 Training Loss = 0.023751831221194 
2016-12-10 00:42:01 Valid Error = 0.49696233292831 
2016-12-10 00:42:01 Valid Loss = 0.023533941116288 
2016-12-10 00:42:03 Test Error = 0.54148471615721 
2016-12-10 00:42:03 Test Loss = 0.027007583683612 
2016-12-10 00:42:03 -------------------LR------------------- 
2016-12-10 00:42:03 0.00390625 
2016-12-10 00:42:03 Epoch 138 
2016-12-10 00:42:39 Training Error = 0.47482111516133 
2016-12-10 00:42:39 Training Loss = 0.023756195782373 
2016-12-10 00:42:40 Valid Error = 0.49453219927096 
2016-12-10 00:42:40 Valid Loss = 0.023339607222893 
2016-12-10 00:42:42 Test Error = 0.53493449781659 
2016-12-10 00:42:42 Test Loss = 0.02693268391042 
2016-12-10 00:42:42 -------------------LR------------------- 
2016-12-10 00:42:42 0.00390625 
2016-12-10 00:42:42 Epoch 139 
2016-12-10 00:43:19 Training Error = 0.47711624139328 
2016-12-10 00:43:19 Training Loss = 0.023772661114543 
2016-12-10 00:43:20 Valid Error = 0.50546780072904 
2016-12-10 00:43:20 Valid Loss = 0.023450593360919 
2016-12-10 00:43:21 Test Error = 0.54585152838428 
2016-12-10 00:43:21 Test Loss = 0.026985908146777 
2016-12-10 00:43:21 -------------------LR------------------- 
2016-12-10 00:43:21 0.00390625 
2016-12-10 00:43:21 Epoch 140 
2016-12-10 00:44:05 Training Error = 0.47873633049818 
2016-12-10 00:44:05 Training Loss = 0.023775260298724 
2016-12-10 00:44:06 Valid Error = 0.49453219927096 
2016-12-10 00:44:06 Valid Loss = 0.023430328606169 
2016-12-10 00:44:07 Test Error = 0.53493449781659 
2016-12-10 00:44:07 Test Loss = 0.026911340772716 
2016-12-10 00:44:07 -------------------LR------------------- 
2016-12-10 00:44:07 0.00390625 
2016-12-10 00:44:07 Epoch 141 
2016-12-10 00:44:42 Training Error = 0.4759011745646 
2016-12-10 00:44:42 Training Loss = 0.023709393958652 
2016-12-10 00:44:43 Valid Error = 0.50303766707169 
2016-12-10 00:44:43 Valid Loss = 0.023428781734632 
2016-12-10 00:44:45 Test Error = 0.53930131004367 
2016-12-10 00:44:45 Test Loss = 0.026985316775204 
2016-12-10 00:44:45 -------------------LR------------------- 
2016-12-10 00:44:45 0.00390625 
2016-12-10 00:44:45 Epoch 142 
2016-12-10 00:45:22 Training Error = 0.4791413527744 
2016-12-10 00:45:22 Training Loss = 0.023721346172027 
2016-12-10 00:45:23 Valid Error = 0.50546780072904 
2016-12-10 00:45:23 Valid Loss = 0.023457542678897 
2016-12-10 00:45:24 Test Error = 0.54585152838428 
2016-12-10 00:45:24 Test Loss = 0.026961277731104 
2016-12-10 00:45:24 -------------------LR------------------- 
2016-12-10 00:45:24 0.00390625 
2016-12-10 00:45:24 Epoch 143 
2016-12-10 00:46:01 Training Error = 0.47644120426623 
2016-12-10 00:46:01 Training Loss = 0.023755419304412 
2016-12-10 00:46:03 Valid Error = 0.50303766707169 
2016-12-10 00:46:03 Valid Loss = 0.023403195957774 
2016-12-10 00:46:04 Test Error = 0.53930131004367 
2016-12-10 00:46:04 Test Loss = 0.026937835403517 
2016-12-10 00:46:04 -------------------LR------------------- 
2016-12-10 00:46:04 0.00390625 
2016-12-10 00:46:04 Epoch 144 
2016-12-10 00:46:40 Training Error = 0.47684622654246 
2016-12-10 00:46:40 Training Loss = 0.023757928480094 
2016-12-10 00:46:41 Valid Error = 0.49453219927096 
2016-12-10 00:46:41 Valid Loss = 0.023313324392912 
2016-12-10 00:46:42 Test Error = 0.53493449781659 
2016-12-10 00:46:42 Test Loss = 0.026924616698346 
2016-12-10 00:46:42 -------------------LR------------------- 
2016-12-10 00:46:42 0.00390625 
2016-12-10 00:46:42 Epoch 145 
2016-12-10 00:47:20 Training Error = 0.4775212636695 
2016-12-10 00:47:20 Training Loss = 0.023743321794179 
2016-12-10 00:47:21 Valid Error = 0.50303766707169 
2016-12-10 00:47:21 Valid Loss = 0.023379751226482 
2016-12-10 00:47:22 Test Error = 0.53930131004367 
2016-12-10 00:47:22 Test Loss = 0.026873879869 
2016-12-10 00:47:22 -------------------LR------------------- 
2016-12-10 00:47:22 0.00390625 
2016-12-10 00:47:22 Epoch 146 
2016-12-10 00:47:58 Training Error = 0.47725124881869 
2016-12-10 00:47:58 Training Loss = 0.023758893995329 
2016-12-10 00:47:59 Valid Error = 0.50303766707169 
2016-12-10 00:47:59 Valid Loss = 0.023376837785686 
2016-12-10 00:48:01 Test Error = 0.53930131004367 
2016-12-10 00:48:01 Test Loss = 0.026889367290572 
2016-12-10 00:48:01 -------------------LR------------------- 
2016-12-10 00:48:01 0.00390625 
2016-12-10 00:48:01 Epoch 147 
2016-12-10 00:48:36 Training Error = 0.47725124881869 
2016-12-10 00:48:36 Training Loss = 0.023733010222224 
2016-12-10 00:48:37 Valid Error = 0.50303766707169 
2016-12-10 00:48:37 Valid Loss = 0.023439164002126 
2016-12-10 00:48:38 Test Error = 0.53930131004367 
2016-12-10 00:48:38 Test Loss = 0.026953071161033 
2016-12-10 00:48:38 -------------------LR------------------- 
2016-12-10 00:48:38 0.00390625 
2016-12-10 00:48:38 Epoch 148 
2016-12-10 00:49:14 Training Error = 0.47738625624409 
2016-12-10 00:49:14 Training Loss = 0.023790136747657 
2016-12-10 00:49:15 Valid Error = 0.50303766707169 
2016-12-10 00:49:15 Valid Loss = 0.023351944193189 
2016-12-10 00:49:16 Test Error = 0.53930131004367 
2016-12-10 00:49:16 Test Loss = 0.026860009525336 
2016-12-10 00:49:16 -------------------LR------------------- 
2016-12-10 00:49:16 0.00390625 
2016-12-10 00:49:16 Epoch 149 
2016-12-10 00:49:53 Training Error = 0.47509113001215 
2016-12-10 00:49:53 Training Loss = 0.023762755608782 
2016-12-10 00:49:54 Valid Error = 0.50303766707169 
2016-12-10 00:49:54 Valid Loss = 0.023480292479882 
2016-12-10 00:49:55 Test Error = 0.53930131004367 
2016-12-10 00:49:55 Test Loss = 0.026964222504423 
2016-12-10 00:49:55 -------------------LR------------------- 
2016-12-10 00:49:55 0.00390625 
2016-12-10 00:49:55 Epoch 150 
2016-12-10 00:50:39 Training Error = 0.47819630079654 
2016-12-10 00:50:39 Training Loss = 0.023760657618224 
2016-12-10 00:50:40 Valid Error = 0.49453219927096 
2016-12-10 00:50:40 Valid Loss = 0.023332171800744 
2016-12-10 00:50:41 Test Error = 0.53493449781659 
2016-12-10 00:50:41 Test Loss = 0.026909580378751 
2016-12-10 00:50:41 -------------------LR------------------- 
2016-12-10 00:50:41 0.001953125 
2016-12-10 00:50:41 Epoch 151 
2016-12-10 00:51:18 Training Error = 0.47927636019981 
2016-12-10 00:51:18 Training Loss = 0.023746939998944 
2016-12-10 00:51:19 Valid Error = 0.50303766707169 
2016-12-10 00:51:19 Valid Loss = 0.023328357623748 
2016-12-10 00:51:20 Test Error = 0.53930131004367 
2016-12-10 00:51:20 Test Loss = 0.026881092903661 
2016-12-10 00:51:20 -------------------LR------------------- 
2016-12-10 00:51:20 0.001953125 
2016-12-10 00:51:20 Epoch 152 
2016-12-10 00:51:57 Training Error = 0.47765627109491 
2016-12-10 00:51:57 Training Loss = 0.023749084802201 
2016-12-10 00:51:58 Valid Error = 0.50303766707169 
2016-12-10 00:51:58 Valid Loss = 0.023424208164658 
2016-12-10 00:51:59 Test Error = 0.53930131004367 
2016-12-10 00:51:59 Test Loss = 0.026983173306471 
2016-12-10 00:51:59 -------------------LR------------------- 
2016-12-10 00:51:59 0.001953125 
2016-12-10 00:51:59 Epoch 153 
2016-12-10 00:52:36 Training Error = 0.47900634534899 
2016-12-10 00:52:36 Training Loss = 0.023720797410643 
2016-12-10 00:52:37 Valid Error = 0.49453219927096 
2016-12-10 00:52:37 Valid Loss = 0.023342100879654 
2016-12-10 00:52:38 Test Error = 0.53493449781659 
2016-12-10 00:52:38 Test Loss = 0.026947760387184 
2016-12-10 00:52:38 -------------------LR------------------- 
2016-12-10 00:52:38 0.001953125 
2016-12-10 00:52:38 Epoch 154 
2016-12-10 00:53:13 Training Error = 0.47576616713919 
2016-12-10 00:53:13 Training Loss = 0.02371991524826 
2016-12-10 00:53:14 Valid Error = 0.49696233292831 
2016-12-10 00:53:14 Valid Loss = 0.023401658385487 
2016-12-10 00:53:15 Test Error = 0.54148471615721 
2016-12-10 00:53:15 Test Loss = 0.027011147979038 
2016-12-10 00:53:15 -------------------LR------------------- 
2016-12-10 00:53:15 0.001953125 
2016-12-10 00:53:15 Epoch 155 
2016-12-10 00:53:52 Training Error = 0.4759011745646 
2016-12-10 00:53:52 Training Loss = 0.023718333493596 
2016-12-10 00:53:53 Valid Error = 0.50546780072904 
2016-12-10 00:53:53 Valid Loss = 0.02361264197804 
2016-12-10 00:53:54 Test Error = 0.54585152838428 
2016-12-10 00:53:54 Test Loss = 0.027078751076281 
2016-12-10 00:53:54 -------------------LR------------------- 
2016-12-10 00:53:54 0.001953125 
2016-12-10 00:53:54 Epoch 156 
2016-12-10 00:54:30 Training Error = 0.47617118941542 
2016-12-10 00:54:30 Training Loss = 0.023845292282141 
2016-12-10 00:54:31 Valid Error = 0.50303766707169 
2016-12-10 00:54:31 Valid Loss = 0.023445191638978 
2016-12-10 00:54:32 Test Error = 0.53930131004367 
2016-12-10 00:54:32 Test Loss = 0.027003410688413 
2016-12-10 00:54:32 -------------------LR------------------- 
2016-12-10 00:54:32 0.001953125 
2016-12-10 00:54:33 Epoch 157 
2016-12-10 00:55:09 Training Error = 0.4791413527744 
2016-12-10 00:55:09 Training Loss = 0.023775213889573 
2016-12-10 00:55:10 Valid Error = 0.48967193195626 
2016-12-10 00:55:10 Valid Loss = 0.023322921805553 
2016-12-10 00:55:11 Test Error = 0.52729257641921 
2016-12-10 00:55:11 Test Loss = 0.026861285127066 
2016-12-10 00:55:11 -------------------LR------------------- 
2016-12-10 00:55:11 0.001953125 
2016-12-10 00:55:11 Epoch 158 
2016-12-10 00:55:47 Training Error = 0.47941136762522 
2016-12-10 00:55:47 Training Loss = 0.023737845259986 
2016-12-10 00:55:48 Valid Error = 0.49453219927096 
2016-12-10 00:55:48 Valid Loss = 0.023371337537617 
2016-12-10 00:55:50 Test Error = 0.53493449781659 
2016-12-10 00:55:50 Test Loss = 0.02690886740591 
2016-12-10 00:55:50 -------------------LR------------------- 
2016-12-10 00:55:50 0.001953125 
2016-12-10 00:55:50 Epoch 159 
2016-12-10 00:56:26 Training Error = 0.47630619684083 
2016-12-10 00:56:26 Training Loss = 0.023778925239872 
2016-12-10 00:56:27 Valid Error = 0.49453219927096 
2016-12-10 00:56:27 Valid Loss = 0.023449039089338 
2016-12-10 00:56:28 Test Error = 0.53493449781659 
2016-12-10 00:56:28 Test Loss = 0.027019672728831 
2016-12-10 00:56:28 -------------------LR------------------- 
2016-12-10 00:56:28 0.001953125 
2016-12-10 00:56:28 Epoch 160 
2016-12-10 00:57:10 Training Error = 0.4759011745646 
2016-12-10 00:57:10 Training Loss = 0.023812916067011 
2016-12-10 00:57:11 Valid Error = 0.50303766707169 
2016-12-10 00:57:11 Valid Loss = 0.02352761789509 
2016-12-10 00:57:13 Test Error = 0.53930131004367 
2016-12-10 00:57:13 Test Loss = 0.027027384198569 
2016-12-10 00:57:13 -------------------LR------------------- 
2016-12-10 00:57:13 0.001953125 
2016-12-10 00:57:13 Epoch 161 
2016-12-10 00:57:48 Training Error = 0.47900634534899 
2016-12-10 00:57:48 Training Loss = 0.02376823168277 
2016-12-10 00:57:49 Valid Error = 0.49453219927096 
2016-12-10 00:57:49 Valid Loss = 0.023261299201502 
2016-12-10 00:57:50 Test Error = 0.53493449781659 
2016-12-10 00:57:50 Test Loss = 0.026852861689586 
2016-12-10 00:57:50 -------------------LR------------------- 
2016-12-10 00:57:50 0.001953125 
2016-12-10 00:57:50 Epoch 162 
2016-12-10 00:58:27 Training Error = 0.47833130822195 
2016-12-10 00:58:27 Training Loss = 0.023749593694451 
2016-12-10 00:58:28 Valid Error = 0.50546780072904 
2016-12-10 00:58:28 Valid Loss = 0.023460941755771 
2016-12-10 00:58:30 Test Error = 0.54585152838428 
2016-12-10 00:58:30 Test Loss = 0.027043722416061 
2016-12-10 00:58:30 -------------------LR------------------- 
2016-12-10 00:58:30 0.001953125 
2016-12-10 00:58:30 Epoch 163 
2016-12-10 00:59:06 Training Error = 0.47563115971378 
2016-12-10 00:59:06 Training Loss = 0.023772818211415 
2016-12-10 00:59:07 Valid Error = 0.49453219927096 
2016-12-10 00:59:07 Valid Loss = 0.023394331617568 
2016-12-10 00:59:08 Test Error = 0.53493449781659 
2016-12-10 00:59:08 Test Loss = 0.026961955813801 
2016-12-10 00:59:08 -------------------LR------------------- 
2016-12-10 00:59:08 0.001953125 
2016-12-10 00:59:08 Epoch 164 
2016-12-10 00:59:44 Training Error = 0.47725124881869 
2016-12-10 00:59:44 Training Loss = 0.023755215671196 
2016-12-10 00:59:45 Valid Error = 0.49453219927096 
2016-12-10 00:59:45 Valid Loss = 0.023332111386929 
2016-12-10 00:59:46 Test Error = 0.53493449781659 
2016-12-10 00:59:46 Test Loss = 0.026970617708817 
2016-12-10 00:59:46 -------------------LR------------------- 
2016-12-10 00:59:46 0.001953125 
2016-12-10 00:59:46 Epoch 165 
2016-12-10 01:00:22 Training Error = 0.47306601863102 
2016-12-10 01:00:22 Training Loss = 0.02373829001589 
2016-12-10 01:00:23 Valid Error = 0.50546780072904 
2016-12-10 01:00:23 Valid Loss = 0.023368531615105 
2016-12-10 01:00:24 Test Error = 0.54585152838428 
2016-12-10 01:00:24 Test Loss = 0.026909602748023 
2016-12-10 01:00:24 -------------------LR------------------- 
2016-12-10 01:00:24 0.001953125 
2016-12-10 01:00:24 Epoch 166 
2016-12-10 01:01:00 Training Error = 0.47576616713919 
2016-12-10 01:01:00 Training Loss = 0.02376083753578 
2016-12-10 01:01:01 Valid Error = 0.50303766707169 
2016-12-10 01:01:01 Valid Loss = 0.023681193962885 
2016-12-10 01:01:03 Test Error = 0.53930131004367 
2016-12-10 01:01:03 Test Loss = 0.027136545609805 
2016-12-10 01:01:03 -------------------LR------------------- 
2016-12-10 01:01:03 0.001953125 
2016-12-10 01:01:03 Epoch 167 
2016-12-10 01:01:38 Training Error = 0.47630619684083 
2016-12-10 01:01:38 Training Loss = 0.023743601255064 
2016-12-10 01:01:39 Valid Error = 0.49696233292831 
2016-12-10 01:01:39 Valid Loss = 0.023345518125692 
2016-12-10 01:01:40 Test Error = 0.54148471615721 
2016-12-10 01:01:40 Test Loss = 0.026905880753511 
2016-12-10 01:01:40 -------------------LR------------------- 
2016-12-10 01:01:40 0.001953125 
2016-12-10 01:01:40 Epoch 168 
2016-12-10 01:02:17 Training Error = 0.47671121911705 
2016-12-10 01:02:17 Training Loss = 0.023772459556881 
2016-12-10 01:02:18 Valid Error = 0.50546780072904 
2016-12-10 01:02:18 Valid Loss = 0.023464550881189 
2016-12-10 01:02:19 Test Error = 0.54585152838428 
2016-12-10 01:02:19 Test Loss = 0.027003456837212 
2016-12-10 01:02:19 -------------------LR------------------- 
2016-12-10 01:02:19 0.001953125 
2016-12-10 01:02:19 Epoch 169 
2016-12-10 01:02:58 Training Error = 0.48062643445389 
2016-12-10 01:02:58 Training Loss = 0.023833327507907 
2016-12-10 01:02:59 Valid Error = 0.50303766707169 
2016-12-10 01:02:59 Valid Loss = 0.023318750882042 
2016-12-10 01:03:00 Test Error = 0.53930131004367 
2016-12-10 01:03:00 Test Loss = 0.026929593857597 
2016-12-10 01:03:00 -------------------LR------------------- 
2016-12-10 01:03:00 0.001953125 
2016-12-10 01:03:00 Epoch 170 
2016-12-10 01:03:41 Training Error = 0.4759011745646 
2016-12-10 01:03:41 Training Loss = 0.023756653769788 
2016-12-10 01:03:43 Valid Error = 0.49817739975699 
2016-12-10 01:03:43 Valid Loss = 0.023444545223382 
2016-12-10 01:03:44 Test Error = 0.53165938864629 
2016-12-10 01:03:44 Test Loss = 0.026964002045151 
2016-12-10 01:03:44 -------------------LR------------------- 
2016-12-10 01:03:44 0.001953125 
2016-12-10 01:03:44 Epoch 171 
2016-12-10 01:04:18 Training Error = 0.47738625624409 
2016-12-10 01:04:18 Training Loss = 0.023770030077838 
2016-12-10 01:04:19 Valid Error = 0.49453219927096 
2016-12-10 01:04:19 Valid Loss = 0.023503034323285 
2016-12-10 01:04:20 Test Error = 0.53493449781659 
2016-12-10 01:04:20 Test Loss = 0.027008655975068 
2016-12-10 01:04:20 -------------------LR------------------- 
2016-12-10 01:04:20 0.001953125 
2016-12-10 01:04:20 Epoch 172 
2016-12-10 01:04:55 Training Error = 0.47482111516133 
2016-12-10 01:04:55 Training Loss = 0.023765152896506 
2016-12-10 01:04:56 Valid Error = 0.50303766707169 
2016-12-10 01:04:56 Valid Loss = 0.023447844667997 
2016-12-10 01:04:57 Test Error = 0.53930131004367 
2016-12-10 01:04:57 Test Loss = 0.02695949467179 
2016-12-10 01:04:57 -------------------LR------------------- 
2016-12-10 01:04:57 0.001953125 
2016-12-10 01:04:57 Epoch 173 
2016-12-10 01:05:32 Training Error = 0.47725124881869 
2016-12-10 01:05:32 Training Loss = 0.023724601443956 
2016-12-10 01:05:33 Valid Error = 0.50546780072904 
2016-12-10 01:05:33 Valid Loss = 0.023513474723759 
2016-12-10 01:05:34 Test Error = 0.54585152838428 
2016-12-10 01:05:34 Test Loss = 0.027038715602526 
2016-12-10 01:05:34 -------------------LR------------------- 
2016-12-10 01:05:34 0.001953125 
2016-12-10 01:05:34 Epoch 174 
2016-12-10 01:06:09 Training Error = 0.47360604833266 
2016-12-10 01:06:09 Training Loss = 0.023754951564785 
2016-12-10 01:06:10 Valid Error = 0.49453219927096 
2016-12-10 01:06:10 Valid Loss = 0.023291038475095 
2016-12-10 01:06:11 Test Error = 0.53493449781659 
2016-12-10 01:06:11 Test Loss = 0.026893136283151 
2016-12-10 01:06:11 -------------------LR------------------- 
2016-12-10 01:06:11 0.001953125 
2016-12-10 01:06:11 Epoch 175 
2016-12-10 01:06:46 Training Error = 0.47563115971378 
2016-12-10 01:06:46 Training Loss = 0.023750720611454 
2016-12-10 01:06:47 Valid Error = 0.49817739975699 
2016-12-10 01:06:47 Valid Loss = 0.023456653317059 
2016-12-10 01:06:49 Test Error = 0.53165938864629 
2016-12-10 01:06:49 Test Loss = 0.026910049323163 
2016-12-10 01:06:49 -------------------LR------------------- 
2016-12-10 01:06:49 0.001953125 
2016-12-10 01:06:49 Epoch 176 
2016-12-10 01:07:23 Training Error = 0.47941136762522 
2016-12-10 01:07:23 Training Loss = 0.023805930219027 
2016-12-10 01:07:24 Valid Error = 0.50546780072904 
2016-12-10 01:07:24 Valid Loss = 0.023409661807215 
2016-12-10 01:07:26 Test Error = 0.54585152838428 
2016-12-10 01:07:26 Test Loss = 0.026890196231456 
2016-12-10 01:07:26 -------------------LR------------------- 
2016-12-10 01:07:26 0.001953125 
2016-12-10 01:07:26 Epoch 177 
2016-12-10 01:08:00 Training Error = 0.47401107060888 
2016-12-10 01:08:00 Training Loss = 0.023669569183491 
2016-12-10 01:08:01 Valid Error = 0.49696233292831 
2016-12-10 01:08:01 Valid Loss = 0.023315790769092 
2016-12-10 01:08:02 Test Error = 0.54148471615721 
2016-12-10 01:08:02 Test Loss = 0.026918669533885 
2016-12-10 01:08:02 -------------------LR------------------- 
2016-12-10 01:08:02 0.001953125 
2016-12-10 01:08:02 Epoch 178 
2016-12-10 01:08:37 Training Error = 0.47684622654246 
2016-12-10 01:08:37 Training Loss = 0.02369346385803 
2016-12-10 01:08:38 Valid Error = 0.50546780072904 
2016-12-10 01:08:38 Valid Loss = 0.023356199498666 
2016-12-10 01:08:39 Test Error = 0.54585152838428 
2016-12-10 01:08:39 Test Loss = 0.0269086951368 
2016-12-10 01:08:39 -------------------LR------------------- 
2016-12-10 01:08:39 0.001953125 
2016-12-10 01:08:39 Epoch 179 
2016-12-10 01:09:15 Training Error = 0.47725124881869 
2016-12-10 01:09:15 Training Loss = 0.023811113318483 
2016-12-10 01:09:16 Valid Error = 0.50546780072904 
2016-12-10 01:09:16 Valid Loss = 0.023333081293564 
2016-12-10 01:09:17 Test Error = 0.54585152838428 
2016-12-10 01:09:17 Test Loss = 0.026898967409446 
2016-12-10 01:09:17 -------------------LR------------------- 
2016-12-10 01:09:17 0.001953125 
2016-12-10 01:09:17 Epoch 180 
2016-12-10 01:09:59 Training Error = 0.47900634534899 
2016-12-10 01:09:59 Training Loss = 0.023743131098775 
2016-12-10 01:10:00 Valid Error = 0.50546780072904 
2016-12-10 01:10:00 Valid Loss = 0.023355125335491 
2016-12-10 01:10:01 Test Error = 0.54585152838428 
2016-12-10 01:10:01 Test Loss = 0.026910877897848 
2016-12-10 01:10:01 -------------------LR------------------- 
2016-12-10 01:10:01 0.001953125 
2016-12-10 01:10:01 Epoch 181 
2016-12-10 01:10:37 Training Error = 0.47630619684083 
2016-12-10 01:10:37 Training Loss = 0.023718316494869 
2016-12-10 01:10:38 Valid Error = 0.50303766707169 
2016-12-10 01:10:38 Valid Loss = 0.023447394368471 
2016-12-10 01:10:39 Test Error = 0.53930131004367 
2016-12-10 01:10:39 Test Loss = 0.027004110883264 
2016-12-10 01:10:39 -------------------LR------------------- 
2016-12-10 01:10:39 0.001953125 
2016-12-10 01:10:39 Epoch 182 
2016-12-10 01:11:14 Training Error = 0.47738625624409 
2016-12-10 01:11:14 Training Loss = 0.023771512341208 
2016-12-10 01:11:15 Valid Error = 0.49210206561361 
2016-12-10 01:11:15 Valid Loss = 0.023459444427557 
2016-12-10 01:11:16 Test Error = 0.52838427947598 
2016-12-10 01:11:16 Test Loss = 0.026975161016377 
2016-12-10 01:11:16 -------------------LR------------------- 
2016-12-10 01:11:16 0.001953125 
2016-12-10 01:11:16 Epoch 183 
2016-12-10 01:11:51 Training Error = 0.47887133792359 
2016-12-10 01:11:51 Training Loss = 0.023789426648103 
2016-12-10 01:11:52 Valid Error = 0.48845686512758 
2016-12-10 01:11:52 Valid Loss = 0.02337301551396 
2016-12-10 01:11:54 Test Error = 0.53165938864629 
2016-12-10 01:11:54 Test Loss = 0.026910109691371 
2016-12-10 01:11:54 -------------------LR------------------- 
2016-12-10 01:11:54 0.001953125 
2016-12-10 01:11:54 Epoch 184 
2016-12-10 01:12:29 Training Error = 0.47698123396787 
2016-12-10 01:12:29 Training Loss = 0.02373286089567 
2016-12-10 01:12:30 Valid Error = 0.48845686512758 
2016-12-10 01:12:30 Valid Loss = 0.023342789375918 
2016-12-10 01:12:31 Test Error = 0.53165938864629 
2016-12-10 01:12:31 Test Loss = 0.026919645632015 
2016-12-10 01:12:31 -------------------LR------------------- 
2016-12-10 01:12:31 0.001953125 
2016-12-10 01:12:31 Epoch 185 
2016-12-10 01:13:07 Training Error = 0.47941136762522 
2016-12-10 01:13:07 Training Loss = 0.023808624404599 
2016-12-10 01:13:08 Valid Error = 0.50303766707169 
2016-12-10 01:13:08 Valid Loss = 0.023470308401533 
2016-12-10 01:13:09 Test Error = 0.53930131004367 
2016-12-10 01:13:09 Test Loss = 0.027078665385838 
2016-12-10 01:13:09 -------------------LR------------------- 
2016-12-10 01:13:09 0.001953125 
2016-12-10 01:13:09 Epoch 186 
2016-12-10 01:13:45 Training Error = 0.47873633049818 
2016-12-10 01:13:45 Training Loss = 0.023738260904948 
2016-12-10 01:13:46 Valid Error = 0.50303766707169 
2016-12-10 01:13:46 Valid Loss = 0.023387051280303 
2016-12-10 01:13:47 Test Error = 0.53930131004367 
2016-12-10 01:13:47 Test Loss = 0.026932484659494 
2016-12-10 01:13:47 -------------------LR------------------- 
2016-12-10 01:13:47 0.001953125 
2016-12-10 01:13:47 Epoch 187 
2016-12-10 01:14:21 Training Error = 0.47563115971378 
2016-12-10 01:14:21 Training Loss = 0.023744072476302 
2016-12-10 01:14:22 Valid Error = 0.49453219927096 
2016-12-10 01:14:22 Valid Loss = 0.023524220863515 
2016-12-10 01:14:23 Test Error = 0.53493449781659 
2016-12-10 01:14:23 Test Loss = 0.027070599342483 
2016-12-10 01:14:23 -------------------LR------------------- 
2016-12-10 01:14:23 0.001953125 
2016-12-10 01:14:23 Epoch 188 
2016-12-10 01:14:58 Training Error = 0.47819630079654 
2016-12-10 01:14:58 Training Loss = 0.023749295836876 
2016-12-10 01:14:59 Valid Error = 0.49817739975699 
2016-12-10 01:14:59 Valid Loss = 0.023440083160918 
2016-12-10 01:15:00 Test Error = 0.53165938864629 
2016-12-10 01:15:00 Test Loss = 0.026971160586363 
2016-12-10 01:15:00 -------------------LR------------------- 
2016-12-10 01:15:00 0.001953125 
2016-12-10 01:15:00 Epoch 189 
2016-12-10 01:15:36 Training Error = 0.47630619684083 
2016-12-10 01:15:36 Training Loss = 0.023784478673621 
2016-12-10 01:15:37 Valid Error = 0.50546780072904 
2016-12-10 01:15:37 Valid Loss = 0.023411998977795 
2016-12-10 01:15:38 Test Error = 0.54585152838428 
2016-12-10 01:15:38 Test Loss = 0.02694688181472 
2016-12-10 01:15:38 -------------------LR------------------- 
2016-12-10 01:15:38 0.001953125 
2016-12-10 01:15:38 Epoch 190 
2016-12-10 01:16:20 Training Error = 0.47657621169164 
2016-12-10 01:16:20 Training Loss = 0.023833031354714 
2016-12-10 01:16:21 Valid Error = 0.50303766707169 
2016-12-10 01:16:21 Valid Loss = 0.023384410606554 
2016-12-10 01:16:22 Test Error = 0.53930131004367 
2016-12-10 01:16:22 Test Loss = 0.026973067148059 
2016-12-10 01:16:22 -------------------LR------------------- 
2016-12-10 01:16:22 0.001953125 
2016-12-10 01:16:22 Epoch 191 
2016-12-10 01:16:57 Training Error = 0.47441609288511 
2016-12-10 01:16:57 Training Loss = 0.023723548873406 
2016-12-10 01:16:58 Valid Error = 0.50303766707169 
2016-12-10 01:16:58 Valid Loss = 0.023398561458188 
2016-12-10 01:16:59 Test Error = 0.53930131004367 
2016-12-10 01:16:59 Test Loss = 0.026927022848254 
2016-12-10 01:16:59 -------------------LR------------------- 
2016-12-10 01:16:59 0.001953125 
2016-12-10 01:16:59 Epoch 192 
2016-12-10 01:17:35 Training Error = 0.4807614418793 
2016-12-10 01:17:35 Training Loss = 0.023769438024681 
2016-12-10 01:17:36 Valid Error = 0.49453219927096 
2016-12-10 01:17:36 Valid Loss = 0.023401973182518 
2016-12-10 01:17:37 Test Error = 0.53493449781659 
2016-12-10 01:17:37 Test Loss = 0.026941265459933 
2016-12-10 01:17:37 -------------------LR------------------- 
2016-12-10 01:17:37 0.001953125 
2016-12-10 01:17:37 Epoch 193 
2016-12-10 01:18:13 Training Error = 0.47401107060888 
2016-12-10 01:18:13 Training Loss = 0.023801923528413 
2016-12-10 01:18:14 Valid Error = 0.49453219927096 
2016-12-10 01:18:14 Valid Loss = 0.023341469055442 
2016-12-10 01:18:15 Test Error = 0.53493449781659 
2016-12-10 01:18:15 Test Loss = 0.026905831737456 
2016-12-10 01:18:15 -------------------LR------------------- 
2016-12-10 01:18:15 0.001953125 
2016-12-10 01:18:15 Epoch 194 
2016-12-10 01:18:49 Training Error = 0.4775212636695 
2016-12-10 01:18:49 Training Loss = 0.023750137884992 
2016-12-10 01:18:50 Valid Error = 0.49453219927096 
2016-12-10 01:18:50 Valid Loss = 0.023403822048592 
2016-12-10 01:18:52 Test Error = 0.53493449781659 
2016-12-10 01:18:52 Test Loss = 0.02691319132942 
2016-12-10 01:18:52 -------------------LR------------------- 
2016-12-10 01:18:52 0.001953125 
2016-12-10 01:18:52 Epoch 195 
2016-12-10 01:19:27 Training Error = 0.4775212636695 
2016-12-10 01:19:27 Training Loss = 0.023712265705247 
2016-12-10 01:19:28 Valid Error = 0.49453219927096 
2016-12-10 01:19:28 Valid Loss = 0.023364697977961 
2016-12-10 01:19:29 Test Error = 0.53493449781659 
2016-12-10 01:19:29 Test Loss = 0.026912519339642 
2016-12-10 01:19:29 -------------------LR------------------- 
2016-12-10 01:19:29 0.001953125 
2016-12-10 01:19:29 Epoch 196 
2016-12-10 01:20:04 Training Error = 0.47792628594573 
2016-12-10 01:20:04 Training Loss = 0.023865437556104 
2016-12-10 01:20:05 Valid Error = 0.50546780072904 
2016-12-10 01:20:05 Valid Loss = 0.023463751855342 
2016-12-10 01:20:06 Test Error = 0.54585152838428 
2016-12-10 01:20:06 Test Loss = 0.026970184106453 
2016-12-10 01:20:06 -------------------LR------------------- 
2016-12-10 01:20:06 0.001953125 
2016-12-10 01:20:06 Epoch 197 
2016-12-10 01:20:40 Training Error = 0.47779127852032 
2016-12-10 01:20:40 Training Loss = 0.023816999434016 
2016-12-10 01:20:41 Valid Error = 0.50546780072904 
2016-12-10 01:20:41 Valid Loss = 0.0234474462135 
2016-12-10 01:20:43 Test Error = 0.54585152838428 
2016-12-10 01:20:43 Test Loss = 0.026995202271767 
2016-12-10 01:20:43 -------------------LR------------------- 
2016-12-10 01:20:43 0.001953125 
2016-12-10 01:20:43 Epoch 198 
2016-12-10 01:21:18 Training Error = 0.47509113001215 
2016-12-10 01:21:18 Training Loss = 0.023796763653189 
2016-12-10 01:21:19 Valid Error = 0.49453219927096 
2016-12-10 01:21:19 Valid Loss = 0.02342573246934 
2016-12-10 01:21:20 Test Error = 0.53493449781659 
2016-12-10 01:21:20 Test Loss = 0.026899791768953 
2016-12-10 01:21:20 -------------------LR------------------- 
2016-12-10 01:21:20 0.001953125 
2016-12-10 01:21:20 Epoch 199 
2016-12-10 01:21:55 Training Error = 0.48008640475226 
2016-12-10 01:21:55 Training Loss = 0.0237730909704 
2016-12-10 01:21:56 Valid Error = 0.50303766707169 
2016-12-10 01:21:56 Valid Loss = 0.023366285066739 
2016-12-10 01:21:57 Test Error = 0.53930131004367 
2016-12-10 01:21:57 Test Loss = 0.026943694321938 
2016-12-10 01:21:57 -------------------LR------------------- 
2016-12-10 01:21:57 0.001953125 
2016-12-10 01:21:57 Epoch 200 
2016-12-10 01:22:39 Training Error = 0.47846631564736 
2016-12-10 01:22:39 Training Loss = 0.023767410308095 
2016-12-10 01:22:40 Valid Error = 0.50303766707169 
2016-12-10 01:22:40 Valid Loss = 0.02347512311097 
2016-12-10 01:22:41 Test Error = 0.53930131004367 
2016-12-10 01:22:41 Test Loss = 0.02701534323443 
2016-12-10 01:22:41 -------------------LR------------------- 
2016-12-10 01:22:41 0.0009765625 
2016-12-10 01:22:41 Epoch 201 
2016-12-10 01:23:16 Training Error = 0.47846631564736 
2016-12-10 01:23:16 Training Loss = 0.023761966057723 
2016-12-10 01:23:17 Valid Error = 0.49453219927096 
2016-12-10 01:23:17 Valid Loss = 0.023367292528149 
2016-12-10 01:23:18 Test Error = 0.53493449781659 
2016-12-10 01:23:18 Test Loss = 0.026875115742091 
2016-12-10 01:23:18 -------------------LR------------------- 
2016-12-10 01:23:18 0.0009765625 
2016-12-10 01:23:18 Epoch 202 
2016-12-10 01:23:53 Training Error = 0.48035641960308 
2016-12-10 01:23:53 Training Loss = 0.023747103080811 
2016-12-10 01:23:54 Valid Error = 0.48967193195626 
2016-12-10 01:23:54 Valid Loss = 0.023476178156868 
2016-12-10 01:23:55 Test Error = 0.52729257641921 
2016-12-10 01:23:55 Test Loss = 0.026962045345431 
2016-12-10 01:23:55 -------------------LR------------------- 
2016-12-10 01:23:55 0.0009765625 
2016-12-10 01:23:55 Epoch 203 
2016-12-10 01:24:30 Training Error = 0.47900634534899 
2016-12-10 01:24:30 Training Loss = 0.023761381453434 
2016-12-10 01:24:31 Valid Error = 0.50303766707169 
2016-12-10 01:24:31 Valid Loss = 0.023408694882064 
2016-12-10 01:24:32 Test Error = 0.53930131004367 
2016-12-10 01:24:32 Test Loss = 0.026950893682592 
2016-12-10 01:24:32 -------------------LR------------------- 
2016-12-10 01:24:32 0.0009765625 
2016-12-10 01:24:32 Epoch 204 
2016-12-10 01:25:09 Training Error = 0.47711624139328 
2016-12-10 01:25:09 Training Loss = 0.023790041821426 
2016-12-10 01:25:10 Valid Error = 0.50303766707169 
2016-12-10 01:25:10 Valid Loss = 0.023356204701356 
2016-12-10 01:25:11 Test Error = 0.53930131004367 
2016-12-10 01:25:11 Test Loss = 0.026908640791388 
2016-12-10 01:25:11 -------------------LR------------------- 
2016-12-10 01:25:11 0.0009765625 
2016-12-10 01:25:11 Epoch 205 
2016-12-10 01:25:47 Training Error = 0.47900634534899 
2016-12-10 01:25:47 Training Loss = 0.023774376107039 
2016-12-10 01:25:48 Valid Error = 0.49453219927096 
2016-12-10 01:25:48 Valid Loss = 0.023349690853001 
2016-12-10 01:25:49 Test Error = 0.53493449781659 
2016-12-10 01:25:49 Test Loss = 0.026900095308528 
2016-12-10 01:25:49 -------------------LR------------------- 
2016-12-10 01:25:49 0.0009765625 
2016-12-10 01:25:49 Epoch 206 
2016-12-10 01:26:23 Training Error = 0.47806129337114 
2016-12-10 01:26:23 Training Loss = 0.023797204484621 
2016-12-10 01:26:24 Valid Error = 0.50303766707169 
2016-12-10 01:26:24 Valid Loss = 0.02358874892991 
2016-12-10 01:26:25 Test Error = 0.53930131004367 
2016-12-10 01:26:25 Test Loss = 0.027021304283267 
2016-12-10 01:26:25 -------------------LR------------------- 
2016-12-10 01:26:25 0.0009765625 
2016-12-10 01:26:25 Epoch 207 
2016-12-10 01:27:00 Training Error = 0.47711624139328 
2016-12-10 01:27:00 Training Loss = 0.023808671936515 
2016-12-10 01:27:02 Valid Error = 0.50303766707169 
2016-12-10 01:27:02 Valid Loss = 0.023304506915674 
2016-12-10 01:27:03 Test Error = 0.53930131004367 
2016-12-10 01:27:03 Test Loss = 0.026906662859948 
2016-12-10 01:27:03 -------------------LR------------------- 
2016-12-10 01:27:03 0.0009765625 
2016-12-10 01:27:03 Epoch 208 
2016-12-10 01:27:39 Training Error = 0.47806129337114 
2016-12-10 01:27:39 Training Loss = 0.023777686201339 
2016-12-10 01:27:40 Valid Error = 0.49453219927096 
2016-12-10 01:27:40 Valid Loss = 0.023350571607294 
2016-12-10 01:27:41 Test Error = 0.53493449781659 
2016-12-10 01:27:41 Test Loss = 0.026926416267757 
2016-12-10 01:27:41 -------------------LR------------------- 
2016-12-10 01:27:41 0.0009765625 
2016-12-10 01:27:41 Epoch 209 
2016-12-10 01:28:16 Training Error = 0.47671121911705 
2016-12-10 01:28:16 Training Loss = 0.023793136244298 
2016-12-10 01:28:17 Valid Error = 0.50546780072904 
2016-12-10 01:28:17 Valid Loss = 0.023618437709086 
2016-12-10 01:28:18 Test Error = 0.54585152838428 
2016-12-10 01:28:18 Test Loss = 0.027075143351274 
2016-12-10 01:28:18 -------------------LR------------------- 
2016-12-10 01:28:18 0.0009765625 
2016-12-10 01:28:18 Epoch 210 
2016-12-10 01:29:00 Training Error = 0.47617118941542 
2016-12-10 01:29:00 Training Loss = 0.023743735405215 
2016-12-10 01:29:01 Valid Error = 0.49453219927096 
2016-12-10 01:29:01 Valid Loss = 0.023479219762727 
2016-12-10 01:29:02 Test Error = 0.53493449781659 
2016-12-10 01:29:02 Test Loss = 0.027004649841708 
2016-12-10 01:29:02 -------------------LR------------------- 
2016-12-10 01:29:02 0.0009765625 
2016-12-10 01:29:02 Epoch 211 
2016-12-10 01:29:37 Training Error = 0.47995139732685 
2016-12-10 01:29:37 Training Loss = 0.023725853093068 
2016-12-10 01:29:38 Valid Error = 0.49453219927096 
2016-12-10 01:29:38 Valid Loss = 0.023241172564009 
2016-12-10 01:29:40 Test Error = 0.53493449781659 
2016-12-10 01:29:40 Test Loss = 0.026865373226552 
2016-12-10 01:29:40 -------------------LR------------------- 
2016-12-10 01:29:40 0.0009765625 
2016-12-10 01:29:40 Epoch 212 
2016-12-10 01:30:16 Training Error = 0.47738625624409 
2016-12-10 01:30:16 Training Loss = 0.023715564003002 
2016-12-10 01:30:17 Valid Error = 0.50303766707169 
2016-12-10 01:30:17 Valid Loss = 0.023382988426651 
2016-12-10 01:30:18 Test Error = 0.53930131004367 
2016-12-10 01:30:18 Test Loss = 0.026943175512202 
2016-12-10 01:30:18 -------------------LR------------------- 
2016-12-10 01:30:18 0.0009765625 
2016-12-10 01:30:18 Epoch 213 
2016-12-10 01:30:53 Training Error = 0.47671121911705 
2016-12-10 01:30:53 Training Loss = 0.023820904366993 
2016-12-10 01:30:54 Valid Error = 0.50060753341434 
2016-12-10 01:30:54 Valid Loss = 0.023435238111897 
2016-12-10 01:30:55 Test Error = 0.5382096069869 
2016-12-10 01:30:55 Test Loss = 0.026977995252298 
2016-12-10 01:30:55 -------------------LR------------------- 
2016-12-10 01:30:55 0.0009765625 
2016-12-10 01:30:55 Epoch 214 
2016-12-10 01:31:30 Training Error = 0.47819630079654 
2016-12-10 01:31:30 Training Loss = 0.023763434768132 
2016-12-10 01:31:31 Valid Error = 0.49453219927096 
2016-12-10 01:31:31 Valid Loss = 0.023377980311313 
2016-12-10 01:31:32 Test Error = 0.53493449781659 
2016-12-10 01:31:32 Test Loss = 0.026975985555088 
2016-12-10 01:31:32 -------------------LR------------------- 
2016-12-10 01:31:32 0.0009765625 
2016-12-10 01:31:32 Epoch 215 
2016-12-10 01:32:13 Training Error = 0.47657621169164 
2016-12-10 01:32:13 Training Loss = 0.023730235034552 
2016-12-10 01:32:14 Valid Error = 0.50546780072904 
2016-12-10 01:32:14 Valid Loss = 0.02339610593461 
2016-12-10 01:32:15 Test Error = 0.54585152838428 
2016-12-10 01:32:15 Test Loss = 0.026976655659333 
2016-12-10 01:32:15 -------------------LR------------------- 
2016-12-10 01:32:15 0.0009765625 
2016-12-10 01:32:15 Epoch 216 
