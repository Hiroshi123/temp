2016-12-09 22:47:38 [program started on Fri Dec  9 22:47:38 2016] 
2016-12-09 22:47:38 [command line arguments] 
2016-12-09 22:47:38 stcWeights false 
2016-12-09 22:47:38 LR 0.015625 
2016-12-09 22:47:38 batchSize 100 
2016-12-09 22:47:38 network ./Models/Cifar10_Custom 
2016-12-09 22:47:38 stcNeurons true 
2016-12-09 22:47:38 constBatchSize false 
2016-12-09 22:47:38 chartFileName chart1 
2016-12-09 22:47:38 dp_prepro false 
2016-12-09 22:47:38 nGPU 1 
2016-12-09 22:47:38 dataset Caltech101 
2016-12-09 22:47:38 type cuda 
2016-12-09 22:47:38 momentum 0 
2016-12-09 22:47:38 threads 8 
2016-12-09 22:47:38 weightDecay 0 
2016-12-09 22:47:38 runningVal false 
2016-12-09 22:47:38 convLayerN 6 
2016-12-09 22:47:38 LRDecay 0 
2016-12-09 22:47:38 numHid 1024 
2016-12-09 22:47:38 save /dev/shm/clone/temp/th/Results/Caltech101/model6-10 
2016-12-09 22:47:38 augment false 
2016-12-09 22:47:38 epoch -1 
2016-12-09 22:47:38 modelsFolder ./Models/ 
2016-12-09 22:47:38 format rgb 
2016-12-09 22:47:38 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-09 22:47:38 imageFileExtension svg 
2016-12-09 22:47:38 channel 1 
2016-12-09 22:47:38 devid 7 
2016-12-09 22:47:38 visualize 1 
2016-12-09 22:47:38 LRDecayPerEpoch 0.0001 
2016-12-09 22:47:38 optimization adam 
2016-12-09 22:47:38 SBN true 
2016-12-09 22:47:38 normalization simple 
2016-12-09 22:47:38 title model1 
2016-12-09 22:47:38 load  
2016-12-09 22:47:38 whiten true 
2016-12-09 22:47:38 [----------------------] 
2016-12-09 22:47:39 ==> Network 
2016-12-09 22:47:39 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 102)
  (38): nn.BatchNormalization
} 
2016-12-09 22:47:39 ==>14128050 Parameters 
2016-12-09 22:47:39 ==> Loss 
2016-12-09 22:47:39 SqrtHingeEmbeddingCriterion 
2016-12-09 22:47:39 
==> Starting Training
 
2016-12-09 22:47:39 Epoch 1 
2016-12-09 22:48:40 Training Error = 0.77683272579992 
2016-12-09 22:48:40 Training Loss = 0.39516092944461 
2016-12-09 22:48:42 Valid Error = 0.72053462940462 
2016-12-09 22:48:42 Valid Loss = 0.067004407684132 
2016-12-09 22:48:44 Test Error = 0.75 
2016-12-09 22:48:44 Test Loss = 0.06808595532062 
2016-12-09 22:48:44 -------------------LR------------------- 
2016-12-09 22:48:44 0.015625 
2016-12-09 22:48:44 Epoch 2 
2016-12-09 22:49:43 Training Error = 0.62589442419333 
2016-12-09 22:49:43 Training Loss = 0.039291570483581 
2016-12-09 22:49:45 Valid Error = 0.7314702308627 
2016-12-09 22:49:45 Valid Loss = 0.034711135108328 
2016-12-09 22:49:47 Test Error = 0.76091703056769 
2016-12-09 22:49:47 Test Loss = 0.036402577400208 
2016-12-09 22:49:47 -------------------LR------------------- 
2016-12-09 22:49:47 0.015625 
2016-12-09 22:49:47 Epoch 3 
2016-12-09 22:50:48 Training Error = 0.63048467665722 
2016-12-09 22:50:48 Training Loss = 0.030254272708839 
2016-12-09 22:50:50 Valid Error = 0.71324422843256 
2016-12-09 22:50:50 Valid Loss = 0.030425456550138 
2016-12-09 22:50:52 Test Error = 0.74781659388646 
2016-12-09 22:50:52 Test Loss = 0.032580676406038 
2016-12-09 22:50:52 -------------------LR------------------- 
2016-12-09 22:50:52 0.015625 
2016-12-09 22:50:52 Epoch 4 
2016-12-09 22:52:04 Training Error = 0.60253813959768 
2016-12-09 22:52:04 Training Loss = 0.0281237016124 
2016-12-09 22:52:05 Valid Error = 0.70595382746051 
2016-12-09 22:52:05 Valid Loss = 0.02924491549166 
2016-12-09 22:52:07 Test Error = 0.74344978165939 
2016-12-09 22:52:07 Test Loss = 0.031239062262516 
2016-12-09 22:52:07 -------------------LR------------------- 
2016-12-09 22:52:07 0.015625 
2016-12-09 22:52:07 Epoch 5 
2016-12-09 22:53:11 Training Error = 0.57472660996355 
2016-12-09 22:53:11 Training Loss = 0.026852196580333 
2016-12-09 22:53:13 Valid Error = 0.75455650060753 
2016-12-09 22:53:13 Valid Loss = 0.030594152017131 
2016-12-09 22:53:15 Test Error = 0.79803493449782 
2016-12-09 22:53:15 Test Loss = 0.032818934767854 
2016-12-09 22:53:15 -------------------LR------------------- 
2016-12-09 22:53:15 0.015625 
2016-12-09 22:53:15 Epoch 6 
2016-12-09 22:54:17 Training Error = 0.5691913055218 
2016-12-09 22:54:17 Training Loss = 0.026739094408108 
2016-12-09 22:54:18 Valid Error = 0.73754556500608 
2016-12-09 22:54:18 Valid Loss = 0.030896308648154 
2016-12-09 22:54:20 Test Error = 0.77620087336245 
2016-12-09 22:54:20 Test Loss = 0.032498640266119 
2016-12-09 22:54:20 -------------------LR------------------- 
2016-12-09 22:54:20 0.015625 
2016-12-09 22:54:20 Epoch 7 
2016-12-09 22:55:24 Training Error = 0.54124476846227 
2016-12-09 22:55:24 Training Loss = 0.025336325449369 
2016-12-09 22:55:26 Valid Error = 0.56379100850547 
2016-12-09 22:55:26 Valid Loss = 0.027301688881278 
2016-12-09 22:55:28 Test Error = 0.61244541484716 
2016-12-09 22:55:28 Test Loss = 0.030186206032248 
2016-12-09 22:55:28 -------------------LR------------------- 
2016-12-09 22:55:28 0.015625 
2016-12-09 22:55:28 Epoch 8 
2016-12-09 22:56:45 Training Error = 0.52031861752396 
2016-12-09 22:56:45 Training Loss = 0.0248103068561 
2016-12-09 22:56:47 Valid Error = 0.73390036452005 
2016-12-09 22:56:47 Valid Loss = 0.034539934429152 
2016-12-09 22:56:49 Test Error = 0.7674672489083 
2016-12-09 22:56:49 Test Loss = 0.037942510679656 
2016-12-09 22:56:49 -------------------LR------------------- 
2016-12-09 22:56:49 0.015625 
2016-12-09 22:56:49 Epoch 9 
2016-12-09 22:57:56 Training Error = 0.49642230322668 
2016-12-09 22:57:56 Training Loss = 0.024105146356435 
2016-12-09 22:57:58 Valid Error = 0.52126366950182 
2016-12-09 22:57:58 Valid Loss = 0.024619083012484 
2016-12-09 22:58:00 Test Error = 0.56331877729258 
2016-12-09 22:58:00 Test Loss = 0.027318014874178 
2016-12-09 22:58:00 -------------------LR------------------- 
2016-12-09 22:58:00 0.015625 
2016-12-09 22:58:00 Epoch 10 
2016-12-09 22:59:09 Training Error = 0.45375995679762 
2016-12-09 22:59:09 Training Loss = 0.02355332654709 
2016-12-09 22:59:11 Valid Error = 0.46294046172539 
2016-12-09 22:59:11 Valid Loss = 0.022953610833513 
2016-12-09 22:59:13 Test Error = 0.50764192139738 
2016-12-09 22:59:13 Test Loss = 0.026583416920082 
2016-12-09 22:59:13 -------------------LR------------------- 
2016-12-09 22:59:13 0.015625 
2016-12-09 22:59:13 Epoch 11 
2016-12-09 23:00:29 Training Error = 0.41946807074389 
2016-12-09 23:00:29 Training Loss = 0.022649501048995 
2016-12-09 23:00:31 Valid Error = 0.49331713244228 
2016-12-09 23:00:31 Valid Loss = 0.02309994577876 
2016-12-09 23:00:33 Test Error = 0.53056768558952 
2016-12-09 23:00:33 Test Loss = 0.026774518667483 
2016-12-09 23:00:33 -------------------LR------------------- 
2016-12-09 23:00:33 0.015625 
2016-12-09 23:00:33 Epoch 12 
2016-12-09 23:01:43 Training Error = 0.42081814499797 
2016-12-09 23:01:43 Training Loss = 0.022576052954751 
2016-12-09 23:01:45 Valid Error = 0.47995139732685 
2016-12-09 23:01:45 Valid Loss = 0.023023677449047 
2016-12-09 23:01:47 Test Error = 0.51855895196507 
2016-12-09 23:01:47 Test Loss = 0.026720732333613 
2016-12-09 23:01:47 -------------------LR------------------- 
2016-12-09 23:01:47 0.015625 
2016-12-09 23:01:47 Epoch 13 
2016-12-09 23:03:09 Training Error = 0.42108815984879 
2016-12-09 23:03:09 Training Loss = 0.022585682017151 
2016-12-09 23:03:11 Valid Error = 0.47995139732685 
2016-12-09 23:03:11 Valid Loss = 0.022814367983934 
2016-12-09 23:03:13 Test Error = 0.51855895196507 
2016-12-09 23:03:13 Test Loss = 0.026623770704456 
2016-12-09 23:03:13 -------------------LR------------------- 
2016-12-09 23:03:13 0.015625 
2016-12-09 23:03:13 Epoch 14 
2016-12-09 23:04:42 Training Error = 0.41973808559471 
2016-12-09 23:04:42 Training Loss = 0.022637105965637 
2016-12-09 23:04:43 Valid Error = 0.47387606318348 
2016-12-09 23:04:43 Valid Loss = 0.024541002522706 
2016-12-09 23:04:45 Test Error = 0.51528384279476 
2016-12-09 23:04:45 Test Loss = 0.028595339943381 
2016-12-09 23:04:45 -------------------LR------------------- 
2016-12-09 23:04:45 0.015625 
2016-12-09 23:04:45 Epoch 15 
2016-12-09 23:05:57 Training Error = 0.42203321182665 
2016-12-09 23:05:57 Training Loss = 0.022757352287228 
2016-12-09 23:05:59 Valid Error = 0.52855407047388 
2016-12-09 23:05:59 Valid Loss = 0.024725810791085 
2016-12-09 23:06:01 Test Error = 0.5938864628821 
2016-12-09 23:06:01 Test Loss = 0.02864284511641 
2016-12-09 23:06:01 -------------------LR------------------- 
2016-12-09 23:06:01 0.015625 
2016-12-09 23:06:01 Epoch 16 
2016-12-09 23:07:12 Training Error = 0.42716349399217 
2016-12-09 23:07:12 Training Loss = 0.022799660283221 
2016-12-09 23:07:14 Valid Error = 0.47144592952612 
2016-12-09 23:07:14 Valid Loss = 0.023155323067228 
2016-12-09 23:07:16 Test Error = 0.51637554585153 
2016-12-09 23:07:16 Test Loss = 0.026925156172584 
2016-12-09 23:07:16 -------------------LR------------------- 
2016-12-09 23:07:16 0.015625 
2016-12-09 23:07:16 Epoch 17 
2016-12-09 23:08:33 Training Error = 0.42230322667747 
2016-12-09 23:08:33 Training Loss = 0.022815291708725 
2016-12-09 23:08:35 Valid Error = 0.54313487241798 
2016-12-09 23:08:35 Valid Loss = 0.024843180147753 
2016-12-09 23:08:37 Test Error = 0.60698689956332 
2016-12-09 23:08:37 Test Loss = 0.028709756037768 
2016-12-09 23:08:37 -------------------LR------------------- 
2016-12-09 23:08:37 0.015625 
2016-12-09 23:08:37 Epoch 18 
2016-12-09 23:10:19 Training Error = 0.42135817469961 
2016-12-09 23:10:19 Training Loss = 0.022739328309245 
2016-12-09 23:10:20 Valid Error = 0.48602673147023 
2016-12-09 23:10:20 Valid Loss = 0.0228403036362 
2016-12-09 23:10:22 Test Error = 0.53056768558952 
2016-12-09 23:10:22 Test Loss = 0.026330310447543 
2016-12-09 23:10:22 -------------------LR------------------- 
2016-12-09 23:10:22 0.015625 
2016-12-09 23:10:22 Epoch 19 
2016-12-09 23:12:09 Training Error = 0.42432833805859 
2016-12-09 23:12:09 Training Loss = 0.02257823574376 
2016-12-09 23:12:11 Valid Error = 0.47995139732685 
2016-12-09 23:12:11 Valid Loss = 0.023599390519708 
2016-12-09 23:12:13 Test Error = 0.5207423580786 
2016-12-09 23:12:13 Test Loss = 0.027441202874277 
2016-12-09 23:12:13 -------------------LR------------------- 
2016-12-09 23:12:13 0.015625 
2016-12-09 23:12:13 Epoch 20 
2016-12-09 23:13:51 Training Error = 0.41703793708654 
2016-12-09 23:13:51 Training Loss = 0.022726624976976 
2016-12-09 23:13:53 Valid Error = 0.50668286755772 
2016-12-09 23:13:53 Valid Loss = 0.022904015472693 
2016-12-09 23:13:55 Test Error = 0.55021834061135 
2016-12-09 23:13:55 Test Loss = 0.026572004103193 
2016-12-09 23:13:55 -------------------LR------------------- 
2016-12-09 23:13:55 0.015625 
2016-12-09 23:13:55 Epoch 21 
2016-12-09 23:15:35 Training Error = 0.42311327122992 
2016-12-09 23:15:35 Training Loss = 0.022667164064723 
2016-12-09 23:15:37 Valid Error = 0.47387606318348 
2016-12-09 23:15:37 Valid Loss = 0.024178987593207 
2016-12-09 23:15:39 Test Error = 0.51528384279476 
2016-12-09 23:15:39 Test Loss = 0.027851074545991 
2016-12-09 23:15:39 -------------------LR------------------- 
2016-12-09 23:15:39 0.015625 
2016-12-09 23:15:39 Epoch 22 
2016-12-09 23:17:19 Training Error = 0.42027811529634 
2016-12-09 23:17:19 Training Loss = 0.022760190582988 
2016-12-09 23:17:21 Valid Error = 0.47144592952612 
2016-12-09 23:17:21 Valid Loss = 0.022866403742858 
2016-12-09 23:17:23 Test Error = 0.51637554585153 
2016-12-09 23:17:23 Test Loss = 0.026672389666239 
2016-12-09 23:17:23 -------------------LR------------------- 
2016-12-09 23:17:23 0.015625 
2016-12-09 23:17:23 Epoch 23 
2016-12-09 23:19:09 Training Error = 0.42216821925206 
2016-12-09 23:19:09 Training Loss = 0.022901662307583 
2016-12-09 23:19:10 Valid Error = 0.46901579586877 
2016-12-09 23:19:10 Valid Loss = 0.024265412170462 
2016-12-09 23:19:12 Test Error = 0.50764192139738 
2016-12-09 23:19:12 Test Loss = 0.028005297324237 
2016-12-09 23:19:12 -------------------LR------------------- 
2016-12-09 23:19:12 0.015625 
2016-12-09 23:19:12 Epoch 24 
2016-12-09 23:20:55 Training Error = 0.42365330093155 
2016-12-09 23:20:55 Training Loss = 0.022923999180157 
2016-12-09 23:20:57 Valid Error = 0.48845686512758 
2016-12-09 23:20:57 Valid Loss = 0.022871406369446 
2016-12-09 23:20:59 Test Error = 0.52292576419214 
2016-12-09 23:20:59 Test Loss = 0.026557202152177 
2016-12-09 23:20:59 -------------------LR------------------- 
2016-12-09 23:20:59 0.015625 
2016-12-09 23:20:59 Epoch 25 
2016-12-09 23:22:42 Training Error = 0.41825300391522 
2016-12-09 23:22:42 Training Loss = 0.022575242533537 
2016-12-09 23:22:44 Valid Error = 0.47630619684083 
2016-12-09 23:22:44 Valid Loss = 0.023447893617324 
2016-12-09 23:22:46 Test Error = 0.52183406113537 
2016-12-09 23:22:46 Test Loss = 0.027336048107521 
2016-12-09 23:22:46 -------------------LR------------------- 
2016-12-09 23:22:46 0.015625 
2016-12-09 23:22:46 Epoch 26 
2016-12-09 23:24:28 Training Error = 0.42351829350614 
2016-12-09 23:24:28 Training Loss = 0.02283407844807 
2016-12-09 23:24:30 Valid Error = 0.48845686512758 
2016-12-09 23:24:30 Valid Loss = 0.023397740296052 
2016-12-09 23:24:32 Test Error = 0.52292576419214 
2016-12-09 23:24:32 Test Loss = 0.027226190941007 
2016-12-09 23:24:32 -------------------LR------------------- 
2016-12-09 23:24:32 0.015625 
2016-12-09 23:24:32 Epoch 27 
2016-12-09 23:26:11 Training Error = 0.42176319697583 
2016-12-09 23:26:11 Training Loss = 0.022581937419133 
2016-12-09 23:26:12 Valid Error = 0.47387606318348 
2016-12-09 23:26:12 Valid Loss = 0.023846985098877 
2016-12-09 23:26:14 Test Error = 0.51528384279476 
2016-12-09 23:26:14 Test Loss = 0.027636529043609 
2016-12-09 23:26:14 -------------------LR------------------- 
2016-12-09 23:26:14 0.015625 
2016-12-09 23:26:14 Epoch 28 
2016-12-09 23:27:59 Training Error = 0.41865802619144 
2016-12-09 23:27:59 Training Loss = 0.022856338039366 
2016-12-09 23:28:01 Valid Error = 0.51883353584447 
2016-12-09 23:28:01 Valid Loss = 0.024353804729693 
2016-12-09 23:28:03 Test Error = 0.57860262008734 
2016-12-09 23:28:03 Test Loss = 0.028051463912515 
2016-12-09 23:28:03 -------------------LR------------------- 
2016-12-09 23:28:03 0.015625 
2016-12-09 23:28:03 Epoch 29 
2016-12-09 23:29:43 Training Error = 0.41784798163899 
2016-12-09 23:29:43 Training Loss = 0.022640047456971 
2016-12-09 23:29:45 Valid Error = 0.4775212636695 
2016-12-09 23:29:45 Valid Loss = 0.023083418166535 
2016-12-09 23:29:47 Test Error = 0.52838427947598 
2016-12-09 23:29:47 Test Loss = 0.026954305368311 
2016-12-09 23:29:47 -------------------LR------------------- 
2016-12-09 23:29:47 0.015625 
2016-12-09 23:29:47 Epoch 30 
2016-12-09 23:31:34 Training Error = 0.4212231672742 
2016-12-09 23:31:34 Training Loss = 0.022639410625497 
2016-12-09 23:31:36 Valid Error = 0.46051032806804 
2016-12-09 23:31:36 Valid Loss = 0.023795189596864 
2016-12-09 23:31:38 Test Error = 0.50545851528384 
2016-12-09 23:31:38 Test Loss = 0.027571910035376 
2016-12-09 23:31:38 -------------------LR------------------- 
2016-12-09 23:31:38 0.015625 
2016-12-09 23:31:38 Epoch 31 
2016-12-09 23:33:20 Training Error = 0.42108815984879 
2016-12-09 23:33:20 Training Loss = 0.022929195485974 
2016-12-09 23:33:22 Valid Error = 0.47387606318348 
2016-12-09 23:33:22 Valid Loss = 0.02397810729015 
2016-12-09 23:33:24 Test Error = 0.51528384279476 
2016-12-09 23:33:24 Test Loss = 0.027877638433494 
2016-12-09 23:33:24 -------------------LR------------------- 
2016-12-09 23:33:24 0.015625 
2016-12-09 23:33:24 Epoch 32 
2016-12-09 23:35:04 Training Error = 0.41757796678817 
2016-12-09 23:35:04 Training Loss = 0.022526724954101 
2016-12-09 23:35:06 Valid Error = 0.47387606318348 
2016-12-09 23:35:06 Valid Loss = 0.023986514981208 
2016-12-09 23:35:08 Test Error = 0.5174672489083 
2016-12-09 23:35:08 Test Loss = 0.027820058719785 
2016-12-09 23:35:08 -------------------LR------------------- 
2016-12-09 23:35:08 0.015625 
2016-12-09 23:35:08 Epoch 33 
2016-12-09 23:36:52 Training Error = 0.4179829890644 
2016-12-09 23:36:52 Training Loss = 0.022801866319444 
2016-12-09 23:36:54 Valid Error = 0.47387606318348 
2016-12-09 23:36:54 Valid Loss = 0.022845913329743 
2016-12-09 23:36:56 Test Error = 0.53165938864629 
2016-12-09 23:36:56 Test Loss = 0.026584430199043 
2016-12-09 23:36:56 -------------------LR------------------- 
2016-12-09 23:36:56 0.015625 
2016-12-09 23:36:56 Epoch 34 
2016-12-09 23:38:36 Training Error = 0.42230322667747 
2016-12-09 23:38:36 Training Loss = 0.022763484751811 
2016-12-09 23:38:38 Valid Error = 0.50182260024301 
2016-12-09 23:38:38 Valid Loss = 0.023130988948237 
2016-12-09 23:38:40 Test Error = 0.55131004366812 
2016-12-09 23:38:40 Test Loss = 0.027017348083795 
2016-12-09 23:38:40 -------------------LR------------------- 
2016-12-09 23:38:40 0.015625 
2016-12-09 23:38:40 Epoch 35 
2016-12-09 23:40:22 Training Error = 0.41946807074389 
2016-12-09 23:40:22 Training Loss = 0.022657192562898 
2016-12-09 23:40:24 Valid Error = 0.56136087484812 
2016-12-09 23:40:24 Valid Loss = 0.025321690012946 
2016-12-09 23:40:26 Test Error = 0.61353711790393 
2016-12-09 23:40:26 Test Loss = 0.029380591551463 
2016-12-09 23:40:26 -------------------LR------------------- 
2016-12-09 23:40:26 0.015625 
2016-12-09 23:40:26 Epoch 36 
2016-12-09 23:42:07 Training Error = 0.41825300391522 
2016-12-09 23:42:07 Training Loss = 0.022805021958124 
2016-12-09 23:42:09 Valid Error = 0.4678007290401 
2016-12-09 23:42:09 Valid Loss = 0.023741980058808 
2016-12-09 23:42:11 Test Error = 0.50655021834061 
2016-12-09 23:42:11 Test Loss = 0.027493687882143 
2016-12-09 23:42:11 -------------------LR------------------- 
2016-12-09 23:42:11 0.015625 
2016-12-09 23:42:11 Epoch 37 
2016-12-09 23:43:53 Training Error = 0.41933306331848 
2016-12-09 23:43:53 Training Loss = 0.02268687968962 
2016-12-09 23:43:55 Valid Error = 0.49331713244228 
2016-12-09 23:43:55 Valid Loss = 0.023360158868435 
2016-12-09 23:43:57 Test Error = 0.54912663755459 
2016-12-09 23:43:57 Test Loss = 0.026919473246032 
2016-12-09 23:43:57 -------------------LR------------------- 
2016-12-09 23:43:57 0.015625 
2016-12-09 23:43:57 Epoch 38 
2016-12-09 23:45:38 Training Error = 0.4212231672742 
2016-12-09 23:45:38 Training Loss = 0.022827280483727 
2016-12-09 23:45:39 Valid Error = 0.54070473876063 
2016-12-09 23:45:39 Valid Loss = 0.02511875158008 
2016-12-09 23:45:41 Test Error = 0.60262008733624 
2016-12-09 23:45:41 Test Loss = 0.029025598376405 
2016-12-09 23:45:41 -------------------LR------------------- 
2016-12-09 23:45:41 0.015625 
2016-12-09 23:45:41 Epoch 39 
2016-12-09 23:47:24 Training Error = 0.42176319697583 
2016-12-09 23:47:24 Training Loss = 0.022754341765189 
2016-12-09 23:47:26 Valid Error = 0.48481166464156 
2016-12-09 23:47:26 Valid Loss = 0.023407754416582 
2016-12-09 23:47:28 Test Error = 0.52620087336245 
2016-12-09 23:47:28 Test Loss = 0.026961587700189 
2016-12-09 23:47:28 -------------------LR------------------- 
2016-12-09 23:47:28 0.015625 
2016-12-09 23:47:28 Epoch 40 
2016-12-09 23:49:14 Training Error = 0.41987309302012 
2016-12-09 23:49:14 Training Loss = 0.022643458528634 
2016-12-09 23:49:16 Valid Error = 0.47509113001215 
2016-12-09 23:49:16 Valid Loss = 0.02405393429368 
2016-12-09 23:49:18 Test Error = 0.50764192139738 
2016-12-09 23:49:18 Test Loss = 0.027934364038355 
2016-12-09 23:49:18 -------------------LR------------------- 
2016-12-09 23:49:18 0.015625 
2016-12-09 23:49:18 Epoch 41 
2016-12-09 23:50:59 Training Error = 0.41987309302012 
2016-12-09 23:50:59 Training Loss = 0.022557825983584 
2016-12-09 23:51:01 Valid Error = 0.45321992709599 
2016-12-09 23:51:01 Valid Loss = 0.024322158533074 
2016-12-09 23:51:02 Test Error = 0.50218340611354 
2016-12-09 23:51:02 Test Loss = 0.028111406765732 
2016-12-09 23:51:02 -------------------LR------------------- 
2016-12-09 23:51:02 0.015625 
2016-12-09 23:51:02 Epoch 42 
2016-12-09 23:52:41 Training Error = 0.4179829890644 
2016-12-09 23:52:41 Training Loss = 0.022675948387167 
2016-12-09 23:52:43 Valid Error = 0.47630619684083 
2016-12-09 23:52:43 Valid Loss = 0.023811606294878 
2016-12-09 23:52:45 Test Error = 0.52183406113537 
2016-12-09 23:52:45 Test Loss = 0.027832419021457 
2016-12-09 23:52:45 -------------------LR------------------- 
2016-12-09 23:52:45 0.015625 
2016-12-09 23:52:45 Epoch 43 
2016-12-09 23:54:25 Training Error = 0.42405832320778 
2016-12-09 23:54:25 Training Loss = 0.022783829017447 
2016-12-09 23:54:26 Valid Error = 0.4775212636695 
2016-12-09 23:54:26 Valid Loss = 0.024038781031205 
2016-12-09 23:54:28 Test Error = 0.51200873362445 
2016-12-09 23:54:28 Test Loss = 0.028002005633186 
2016-12-09 23:54:28 -------------------LR------------------- 
2016-12-09 23:54:28 0.015625 
2016-12-09 23:54:28 Epoch 44 
2016-12-09 23:56:25 Training Error = 0.42216821925206 
2016-12-09 23:56:25 Training Loss = 0.022744874736597 
2016-12-09 23:56:27 Valid Error = 0.47144592952612 
2016-12-09 23:56:27 Valid Loss = 0.02492414035275 
2016-12-09 23:56:29 Test Error = 0.51637554585153 
2016-12-09 23:56:29 Test Loss = 0.029152238995421 
2016-12-09 23:56:29 -------------------LR------------------- 
2016-12-09 23:56:29 0.015625 
2016-12-09 23:56:29 Epoch 45 
2016-12-09 23:58:34 Training Error = 0.4196030781693 
2016-12-09 23:58:34 Training Loss = 0.02257219146814 
2016-12-09 23:58:36 Valid Error = 0.45808019441069 
2016-12-09 23:58:36 Valid Loss = 0.023192679436017 
2016-12-09 23:58:38 Test Error = 0.50436681222707 
2016-12-09 23:58:38 Test Loss = 0.027020729457631 
2016-12-09 23:58:38 -------------------LR------------------- 
2016-12-09 23:58:38 0.015625 
2016-12-09 23:58:38 Epoch 46 
2016-12-10 00:00:34 Training Error = 0.4196030781693 
2016-12-10 00:00:34 Training Loss = 0.022639694232389 
2016-12-10 00:00:36 Valid Error = 0.49939246658566 
2016-12-10 00:00:36 Valid Loss = 0.022688654684327 
2016-12-10 00:00:38 Test Error = 0.54257641921397 
2016-12-10 00:00:38 Test Loss = 0.0262437526011 
2016-12-10 00:00:38 -------------------LR------------------- 
2016-12-10 00:00:38 0.015625 
2016-12-10 00:00:38 Epoch 47 
2016-12-10 00:02:26 Training Error = 0.42054813014716 
2016-12-10 00:02:26 Training Loss = 0.022835982370243 
2016-12-10 00:02:28 Valid Error = 0.49696233292831 
2016-12-10 00:02:28 Valid Loss = 0.023303339015899 
2016-12-10 00:02:30 Test Error = 0.54585152838428 
2016-12-10 00:02:30 Test Loss = 0.026941237487045 
2016-12-10 00:02:30 -------------------LR------------------- 
2016-12-10 00:02:30 0.015625 
2016-12-10 00:02:30 Epoch 48 
2016-12-10 00:04:14 Training Error = 0.42176319697583 
2016-12-10 00:04:14 Training Loss = 0.022905452428367 
2016-12-10 00:04:16 Valid Error = 0.49696233292831 
2016-12-10 00:04:16 Valid Loss = 0.022832436510545 
2016-12-10 00:04:18 Test Error = 0.54366812227074 
2016-12-10 00:04:18 Test Loss = 0.026633340209138 
2016-12-10 00:04:18 -------------------LR------------------- 
2016-12-10 00:04:18 0.015625 
2016-12-10 00:04:18 Epoch 49 
2016-12-10 00:06:02 Training Error = 0.42162818955043 
2016-12-10 00:06:02 Training Loss = 0.022783336507617 
2016-12-10 00:06:04 Valid Error = 0.4775212636695 
2016-12-10 00:06:04 Valid Loss = 0.02316072744572 
2016-12-10 00:06:06 Test Error = 0.52838427947598 
2016-12-10 00:06:06 Test Loss = 0.026851247329338 
2016-12-10 00:06:06 -------------------LR------------------- 
2016-12-10 00:06:06 0.015625 
2016-12-10 00:06:06 Epoch 50 
2016-12-10 00:07:47 Training Error = 0.42351829350614 
2016-12-10 00:07:47 Training Loss = 0.022663032924962 
2016-12-10 00:07:49 Valid Error = 0.47387606318348 
2016-12-10 00:07:49 Valid Loss = 0.024347768344357 
2016-12-10 00:07:51 Test Error = 0.51528384279476 
2016-12-10 00:07:51 Test Loss = 0.028400180994296 
2016-12-10 00:07:51 -------------------LR------------------- 
2016-12-10 00:07:51 0.0078125 
2016-12-10 00:07:51 Epoch 51 
2016-12-10 00:09:30 Training Error = 0.4196030781693 
2016-12-10 00:09:30 Training Loss = 0.022749828523125 
2016-12-10 00:09:32 Valid Error = 0.54556500607533 
2016-12-10 00:09:32 Valid Loss = 0.02494440190571 
2016-12-10 00:09:34 Test Error = 0.60043668122271 
2016-12-10 00:09:34 Test Loss = 0.028826423336478 
2016-12-10 00:09:34 -------------------LR------------------- 
2016-12-10 00:09:34 0.0078125 
2016-12-10 00:09:34 Epoch 52 
2016-12-10 00:11:14 Training Error = 0.42041312272175 
2016-12-10 00:11:14 Training Loss = 0.022713438025153 
2016-12-10 00:11:15 Valid Error = 0.47630619684083 
2016-12-10 00:11:15 Valid Loss = 0.02281824695688 
2016-12-10 00:11:17 Test Error = 0.51310043668122 
2016-12-10 00:11:17 Test Loss = 0.026610844004388 
2016-12-10 00:11:17 -------------------LR------------------- 
2016-12-10 00:11:17 0.0078125 
2016-12-10 00:11:17 Epoch 53 
2016-12-10 00:12:53 Training Error = 0.42068313757257 
2016-12-10 00:12:53 Training Loss = 0.022912785139894 
2016-12-10 00:12:55 Valid Error = 0.45929526123937 
2016-12-10 00:12:55 Valid Loss = 0.024204170333286 
2016-12-10 00:12:57 Test Error = 0.50436681222707 
2016-12-10 00:12:57 Test Loss = 0.027974433870877 
2016-12-10 00:12:57 -------------------LR------------------- 
2016-12-10 00:12:57 0.0078125 
2016-12-10 00:12:57 Epoch 54 
2016-12-10 00:14:33 Training Error = 0.424463345484 
2016-12-10 00:14:33 Training Loss = 0.022849720526231 
2016-12-10 00:14:35 Valid Error = 0.55285540704739 
2016-12-10 00:14:35 Valid Loss = 0.024884989815159 
2016-12-10 00:14:37 Test Error = 0.61135371179039 
2016-12-10 00:14:37 Test Loss = 0.028648066660937 
2016-12-10 00:14:37 -------------------LR------------------- 
2016-12-10 00:14:37 0.0078125 
2016-12-10 00:14:37 Epoch 55 
2016-12-10 00:16:15 Training Error = 0.42108815984879 
2016-12-10 00:16:15 Training Loss = 0.022777840643704 
2016-12-10 00:16:17 Valid Error = 0.47995139732685 
2016-12-10 00:16:17 Valid Loss = 0.023189933685074 
2016-12-10 00:16:19 Test Error = 0.51855895196507 
2016-12-10 00:16:19 Test Loss = 0.026807302923763 
2016-12-10 00:16:19 -------------------LR------------------- 
2016-12-10 00:16:19 0.0078125 
2016-12-10 00:16:19 Epoch 56 
2016-12-10 00:17:56 Training Error = 0.42297826380451 
2016-12-10 00:17:56 Training Loss = 0.022809542087302 
2016-12-10 00:17:58 Valid Error = 0.48481166464156 
2016-12-10 00:17:58 Valid Loss = 0.023799444731409 
2016-12-10 00:18:00 Test Error = 0.52620087336245 
2016-12-10 00:18:00 Test Loss = 0.0273400312592 
2016-12-10 00:18:00 -------------------LR------------------- 
2016-12-10 00:18:00 0.0078125 
2016-12-10 00:18:00 Epoch 57 
2016-12-10 00:19:35 Training Error = 0.41973808559471 
2016-12-10 00:19:35 Training Loss = 0.022721202017591 
2016-12-10 00:19:37 Valid Error = 0.45929526123937 
2016-12-10 00:19:37 Valid Loss = 0.024034614479879 
2016-12-10 00:19:39 Test Error = 0.50218340611354 
2016-12-10 00:19:39 Test Loss = 0.028105431790445 
2016-12-10 00:19:39 -------------------LR------------------- 
2016-12-10 00:19:39 0.0078125 
2016-12-10 00:19:39 Epoch 58 
2016-12-10 00:21:14 Training Error = 0.42405832320778 
2016-12-10 00:21:14 Training Loss = 0.022770005994952 
2016-12-10 00:21:16 Valid Error = 0.46658566221142 
2016-12-10 00:21:16 Valid Loss = 0.023437983473221 
2016-12-10 00:21:18 Test Error = 0.50873362445415 
2016-12-10 00:21:18 Test Loss = 0.027013954031701 
2016-12-10 00:21:18 -------------------LR------------------- 
2016-12-10 00:21:18 0.0078125 
2016-12-10 00:21:18 Epoch 59 
2016-12-10 00:22:51 Training Error = 0.42014310787093 
2016-12-10 00:22:51 Training Loss = 0.022732022650369 
2016-12-10 00:22:53 Valid Error = 0.50182260024301 
2016-12-10 00:22:53 Valid Loss = 0.023033671103114 
2016-12-10 00:22:55 Test Error = 0.55131004366812 
2016-12-10 00:22:55 Test Loss = 0.026920080615025 
2016-12-10 00:22:55 -------------------LR------------------- 
2016-12-10 00:22:55 0.0078125 
2016-12-10 00:22:55 Epoch 60 
2016-12-10 00:24:38 Training Error = 0.42743350884299 
2016-12-10 00:24:38 Training Loss = 0.022733624840317 
2016-12-10 00:24:40 Valid Error = 0.46294046172539 
2016-12-10 00:24:40 Valid Loss = 0.023507771861929 
2016-12-10 00:24:42 Test Error = 0.51200873362445 
2016-12-10 00:24:42 Test Loss = 0.027357046613506 
2016-12-10 00:24:42 -------------------LR------------------- 
2016-12-10 00:24:42 0.0078125 
2016-12-10 00:24:42 Epoch 61 
2016-12-10 00:26:21 Training Error = 0.42081814499797 
2016-12-10 00:26:21 Training Loss = 0.022683271033023 
2016-12-10 00:26:23 Valid Error = 0.46537059538275 
2016-12-10 00:26:23 Valid Loss = 0.024172362862092 
2016-12-10 00:26:25 Test Error = 0.51310043668122 
2016-12-10 00:26:25 Test Loss = 0.028072543854807 
2016-12-10 00:26:25 -------------------LR------------------- 
2016-12-10 00:26:25 0.0078125 
2016-12-10 00:26:25 Epoch 62 
2016-12-10 00:28:02 Training Error = 0.42203321182665 
2016-12-10 00:28:02 Training Loss = 0.022869426470132 
2016-12-10 00:28:03 Valid Error = 0.47995139732685 
2016-12-10 00:28:03 Valid Loss = 0.022757491060896 
2016-12-10 00:28:05 Test Error = 0.51855895196507 
2016-12-10 00:28:05 Test Loss = 0.026467834996242 
2016-12-10 00:28:05 -------------------LR------------------- 
2016-12-10 00:28:05 0.0078125 
2016-12-10 00:28:05 Epoch 63 
2016-12-10 00:29:45 Training Error = 0.41946807074389 
2016-12-10 00:29:45 Training Loss = 0.022691580318447 
2016-12-10 00:29:46 Valid Error = 0.47630619684083 
2016-12-10 00:29:46 Valid Loss = 0.022721188935387 
2016-12-10 00:29:48 Test Error = 0.52401746724891 
2016-12-10 00:29:48 Test Loss = 0.026261571940254 
2016-12-10 00:29:48 -------------------LR------------------- 
2016-12-10 00:29:48 0.0078125 
2016-12-10 00:29:48 Epoch 64 
2016-12-10 00:31:25 Training Error = 0.42635344943972 
2016-12-10 00:31:25 Training Loss = 0.022645618305509 
2016-12-10 00:31:27 Valid Error = 0.47387606318348 
2016-12-10 00:31:27 Valid Loss = 0.023632930832581 
2016-12-10 00:31:29 Test Error = 0.5174672489083 
2016-12-10 00:31:29 Test Loss = 0.027381226735957 
2016-12-10 00:31:29 -------------------LR------------------- 
2016-12-10 00:31:29 0.0078125 
2016-12-10 00:31:29 Epoch 65 
2016-12-10 00:33:05 Training Error = 0.42365330093155 
2016-12-10 00:33:05 Training Loss = 0.022649830718624 
2016-12-10 00:33:07 Valid Error = 0.47387606318348 
2016-12-10 00:33:07 Valid Loss = 0.023177818189214 
2016-12-10 00:33:09 Test Error = 0.5174672489083 
2016-12-10 00:33:09 Test Loss = 0.026882793688307 
2016-12-10 00:33:09 -------------------LR------------------- 
2016-12-10 00:33:09 0.0078125 
2016-12-10 00:33:09 Epoch 66 
2016-12-10 00:34:48 Training Error = 0.42149318212502 
2016-12-10 00:34:48 Training Loss = 0.022745480181412 
2016-12-10 00:34:49 Valid Error = 0.48724179829891 
2016-12-10 00:34:49 Valid Loss = 0.022795187359429 
2016-12-10 00:34:51 Test Error = 0.53275109170306 
2016-12-10 00:34:51 Test Loss = 0.026401175246519 
2016-12-10 00:34:51 -------------------LR------------------- 
2016-12-10 00:34:51 0.0078125 
2016-12-10 00:34:51 Epoch 67 
2016-12-10 00:36:27 Training Error = 0.41717294451195 
2016-12-10 00:36:27 Training Loss = 0.022634231064455 
2016-12-10 00:36:29 Valid Error = 0.4823815309842 
2016-12-10 00:36:29 Valid Loss = 0.024026780969956 
2016-12-10 00:36:31 Test Error = 0.51965065502183 
2016-12-10 00:36:31 Test Loss = 0.027836209745968 
2016-12-10 00:36:31 -------------------LR------------------- 
2016-12-10 00:36:31 0.0078125 
2016-12-10 00:36:31 Epoch 68 
2016-12-10 00:38:09 Training Error = 0.41744295936276 
2016-12-10 00:38:09 Training Loss = 0.022655571022354 
2016-12-10 00:38:11 Valid Error = 0.48481166464156 
2016-12-10 00:38:11 Valid Loss = 0.023194043375478 
2016-12-10 00:38:13 Test Error = 0.52620087336245 
2016-12-10 00:38:13 Test Loss = 0.026948938799839 
2016-12-10 00:38:13 -------------------LR------------------- 
2016-12-10 00:38:13 0.0078125 
2016-12-10 00:38:13 Epoch 69 
2016-12-10 00:39:47 Training Error = 0.41879303361685 
2016-12-10 00:39:47 Training Loss = 0.02284762249545 
2016-12-10 00:39:48 Valid Error = 0.48724179829891 
2016-12-10 00:39:48 Valid Loss = 0.022705634419661 
2016-12-10 00:39:50 Test Error = 0.53275109170306 
2016-12-10 00:39:50 Test Loss = 0.026360075249391 
2016-12-10 00:39:50 -------------------LR------------------- 
2016-12-10 00:39:50 0.0078125 
2016-12-10 00:39:50 Epoch 70 
2016-12-10 00:41:32 Training Error = 0.42054813014716 
2016-12-10 00:41:32 Training Loss = 0.022669374320977 
2016-12-10 00:41:34 Valid Error = 0.48481166464156 
2016-12-10 00:41:34 Valid Loss = 0.022825618554914 
2016-12-10 00:41:36 Test Error = 0.54475982532751 
2016-12-10 00:41:36 Test Loss = 0.026688681443532 
2016-12-10 00:41:36 -------------------LR------------------- 
2016-12-10 00:41:36 0.0078125 
2016-12-10 00:41:36 Epoch 71 
2016-12-10 00:43:16 Training Error = 0.42230322667747 
2016-12-10 00:43:16 Training Loss = 0.022695918725563 
2016-12-10 00:43:17 Valid Error = 0.45929526123937 
2016-12-10 00:43:17 Valid Loss = 0.024105076783984 
2016-12-10 00:43:19 Test Error = 0.50436681222707 
2016-12-10 00:43:19 Test Loss = 0.028233329950594 
2016-12-10 00:43:19 -------------------LR------------------- 
2016-12-10 00:43:19 0.0078125 
2016-12-10 00:43:19 Epoch 72 
2016-12-10 00:44:58 Training Error = 0.42135817469961 
2016-12-10 00:44:58 Training Loss = 0.022851588853111 
2016-12-10 00:45:00 Valid Error = 0.48724179829891 
2016-12-10 00:45:00 Valid Loss = 0.022887926986071 
2016-12-10 00:45:02 Test Error = 0.52620087336245 
2016-12-10 00:45:02 Test Loss = 0.026645794784322 
2016-12-10 00:45:02 -------------------LR------------------- 
2016-12-10 00:45:02 0.0078125 
2016-12-10 00:45:02 Epoch 73 
2016-12-10 00:46:40 Training Error = 0.41838801134062 
2016-12-10 00:46:40 Training Loss = 0.022576086712151 
2016-12-10 00:46:42 Valid Error = 0.45929526123937 
2016-12-10 00:46:42 Valid Loss = 0.023813692927417 
2016-12-10 00:46:44 Test Error = 0.51419213973799 
2016-12-10 00:46:44 Test Loss = 0.027580130165698 
2016-12-10 00:46:44 -------------------LR------------------- 
2016-12-10 00:46:44 0.0078125 
2016-12-10 00:46:44 Epoch 74 
2016-12-10 00:48:22 Training Error = 0.42365330093155 
2016-12-10 00:48:22 Training Loss = 0.022862181012949 
2016-12-10 00:48:24 Valid Error = 0.45929526123937 
2016-12-10 00:48:24 Valid Loss = 0.023812769020531 
2016-12-10 00:48:26 Test Error = 0.50218340611354 
2016-12-10 00:48:26 Test Loss = 0.027630861534792 
2016-12-10 00:48:26 -------------------LR------------------- 
2016-12-10 00:48:26 0.0078125 
2016-12-10 00:48:26 Epoch 75 
2016-12-10 00:50:00 Training Error = 0.42135817469961 
2016-12-10 00:50:00 Training Loss = 0.022635435061272 
2016-12-10 00:50:02 Valid Error = 0.47144592952612 
2016-12-10 00:50:02 Valid Loss = 0.022976303205375 
2016-12-10 00:50:04 Test Error = 0.51637554585153 
2016-12-10 00:50:04 Test Loss = 0.026730439672283 
2016-12-10 00:50:04 -------------------LR------------------- 
2016-12-10 00:50:04 0.0078125 
2016-12-10 00:50:04 Epoch 76 
2016-12-10 00:51:42 Training Error = 0.41771297421358 
2016-12-10 00:51:42 Training Loss = 0.022569449903985 
2016-12-10 00:51:44 Valid Error = 0.47995139732685 
2016-12-10 00:51:44 Valid Loss = 0.02453424478126 
2016-12-10 00:51:46 Test Error = 0.51855895196507 
2016-12-10 00:51:46 Test Loss = 0.028524122864592 
2016-12-10 00:51:46 -------------------LR------------------- 
2016-12-10 00:51:46 0.0078125 
2016-12-10 00:51:46 Epoch 77 
2016-12-10 00:53:21 Training Error = 0.42500337518564 
2016-12-10 00:53:21 Training Loss = 0.022649919275164 
2016-12-10 00:53:23 Valid Error = 0.47630619684083 
2016-12-10 00:53:23 Valid Loss = 0.024373621736906 
2016-12-10 00:53:25 Test Error = 0.5207423580786 
2016-12-10 00:53:25 Test Loss = 0.028266178561192 
2016-12-10 00:53:25 -------------------LR------------------- 
2016-12-10 00:53:25 0.0078125 
2016-12-10 00:53:25 Epoch 78 
2016-12-10 00:55:03 Training Error = 0.41973808559471 
2016-12-10 00:55:03 Training Loss = 0.022796553189147 
2016-12-10 00:55:05 Valid Error = 0.46537059538275 
2016-12-10 00:55:05 Valid Loss = 0.02409005586697 
2016-12-10 00:55:07 Test Error = 0.51310043668122 
2016-12-10 00:55:07 Test Loss = 0.027971550128039 
2016-12-10 00:55:07 -------------------LR------------------- 
2016-12-10 00:55:07 0.0078125 
2016-12-10 00:55:07 Epoch 79 
2016-12-10 00:56:44 Training Error = 0.41703793708654 
2016-12-10 00:56:44 Training Loss = 0.022623798235725 
2016-12-10 00:56:46 Valid Error = 0.47630619684083 
2016-12-10 00:56:46 Valid Loss = 0.022959669871437 
2016-12-10 00:56:48 Test Error = 0.51310043668122 
2016-12-10 00:56:48 Test Loss = 0.026715050762775 
2016-12-10 00:56:48 -------------------LR------------------- 
2016-12-10 00:56:48 0.0078125 
2016-12-10 00:56:48 Epoch 80 
2016-12-10 00:58:31 Training Error = 0.42270824895369 
2016-12-10 00:58:31 Training Loss = 0.022709475445859 
2016-12-10 00:58:32 Valid Error = 0.47995139732685 
2016-12-10 00:58:32 Valid Loss = 0.023901173095761 
2016-12-10 00:58:34 Test Error = 0.51855895196507 
2016-12-10 00:58:34 Test Loss = 0.027495020772897 
2016-12-10 00:58:34 -------------------LR------------------- 
2016-12-10 00:58:34 0.0078125 
2016-12-10 00:58:34 Epoch 81 
2016-12-10 01:00:12 Training Error = 0.41406777372755 
2016-12-10 01:00:12 Training Loss = 0.022614930303379 
2016-12-10 01:00:13 Valid Error = 0.46901579586877 
2016-12-10 01:00:13 Valid Loss = 0.024711439814364 
2016-12-10 01:00:15 Test Error = 0.50764192139738 
2016-12-10 01:00:15 Test Loss = 0.028780470670438 
2016-12-10 01:00:15 -------------------LR------------------- 
2016-12-10 01:00:15 0.0078125 
2016-12-10 01:00:15 Epoch 82 
2016-12-10 01:01:48 Training Error = 0.42459835290941 
2016-12-10 01:01:48 Training Loss = 0.022787034843438 
2016-12-10 01:01:50 Valid Error = 0.46537059538275 
2016-12-10 01:01:50 Valid Loss = 0.023824276712296 
2016-12-10 01:01:52 Test Error = 0.51310043668122 
2016-12-10 01:01:52 Test Loss = 0.027574220545152 
2016-12-10 01:01:52 -------------------LR------------------- 
2016-12-10 01:01:52 0.0078125 
2016-12-10 01:01:52 Epoch 83 
2016-12-10 01:03:30 Training Error = 0.41757796678817 
2016-12-10 01:03:30 Training Loss = 0.022679159916327 
2016-12-10 01:03:32 Valid Error = 0.50182260024301 
2016-12-10 01:03:32 Valid Loss = 0.022949177683377 
2016-12-10 01:03:34 Test Error = 0.53930131004367 
2016-12-10 01:03:34 Test Loss = 0.026691136902454 
2016-12-10 01:03:34 -------------------LR------------------- 
2016-12-10 01:03:34 0.0078125 
2016-12-10 01:03:34 Epoch 84 
2016-12-10 01:05:01 Training Error = 0.41906304846767 
2016-12-10 01:05:01 Training Loss = 0.022750253065093 
2016-12-10 01:05:03 Valid Error = 0.46537059538275 
2016-12-10 01:05:03 Valid Loss = 0.02398678965242 
2016-12-10 01:05:05 Test Error = 0.51310043668122 
2016-12-10 01:05:05 Test Loss = 0.02764705360637 
2016-12-10 01:05:05 -------------------LR------------------- 
2016-12-10 01:05:05 0.0078125 
2016-12-10 01:05:05 Epoch 85 
2016-12-10 01:06:31 Training Error = 0.42014310787093 
2016-12-10 01:06:31 Training Loss = 0.022601876967828 
2016-12-10 01:06:33 Valid Error = 0.47144592952612 
2016-12-10 01:06:33 Valid Loss = 0.023948375285999 
2016-12-10 01:06:35 Test Error = 0.51419213973799 
2016-12-10 01:06:35 Test Loss = 0.027900595926771 
2016-12-10 01:06:35 -------------------LR------------------- 
2016-12-10 01:06:35 0.0078125 
2016-12-10 01:06:35 Epoch 86 
2016-12-10 01:08:00 Training Error = 0.42189820440124 
2016-12-10 01:08:00 Training Loss = 0.022712987873779 
2016-12-10 01:08:02 Valid Error = 0.48845686512758 
2016-12-10 01:08:02 Valid Loss = 0.023107482441856 
2016-12-10 01:08:04 Test Error = 0.52292576419214 
2016-12-10 01:08:04 Test Loss = 0.026932018495074 
2016-12-10 01:08:04 -------------------LR------------------- 
2016-12-10 01:08:04 0.0078125 
2016-12-10 01:08:04 Epoch 87 
2016-12-10 01:09:33 Training Error = 0.42311327122992 
2016-12-10 01:09:33 Training Loss = 0.022776751414067 
2016-12-10 01:09:35 Valid Error = 0.47995139732685 
2016-12-10 01:09:35 Valid Loss = 0.023565620501136 
2016-12-10 01:09:37 Test Error = 0.51855895196507 
2016-12-10 01:09:37 Test Loss = 0.027472770111234 
2016-12-10 01:09:37 -------------------LR------------------- 
2016-12-10 01:09:37 0.0078125 
2016-12-10 01:09:37 Epoch 88 
2016-12-10 01:11:03 Training Error = 0.41730795193736 
2016-12-10 01:11:03 Training Loss = 0.0225270415063 
2016-12-10 01:11:05 Valid Error = 0.4823815309842 
2016-12-10 01:11:05 Valid Loss = 0.0230373491983 
2016-12-10 01:11:07 Test Error = 0.52401746724891 
2016-12-10 01:11:07 Test Loss = 0.026763514500038 
2016-12-10 01:11:07 -------------------LR------------------- 
2016-12-10 01:11:07 0.0078125 
2016-12-10 01:11:07 Epoch 89 
2016-12-10 01:12:35 Training Error = 0.42095315242338 
2016-12-10 01:12:35 Training Loss = 0.022794788516603 
2016-12-10 01:12:37 Valid Error = 0.47630619684083 
2016-12-10 01:12:37 Valid Loss = 0.02376493486681 
2016-12-10 01:12:39 Test Error = 0.52401746724891 
2016-12-10 01:12:39 Test Loss = 0.02761526332182 
2016-12-10 01:12:39 -------------------LR------------------- 
2016-12-10 01:12:39 0.0078125 
2016-12-10 01:12:39 Epoch 90 
2016-12-10 01:14:13 Training Error = 0.41919805589307 
2016-12-10 01:14:13 Training Loss = 0.022665635286504 
2016-12-10 01:14:14 Valid Error = 0.46537059538275 
2016-12-10 01:14:14 Valid Loss = 0.02363875621533 
2016-12-10 01:14:16 Test Error = 0.51310043668122 
2016-12-10 01:14:16 Test Loss = 0.027452275734322 
2016-12-10 01:14:16 -------------------LR------------------- 
2016-12-10 01:14:16 0.0078125 
2016-12-10 01:14:16 Epoch 91 
2016-12-10 01:15:45 Training Error = 0.42149318212502 
2016-12-10 01:15:45 Training Loss = 0.022772721519435 
2016-12-10 01:15:47 Valid Error = 0.47995139732685 
2016-12-10 01:15:47 Valid Loss = 0.022682020496868 
2016-12-10 01:15:49 Test Error = 0.51855895196507 
2016-12-10 01:15:49 Test Loss = 0.026287094864191 
2016-12-10 01:15:49 -------------------LR------------------- 
2016-12-10 01:15:49 0.0078125 
2016-12-10 01:15:49 Epoch 92 
2016-12-10 01:17:17 Training Error = 0.42203321182665 
2016-12-10 01:17:17 Training Loss = 0.022646838093962 
2016-12-10 01:17:19 Valid Error = 0.48481166464156 
2016-12-10 01:17:19 Valid Loss = 0.023038438755623 
2016-12-10 01:17:21 Test Error = 0.52620087336245 
2016-12-10 01:17:21 Test Loss = 0.026641990035188 
2016-12-10 01:17:21 -------------------LR------------------- 
2016-12-10 01:17:21 0.0078125 
2016-12-10 01:17:21 Epoch 93 
2016-12-10 01:18:47 Training Error = 0.41933306331848 
2016-12-10 01:18:47 Training Loss = 0.022846072330706 
2016-12-10 01:18:49 Valid Error = 0.54313487241798 
2016-12-10 01:18:49 Valid Loss = 0.024753481442248 
2016-12-10 01:18:51 Test Error = 0.60698689956332 
2016-12-10 01:18:51 Test Loss = 0.028804343130074 
2016-12-10 01:18:51 -------------------LR------------------- 
2016-12-10 01:18:51 0.0078125 
2016-12-10 01:18:51 Epoch 94 
2016-12-10 01:20:19 Training Error = 0.41892804104226 
2016-12-10 01:20:19 Training Loss = 0.022597324503125 
2016-12-10 01:20:21 Valid Error = 0.47144592952612 
2016-12-10 01:20:21 Valid Loss = 0.023116887952496 
2016-12-10 01:20:23 Test Error = 0.51637554585153 
2016-12-10 01:20:23 Test Loss = 0.026767494061414 
2016-12-10 01:20:23 -------------------LR------------------- 
2016-12-10 01:20:23 0.0078125 
2016-12-10 01:20:23 Epoch 95 
2016-12-10 01:21:52 Training Error = 0.42162818955043 
2016-12-10 01:21:52 Training Loss = 0.022812720228065 
2016-12-10 01:21:54 Valid Error = 0.47387606318348 
2016-12-10 01:21:54 Valid Loss = 0.025005577075117 
2016-12-10 01:21:56 Test Error = 0.51528384279476 
2016-12-10 01:21:56 Test Loss = 0.028901088153615 
2016-12-10 01:21:56 -------------------LR------------------- 
2016-12-10 01:21:56 0.0078125 
2016-12-10 01:21:56 Epoch 96 
2016-12-10 01:23:20 Training Error = 0.41946807074389 
2016-12-10 01:23:20 Training Loss = 0.022570771803798 
2016-12-10 01:23:22 Valid Error = 0.47509113001215 
2016-12-10 01:23:22 Valid Loss = 0.02381053098892 
2016-12-10 01:23:24 Test Error = 0.51091703056769 
2016-12-10 01:23:24 Test Loss = 0.027685756197163 
2016-12-10 01:23:24 -------------------LR------------------- 
2016-12-10 01:23:24 0.0078125 
2016-12-10 01:23:24 Epoch 97 
2016-12-10 01:24:53 Training Error = 0.4212231672742 
2016-12-10 01:24:53 Training Loss = 0.022750504024445 
2016-12-10 01:24:55 Valid Error = 0.47387606318348 
2016-12-10 01:24:55 Valid Loss = 0.024531790222127 
2016-12-10 01:24:57 Test Error = 0.51528384279476 
2016-12-10 01:24:57 Test Loss = 0.028320880338257 
2016-12-10 01:24:57 -------------------LR------------------- 
2016-12-10 01:24:57 0.0078125 
2016-12-10 01:24:57 Epoch 98 
2016-12-10 01:26:24 Training Error = 0.4179829890644 
2016-12-10 01:26:24 Training Loss = 0.022786658207798 
2016-12-10 01:26:26 Valid Error = 0.55407047387606 
2016-12-10 01:26:26 Valid Loss = 0.024818985138561 
2016-12-10 01:26:28 Test Error = 0.6146288209607 
2016-12-10 01:26:28 Test Loss = 0.028757334821364 
2016-12-10 01:26:28 -------------------LR------------------- 
2016-12-10 01:26:28 0.0078125 
2016-12-10 01:26:28 Epoch 99 
2016-12-10 01:27:59 Training Error = 0.42041312272175 
2016-12-10 01:27:59 Training Loss = 0.022670559510018 
2016-12-10 01:28:01 Valid Error = 0.45929526123937 
2016-12-10 01:28:01 Valid Loss = 0.023619889142534 
2016-12-10 01:28:03 Test Error = 0.50436681222707 
2016-12-10 01:28:03 Test Loss = 0.027548393455206 
2016-12-10 01:28:03 -------------------LR------------------- 
2016-12-10 01:28:03 0.0078125 
2016-12-10 01:28:03 Epoch 100 
2016-12-10 01:29:34 Training Error = 0.42149318212502 
2016-12-10 01:29:34 Training Loss = 0.02264987647362 
2016-12-10 01:29:36 Valid Error = 0.47144592952612 
2016-12-10 01:29:36 Valid Loss = 0.022984375949609 
2016-12-10 01:29:38 Test Error = 0.50545851528384 
2016-12-10 01:29:38 Test Loss = 0.026575397902844 
2016-12-10 01:29:38 -------------------LR------------------- 
2016-12-10 01:29:38 0.00390625 
2016-12-10 01:29:38 Epoch 101 
2016-12-10 01:31:06 Training Error = 0.41865802619144 
2016-12-10 01:31:06 Training Loss = 0.02288008348481 
2016-12-10 01:31:08 Valid Error = 0.46537059538275 
2016-12-10 01:31:08 Valid Loss = 0.024029984527932 
2016-12-10 01:31:10 Test Error = 0.51310043668122 
2016-12-10 01:31:10 Test Loss = 0.027975481697157 
2016-12-10 01:31:10 -------------------LR------------------- 
2016-12-10 01:31:10 0.00390625 
2016-12-10 01:31:10 Epoch 102 
2016-12-10 01:32:53 Training Error = 0.42162818955043 
2016-12-10 01:32:53 Training Loss = 0.0226215663137 
2016-12-10 01:32:54 Valid Error = 0.54313487241798 
2016-12-10 01:32:54 Valid Loss = 0.024941409061248 
2016-12-10 01:32:56 Test Error = 0.60480349344978 
2016-12-10 01:32:56 Test Loss = 0.028988024029077 
2016-12-10 01:32:56 -------------------LR------------------- 
2016-12-10 01:32:56 0.00390625 
2016-12-10 01:32:56 Epoch 103 
2016-12-10 01:34:33 Training Error = 0.41811799648981 
2016-12-10 01:34:33 Training Loss = 0.022799440945608 
2016-12-10 01:34:35 Valid Error = 0.47144592952612 
2016-12-10 01:34:35 Valid Loss = 0.023165117231092 
2016-12-10 01:34:37 Test Error = 0.51419213973799 
2016-12-10 01:34:37 Test Loss = 0.026834498938392 
2016-12-10 01:34:37 -------------------LR------------------- 
2016-12-10 01:34:37 0.00390625 
2016-12-10 01:34:37 Epoch 104 
2016-12-10 01:36:05 Training Error = 0.41771297421358 
2016-12-10 01:36:05 Training Loss = 0.022793007766054 
2016-12-10 01:36:07 Valid Error = 0.48845686512758 
2016-12-10 01:36:07 Valid Loss = 0.023935209922722 
2016-12-10 01:36:09 Test Error = 0.52292576419214 
2016-12-10 01:36:09 Test Loss = 0.027701764910829 
2016-12-10 01:36:09 -------------------LR------------------- 
2016-12-10 01:36:09 0.00390625 
2016-12-10 01:36:09 Epoch 105 
2016-12-10 01:37:33 Training Error = 0.42041312272175 
2016-12-10 01:37:33 Training Loss = 0.022675224741589 
2016-12-10 01:37:35 Valid Error = 0.54313487241798 
2016-12-10 01:37:35 Valid Loss = 0.024724257305579 
2016-12-10 01:37:37 Test Error = 0.60698689956332 
2016-12-10 01:37:37 Test Loss = 0.028608304210738 
2016-12-10 01:37:37 -------------------LR------------------- 
2016-12-10 01:37:37 0.00390625 
2016-12-10 01:37:37 Epoch 106 
2016-12-10 01:39:03 Training Error = 0.42243823410288 
2016-12-10 01:39:03 Training Loss = 0.022718018156563 
2016-12-10 01:39:05 Valid Error = 0.47630619684083 
2016-12-10 01:39:05 Valid Loss = 0.023315242688923 
2016-12-10 01:39:07 Test Error = 0.52401746724891 
2016-12-10 01:39:07 Test Loss = 0.027054963429769 
2016-12-10 01:39:07 -------------------LR------------------- 
2016-12-10 01:39:07 0.00390625 
2016-12-10 01:39:07 Epoch 107 
2016-12-10 01:40:28 Training Error = 0.41973808559471 
2016-12-10 01:40:28 Training Loss = 0.022787346669828 
2016-12-10 01:40:30 Valid Error = 0.50303766707169 
2016-12-10 01:40:30 Valid Loss = 0.023762148363613 
2016-12-10 01:40:32 Test Error = 0.54475982532751 
2016-12-10 01:40:32 Test Loss = 0.027441765476676 
2016-12-10 01:40:32 -------------------LR------------------- 
2016-12-10 01:40:32 0.00390625 
2016-12-10 01:40:32 Epoch 108 
2016-12-10 01:42:02 Training Error = 0.41879303361685 
2016-12-10 01:42:02 Training Loss = 0.022717614163382 
2016-12-10 01:42:03 Valid Error = 0.48116646415553 
2016-12-10 01:42:03 Valid Loss = 0.023099127015438 
2016-12-10 01:42:05 Test Error = 0.5207423580786 
2016-12-10 01:42:05 Test Loss = 0.026619643641453 
2016-12-10 01:42:05 -------------------LR------------------- 
2016-12-10 01:42:05 0.00390625 
2016-12-10 01:42:05 Epoch 109 
2016-12-10 01:43:30 Training Error = 0.41973808559471 
2016-12-10 01:43:30 Training Loss = 0.022742686889819 
2016-12-10 01:43:32 Valid Error = 0.47630619684083 
2016-12-10 01:43:32 Valid Loss = 0.022978092947726 
2016-12-10 01:43:34 Test Error = 0.52401746724891 
2016-12-10 01:43:34 Test Loss = 0.026829765749913 
2016-12-10 01:43:34 -------------------LR------------------- 
2016-12-10 01:43:34 0.00390625 
2016-12-10 01:43:34 Epoch 110 
2016-12-10 01:45:05 Training Error = 0.42230322667747 
2016-12-10 01:45:05 Training Loss = 0.022904364310014 
2016-12-10 01:45:06 Valid Error = 0.50668286755772 
2016-12-10 01:45:06 Valid Loss = 0.023280052986517 
2016-12-10 01:45:08 Test Error = 0.55021834061135 
2016-12-10 01:45:08 Test Loss = 0.027261422652824 
2016-12-10 01:45:08 -------------------LR------------------- 
2016-12-10 01:45:08 0.00390625 
2016-12-10 01:45:08 Epoch 111 
2016-12-10 01:46:36 Training Error = 0.42000810044552 
2016-12-10 01:46:36 Training Loss = 0.022613998655289 
2016-12-10 01:46:38 Valid Error = 0.47630619684083 
2016-12-10 01:46:38 Valid Loss = 0.023435440211627 
2016-12-10 01:46:40 Test Error = 0.52401746724891 
2016-12-10 01:46:40 Test Loss = 0.027416414111268 
2016-12-10 01:46:40 -------------------LR------------------- 
2016-12-10 01:46:40 0.00390625 
2016-12-10 01:46:40 Epoch 112 
2016-12-10 01:48:07 Training Error = 0.41757796678817 
2016-12-10 01:48:07 Training Loss = 0.022657421595754 
2016-12-10 01:48:09 Valid Error = 0.47995139732685 
2016-12-10 01:48:09 Valid Loss = 0.023432877361633 
2016-12-10 01:48:11 Test Error = 0.51855895196507 
2016-12-10 01:48:11 Test Loss = 0.026939868132273 
2016-12-10 01:48:11 -------------------LR------------------- 
2016-12-10 01:48:11 0.00390625 
2016-12-10 01:48:11 Epoch 113 
2016-12-10 01:49:35 Training Error = 0.41987309302012 
2016-12-10 01:49:35 Training Loss = 0.022845290003615 
2016-12-10 01:49:37 Valid Error = 0.56014580801944 
2016-12-10 01:49:37 Valid Loss = 0.025440203836609 
2016-12-10 01:49:39 Test Error = 0.61353711790393 
2016-12-10 01:49:39 Test Loss = 0.029226288917018 
2016-12-10 01:49:39 -------------------LR------------------- 
2016-12-10 01:49:39 0.00390625 
2016-12-10 01:49:39 Epoch 114 
2016-12-10 01:51:04 Training Error = 0.41609288510868 
2016-12-10 01:51:04 Training Loss = 0.022619128856784 
2016-12-10 01:51:06 Valid Error = 0.54678007290401 
2016-12-10 01:51:06 Valid Loss = 0.025218784845021 
2016-12-10 01:51:08 Test Error = 0.60152838427948 
2016-12-10 01:51:08 Test Loss = 0.029413549825257 
2016-12-10 01:51:08 -------------------LR------------------- 
2016-12-10 01:51:08 0.00390625 
2016-12-10 01:51:08 Epoch 115 
2016-12-10 01:52:36 Training Error = 0.42000810044552 
2016-12-10 01:52:36 Training Loss = 0.022661358474461 
2016-12-10 01:52:38 Valid Error = 0.48481166464156 
2016-12-10 01:52:38 Valid Loss = 0.023175934306191 
2016-12-10 01:52:40 Test Error = 0.52620087336245 
2016-12-10 01:52:40 Test Loss = 0.026734590829587 
2016-12-10 01:52:40 -------------------LR------------------- 
2016-12-10 01:52:40 0.00390625 
2016-12-10 01:52:40 Epoch 116 
2016-12-10 01:54:03 Training Error = 0.42000810044552 
2016-12-10 01:54:03 Training Loss = 0.022601215481513 
2016-12-10 01:54:05 Valid Error = 0.46901579586877 
2016-12-10 01:54:05 Valid Loss = 0.023784602205783 
2016-12-10 01:54:07 Test Error = 0.50764192139738 
2016-12-10 01:54:07 Test Loss = 0.027645975608452 
2016-12-10 01:54:07 -------------------LR------------------- 
2016-12-10 01:54:07 0.00390625 
2016-12-10 01:54:07 Epoch 117 
2016-12-10 01:55:30 Training Error = 0.42095315242338 
2016-12-10 01:55:30 Training Loss = 0.022593215214349 
2016-12-10 01:55:32 Valid Error = 0.47144592952612 
2016-12-10 01:55:32 Valid Loss = 0.023086366732034 
2016-12-10 01:55:34 Test Error = 0.51637554585153 
2016-12-10 01:55:34 Test Loss = 0.026838236528284 
2016-12-10 01:55:34 -------------------LR------------------- 
2016-12-10 01:55:34 0.00390625 
2016-12-10 01:55:34 Epoch 118 
2016-12-10 01:57:20 Training Error = 0.42324827865533 
2016-12-10 01:57:20 Training Loss = 0.022669736203604 
2016-12-10 01:57:22 Valid Error = 0.49574726609964 
2016-12-10 01:57:22 Valid Loss = 0.0231679475688 
2016-12-10 01:57:24 Test Error = 0.53930131004367 
2016-12-10 01:57:24 Test Loss = 0.026696428813186 
2016-12-10 01:57:24 -------------------LR------------------- 
2016-12-10 01:57:24 0.00390625 
2016-12-10 01:57:24 Epoch 119 
2016-12-10 01:59:08 Training Error = 0.41879303361685 
2016-12-10 01:59:08 Training Loss = 0.022618236414235 
2016-12-10 01:59:10 Valid Error = 0.45686512758202 
2016-12-10 01:59:10 Valid Loss = 0.023052223395633 
2016-12-10 01:59:12 Test Error = 0.50873362445415 
2016-12-10 01:59:12 Test Loss = 0.02680894278545 
2016-12-10 01:59:12 -------------------LR------------------- 
2016-12-10 01:59:12 0.00390625 
2016-12-10 01:59:12 Epoch 120 
2016-12-10 02:00:58 Training Error = 0.42392331578237 
2016-12-10 02:00:58 Training Loss = 0.02282923065385 
2016-12-10 02:01:00 Valid Error = 0.50546780072904 
2016-12-10 02:01:00 Valid Loss = 0.022955007261316 
2016-12-10 02:01:02 Test Error = 0.54803493449782 
2016-12-10 02:01:02 Test Loss = 0.026775078941794 
2016-12-10 02:01:02 -------------------LR------------------- 
2016-12-10 02:01:02 0.00390625 
2016-12-10 02:01:02 Epoch 121 
2016-12-10 02:02:41 Training Error = 0.41919805589307 
2016-12-10 02:02:41 Training Loss = 0.022903052156735 
2016-12-10 02:02:43 Valid Error = 0.52976913730255 
2016-12-10 02:02:43 Valid Loss = 0.024778804072627 
2016-12-10 02:02:45 Test Error = 0.59497816593886 
2016-12-10 02:02:45 Test Loss = 0.028760753874685 
2016-12-10 02:02:45 -------------------LR------------------- 
2016-12-10 02:02:45 0.00390625 
2016-12-10 02:02:45 Epoch 122 
2016-12-10 02:04:23 Training Error = 0.4228432563791 
2016-12-10 02:04:23 Training Loss = 0.022789859994698 
2016-12-10 02:04:25 Valid Error = 0.4726609963548 
2016-12-10 02:04:25 Valid Loss = 0.022936542746221 
2016-12-10 02:04:27 Test Error = 0.51855895196507 
2016-12-10 02:04:27 Test Loss = 0.026581702241711 
2016-12-10 02:04:27 -------------------LR------------------- 
2016-12-10 02:04:27 0.00390625 
2016-12-10 02:04:27 Epoch 123 
2016-12-10 02:06:02 Training Error = 0.42203321182665 
2016-12-10 02:06:02 Training Loss = 0.0228693331023 
2016-12-10 02:06:04 Valid Error = 0.45686512758202 
2016-12-10 02:06:04 Valid Loss = 0.023827400052142 
2016-12-10 02:06:06 Test Error = 0.50873362445415 
2016-12-10 02:06:06 Test Loss = 0.027745415491216 
2016-12-10 02:06:06 -------------------LR------------------- 
2016-12-10 02:06:06 0.00390625 
2016-12-10 02:06:06 Epoch 124 
2016-12-10 02:07:39 Training Error = 0.41973808559471 
2016-12-10 02:07:39 Training Loss = 0.022799969039333 
2016-12-10 02:07:40 Valid Error = 0.54434993924666 
2016-12-10 02:07:40 Valid Loss = 0.025368010988964 
2016-12-10 02:07:42 Test Error = 0.60698689956332 
2016-12-10 02:07:42 Test Loss = 0.029217048832014 
2016-12-10 02:07:42 -------------------LR------------------- 
2016-12-10 02:07:42 0.00390625 
2016-12-10 02:07:42 Epoch 125 
2016-12-10 02:09:15 Training Error = 0.4179829890644 
2016-12-10 02:09:15 Training Loss = 0.022584023141727 
2016-12-10 02:09:17 Valid Error = 0.47995139732685 
2016-12-10 02:09:17 Valid Loss = 0.024007898865295 
2016-12-10 02:09:19 Test Error = 0.5207423580786 
2016-12-10 02:09:19 Test Loss = 0.027853770527185 
2016-12-10 02:09:19 -------------------LR------------------- 
2016-12-10 02:09:19 0.00390625 
2016-12-10 02:09:19 Epoch 126 
2016-12-10 02:10:49 Training Error = 0.41865802619144 
2016-12-10 02:10:49 Training Loss = 0.022682170587962 
2016-12-10 02:10:51 Valid Error = 0.48481166464156 
2016-12-10 02:10:51 Valid Loss = 0.022861339333858 
2016-12-10 02:10:53 Test Error = 0.52620087336245 
2016-12-10 02:10:53 Test Loss = 0.026681780805775 
2016-12-10 02:10:53 -------------------LR------------------- 
2016-12-10 02:10:53 0.00390625 
2016-12-10 02:10:53 Epoch 127 
