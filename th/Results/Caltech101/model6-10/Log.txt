2016-12-09 22:47:38 [program started on Fri Dec  9 22:47:38 2016] 
2016-12-09 22:47:38 [command line arguments] 
2016-12-09 22:47:38 stcWeights false 
2016-12-09 22:47:38 LR 0.015625 
2016-12-09 22:47:38 batchSize 100 
2016-12-09 22:47:38 network ./Models/Cifar10_Custom 
2016-12-09 22:47:38 stcNeurons true 
2016-12-09 22:47:38 constBatchSize false 
2016-12-09 22:47:38 chartFileName chart1 
2016-12-09 22:47:38 dp_prepro false 
2016-12-09 22:47:38 nGPU 1 
2016-12-09 22:47:38 dataset Caltech101 
2016-12-09 22:47:38 type cuda 
2016-12-09 22:47:38 momentum 0 
2016-12-09 22:47:38 threads 8 
2016-12-09 22:47:38 weightDecay 0 
2016-12-09 22:47:38 runningVal false 
2016-12-09 22:47:38 convLayerN 6 
2016-12-09 22:47:38 LRDecay 0 
2016-12-09 22:47:38 numHid 1024 
2016-12-09 22:47:38 save /dev/shm/clone/temp/th/Results/Caltech101/model6-10 
2016-12-09 22:47:38 augment false 
2016-12-09 22:47:38 epoch -1 
2016-12-09 22:47:38 modelsFolder ./Models/ 
2016-12-09 22:47:38 format rgb 
2016-12-09 22:47:38 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-09 22:47:38 imageFileExtension svg 
2016-12-09 22:47:38 channel 1 
2016-12-09 22:47:38 devid 7 
2016-12-09 22:47:38 visualize 1 
2016-12-09 22:47:38 LRDecayPerEpoch 0.0001 
2016-12-09 22:47:38 optimization adam 
2016-12-09 22:47:38 SBN true 
2016-12-09 22:47:38 normalization simple 
2016-12-09 22:47:38 title model1 
2016-12-09 22:47:38 load  
2016-12-09 22:47:38 whiten true 
2016-12-09 22:47:38 [----------------------] 
2016-12-09 22:47:39 ==> Network 
2016-12-09 22:47:39 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 102)
  (38): nn.BatchNormalization
} 
2016-12-09 22:47:39 ==>14128050 Parameters 
2016-12-09 22:47:39 ==> Loss 
2016-12-09 22:47:39 SqrtHingeEmbeddingCriterion 
2016-12-09 22:47:39 
==> Starting Training
 
2016-12-09 22:47:39 Epoch 1 
2016-12-09 22:48:40 Training Error = 0.77683272579992 
2016-12-09 22:48:40 Training Loss = 0.39516092944461 
2016-12-09 22:48:42 Valid Error = 0.72053462940462 
2016-12-09 22:48:42 Valid Loss = 0.067004407684132 
2016-12-09 22:48:44 Test Error = 0.75 
2016-12-09 22:48:44 Test Loss = 0.06808595532062 
2016-12-09 22:48:44 -------------------LR------------------- 
2016-12-09 22:48:44 0.015625 
2016-12-09 22:48:44 Epoch 2 
2016-12-09 22:49:43 Training Error = 0.62589442419333 
2016-12-09 22:49:43 Training Loss = 0.039291570483581 
2016-12-09 22:49:45 Valid Error = 0.7314702308627 
2016-12-09 22:49:45 Valid Loss = 0.034711135108328 
2016-12-09 22:49:47 Test Error = 0.76091703056769 
2016-12-09 22:49:47 Test Loss = 0.036402577400208 
2016-12-09 22:49:47 -------------------LR------------------- 
2016-12-09 22:49:47 0.015625 
2016-12-09 22:49:47 Epoch 3 
2016-12-09 22:50:48 Training Error = 0.63048467665722 
2016-12-09 22:50:48 Training Loss = 0.030254272708839 
2016-12-09 22:50:50 Valid Error = 0.71324422843256 
2016-12-09 22:50:50 Valid Loss = 0.030425456550138 
2016-12-09 22:50:52 Test Error = 0.74781659388646 
2016-12-09 22:50:52 Test Loss = 0.032580676406038 
2016-12-09 22:50:52 -------------------LR------------------- 
2016-12-09 22:50:52 0.015625 
2016-12-09 22:50:52 Epoch 4 
2016-12-09 22:52:04 Training Error = 0.60253813959768 
2016-12-09 22:52:04 Training Loss = 0.0281237016124 
2016-12-09 22:52:05 Valid Error = 0.70595382746051 
2016-12-09 22:52:05 Valid Loss = 0.02924491549166 
2016-12-09 22:52:07 Test Error = 0.74344978165939 
2016-12-09 22:52:07 Test Loss = 0.031239062262516 
2016-12-09 22:52:07 -------------------LR------------------- 
2016-12-09 22:52:07 0.015625 
2016-12-09 22:52:07 Epoch 5 
2016-12-09 22:53:11 Training Error = 0.57472660996355 
2016-12-09 22:53:11 Training Loss = 0.026852196580333 
2016-12-09 22:53:13 Valid Error = 0.75455650060753 
2016-12-09 22:53:13 Valid Loss = 0.030594152017131 
2016-12-09 22:53:15 Test Error = 0.79803493449782 
2016-12-09 22:53:15 Test Loss = 0.032818934767854 
2016-12-09 22:53:15 -------------------LR------------------- 
2016-12-09 22:53:15 0.015625 
2016-12-09 22:53:15 Epoch 6 
2016-12-09 22:54:17 Training Error = 0.5691913055218 
2016-12-09 22:54:17 Training Loss = 0.026739094408108 
2016-12-09 22:54:18 Valid Error = 0.73754556500608 
2016-12-09 22:54:18 Valid Loss = 0.030896308648154 
2016-12-09 22:54:20 Test Error = 0.77620087336245 
2016-12-09 22:54:20 Test Loss = 0.032498640266119 
2016-12-09 22:54:20 -------------------LR------------------- 
2016-12-09 22:54:20 0.015625 
2016-12-09 22:54:20 Epoch 7 
2016-12-09 22:55:24 Training Error = 0.54124476846227 
2016-12-09 22:55:24 Training Loss = 0.025336325449369 
2016-12-09 22:55:26 Valid Error = 0.56379100850547 
2016-12-09 22:55:26 Valid Loss = 0.027301688881278 
2016-12-09 22:55:28 Test Error = 0.61244541484716 
2016-12-09 22:55:28 Test Loss = 0.030186206032248 
2016-12-09 22:55:28 -------------------LR------------------- 
2016-12-09 22:55:28 0.015625 
2016-12-09 22:55:28 Epoch 8 
2016-12-09 22:56:45 Training Error = 0.52031861752396 
2016-12-09 22:56:45 Training Loss = 0.0248103068561 
2016-12-09 22:56:47 Valid Error = 0.73390036452005 
2016-12-09 22:56:47 Valid Loss = 0.034539934429152 
2016-12-09 22:56:49 Test Error = 0.7674672489083 
2016-12-09 22:56:49 Test Loss = 0.037942510679656 
2016-12-09 22:56:49 -------------------LR------------------- 
2016-12-09 22:56:49 0.015625 
2016-12-09 22:56:49 Epoch 9 
2016-12-09 22:57:56 Training Error = 0.49642230322668 
2016-12-09 22:57:56 Training Loss = 0.024105146356435 
2016-12-09 22:57:58 Valid Error = 0.52126366950182 
2016-12-09 22:57:58 Valid Loss = 0.024619083012484 
2016-12-09 22:58:00 Test Error = 0.56331877729258 
2016-12-09 22:58:00 Test Loss = 0.027318014874178 
2016-12-09 22:58:00 -------------------LR------------------- 
2016-12-09 22:58:00 0.015625 
2016-12-09 22:58:00 Epoch 10 
2016-12-09 22:59:09 Training Error = 0.45375995679762 
2016-12-09 22:59:09 Training Loss = 0.02355332654709 
2016-12-09 22:59:11 Valid Error = 0.46294046172539 
2016-12-09 22:59:11 Valid Loss = 0.022953610833513 
2016-12-09 22:59:13 Test Error = 0.50764192139738 
2016-12-09 22:59:13 Test Loss = 0.026583416920082 
2016-12-09 22:59:13 -------------------LR------------------- 
2016-12-09 22:59:13 0.015625 
2016-12-09 22:59:13 Epoch 11 
2016-12-09 23:00:29 Training Error = 0.41946807074389 
2016-12-09 23:00:29 Training Loss = 0.022649501048995 
2016-12-09 23:00:31 Valid Error = 0.49331713244228 
2016-12-09 23:00:31 Valid Loss = 0.02309994577876 
2016-12-09 23:00:33 Test Error = 0.53056768558952 
2016-12-09 23:00:33 Test Loss = 0.026774518667483 
2016-12-09 23:00:33 -------------------LR------------------- 
2016-12-09 23:00:33 0.015625 
2016-12-09 23:00:33 Epoch 12 
2016-12-09 23:01:43 Training Error = 0.42081814499797 
2016-12-09 23:01:43 Training Loss = 0.022576052954751 
2016-12-09 23:01:45 Valid Error = 0.47995139732685 
2016-12-09 23:01:45 Valid Loss = 0.023023677449047 
2016-12-09 23:01:47 Test Error = 0.51855895196507 
2016-12-09 23:01:47 Test Loss = 0.026720732333613 
2016-12-09 23:01:47 -------------------LR------------------- 
2016-12-09 23:01:47 0.015625 
2016-12-09 23:01:47 Epoch 13 
2016-12-09 23:03:09 Training Error = 0.42108815984879 
2016-12-09 23:03:09 Training Loss = 0.022585682017151 
2016-12-09 23:03:11 Valid Error = 0.47995139732685 
2016-12-09 23:03:11 Valid Loss = 0.022814367983934 
2016-12-09 23:03:13 Test Error = 0.51855895196507 
2016-12-09 23:03:13 Test Loss = 0.026623770704456 
2016-12-09 23:03:13 -------------------LR------------------- 
2016-12-09 23:03:13 0.015625 
2016-12-09 23:03:13 Epoch 14 
2016-12-09 23:04:42 Training Error = 0.41973808559471 
2016-12-09 23:04:42 Training Loss = 0.022637105965637 
2016-12-09 23:04:43 Valid Error = 0.47387606318348 
2016-12-09 23:04:43 Valid Loss = 0.024541002522706 
2016-12-09 23:04:45 Test Error = 0.51528384279476 
2016-12-09 23:04:45 Test Loss = 0.028595339943381 
2016-12-09 23:04:45 -------------------LR------------------- 
2016-12-09 23:04:45 0.015625 
2016-12-09 23:04:45 Epoch 15 
2016-12-09 23:05:57 Training Error = 0.42203321182665 
2016-12-09 23:05:57 Training Loss = 0.022757352287228 
2016-12-09 23:05:59 Valid Error = 0.52855407047388 
2016-12-09 23:05:59 Valid Loss = 0.024725810791085 
2016-12-09 23:06:01 Test Error = 0.5938864628821 
2016-12-09 23:06:01 Test Loss = 0.02864284511641 
2016-12-09 23:06:01 -------------------LR------------------- 
2016-12-09 23:06:01 0.015625 
2016-12-09 23:06:01 Epoch 16 
2016-12-09 23:07:12 Training Error = 0.42716349399217 
2016-12-09 23:07:12 Training Loss = 0.022799660283221 
2016-12-09 23:07:14 Valid Error = 0.47144592952612 
2016-12-09 23:07:14 Valid Loss = 0.023155323067228 
2016-12-09 23:07:16 Test Error = 0.51637554585153 
2016-12-09 23:07:16 Test Loss = 0.026925156172584 
2016-12-09 23:07:16 -------------------LR------------------- 
2016-12-09 23:07:16 0.015625 
2016-12-09 23:07:16 Epoch 17 
2016-12-09 23:08:33 Training Error = 0.42230322667747 
2016-12-09 23:08:33 Training Loss = 0.022815291708725 
2016-12-09 23:08:35 Valid Error = 0.54313487241798 
2016-12-09 23:08:35 Valid Loss = 0.024843180147753 
2016-12-09 23:08:37 Test Error = 0.60698689956332 
2016-12-09 23:08:37 Test Loss = 0.028709756037768 
2016-12-09 23:08:37 -------------------LR------------------- 
2016-12-09 23:08:37 0.015625 
2016-12-09 23:08:37 Epoch 18 
2016-12-09 23:10:19 Training Error = 0.42135817469961 
2016-12-09 23:10:19 Training Loss = 0.022739328309245 
2016-12-09 23:10:20 Valid Error = 0.48602673147023 
2016-12-09 23:10:20 Valid Loss = 0.0228403036362 
2016-12-09 23:10:22 Test Error = 0.53056768558952 
2016-12-09 23:10:22 Test Loss = 0.026330310447543 
2016-12-09 23:10:22 -------------------LR------------------- 
2016-12-09 23:10:22 0.015625 
2016-12-09 23:10:22 Epoch 19 
2016-12-09 23:12:09 Training Error = 0.42432833805859 
2016-12-09 23:12:09 Training Loss = 0.02257823574376 
2016-12-09 23:12:11 Valid Error = 0.47995139732685 
2016-12-09 23:12:11 Valid Loss = 0.023599390519708 
2016-12-09 23:12:13 Test Error = 0.5207423580786 
2016-12-09 23:12:13 Test Loss = 0.027441202874277 
2016-12-09 23:12:13 -------------------LR------------------- 
2016-12-09 23:12:13 0.015625 
2016-12-09 23:12:13 Epoch 20 
2016-12-09 23:13:51 Training Error = 0.41703793708654 
2016-12-09 23:13:51 Training Loss = 0.022726624976976 
2016-12-09 23:13:53 Valid Error = 0.50668286755772 
2016-12-09 23:13:53 Valid Loss = 0.022904015472693 
2016-12-09 23:13:55 Test Error = 0.55021834061135 
2016-12-09 23:13:55 Test Loss = 0.026572004103193 
2016-12-09 23:13:55 -------------------LR------------------- 
2016-12-09 23:13:55 0.015625 
2016-12-09 23:13:55 Epoch 21 
2016-12-09 23:15:35 Training Error = 0.42311327122992 
2016-12-09 23:15:35 Training Loss = 0.022667164064723 
2016-12-09 23:15:37 Valid Error = 0.47387606318348 
2016-12-09 23:15:37 Valid Loss = 0.024178987593207 
2016-12-09 23:15:39 Test Error = 0.51528384279476 
2016-12-09 23:15:39 Test Loss = 0.027851074545991 
2016-12-09 23:15:39 -------------------LR------------------- 
2016-12-09 23:15:39 0.015625 
2016-12-09 23:15:39 Epoch 22 
2016-12-09 23:17:19 Training Error = 0.42027811529634 
2016-12-09 23:17:19 Training Loss = 0.022760190582988 
2016-12-09 23:17:21 Valid Error = 0.47144592952612 
2016-12-09 23:17:21 Valid Loss = 0.022866403742858 
2016-12-09 23:17:23 Test Error = 0.51637554585153 
2016-12-09 23:17:23 Test Loss = 0.026672389666239 
2016-12-09 23:17:23 -------------------LR------------------- 
2016-12-09 23:17:23 0.015625 
2016-12-09 23:17:23 Epoch 23 
2016-12-09 23:19:09 Training Error = 0.42216821925206 
2016-12-09 23:19:09 Training Loss = 0.022901662307583 
2016-12-09 23:19:10 Valid Error = 0.46901579586877 
2016-12-09 23:19:10 Valid Loss = 0.024265412170462 
2016-12-09 23:19:12 Test Error = 0.50764192139738 
2016-12-09 23:19:12 Test Loss = 0.028005297324237 
2016-12-09 23:19:12 -------------------LR------------------- 
2016-12-09 23:19:12 0.015625 
2016-12-09 23:19:12 Epoch 24 
2016-12-09 23:20:55 Training Error = 0.42365330093155 
2016-12-09 23:20:55 Training Loss = 0.022923999180157 
2016-12-09 23:20:57 Valid Error = 0.48845686512758 
2016-12-09 23:20:57 Valid Loss = 0.022871406369446 
2016-12-09 23:20:59 Test Error = 0.52292576419214 
2016-12-09 23:20:59 Test Loss = 0.026557202152177 
2016-12-09 23:20:59 -------------------LR------------------- 
2016-12-09 23:20:59 0.015625 
2016-12-09 23:20:59 Epoch 25 
2016-12-09 23:22:42 Training Error = 0.41825300391522 
2016-12-09 23:22:42 Training Loss = 0.022575242533537 
2016-12-09 23:22:44 Valid Error = 0.47630619684083 
2016-12-09 23:22:44 Valid Loss = 0.023447893617324 
2016-12-09 23:22:46 Test Error = 0.52183406113537 
2016-12-09 23:22:46 Test Loss = 0.027336048107521 
2016-12-09 23:22:46 -------------------LR------------------- 
2016-12-09 23:22:46 0.015625 
2016-12-09 23:22:46 Epoch 26 
2016-12-09 23:24:28 Training Error = 0.42351829350614 
2016-12-09 23:24:28 Training Loss = 0.02283407844807 
2016-12-09 23:24:30 Valid Error = 0.48845686512758 
2016-12-09 23:24:30 Valid Loss = 0.023397740296052 
2016-12-09 23:24:32 Test Error = 0.52292576419214 
2016-12-09 23:24:32 Test Loss = 0.027226190941007 
2016-12-09 23:24:32 -------------------LR------------------- 
2016-12-09 23:24:32 0.015625 
2016-12-09 23:24:32 Epoch 27 
2016-12-09 23:26:11 Training Error = 0.42176319697583 
2016-12-09 23:26:11 Training Loss = 0.022581937419133 
2016-12-09 23:26:12 Valid Error = 0.47387606318348 
2016-12-09 23:26:12 Valid Loss = 0.023846985098877 
2016-12-09 23:26:14 Test Error = 0.51528384279476 
2016-12-09 23:26:14 Test Loss = 0.027636529043609 
2016-12-09 23:26:14 -------------------LR------------------- 
2016-12-09 23:26:14 0.015625 
2016-12-09 23:26:14 Epoch 28 
2016-12-09 23:27:59 Training Error = 0.41865802619144 
2016-12-09 23:27:59 Training Loss = 0.022856338039366 
2016-12-09 23:28:01 Valid Error = 0.51883353584447 
2016-12-09 23:28:01 Valid Loss = 0.024353804729693 
2016-12-09 23:28:03 Test Error = 0.57860262008734 
2016-12-09 23:28:03 Test Loss = 0.028051463912515 
2016-12-09 23:28:03 -------------------LR------------------- 
2016-12-09 23:28:03 0.015625 
2016-12-09 23:28:03 Epoch 29 
2016-12-09 23:29:43 Training Error = 0.41784798163899 
2016-12-09 23:29:43 Training Loss = 0.022640047456971 
2016-12-09 23:29:45 Valid Error = 0.4775212636695 
2016-12-09 23:29:45 Valid Loss = 0.023083418166535 
2016-12-09 23:29:47 Test Error = 0.52838427947598 
2016-12-09 23:29:47 Test Loss = 0.026954305368311 
2016-12-09 23:29:47 -------------------LR------------------- 
2016-12-09 23:29:47 0.015625 
2016-12-09 23:29:47 Epoch 30 
2016-12-09 23:31:34 Training Error = 0.4212231672742 
2016-12-09 23:31:34 Training Loss = 0.022639410625497 
2016-12-09 23:31:36 Valid Error = 0.46051032806804 
2016-12-09 23:31:36 Valid Loss = 0.023795189596864 
2016-12-09 23:31:38 Test Error = 0.50545851528384 
2016-12-09 23:31:38 Test Loss = 0.027571910035376 
2016-12-09 23:31:38 -------------------LR------------------- 
2016-12-09 23:31:38 0.015625 
2016-12-09 23:31:38 Epoch 31 
2016-12-09 23:33:20 Training Error = 0.42108815984879 
2016-12-09 23:33:20 Training Loss = 0.022929195485974 
2016-12-09 23:33:22 Valid Error = 0.47387606318348 
2016-12-09 23:33:22 Valid Loss = 0.02397810729015 
2016-12-09 23:33:24 Test Error = 0.51528384279476 
2016-12-09 23:33:24 Test Loss = 0.027877638433494 
2016-12-09 23:33:24 -------------------LR------------------- 
2016-12-09 23:33:24 0.015625 
2016-12-09 23:33:24 Epoch 32 
2016-12-09 23:35:04 Training Error = 0.41757796678817 
2016-12-09 23:35:04 Training Loss = 0.022526724954101 
2016-12-09 23:35:06 Valid Error = 0.47387606318348 
2016-12-09 23:35:06 Valid Loss = 0.023986514981208 
2016-12-09 23:35:08 Test Error = 0.5174672489083 
2016-12-09 23:35:08 Test Loss = 0.027820058719785 
2016-12-09 23:35:08 -------------------LR------------------- 
2016-12-09 23:35:08 0.015625 
2016-12-09 23:35:08 Epoch 33 
2016-12-09 23:36:52 Training Error = 0.4179829890644 
2016-12-09 23:36:52 Training Loss = 0.022801866319444 
2016-12-09 23:36:54 Valid Error = 0.47387606318348 
2016-12-09 23:36:54 Valid Loss = 0.022845913329743 
2016-12-09 23:36:56 Test Error = 0.53165938864629 
2016-12-09 23:36:56 Test Loss = 0.026584430199043 
2016-12-09 23:36:56 -------------------LR------------------- 
2016-12-09 23:36:56 0.015625 
2016-12-09 23:36:56 Epoch 34 
2016-12-09 23:38:36 Training Error = 0.42230322667747 
2016-12-09 23:38:36 Training Loss = 0.022763484751811 
2016-12-09 23:38:38 Valid Error = 0.50182260024301 
2016-12-09 23:38:38 Valid Loss = 0.023130988948237 
2016-12-09 23:38:40 Test Error = 0.55131004366812 
2016-12-09 23:38:40 Test Loss = 0.027017348083795 
2016-12-09 23:38:40 -------------------LR------------------- 
2016-12-09 23:38:40 0.015625 
2016-12-09 23:38:40 Epoch 35 
2016-12-09 23:40:22 Training Error = 0.41946807074389 
2016-12-09 23:40:22 Training Loss = 0.022657192562898 
2016-12-09 23:40:24 Valid Error = 0.56136087484812 
2016-12-09 23:40:24 Valid Loss = 0.025321690012946 
2016-12-09 23:40:26 Test Error = 0.61353711790393 
2016-12-09 23:40:26 Test Loss = 0.029380591551463 
2016-12-09 23:40:26 -------------------LR------------------- 
2016-12-09 23:40:26 0.015625 
2016-12-09 23:40:26 Epoch 36 
2016-12-09 23:42:07 Training Error = 0.41825300391522 
2016-12-09 23:42:07 Training Loss = 0.022805021958124 
2016-12-09 23:42:09 Valid Error = 0.4678007290401 
2016-12-09 23:42:09 Valid Loss = 0.023741980058808 
2016-12-09 23:42:11 Test Error = 0.50655021834061 
2016-12-09 23:42:11 Test Loss = 0.027493687882143 
2016-12-09 23:42:11 -------------------LR------------------- 
2016-12-09 23:42:11 0.015625 
2016-12-09 23:42:11 Epoch 37 
2016-12-09 23:43:53 Training Error = 0.41933306331848 
2016-12-09 23:43:53 Training Loss = 0.02268687968962 
2016-12-09 23:43:55 Valid Error = 0.49331713244228 
2016-12-09 23:43:55 Valid Loss = 0.023360158868435 
2016-12-09 23:43:57 Test Error = 0.54912663755459 
2016-12-09 23:43:57 Test Loss = 0.026919473246032 
2016-12-09 23:43:57 -------------------LR------------------- 
2016-12-09 23:43:57 0.015625 
2016-12-09 23:43:57 Epoch 38 
2016-12-09 23:45:38 Training Error = 0.4212231672742 
2016-12-09 23:45:38 Training Loss = 0.022827280483727 
2016-12-09 23:45:39 Valid Error = 0.54070473876063 
2016-12-09 23:45:39 Valid Loss = 0.02511875158008 
2016-12-09 23:45:41 Test Error = 0.60262008733624 
2016-12-09 23:45:41 Test Loss = 0.029025598376405 
2016-12-09 23:45:41 -------------------LR------------------- 
2016-12-09 23:45:41 0.015625 
2016-12-09 23:45:41 Epoch 39 
2016-12-09 23:47:24 Training Error = 0.42176319697583 
2016-12-09 23:47:24 Training Loss = 0.022754341765189 
2016-12-09 23:47:26 Valid Error = 0.48481166464156 
2016-12-09 23:47:26 Valid Loss = 0.023407754416582 
2016-12-09 23:47:28 Test Error = 0.52620087336245 
2016-12-09 23:47:28 Test Loss = 0.026961587700189 
2016-12-09 23:47:28 -------------------LR------------------- 
2016-12-09 23:47:28 0.015625 
2016-12-09 23:47:28 Epoch 40 
2016-12-09 23:49:14 Training Error = 0.41987309302012 
2016-12-09 23:49:14 Training Loss = 0.022643458528634 
2016-12-09 23:49:16 Valid Error = 0.47509113001215 
2016-12-09 23:49:16 Valid Loss = 0.02405393429368 
2016-12-09 23:49:18 Test Error = 0.50764192139738 
2016-12-09 23:49:18 Test Loss = 0.027934364038355 
2016-12-09 23:49:18 -------------------LR------------------- 
2016-12-09 23:49:18 0.015625 
2016-12-09 23:49:18 Epoch 41 
2016-12-09 23:50:59 Training Error = 0.41987309302012 
2016-12-09 23:50:59 Training Loss = 0.022557825983584 
2016-12-09 23:51:01 Valid Error = 0.45321992709599 
2016-12-09 23:51:01 Valid Loss = 0.024322158533074 
2016-12-09 23:51:02 Test Error = 0.50218340611354 
2016-12-09 23:51:02 Test Loss = 0.028111406765732 
2016-12-09 23:51:02 -------------------LR------------------- 
2016-12-09 23:51:02 0.015625 
2016-12-09 23:51:02 Epoch 42 
2016-12-09 23:52:41 Training Error = 0.4179829890644 
2016-12-09 23:52:41 Training Loss = 0.022675948387167 
2016-12-09 23:52:43 Valid Error = 0.47630619684083 
2016-12-09 23:52:43 Valid Loss = 0.023811606294878 
2016-12-09 23:52:45 Test Error = 0.52183406113537 
2016-12-09 23:52:45 Test Loss = 0.027832419021457 
2016-12-09 23:52:45 -------------------LR------------------- 
2016-12-09 23:52:45 0.015625 
2016-12-09 23:52:45 Epoch 43 
2016-12-09 23:54:25 Training Error = 0.42405832320778 
2016-12-09 23:54:25 Training Loss = 0.022783829017447 
2016-12-09 23:54:26 Valid Error = 0.4775212636695 
2016-12-09 23:54:26 Valid Loss = 0.024038781031205 
2016-12-09 23:54:28 Test Error = 0.51200873362445 
2016-12-09 23:54:28 Test Loss = 0.028002005633186 
2016-12-09 23:54:28 -------------------LR------------------- 
2016-12-09 23:54:28 0.015625 
2016-12-09 23:54:28 Epoch 44 
2016-12-09 23:56:25 Training Error = 0.42216821925206 
2016-12-09 23:56:25 Training Loss = 0.022744874736597 
2016-12-09 23:56:27 Valid Error = 0.47144592952612 
2016-12-09 23:56:27 Valid Loss = 0.02492414035275 
2016-12-09 23:56:29 Test Error = 0.51637554585153 
2016-12-09 23:56:29 Test Loss = 0.029152238995421 
2016-12-09 23:56:29 -------------------LR------------------- 
2016-12-09 23:56:29 0.015625 
2016-12-09 23:56:29 Epoch 45 
2016-12-09 23:58:34 Training Error = 0.4196030781693 
2016-12-09 23:58:34 Training Loss = 0.02257219146814 
2016-12-09 23:58:36 Valid Error = 0.45808019441069 
2016-12-09 23:58:36 Valid Loss = 0.023192679436017 
2016-12-09 23:58:38 Test Error = 0.50436681222707 
2016-12-09 23:58:38 Test Loss = 0.027020729457631 
2016-12-09 23:58:38 -------------------LR------------------- 
2016-12-09 23:58:38 0.015625 
2016-12-09 23:58:38 Epoch 46 
2016-12-10 00:00:34 Training Error = 0.4196030781693 
2016-12-10 00:00:34 Training Loss = 0.022639694232389 
2016-12-10 00:00:36 Valid Error = 0.49939246658566 
2016-12-10 00:00:36 Valid Loss = 0.022688654684327 
2016-12-10 00:00:38 Test Error = 0.54257641921397 
2016-12-10 00:00:38 Test Loss = 0.0262437526011 
2016-12-10 00:00:38 -------------------LR------------------- 
2016-12-10 00:00:38 0.015625 
2016-12-10 00:00:38 Epoch 47 
2016-12-10 00:02:26 Training Error = 0.42054813014716 
2016-12-10 00:02:26 Training Loss = 0.022835982370243 
2016-12-10 00:02:28 Valid Error = 0.49696233292831 
2016-12-10 00:02:28 Valid Loss = 0.023303339015899 
2016-12-10 00:02:30 Test Error = 0.54585152838428 
2016-12-10 00:02:30 Test Loss = 0.026941237487045 
2016-12-10 00:02:30 -------------------LR------------------- 
2016-12-10 00:02:30 0.015625 
2016-12-10 00:02:30 Epoch 48 
2016-12-10 00:04:14 Training Error = 0.42176319697583 
2016-12-10 00:04:14 Training Loss = 0.022905452428367 
2016-12-10 00:04:16 Valid Error = 0.49696233292831 
2016-12-10 00:04:16 Valid Loss = 0.022832436510545 
2016-12-10 00:04:18 Test Error = 0.54366812227074 
2016-12-10 00:04:18 Test Loss = 0.026633340209138 
2016-12-10 00:04:18 -------------------LR------------------- 
2016-12-10 00:04:18 0.015625 
2016-12-10 00:04:18 Epoch 49 
2016-12-10 00:06:02 Training Error = 0.42162818955043 
2016-12-10 00:06:02 Training Loss = 0.022783336507617 
2016-12-10 00:06:04 Valid Error = 0.4775212636695 
2016-12-10 00:06:04 Valid Loss = 0.02316072744572 
2016-12-10 00:06:06 Test Error = 0.52838427947598 
2016-12-10 00:06:06 Test Loss = 0.026851247329338 
2016-12-10 00:06:06 -------------------LR------------------- 
2016-12-10 00:06:06 0.015625 
2016-12-10 00:06:06 Epoch 50 
2016-12-10 00:07:47 Training Error = 0.42351829350614 
2016-12-10 00:07:47 Training Loss = 0.022663032924962 
2016-12-10 00:07:49 Valid Error = 0.47387606318348 
2016-12-10 00:07:49 Valid Loss = 0.024347768344357 
2016-12-10 00:07:51 Test Error = 0.51528384279476 
2016-12-10 00:07:51 Test Loss = 0.028400180994296 
2016-12-10 00:07:51 -------------------LR------------------- 
2016-12-10 00:07:51 0.0078125 
2016-12-10 00:07:51 Epoch 51 
2016-12-10 00:09:30 Training Error = 0.4196030781693 
2016-12-10 00:09:30 Training Loss = 0.022749828523125 
2016-12-10 00:09:32 Valid Error = 0.54556500607533 
2016-12-10 00:09:32 Valid Loss = 0.02494440190571 
2016-12-10 00:09:34 Test Error = 0.60043668122271 
2016-12-10 00:09:34 Test Loss = 0.028826423336478 
2016-12-10 00:09:34 -------------------LR------------------- 
2016-12-10 00:09:34 0.0078125 
2016-12-10 00:09:34 Epoch 52 
2016-12-10 00:11:14 Training Error = 0.42041312272175 
2016-12-10 00:11:14 Training Loss = 0.022713438025153 
2016-12-10 00:11:15 Valid Error = 0.47630619684083 
2016-12-10 00:11:15 Valid Loss = 0.02281824695688 
2016-12-10 00:11:17 Test Error = 0.51310043668122 
2016-12-10 00:11:17 Test Loss = 0.026610844004388 
2016-12-10 00:11:17 -------------------LR------------------- 
2016-12-10 00:11:17 0.0078125 
2016-12-10 00:11:17 Epoch 53 
2016-12-10 00:12:53 Training Error = 0.42068313757257 
2016-12-10 00:12:53 Training Loss = 0.022912785139894 
2016-12-10 00:12:55 Valid Error = 0.45929526123937 
2016-12-10 00:12:55 Valid Loss = 0.024204170333286 
2016-12-10 00:12:57 Test Error = 0.50436681222707 
2016-12-10 00:12:57 Test Loss = 0.027974433870877 
2016-12-10 00:12:57 -------------------LR------------------- 
2016-12-10 00:12:57 0.0078125 
2016-12-10 00:12:57 Epoch 54 
2016-12-10 00:14:33 Training Error = 0.424463345484 
2016-12-10 00:14:33 Training Loss = 0.022849720526231 
2016-12-10 00:14:35 Valid Error = 0.55285540704739 
2016-12-10 00:14:35 Valid Loss = 0.024884989815159 
2016-12-10 00:14:37 Test Error = 0.61135371179039 
2016-12-10 00:14:37 Test Loss = 0.028648066660937 
2016-12-10 00:14:37 -------------------LR------------------- 
2016-12-10 00:14:37 0.0078125 
2016-12-10 00:14:37 Epoch 55 
2016-12-10 00:16:15 Training Error = 0.42108815984879 
2016-12-10 00:16:15 Training Loss = 0.022777840643704 
2016-12-10 00:16:17 Valid Error = 0.47995139732685 
2016-12-10 00:16:17 Valid Loss = 0.023189933685074 
2016-12-10 00:16:19 Test Error = 0.51855895196507 
2016-12-10 00:16:19 Test Loss = 0.026807302923763 
2016-12-10 00:16:19 -------------------LR------------------- 
2016-12-10 00:16:19 0.0078125 
2016-12-10 00:16:19 Epoch 56 
2016-12-10 00:17:56 Training Error = 0.42297826380451 
2016-12-10 00:17:56 Training Loss = 0.022809542087302 
2016-12-10 00:17:58 Valid Error = 0.48481166464156 
2016-12-10 00:17:58 Valid Loss = 0.023799444731409 
2016-12-10 00:18:00 Test Error = 0.52620087336245 
2016-12-10 00:18:00 Test Loss = 0.0273400312592 
2016-12-10 00:18:00 -------------------LR------------------- 
2016-12-10 00:18:00 0.0078125 
2016-12-10 00:18:00 Epoch 57 
2016-12-10 00:19:35 Training Error = 0.41973808559471 
2016-12-10 00:19:35 Training Loss = 0.022721202017591 
2016-12-10 00:19:37 Valid Error = 0.45929526123937 
2016-12-10 00:19:37 Valid Loss = 0.024034614479879 
2016-12-10 00:19:39 Test Error = 0.50218340611354 
2016-12-10 00:19:39 Test Loss = 0.028105431790445 
2016-12-10 00:19:39 -------------------LR------------------- 
2016-12-10 00:19:39 0.0078125 
2016-12-10 00:19:39 Epoch 58 
2016-12-10 00:21:14 Training Error = 0.42405832320778 
2016-12-10 00:21:14 Training Loss = 0.022770005994952 
2016-12-10 00:21:16 Valid Error = 0.46658566221142 
2016-12-10 00:21:16 Valid Loss = 0.023437983473221 
2016-12-10 00:21:18 Test Error = 0.50873362445415 
2016-12-10 00:21:18 Test Loss = 0.027013954031701 
2016-12-10 00:21:18 -------------------LR------------------- 
2016-12-10 00:21:18 0.0078125 
2016-12-10 00:21:18 Epoch 59 
2016-12-10 00:22:51 Training Error = 0.42014310787093 
2016-12-10 00:22:51 Training Loss = 0.022732022650369 
2016-12-10 00:22:53 Valid Error = 0.50182260024301 
2016-12-10 00:22:53 Valid Loss = 0.023033671103114 
2016-12-10 00:22:55 Test Error = 0.55131004366812 
2016-12-10 00:22:55 Test Loss = 0.026920080615025 
2016-12-10 00:22:55 -------------------LR------------------- 
2016-12-10 00:22:55 0.0078125 
2016-12-10 00:22:55 Epoch 60 
2016-12-10 00:24:38 Training Error = 0.42743350884299 
2016-12-10 00:24:38 Training Loss = 0.022733624840317 
2016-12-10 00:24:40 Valid Error = 0.46294046172539 
2016-12-10 00:24:40 Valid Loss = 0.023507771861929 
2016-12-10 00:24:42 Test Error = 0.51200873362445 
2016-12-10 00:24:42 Test Loss = 0.027357046613506 
2016-12-10 00:24:42 -------------------LR------------------- 
2016-12-10 00:24:42 0.0078125 
2016-12-10 00:24:42 Epoch 61 
2016-12-10 00:26:21 Training Error = 0.42081814499797 
2016-12-10 00:26:21 Training Loss = 0.022683271033023 
2016-12-10 00:26:23 Valid Error = 0.46537059538275 
2016-12-10 00:26:23 Valid Loss = 0.024172362862092 
2016-12-10 00:26:25 Test Error = 0.51310043668122 
2016-12-10 00:26:25 Test Loss = 0.028072543854807 
2016-12-10 00:26:25 -------------------LR------------------- 
2016-12-10 00:26:25 0.0078125 
2016-12-10 00:26:25 Epoch 62 
2016-12-10 00:28:02 Training Error = 0.42203321182665 
2016-12-10 00:28:02 Training Loss = 0.022869426470132 
2016-12-10 00:28:03 Valid Error = 0.47995139732685 
2016-12-10 00:28:03 Valid Loss = 0.022757491060896 
2016-12-10 00:28:05 Test Error = 0.51855895196507 
2016-12-10 00:28:05 Test Loss = 0.026467834996242 
2016-12-10 00:28:05 -------------------LR------------------- 
2016-12-10 00:28:05 0.0078125 
2016-12-10 00:28:05 Epoch 63 
2016-12-10 00:29:45 Training Error = 0.41946807074389 
2016-12-10 00:29:45 Training Loss = 0.022691580318447 
2016-12-10 00:29:46 Valid Error = 0.47630619684083 
2016-12-10 00:29:46 Valid Loss = 0.022721188935387 
2016-12-10 00:29:48 Test Error = 0.52401746724891 
2016-12-10 00:29:48 Test Loss = 0.026261571940254 
2016-12-10 00:29:48 -------------------LR------------------- 
2016-12-10 00:29:48 0.0078125 
2016-12-10 00:29:48 Epoch 64 
2016-12-10 00:31:25 Training Error = 0.42635344943972 
2016-12-10 00:31:25 Training Loss = 0.022645618305509 
2016-12-10 00:31:27 Valid Error = 0.47387606318348 
2016-12-10 00:31:27 Valid Loss = 0.023632930832581 
2016-12-10 00:31:29 Test Error = 0.5174672489083 
2016-12-10 00:31:29 Test Loss = 0.027381226735957 
2016-12-10 00:31:29 -------------------LR------------------- 
2016-12-10 00:31:29 0.0078125 
2016-12-10 00:31:29 Epoch 65 
2016-12-10 00:33:05 Training Error = 0.42365330093155 
2016-12-10 00:33:05 Training Loss = 0.022649830718624 
2016-12-10 00:33:07 Valid Error = 0.47387606318348 
2016-12-10 00:33:07 Valid Loss = 0.023177818189214 
2016-12-10 00:33:09 Test Error = 0.5174672489083 
2016-12-10 00:33:09 Test Loss = 0.026882793688307 
2016-12-10 00:33:09 -------------------LR------------------- 
2016-12-10 00:33:09 0.0078125 
2016-12-10 00:33:09 Epoch 66 
2016-12-10 00:34:48 Training Error = 0.42149318212502 
2016-12-10 00:34:48 Training Loss = 0.022745480181412 
2016-12-10 00:34:49 Valid Error = 0.48724179829891 
2016-12-10 00:34:49 Valid Loss = 0.022795187359429 
2016-12-10 00:34:51 Test Error = 0.53275109170306 
2016-12-10 00:34:51 Test Loss = 0.026401175246519 
2016-12-10 00:34:51 -------------------LR------------------- 
2016-12-10 00:34:51 0.0078125 
2016-12-10 00:34:51 Epoch 67 
2016-12-10 00:36:27 Training Error = 0.41717294451195 
2016-12-10 00:36:27 Training Loss = 0.022634231064455 
2016-12-10 00:36:29 Valid Error = 0.4823815309842 
2016-12-10 00:36:29 Valid Loss = 0.024026780969956 
2016-12-10 00:36:31 Test Error = 0.51965065502183 
2016-12-10 00:36:31 Test Loss = 0.027836209745968 
2016-12-10 00:36:31 -------------------LR------------------- 
2016-12-10 00:36:31 0.0078125 
2016-12-10 00:36:31 Epoch 68 
2016-12-10 00:38:09 Training Error = 0.41744295936276 
2016-12-10 00:38:09 Training Loss = 0.022655571022354 
2016-12-10 00:38:11 Valid Error = 0.48481166464156 
2016-12-10 00:38:11 Valid Loss = 0.023194043375478 
2016-12-10 00:38:13 Test Error = 0.52620087336245 
2016-12-10 00:38:13 Test Loss = 0.026948938799839 
2016-12-10 00:38:13 -------------------LR------------------- 
2016-12-10 00:38:13 0.0078125 
2016-12-10 00:38:13 Epoch 69 
2016-12-10 00:39:47 Training Error = 0.41879303361685 
2016-12-10 00:39:47 Training Loss = 0.02284762249545 
2016-12-10 00:39:48 Valid Error = 0.48724179829891 
2016-12-10 00:39:48 Valid Loss = 0.022705634419661 
2016-12-10 00:39:50 Test Error = 0.53275109170306 
2016-12-10 00:39:50 Test Loss = 0.026360075249391 
2016-12-10 00:39:50 -------------------LR------------------- 
2016-12-10 00:39:50 0.0078125 
2016-12-10 00:39:50 Epoch 70 
2016-12-10 00:41:32 Training Error = 0.42054813014716 
2016-12-10 00:41:32 Training Loss = 0.022669374320977 
2016-12-10 00:41:34 Valid Error = 0.48481166464156 
2016-12-10 00:41:34 Valid Loss = 0.022825618554914 
2016-12-10 00:41:36 Test Error = 0.54475982532751 
2016-12-10 00:41:36 Test Loss = 0.026688681443532 
2016-12-10 00:41:36 -------------------LR------------------- 
2016-12-10 00:41:36 0.0078125 
2016-12-10 00:41:36 Epoch 71 
2016-12-10 00:43:16 Training Error = 0.42230322667747 
2016-12-10 00:43:16 Training Loss = 0.022695918725563 
2016-12-10 00:43:17 Valid Error = 0.45929526123937 
2016-12-10 00:43:17 Valid Loss = 0.024105076783984 
2016-12-10 00:43:19 Test Error = 0.50436681222707 
2016-12-10 00:43:19 Test Loss = 0.028233329950594 
2016-12-10 00:43:19 -------------------LR------------------- 
2016-12-10 00:43:19 0.0078125 
2016-12-10 00:43:19 Epoch 72 
2016-12-10 00:44:58 Training Error = 0.42135817469961 
2016-12-10 00:44:58 Training Loss = 0.022851588853111 
2016-12-10 00:45:00 Valid Error = 0.48724179829891 
2016-12-10 00:45:00 Valid Loss = 0.022887926986071 
2016-12-10 00:45:02 Test Error = 0.52620087336245 
2016-12-10 00:45:02 Test Loss = 0.026645794784322 
2016-12-10 00:45:02 -------------------LR------------------- 
2016-12-10 00:45:02 0.0078125 
2016-12-10 00:45:02 Epoch 73 
2016-12-10 00:46:40 Training Error = 0.41838801134062 
2016-12-10 00:46:40 Training Loss = 0.022576086712151 
2016-12-10 00:46:42 Valid Error = 0.45929526123937 
2016-12-10 00:46:42 Valid Loss = 0.023813692927417 
2016-12-10 00:46:44 Test Error = 0.51419213973799 
2016-12-10 00:46:44 Test Loss = 0.027580130165698 
2016-12-10 00:46:44 -------------------LR------------------- 
2016-12-10 00:46:44 0.0078125 
2016-12-10 00:46:44 Epoch 74 
2016-12-10 00:48:22 Training Error = 0.42365330093155 
2016-12-10 00:48:22 Training Loss = 0.022862181012949 
2016-12-10 00:48:24 Valid Error = 0.45929526123937 
2016-12-10 00:48:24 Valid Loss = 0.023812769020531 
2016-12-10 00:48:26 Test Error = 0.50218340611354 
2016-12-10 00:48:26 Test Loss = 0.027630861534792 
2016-12-10 00:48:26 -------------------LR------------------- 
2016-12-10 00:48:26 0.0078125 
2016-12-10 00:48:26 Epoch 75 
2016-12-10 00:50:00 Training Error = 0.42135817469961 
2016-12-10 00:50:00 Training Loss = 0.022635435061272 
2016-12-10 00:50:02 Valid Error = 0.47144592952612 
2016-12-10 00:50:02 Valid Loss = 0.022976303205375 
2016-12-10 00:50:04 Test Error = 0.51637554585153 
2016-12-10 00:50:04 Test Loss = 0.026730439672283 
2016-12-10 00:50:04 -------------------LR------------------- 
2016-12-10 00:50:04 0.0078125 
2016-12-10 00:50:04 Epoch 76 
2016-12-10 00:51:42 Training Error = 0.41771297421358 
2016-12-10 00:51:42 Training Loss = 0.022569449903985 
2016-12-10 00:51:44 Valid Error = 0.47995139732685 
2016-12-10 00:51:44 Valid Loss = 0.02453424478126 
2016-12-10 00:51:46 Test Error = 0.51855895196507 
2016-12-10 00:51:46 Test Loss = 0.028524122864592 
2016-12-10 00:51:46 -------------------LR------------------- 
2016-12-10 00:51:46 0.0078125 
2016-12-10 00:51:46 Epoch 77 
2016-12-10 00:53:21 Training Error = 0.42500337518564 
2016-12-10 00:53:21 Training Loss = 0.022649919275164 
2016-12-10 00:53:23 Valid Error = 0.47630619684083 
2016-12-10 00:53:23 Valid Loss = 0.024373621736906 
2016-12-10 00:53:25 Test Error = 0.5207423580786 
2016-12-10 00:53:25 Test Loss = 0.028266178561192 
2016-12-10 00:53:25 -------------------LR------------------- 
2016-12-10 00:53:25 0.0078125 
2016-12-10 00:53:25 Epoch 78 
2016-12-10 00:55:03 Training Error = 0.41973808559471 
2016-12-10 00:55:03 Training Loss = 0.022796553189147 
2016-12-10 00:55:05 Valid Error = 0.46537059538275 
2016-12-10 00:55:05 Valid Loss = 0.02409005586697 
2016-12-10 00:55:07 Test Error = 0.51310043668122 
2016-12-10 00:55:07 Test Loss = 0.027971550128039 
2016-12-10 00:55:07 -------------------LR------------------- 
2016-12-10 00:55:07 0.0078125 
2016-12-10 00:55:07 Epoch 79 
2016-12-10 00:56:44 Training Error = 0.41703793708654 
2016-12-10 00:56:44 Training Loss = 0.022623798235725 
2016-12-10 00:56:46 Valid Error = 0.47630619684083 
2016-12-10 00:56:46 Valid Loss = 0.022959669871437 
2016-12-10 00:56:48 Test Error = 0.51310043668122 
2016-12-10 00:56:48 Test Loss = 0.026715050762775 
2016-12-10 00:56:48 -------------------LR------------------- 
2016-12-10 00:56:48 0.0078125 
2016-12-10 00:56:48 Epoch 80 
2016-12-10 00:58:31 Training Error = 0.42270824895369 
2016-12-10 00:58:31 Training Loss = 0.022709475445859 
2016-12-10 00:58:32 Valid Error = 0.47995139732685 
2016-12-10 00:58:32 Valid Loss = 0.023901173095761 
2016-12-10 00:58:34 Test Error = 0.51855895196507 
2016-12-10 00:58:34 Test Loss = 0.027495020772897 
2016-12-10 00:58:34 -------------------LR------------------- 
2016-12-10 00:58:34 0.0078125 
2016-12-10 00:58:34 Epoch 81 
2016-12-10 01:00:12 Training Error = 0.41406777372755 
2016-12-10 01:00:12 Training Loss = 0.022614930303379 
2016-12-10 01:00:13 Valid Error = 0.46901579586877 
2016-12-10 01:00:13 Valid Loss = 0.024711439814364 
2016-12-10 01:00:15 Test Error = 0.50764192139738 
2016-12-10 01:00:15 Test Loss = 0.028780470670438 
2016-12-10 01:00:15 -------------------LR------------------- 
2016-12-10 01:00:15 0.0078125 
2016-12-10 01:00:15 Epoch 82 
2016-12-10 01:01:48 Training Error = 0.42459835290941 
2016-12-10 01:01:48 Training Loss = 0.022787034843438 
2016-12-10 01:01:50 Valid Error = 0.46537059538275 
2016-12-10 01:01:50 Valid Loss = 0.023824276712296 
2016-12-10 01:01:52 Test Error = 0.51310043668122 
2016-12-10 01:01:52 Test Loss = 0.027574220545152 
2016-12-10 01:01:52 -------------------LR------------------- 
2016-12-10 01:01:52 0.0078125 
2016-12-10 01:01:52 Epoch 83 
2016-12-10 01:03:30 Training Error = 0.41757796678817 
2016-12-10 01:03:30 Training Loss = 0.022679159916327 
2016-12-10 01:03:32 Valid Error = 0.50182260024301 
2016-12-10 01:03:32 Valid Loss = 0.022949177683377 
2016-12-10 01:03:34 Test Error = 0.53930131004367 
2016-12-10 01:03:34 Test Loss = 0.026691136902454 
2016-12-10 01:03:34 -------------------LR------------------- 
2016-12-10 01:03:34 0.0078125 
2016-12-10 01:03:34 Epoch 84 
2016-12-10 01:05:01 Training Error = 0.41906304846767 
2016-12-10 01:05:01 Training Loss = 0.022750253065093 
2016-12-10 01:05:03 Valid Error = 0.46537059538275 
2016-12-10 01:05:03 Valid Loss = 0.02398678965242 
2016-12-10 01:05:05 Test Error = 0.51310043668122 
2016-12-10 01:05:05 Test Loss = 0.02764705360637 
2016-12-10 01:05:05 -------------------LR------------------- 
2016-12-10 01:05:05 0.0078125 
2016-12-10 01:05:05 Epoch 85 
2016-12-10 01:06:31 Training Error = 0.42014310787093 
2016-12-10 01:06:31 Training Loss = 0.022601876967828 
2016-12-10 01:06:33 Valid Error = 0.47144592952612 
2016-12-10 01:06:33 Valid Loss = 0.023948375285999 
2016-12-10 01:06:35 Test Error = 0.51419213973799 
2016-12-10 01:06:35 Test Loss = 0.027900595926771 
2016-12-10 01:06:35 -------------------LR------------------- 
2016-12-10 01:06:35 0.0078125 
2016-12-10 01:06:35 Epoch 86 
2016-12-10 01:08:00 Training Error = 0.42189820440124 
2016-12-10 01:08:00 Training Loss = 0.022712987873779 
2016-12-10 01:08:02 Valid Error = 0.48845686512758 
2016-12-10 01:08:02 Valid Loss = 0.023107482441856 
2016-12-10 01:08:04 Test Error = 0.52292576419214 
2016-12-10 01:08:04 Test Loss = 0.026932018495074 
2016-12-10 01:08:04 -------------------LR------------------- 
2016-12-10 01:08:04 0.0078125 
2016-12-10 01:08:04 Epoch 87 
2016-12-10 01:09:33 Training Error = 0.42311327122992 
2016-12-10 01:09:33 Training Loss = 0.022776751414067 
2016-12-10 01:09:35 Valid Error = 0.47995139732685 
2016-12-10 01:09:35 Valid Loss = 0.023565620501136 
2016-12-10 01:09:37 Test Error = 0.51855895196507 
2016-12-10 01:09:37 Test Loss = 0.027472770111234 
2016-12-10 01:09:37 -------------------LR------------------- 
2016-12-10 01:09:37 0.0078125 
2016-12-10 01:09:37 Epoch 88 
2016-12-10 01:11:03 Training Error = 0.41730795193736 
2016-12-10 01:11:03 Training Loss = 0.0225270415063 
2016-12-10 01:11:05 Valid Error = 0.4823815309842 
2016-12-10 01:11:05 Valid Loss = 0.0230373491983 
2016-12-10 01:11:07 Test Error = 0.52401746724891 
2016-12-10 01:11:07 Test Loss = 0.026763514500038 
2016-12-10 01:11:07 -------------------LR------------------- 
2016-12-10 01:11:07 0.0078125 
2016-12-10 01:11:07 Epoch 89 
2016-12-10 01:12:35 Training Error = 0.42095315242338 
2016-12-10 01:12:35 Training Loss = 0.022794788516603 
2016-12-10 01:12:37 Valid Error = 0.47630619684083 
2016-12-10 01:12:37 Valid Loss = 0.02376493486681 
2016-12-10 01:12:39 Test Error = 0.52401746724891 
2016-12-10 01:12:39 Test Loss = 0.02761526332182 
2016-12-10 01:12:39 -------------------LR------------------- 
2016-12-10 01:12:39 0.0078125 
2016-12-10 01:12:39 Epoch 90 
2016-12-10 01:14:13 Training Error = 0.41919805589307 
2016-12-10 01:14:13 Training Loss = 0.022665635286504 
2016-12-10 01:14:14 Valid Error = 0.46537059538275 
2016-12-10 01:14:14 Valid Loss = 0.02363875621533 
2016-12-10 01:14:16 Test Error = 0.51310043668122 
2016-12-10 01:14:16 Test Loss = 0.027452275734322 
2016-12-10 01:14:16 -------------------LR------------------- 
2016-12-10 01:14:16 0.0078125 
2016-12-10 01:14:16 Epoch 91 
2016-12-10 01:15:45 Training Error = 0.42149318212502 
2016-12-10 01:15:45 Training Loss = 0.022772721519435 
2016-12-10 01:15:47 Valid Error = 0.47995139732685 
2016-12-10 01:15:47 Valid Loss = 0.022682020496868 
2016-12-10 01:15:49 Test Error = 0.51855895196507 
2016-12-10 01:15:49 Test Loss = 0.026287094864191 
2016-12-10 01:15:49 -------------------LR------------------- 
2016-12-10 01:15:49 0.0078125 
2016-12-10 01:15:49 Epoch 92 
2016-12-10 01:17:17 Training Error = 0.42203321182665 
2016-12-10 01:17:17 Training Loss = 0.022646838093962 
2016-12-10 01:17:19 Valid Error = 0.48481166464156 
2016-12-10 01:17:19 Valid Loss = 0.023038438755623 
2016-12-10 01:17:21 Test Error = 0.52620087336245 
2016-12-10 01:17:21 Test Loss = 0.026641990035188 
2016-12-10 01:17:21 -------------------LR------------------- 
2016-12-10 01:17:21 0.0078125 
2016-12-10 01:17:21 Epoch 93 
2016-12-10 01:18:47 Training Error = 0.41933306331848 
2016-12-10 01:18:47 Training Loss = 0.022846072330706 
2016-12-10 01:18:49 Valid Error = 0.54313487241798 
2016-12-10 01:18:49 Valid Loss = 0.024753481442248 
2016-12-10 01:18:51 Test Error = 0.60698689956332 
2016-12-10 01:18:51 Test Loss = 0.028804343130074 
2016-12-10 01:18:51 -------------------LR------------------- 
2016-12-10 01:18:51 0.0078125 
2016-12-10 01:18:51 Epoch 94 
2016-12-10 01:20:19 Training Error = 0.41892804104226 
2016-12-10 01:20:19 Training Loss = 0.022597324503125 
2016-12-10 01:20:21 Valid Error = 0.47144592952612 
2016-12-10 01:20:21 Valid Loss = 0.023116887952496 
2016-12-10 01:20:23 Test Error = 0.51637554585153 
2016-12-10 01:20:23 Test Loss = 0.026767494061414 
2016-12-10 01:20:23 -------------------LR------------------- 
2016-12-10 01:20:23 0.0078125 
2016-12-10 01:20:23 Epoch 95 
2016-12-10 01:21:52 Training Error = 0.42162818955043 
2016-12-10 01:21:52 Training Loss = 0.022812720228065 
2016-12-10 01:21:54 Valid Error = 0.47387606318348 
2016-12-10 01:21:54 Valid Loss = 0.025005577075117 
2016-12-10 01:21:56 Test Error = 0.51528384279476 
2016-12-10 01:21:56 Test Loss = 0.028901088153615 
2016-12-10 01:21:56 -------------------LR------------------- 
2016-12-10 01:21:56 0.0078125 
2016-12-10 01:21:56 Epoch 96 
2016-12-10 01:23:20 Training Error = 0.41946807074389 
2016-12-10 01:23:20 Training Loss = 0.022570771803798 
2016-12-10 01:23:22 Valid Error = 0.47509113001215 
2016-12-10 01:23:22 Valid Loss = 0.02381053098892 
2016-12-10 01:23:24 Test Error = 0.51091703056769 
2016-12-10 01:23:24 Test Loss = 0.027685756197163 
2016-12-10 01:23:24 -------------------LR------------------- 
2016-12-10 01:23:24 0.0078125 
2016-12-10 01:23:24 Epoch 97 
2016-12-10 01:24:53 Training Error = 0.4212231672742 
2016-12-10 01:24:53 Training Loss = 0.022750504024445 
2016-12-10 01:24:55 Valid Error = 0.47387606318348 
2016-12-10 01:24:55 Valid Loss = 0.024531790222127 
2016-12-10 01:24:57 Test Error = 0.51528384279476 
2016-12-10 01:24:57 Test Loss = 0.028320880338257 
2016-12-10 01:24:57 -------------------LR------------------- 
2016-12-10 01:24:57 0.0078125 
2016-12-10 01:24:57 Epoch 98 
2016-12-10 01:26:24 Training Error = 0.4179829890644 
2016-12-10 01:26:24 Training Loss = 0.022786658207798 
2016-12-10 01:26:26 Valid Error = 0.55407047387606 
2016-12-10 01:26:26 Valid Loss = 0.024818985138561 
2016-12-10 01:26:28 Test Error = 0.6146288209607 
2016-12-10 01:26:28 Test Loss = 0.028757334821364 
2016-12-10 01:26:28 -------------------LR------------------- 
2016-12-10 01:26:28 0.0078125 
2016-12-10 01:26:28 Epoch 99 
2016-12-10 01:27:59 Training Error = 0.42041312272175 
2016-12-10 01:27:59 Training Loss = 0.022670559510018 
2016-12-10 01:28:01 Valid Error = 0.45929526123937 
2016-12-10 01:28:01 Valid Loss = 0.023619889142534 
2016-12-10 01:28:03 Test Error = 0.50436681222707 
2016-12-10 01:28:03 Test Loss = 0.027548393455206 
2016-12-10 01:28:03 -------------------LR------------------- 
2016-12-10 01:28:03 0.0078125 
2016-12-10 01:28:03 Epoch 100 
2016-12-10 01:29:34 Training Error = 0.42149318212502 
2016-12-10 01:29:34 Training Loss = 0.02264987647362 
2016-12-10 01:29:36 Valid Error = 0.47144592952612 
2016-12-10 01:29:36 Valid Loss = 0.022984375949609 
2016-12-10 01:29:38 Test Error = 0.50545851528384 
2016-12-10 01:29:38 Test Loss = 0.026575397902844 
2016-12-10 01:29:38 -------------------LR------------------- 
2016-12-10 01:29:38 0.00390625 
2016-12-10 01:29:38 Epoch 101 
2016-12-10 01:31:06 Training Error = 0.41865802619144 
2016-12-10 01:31:06 Training Loss = 0.02288008348481 
2016-12-10 01:31:08 Valid Error = 0.46537059538275 
2016-12-10 01:31:08 Valid Loss = 0.024029984527932 
2016-12-10 01:31:10 Test Error = 0.51310043668122 
2016-12-10 01:31:10 Test Loss = 0.027975481697157 
2016-12-10 01:31:10 -------------------LR------------------- 
2016-12-10 01:31:10 0.00390625 
2016-12-10 01:31:10 Epoch 102 
2016-12-10 01:32:53 Training Error = 0.42162818955043 
2016-12-10 01:32:53 Training Loss = 0.0226215663137 
2016-12-10 01:32:54 Valid Error = 0.54313487241798 
2016-12-10 01:32:54 Valid Loss = 0.024941409061248 
2016-12-10 01:32:56 Test Error = 0.60480349344978 
2016-12-10 01:32:56 Test Loss = 0.028988024029077 
2016-12-10 01:32:56 -------------------LR------------------- 
2016-12-10 01:32:56 0.00390625 
2016-12-10 01:32:56 Epoch 103 
2016-12-10 01:34:33 Training Error = 0.41811799648981 
2016-12-10 01:34:33 Training Loss = 0.022799440945608 
2016-12-10 01:34:35 Valid Error = 0.47144592952612 
2016-12-10 01:34:35 Valid Loss = 0.023165117231092 
2016-12-10 01:34:37 Test Error = 0.51419213973799 
2016-12-10 01:34:37 Test Loss = 0.026834498938392 
2016-12-10 01:34:37 -------------------LR------------------- 
2016-12-10 01:34:37 0.00390625 
2016-12-10 01:34:37 Epoch 104 
2016-12-10 01:36:05 Training Error = 0.41771297421358 
2016-12-10 01:36:05 Training Loss = 0.022793007766054 
2016-12-10 01:36:07 Valid Error = 0.48845686512758 
2016-12-10 01:36:07 Valid Loss = 0.023935209922722 
2016-12-10 01:36:09 Test Error = 0.52292576419214 
2016-12-10 01:36:09 Test Loss = 0.027701764910829 
2016-12-10 01:36:09 -------------------LR------------------- 
2016-12-10 01:36:09 0.00390625 
2016-12-10 01:36:09 Epoch 105 
2016-12-10 01:37:33 Training Error = 0.42041312272175 
2016-12-10 01:37:33 Training Loss = 0.022675224741589 
2016-12-10 01:37:35 Valid Error = 0.54313487241798 
2016-12-10 01:37:35 Valid Loss = 0.024724257305579 
2016-12-10 01:37:37 Test Error = 0.60698689956332 
2016-12-10 01:37:37 Test Loss = 0.028608304210738 
2016-12-10 01:37:37 -------------------LR------------------- 
2016-12-10 01:37:37 0.00390625 
2016-12-10 01:37:37 Epoch 106 
2016-12-10 01:39:03 Training Error = 0.42243823410288 
2016-12-10 01:39:03 Training Loss = 0.022718018156563 
2016-12-10 01:39:05 Valid Error = 0.47630619684083 
2016-12-10 01:39:05 Valid Loss = 0.023315242688923 
2016-12-10 01:39:07 Test Error = 0.52401746724891 
2016-12-10 01:39:07 Test Loss = 0.027054963429769 
2016-12-10 01:39:07 -------------------LR------------------- 
2016-12-10 01:39:07 0.00390625 
2016-12-10 01:39:07 Epoch 107 
2016-12-10 01:40:28 Training Error = 0.41973808559471 
2016-12-10 01:40:28 Training Loss = 0.022787346669828 
2016-12-10 01:40:30 Valid Error = 0.50303766707169 
2016-12-10 01:40:30 Valid Loss = 0.023762148363613 
2016-12-10 01:40:32 Test Error = 0.54475982532751 
2016-12-10 01:40:32 Test Loss = 0.027441765476676 
2016-12-10 01:40:32 -------------------LR------------------- 
2016-12-10 01:40:32 0.00390625 
2016-12-10 01:40:32 Epoch 108 
2016-12-10 01:42:02 Training Error = 0.41879303361685 
2016-12-10 01:42:02 Training Loss = 0.022717614163382 
2016-12-10 01:42:03 Valid Error = 0.48116646415553 
2016-12-10 01:42:03 Valid Loss = 0.023099127015438 
2016-12-10 01:42:05 Test Error = 0.5207423580786 
2016-12-10 01:42:05 Test Loss = 0.026619643641453 
2016-12-10 01:42:05 -------------------LR------------------- 
2016-12-10 01:42:05 0.00390625 
2016-12-10 01:42:05 Epoch 109 
2016-12-10 01:43:30 Training Error = 0.41973808559471 
2016-12-10 01:43:30 Training Loss = 0.022742686889819 
2016-12-10 01:43:32 Valid Error = 0.47630619684083 
2016-12-10 01:43:32 Valid Loss = 0.022978092947726 
2016-12-10 01:43:34 Test Error = 0.52401746724891 
2016-12-10 01:43:34 Test Loss = 0.026829765749913 
2016-12-10 01:43:34 -------------------LR------------------- 
2016-12-10 01:43:34 0.00390625 
2016-12-10 01:43:34 Epoch 110 
2016-12-10 01:45:05 Training Error = 0.42230322667747 
2016-12-10 01:45:05 Training Loss = 0.022904364310014 
2016-12-10 01:45:06 Valid Error = 0.50668286755772 
2016-12-10 01:45:06 Valid Loss = 0.023280052986517 
2016-12-10 01:45:08 Test Error = 0.55021834061135 
2016-12-10 01:45:08 Test Loss = 0.027261422652824 
2016-12-10 01:45:08 -------------------LR------------------- 
2016-12-10 01:45:08 0.00390625 
2016-12-10 01:45:08 Epoch 111 
2016-12-10 01:46:36 Training Error = 0.42000810044552 
2016-12-10 01:46:36 Training Loss = 0.022613998655289 
2016-12-10 01:46:38 Valid Error = 0.47630619684083 
2016-12-10 01:46:38 Valid Loss = 0.023435440211627 
2016-12-10 01:46:40 Test Error = 0.52401746724891 
2016-12-10 01:46:40 Test Loss = 0.027416414111268 
2016-12-10 01:46:40 -------------------LR------------------- 
2016-12-10 01:46:40 0.00390625 
2016-12-10 01:46:40 Epoch 112 
2016-12-10 01:48:07 Training Error = 0.41757796678817 
2016-12-10 01:48:07 Training Loss = 0.022657421595754 
2016-12-10 01:48:09 Valid Error = 0.47995139732685 
2016-12-10 01:48:09 Valid Loss = 0.023432877361633 
2016-12-10 01:48:11 Test Error = 0.51855895196507 
2016-12-10 01:48:11 Test Loss = 0.026939868132273 
2016-12-10 01:48:11 -------------------LR------------------- 
2016-12-10 01:48:11 0.00390625 
2016-12-10 01:48:11 Epoch 113 
2016-12-10 01:49:35 Training Error = 0.41987309302012 
2016-12-10 01:49:35 Training Loss = 0.022845290003615 
2016-12-10 01:49:37 Valid Error = 0.56014580801944 
2016-12-10 01:49:37 Valid Loss = 0.025440203836609 
2016-12-10 01:49:39 Test Error = 0.61353711790393 
2016-12-10 01:49:39 Test Loss = 0.029226288917018 
2016-12-10 01:49:39 -------------------LR------------------- 
2016-12-10 01:49:39 0.00390625 
2016-12-10 01:49:39 Epoch 114 
2016-12-10 01:51:04 Training Error = 0.41609288510868 
2016-12-10 01:51:04 Training Loss = 0.022619128856784 
2016-12-10 01:51:06 Valid Error = 0.54678007290401 
2016-12-10 01:51:06 Valid Loss = 0.025218784845021 
2016-12-10 01:51:08 Test Error = 0.60152838427948 
2016-12-10 01:51:08 Test Loss = 0.029413549825257 
2016-12-10 01:51:08 -------------------LR------------------- 
2016-12-10 01:51:08 0.00390625 
2016-12-10 01:51:08 Epoch 115 
2016-12-10 01:52:36 Training Error = 0.42000810044552 
2016-12-10 01:52:36 Training Loss = 0.022661358474461 
2016-12-10 01:52:38 Valid Error = 0.48481166464156 
2016-12-10 01:52:38 Valid Loss = 0.023175934306191 
2016-12-10 01:52:40 Test Error = 0.52620087336245 
2016-12-10 01:52:40 Test Loss = 0.026734590829587 
2016-12-10 01:52:40 -------------------LR------------------- 
2016-12-10 01:52:40 0.00390625 
2016-12-10 01:52:40 Epoch 116 
2016-12-10 01:54:03 Training Error = 0.42000810044552 
2016-12-10 01:54:03 Training Loss = 0.022601215481513 
2016-12-10 01:54:05 Valid Error = 0.46901579586877 
2016-12-10 01:54:05 Valid Loss = 0.023784602205783 
2016-12-10 01:54:07 Test Error = 0.50764192139738 
2016-12-10 01:54:07 Test Loss = 0.027645975608452 
2016-12-10 01:54:07 -------------------LR------------------- 
2016-12-10 01:54:07 0.00390625 
2016-12-10 01:54:07 Epoch 117 
2016-12-10 01:55:30 Training Error = 0.42095315242338 
2016-12-10 01:55:30 Training Loss = 0.022593215214349 
2016-12-10 01:55:32 Valid Error = 0.47144592952612 
2016-12-10 01:55:32 Valid Loss = 0.023086366732034 
2016-12-10 01:55:34 Test Error = 0.51637554585153 
2016-12-10 01:55:34 Test Loss = 0.026838236528284 
2016-12-10 01:55:34 -------------------LR------------------- 
2016-12-10 01:55:34 0.00390625 
2016-12-10 01:55:34 Epoch 118 
2016-12-10 01:57:20 Training Error = 0.42324827865533 
2016-12-10 01:57:20 Training Loss = 0.022669736203604 
2016-12-10 01:57:22 Valid Error = 0.49574726609964 
2016-12-10 01:57:22 Valid Loss = 0.0231679475688 
2016-12-10 01:57:24 Test Error = 0.53930131004367 
2016-12-10 01:57:24 Test Loss = 0.026696428813186 
2016-12-10 01:57:24 -------------------LR------------------- 
2016-12-10 01:57:24 0.00390625 
2016-12-10 01:57:24 Epoch 119 
2016-12-10 01:59:08 Training Error = 0.41879303361685 
2016-12-10 01:59:08 Training Loss = 0.022618236414235 
2016-12-10 01:59:10 Valid Error = 0.45686512758202 
2016-12-10 01:59:10 Valid Loss = 0.023052223395633 
2016-12-10 01:59:12 Test Error = 0.50873362445415 
2016-12-10 01:59:12 Test Loss = 0.02680894278545 
2016-12-10 01:59:12 -------------------LR------------------- 
2016-12-10 01:59:12 0.00390625 
2016-12-10 01:59:12 Epoch 120 
2016-12-10 02:00:58 Training Error = 0.42392331578237 
2016-12-10 02:00:58 Training Loss = 0.02282923065385 
2016-12-10 02:01:00 Valid Error = 0.50546780072904 
2016-12-10 02:01:00 Valid Loss = 0.022955007261316 
2016-12-10 02:01:02 Test Error = 0.54803493449782 
2016-12-10 02:01:02 Test Loss = 0.026775078941794 
2016-12-10 02:01:02 -------------------LR------------------- 
2016-12-10 02:01:02 0.00390625 
2016-12-10 02:01:02 Epoch 121 
2016-12-10 02:02:41 Training Error = 0.41919805589307 
2016-12-10 02:02:41 Training Loss = 0.022903052156735 
2016-12-10 02:02:43 Valid Error = 0.52976913730255 
2016-12-10 02:02:43 Valid Loss = 0.024778804072627 
2016-12-10 02:02:45 Test Error = 0.59497816593886 
2016-12-10 02:02:45 Test Loss = 0.028760753874685 
2016-12-10 02:02:45 -------------------LR------------------- 
2016-12-10 02:02:45 0.00390625 
2016-12-10 02:02:45 Epoch 122 
2016-12-10 02:04:23 Training Error = 0.4228432563791 
2016-12-10 02:04:23 Training Loss = 0.022789859994698 
2016-12-10 02:04:25 Valid Error = 0.4726609963548 
2016-12-10 02:04:25 Valid Loss = 0.022936542746221 
2016-12-10 02:04:27 Test Error = 0.51855895196507 
2016-12-10 02:04:27 Test Loss = 0.026581702241711 
2016-12-10 02:04:27 -------------------LR------------------- 
2016-12-10 02:04:27 0.00390625 
2016-12-10 02:04:27 Epoch 123 
2016-12-10 02:06:02 Training Error = 0.42203321182665 
2016-12-10 02:06:02 Training Loss = 0.0228693331023 
2016-12-10 02:06:04 Valid Error = 0.45686512758202 
2016-12-10 02:06:04 Valid Loss = 0.023827400052142 
2016-12-10 02:06:06 Test Error = 0.50873362445415 
2016-12-10 02:06:06 Test Loss = 0.027745415491216 
2016-12-10 02:06:06 -------------------LR------------------- 
2016-12-10 02:06:06 0.00390625 
2016-12-10 02:06:06 Epoch 124 
2016-12-10 02:07:39 Training Error = 0.41973808559471 
2016-12-10 02:07:39 Training Loss = 0.022799969039333 
2016-12-10 02:07:40 Valid Error = 0.54434993924666 
2016-12-10 02:07:40 Valid Loss = 0.025368010988964 
2016-12-10 02:07:42 Test Error = 0.60698689956332 
2016-12-10 02:07:42 Test Loss = 0.029217048832014 
2016-12-10 02:07:42 -------------------LR------------------- 
2016-12-10 02:07:42 0.00390625 
2016-12-10 02:07:42 Epoch 125 
2016-12-10 02:09:15 Training Error = 0.4179829890644 
2016-12-10 02:09:15 Training Loss = 0.022584023141727 
2016-12-10 02:09:17 Valid Error = 0.47995139732685 
2016-12-10 02:09:17 Valid Loss = 0.024007898865295 
2016-12-10 02:09:19 Test Error = 0.5207423580786 
2016-12-10 02:09:19 Test Loss = 0.027853770527185 
2016-12-10 02:09:19 -------------------LR------------------- 
2016-12-10 02:09:19 0.00390625 
2016-12-10 02:09:19 Epoch 126 
2016-12-10 02:10:49 Training Error = 0.41865802619144 
2016-12-10 02:10:49 Training Loss = 0.022682170587962 
2016-12-10 02:10:51 Valid Error = 0.48481166464156 
2016-12-10 02:10:51 Valid Loss = 0.022861339333858 
2016-12-10 02:10:53 Test Error = 0.52620087336245 
2016-12-10 02:10:53 Test Loss = 0.026681780805775 
2016-12-10 02:10:53 -------------------LR------------------- 
2016-12-10 02:10:53 0.00390625 
2016-12-10 02:10:53 Epoch 127 
2016-12-10 02:12:24 Training Error = 0.42243823410288 
2016-12-10 02:12:24 Training Loss = 0.022577600976711 
2016-12-10 02:12:25 Valid Error = 0.56014580801944 
2016-12-10 02:12:25 Valid Loss = 0.025647607918794 
2016-12-10 02:12:27 Test Error = 0.61353711790393 
2016-12-10 02:12:27 Test Loss = 0.02970836314968 
2016-12-10 02:12:27 -------------------LR------------------- 
2016-12-10 02:12:27 0.00390625 
2016-12-10 02:12:27 Epoch 128 
2016-12-10 02:13:58 Training Error = 0.42054813014716 
2016-12-10 02:13:58 Training Loss = 0.022661990644239 
2016-12-10 02:14:00 Valid Error = 0.48845686512758 
2016-12-10 02:14:00 Valid Loss = 0.023152081951269 
2016-12-10 02:14:02 Test Error = 0.52292576419214 
2016-12-10 02:14:02 Test Loss = 0.026783799311694 
2016-12-10 02:14:02 -------------------LR------------------- 
2016-12-10 02:14:02 0.00390625 
2016-12-10 02:14:02 Epoch 129 
2016-12-10 02:15:32 Training Error = 0.42716349399217 
2016-12-10 02:15:32 Training Loss = 0.022760059244849 
2016-12-10 02:15:34 Valid Error = 0.47387606318348 
2016-12-10 02:15:34 Valid Loss = 0.022995006282684 
2016-12-10 02:15:36 Test Error = 0.50982532751092 
2016-12-10 02:15:36 Test Loss = 0.026538948395673 
2016-12-10 02:15:36 -------------------LR------------------- 
2016-12-10 02:15:36 0.00390625 
2016-12-10 02:15:36 Epoch 130 
2016-12-10 02:17:10 Training Error = 0.42216821925206 
2016-12-10 02:17:10 Training Loss = 0.022664030044798 
2016-12-10 02:17:12 Valid Error = 0.4823815309842 
2016-12-10 02:17:12 Valid Loss = 0.022893590194501 
2016-12-10 02:17:14 Test Error = 0.52510917030568 
2016-12-10 02:17:14 Test Loss = 0.026609575589498 
2016-12-10 02:17:14 -------------------LR------------------- 
2016-12-10 02:17:14 0.00390625 
2016-12-10 02:17:14 Epoch 131 
2016-12-10 02:18:46 Training Error = 0.41946807074389 
2016-12-10 02:18:46 Training Loss = 0.022751711385034 
2016-12-10 02:18:48 Valid Error = 0.53827460510328 
2016-12-10 02:18:48 Valid Loss = 0.025049550355559 
2016-12-10 02:18:50 Test Error = 0.59934497816594 
2016-12-10 02:18:50 Test Loss = 0.028962032738854 
2016-12-10 02:18:50 -------------------LR------------------- 
2016-12-10 02:18:50 0.00390625 
2016-12-10 02:18:50 Epoch 132 
2016-12-10 02:20:23 Training Error = 0.41730795193736 
2016-12-10 02:20:23 Training Loss = 0.022680430838107 
2016-12-10 02:20:25 Valid Error = 0.49331713244228 
2016-12-10 02:20:25 Valid Loss = 0.023227574698139 
2016-12-10 02:20:27 Test Error = 0.53711790393013 
2016-12-10 02:20:27 Test Loss = 0.027016340050043 
2016-12-10 02:20:27 -------------------LR------------------- 
2016-12-10 02:20:27 0.00390625 
2016-12-10 02:20:27 Epoch 133 
2016-12-10 02:21:59 Training Error = 0.42054813014716 
2016-12-10 02:21:59 Training Loss = 0.022600087329854 
2016-12-10 02:22:01 Valid Error = 0.48481166464156 
2016-12-10 02:22:01 Valid Loss = 0.022984896756781 
2016-12-10 02:22:03 Test Error = 0.52620087336245 
2016-12-10 02:22:03 Test Loss = 0.026696377763561 
2016-12-10 02:22:03 -------------------LR------------------- 
2016-12-10 02:22:03 0.00390625 
2016-12-10 02:22:03 Epoch 134 
2016-12-10 02:23:30 Training Error = 0.42513838261104 
2016-12-10 02:23:30 Training Loss = 0.022669101130239 
2016-12-10 02:23:32 Valid Error = 0.48481166464156 
2016-12-10 02:23:32 Valid Loss = 0.023532149313164 
2016-12-10 02:23:34 Test Error = 0.52620087336245 
2016-12-10 02:23:34 Test Loss = 0.027012072525772 
2016-12-10 02:23:34 -------------------LR------------------- 
2016-12-10 02:23:34 0.00390625 
2016-12-10 02:23:34 Epoch 135 
2016-12-10 02:25:05 Training Error = 0.42216821925206 
2016-12-10 02:25:05 Training Loss = 0.022850517545071 
2016-12-10 02:25:07 Valid Error = 0.55164034021871 
2016-12-10 02:25:07 Valid Loss = 0.025437225279646 
2016-12-10 02:25:09 Test Error = 0.60917030567686 
2016-12-10 02:25:09 Test Loss = 0.029566199499018 
2016-12-10 02:25:09 -------------------LR------------------- 
2016-12-10 02:25:09 0.00390625 
2016-12-10 02:25:09 Epoch 136 
2016-12-10 02:26:39 Training Error = 0.41717294451195 
2016-12-10 02:26:39 Training Loss = 0.02262745421024 
2016-12-10 02:26:41 Valid Error = 0.48481166464156 
2016-12-10 02:26:41 Valid Loss = 0.023008996570179 
2016-12-10 02:26:43 Test Error = 0.52620087336245 
2016-12-10 02:26:43 Test Loss = 0.02676310449488 
2016-12-10 02:26:43 -------------------LR------------------- 
2016-12-10 02:26:43 0.00390625 
2016-12-10 02:26:43 Epoch 137 
2016-12-10 02:28:14 Training Error = 0.41946807074389 
2016-12-10 02:28:14 Training Loss = 0.022670378131314 
2016-12-10 02:28:16 Valid Error = 0.47995139732685 
2016-12-10 02:28:16 Valid Loss = 0.023911491669386 
2016-12-10 02:28:18 Test Error = 0.5207423580786 
2016-12-10 02:28:18 Test Loss = 0.027983887345183 
2016-12-10 02:28:18 -------------------LR------------------- 
2016-12-10 02:28:18 0.00390625 
2016-12-10 02:28:18 Epoch 138 
2016-12-10 02:29:50 Training Error = 0.4260834345889 
2016-12-10 02:29:50 Training Loss = 0.022820344002062 
2016-12-10 02:29:51 Valid Error = 0.47995139732685 
2016-12-10 02:29:51 Valid Loss = 0.024518052665101 
2016-12-10 02:29:53 Test Error = 0.51855895196507 
2016-12-10 02:29:53 Test Loss = 0.028308071286071 
2016-12-10 02:29:53 -------------------LR------------------- 
2016-12-10 02:29:53 0.00390625 
2016-12-10 02:29:53 Epoch 139 
2016-12-10 02:31:26 Training Error = 0.42014310787093 
2016-12-10 02:31:26 Training Loss = 0.022746935449595 
2016-12-10 02:31:28 Valid Error = 0.55042527339004 
2016-12-10 02:31:28 Valid Loss = 0.025291840977049 
2016-12-10 02:31:30 Test Error = 0.5971615720524 
2016-12-10 02:31:30 Test Loss = 0.029214534572527 
2016-12-10 02:31:30 -------------------LR------------------- 
2016-12-10 02:31:30 0.00390625 
2016-12-10 02:31:30 Epoch 140 
2016-12-10 02:33:03 Training Error = 0.41811799648981 
2016-12-10 02:33:03 Training Loss = 0.022670301476914 
2016-12-10 02:33:05 Valid Error = 0.47144592952612 
2016-12-10 02:33:05 Valid Loss = 0.023993380214947 
2016-12-10 02:33:07 Test Error = 0.51637554585153 
2016-12-10 02:33:07 Test Loss = 0.027689694657045 
2016-12-10 02:33:07 -------------------LR------------------- 
2016-12-10 02:33:07 0.00390625 
2016-12-10 02:33:07 Epoch 141 
2016-12-10 02:34:36 Training Error = 0.42162818955043 
2016-12-10 02:34:36 Training Loss = 0.022636967026597 
2016-12-10 02:34:38 Valid Error = 0.47630619684083 
2016-12-10 02:34:38 Valid Loss = 0.02323451983564 
2016-12-10 02:34:40 Test Error = 0.52401746724891 
2016-12-10 02:34:40 Test Loss = 0.026820260739794 
2016-12-10 02:34:40 -------------------LR------------------- 
2016-12-10 02:34:40 0.00390625 
2016-12-10 02:34:40 Epoch 142 
2016-12-10 02:36:11 Training Error = 0.42108815984879 
2016-12-10 02:36:11 Training Loss = 0.022752036982803 
2016-12-10 02:36:13 Valid Error = 0.47995139732685 
2016-12-10 02:36:13 Valid Loss = 0.02317777685881 
2016-12-10 02:36:15 Test Error = 0.5207423580786 
2016-12-10 02:36:15 Test Loss = 0.026952978956933 
2016-12-10 02:36:15 -------------------LR------------------- 
2016-12-10 02:36:15 0.00390625 
2016-12-10 02:36:15 Epoch 143 
2016-12-10 02:37:45 Training Error = 0.42135817469961 
2016-12-10 02:37:45 Training Loss = 0.022944832758543 
2016-12-10 02:37:47 Valid Error = 0.54313487241798 
2016-12-10 02:37:47 Valid Loss = 0.024811340408636 
2016-12-10 02:37:49 Test Error = 0.60698689956332 
2016-12-10 02:37:49 Test Loss = 0.028648356802323 
2016-12-10 02:37:49 -------------------LR------------------- 
2016-12-10 02:37:49 0.00390625 
2016-12-10 02:37:49 Epoch 144 
2016-12-10 02:39:19 Training Error = 0.42311327122992 
2016-12-10 02:39:19 Training Loss = 0.022790651722115 
2016-12-10 02:39:21 Valid Error = 0.49817739975699 
2016-12-10 02:39:21 Valid Loss = 0.023331060153896 
2016-12-10 02:39:23 Test Error = 0.54585152838428 
2016-12-10 02:39:23 Test Loss = 0.027249180270176 
2016-12-10 02:39:23 -------------------LR------------------- 
2016-12-10 02:39:23 0.00390625 
2016-12-10 02:39:23 Epoch 145 
2016-12-10 02:40:54 Training Error = 0.41757796678817 
2016-12-10 02:40:54 Training Loss = 0.02261454526757 
2016-12-10 02:40:56 Valid Error = 0.48116646415553 
2016-12-10 02:40:56 Valid Loss = 0.022871375442105 
2016-12-10 02:40:58 Test Error = 0.5207423580786 
2016-12-10 02:40:58 Test Loss = 0.026549939576317 
2016-12-10 02:40:58 -------------------LR------------------- 
2016-12-10 02:40:58 0.00390625 
2016-12-10 02:40:58 Epoch 146 
2016-12-10 02:42:30 Training Error = 0.42041312272175 
2016-12-10 02:42:30 Training Loss = 0.022791685066971 
2016-12-10 02:42:31 Valid Error = 0.53705953827461 
2016-12-10 02:42:31 Valid Loss = 0.025376565551469 
2016-12-10 02:42:33 Test Error = 0.59825327510917 
2016-12-10 02:42:33 Test Loss = 0.029515700517916 
2016-12-10 02:42:33 -------------------LR------------------- 
2016-12-10 02:42:33 0.00390625 
2016-12-10 02:42:33 Epoch 147 
2016-12-10 02:44:02 Training Error = 0.41595787768327 
2016-12-10 02:44:02 Training Loss = 0.022684538478477 
2016-12-10 02:44:03 Valid Error = 0.46537059538275 
2016-12-10 02:44:03 Valid Loss = 0.024845161781264 
2016-12-10 02:44:05 Test Error = 0.51310043668122 
2016-12-10 02:44:05 Test Loss = 0.029002622323878 
2016-12-10 02:44:05 -------------------LR------------------- 
2016-12-10 02:44:05 0.00390625 
2016-12-10 02:44:05 Epoch 148 
2016-12-10 02:45:38 Training Error = 0.42149318212502 
2016-12-10 02:45:38 Training Loss = 0.02264338400847 
2016-12-10 02:45:40 Valid Error = 0.46415552855407 
2016-12-10 02:45:40 Valid Loss = 0.023658332257399 
2016-12-10 02:45:42 Test Error = 0.50764192139738 
2016-12-10 02:45:42 Test Loss = 0.027286405825147 
2016-12-10 02:45:42 -------------------LR------------------- 
2016-12-10 02:45:42 0.00390625 
2016-12-10 02:45:42 Epoch 149 
2016-12-10 02:47:14 Training Error = 0.41838801134062 
2016-12-10 02:47:14 Training Loss = 0.022748553018009 
2016-12-10 02:47:16 Valid Error = 0.56014580801944 
2016-12-10 02:47:16 Valid Loss = 0.025030855592751 
2016-12-10 02:47:18 Test Error = 0.61353711790393 
2016-12-10 02:47:18 Test Loss = 0.028922736990686 
2016-12-10 02:47:18 -------------------LR------------------- 
2016-12-10 02:47:18 0.00390625 
2016-12-10 02:47:18 Epoch 150 
2016-12-10 02:48:55 Training Error = 0.42486836776023 
2016-12-10 02:48:55 Training Loss = 0.022815694365515 
2016-12-10 02:48:57 Valid Error = 0.45686512758202 
2016-12-10 02:48:57 Valid Loss = 0.023939664666712 
2016-12-10 02:48:59 Test Error = 0.50873362445415 
2016-12-10 02:48:59 Test Loss = 0.027797832872353 
2016-12-10 02:48:59 -------------------LR------------------- 
2016-12-10 02:48:59 0.001953125 
2016-12-10 02:48:59 Epoch 151 
2016-12-10 02:50:28 Training Error = 0.42095315242338 
2016-12-10 02:50:28 Training Loss = 0.0226930283989 
2016-12-10 02:50:29 Valid Error = 0.4775212636695 
2016-12-10 02:50:29 Valid Loss = 0.022797364472236 
2016-12-10 02:50:31 Test Error = 0.52838427947598 
2016-12-10 02:50:31 Test Loss = 0.026432026666753 
2016-12-10 02:50:31 -------------------LR------------------- 
2016-12-10 02:50:31 0.001953125 
2016-12-10 02:50:31 Epoch 152 
2016-12-10 02:52:05 Training Error = 0.42243823410288 
2016-12-10 02:52:05 Training Loss = 0.022828043500115 
2016-12-10 02:52:06 Valid Error = 0.47630619684083 
2016-12-10 02:52:06 Valid Loss = 0.023271493560337 
2016-12-10 02:52:08 Test Error = 0.52401746724891 
2016-12-10 02:52:08 Test Loss = 0.027182014624278 
2016-12-10 02:52:08 -------------------LR------------------- 
2016-12-10 02:52:08 0.001953125 
2016-12-10 02:52:08 Epoch 153 
2016-12-10 02:53:38 Training Error = 0.42432833805859 
2016-12-10 02:53:38 Training Loss = 0.022789622910728 
2016-12-10 02:53:39 Valid Error = 0.53462940461725 
2016-12-10 02:53:39 Valid Loss = 0.024937305520901 
2016-12-10 02:53:41 Test Error = 0.60262008733624 
2016-12-10 02:53:41 Test Loss = 0.02870822985967 
2016-12-10 02:53:41 -------------------LR------------------- 
2016-12-10 02:53:41 0.001953125 
2016-12-10 02:53:41 Epoch 154 
2016-12-10 02:55:03 Training Error = 0.4179829890644 
2016-12-10 02:55:03 Training Loss = 0.02258823724029 
2016-12-10 02:55:05 Valid Error = 0.47995139732685 
2016-12-10 02:55:05 Valid Loss = 0.023243469992765 
2016-12-10 02:55:07 Test Error = 0.5207423580786 
2016-12-10 02:55:07 Test Loss = 0.026916081306981 
2016-12-10 02:55:07 -------------------LR------------------- 
2016-12-10 02:55:07 0.001953125 
2016-12-10 02:55:07 Epoch 155 
2016-12-10 02:56:31 Training Error = 0.42797353854462 
2016-12-10 02:56:31 Training Loss = 0.022746844636292 
2016-12-10 02:56:33 Valid Error = 0.47387606318348 
2016-12-10 02:56:33 Valid Loss = 0.023511242524595 
2016-12-10 02:56:35 Test Error = 0.51528384279476 
2016-12-10 02:56:35 Test Loss = 0.027231703468398 
2016-12-10 02:56:35 -------------------LR------------------- 
2016-12-10 02:56:35 0.001953125 
2016-12-10 02:56:35 Epoch 156 
2016-12-10 02:57:56 Training Error = 0.41892804104226 
2016-12-10 02:57:56 Training Loss = 0.022695283726283 
2016-12-10 02:57:58 Valid Error = 0.4678007290401 
2016-12-10 02:57:58 Valid Loss = 0.02337732999989 
2016-12-10 02:58:00 Test Error = 0.51965065502183 
2016-12-10 02:58:00 Test Loss = 0.027169453873354 
2016-12-10 02:58:00 -------------------LR------------------- 
2016-12-10 02:58:00 0.001953125 
2016-12-10 02:58:00 Epoch 157 
2016-12-10 02:59:28 Training Error = 0.42243823410288 
2016-12-10 02:59:28 Training Loss = 0.02263767274203 
2016-12-10 02:59:29 Valid Error = 0.54313487241798 
2016-12-10 02:59:29 Valid Loss = 0.025272487421046 
2016-12-10 02:59:31 Test Error = 0.60480349344978 
2016-12-10 02:59:31 Test Loss = 0.029275915791007 
2016-12-10 02:59:31 -------------------LR------------------- 
2016-12-10 02:59:31 0.001953125 
2016-12-10 02:59:31 Epoch 158 
2016-12-10 03:00:56 Training Error = 0.42014310787093 
2016-12-10 03:00:56 Training Loss = 0.022732377588894 
2016-12-10 03:00:57 Valid Error = 0.46537059538275 
2016-12-10 03:00:57 Valid Loss = 0.023950332297603 
2016-12-10 03:00:59 Test Error = 0.51091703056769 
2016-12-10 03:00:59 Test Loss = 0.027557993309171 
2016-12-10 03:00:59 -------------------LR------------------- 
2016-12-10 03:00:59 0.001953125 
2016-12-10 03:00:59 Epoch 159 
2016-12-10 03:02:24 Training Error = 0.42216821925206 
2016-12-10 03:02:24 Training Loss = 0.022624961897194 
2016-12-10 03:02:26 Valid Error = 0.54313487241798 
2016-12-10 03:02:26 Valid Loss = 0.024563972391481 
2016-12-10 03:02:28 Test Error = 0.60698689956332 
2016-12-10 03:02:28 Test Loss = 0.028497833569845 
2016-12-10 03:02:28 -------------------LR------------------- 
2016-12-10 03:02:28 0.001953125 
2016-12-10 03:02:28 Epoch 160 
2016-12-10 03:03:58 Training Error = 0.42041312272175 
2016-12-10 03:03:58 Training Loss = 0.022672320587985 
2016-12-10 03:04:00 Valid Error = 0.45686512758202 
2016-12-10 03:04:00 Valid Loss = 0.02346320579119 
2016-12-10 03:04:01 Test Error = 0.50873362445415 
2016-12-10 03:04:01 Test Loss = 0.027270039857603 
2016-12-10 03:04:01 -------------------LR------------------- 
2016-12-10 03:04:01 0.001953125 
2016-12-10 03:04:01 Epoch 161 
2016-12-10 03:05:23 Training Error = 0.41784798163899 
2016-12-10 03:05:23 Training Loss = 0.02252439553682 
2016-12-10 03:05:25 Valid Error = 0.47144592952612 
2016-12-10 03:05:25 Valid Loss = 0.023492598508788 
2016-12-10 03:05:27 Test Error = 0.51637554585153 
2016-12-10 03:05:27 Test Loss = 0.027406875974992 
2016-12-10 03:05:27 -------------------LR------------------- 
2016-12-10 03:05:27 0.001953125 
2016-12-10 03:05:27 Epoch 162 
2016-12-10 03:06:52 Training Error = 0.42000810044552 
2016-12-10 03:06:52 Training Loss = 0.022706436791229 
2016-12-10 03:06:53 Valid Error = 0.50182260024301 
2016-12-10 03:06:53 Valid Loss = 0.023046664611695 
2016-12-10 03:06:55 Test Error = 0.55131004366812 
2016-12-10 03:06:55 Test Loss = 0.026925442443174 
2016-12-10 03:06:55 -------------------LR------------------- 
2016-12-10 03:06:55 0.001953125 
2016-12-10 03:06:55 Epoch 163 
2016-12-10 03:08:20 Training Error = 0.42068313757257 
2016-12-10 03:08:20 Training Loss = 0.022670359014374 
2016-12-10 03:08:22 Valid Error = 0.53827460510328 
2016-12-10 03:08:22 Valid Loss = 0.024978758788554 
2016-12-10 03:08:24 Test Error = 0.5971615720524 
2016-12-10 03:08:24 Test Loss = 0.029078489238141 
2016-12-10 03:08:24 -------------------LR------------------- 
2016-12-10 03:08:24 0.001953125 
2016-12-10 03:08:24 Epoch 164 
2016-12-10 03:09:50 Training Error = 0.4212231672742 
2016-12-10 03:09:50 Training Loss = 0.022759987125343 
2016-12-10 03:09:52 Valid Error = 0.46658566221142 
2016-12-10 03:09:52 Valid Loss = 0.023024587115409 
2016-12-10 03:09:54 Test Error = 0.50873362445415 
2016-12-10 03:09:54 Test Loss = 0.026602800350563 
2016-12-10 03:09:54 -------------------LR------------------- 
2016-12-10 03:09:54 0.001953125 
2016-12-10 03:09:54 Epoch 165 
2016-12-10 03:11:17 Training Error = 0.41622789253409 
2016-12-10 03:11:17 Training Loss = 0.022677274113788 
2016-12-10 03:11:18 Valid Error = 0.47509113001215 
2016-12-10 03:11:18 Valid Loss = 0.023057185761391 
2016-12-10 03:11:20 Test Error = 0.51091703056769 
2016-12-10 03:11:20 Test Loss = 0.026847104343714 
2016-12-10 03:11:20 -------------------LR------------------- 
2016-12-10 03:11:20 0.001953125 
2016-12-10 03:11:20 Epoch 166 
2016-12-10 03:12:46 Training Error = 0.41919805589307 
2016-12-10 03:12:46 Training Loss = 0.022674840989456 
2016-12-10 03:12:47 Valid Error = 0.47995139732685 
2016-12-10 03:12:47 Valid Loss = 0.023251739827884 
2016-12-10 03:12:49 Test Error = 0.51855895196507 
2016-12-10 03:12:49 Test Loss = 0.026923515422671 
2016-12-10 03:12:49 -------------------LR------------------- 
2016-12-10 03:12:49 0.001953125 
2016-12-10 03:12:49 Epoch 167 
2016-12-10 03:14:13 Training Error = 0.42297826380451 
2016-12-10 03:14:13 Training Loss = 0.022631727866521 
2016-12-10 03:14:15 Valid Error = 0.50546780072904 
2016-12-10 03:14:15 Valid Loss = 0.022946866053438 
2016-12-10 03:14:17 Test Error = 0.54803493449782 
2016-12-10 03:14:17 Test Loss = 0.026592607601016 
2016-12-10 03:14:17 -------------------LR------------------- 
2016-12-10 03:14:17 0.001953125 
2016-12-10 03:14:17 Epoch 168 
2016-12-10 03:15:40 Training Error = 0.41973808559471 
2016-12-10 03:15:40 Training Loss = 0.022705792673718 
2016-12-10 03:15:42 Valid Error = 0.47144592952612 
2016-12-10 03:15:42 Valid Loss = 0.022851256905061 
2016-12-10 03:15:44 Test Error = 0.51637554585153 
2016-12-10 03:15:44 Test Loss = 0.02650023282743 
2016-12-10 03:15:44 -------------------LR------------------- 
2016-12-10 03:15:44 0.001953125 
2016-12-10 03:15:44 Epoch 169 
2016-12-10 03:17:11 Training Error = 0.42014310787093 
2016-12-10 03:17:11 Training Loss = 0.022636119565421 
2016-12-10 03:17:12 Valid Error = 0.4823815309842 
2016-12-10 03:17:12 Valid Loss = 0.023642692858606 
2016-12-10 03:17:14 Test Error = 0.51965065502183 
2016-12-10 03:17:14 Test Loss = 0.027362705744949 
2016-12-10 03:17:14 -------------------LR------------------- 
2016-12-10 03:17:14 0.001953125 
2016-12-10 03:17:14 Epoch 170 
2016-12-10 03:18:39 Training Error = 0.42095315242338 
2016-12-10 03:18:39 Training Loss = 0.022576599377544 
2016-12-10 03:18:41 Valid Error = 0.47387606318348 
2016-12-10 03:18:41 Valid Loss = 0.02422920739435 
2016-12-10 03:18:43 Test Error = 0.51528384279476 
2016-12-10 03:18:43 Test Loss = 0.02804469981848 
2016-12-10 03:18:43 -------------------LR------------------- 
2016-12-10 03:18:43 0.001953125 
2016-12-10 03:18:43 Epoch 171 
2016-12-10 03:20:09 Training Error = 0.4228432563791 
2016-12-10 03:20:09 Training Loss = 0.022741186882468 
2016-12-10 03:20:11 Valid Error = 0.48602673147023 
2016-12-10 03:20:11 Valid Loss = 0.022958265848206 
2016-12-10 03:20:13 Test Error = 0.53056768558952 
2016-12-10 03:20:13 Test Loss = 0.026643818023158 
2016-12-10 03:20:13 -------------------LR------------------- 
2016-12-10 03:20:13 0.001953125 
2016-12-10 03:20:13 Epoch 172 
2016-12-10 03:21:36 Training Error = 0.4132577291751 
2016-12-10 03:21:36 Training Loss = 0.022568355315963 
2016-12-10 03:21:37 Valid Error = 0.47144592952612 
2016-12-10 03:21:37 Valid Loss = 0.023399793168321 
2016-12-10 03:21:39 Test Error = 0.51637554585153 
2016-12-10 03:21:39 Test Loss = 0.027101398533466 
2016-12-10 03:21:39 -------------------LR------------------- 
2016-12-10 03:21:39 0.001953125 
2016-12-10 03:21:39 Epoch 173 
2016-12-10 03:23:05 Training Error = 0.41879303361685 
2016-12-10 03:23:05 Training Loss = 0.022722866836961 
2016-12-10 03:23:07 Valid Error = 0.54678007290401 
2016-12-10 03:23:07 Valid Loss = 0.025245699848631 
2016-12-10 03:23:09 Test Error = 0.60371179039301 
2016-12-10 03:23:09 Test Loss = 0.029217772726919 
2016-12-10 03:23:09 -------------------LR------------------- 
2016-12-10 03:23:09 0.001953125 
2016-12-10 03:23:09 Epoch 174 
2016-12-10 03:24:29 Training Error = 0.42095315242338 
2016-12-10 03:24:29 Training Loss = 0.022775001668351 
2016-12-10 03:24:31 Valid Error = 0.47630619684083 
2016-12-10 03:24:31 Valid Loss = 0.023067445175953 
2016-12-10 03:24:33 Test Error = 0.52401746724891 
2016-12-10 03:24:33 Test Loss = 0.026827264149984 
2016-12-10 03:24:33 -------------------LR------------------- 
2016-12-10 03:24:33 0.001953125 
2016-12-10 03:24:33 Epoch 175 
2016-12-10 03:25:59 Training Error = 0.42257324152828 
2016-12-10 03:25:59 Training Loss = 0.022699645263786 
2016-12-10 03:26:01 Valid Error = 0.45929526123937 
2016-12-10 03:26:01 Valid Loss = 0.023648237463447 
2016-12-10 03:26:03 Test Error = 0.50545851528384 
2016-12-10 03:26:03 Test Loss = 0.027498346104341 
2016-12-10 03:26:03 -------------------LR------------------- 
2016-12-10 03:26:03 0.001953125 
2016-12-10 03:26:03 Epoch 176 
2016-12-10 03:27:26 Training Error = 0.42189820440124 
2016-12-10 03:27:26 Training Loss = 0.022749596076631 
2016-12-10 03:27:28 Valid Error = 0.49210206561361 
2016-12-10 03:27:28 Valid Loss = 0.022695786842085 
2016-12-10 03:27:30 Test Error = 0.53384279475983 
2016-12-10 03:27:30 Test Loss = 0.026417197377074 
2016-12-10 03:27:30 -------------------LR------------------- 
2016-12-10 03:27:30 0.001953125 
2016-12-10 03:27:30 Epoch 177 
2016-12-10 03:28:58 Training Error = 0.41757796678817 
2016-12-10 03:28:58 Training Loss = 0.022750170745992 
2016-12-10 03:28:59 Valid Error = 0.46901579586877 
2016-12-10 03:28:59 Valid Loss = 0.02382593725287 
2016-12-10 03:29:01 Test Error = 0.50764192139738 
2016-12-10 03:29:01 Test Loss = 0.027472493199741 
2016-12-10 03:29:01 -------------------LR------------------- 
2016-12-10 03:29:01 0.001953125 
2016-12-10 03:29:01 Epoch 178 
2016-12-10 03:30:22 Training Error = 0.42351829350614 
2016-12-10 03:30:22 Training Loss = 0.022708333086856 
2016-12-10 03:30:24 Valid Error = 0.47630619684083 
2016-12-10 03:30:24 Valid Loss = 0.022599952042278 
2016-12-10 03:30:26 Test Error = 0.52183406113537 
2016-12-10 03:30:26 Test Loss = 0.026328114088844 
2016-12-10 03:30:26 -------------------LR------------------- 
2016-12-10 03:30:26 0.001953125 
2016-12-10 03:30:26 Epoch 179 
2016-12-10 03:31:50 Training Error = 0.41973808559471 
2016-12-10 03:31:50 Training Loss = 0.022679545802696 
2016-12-10 03:31:52 Valid Error = 0.53462940461725 
2016-12-10 03:31:52 Valid Loss = 0.024781159905646 
2016-12-10 03:31:54 Test Error = 0.60262008733624 
2016-12-10 03:31:54 Test Loss = 0.0285554282899 
2016-12-10 03:31:54 -------------------LR------------------- 
2016-12-10 03:31:54 0.001953125 
2016-12-10 03:31:54 Epoch 180 
2016-12-10 03:33:24 Training Error = 0.42270824895369 
2016-12-10 03:33:24 Training Loss = 0.022717961385604 
2016-12-10 03:33:25 Valid Error = 0.46172539489672 
2016-12-10 03:33:25 Valid Loss = 0.024272760324568 
2016-12-10 03:33:27 Test Error = 0.50655021834061 
2016-12-10 03:33:27 Test Loss = 0.028112245054806 
2016-12-10 03:33:27 -------------------LR------------------- 
2016-12-10 03:33:27 0.001953125 
2016-12-10 03:33:27 Epoch 181 
2016-12-10 03:34:50 Training Error = 0.41676792223572 
2016-12-10 03:34:50 Training Loss = 0.022577348316239 
2016-12-10 03:34:52 Valid Error = 0.54313487241798 
2016-12-10 03:34:52 Valid Loss = 0.025054141253563 
2016-12-10 03:34:54 Test Error = 0.60698689956332 
2016-12-10 03:34:54 Test Loss = 0.029137174232333 
2016-12-10 03:34:54 -------------------LR------------------- 
2016-12-10 03:34:54 0.001953125 
2016-12-10 03:34:54 Epoch 182 
2016-12-10 03:36:18 Training Error = 0.42162818955043 
2016-12-10 03:36:18 Training Loss = 0.022796636891654 
2016-12-10 03:36:20 Valid Error = 0.54678007290401 
2016-12-10 03:36:20 Valid Loss = 0.024860803145762 
2016-12-10 03:36:22 Test Error = 0.60152838427948 
2016-12-10 03:36:22 Test Loss = 0.028869294979993 
2016-12-10 03:36:22 -------------------LR------------------- 
2016-12-10 03:36:22 0.001953125 
2016-12-10 03:36:22 Epoch 183 
2016-12-10 03:37:46 Training Error = 0.42054813014716 
2016-12-10 03:37:46 Training Loss = 0.022694046849697 
2016-12-10 03:37:48 Valid Error = 0.47509113001215 
2016-12-10 03:37:48 Valid Loss = 0.023242832301997 
2016-12-10 03:37:50 Test Error = 0.51091703056769 
2016-12-10 03:37:50 Test Loss = 0.02688101457147 
2016-12-10 03:37:50 -------------------LR------------------- 
2016-12-10 03:37:50 0.001953125 
2016-12-10 03:37:50 Epoch 184 
2016-12-10 03:39:15 Training Error = 0.41622789253409 
2016-12-10 03:39:15 Training Loss = 0.022677823539898 
2016-12-10 03:39:17 Valid Error = 0.48724179829891 
2016-12-10 03:39:17 Valid Loss = 0.023061280867994 
2016-12-10 03:39:18 Test Error = 0.53275109170306 
2016-12-10 03:39:18 Test Loss = 0.026939657613343 
2016-12-10 03:39:18 -------------------LR------------------- 
2016-12-10 03:39:18 0.001953125 
2016-12-10 03:39:18 Epoch 185 
2016-12-10 03:40:45 Training Error = 0.41919805589307 
2016-12-10 03:40:45 Training Loss = 0.022700515873871 
2016-12-10 03:40:47 Valid Error = 0.47509113001215 
2016-12-10 03:40:47 Valid Loss = 0.022763593716525 
2016-12-10 03:40:49 Test Error = 0.51091703056769 
2016-12-10 03:40:49 Test Loss = 0.026400343792111 
2016-12-10 03:40:49 -------------------LR------------------- 
2016-12-10 03:40:49 0.001953125 
2016-12-10 03:40:49 Epoch 186 
2016-12-10 03:42:10 Training Error = 0.41730795193736 
2016-12-10 03:42:10 Training Loss = 0.022774464266908 
2016-12-10 03:42:12 Valid Error = 0.48967193195626 
2016-12-10 03:42:12 Valid Loss = 0.023886540145419 
2016-12-10 03:42:14 Test Error = 0.54475982532751 
2016-12-10 03:42:14 Test Loss = 0.027906333717645 
2016-12-10 03:42:14 -------------------LR------------------- 
2016-12-10 03:42:14 0.001953125 
2016-12-10 03:42:14 Epoch 187 
2016-12-10 03:43:37 Training Error = 0.41906304846767 
2016-12-10 03:43:37 Training Loss = 0.022797111944346 
2016-12-10 03:43:38 Valid Error = 0.48724179829891 
2016-12-10 03:43:38 Valid Loss = 0.022947693015631 
2016-12-10 03:43:40 Test Error = 0.53275109170306 
2016-12-10 03:43:40 Test Loss = 0.026726961893194 
2016-12-10 03:43:40 -------------------LR------------------- 
2016-12-10 03:43:40 0.001953125 
2016-12-10 03:43:40 Epoch 188 
2016-12-10 03:45:04 Training Error = 0.42108815984879 
2016-12-10 03:45:04 Training Loss = 0.022759962172735 
2016-12-10 03:45:06 Valid Error = 0.47995139732685 
2016-12-10 03:45:06 Valid Loss = 0.022993211485146 
2016-12-10 03:45:08 Test Error = 0.51855895196507 
2016-12-10 03:45:08 Test Loss = 0.026711121596542 
2016-12-10 03:45:08 -------------------LR------------------- 
2016-12-10 03:45:08 0.001953125 
2016-12-10 03:45:08 Epoch 189 
2016-12-10 03:46:31 Training Error = 0.42405832320778 
2016-12-10 03:46:31 Training Loss = 0.022806726230938 
2016-12-10 03:46:33 Valid Error = 0.47144592952612 
2016-12-10 03:46:33 Valid Loss = 0.024313267769885 
2016-12-10 03:46:35 Test Error = 0.51419213973799 
2016-12-10 03:46:35 Test Loss = 0.02820280083488 
2016-12-10 03:46:35 -------------------LR------------------- 
2016-12-10 03:46:35 0.001953125 
2016-12-10 03:46:35 Epoch 190 
2016-12-10 03:48:02 Training Error = 0.42095315242338 
2016-12-10 03:48:02 Training Loss = 0.022666703474399 
2016-12-10 03:48:04 Valid Error = 0.49817739975699 
2016-12-10 03:48:04 Valid Loss = 0.022856432517347 
2016-12-10 03:48:06 Test Error = 0.54585152838428 
2016-12-10 03:48:06 Test Loss = 0.026521253632564 
2016-12-10 03:48:06 -------------------LR------------------- 
2016-12-10 03:48:06 0.001953125 
2016-12-10 03:48:06 Epoch 191 
2016-12-10 03:49:32 Training Error = 0.42149318212502 
2016-12-10 03:49:32 Training Loss = 0.022611654674484 
2016-12-10 03:49:34 Valid Error = 0.46537059538275 
2016-12-10 03:49:34 Valid Loss = 0.024065891109408 
2016-12-10 03:49:36 Test Error = 0.51310043668122 
2016-12-10 03:49:36 Test Loss = 0.027933149992251 
2016-12-10 03:49:36 -------------------LR------------------- 
2016-12-10 03:49:36 0.001953125 
2016-12-10 03:49:36 Epoch 192 
2016-12-10 03:51:02 Training Error = 0.4212231672742 
2016-12-10 03:51:02 Training Loss = 0.022697044671751 
2016-12-10 03:51:03 Valid Error = 0.47387606318348 
2016-12-10 03:51:03 Valid Loss = 0.024034485205834 
2016-12-10 03:51:05 Test Error = 0.51528384279476 
2016-12-10 03:51:05 Test Loss = 0.027971199250689 
2016-12-10 03:51:05 -------------------LR------------------- 
2016-12-10 03:51:05 0.001953125 
2016-12-10 03:51:05 Epoch 193 
2016-12-10 03:52:27 Training Error = 0.42014310787093 
2016-12-10 03:52:27 Training Loss = 0.022933359687869 
2016-12-10 03:52:28 Valid Error = 0.48359659781288 
2016-12-10 03:52:28 Valid Loss = 0.022656188593383 
2016-12-10 03:52:30 Test Error = 0.52838427947598 
2016-12-10 03:52:30 Test Loss = 0.026453774115619 
2016-12-10 03:52:30 -------------------LR------------------- 
2016-12-10 03:52:30 0.001953125 
2016-12-10 03:52:30 Epoch 194 
2016-12-10 03:53:49 Training Error = 0.42189820440124 
2016-12-10 03:53:49 Training Loss = 0.022818907087168 
2016-12-10 03:53:51 Valid Error = 0.49453219927096 
2016-12-10 03:53:51 Valid Loss = 0.023894795479846 
2016-12-10 03:53:52 Test Error = 0.53493449781659 
2016-12-10 03:53:52 Test Loss = 0.027569925813114 
2016-12-10 03:53:52 -------------------LR------------------- 
2016-12-10 03:53:52 0.001953125 
2016-12-10 03:53:53 Epoch 195 
2016-12-10 03:55:09 Training Error = 0.42095315242338 
2016-12-10 03:55:09 Training Loss = 0.022658398842121 
2016-12-10 03:55:11 Valid Error = 0.45929526123937 
2016-12-10 03:55:11 Valid Loss = 0.024829290964008 
2016-12-10 03:55:13 Test Error = 0.50436681222707 
2016-12-10 03:55:13 Test Loss = 0.029118628277498 
2016-12-10 03:55:13 -------------------LR------------------- 
2016-12-10 03:55:13 0.001953125 
2016-12-10 03:55:13 Epoch 196 
2016-12-10 03:56:31 Training Error = 0.42108815984879 
2016-12-10 03:56:31 Training Loss = 0.022678949525977 
2016-12-10 03:56:33 Valid Error = 0.44714459295261 
2016-12-10 03:56:33 Valid Loss = 0.023775624561301 
2016-12-10 03:56:35 Test Error = 0.49344978165939 
2016-12-10 03:56:35 Test Loss = 0.027601245076049 
2016-12-10 03:56:35 -------------------LR------------------- 
2016-12-10 03:56:35 0.001953125 
2016-12-10 03:56:35 Epoch 197 
2016-12-10 03:57:52 Training Error = 0.41852301876603 
2016-12-10 03:57:52 Training Loss = 0.022875197307113 
2016-12-10 03:57:54 Valid Error = 0.46537059538275 
2016-12-10 03:57:54 Valid Loss = 0.024321867876052 
2016-12-10 03:57:56 Test Error = 0.51310043668122 
2016-12-10 03:57:56 Test Loss = 0.028163331835878 
2016-12-10 03:57:56 -------------------LR------------------- 
2016-12-10 03:57:56 0.001953125 
2016-12-10 03:57:56 Epoch 198 
2016-12-10 03:59:13 Training Error = 0.42108815984879 
2016-12-10 03:59:13 Training Loss = 0.022519179498582 
2016-12-10 03:59:15 Valid Error = 0.47995139732685 
2016-12-10 03:59:15 Valid Loss = 0.023541669149093 
2016-12-10 03:59:17 Test Error = 0.51855895196507 
2016-12-10 03:59:17 Test Loss = 0.027368432989307 
2016-12-10 03:59:17 -------------------LR------------------- 
2016-12-10 03:59:17 0.001953125 
2016-12-10 03:59:17 Epoch 199 
2016-12-10 04:00:36 Training Error = 0.42189820440124 
2016-12-10 04:00:36 Training Loss = 0.022768381710391 
2016-12-10 04:00:38 Valid Error = 0.46537059538275 
2016-12-10 04:00:38 Valid Loss = 0.024660445980539 
2016-12-10 04:00:40 Test Error = 0.51310043668122 
2016-12-10 04:00:40 Test Loss = 0.028578745692384 
2016-12-10 04:00:40 -------------------LR------------------- 
2016-12-10 04:00:40 0.001953125 
2016-12-10 04:00:40 Epoch 200 
2016-12-10 04:02:00 Training Error = 0.42216821925206 
2016-12-10 04:02:00 Training Loss = 0.022645481332588 
2016-12-10 04:02:02 Valid Error = 0.48116646415553 
2016-12-10 04:02:02 Valid Loss = 0.023048949260157 
2016-12-10 04:02:04 Test Error = 0.5207423580786 
2016-12-10 04:02:04 Test Loss = 0.026835144435658 
2016-12-10 04:02:04 -------------------LR------------------- 
2016-12-10 04:02:04 0.0009765625 
2016-12-10 04:02:04 Epoch 201 
2016-12-10 04:03:20 Training Error = 0.41892804104226 
2016-12-10 04:03:20 Training Loss = 0.022765590793813 
2016-12-10 04:03:22 Valid Error = 0.47995139732685 
2016-12-10 04:03:22 Valid Loss = 0.023471037638936 
2016-12-10 04:03:24 Test Error = 0.52947598253275 
2016-12-10 04:03:24 Test Loss = 0.027029750767876 
2016-12-10 04:03:24 -------------------LR------------------- 
2016-12-10 04:03:24 0.0009765625 
2016-12-10 04:03:24 Epoch 202 
2016-12-10 04:04:40 Training Error = 0.42054813014716 
2016-12-10 04:04:40 Training Loss = 0.02267169071486 
2016-12-10 04:04:42 Valid Error = 0.48481166464156 
2016-12-10 04:04:42 Valid Loss = 0.02313215569925 
2016-12-10 04:04:44 Test Error = 0.52620087336245 
2016-12-10 04:04:44 Test Loss = 0.027033579732857 
2016-12-10 04:04:44 -------------------LR------------------- 
2016-12-10 04:04:44 0.0009765625 
2016-12-10 04:04:44 Epoch 203 
2016-12-10 04:06:01 Training Error = 0.42095315242338 
2016-12-10 04:06:01 Training Loss = 0.022674236100283 
2016-12-10 04:06:03 Valid Error = 0.4678007290401 
2016-12-10 04:06:03 Valid Loss = 0.02285210973218 
2016-12-10 04:06:05 Test Error = 0.51965065502183 
2016-12-10 04:06:05 Test Loss = 0.026542107021107 
2016-12-10 04:06:05 -------------------LR------------------- 
2016-12-10 04:06:05 0.0009765625 
2016-12-10 04:06:05 Epoch 204 
2016-12-10 04:07:24 Training Error = 0.41784798163899 
2016-12-10 04:07:24 Training Loss = 0.022676894446336 
2016-12-10 04:07:26 Valid Error = 0.47387606318348 
2016-12-10 04:07:26 Valid Loss = 0.023363847970127 
2016-12-10 04:07:28 Test Error = 0.51528384279476 
2016-12-10 04:07:28 Test Loss = 0.027128491046382 
2016-12-10 04:07:28 -------------------LR------------------- 
2016-12-10 04:07:28 0.0009765625 
2016-12-10 04:07:28 Epoch 205 
2016-12-10 04:08:45 Training Error = 0.41919805589307 
2016-12-10 04:08:45 Training Loss = 0.02259048413046 
2016-12-10 04:08:46 Valid Error = 0.54313487241798 
2016-12-10 04:08:46 Valid Loss = 0.024867336811233 
2016-12-10 04:08:48 Test Error = 0.60698689956332 
2016-12-10 04:08:48 Test Loss = 0.028854081733554 
2016-12-10 04:08:48 -------------------LR------------------- 
2016-12-10 04:08:48 0.0009765625 
2016-12-10 04:08:48 Epoch 206 
2016-12-10 04:10:06 Training Error = 0.41933306331848 
2016-12-10 04:10:06 Training Loss = 0.022528834787292 
2016-12-10 04:10:07 Valid Error = 0.46172539489672 
2016-12-10 04:10:07 Valid Loss = 0.023591590650811 
2016-12-10 04:10:09 Test Error = 0.50873362445415 
2016-12-10 04:10:09 Test Loss = 0.027429042470221 
2016-12-10 04:10:09 -------------------LR------------------- 
2016-12-10 04:10:09 0.0009765625 
2016-12-10 04:10:09 Epoch 207 
2016-12-10 04:11:25 Training Error = 0.41717294451195 
2016-12-10 04:11:25 Training Loss = 0.022797166314646 
2016-12-10 04:11:27 Valid Error = 0.50668286755772 
2016-12-10 04:11:27 Valid Loss = 0.023281955290803 
2016-12-10 04:11:29 Test Error = 0.55021834061135 
2016-12-10 04:11:29 Test Loss = 0.026947902268054 
2016-12-10 04:11:29 -------------------LR------------------- 
2016-12-10 04:11:29 0.0009765625 
2016-12-10 04:11:29 Epoch 208 
2016-12-10 04:12:46 Training Error = 0.41717294451195 
2016-12-10 04:12:46 Training Loss = 0.022653981137743 
2016-12-10 04:12:48 Valid Error = 0.48481166464156 
2016-12-10 04:12:48 Valid Loss = 0.023366863767091 
2016-12-10 04:12:50 Test Error = 0.52838427947598 
2016-12-10 04:12:50 Test Loss = 0.027147148038827 
2016-12-10 04:12:50 -------------------LR------------------- 
2016-12-10 04:12:50 0.0009765625 
2016-12-10 04:12:50 Epoch 209 
2016-12-10 04:14:06 Training Error = 0.42135817469961 
2016-12-10 04:14:06 Training Loss = 0.022796695355185 
2016-12-10 04:14:08 Valid Error = 0.4823815309842 
2016-12-10 04:14:08 Valid Loss = 0.023125260040436 
2016-12-10 04:14:10 Test Error = 0.52401746724891 
2016-12-10 04:14:10 Test Loss = 0.026790697920556 
2016-12-10 04:14:10 -------------------LR------------------- 
2016-12-10 04:14:10 0.0009765625 
2016-12-10 04:14:10 Epoch 210 
2016-12-10 04:15:32 Training Error = 0.4196030781693 
2016-12-10 04:15:32 Training Loss = 0.02265568848796 
2016-12-10 04:15:34 Valid Error = 0.50668286755772 
2016-12-10 04:15:34 Valid Loss = 0.023326185507746 
2016-12-10 04:15:36 Test Error = 0.55021834061135 
2016-12-10 04:15:36 Test Loss = 0.027190753983516 
2016-12-10 04:15:36 -------------------LR------------------- 
2016-12-10 04:15:36 0.0009765625 
2016-12-10 04:15:36 Epoch 211 
2016-12-10 04:16:50 Training Error = 0.42432833805859 
2016-12-10 04:16:50 Training Loss = 0.022778616488303 
2016-12-10 04:16:51 Valid Error = 0.49939246658566 
2016-12-10 04:16:51 Valid Loss = 0.023107711587472 
2016-12-10 04:16:53 Test Error = 0.53930131004367 
2016-12-10 04:16:53 Test Loss = 0.026872600957459 
2016-12-10 04:16:53 -------------------LR------------------- 
2016-12-10 04:16:53 0.0009765625 
2016-12-10 04:16:53 Epoch 212 
2016-12-10 04:18:12 Training Error = 0.41946807074389 
2016-12-10 04:18:12 Training Loss = 0.022760195857314 
2016-12-10 04:18:13 Valid Error = 0.47144592952612 
2016-12-10 04:18:13 Valid Loss = 0.023827715728549 
2016-12-10 04:18:15 Test Error = 0.51419213973799 
2016-12-10 04:18:15 Test Loss = 0.027742204787684 
2016-12-10 04:18:15 -------------------LR------------------- 
2016-12-10 04:18:15 0.0009765625 
2016-12-10 04:18:15 Epoch 213 
2016-12-10 04:19:33 Training Error = 0.42189820440124 
2016-12-10 04:19:33 Training Loss = 0.022704049560091 
2016-12-10 04:19:35 Valid Error = 0.4823815309842 
2016-12-10 04:19:35 Valid Loss = 0.023058875964606 
2016-12-10 04:19:37 Test Error = 0.53602620087336 
2016-12-10 04:19:37 Test Loss = 0.026573260129667 
2016-12-10 04:19:37 -------------------LR------------------- 
2016-12-10 04:19:37 0.0009765625 
2016-12-10 04:19:37 Epoch 214 
2016-12-10 04:20:53 Training Error = 0.41784798163899 
2016-12-10 04:20:53 Training Loss = 0.022647576301639 
2016-12-10 04:20:55 Valid Error = 0.53705953827461 
2016-12-10 04:20:55 Valid Loss = 0.025358601546913 
2016-12-10 04:20:57 Test Error = 0.59825327510917 
2016-12-10 04:20:57 Test Loss = 0.029405439647974 
2016-12-10 04:20:57 -------------------LR------------------- 
2016-12-10 04:20:57 0.0009765625 
2016-12-10 04:20:57 Epoch 215 
2016-12-10 04:22:13 Training Error = 0.42027811529634 
2016-12-10 04:22:13 Training Loss = 0.02257951844373 
2016-12-10 04:22:15 Valid Error = 0.48724179829891 
2016-12-10 04:22:15 Valid Loss = 0.023240725932908 
2016-12-10 04:22:17 Test Error = 0.52292576419214 
2016-12-10 04:22:17 Test Loss = 0.027050378939685 
2016-12-10 04:22:17 -------------------LR------------------- 
2016-12-10 04:22:17 0.0009765625 
2016-12-10 04:22:17 Epoch 216 
2016-12-10 04:23:35 Training Error = 0.41933306331848 
2016-12-10 04:23:35 Training Loss = 0.022819404307133 
2016-12-10 04:23:37 Valid Error = 0.47144592952612 
2016-12-10 04:23:37 Valid Loss = 0.023036025570256 
2016-12-10 04:23:39 Test Error = 0.51637554585153 
2016-12-10 04:23:39 Test Loss = 0.026823515686334 
2016-12-10 04:23:39 -------------------LR------------------- 
2016-12-10 04:23:39 0.0009765625 
2016-12-10 04:23:39 Epoch 217 
2016-12-10 04:24:56 Training Error = 0.42108815984879 
2016-12-10 04:24:56 Training Loss = 0.022810667091747 
2016-12-10 04:24:58 Valid Error = 0.45686512758202 
2016-12-10 04:24:58 Valid Loss = 0.024744190412274 
