2016-12-09 09:16:22 [program started on Fri Dec  9 09:16:22 2016] 
2016-12-09 09:16:22 [command line arguments] 
2016-12-09 09:16:22 stcWeights false 
2016-12-09 09:16:22 LR 0.015625 
2016-12-09 09:16:22 batchSize 64 
2016-12-09 09:16:22 network ./Models/Cifar10_Custom 
2016-12-09 09:16:22 stcNeurons true 
2016-12-09 09:16:22 constBatchSize false 
2016-12-09 09:16:22 chartFileName chart1 
2016-12-09 09:16:22 dp_prepro false 
2016-12-09 09:16:22 nGPU 1 
2016-12-09 09:16:22 dataset Caltech101 
2016-12-09 09:16:22 type cuda 
2016-12-09 09:16:22 momentum 0 
2016-12-09 09:16:22 threads 8 
2016-12-09 09:16:22 weightDecay 0 
2016-12-09 09:16:22 runningVal false 
2016-12-09 09:16:22 convLayerN 6 
2016-12-09 09:16:22 LRDecay 0 
2016-12-09 09:16:22 numHid 1024 
2016-12-09 09:16:22 save /dev/shm/clone/temp/th/Results/Caltech101/model00001 
2016-12-09 09:16:22 augment false 
2016-12-09 09:16:22 epoch -1 
2016-12-09 09:16:22 modelsFolder ./Models/ 
2016-12-09 09:16:22 format rgb 
2016-12-09 09:16:22 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-09 09:16:22 imageFileExtension svg 
2016-12-09 09:16:22 channel 1 
2016-12-09 09:16:22 devid 4 
2016-12-09 09:16:22 visualize 1 
2016-12-09 09:16:22 LRDecayPerEpoch 0.0001 
2016-12-09 09:16:22 optimization adam 
2016-12-09 09:16:22 SBN true 
2016-12-09 09:16:22 normalization simple 
2016-12-09 09:16:22 title model1 
2016-12-09 09:16:22 load  
2016-12-09 09:16:22 whiten true 
2016-12-09 09:16:22 [----------------------] 
2016-12-09 09:16:23 ==> Network 
2016-12-09 09:16:23 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 102)
  (38): nn.BatchNormalization
} 
2016-12-09 09:16:23 ==>14128050 Parameters 
2016-12-09 09:16:23 ==> Loss 
2016-12-09 09:16:23 SqrtHingeEmbeddingCriterion 
2016-12-09 09:16:23 
==> Starting Training
 
2016-12-09 09:16:23 Epoch 1 
2016-12-09 09:17:20 Training Error = 0.76090184960173 
2016-12-09 09:17:20 Training Loss = 0.27567333408746 
2016-12-09 09:17:21 Valid Error = 0.71688942891859 
2016-12-09 09:17:21 Valid Loss = 0.036371078233602 
2016-12-09 09:17:23 Test Error = 0.72161572052402 
2016-12-09 09:17:23 Test Loss = 0.037071082701091 
2016-12-09 09:17:23 -------------------LR------------------- 
2016-12-09 09:17:23 0.015625 
2016-12-09 09:17:23 Epoch 2 
2016-12-09 09:18:33 Training Error = 0.64425543404887 
2016-12-09 09:18:33 Training Loss = 0.031469321932339 
2016-12-09 09:18:35 Valid Error = 0.65370595382746 
2016-12-09 09:18:35 Valid Loss = 0.029541789666462 
2016-12-09 09:18:37 Test Error = 0.66703056768559 
2016-12-09 09:18:37 Test Loss = 0.030211726294623 
2016-12-09 09:18:37 -------------------LR------------------- 
2016-12-09 09:18:37 0.015625 
2016-12-09 09:18:37 Epoch 3 
2016-12-09 09:19:33 Training Error = 0.62764952072364 
2016-12-09 09:19:33 Training Loss = 0.028733942050574 
2016-12-09 09:19:35 Valid Error = 0.72053462940462 
2016-12-09 09:19:35 Valid Loss = 0.031705536777617 
2016-12-09 09:19:37 Test Error = 0.75218340611354 
2016-12-09 09:19:37 Test Loss = 0.03302054542342 
2016-12-09 09:19:37 -------------------LR------------------- 
2016-12-09 09:19:37 0.015625 
2016-12-09 09:19:37 Epoch 4 
2016-12-09 09:20:34 Training Error = 0.61279870392872 
2016-12-09 09:20:34 Training Loss = 0.027433553017832 
2016-12-09 09:20:36 Valid Error = 0.61239368165249 
2016-12-09 09:20:36 Valid Loss = 0.029570237014187 
2016-12-09 09:20:38 Test Error = 0.63318777292576 
2016-12-09 09:20:38 Test Loss = 0.031202390490015 
2016-12-09 09:20:38 -------------------LR------------------- 
2016-12-09 09:20:38 0.015625 
2016-12-09 09:20:38 Epoch 5 
2016-12-09 09:21:35 Training Error = 0.58728230052653 
2016-12-09 09:21:35 Training Loss = 0.026749876396343 
2016-12-09 09:21:37 Valid Error = 0.67800729040097 
2016-12-09 09:21:37 Valid Loss = 0.029597869194634 
2016-12-09 09:21:39 Test Error = 0.70087336244541 
2016-12-09 09:21:39 Test Loss = 0.02997116082634 
2016-12-09 09:21:39 -------------------LR------------------- 
2016-12-09 09:21:39 0.015625 
2016-12-09 09:21:39 Epoch 6 
2016-12-09 09:22:42 Training Error = 0.57121641690293 
2016-12-09 09:22:42 Training Loss = 0.026406608663526 
2016-12-09 09:22:43 Valid Error = 0.68043742405832 
2016-12-09 09:22:43 Valid Loss = 0.029474469583319 
2016-12-09 09:22:45 Test Error = 0.70851528384279 
2016-12-09 09:22:45 Test Loss = 0.030930864109712 
2016-12-09 09:22:45 -------------------LR------------------- 
2016-12-09 09:22:45 0.015625 
2016-12-09 09:22:45 Epoch 7 
2016-12-09 09:23:53 Training Error = 0.5385446199541 
2016-12-09 09:23:53 Training Loss = 0.025234636371696 
2016-12-09 09:23:55 Valid Error = 0.52490886998785 
2016-12-09 09:23:55 Valid Loss = 0.027356902542517 
2016-12-09 09:23:57 Test Error = 0.56986899563319 
2016-12-09 09:23:57 Test Loss = 0.030366036408867 
2016-12-09 09:23:57 -------------------LR------------------- 
2016-12-09 09:23:57 0.015625 
2016-12-09 09:23:57 Epoch 8 
2016-12-09 09:24:54 Training Error = 0.50330768192251 
2016-12-09 09:24:54 Training Loss = 0.024508267320163 
2016-12-09 09:24:56 Valid Error = 0.56257594167679 
2016-12-09 09:24:56 Valid Loss = 0.026086952041308 
2016-12-09 09:24:58 Test Error = 0.57096069868996 
2016-12-09 09:24:58 Test Loss = 0.026984876339732 
2016-12-09 09:24:58 -------------------LR------------------- 
2016-12-09 09:24:58 0.015625 
2016-12-09 09:24:58 Epoch 9 
2016-12-09 09:25:55 Training Error = 0.43688402862157 
2016-12-09 09:25:55 Training Loss = 0.023440227024397 
2016-12-09 09:25:57 Valid Error = 0.46051032806804 
2016-12-09 09:25:57 Valid Loss = 0.023627663361557 
2016-12-09 09:25:59 Test Error = 0.49017467248908 
2016-12-09 09:25:59 Test Loss = 0.02486378264583 
2016-12-09 09:25:59 -------------------LR------------------- 
2016-12-09 09:25:59 0.015625 
2016-12-09 09:25:59 Epoch 10 
2016-12-09 09:26:58 Training Error = 0.36600513028217 
2016-12-09 09:26:58 Training Loss = 0.022351539208249 
2016-12-09 09:26:59 Valid Error = 0.52126366950182 
2016-12-09 09:26:59 Valid Loss = 0.032380706760825 
2016-12-09 09:27:01 Test Error = 0.54039301310044 
2016-12-09 09:27:01 Test Loss = 0.034295906241423 
2016-12-09 09:27:01 -------------------LR------------------- 
2016-12-09 09:27:01 0.015625 
2016-12-09 09:27:01 Epoch 11 
2016-12-09 09:27:58 Training Error = 0.33360334818415 
2016-12-09 09:27:58 Training Loss = 0.021762241583711 
2016-12-09 09:28:00 Valid Error = 0.3681652490887 
2016-12-09 09:28:00 Valid Loss = 0.022231071961036 
2016-12-09 09:28:02 Test Error = 0.40065502183406 
2016-12-09 09:28:02 Test Loss = 0.023809883064694 
2016-12-09 09:28:02 -------------------LR------------------- 
2016-12-09 09:28:02 0.015625 
2016-12-09 09:28:02 Epoch 12 
2016-12-09 09:28:59 Training Error = 0.33819360064804 
2016-12-09 09:28:59 Training Loss = 0.021729410281818 
2016-12-09 09:29:01 Valid Error = 0.3730255164034 
2016-12-09 09:29:01 Valid Loss = 0.022332043383292 
2016-12-09 09:29:03 Test Error = 0.40502183406114 
2016-12-09 09:29:03 Test Loss = 0.024179432251874 
2016-12-09 09:29:03 -------------------LR------------------- 
2016-12-09 09:29:03 0.015625 
2016-12-09 09:29:03 Epoch 13 
2016-12-09 09:30:00 Training Error = 0.33819360064804 
2016-12-09 09:30:00 Training Loss = 0.021874992454306 
2016-12-09 09:30:02 Valid Error = 0.34750911300122 
2016-12-09 09:30:02 Valid Loss = 0.022302065238236 
2016-12-09 09:30:04 Test Error = 0.36244541484716 
2016-12-09 09:30:04 Test Loss = 0.023920101246803 
2016-12-09 09:30:04 -------------------LR------------------- 
2016-12-09 09:30:04 0.015625 
2016-12-09 09:30:04 Epoch 14 
2016-12-09 09:31:03 Training Error = 0.33562845956528 
2016-12-09 09:31:03 Training Loss = 0.02184020280032 
2016-12-09 09:31:04 Valid Error = 0.35722964763062 
2016-12-09 09:31:04 Valid Loss = 0.022206439040872 
2016-12-09 09:31:06 Test Error = 0.38318777292576 
2016-12-09 09:31:06 Test Loss = 0.023843706760531 
2016-12-09 09:31:06 -------------------LR------------------- 
2016-12-09 09:31:06 0.015625 
2016-12-09 09:31:06 Epoch 15 
2016-12-09 09:32:04 Training Error = 0.33562845956528 
2016-12-09 09:32:04 Training Loss = 0.021780502270893 
2016-12-09 09:32:05 Valid Error = 0.35722964763062 
2016-12-09 09:32:05 Valid Loss = 0.022288785393667 
2016-12-09 09:32:07 Test Error = 0.38973799126638 
2016-12-09 09:32:07 Test Loss = 0.02403610656464 
2016-12-09 09:32:07 -------------------LR------------------- 
2016-12-09 09:32:07 0.015625 
2016-12-09 09:32:07 Epoch 16 
2016-12-09 09:33:17 Training Error = 0.33454840016201 
2016-12-09 09:33:17 Training Loss = 0.021745681816715 
2016-12-09 09:33:18 Valid Error = 0.3730255164034 
2016-12-09 09:33:18 Valid Loss = 0.022487773969473 
2016-12-09 09:33:20 Test Error = 0.40502183406114 
2016-12-09 09:33:20 Test Loss = 0.024364643206004 
2016-12-09 09:33:20 -------------------LR------------------- 
2016-12-09 09:33:20 0.015625 
2016-12-09 09:33:20 Epoch 17 
2016-12-09 09:34:17 Training Error = 0.33711354124477 
2016-12-09 09:34:17 Training Loss = 0.021861377155304 
2016-12-09 09:34:19 Valid Error = 0.35479951397327 
2016-12-09 09:34:19 Valid Loss = 0.022205203981634 
2016-12-09 09:34:21 Test Error = 0.37445414847162 
2016-12-09 09:34:21 Test Loss = 0.023450283458809 
2016-12-09 09:34:21 -------------------LR------------------- 
2016-12-09 09:34:21 0.015625 
2016-12-09 09:34:21 Epoch 18 
2016-12-09 09:35:19 Training Error = 0.33886863777508 
2016-12-09 09:35:19 Training Loss = 0.021765343077785 
2016-12-09 09:35:20 Valid Error = 0.3730255164034 
2016-12-09 09:35:20 Valid Loss = 0.022441328495402 
2016-12-09 09:35:22 Test Error = 0.40502183406114 
2016-12-09 09:35:22 Test Loss = 0.024700841218038 
2016-12-09 09:35:22 -------------------LR------------------- 
2016-12-09 09:35:22 0.015625 
2016-12-09 09:35:22 Epoch 19 
2016-12-09 09:36:19 Training Error = 0.33657351154313 
2016-12-09 09:36:19 Training Loss = 0.021796618756586 
2016-12-09 09:36:21 Valid Error = 0.36452004860267 
2016-12-09 09:36:21 Valid Loss = 0.022501243690756 
2016-12-09 09:36:23 Test Error = 0.40938864628821 
2016-12-09 09:36:23 Test Loss = 0.024216632219701 
2016-12-09 09:36:23 -------------------LR------------------- 
2016-12-09 09:36:23 0.015625 
2016-12-09 09:36:23 Epoch 20 
2016-12-09 09:37:22 Training Error = 0.33724854867018 
2016-12-09 09:37:22 Training Loss = 0.021746783381085 
2016-12-09 09:37:24 Valid Error = 0.36087484811665 
2016-12-09 09:37:24 Valid Loss = 0.022300100825082 
2016-12-09 09:37:26 Test Error = 0.39519650655022 
2016-12-09 09:37:26 Test Loss = 0.023887643377765 
2016-12-09 09:37:26 -------------------LR------------------- 
2016-12-09 09:37:26 0.0078125 
2016-12-09 09:37:26 Epoch 21 
2016-12-09 09:38:23 Training Error = 0.33684352639395 
2016-12-09 09:38:23 Training Loss = 0.021833688086945 
2016-12-09 09:38:25 Valid Error = 0.363304981774 
2016-12-09 09:38:25 Valid Loss = 0.022350011958223 
2016-12-09 09:38:27 Test Error = 0.40174672489083 
2016-12-09 09:38:27 Test Loss = 0.024419295741063 
2016-12-09 09:38:27 -------------------LR------------------- 
2016-12-09 09:38:27 0.0078125 
2016-12-09 09:38:27 Epoch 22 
2016-12-09 09:39:24 Training Error = 0.33630349669232 
2016-12-09 09:39:24 Training Loss = 0.021841491449902 
2016-12-09 09:39:26 Valid Error = 0.35479951397327 
2016-12-09 09:39:26 Valid Loss = 0.022461655116058 
2016-12-09 09:39:28 Test Error = 0.39082969432314 
2016-12-09 09:39:28 Test Loss = 0.024017972634509 
2016-12-09 09:39:28 -------------------LR------------------- 
2016-12-09 09:39:28 0.0078125 
2016-12-09 09:39:28 Epoch 23 
2016-12-09 09:40:24 Training Error = 0.33549345213987 
2016-12-09 09:40:24 Training Loss = 0.021912974792421 
2016-12-09 09:40:26 Valid Error = 0.34993924665857 
2016-12-09 09:40:26 Valid Loss = 0.023101881137849 
2016-12-09 09:40:28 Test Error = 0.38973799126638 
2016-12-09 09:40:28 Test Loss = 0.02570275939368 
2016-12-09 09:40:28 -------------------LR------------------- 
2016-12-09 09:40:28 0.0078125 
2016-12-09 09:40:28 Epoch 24 
2016-12-09 09:41:26 Training Error = 0.33589847441609 
2016-12-09 09:41:26 Training Loss = 0.021946341193978 
2016-12-09 09:41:27 Valid Error = 0.37545565006075 
2016-12-09 09:41:27 Valid Loss = 0.022161806177312 
2016-12-09 09:41:29 Test Error = 0.41157205240175 
2016-12-09 09:41:29 Test Loss = 0.023613172543594 
2016-12-09 09:41:29 -------------------LR------------------- 
2016-12-09 09:41:29 0.0078125 
2016-12-09 09:41:29 Epoch 25 
2016-12-09 09:42:26 Training Error = 0.33495342243823 
2016-12-09 09:42:26 Training Loss = 0.0217330797105 
2016-12-09 09:42:28 Valid Error = 0.36087484811665 
2016-12-09 09:42:28 Valid Loss = 0.022744491308556 
2016-12-09 09:42:30 Test Error = 0.40065502183406 
2016-12-09 09:42:30 Test Loss = 0.025030563298394 
2016-12-09 09:42:30 -------------------LR------------------- 
2016-12-09 09:42:30 0.0078125 
2016-12-09 09:42:30 Epoch 26 
2016-12-09 09:43:38 Training Error = 0.33846361549885 
2016-12-09 09:43:38 Training Loss = 0.021842148318588 
2016-12-09 09:43:40 Valid Error = 0.36087484811665 
2016-12-09 09:43:40 Valid Loss = 0.022293903419678 
2016-12-09 09:43:42 Test Error = 0.39519650655022 
2016-12-09 09:43:42 Test Loss = 0.024199329949672 
2016-12-09 09:43:42 -------------------LR------------------- 
2016-12-09 09:43:42 0.0078125 
2016-12-09 09:43:42 Epoch 27 
2016-12-09 09:44:40 Training Error = 0.33414337788578 
2016-12-09 09:44:40 Training Loss = 0.021826963721287 
2016-12-09 09:44:42 Valid Error = 0.36208991494532 
2016-12-09 09:44:42 Valid Loss = 0.021977888221981 
2016-12-09 09:44:44 Test Error = 0.39737991266376 
2016-12-09 09:44:44 Test Loss = 0.02371658719443 
2016-12-09 09:44:44 -------------------LR------------------- 
2016-12-09 09:44:44 0.0078125 
2016-12-09 09:44:44 Epoch 28 
2016-12-09 09:45:41 Training Error = 0.33360334818415 
2016-12-09 09:45:41 Training Loss = 0.021862278333108 
2016-12-09 09:45:43 Valid Error = 0.36938031591738 
2016-12-09 09:45:43 Valid Loss = 0.0222482715061 
2016-12-09 09:45:45 Test Error = 0.39956331877729 
2016-12-09 09:45:45 Test Loss = 0.024230589274487 
2016-12-09 09:45:45 -------------------LR------------------- 
2016-12-09 09:45:45 0.0078125 
2016-12-09 09:45:45 Epoch 29 
2016-12-09 09:46:42 Training Error = 0.33724854867018 
2016-12-09 09:46:42 Training Loss = 0.021809508435726 
2016-12-09 09:46:44 Valid Error = 0.36208991494532 
2016-12-09 09:46:44 Valid Loss = 0.022352795638159 
2016-12-09 09:46:46 Test Error = 0.39737991266376 
2016-12-09 09:46:46 Test Loss = 0.023941404367584 
2016-12-09 09:46:46 -------------------LR------------------- 
2016-12-09 09:46:46 0.0078125 
2016-12-09 09:46:46 Epoch 30 
2016-12-09 09:47:45 Training Error = 0.33684352639395 
2016-12-09 09:47:45 Training Loss = 0.021829208296662 
2016-12-09 09:47:47 Valid Error = 0.35722964763062 
2016-12-09 09:47:47 Valid Loss = 0.022270096718129 
2016-12-09 09:47:49 Test Error = 0.38427947598253 
2016-12-09 09:47:49 Test Loss = 0.023846954115076 
2016-12-09 09:47:49 -------------------LR------------------- 
2016-12-09 09:47:49 0.0078125 
2016-12-09 09:47:49 Epoch 31 
2016-12-09 09:48:46 Training Error = 0.33589847441609 
2016-12-09 09:48:46 Training Loss = 0.021853515912055 
2016-12-09 09:48:48 Valid Error = 0.3584447144593 
2016-12-09 09:48:48 Valid Loss = 0.022688088697546 
2016-12-09 09:48:50 Test Error = 0.39410480349345 
2016-12-09 09:48:50 Test Loss = 0.024810365228092 
2016-12-09 09:48:50 -------------------LR------------------- 
2016-12-09 09:48:50 0.0078125 
2016-12-09 09:48:50 Epoch 32 
2016-12-09 09:49:47 Training Error = 0.33657351154313 
2016-12-09 09:49:47 Training Loss = 0.021806954353589 
2016-12-09 09:49:49 Valid Error = 0.35965978128797 
2016-12-09 09:49:49 Valid Loss = 0.022388837902402 
2016-12-09 09:49:51 Test Error = 0.39301310043668 
2016-12-09 09:49:51 Test Loss = 0.024537737634447 
2016-12-09 09:49:51 -------------------LR------------------- 
2016-12-09 09:49:51 0.0078125 
2016-12-09 09:49:51 Epoch 33 
2016-12-09 09:50:48 Training Error = 0.33427838531119 
2016-12-09 09:50:48 Training Loss = 0.021688816828229 
2016-12-09 09:50:50 Valid Error = 0.37059538274605 
2016-12-09 09:50:50 Valid Loss = 0.021646540560187 
2016-12-09 09:50:52 Test Error = 0.38973799126638 
2016-12-09 09:50:52 Test Loss = 0.023102820807812 
2016-12-09 09:50:52 -------------------LR------------------- 
2016-12-09 09:50:52 0.0078125 
2016-12-09 09:50:52 Epoch 34 
2016-12-09 09:51:49 Training Error = 0.34102875658161 
2016-12-09 09:51:49 Training Loss = 0.021970325497068 
2016-12-09 09:51:51 Valid Error = 0.35358444714459 
2016-12-09 09:51:51 Valid Loss = 0.022644123790131 
2016-12-09 09:51:53 Test Error = 0.39519650655022 
2016-12-09 09:51:53 Test Loss = 0.024646217526953 
2016-12-09 09:51:53 -------------------LR------------------- 
2016-12-09 09:51:53 0.0078125 
2016-12-09 09:51:53 Epoch 35 
2016-12-09 09:52:50 Training Error = 0.33954367490212 
2016-12-09 09:52:50 Training Loss = 0.021844365329184 
2016-12-09 09:52:52 Valid Error = 0.35965978128797 
2016-12-09 09:52:52 Valid Loss = 0.022142293957318 
2016-12-09 09:52:54 Test Error = 0.38100436681223 
2016-12-09 09:52:54 Test Loss = 0.023528450236601 
2016-12-09 09:52:54 -------------------LR------------------- 
2016-12-09 09:52:54 0.0078125 
2016-12-09 09:52:54 Epoch 36 
2016-12-09 09:53:51 Training Error = 0.33373835560956 
2016-12-09 09:53:51 Training Loss = 0.021769475988252 
2016-12-09 09:53:53 Valid Error = 0.36938031591738 
2016-12-09 09:53:53 Valid Loss = 0.022492382721892 
2016-12-09 09:53:55 Test Error = 0.40829694323144 
2016-12-09 09:53:55 Test Loss = 0.024405468195872 
2016-12-09 09:53:55 -------------------LR------------------- 
2016-12-09 09:53:55 0.0078125 
2016-12-09 09:53:55 Epoch 37 
2016-12-09 09:54:52 Training Error = 0.33616848926691 
2016-12-09 09:54:52 Training Loss = 0.021768762779272 
2016-12-09 09:54:54 Valid Error = 0.36208991494532 
2016-12-09 09:54:54 Valid Loss = 0.022171678957291 
2016-12-09 09:54:56 Test Error = 0.3853711790393 
2016-12-09 09:54:56 Test Loss = 0.023385627706066 
2016-12-09 09:54:56 -------------------LR------------------- 
2016-12-09 09:54:56 0.0078125 
2016-12-09 09:54:56 Epoch 38 
2016-12-09 09:55:53 Training Error = 0.33184825165384 
2016-12-09 09:55:53 Training Loss = 0.021797103959771 
2016-12-09 09:55:55 Valid Error = 0.36208991494532 
2016-12-09 09:55:55 Valid Loss = 0.022796345953586 
2016-12-09 09:55:57 Test Error = 0.39737991266376 
2016-12-09 09:55:57 Test Loss = 0.024797862043568 
2016-12-09 09:55:57 -------------------LR------------------- 
2016-12-09 09:55:57 0.0078125 
2016-12-09 09:55:57 Epoch 39 
2016-12-09 09:56:54 Training Error = 0.3344133927366 
2016-12-09 09:56:54 Training Loss = 0.02177823726631 
2016-12-09 09:56:56 Valid Error = 0.363304981774 
2016-12-09 09:56:56 Valid Loss = 0.022525756228008 
2016-12-09 09:56:58 Test Error = 0.40393013100437 
2016-12-09 09:56:58 Test Loss = 0.024577851186391 
2016-12-09 09:56:58 -------------------LR------------------- 
2016-12-09 09:56:58 0.0078125 
2016-12-09 09:56:58 Epoch 40 
