2016-12-09 23:02:45 [program started on Fri Dec  9 23:02:45 2016] 
2016-12-09 23:02:45 [command line arguments] 
2016-12-09 23:02:45 stcWeights false 
2016-12-09 23:02:45 LR 0.015625 
2016-12-09 23:02:45 batchSize 300 
2016-12-09 23:02:45 network ./Models/Cifar10_Custom 
2016-12-09 23:02:45 stcNeurons true 
2016-12-09 23:02:45 constBatchSize false 
2016-12-09 23:02:45 chartFileName chart1 
2016-12-09 23:02:45 dp_prepro false 
2016-12-09 23:02:45 nGPU 1 
2016-12-09 23:02:45 dataset Caltech101 
2016-12-09 23:02:45 type cuda 
2016-12-09 23:02:45 momentum 0 
2016-12-09 23:02:45 threads 8 
2016-12-09 23:02:45 weightDecay 0 
2016-12-09 23:02:45 runningVal false 
2016-12-09 23:02:45 convLayerN 6 
2016-12-09 23:02:45 LRDecay 0 
2016-12-09 23:02:45 numHid 216 
2016-12-09 23:02:45 save /dev/shm/clone/temp/th/Results/Caltech101/model6-10-216 
2016-12-09 23:02:45 augment false 
2016-12-09 23:02:45 epoch -1 
2016-12-09 23:02:45 modelsFolder ./Models/ 
2016-12-09 23:02:45 format rgb 
2016-12-09 23:02:45 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-09 23:02:45 imageFileExtension svg 
2016-12-09 23:02:45 channel 1 
2016-12-09 23:02:45 devid 12 
2016-12-09 23:02:45 visualize 1 
2016-12-09 23:02:45 LRDecayPerEpoch 0.0001 
2016-12-09 23:02:45 optimization adam 
2016-12-09 23:02:45 SBN true 
2016-12-09 23:02:45 normalization simple 
2016-12-09 23:02:45 title model1 
2016-12-09 23:02:45 load  
2016-12-09 23:02:45 whiten true 
2016-12-09 23:02:45 [----------------------] 
2016-12-09 23:02:46 ==> Network 
2016-12-09 23:02:46 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 216)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(216 -> 216)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(216 -> 102)
  (38): nn.BatchNormalization
} 
2016-12-09 23:02:46 ==>6419730 Parameters 
2016-12-09 23:02:46 ==> Loss 
2016-12-09 23:02:46 SqrtHingeEmbeddingCriterion 
2016-12-09 23:02:46 
==> Starting Training
 
2016-12-09 23:02:46 Epoch 1 
2016-12-09 23:03:42 Training Error = 0.96246793573647 
2016-12-09 23:03:42 Training Loss = 0.81531109793857 
2016-12-09 23:03:44 Valid Error = 0.94896719319563 
2016-12-09 23:03:44 Valid Loss = 0.44991962767645 
2016-12-09 23:03:46 Test Error = 0.96506550218341 
2016-12-09 23:03:46 Test Loss = 0.45447684281792 
2016-12-09 23:03:46 -------------------LR------------------- 
2016-12-09 23:03:46 0.015625 
2016-12-09 23:03:46 Epoch 2 
2016-12-09 23:04:52 Training Error = 0.90144457945187 
2016-12-09 23:04:52 Training Loss = 0.28981380183357 
2016-12-09 23:04:54 Valid Error = 0.79708383961118 
2016-12-09 23:04:54 Valid Loss = 0.15453528836076 
2016-12-09 23:04:56 Test Error = 0.80786026200873 
2016-12-09 23:04:56 Test Loss = 0.15490692690307 
2016-12-09 23:04:56 -------------------LR------------------- 
2016-12-09 23:04:56 0.015625 
2016-12-09 23:04:56 Epoch 3 
2016-12-09 23:05:52 Training Error = 0.77102740650736 
2016-12-09 23:05:52 Training Loss = 0.1087989282881 
2016-12-09 23:05:54 Valid Error = 0.86391251518834 
2016-12-09 23:05:54 Valid Loss = 0.071608841078189 
2016-12-09 23:05:56 Test Error = 0.89519650655022 
2016-12-09 23:05:56 Test Loss = 0.071893908790514 
2016-12-09 23:05:56 -------------------LR------------------- 
2016-12-09 23:05:56 0.015625 
2016-12-09 23:05:56 Epoch 4 
2016-12-09 23:06:52 Training Error = 0.73849061698393 
2016-12-09 23:06:52 Training Loss = 0.054440894574542 
2016-12-09 23:06:54 Valid Error = 0.86391251518834 
2016-12-09 23:06:54 Valid Loss = 0.04553443878802 
2016-12-09 23:06:56 Test Error = 0.89519650655022 
2016-12-09 23:06:56 Test Loss = 0.046670619864869 
2016-12-09 23:06:56 -------------------LR------------------- 
2016-12-09 23:06:56 0.015625 
2016-12-09 23:06:56 Epoch 5 
2016-12-09 23:07:52 Training Error = 0.73835560955853 
2016-12-09 23:07:52 Training Loss = 0.038943961822114 
2016-12-09 23:07:54 Valid Error = 0.86391251518834 
2016-12-09 23:07:54 Valid Loss = 0.042096335079205 
2016-12-09 23:07:56 Test Error = 0.89519650655022 
2016-12-09 23:07:56 Test Loss = 0.042649587852503 
2016-12-09 23:07:56 -------------------LR------------------- 
2016-12-09 23:07:56 0.015625 
2016-12-09 23:07:56 Epoch 6 
2016-12-09 23:08:52 Training Error = 0.7218847036587 
2016-12-09 23:08:52 Training Loss = 0.034114987280035 
2016-12-09 23:08:54 Valid Error = 0.82624544349939 
2016-12-09 23:08:54 Valid Loss = 0.035879103588478 
2016-12-09 23:08:56 Test Error = 0.85262008733624 
2016-12-09 23:08:56 Test Loss = 0.037461478866004 
2016-12-09 23:08:56 -------------------LR------------------- 
2016-12-09 23:08:56 0.015625 
2016-12-09 23:08:56 Epoch 7 
2016-12-09 23:10:03 Training Error = 0.66018631024706 
2016-12-09 23:10:03 Training Loss = 0.031966071684609 
2016-12-09 23:10:05 Valid Error = 0.76306196840826 
2016-12-09 23:10:05 Valid Loss = 0.035160444059828 
2016-12-09 23:10:07 Test Error = 0.79803493449782 
2016-12-09 23:10:07 Test Loss = 0.036546595003091 
2016-12-09 23:10:07 -------------------LR------------------- 
2016-12-09 23:10:07 0.015625 
2016-12-09 23:10:07 Epoch 8 
2016-12-09 23:11:10 Training Error = 0.64061023356285 
2016-12-09 23:11:10 Training Loss = 0.03052465152782 
2016-12-09 23:11:12 Valid Error = 0.85419198055893 
2016-12-09 23:11:12 Valid Loss = 0.034585457098217 
2016-12-09 23:11:14 Test Error = 0.87336244541485 
2016-12-09 23:11:14 Test Loss = 0.036035597308788 
2016-12-09 23:11:14 -------------------LR------------------- 
2016-12-09 23:11:14 0.015625 
2016-12-09 23:11:14 Epoch 9 
2016-12-09 23:12:21 Training Error = 0.63845011475631 
2016-12-09 23:12:21 Training Loss = 0.029183849763486 
2016-12-09 23:12:23 Valid Error = 0.85419198055893 
2016-12-09 23:12:23 Valid Loss = 0.037302143250433 
2016-12-09 23:12:25 Test Error = 0.87336244541485 
2016-12-09 23:12:25 Test Loss = 0.038572975599688 
2016-12-09 23:12:25 -------------------LR------------------- 
2016-12-09 23:12:25 0.015625 
2016-12-09 23:12:25 Epoch 10 
2016-12-09 23:13:35 Training Error = 0.63426488456865 
2016-12-09 23:13:35 Training Loss = 0.028315834236633 
2016-12-09 23:13:37 Valid Error = 0.76306196840826 
2016-12-09 23:13:37 Valid Loss = 0.035842143660971 
2016-12-09 23:13:39 Test Error = 0.79803493449782 
2016-12-09 23:13:39 Test Loss = 0.037925304197798 
2016-12-09 23:13:39 -------------------LR------------------- 
2016-12-09 23:13:39 0.015625 
2016-12-09 23:13:39 Epoch 11 
2016-12-09 23:14:40 Training Error = 0.6318347509113 
2016-12-09 23:14:40 Training Loss = 0.028407337926655 
2016-12-09 23:14:42 Valid Error = 0.76306196840826 
2016-12-09 23:14:42 Valid Loss = 0.03625047294688 
2016-12-09 23:14:44 Test Error = 0.79803493449782 
2016-12-09 23:14:44 Test Loss = 0.038164806023143 
2016-12-09 23:14:44 -------------------LR------------------- 
2016-12-09 23:14:44 0.015625 
2016-12-09 23:14:44 Epoch 12 
2016-12-09 23:15:46 Training Error = 0.63412987714324 
2016-12-09 23:15:46 Training Loss = 0.02847063393101 
2016-12-09 23:15:48 Valid Error = 0.76306196840826 
2016-12-09 23:15:48 Valid Loss = 0.037795522277946 
2016-12-09 23:15:50 Test Error = 0.79803493449782 
2016-12-09 23:15:50 Test Loss = 0.039563833327075 
2016-12-09 23:15:50 -------------------LR------------------- 
2016-12-09 23:15:50 0.015625 
2016-12-09 23:15:50 Epoch 13 
2016-12-09 23:16:54 Training Error = 0.63331983259079 
2016-12-09 23:16:54 Training Loss = 0.028448002674377 
2016-12-09 23:16:56 Valid Error = 0.76306196840826 
2016-12-09 23:16:56 Valid Loss = 0.037696674257144 
2016-12-09 23:16:58 Test Error = 0.79803493449782 
2016-12-09 23:16:58 Test Loss = 0.039474886632433 
2016-12-09 23:16:58 -------------------LR------------------- 
2016-12-09 23:16:58 0.015625 
2016-12-09 23:16:58 Epoch 14 
2016-12-09 23:18:00 Training Error = 0.63304981773998 
2016-12-09 23:18:00 Training Loss = 0.028503609808889 
2016-12-09 23:18:02 Valid Error = 0.76306196840826 
2016-12-09 23:18:02 Valid Loss = 0.036535860307227 
2016-12-09 23:18:04 Test Error = 0.79803493449782 
2016-12-09 23:18:04 Test Loss = 0.038415127548517 
2016-12-09 23:18:04 -------------------LR------------------- 
2016-12-09 23:18:04 0.015625 
2016-12-09 23:18:04 Epoch 15 
2016-12-09 23:19:08 Training Error = 0.63237478061293 
2016-12-09 23:19:08 Training Loss = 0.02840379400359 
2016-12-09 23:19:09 Valid Error = 0.76306196840826 
2016-12-09 23:19:09 Valid Loss = 0.036300696108351 
2016-12-09 23:19:11 Test Error = 0.79803493449782 
2016-12-09 23:19:11 Test Loss = 0.038207166428659 
2016-12-09 23:19:11 -------------------LR------------------- 
2016-12-09 23:19:11 0.015625 
2016-12-09 23:19:11 Epoch 16 
2016-12-09 23:20:15 Training Error = 0.63426488456865 
2016-12-09 23:20:15 Training Loss = 0.028413884691529 
2016-12-09 23:20:17 Valid Error = 0.76306196840826 
2016-12-09 23:20:17 Valid Loss = 0.036662129467819 
2016-12-09 23:20:19 Test Error = 0.79803493449782 
2016-12-09 23:20:19 Test Loss = 0.038532487364376 
2016-12-09 23:20:19 -------------------LR------------------- 
2016-12-09 23:20:19 0.015625 
2016-12-09 23:20:19 Epoch 17 
2016-12-09 23:21:22 Training Error = 0.63264479546375 
2016-12-09 23:21:22 Training Loss = 0.028408882203409 
2016-12-09 23:21:23 Valid Error = 0.76306196840826 
2016-12-09 23:21:23 Valid Loss = 0.036335961861111 
2016-12-09 23:21:26 Test Error = 0.79803493449782 
2016-12-09 23:21:26 Test Loss = 0.038222347256405 
2016-12-09 23:21:26 -------------------LR------------------- 
2016-12-09 23:21:26 0.015625 
2016-12-09 23:21:26 Epoch 18 
2016-12-09 23:22:28 Training Error = 0.63412987714324 
2016-12-09 23:22:28 Training Loss = 0.028497110991041 
2016-12-09 23:22:30 Valid Error = 0.76306196840826 
2016-12-09 23:22:30 Valid Loss = 0.037049960984059 
2016-12-09 23:22:32 Test Error = 0.79803493449782 
2016-12-09 23:22:32 Test Loss = 0.038899613424064 
2016-12-09 23:22:32 -------------------LR------------------- 
2016-12-09 23:22:32 0.015625 
2016-12-09 23:22:32 Epoch 19 
2016-12-09 23:23:36 Training Error = 0.63385986229243 
2016-12-09 23:23:36 Training Loss = 0.028494717098206 
2016-12-09 23:23:38 Valid Error = 0.76306196840826 
2016-12-09 23:23:38 Valid Loss = 0.036481133691346 
2016-12-09 23:23:40 Test Error = 0.79803493449782 
2016-12-09 23:23:40 Test Loss = 0.038337715466817 
2016-12-09 23:23:40 -------------------LR------------------- 
2016-12-09 23:23:40 0.015625 
2016-12-09 23:23:40 Epoch 20 
2016-12-09 23:24:52 Training Error = 0.63399486971783 
2016-12-09 23:24:52 Training Loss = 0.028467166855467 
2016-12-09 23:24:54 Valid Error = 0.76306196840826 
2016-12-09 23:24:54 Valid Loss = 0.037861652749003 
2016-12-09 23:24:56 Test Error = 0.79803493449782 
2016-12-09 23:24:56 Test Loss = 0.039637616646835 
2016-12-09 23:24:56 -------------------LR------------------- 
2016-12-09 23:24:56 0.015625 
2016-12-09 23:24:56 Epoch 21 
2016-12-09 23:25:57 Training Error = 0.63264479546375 
2016-12-09 23:25:57 Training Loss = 0.028438254837856 
2016-12-09 23:25:59 Valid Error = 0.76306196840826 
2016-12-09 23:25:59 Valid Loss = 0.03675789644667 
2016-12-09 23:26:01 Test Error = 0.79803493449782 
2016-12-09 23:26:01 Test Loss = 0.038635075388391 
2016-12-09 23:26:01 -------------------LR------------------- 
2016-12-09 23:26:01 0.015625 
2016-12-09 23:26:01 Epoch 22 
2016-12-09 23:27:04 Training Error = 0.63426488456865 
2016-12-09 23:27:04 Training Loss = 0.028510057165723 
2016-12-09 23:27:06 Valid Error = 0.76306196840826 
2016-12-09 23:27:06 Valid Loss = 0.036057573099696 
2016-12-09 23:27:08 Test Error = 0.79803493449782 
2016-12-09 23:27:08 Test Loss = 0.037970288968554 
2016-12-09 23:27:08 -------------------LR------------------- 
2016-12-09 23:27:08 0.015625 
2016-12-09 23:27:08 Epoch 23 
2016-12-09 23:28:10 Training Error = 0.63196975833671 
2016-12-09 23:28:10 Training Loss = 0.028421508333481 
2016-12-09 23:28:12 Valid Error = 0.76306196840826 
2016-12-09 23:28:12 Valid Loss = 0.03772607769039 
2016-12-09 23:28:14 Test Error = 0.79803493449782 
2016-12-09 23:28:14 Test Loss = 0.039500091605716 
2016-12-09 23:28:14 -------------------LR------------------- 
2016-12-09 23:28:14 0.015625 
2016-12-09 23:28:14 Epoch 24 
2016-12-09 23:29:17 Training Error = 0.63412987714324 
2016-12-09 23:29:17 Training Loss = 0.028522776574303 
2016-12-09 23:29:19 Valid Error = 0.76306196840826 
2016-12-09 23:29:19 Valid Loss = 0.036445349798368 
2016-12-09 23:29:21 Test Error = 0.79803493449782 
2016-12-09 23:29:21 Test Loss = 0.038365485247444 
2016-12-09 23:29:21 -------------------LR------------------- 
2016-12-09 23:29:21 0.015625 
2016-12-09 23:29:21 Epoch 25 
2016-12-09 23:30:24 Training Error = 0.63277980288916 
2016-12-09 23:30:24 Training Loss = 0.028463864666772 
2016-12-09 23:30:26 Valid Error = 0.76306196840826 
2016-12-09 23:30:26 Valid Loss = 0.038219633740548 
2016-12-09 23:30:28 Test Error = 0.79803493449782 
2016-12-09 23:30:28 Test Loss = 0.039940048510732 
2016-12-09 23:30:28 -------------------LR------------------- 
2016-12-09 23:30:28 0.015625 
2016-12-09 23:30:28 Epoch 26 
2016-12-09 23:31:31 Training Error = 0.63264479546375 
2016-12-09 23:31:31 Training Loss = 0.028402445087901 
2016-12-09 23:31:33 Valid Error = 0.76306196840826 
2016-12-09 23:31:33 Valid Loss = 0.036225599527105 
2016-12-09 23:31:35 Test Error = 0.79803493449782 
2016-12-09 23:31:35 Test Loss = 0.038120543551601 
2016-12-09 23:31:35 -------------------LR------------------- 
2016-12-09 23:31:35 0.015625 
2016-12-09 23:31:35 Epoch 27 
2016-12-09 23:32:37 Training Error = 0.63250978803834 
2016-12-09 23:32:37 Training Loss = 0.028470984663751 
2016-12-09 23:32:39 Valid Error = 0.76306196840826 
2016-12-09 23:32:39 Valid Loss = 0.036857465187618 
2016-12-09 23:32:41 Test Error = 0.79803493449782 
2016-12-09 23:32:41 Test Loss = 0.038675426829095 
2016-12-09 23:32:41 -------------------LR------------------- 
2016-12-09 23:32:41 0.015625 
2016-12-09 23:32:41 Epoch 28 
2016-12-09 23:33:44 Training Error = 0.63412987714324 
2016-12-09 23:33:44 Training Loss = 0.02837450579157 
2016-12-09 23:33:46 Valid Error = 0.76306196840826 
2016-12-09 23:33:46 Valid Loss = 0.036750667390934 
2016-12-09 23:33:48 Test Error = 0.79803493449782 
2016-12-09 23:33:48 Test Loss = 0.038612506249372 
2016-12-09 23:33:48 -------------------LR------------------- 
2016-12-09 23:33:48 0.015625 
2016-12-09 23:33:48 Epoch 29 
2016-12-09 23:34:50 Training Error = 0.63318482516538 
2016-12-09 23:34:50 Training Loss = 0.028478331496208 
2016-12-09 23:34:52 Valid Error = 0.76306196840826 
2016-12-09 23:34:52 Valid Loss = 0.036529897410324 
2016-12-09 23:34:54 Test Error = 0.79803493449782 
2016-12-09 23:34:54 Test Loss = 0.038429353564393 
2016-12-09 23:34:54 -------------------LR------------------- 
2016-12-09 23:34:54 0.015625 
2016-12-09 23:34:54 Epoch 30 
2016-12-09 23:36:07 Training Error = 0.63318482516538 
2016-12-09 23:36:07 Training Loss = 0.028479224443377 
2016-12-09 23:36:09 Valid Error = 0.76306196840826 
2016-12-09 23:36:09 Valid Loss = 0.037216311692108 
2016-12-09 23:36:11 Test Error = 0.79803493449782 
2016-12-09 23:36:11 Test Loss = 0.039045330434064 
2016-12-09 23:36:11 -------------------LR------------------- 
2016-12-09 23:36:11 0.015625 
2016-12-09 23:36:11 Epoch 31 
2016-12-09 23:37:14 Training Error = 0.63277980288916 
2016-12-09 23:37:14 Training Loss = 0.028428254090194 
2016-12-09 23:37:16 Valid Error = 0.76306196840826 
2016-12-09 23:37:16 Valid Loss = 0.037757789102504 
2016-12-09 23:37:18 Test Error = 0.79803493449782 
2016-12-09 23:37:18 Test Loss = 0.039502657036376 
2016-12-09 23:37:18 -------------------LR------------------- 
2016-12-09 23:37:18 0.015625 
2016-12-09 23:37:18 Epoch 32 
2016-12-09 23:38:20 Training Error = 0.63318482516538 
2016-12-09 23:38:20 Training Loss = 0.0284863143905 
2016-12-09 23:38:22 Valid Error = 0.76306196840826 
2016-12-09 23:38:22 Valid Loss = 0.036411683409156 
2016-12-09 23:38:24 Test Error = 0.79803493449782 
2016-12-09 23:38:24 Test Loss = 0.038306398983874 
2016-12-09 23:38:24 -------------------LR------------------- 
2016-12-09 23:38:24 0.015625 
2016-12-09 23:38:24 Epoch 33 
2016-12-09 23:39:27 Training Error = 0.63318482516538 
2016-12-09 23:39:27 Training Loss = 0.02843168203779 
2016-12-09 23:39:29 Valid Error = 0.76306196840826 
2016-12-09 23:39:29 Valid Loss = 0.037855404518096 
2016-12-09 23:39:31 Test Error = 0.79803493449782 
2016-12-09 23:39:31 Test Loss = 0.039635080231561 
2016-12-09 23:39:31 -------------------LR------------------- 
2016-12-09 23:39:31 0.015625 
2016-12-09 23:39:31 Epoch 34 
2016-12-09 23:40:35 Training Error = 0.63372485486702 
2016-12-09 23:40:35 Training Loss = 0.028476121378338 
2016-12-09 23:40:36 Valid Error = 0.76306196840826 
2016-12-09 23:40:36 Valid Loss = 0.037096795617148 
2016-12-09 23:40:38 Test Error = 0.79803493449782 
2016-12-09 23:40:38 Test Loss = 0.038883724524305 
2016-12-09 23:40:38 -------------------LR------------------- 
2016-12-09 23:40:38 0.015625 
2016-12-09 23:40:38 Epoch 35 
2016-12-09 23:41:42 Training Error = 0.63385986229243 
2016-12-09 23:41:42 Training Loss = 0.028433870221856 
2016-12-09 23:41:44 Valid Error = 0.76306196840826 
2016-12-09 23:41:44 Valid Loss = 0.036569592980796 
2016-12-09 23:41:46 Test Error = 0.79803493449782 
2016-12-09 23:41:46 Test Loss = 0.038415070094314 
2016-12-09 23:41:46 -------------------LR------------------- 
2016-12-09 23:41:46 0.015625 
2016-12-09 23:41:46 Epoch 36 
2016-12-09 23:42:50 Training Error = 0.63331983259079 
2016-12-09 23:42:50 Training Loss = 0.0285043916301 
2016-12-09 23:42:52 Valid Error = 0.76306196840826 
2016-12-09 23:42:52 Valid Loss = 0.036700656356103 
2016-12-09 23:42:54 Test Error = 0.79803493449782 
2016-12-09 23:42:54 Test Loss = 0.038538088611528 
2016-12-09 23:42:54 -------------------LR------------------- 
2016-12-09 23:42:54 0.015625 
2016-12-09 23:42:54 Epoch 37 
2016-12-09 23:43:56 Training Error = 0.63264479546375 
2016-12-09 23:43:56 Training Loss = 0.028460023414559 
2016-12-09 23:43:58 Valid Error = 0.76306196840826 
2016-12-09 23:43:58 Valid Loss = 0.036300724712711 
2016-12-09 23:44:00 Test Error = 0.79803493449782 
2016-12-09 23:44:00 Test Loss = 0.038218265156341 
2016-12-09 23:44:00 -------------------LR------------------- 
2016-12-09 23:44:00 0.015625 
2016-12-09 23:44:00 Epoch 38 
2016-12-09 23:45:03 Training Error = 0.63399486971783 
2016-12-09 23:45:03 Training Loss = 0.028459821550478 
2016-12-09 23:45:05 Valid Error = 0.76306196840826 
2016-12-09 23:45:05 Valid Loss = 0.036698559716763 
2016-12-09 23:45:07 Test Error = 0.79803493449782 
2016-12-09 23:45:07 Test Loss = 0.038563966143365 
2016-12-09 23:45:07 -------------------LR------------------- 
2016-12-09 23:45:07 0.015625 
2016-12-09 23:45:07 Epoch 39 
2016-12-09 23:46:11 Training Error = 0.63264479546375 
2016-12-09 23:46:11 Training Loss = 0.028398028552312 
2016-12-09 23:46:13 Valid Error = 0.76306196840826 
2016-12-09 23:46:13 Valid Loss = 0.037810332926077 
2016-12-09 23:46:15 Test Error = 0.79803493449782 
2016-12-09 23:46:15 Test Loss = 0.039580484745549 
2016-12-09 23:46:15 -------------------LR------------------- 
2016-12-09 23:46:15 0.015625 
2016-12-09 23:46:15 Epoch 40 
2016-12-09 23:47:28 Training Error = 0.6318347509113 
2016-12-09 23:47:28 Training Loss = 0.028452876364847 
2016-12-09 23:47:30 Valid Error = 0.76306196840826 
2016-12-09 23:47:30 Valid Loss = 0.037224767163494 
2016-12-09 23:47:32 Test Error = 0.79803493449782 
2016-12-09 23:47:32 Test Loss = 0.039029840051738 
2016-12-09 23:47:32 -------------------LR------------------- 
2016-12-09 23:47:32 0.015625 
2016-12-09 23:47:32 Epoch 41 
2016-12-09 23:48:35 Training Error = 0.63210476576212 
2016-12-09 23:48:35 Training Loss = 0.028393747061848 
2016-12-09 23:48:37 Valid Error = 0.76306196840826 
2016-12-09 23:48:37 Valid Loss = 0.037994698596655 
2016-12-09 23:48:39 Test Error = 0.79803493449782 
2016-12-09 23:48:39 Test Loss = 0.039720200728747 
2016-12-09 23:48:39 -------------------LR------------------- 
2016-12-09 23:48:39 0.015625 
2016-12-09 23:48:39 Epoch 42 
2016-12-09 23:49:42 Training Error = 0.63318482516538 
2016-12-09 23:49:42 Training Loss = 0.028519623506341 
2016-12-09 23:49:44 Valid Error = 0.76306196840826 
2016-12-09 23:49:44 Valid Loss = 0.036843938104225 
2016-12-09 23:49:46 Test Error = 0.79803493449782 
2016-12-09 23:49:46 Test Loss = 0.038649872751797 
2016-12-09 23:49:46 -------------------LR------------------- 
2016-12-09 23:49:46 0.015625 
2016-12-09 23:49:46 Epoch 43 
2016-12-09 23:50:50 Training Error = 0.63385986229243 
2016-12-09 23:50:50 Training Loss = 0.028477274847396 
2016-12-09 23:50:52 Valid Error = 0.76306196840826 
2016-12-09 23:50:52 Valid Loss = 0.037092471260496 
2016-12-09 23:50:54 Test Error = 0.79803493449782 
2016-12-09 23:50:54 Test Loss = 0.038922430907979 
2016-12-09 23:50:54 -------------------LR------------------- 
2016-12-09 23:50:54 0.015625 
2016-12-09 23:50:54 Epoch 44 
2016-12-09 23:51:56 Training Error = 0.6334548400162 
2016-12-09 23:51:56 Training Loss = 0.02842842830258 
2016-12-09 23:51:58 Valid Error = 0.76306196840826 
2016-12-09 23:51:58 Valid Loss = 0.036364616101038 
2016-12-09 23:52:00 Test Error = 0.79803493449782 
2016-12-09 23:52:00 Test Loss = 0.038262634464339 
2016-12-09 23:52:00 -------------------LR------------------- 
2016-12-09 23:52:00 0.015625 
2016-12-09 23:52:00 Epoch 45 
2016-12-09 23:53:01 Training Error = 0.63291481031457 
2016-12-09 23:53:01 Training Loss = 0.028408703932419 
2016-12-09 23:53:03 Valid Error = 0.76306196840826 
2016-12-09 23:53:03 Valid Loss = 0.038048356899032 
2016-12-09 23:53:05 Test Error = 0.79803493449782 
2016-12-09 23:53:05 Test Loss = 0.039836905703825 
2016-12-09 23:53:05 -------------------LR------------------- 
2016-12-09 23:53:05 0.015625 
2016-12-09 23:53:05 Epoch 46 
2016-12-09 23:54:09 Training Error = 0.63250978803834 
2016-12-09 23:54:09 Training Loss = 0.028423000073864 
2016-12-09 23:54:11 Valid Error = 0.76306196840826 
2016-12-09 23:54:11 Valid Loss = 0.036722590414058 
2016-12-09 23:54:13 Test Error = 0.79803493449782 
2016-12-09 23:54:13 Test Loss = 0.038546743704603 
2016-12-09 23:54:13 -------------------LR------------------- 
2016-12-09 23:54:13 0.015625 
2016-12-09 23:54:13 Epoch 47 
2016-12-09 23:55:22 Training Error = 0.63277980288916 
2016-12-09 23:55:22 Training Loss = 0.028408464243539 
2016-12-09 23:55:24 Valid Error = 0.76306196840826 
2016-12-09 23:55:24 Valid Loss = 0.036861769174769 
2016-12-09 23:55:26 Test Error = 0.79803493449782 
2016-12-09 23:55:26 Test Loss = 0.038673137449751 
2016-12-09 23:55:26 -------------------LR------------------- 
2016-12-09 23:55:26 0.015625 
2016-12-09 23:55:26 Epoch 48 
2016-12-09 23:56:34 Training Error = 0.63277980288916 
2016-12-09 23:56:34 Training Loss = 0.028462802871281 
2016-12-09 23:56:36 Valid Error = 0.76306196840826 
2016-12-09 23:56:36 Valid Loss = 0.03714317173374 
2016-12-09 23:56:38 Test Error = 0.79803493449782 
2016-12-09 23:56:38 Test Loss = 0.038954576308431 
2016-12-09 23:56:38 -------------------LR------------------- 
2016-12-09 23:56:38 0.015625 
2016-12-09 23:56:38 Epoch 49 
2016-12-09 23:57:47 Training Error = 0.63250978803834 
2016-12-09 23:57:47 Training Loss = 0.028439990692269 
2016-12-09 23:57:49 Valid Error = 0.76306196840826 
2016-12-09 23:57:49 Valid Loss = 0.036755521241296 
2016-12-09 23:57:51 Test Error = 0.79803493449782 
2016-12-09 23:57:51 Test Loss = 0.038626458894194 
2016-12-09 23:57:51 -------------------LR------------------- 
2016-12-09 23:57:51 0.015625 
2016-12-09 23:57:51 Epoch 50 
2016-12-09 23:59:11 Training Error = 0.63237478061293 
2016-12-09 23:59:11 Training Loss = 0.028443785489079 
2016-12-09 23:59:13 Valid Error = 0.76306196840826 
2016-12-09 23:59:13 Valid Loss = 0.03663805928971 
2016-12-09 23:59:15 Test Error = 0.79803493449782 
2016-12-09 23:59:15 Test Loss = 0.038533791077682 
2016-12-09 23:59:15 -------------------LR------------------- 
2016-12-09 23:59:15 0.0078125 
2016-12-09 23:59:15 Epoch 51 
2016-12-10 00:00:27 Training Error = 0.63304981773998 
2016-12-10 00:00:27 Training Loss = 0.028489968894907 
2016-12-10 00:00:29 Valid Error = 0.76306196840826 
2016-12-10 00:00:29 Valid Loss = 0.03747725892582 
2016-12-10 00:00:31 Test Error = 0.79803493449782 
2016-12-10 00:00:31 Test Loss = 0.039252598550585 
2016-12-10 00:00:31 -------------------LR------------------- 
2016-12-10 00:00:31 0.0078125 
2016-12-10 00:00:31 Epoch 52 
2016-12-10 00:01:35 Training Error = 0.63304981773998 
2016-12-10 00:01:35 Training Loss = 0.028442426132024 
2016-12-10 00:01:37 Valid Error = 0.76306196840826 
2016-12-10 00:01:37 Valid Loss = 0.036784785689673 
2016-12-10 00:01:39 Test Error = 0.79803493449782 
2016-12-10 00:01:39 Test Loss = 0.038633420716703 
2016-12-10 00:01:39 -------------------LR------------------- 
2016-12-10 00:01:39 0.0078125 
2016-12-10 00:01:39 Epoch 53 
2016-12-10 00:02:43 Training Error = 0.63277980288916 
2016-12-10 00:02:43 Training Loss = 0.028405838132661 
2016-12-10 00:02:45 Valid Error = 0.76306196840826 
2016-12-10 00:02:45 Valid Loss = 0.038085853785886 
2016-12-10 00:02:47 Test Error = 0.79803493449782 
2016-12-10 00:02:47 Test Loss = 0.039821177276911 
2016-12-10 00:02:47 -------------------LR------------------- 
2016-12-10 00:02:47 0.0078125 
2016-12-10 00:02:47 Epoch 54 
2016-12-10 00:03:51 Training Error = 0.63331983259079 
2016-12-10 00:03:51 Training Loss = 0.028425653008528 
2016-12-10 00:03:53 Valid Error = 0.76306196840826 
2016-12-10 00:03:53 Valid Loss = 0.037263221148525 
2016-12-10 00:03:55 Test Error = 0.79803493449782 
2016-12-10 00:03:55 Test Loss = 0.039085055815628 
2016-12-10 00:03:55 -------------------LR------------------- 
2016-12-10 00:03:55 0.0078125 
2016-12-10 00:03:55 Epoch 55 
2016-12-10 00:04:59 Training Error = 0.63169974348589 
2016-12-10 00:04:59 Training Loss = 0.028429226969887 
2016-12-10 00:05:01 Valid Error = 0.76306196840826 
2016-12-10 00:05:01 Valid Loss = 0.036893117257252 
2016-12-10 00:05:03 Test Error = 0.79803493449782 
2016-12-10 00:05:03 Test Loss = 0.038692605168212 
2016-12-10 00:05:03 -------------------LR------------------- 
2016-12-10 00:05:03 0.0078125 
2016-12-10 00:05:03 Epoch 56 
2016-12-10 00:06:06 Training Error = 0.63358984744161 
2016-12-10 00:06:06 Training Loss = 0.028497313785941 
2016-12-10 00:06:08 Valid Error = 0.76306196840826 
2016-12-10 00:06:08 Valid Loss = 0.036542120732404 
2016-12-10 00:06:10 Test Error = 0.79803493449782 
2016-12-10 00:06:10 Test Loss = 0.038426164225036 
2016-12-10 00:06:10 -------------------LR------------------- 
2016-12-10 00:06:10 0.0078125 
2016-12-10 00:06:10 Epoch 57 
2016-12-10 00:07:13 Training Error = 0.63264479546375 
2016-12-10 00:07:13 Training Loss = 0.028475417681202 
2016-12-10 00:07:15 Valid Error = 0.76306196840826 
2016-12-10 00:07:15 Valid Loss = 0.036428225250141 
2016-12-10 00:07:17 Test Error = 0.79803493449782 
2016-12-10 00:07:17 Test Loss = 0.038303707160202 
2016-12-10 00:07:17 -------------------LR------------------- 
2016-12-10 00:07:17 0.0078125 
2016-12-10 00:07:17 Epoch 58 
2016-12-10 00:08:19 Training Error = 0.63412987714324 
2016-12-10 00:08:19 Training Loss = 0.028402915111215 
2016-12-10 00:08:21 Valid Error = 0.76306196840826 
2016-12-10 00:08:21 Valid Loss = 0.036434737950625 
2016-12-10 00:08:23 Test Error = 0.79803493449782 
2016-12-10 00:08:23 Test Loss = 0.038305644599441 
2016-12-10 00:08:23 -------------------LR------------------- 
2016-12-10 00:08:23 0.0078125 
2016-12-10 00:08:23 Epoch 59 
2016-12-10 00:09:26 Training Error = 0.63304981773998 
2016-12-10 00:09:26 Training Loss = 0.028439614504798 
2016-12-10 00:09:28 Valid Error = 0.76306196840826 
2016-12-10 00:09:28 Valid Loss = 0.036915042185903 
2016-12-10 00:09:30 Test Error = 0.79803493449782 
2016-12-10 00:09:30 Test Loss = 0.038758818043603 
2016-12-10 00:09:30 -------------------LR------------------- 
2016-12-10 00:09:30 0.0078125 
2016-12-10 00:09:30 Epoch 60 
2016-12-10 00:10:42 Training Error = 0.63264479546375 
2016-12-10 00:10:42 Training Loss = 0.028387905003558 
2016-12-10 00:10:44 Valid Error = 0.76306196840826 
2016-12-10 00:10:44 Valid Loss = 0.036610446512039 
2016-12-10 00:10:46 Test Error = 0.79803493449782 
2016-12-10 00:10:46 Test Loss = 0.038462284967011 
2016-12-10 00:10:46 -------------------LR------------------- 
2016-12-10 00:10:46 0.0078125 
2016-12-10 00:10:46 Epoch 61 
2016-12-10 00:11:48 Training Error = 0.63291481031457 
2016-12-10 00:11:48 Training Loss = 0.028395904451403 
2016-12-10 00:11:49 Valid Error = 0.76306196840826 
2016-12-10 00:11:49 Valid Loss = 0.036417766638762 
2016-12-10 00:11:52 Test Error = 0.79803493449782 
2016-12-10 00:11:52 Test Loss = 0.038281754200755 
2016-12-10 00:11:52 -------------------LR------------------- 
2016-12-10 00:11:52 0.0078125 
2016-12-10 00:11:52 Epoch 62 
2016-12-10 00:12:53 Training Error = 0.63250978803834 
2016-12-10 00:12:53 Training Loss = 0.028410020861454 
2016-12-10 00:12:55 Valid Error = 0.76306196840826 
2016-12-10 00:12:55 Valid Loss = 0.036962633621059 
2016-12-10 00:12:57 Test Error = 0.79803493449782 
2016-12-10 00:12:57 Test Loss = 0.038822517753427 
2016-12-10 00:12:57 -------------------LR------------------- 
2016-12-10 00:12:57 0.0078125 
2016-12-10 00:12:57 Epoch 63 
2016-12-10 00:14:00 Training Error = 0.63264479546375 
2016-12-10 00:14:00 Training Loss = 0.02848155529488 
2016-12-10 00:14:02 Valid Error = 0.76306196840826 
2016-12-10 00:14:02 Valid Loss = 0.037147771215793 
2016-12-10 00:14:04 Test Error = 0.79803493449782 
2016-12-10 00:14:04 Test Loss = 0.039004081666859 
2016-12-10 00:14:04 -------------------LR------------------- 
2016-12-10 00:14:04 0.0078125 
2016-12-10 00:14:04 Epoch 64 
2016-12-10 00:15:05 Training Error = 0.63372485486702 
2016-12-10 00:15:05 Training Loss = 0.028479491298307 
2016-12-10 00:15:07 Valid Error = 0.76306196840826 
2016-12-10 00:15:07 Valid Loss = 0.03690983468977 
2016-12-10 00:15:09 Test Error = 0.79803493449782 
2016-12-10 00:15:09 Test Loss = 0.038774784826765 
2016-12-10 00:15:09 -------------------LR------------------- 
2016-12-10 00:15:09 0.0078125 
2016-12-10 00:15:09 Epoch 65 
2016-12-10 00:16:11 Training Error = 0.6334548400162 
2016-12-10 00:16:11 Training Loss = 0.028397511345127 
2016-12-10 00:16:13 Valid Error = 0.76306196840826 
2016-12-10 00:16:13 Valid Loss = 0.036728699141317 
2016-12-10 00:16:15 Test Error = 0.79803493449782 
2016-12-10 00:16:15 Test Loss = 0.038559398666706 
2016-12-10 00:16:15 -------------------LR------------------- 
2016-12-10 00:16:15 0.0078125 
2016-12-10 00:16:15 Epoch 66 
2016-12-10 00:17:17 Training Error = 0.63237478061293 
2016-12-10 00:17:17 Training Loss = 0.028409482363366 
2016-12-10 00:17:19 Valid Error = 0.76306196840826 
2016-12-10 00:17:19 Valid Loss = 0.036613068906308 
2016-12-10 00:17:21 Test Error = 0.79803493449782 
2016-12-10 00:17:21 Test Loss = 0.038414744551665 
2016-12-10 00:17:21 -------------------LR------------------- 
2016-12-10 00:17:21 0.0078125 
2016-12-10 00:17:21 Epoch 67 
2016-12-10 00:18:23 Training Error = 0.63358984744161 
2016-12-10 00:18:23 Training Loss = 0.028373746274179 
2016-12-10 00:18:25 Valid Error = 0.76306196840826 
2016-12-10 00:18:25 Valid Loss = 0.036651806543786 
2016-12-10 00:18:27 Test Error = 0.79803493449782 
2016-12-10 00:18:27 Test Loss = 0.038451698325039 
2016-12-10 00:18:27 -------------------LR------------------- 
2016-12-10 00:18:27 0.0078125 
2016-12-10 00:18:27 Epoch 68 
2016-12-10 00:19:30 Training Error = 0.63304981773998 
2016-12-10 00:19:30 Training Loss = 0.02846000348693 
2016-12-10 00:19:32 Valid Error = 0.76306196840826 
2016-12-10 00:19:32 Valid Loss = 0.036334120597822 
2016-12-10 00:19:34 Test Error = 0.79803493449782 
2016-12-10 00:19:34 Test Loss = 0.038182017803192 
2016-12-10 00:19:34 -------------------LR------------------- 
2016-12-10 00:19:34 0.0078125 
2016-12-10 00:19:34 Epoch 69 
2016-12-10 00:20:34 Training Error = 0.63399486971783 
2016-12-10 00:20:34 Training Loss = 0.028487811768989 
2016-12-10 00:20:36 Valid Error = 0.76306196840826 
2016-12-10 00:20:36 Valid Loss = 0.036522749486736 
2016-12-10 00:20:38 Test Error = 0.79803493449782 
2016-12-10 00:20:38 Test Loss = 0.03839468027252 
2016-12-10 00:20:38 -------------------LR------------------- 
2016-12-10 00:20:38 0.0078125 
2016-12-10 00:20:38 Epoch 70 
2016-12-10 00:21:48 Training Error = 0.63291481031457 
2016-12-10 00:21:48 Training Loss = 0.028412456456154 
2016-12-10 00:21:50 Valid Error = 0.76306196840826 
2016-12-10 00:21:50 Valid Loss = 0.036562439434129 
2016-12-10 00:21:52 Test Error = 0.79803493449782 
2016-12-10 00:21:52 Test Loss = 0.038436439161986 
2016-12-10 00:21:52 -------------------LR------------------- 
2016-12-10 00:21:52 0.0078125 
2016-12-10 00:21:52 Epoch 71 
2016-12-10 00:22:53 Training Error = 0.63196975833671 
2016-12-10 00:22:53 Training Loss = 0.028428189966567 
2016-12-10 00:22:55 Valid Error = 0.76306196840826 
2016-12-10 00:22:55 Valid Loss = 0.037175360314516 
2016-12-10 00:22:57 Test Error = 0.79803493449782 
2016-12-10 00:22:57 Test Loss = 0.038967619378582 
2016-12-10 00:22:57 -------------------LR------------------- 
2016-12-10 00:22:57 0.0078125 
2016-12-10 00:22:57 Epoch 72 
2016-12-10 00:24:00 Training Error = 0.63291481031457 
2016-12-10 00:24:00 Training Loss = 0.028455765305584 
2016-12-10 00:24:02 Valid Error = 0.76306196840826 
2016-12-10 00:24:02 Valid Loss = 0.036993954285813 
2016-12-10 00:24:04 Test Error = 0.79803493449782 
2016-12-10 00:24:04 Test Loss = 0.038856590620053 
2016-12-10 00:24:04 -------------------LR------------------- 
2016-12-10 00:24:04 0.0078125 
2016-12-10 00:24:04 Epoch 73 
2016-12-10 00:25:06 Training Error = 0.6318347509113 
2016-12-10 00:25:06 Training Loss = 0.028439996680733 
2016-12-10 00:25:08 Valid Error = 0.76306196840826 
2016-12-10 00:25:08 Valid Loss = 0.037673955591799 
2016-12-10 00:25:10 Test Error = 0.79803493449782 
2016-12-10 00:25:10 Test Loss = 0.039510895006018 
2016-12-10 00:25:10 -------------------LR------------------- 
2016-12-10 00:25:10 0.0078125 
2016-12-10 00:25:10 Epoch 74 
2016-12-10 00:26:13 Training Error = 0.63250978803834 
2016-12-10 00:26:13 Training Loss = 0.028425643503764 
2016-12-10 00:26:15 Valid Error = 0.76306196840826 
2016-12-10 00:26:15 Valid Loss = 0.036988258523935 
2016-12-10 00:26:17 Test Error = 0.79803493449782 
2016-12-10 00:26:17 Test Loss = 0.038782259373883 
2016-12-10 00:26:17 -------------------LR------------------- 
2016-12-10 00:26:17 0.0078125 
2016-12-10 00:26:17 Epoch 75 
2016-12-10 00:27:19 Training Error = 0.63277980288916 
2016-12-10 00:27:19 Training Loss = 0.028485825225839 
2016-12-10 00:27:21 Valid Error = 0.76306196840826 
2016-12-10 00:27:21 Valid Loss = 0.037948227203753 
2016-12-10 00:27:23 Test Error = 0.79803493449782 
2016-12-10 00:27:23 Test Loss = 0.039698539574941 
2016-12-10 00:27:23 -------------------LR------------------- 
2016-12-10 00:27:23 0.0078125 
2016-12-10 00:27:23 Epoch 76 
2016-12-10 00:28:25 Training Error = 0.63372485486702 
2016-12-10 00:28:25 Training Loss = 0.028455373638761 
2016-12-10 00:28:26 Valid Error = 0.76306196840826 
2016-12-10 00:28:26 Valid Loss = 0.036639277709018 
2016-12-10 00:28:28 Test Error = 0.79803493449782 
2016-12-10 00:28:28 Test Loss = 0.038503071358001 
2016-12-10 00:28:28 -------------------LR------------------- 
2016-12-10 00:28:28 0.0078125 
2016-12-10 00:28:28 Epoch 77 
2016-12-10 00:29:30 Training Error = 0.63412987714324 
2016-12-10 00:29:30 Training Loss = 0.028446320387752 
2016-12-10 00:29:32 Valid Error = 0.76306196840826 
2016-12-10 00:29:32 Valid Loss = 0.036842287936186 
2016-12-10 00:29:34 Test Error = 0.79803493449782 
2016-12-10 00:29:34 Test Loss = 0.038691033709283 
2016-12-10 00:29:34 -------------------LR------------------- 
2016-12-10 00:29:34 0.0078125 
2016-12-10 00:29:34 Epoch 78 
2016-12-10 00:30:35 Training Error = 0.63264479546375 
2016-12-10 00:30:35 Training Loss = 0.028403157960256 
2016-12-10 00:30:37 Valid Error = 0.76306196840826 
2016-12-10 00:30:37 Valid Loss = 0.038012641902192 
2016-12-10 00:30:39 Test Error = 0.79803493449782 
2016-12-10 00:30:39 Test Loss = 0.03974210072187 
2016-12-10 00:30:39 -------------------LR------------------- 
2016-12-10 00:30:39 0.0078125 
2016-12-10 00:30:39 Epoch 79 
2016-12-10 00:31:41 Training Error = 0.63291481031457 
2016-12-10 00:31:41 Training Loss = 0.028378930018849 
2016-12-10 00:31:43 Valid Error = 0.76306196840826 
2016-12-10 00:31:43 Valid Loss = 0.036796775132204 
2016-12-10 00:31:45 Test Error = 0.79803493449782 
2016-12-10 00:31:45 Test Loss = 0.038677286899168 
2016-12-10 00:31:45 -------------------LR------------------- 
2016-12-10 00:31:45 0.0078125 
2016-12-10 00:31:45 Epoch 80 
2016-12-10 00:32:57 Training Error = 0.63169974348589 
2016-12-10 00:32:57 Training Loss = 0.02842539847279 
2016-12-10 00:32:59 Valid Error = 0.76306196840826 
2016-12-10 00:32:59 Valid Loss = 0.036947498366814 
2016-12-10 00:33:01 Test Error = 0.79803493449782 
2016-12-10 00:33:01 Test Loss = 0.038749752309587 
2016-12-10 00:33:01 -------------------LR------------------- 
2016-12-10 00:33:01 0.0078125 
2016-12-10 00:33:01 Epoch 81 
2016-12-10 00:34:02 Training Error = 0.63399486971783 
2016-12-10 00:34:02 Training Loss = 0.028453334558083 
2016-12-10 00:34:04 Valid Error = 0.76306196840826 
2016-12-10 00:34:04 Valid Loss = 0.036675239411752 
2016-12-10 00:34:06 Test Error = 0.79803493449782 
2016-12-10 00:34:06 Test Loss = 0.038515824398963 
2016-12-10 00:34:06 -------------------LR------------------- 
2016-12-10 00:34:06 0.0078125 
2016-12-10 00:34:06 Epoch 82 
2016-12-10 00:35:07 Training Error = 0.63480491427028 
2016-12-10 00:35:07 Training Loss = 0.028408288988173 
2016-12-10 00:35:09 Valid Error = 0.76306196840826 
2016-12-10 00:35:09 Valid Loss = 0.037097529783787 
2016-12-10 00:35:11 Test Error = 0.79803493449782 
2016-12-10 00:35:11 Test Loss = 0.038907271459991 
2016-12-10 00:35:11 -------------------LR------------------- 
2016-12-10 00:35:11 0.0078125 
2016-12-10 00:35:11 Epoch 83 
2016-12-10 00:36:13 Training Error = 0.6334548400162 
2016-12-10 00:36:13 Training Loss = 0.028491188092533 
2016-12-10 00:36:15 Valid Error = 0.76306196840826 
2016-12-10 00:36:15 Valid Loss = 0.037535140208422 
2016-12-10 00:36:17 Test Error = 0.79803493449782 
2016-12-10 00:36:17 Test Loss = 0.039324091602774 
2016-12-10 00:36:17 -------------------LR------------------- 
2016-12-10 00:36:17 0.0078125 
2016-12-10 00:36:17 Epoch 84 
2016-12-10 00:37:19 Training Error = 0.63426488456865 
2016-12-10 00:37:19 Training Loss = 0.028498600979634 
2016-12-10 00:37:21 Valid Error = 0.76306196840826 
2016-12-10 00:37:21 Valid Loss = 0.0373364682674 
2016-12-10 00:37:23 Test Error = 0.79803493449782 
2016-12-10 00:37:23 Test Loss = 0.03914635876425 
2016-12-10 00:37:23 -------------------LR------------------- 
2016-12-10 00:37:23 0.0078125 
2016-12-10 00:37:23 Epoch 85 
2016-12-10 00:38:25 Training Error = 0.63223977318753 
2016-12-10 00:38:25 Training Loss = 0.028376869354725 
2016-12-10 00:38:27 Valid Error = 0.76306196840826 
2016-12-10 00:38:27 Valid Loss = 0.036418354831934 
2016-12-10 00:38:29 Test Error = 0.79803493449782 
2016-12-10 00:38:29 Test Loss = 0.03823827629775 
2016-12-10 00:38:29 -------------------LR------------------- 
2016-12-10 00:38:29 0.0078125 
2016-12-10 00:38:29 Epoch 86 
2016-12-10 00:39:31 Training Error = 0.63318482516538 
2016-12-10 00:39:31 Training Loss = 0.028428237899718 
2016-12-10 00:39:32 Valid Error = 0.76306196840826 
2016-12-10 00:39:32 Valid Loss = 0.036924305180366 
2016-12-10 00:39:34 Test Error = 0.79803493449782 
2016-12-10 00:39:34 Test Loss = 0.038771133313771 
2016-12-10 00:39:34 -------------------LR------------------- 
2016-12-10 00:39:34 0.0078125 
2016-12-10 00:39:35 Epoch 87 
2016-12-10 00:40:35 Training Error = 0.6334548400162 
2016-12-10 00:40:35 Training Loss = 0.028397064687113 
2016-12-10 00:40:37 Valid Error = 0.76306196840826 
2016-12-10 00:40:37 Valid Loss = 0.036604706236601 
2016-12-10 00:40:39 Test Error = 0.79803493449782 
2016-12-10 00:40:39 Test Loss = 0.038403683472303 
2016-12-10 00:40:39 -------------------LR------------------- 
2016-12-10 00:40:39 0.0078125 
2016-12-10 00:40:39 Epoch 88 
2016-12-10 00:41:40 Training Error = 0.63358984744161 
2016-12-10 00:41:40 Training Loss = 0.028400353586483 
2016-12-10 00:41:42 Valid Error = 0.76306196840826 
2016-12-10 00:41:42 Valid Loss = 0.036584540628127 
2016-12-10 00:41:44 Test Error = 0.79803493449782 
2016-12-10 00:41:44 Test Loss = 0.038400279182235 
2016-12-10 00:41:44 -------------------LR------------------- 
2016-12-10 00:41:44 0.0078125 
2016-12-10 00:41:44 Epoch 89 
2016-12-10 00:42:47 Training Error = 0.6334548400162 
2016-12-10 00:42:47 Training Loss = 0.028490995643025 
2016-12-10 00:42:49 Valid Error = 0.76306196840826 
2016-12-10 00:42:49 Valid Loss = 0.038214826431154 
2016-12-10 00:42:51 Test Error = 0.79803493449782 
2016-12-10 00:42:51 Test Loss = 0.039929541996102 
2016-12-10 00:42:51 -------------------LR------------------- 
2016-12-10 00:42:51 0.0078125 
2016-12-10 00:42:51 Epoch 90 
2016-12-10 00:44:03 Training Error = 0.63264479546375 
2016-12-10 00:44:03 Training Loss = 0.028425747018973 
2016-12-10 00:44:05 Valid Error = 0.76306196840826 
2016-12-10 00:44:05 Valid Loss = 0.036665258070406 
2016-12-10 00:44:07 Test Error = 0.79803493449782 
2016-12-10 00:44:07 Test Loss = 0.03857537514244 
2016-12-10 00:44:07 -------------------LR------------------- 
2016-12-10 00:44:07 0.0078125 
2016-12-10 00:44:07 Epoch 91 
2016-12-10 00:45:10 Training Error = 0.63223977318753 
2016-12-10 00:45:10 Training Loss = 0.028433287756717 
2016-12-10 00:45:12 Valid Error = 0.76306196840826 
2016-12-10 00:45:12 Valid Loss = 0.037601604516268 
2016-12-10 00:45:14 Test Error = 0.79803493449782 
2016-12-10 00:45:14 Test Loss = 0.03934987735125 
2016-12-10 00:45:14 -------------------LR------------------- 
2016-12-10 00:45:14 0.0078125 
2016-12-10 00:45:14 Epoch 92 
2016-12-10 00:46:17 Training Error = 0.63331983259079 
2016-12-10 00:46:17 Training Loss = 0.028458087835215 
2016-12-10 00:46:19 Valid Error = 0.76306196840826 
2016-12-10 00:46:19 Valid Loss = 0.036982777715143 
2016-12-10 00:46:21 Test Error = 0.79803493449782 
2016-12-10 00:46:21 Test Loss = 0.038780830810273 
2016-12-10 00:46:21 -------------------LR------------------- 
2016-12-10 00:46:21 0.0078125 
2016-12-10 00:46:21 Epoch 93 
2016-12-10 00:47:21 Training Error = 0.63223977318753 
2016-12-10 00:47:21 Training Loss = 0.028421746836 
2016-12-10 00:47:23 Valid Error = 0.76306196840826 
2016-12-10 00:47:23 Valid Loss = 0.036462887353716 
2016-12-10 00:47:25 Test Error = 0.79803493449782 
2016-12-10 00:47:25 Test Loss = 0.038337703592637 
2016-12-10 00:47:25 -------------------LR------------------- 
2016-12-10 00:47:25 0.0078125 
2016-12-10 00:47:25 Epoch 94 
2016-12-10 00:48:28 Training Error = 0.63358984744161 
2016-12-10 00:48:28 Training Loss = 0.028393993468816 
2016-12-10 00:48:30 Valid Error = 0.76306196840826 
2016-12-10 00:48:30 Valid Loss = 0.037740148769432 
2016-12-10 00:48:32 Test Error = 0.79803493449782 
2016-12-10 00:48:32 Test Loss = 0.039481338239184 
2016-12-10 00:48:32 -------------------LR------------------- 
2016-12-10 00:48:32 0.0078125 
2016-12-10 00:48:32 Epoch 95 
2016-12-10 00:49:34 Training Error = 0.63210476576212 
2016-12-10 00:49:34 Training Loss = 0.028441241028983 
2016-12-10 00:49:36 Valid Error = 0.76306196840826 
2016-12-10 00:49:36 Valid Loss = 0.037261059596311 
2016-12-10 00:49:38 Test Error = 0.79803493449782 
2016-12-10 00:49:38 Test Loss = 0.039081253382116 
2016-12-10 00:49:38 -------------------LR------------------- 
2016-12-10 00:49:38 0.0078125 
2016-12-10 00:49:38 Epoch 96 
2016-12-10 00:50:39 Training Error = 0.63264479546375 
2016-12-10 00:50:39 Training Loss = 0.028413321662593 
2016-12-10 00:50:41 Valid Error = 0.76306196840826 
2016-12-10 00:50:41 Valid Loss = 0.036858957843845 
2016-12-10 00:50:43 Test Error = 0.79803493449782 
2016-12-10 00:50:43 Test Loss = 0.038693762651456 
2016-12-10 00:50:43 -------------------LR------------------- 
2016-12-10 00:50:43 0.0078125 
2016-12-10 00:50:43 Epoch 97 
2016-12-10 00:51:45 Training Error = 0.63264479546375 
2016-12-10 00:51:45 Training Loss = 0.028470351218617 
2016-12-10 00:51:47 Valid Error = 0.76306196840826 
2016-12-10 00:51:47 Valid Loss = 0.036314767712134 
2016-12-10 00:51:49 Test Error = 0.79803493449782 
2016-12-10 00:51:49 Test Loss = 0.03814545569077 
2016-12-10 00:51:49 -------------------LR------------------- 
2016-12-10 00:51:49 0.0078125 
2016-12-10 00:51:49 Epoch 98 
2016-12-10 00:52:52 Training Error = 0.63318482516538 
2016-12-10 00:52:52 Training Loss = 0.028548094282036 
2016-12-10 00:52:54 Valid Error = 0.76306196840826 
2016-12-10 00:52:54 Valid Loss = 0.036425978964145 
2016-12-10 00:52:56 Test Error = 0.79803493449782 
2016-12-10 00:52:56 Test Loss = 0.038313418354084 
2016-12-10 00:52:56 -------------------LR------------------- 
2016-12-10 00:52:56 0.0078125 
2016-12-10 00:52:56 Epoch 99 
2016-12-10 00:53:58 Training Error = 0.63291481031457 
2016-12-10 00:53:58 Training Loss = 0.028362377851059 
2016-12-10 00:54:00 Valid Error = 0.76306196840826 
2016-12-10 00:54:00 Valid Loss = 0.036664025435381 
2016-12-10 00:54:02 Test Error = 0.79803493449782 
2016-12-10 00:54:02 Test Loss = 0.038501924938626 
2016-12-10 00:54:02 -------------------LR------------------- 
2016-12-10 00:54:02 0.0078125 
2016-12-10 00:54:02 Epoch 100 
2016-12-10 00:55:15 Training Error = 0.63372485486702 
2016-12-10 00:55:15 Training Loss = 0.028442701159665 
2016-12-10 00:55:17 Valid Error = 0.76306196840826 
2016-12-10 00:55:17 Valid Loss = 0.036546802366274 
2016-12-10 00:55:19 Test Error = 0.79803493449782 
2016-12-10 00:55:19 Test Loss = 0.038435551870882 
2016-12-10 00:55:19 -------------------LR------------------- 
2016-12-10 00:55:19 0.00390625 
2016-12-10 00:55:19 Epoch 101 
2016-12-10 00:56:20 Training Error = 0.63385986229243 
2016-12-10 00:56:20 Training Loss = 0.028378627539553 
2016-12-10 00:56:22 Valid Error = 0.76306196840826 
2016-12-10 00:56:22 Valid Loss = 0.036866853642937 
2016-12-10 00:56:24 Test Error = 0.79803493449782 
2016-12-10 00:56:24 Test Loss = 0.038718465636758 
2016-12-10 00:56:24 -------------------LR------------------- 
2016-12-10 00:56:24 0.00390625 
2016-12-10 00:56:24 Epoch 102 
2016-12-10 00:57:25 Training Error = 0.63466990684488 
2016-12-10 00:57:25 Training Loss = 0.028455683050059 
2016-12-10 00:57:27 Valid Error = 0.76306196840826 
2016-12-10 00:57:27 Valid Loss = 0.036495633961006 
2016-12-10 00:57:29 Test Error = 0.79803493449782 
2016-12-10 00:57:29 Test Loss = 0.038407843346689 
2016-12-10 00:57:29 -------------------LR------------------- 
2016-12-10 00:57:29 0.00390625 
2016-12-10 00:57:29 Epoch 103 
2016-12-10 00:58:31 Training Error = 0.63412987714324 
2016-12-10 00:58:31 Training Loss = 0.028465786590244 
2016-12-10 00:58:32 Valid Error = 0.76306196840826 
2016-12-10 00:58:32 Valid Loss = 0.036261229635127 
2016-12-10 00:58:34 Test Error = 0.79803493449782 
2016-12-10 00:58:34 Test Loss = 0.038136336273617 
2016-12-10 00:58:34 -------------------LR------------------- 
2016-12-10 00:58:34 0.00390625 
2016-12-10 00:58:34 Epoch 104 
2016-12-10 00:59:36 Training Error = 0.63304981773998 
2016-12-10 00:59:36 Training Loss = 0.028449888354865 
2016-12-10 00:59:38 Valid Error = 0.76306196840826 
2016-12-10 00:59:38 Valid Loss = 0.03630657828455 
2016-12-10 00:59:40 Test Error = 0.79803493449782 
2016-12-10 00:59:40 Test Loss = 0.038164959296682 
2016-12-10 00:59:40 -------------------LR------------------- 
2016-12-10 00:59:40 0.00390625 
2016-12-10 00:59:40 Epoch 105 
2016-12-10 01:00:42 Training Error = 0.63412987714324 
2016-12-10 01:00:42 Training Loss = 0.028445638346909 
2016-12-10 01:00:44 Valid Error = 0.76306196840826 
2016-12-10 01:00:44 Valid Loss = 0.036468698403627 
2016-12-10 01:00:46 Test Error = 0.79803493449782 
2016-12-10 01:00:46 Test Loss = 0.03831759656956 
2016-12-10 01:00:46 -------------------LR------------------- 
2016-12-10 01:00:46 0.00390625 
2016-12-10 01:00:46 Epoch 106 
2016-12-10 01:01:48 Training Error = 0.63358984744161 
2016-12-10 01:01:48 Training Loss = 0.028418749077275 
2016-12-10 01:01:50 Valid Error = 0.76306196840826 
2016-12-10 01:01:50 Valid Loss = 0.036587013632147 
2016-12-10 01:01:52 Test Error = 0.79803493449782 
2016-12-10 01:01:52 Test Loss = 0.038459615956724 
2016-12-10 01:01:52 -------------------LR------------------- 
2016-12-10 01:01:52 0.00390625 
2016-12-10 01:01:52 Epoch 107 
2016-12-10 01:02:57 Training Error = 0.63264479546375 
2016-12-10 01:02:57 Training Loss = 0.028436742669167 
2016-12-10 01:02:59 Valid Error = 0.76306196840826 
2016-12-10 01:02:59 Valid Loss = 0.036575752089176 
2016-12-10 01:03:01 Test Error = 0.79803493449782 
2016-12-10 01:03:01 Test Loss = 0.038443401654561 
2016-12-10 01:03:01 -------------------LR------------------- 
2016-12-10 01:03:01 0.00390625 
2016-12-10 01:03:01 Epoch 108 
2016-12-10 01:04:01 Training Error = 0.63304981773998 
2016-12-10 01:04:01 Training Loss = 0.028484644356002 
2016-12-10 01:04:03 Valid Error = 0.76306196840826 
2016-12-10 01:04:03 Valid Loss = 0.03666752622857 
2016-12-10 01:04:05 Test Error = 0.79803493449782 
2016-12-10 01:04:05 Test Loss = 0.038571234731113 
2016-12-10 01:04:05 -------------------LR------------------- 
2016-12-10 01:04:05 0.00390625 
2016-12-10 01:04:05 Epoch 109 
2016-12-10 01:05:05 Training Error = 0.63264479546375 
2016-12-10 01:05:05 Training Loss = 0.028464298077087 
2016-12-10 01:05:06 Valid Error = 0.76306196840826 
2016-12-10 01:05:06 Valid Loss = 0.036605125552543 
2016-12-10 01:05:09 Test Error = 0.79803493449782 
2016-12-10 01:05:09 Test Loss = 0.038456707966873 
2016-12-10 01:05:09 -------------------LR------------------- 
2016-12-10 01:05:09 0.00390625 
2016-12-10 01:05:09 Epoch 110 
2016-12-10 01:06:18 Training Error = 0.63277980288916 
2016-12-10 01:06:18 Training Loss = 0.028494138177118 
2016-12-10 01:06:20 Valid Error = 0.76306196840826 
2016-12-10 01:06:20 Valid Loss = 0.037603275053808 
2016-12-10 01:06:22 Test Error = 0.79803493449782 
2016-12-10 01:06:22 Test Loss = 0.039414094039817 
2016-12-10 01:06:22 -------------------LR------------------- 
2016-12-10 01:06:22 0.00390625 
2016-12-10 01:06:22 Epoch 111 
2016-12-10 01:07:22 Training Error = 0.63291481031457 
2016-12-10 01:07:22 Training Loss = 0.028483052039718 
2016-12-10 01:07:24 Valid Error = 0.76306196840826 
2016-12-10 01:07:24 Valid Loss = 0.03646625334804 
2016-12-10 01:07:26 Test Error = 0.79803493449782 
2016-12-10 01:07:26 Test Loss = 0.038358101221471 
2016-12-10 01:07:26 -------------------LR------------------- 
2016-12-10 01:07:26 0.00390625 
2016-12-10 01:07:26 Epoch 112 
2016-12-10 01:08:24 Training Error = 0.6334548400162 
2016-12-10 01:08:24 Training Loss = 0.028485525634974 
2016-12-10 01:08:26 Valid Error = 0.76306196840826 
2016-12-10 01:08:26 Valid Loss = 0.038055899541317 
2016-12-10 01:08:28 Test Error = 0.79803493449782 
2016-12-10 01:08:28 Test Loss = 0.039829932116216 
2016-12-10 01:08:28 -------------------LR------------------- 
2016-12-10 01:08:28 0.00390625 
2016-12-10 01:08:28 Epoch 113 
2016-12-10 01:09:28 Training Error = 0.63331983259079 
2016-12-10 01:09:28 Training Loss = 0.028447279544508 
2016-12-10 01:09:30 Valid Error = 0.76306196840826 
2016-12-10 01:09:30 Valid Loss = 0.036818262027155 
2016-12-10 01:09:32 Test Error = 0.79803493449782 
2016-12-10 01:09:32 Test Loss = 0.038657429062463 
2016-12-10 01:09:32 -------------------LR------------------- 
2016-12-10 01:09:32 0.00390625 
2016-12-10 01:09:32 Epoch 114 
2016-12-10 01:10:32 Training Error = 0.63372485486702 
2016-12-10 01:10:32 Training Loss = 0.02859189173301 
2016-12-10 01:10:34 Valid Error = 0.76306196840826 
2016-12-10 01:10:34 Valid Loss = 0.036516159017218 
2016-12-10 01:10:36 Test Error = 0.79803493449782 
2016-12-10 01:10:36 Test Loss = 0.038415790648242 
2016-12-10 01:10:36 -------------------LR------------------- 
2016-12-10 01:10:36 0.00390625 
2016-12-10 01:10:36 Epoch 115 
2016-12-10 01:11:34 Training Error = 0.6334548400162 
2016-12-10 01:11:34 Training Loss = 0.028441875481251 
2016-12-10 01:11:35 Valid Error = 0.76306196840826 
2016-12-10 01:11:35 Valid Loss = 0.037804233024011 
2016-12-10 01:11:38 Test Error = 0.79803493449782 
2016-12-10 01:11:38 Test Loss = 0.0395312035785 
2016-12-10 01:11:38 -------------------LR------------------- 
2016-12-10 01:11:38 0.00390625 
2016-12-10 01:11:38 Epoch 116 
2016-12-10 01:12:38 Training Error = 0.63129472120967 
2016-12-10 01:12:38 Training Loss = 0.028440055605646 
2016-12-10 01:12:40 Valid Error = 0.76306196840826 
2016-12-10 01:12:40 Valid Loss = 0.037066392826165 
2016-12-10 01:12:42 Test Error = 0.79803493449782 
2016-12-10 01:12:42 Test Loss = 0.038913825010163 
2016-12-10 01:12:42 -------------------LR------------------- 
2016-12-10 01:12:42 0.00390625 
2016-12-10 01:12:42 Epoch 117 
2016-12-10 01:13:43 Training Error = 0.63331983259079 
2016-12-10 01:13:43 Training Loss = 0.028446022271166 
2016-12-10 01:13:45 Valid Error = 0.76306196840826 
2016-12-10 01:13:45 Valid Loss = 0.037183909720543 
2016-12-10 01:13:47 Test Error = 0.79803493449782 
2016-12-10 01:13:47 Test Loss = 0.039013774675481 
2016-12-10 01:13:47 -------------------LR------------------- 
2016-12-10 01:13:47 0.00390625 
2016-12-10 01:13:47 Epoch 118 
2016-12-10 01:14:46 Training Error = 0.63277980288916 
2016-12-10 01:14:46 Training Loss = 0.028431132939924 
2016-12-10 01:14:48 Valid Error = 0.76306196840826 
2016-12-10 01:14:48 Valid Loss = 0.036704170786601 
2016-12-10 01:14:50 Test Error = 0.79803493449782 
2016-12-10 01:14:50 Test Loss = 0.038578712940216 
2016-12-10 01:14:50 -------------------LR------------------- 
2016-12-10 01:14:50 0.00390625 
2016-12-10 01:14:50 Epoch 119 
2016-12-10 01:15:51 Training Error = 0.6318347509113 
2016-12-10 01:15:51 Training Loss = 0.028404551436177 
2016-12-10 01:15:53 Valid Error = 0.76306196840826 
2016-12-10 01:15:53 Valid Loss = 0.037952885540305 
2016-12-10 01:15:55 Test Error = 0.79803493449782 
2016-12-10 01:15:55 Test Loss = 0.039698423232908 
2016-12-10 01:15:55 -------------------LR------------------- 
2016-12-10 01:15:55 0.00390625 
2016-12-10 01:15:55 Epoch 120 
2016-12-10 01:17:06 Training Error = 0.6334548400162 
2016-12-10 01:17:06 Training Loss = 0.028465308950398 
2016-12-10 01:17:08 Valid Error = 0.76306196840826 
2016-12-10 01:17:08 Valid Loss = 0.036588757281643 
2016-12-10 01:17:10 Test Error = 0.79803493449782 
2016-12-10 01:17:10 Test Loss = 0.038484500592051 
2016-12-10 01:17:10 -------------------LR------------------- 
2016-12-10 01:17:10 0.00390625 
2016-12-10 01:17:10 Epoch 121 
2016-12-10 01:18:10 Training Error = 0.63318482516538 
2016-12-10 01:18:10 Training Loss = 0.028431641519974 
2016-12-10 01:18:12 Valid Error = 0.76306196840826 
2016-12-10 01:18:12 Valid Loss = 0.03655217932997 
2016-12-10 01:18:14 Test Error = 0.79803493449782 
2016-12-10 01:18:14 Test Loss = 0.038382487156812 
2016-12-10 01:18:14 -------------------LR------------------- 
2016-12-10 01:18:14 0.00390625 
2016-12-10 01:18:14 Epoch 122 
2016-12-10 01:19:14 Training Error = 0.63453489941947 
2016-12-10 01:19:14 Training Loss = 0.028473521551255 
2016-12-10 01:19:15 Valid Error = 0.76306196840826 
2016-12-10 01:19:15 Valid Loss = 0.036634179985171 
2016-12-10 01:19:18 Test Error = 0.79803493449782 
2016-12-10 01:19:18 Test Loss = 0.038487629064547 
2016-12-10 01:19:18 -------------------LR------------------- 
2016-12-10 01:19:18 0.00390625 
2016-12-10 01:19:18 Epoch 123 
2016-12-10 01:20:16 Training Error = 0.6318347509113 
2016-12-10 01:20:16 Training Loss = 0.028361030051197 
2016-12-10 01:20:18 Valid Error = 0.76306196840826 
2016-12-10 01:20:18 Valid Loss = 0.037734320432876 
2016-12-10 01:20:20 Test Error = 0.79803493449782 
2016-12-10 01:20:20 Test Loss = 0.039499332343831 
2016-12-10 01:20:20 -------------------LR------------------- 
2016-12-10 01:20:20 0.00390625 
2016-12-10 01:20:20 Epoch 124 
2016-12-10 01:21:20 Training Error = 0.63264479546375 
2016-12-10 01:21:20 Training Loss = 0.028419617036858 
2016-12-10 01:21:22 Valid Error = 0.76306196840826 
2016-12-10 01:21:22 Valid Loss = 0.036637414448337 
2016-12-10 01:21:24 Test Error = 0.79803493449782 
2016-12-10 01:21:24 Test Loss = 0.038457557001924 
2016-12-10 01:21:24 -------------------LR------------------- 
2016-12-10 01:21:24 0.00390625 
2016-12-10 01:21:24 Epoch 125 
2016-12-10 01:22:25 Training Error = 0.63439989199406 
2016-12-10 01:22:25 Training Loss = 0.028418954651914 
2016-12-10 01:22:26 Valid Error = 0.76306196840826 
2016-12-10 01:22:26 Valid Loss = 0.036455121159743 
2016-12-10 01:22:28 Test Error = 0.79803493449782 
2016-12-10 01:22:28 Test Loss = 0.038330140674815 
2016-12-10 01:22:28 -------------------LR------------------- 
2016-12-10 01:22:28 0.00390625 
2016-12-10 01:22:28 Epoch 126 
2016-12-10 01:23:28 Training Error = 0.63331983259079 
2016-12-10 01:23:28 Training Loss = 0.028446832100212 
2016-12-10 01:23:30 Valid Error = 0.76306196840826 
2016-12-10 01:23:30 Valid Loss = 0.036668575985315 
2016-12-10 01:23:32 Test Error = 0.79803493449782 
2016-12-10 01:23:32 Test Loss = 0.038514716453802 
2016-12-10 01:23:32 -------------------LR------------------- 
2016-12-10 01:23:32 0.00390625 
2016-12-10 01:23:32 Epoch 127 
2016-12-10 01:24:33 Training Error = 0.63358984744161 
2016-12-10 01:24:33 Training Loss = 0.028368469827993 
2016-12-10 01:24:35 Valid Error = 0.76306196840826 
2016-12-10 01:24:35 Valid Loss = 0.036579878660127 
2016-12-10 01:24:37 Test Error = 0.79803493449782 
2016-12-10 01:24:37 Test Loss = 0.038471008235333 
2016-12-10 01:24:37 -------------------LR------------------- 
2016-12-10 01:24:37 0.00390625 
2016-12-10 01:24:37 Epoch 128 
2016-12-10 01:25:39 Training Error = 0.63385986229243 
2016-12-10 01:25:39 Training Loss = 0.0283828656018 
2016-12-10 01:25:40 Valid Error = 0.76306196840826 
2016-12-10 01:25:40 Valid Loss = 0.036710183426587 
2016-12-10 01:25:43 Test Error = 0.79803493449782 
2016-12-10 01:25:43 Test Loss = 0.038568233586604 
2016-12-10 01:25:43 -------------------LR------------------- 
2016-12-10 01:25:43 0.00390625 
2016-12-10 01:25:43 Epoch 129 
2016-12-10 01:26:42 Training Error = 0.63399486971783 
2016-12-10 01:26:42 Training Loss = 0.02846108362361 
2016-12-10 01:26:44 Valid Error = 0.76306196840826 
2016-12-10 01:26:44 Valid Loss = 0.03647680362217 
2016-12-10 01:26:46 Test Error = 0.79803493449782 
2016-12-10 01:26:46 Test Loss = 0.038314337294086 
2016-12-10 01:26:46 -------------------LR------------------- 
2016-12-10 01:26:46 0.00390625 
2016-12-10 01:26:46 Epoch 130 
2016-12-10 01:27:56 Training Error = 0.63399486971783 
2016-12-10 01:27:56 Training Loss = 0.028445212452527 
2016-12-10 01:27:58 Valid Error = 0.76306196840826 
2016-12-10 01:27:58 Valid Loss = 0.036688724020921 
2016-12-10 01:28:00 Test Error = 0.79803493449782 
2016-12-10 01:28:00 Test Loss = 0.038576419275571 
2016-12-10 01:28:00 -------------------LR------------------- 
2016-12-10 01:28:00 0.00390625 
2016-12-10 01:28:00 Epoch 131 
2016-12-10 01:29:00 Training Error = 0.63358984744161 
2016-12-10 01:29:00 Training Loss = 0.028379858502504 
2016-12-10 01:29:02 Valid Error = 0.76306196840826 
2016-12-10 01:29:02 Valid Loss = 0.036760834186563 
2016-12-10 01:29:04 Test Error = 0.79803493449782 
2016-12-10 01:29:04 Test Loss = 0.038656991556579 
2016-12-10 01:29:04 -------------------LR------------------- 
2016-12-10 01:29:04 0.00390625 
2016-12-10 01:29:04 Epoch 132 
2016-12-10 01:30:04 Training Error = 0.63304981773998 
2016-12-10 01:30:04 Training Loss = 0.02849216046808 
2016-12-10 01:30:06 Valid Error = 0.76306196840826 
2016-12-10 01:30:06 Valid Loss = 0.036329863557121 
2016-12-10 01:30:08 Test Error = 0.79803493449782 
2016-12-10 01:30:08 Test Loss = 0.038171447320701 
2016-12-10 01:30:08 -------------------LR------------------- 
2016-12-10 01:30:08 0.00390625 
2016-12-10 01:30:08 Epoch 133 
2016-12-10 01:31:09 Training Error = 0.63412987714324 
2016-12-10 01:31:09 Training Loss = 0.028511949114498 
2016-12-10 01:31:11 Valid Error = 0.76306196840826 
2016-12-10 01:31:11 Valid Loss = 0.0366420118195 
2016-12-10 01:31:13 Test Error = 0.79803493449782 
2016-12-10 01:31:13 Test Loss = 0.038488998335171 
2016-12-10 01:31:13 -------------------LR------------------- 
2016-12-10 01:31:13 0.00390625 
2016-12-10 01:31:13 Epoch 134 
2016-12-10 01:32:19 Training Error = 0.63480491427028 
2016-12-10 01:32:19 Training Loss = 0.028541735923097 
2016-12-10 01:32:21 Valid Error = 0.76306196840826 
2016-12-10 01:32:21 Valid Loss = 0.036428231713999 
2016-12-10 01:32:23 Test Error = 0.79803493449782 
2016-12-10 01:32:23 Test Loss = 0.038306015223459 
2016-12-10 01:32:23 -------------------LR------------------- 
2016-12-10 01:32:23 0.00390625 
2016-12-10 01:32:23 Epoch 135 
2016-12-10 01:33:31 Training Error = 0.6334548400162 
2016-12-10 01:33:31 Training Loss = 0.028399826179599 
2016-12-10 01:33:33 Valid Error = 0.76306196840826 
2016-12-10 01:33:33 Valid Loss = 0.036537048172284 
2016-12-10 01:33:35 Test Error = 0.79803493449782 
2016-12-10 01:33:35 Test Loss = 0.038394865491032 
2016-12-10 01:33:35 -------------------LR------------------- 
2016-12-10 01:33:35 0.00390625 
2016-12-10 01:33:35 Epoch 136 
2016-12-10 01:34:36 Training Error = 0.63304981773998 
2016-12-10 01:34:36 Training Loss = 0.028449625415157 
2016-12-10 01:34:38 Valid Error = 0.76306196840826 
2016-12-10 01:34:38 Valid Loss = 0.036411706551436 
2016-12-10 01:34:40 Test Error = 0.79803493449782 
2016-12-10 01:34:40 Test Loss = 0.038313177146164 
2016-12-10 01:34:40 -------------------LR------------------- 
2016-12-10 01:34:40 0.00390625 
2016-12-10 01:34:40 Epoch 137 
2016-12-10 01:35:39 Training Error = 0.63196975833671 
2016-12-10 01:35:39 Training Loss = 0.02834904882979 
2016-12-10 01:35:41 Valid Error = 0.76306196840826 
2016-12-10 01:35:41 Valid Loss = 0.036434647140578 
2016-12-10 01:35:43 Test Error = 0.79803493449782 
2016-12-10 01:35:43 Test Loss = 0.038310451367322 
2016-12-10 01:35:43 -------------------LR------------------- 
2016-12-10 01:35:43 0.00390625 
2016-12-10 01:35:43 Epoch 138 
2016-12-10 01:36:42 Training Error = 0.63385986229243 
2016-12-10 01:36:42 Training Loss = 0.028506834482878 
2016-12-10 01:36:44 Valid Error = 0.76306196840826 
2016-12-10 01:36:44 Valid Loss = 0.037765169283713 
2016-12-10 01:36:46 Test Error = 0.79803493449782 
2016-12-10 01:36:46 Test Loss = 0.039546627920437 
2016-12-10 01:36:46 -------------------LR------------------- 
2016-12-10 01:36:46 0.00390625 
2016-12-10 01:36:46 Epoch 139 
2016-12-10 01:37:44 Training Error = 0.63250978803834 
2016-12-10 01:37:44 Training Loss = 0.028419154565321 
2016-12-10 01:37:46 Valid Error = 0.76306196840826 
2016-12-10 01:37:46 Valid Loss = 0.037613275244098 
2016-12-10 01:37:48 Test Error = 0.79803493449782 
2016-12-10 01:37:48 Test Loss = 0.03941065852159 
2016-12-10 01:37:48 -------------------LR------------------- 
2016-12-10 01:37:48 0.00390625 
2016-12-10 01:37:48 Epoch 140 
2016-12-10 01:38:56 Training Error = 0.63331983259079 
2016-12-10 01:38:56 Training Loss = 0.028392827577655 
2016-12-10 01:38:58 Valid Error = 0.76306196840826 
2016-12-10 01:38:58 Valid Loss = 0.037828169643552 
2016-12-10 01:39:00 Test Error = 0.79803493449782 
2016-12-10 01:39:00 Test Loss = 0.039610190235711 
2016-12-10 01:39:00 -------------------LR------------------- 
2016-12-10 01:39:00 0.00390625 
2016-12-10 01:39:00 Epoch 141 
2016-12-10 01:39:58 Training Error = 0.63439989199406 
2016-12-10 01:39:58 Training Loss = 0.028445288416639 
2016-12-10 01:40:00 Valid Error = 0.76306196840826 
2016-12-10 01:40:00 Valid Loss = 0.036426200196238 
2016-12-10 01:40:02 Test Error = 0.79803493449782 
2016-12-10 01:40:02 Test Loss = 0.03828911348106 
2016-12-10 01:40:02 -------------------LR------------------- 
2016-12-10 01:40:02 0.00390625 
2016-12-10 01:40:02 Epoch 142 
2016-12-10 01:41:00 Training Error = 0.63331983259079 
2016-12-10 01:41:00 Training Loss = 0.028455047268049 
2016-12-10 01:41:02 Valid Error = 0.76306196840826 
2016-12-10 01:41:02 Valid Loss = 0.036140108412539 
2016-12-10 01:41:04 Test Error = 0.79803493449782 
2016-12-10 01:41:04 Test Loss = 0.038062967786602 
2016-12-10 01:41:04 -------------------LR------------------- 
2016-12-10 01:41:04 0.00390625 
2016-12-10 01:41:04 Epoch 143 
2016-12-10 01:42:04 Training Error = 0.6334548400162 
2016-12-10 01:42:04 Training Loss = 0.02838920651568 
2016-12-10 01:42:06 Valid Error = 0.76306196840826 
2016-12-10 01:42:06 Valid Loss = 0.036394212305128 
2016-12-10 01:42:08 Test Error = 0.79803493449782 
2016-12-10 01:42:08 Test Loss = 0.038231872483796 
2016-12-10 01:42:08 -------------------LR------------------- 
2016-12-10 01:42:08 0.00390625 
2016-12-10 01:42:08 Epoch 144 
2016-12-10 01:43:08 Training Error = 0.63291481031457 
2016-12-10 01:43:08 Training Loss = 0.02843582293637 
2016-12-10 01:43:10 Valid Error = 0.76306196840826 
2016-12-10 01:43:10 Valid Loss = 0.037135273084349 
2016-12-10 01:43:12 Test Error = 0.79803493449782 
2016-12-10 01:43:12 Test Loss = 0.038937968444201 
2016-12-10 01:43:12 -------------------LR------------------- 
2016-12-10 01:43:12 0.00390625 
2016-12-10 01:43:12 Epoch 145 
2016-12-10 01:44:11 Training Error = 0.63291481031457 
2016-12-10 01:44:11 Training Loss = 0.028384808029893 
2016-12-10 01:44:12 Valid Error = 0.76306196840826 
2016-12-10 01:44:12 Valid Loss = 0.036401103218812 
2016-12-10 01:44:15 Test Error = 0.79803493449782 
2016-12-10 01:44:15 Test Loss = 0.038277102155623 
2016-12-10 01:44:15 -------------------LR------------------- 
2016-12-10 01:44:15 0.00390625 
2016-12-10 01:44:15 Epoch 146 
2016-12-10 01:45:14 Training Error = 0.63439989199406 
2016-12-10 01:45:14 Training Loss = 0.028511014061917 
2016-12-10 01:45:16 Valid Error = 0.76306196840826 
2016-12-10 01:45:16 Valid Loss = 0.037540976278949 
2016-12-10 01:45:18 Test Error = 0.79803493449782 
2016-12-10 01:45:18 Test Loss = 0.03928404527552 
2016-12-10 01:45:18 -------------------LR------------------- 
2016-12-10 01:45:18 0.00390625 
2016-12-10 01:45:18 Epoch 147 
2016-12-10 01:46:18 Training Error = 0.63453489941947 
2016-12-10 01:46:18 Training Loss = 0.028434971100198 
2016-12-10 01:46:20 Valid Error = 0.76306196840826 
2016-12-10 01:46:20 Valid Loss = 0.036399912151641 
2016-12-10 01:46:22 Test Error = 0.79803493449782 
2016-12-10 01:46:22 Test Loss = 0.038235931193906 
2016-12-10 01:46:22 -------------------LR------------------- 
2016-12-10 01:46:22 0.00390625 
2016-12-10 01:46:22 Epoch 148 
2016-12-10 01:47:22 Training Error = 0.63372485486702 
2016-12-10 01:47:22 Training Loss = 0.02846996815002 
2016-12-10 01:47:24 Valid Error = 0.76306196840826 
2016-12-10 01:47:24 Valid Loss = 0.037631280147099 
2016-12-10 01:47:26 Test Error = 0.79803493449782 
2016-12-10 01:47:26 Test Loss = 0.039425165731143 
2016-12-10 01:47:26 -------------------LR------------------- 
2016-12-10 01:47:26 0.00390625 
2016-12-10 01:47:26 Epoch 149 
2016-12-10 01:48:24 Training Error = 0.63264479546375 
2016-12-10 01:48:24 Training Loss = 0.028409349049218 
2016-12-10 01:48:25 Valid Error = 0.76306196840826 
2016-12-10 01:48:25 Valid Loss = 0.037599214385584 
2016-12-10 01:48:27 Test Error = 0.79803493449782 
2016-12-10 01:48:27 Test Loss = 0.039355782184725 
2016-12-10 01:48:27 -------------------LR------------------- 
2016-12-10 01:48:27 0.00390625 
2016-12-10 01:48:28 Epoch 150 
2016-12-10 01:49:37 Training Error = 0.63277980288916 
2016-12-10 01:49:37 Training Loss = 0.028477830035481 
2016-12-10 01:49:38 Valid Error = 0.76306196840826 
2016-12-10 01:49:38 Valid Loss = 0.038092826916979 
2016-12-10 01:49:40 Test Error = 0.79803493449782 
2016-12-10 01:49:40 Test Loss = 0.039823318104339 
2016-12-10 01:49:40 -------------------LR------------------- 
2016-12-10 01:49:40 0.001953125 
2016-12-10 01:49:41 Epoch 151 
2016-12-10 01:50:41 Training Error = 0.6334548400162 
2016-12-10 01:50:41 Training Loss = 0.028388526759681 
2016-12-10 01:50:43 Valid Error = 0.76306196840826 
2016-12-10 01:50:43 Valid Loss = 0.037833691465641 
2016-12-10 01:50:45 Test Error = 0.79803493449782 
2016-12-10 01:50:45 Test Loss = 0.03956970900492 
2016-12-10 01:50:45 -------------------LR------------------- 
2016-12-10 01:50:45 0.001953125 
2016-12-10 01:50:45 Epoch 152 
2016-12-10 01:51:44 Training Error = 0.63399486971783 
2016-12-10 01:51:44 Training Loss = 0.028482295527544 
2016-12-10 01:51:46 Valid Error = 0.76306196840826 
2016-12-10 01:51:46 Valid Loss = 0.037610619803058 
2016-12-10 01:51:48 Test Error = 0.79803493449782 
2016-12-10 01:51:48 Test Loss = 0.039362667199054 
2016-12-10 01:51:48 -------------------LR------------------- 
2016-12-10 01:51:48 0.001953125 
2016-12-10 01:51:48 Epoch 153 
2016-12-10 01:52:46 Training Error = 0.63412987714324 
2016-12-10 01:52:46 Training Loss = 0.028582439036765 
2016-12-10 01:52:48 Valid Error = 0.76306196840826 
2016-12-10 01:52:48 Valid Loss = 0.036424378014448 
2016-12-10 01:52:50 Test Error = 0.79803493449782 
2016-12-10 01:52:50 Test Loss = 0.038294464373121 
2016-12-10 01:52:50 -------------------LR------------------- 
2016-12-10 01:52:50 0.001953125 
2016-12-10 01:52:50 Epoch 154 
2016-12-10 01:53:51 Training Error = 0.63318482516538 
2016-12-10 01:53:51 Training Loss = 0.028479760047253 
2016-12-10 01:53:53 Valid Error = 0.76306196840826 
2016-12-10 01:53:53 Valid Loss = 0.037685439577346 
2016-12-10 01:53:55 Test Error = 0.79803493449782 
2016-12-10 01:53:55 Test Loss = 0.039449507161683 
2016-12-10 01:53:55 -------------------LR------------------- 
2016-12-10 01:53:55 0.001953125 
2016-12-10 01:53:55 Epoch 155 
2016-12-10 01:54:54 Training Error = 0.63358984744161 
2016-12-10 01:54:54 Training Loss = 0.028443642184521 
2016-12-10 01:54:55 Valid Error = 0.76306196840826 
2016-12-10 01:54:55 Valid Loss = 0.036533978537492 
2016-12-10 01:54:57 Test Error = 0.79803493449782 
2016-12-10 01:54:57 Test Loss = 0.038401404253018 
2016-12-10 01:54:57 -------------------LR------------------- 
2016-12-10 01:54:57 0.001953125 
2016-12-10 01:54:57 Epoch 156 
2016-12-10 01:55:59 Training Error = 0.63304981773998 
2016-12-10 01:55:59 Training Loss = 0.028429885315884 
2016-12-10 01:56:01 Valid Error = 0.76306196840826 
2016-12-10 01:56:01 Valid Loss = 0.036623378622365 
2016-12-10 01:56:03 Test Error = 0.79803493449782 
2016-12-10 01:56:03 Test Loss = 0.038459264375026 
2016-12-10 01:56:03 -------------------LR------------------- 
2016-12-10 01:56:03 0.001953125 
2016-12-10 01:56:03 Epoch 157 
2016-12-10 01:57:11 Training Error = 0.63453489941947 
2016-12-10 01:57:11 Training Loss = 0.028471208080058 
2016-12-10 01:57:13 Valid Error = 0.76306196840826 
2016-12-10 01:57:13 Valid Loss = 0.036538739025657 
2016-12-10 01:57:15 Test Error = 0.79803493449782 
2016-12-10 01:57:15 Test Loss = 0.038379760318332 
2016-12-10 01:57:15 -------------------LR------------------- 
2016-12-10 01:57:15 0.001953125 
2016-12-10 01:57:15 Epoch 158 
2016-12-10 01:58:23 Training Error = 0.63156473606048 
2016-12-10 01:58:23 Training Loss = 0.028413799658578 
2016-12-10 01:58:24 Valid Error = 0.76306196840826 
2016-12-10 01:58:24 Valid Loss = 0.036843675679946 
2016-12-10 01:58:27 Test Error = 0.79803493449782 
2016-12-10 01:58:27 Test Loss = 0.038666999402389 
2016-12-10 01:58:27 -------------------LR------------------- 
2016-12-10 01:58:27 0.001953125 
2016-12-10 01:58:27 Epoch 159 
2016-12-10 01:59:28 Training Error = 0.6318347509113 
2016-12-10 01:59:28 Training Loss = 0.028500140210306 
2016-12-10 01:59:30 Valid Error = 0.76306196840826 
2016-12-10 01:59:30 Valid Loss = 0.036775785393786 
2016-12-10 01:59:32 Test Error = 0.79803493449782 
2016-12-10 01:59:32 Test Loss = 0.038570999647278 
2016-12-10 01:59:32 -------------------LR------------------- 
2016-12-10 01:59:32 0.001953125 
2016-12-10 01:59:32 Epoch 160 
2016-12-10 02:00:45 Training Error = 0.63439989199406 
2016-12-10 02:00:45 Training Loss = 0.028457606342587 
2016-12-10 02:00:47 Valid Error = 0.76306196840826 
2016-12-10 02:00:47 Valid Loss = 0.036932259327104 
2016-12-10 02:00:49 Test Error = 0.79803493449782 
2016-12-10 02:00:49 Test Loss = 0.038740250627979 
2016-12-10 02:00:49 -------------------LR------------------- 
2016-12-10 02:00:49 0.001953125 
2016-12-10 02:00:49 Epoch 161 
2016-12-10 02:01:50 Training Error = 0.63399486971783 
2016-12-10 02:01:50 Training Loss = 0.02842707037124 
2016-12-10 02:01:52 Valid Error = 0.76306196840826 
2016-12-10 02:01:52 Valid Loss = 0.037882695510137 
2016-12-10 02:01:54 Test Error = 0.79803493449782 
2016-12-10 02:01:54 Test Loss = 0.039637331214606 
2016-12-10 02:01:54 -------------------LR------------------- 
2016-12-10 02:01:54 0.001953125 
2016-12-10 02:01:54 Epoch 162 
2016-12-10 02:02:56 Training Error = 0.63358984744161 
2016-12-10 02:02:56 Training Loss = 0.028407014016544 
2016-12-10 02:02:58 Valid Error = 0.76306196840826 
2016-12-10 02:02:58 Valid Loss = 0.037110418030517 
2016-12-10 02:03:00 Test Error = 0.79803493449782 
2016-12-10 02:03:00 Test Loss = 0.038933075611887 
2016-12-10 02:03:00 -------------------LR------------------- 
2016-12-10 02:03:00 0.001953125 
2016-12-10 02:03:00 Epoch 163 
2016-12-10 02:04:01 Training Error = 0.63291481031457 
2016-12-10 02:04:01 Training Loss = 0.028450714987223 
2016-12-10 02:04:03 Valid Error = 0.76306196840826 
2016-12-10 02:04:03 Valid Loss = 0.036462369481831 
2016-12-10 02:04:05 Test Error = 0.79803493449782 
2016-12-10 02:04:05 Test Loss = 0.038339706012626 
2016-12-10 02:04:05 -------------------LR------------------- 
2016-12-10 02:04:05 0.001953125 
2016-12-10 02:04:05 Epoch 164 
