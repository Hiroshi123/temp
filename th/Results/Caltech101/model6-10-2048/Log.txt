2016-12-10 05:49:05 [program started on Sat Dec 10 05:49:05 2016] 
2016-12-10 05:49:05 [command line arguments] 
2016-12-10 05:49:05 stcWeights false 
2016-12-10 05:49:05 LR 0.015625 
2016-12-10 05:49:05 batchSize 100 
2016-12-10 05:49:05 network ./Models/Cifar10_Custom 
2016-12-10 05:49:05 stcNeurons true 
2016-12-10 05:49:05 constBatchSize false 
2016-12-10 05:49:05 chartFileName chart1 
2016-12-10 05:49:05 dp_prepro false 
2016-12-10 05:49:05 nGPU 1 
2016-12-10 05:49:05 dataset Caltech101 
2016-12-10 05:49:05 type cuda 
2016-12-10 05:49:05 momentum 0 
2016-12-10 05:49:05 threads 8 
2016-12-10 05:49:05 weightDecay 0 
2016-12-10 05:49:05 runningVal false 
2016-12-10 05:49:05 convLayerN 6 
2016-12-10 05:49:05 LRDecay 0 
2016-12-10 05:49:05 numHid 2048 
2016-12-10 05:49:05 save /dev/shm/clone/temp/th/Results/Caltech101/model6-10-2048 
2016-12-10 05:49:05 augment false 
2016-12-10 05:49:05 epoch -1 
2016-12-10 05:49:05 modelsFolder ./Models/ 
2016-12-10 05:49:05 format rgb 
2016-12-10 05:49:05 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-10 05:49:05 imageFileExtension svg 
2016-12-10 05:49:05 channel 1 
2016-12-10 05:49:05 devid 11 
2016-12-10 05:49:05 visualize 1 
2016-12-10 05:49:05 LRDecayPerEpoch 0.0001 
2016-12-10 05:49:05 optimization adam 
2016-12-10 05:49:05 SBN true 
2016-12-10 05:49:05 normalization simple 
2016-12-10 05:49:05 title model1 
2016-12-10 05:49:05 load  
2016-12-10 05:49:05 whiten true 
2016-12-10 05:49:05 [----------------------] 
2016-12-10 05:49:07 ==> Network 
2016-12-10 05:49:07 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 2048)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(2048 -> 2048)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(2048 -> 102)
  (38): nn.BatchNormalization
} 
2016-12-10 05:49:07 ==>25772978 Parameters 
2016-12-10 05:49:07 ==> Loss 
2016-12-10 05:49:07 SqrtHingeEmbeddingCriterion 
2016-12-10 05:49:07 
==> Starting Training
 
2016-12-10 05:49:07 Epoch 1 
2016-12-10 05:50:43 Training Error = 0.80450924800864 
2016-12-10 05:50:43 Training Loss = 0.42673221495385 
2016-12-10 05:50:45 Valid Error = 0.81287970838396 
2016-12-10 05:50:45 Valid Loss = 0.070859704573656 
2016-12-10 05:50:47 Test Error = 0.82314410480349 
2016-12-10 05:50:47 Test Loss = 0.072009207089742 
2016-12-10 05:50:47 -------------------LR------------------- 
2016-12-10 05:50:47 0.015625 
2016-12-10 05:50:47 Epoch 2 
2016-12-10 05:52:18 Training Error = 0.68030241663291 
2016-12-10 05:52:18 Training Loss = 0.041920889132631 
2016-12-10 05:52:20 Valid Error = 0.72053462940462 
2016-12-10 05:52:20 Valid Loss = 0.034831377141255 
2016-12-10 05:52:22 Test Error = 0.75218340611354 
2016-12-10 05:52:22 Test Loss = 0.036282951523276 
2016-12-10 05:52:22 -------------------LR------------------- 
2016-12-10 05:52:22 0.015625 
2016-12-10 05:52:22 Epoch 3 
2016-12-10 05:53:55 Training Error = 0.62076414202781 
2016-12-10 05:53:55 Training Loss = 0.029909920622098 
2016-12-10 05:53:57 Valid Error = 0.72053462940462 
2016-12-10 05:53:57 Valid Loss = 0.031218223821104 
2016-12-10 05:53:59 Test Error = 0.75218340611354 
2016-12-10 05:53:59 Test Loss = 0.033330464737088 
2016-12-10 05:53:59 -------------------LR------------------- 
2016-12-10 05:53:59 0.015625 
2016-12-10 05:53:59 Epoch 4 
2016-12-10 05:55:33 Training Error = 0.60213311732145 
2016-12-10 05:55:33 Training Loss = 0.028227717732804 
2016-12-10 05:55:35 Valid Error = 0.74726609963548 
2016-12-10 05:55:35 Valid Loss = 0.030388561312737 
2016-12-10 05:55:37 Test Error = 0.78493449781659 
2016-12-10 05:55:37 Test Loss = 0.032032748839434 
2016-12-10 05:55:37 -------------------LR------------------- 
2016-12-10 05:55:37 0.015625 
2016-12-10 05:55:37 Epoch 5 
2016-12-10 05:57:09 Training Error = 0.58134197380856 
2016-12-10 05:57:09 Training Loss = 0.02737177319353 
2016-12-10 05:57:11 Valid Error = 0.67922235722965 
2016-12-10 05:57:11 Valid Loss = 0.028680856366314 
2016-12-10 05:57:13 Test Error = 0.70305676855895 
2016-12-10 05:57:13 Test Loss = 0.030220931529999 
2016-12-10 05:57:13 -------------------LR------------------- 
2016-12-10 05:57:13 0.015625 
2016-12-10 05:57:13 Epoch 6 
2016-12-10 05:58:49 Training Error = 0.55852571891454 
2016-12-10 05:58:49 Training Loss = 0.026687134373199 
2016-12-10 05:58:51 Valid Error = 0.65370595382746 
2016-12-10 05:58:51 Valid Loss = 0.037487970489302 
2016-12-10 05:58:53 Test Error = 0.71069868995633 
2016-12-10 05:58:53 Test Loss = 0.040684370620578 
2016-12-10 05:58:53 -------------------LR------------------- 
2016-12-10 05:58:53 0.015625 
2016-12-10 05:58:53 Epoch 7 
2016-12-10 06:00:39 Training Error = 0.54326987984339 
2016-12-10 06:00:39 Training Loss = 0.026192981836086 
2016-12-10 06:00:41 Valid Error = 0.65978128797084 
2016-12-10 06:00:41 Valid Loss = 0.030091549605145 
2016-12-10 06:00:43 Test Error = 0.70524017467249 
2016-12-10 06:00:43 Test Loss = 0.032609335918053 
2016-12-10 06:00:43 -------------------LR------------------- 
2016-12-10 06:00:43 0.015625 
2016-12-10 06:00:43 Epoch 8 
2016-12-10 06:02:19 Training Error = 0.51100310517078 
2016-12-10 06:02:19 Training Loss = 0.025190715062474 
2016-12-10 06:02:21 Valid Error = 0.48724179829891 
2016-12-10 06:02:21 Valid Loss = 0.02661180666589 
2016-12-10 06:02:23 Test Error = 0.52947598253275 
2016-12-10 06:02:23 Test Loss = 0.028988655763514 
2016-12-10 06:02:23 -------------------LR------------------- 
2016-12-10 06:02:23 0.015625 
2016-12-10 06:02:23 Epoch 9 
2016-12-10 06:03:57 Training Error = 0.44876468205751 
2016-12-10 06:03:57 Training Loss = 0.02398770754945 
2016-12-10 06:03:59 Valid Error = 0.59052247873633 
2016-12-10 06:03:59 Valid Loss = 0.030145831963121 
2016-12-10 06:04:01 Test Error = 0.62991266375546 
2016-12-10 06:04:01 Test Loss = 0.03372294736376 
2016-12-10 06:04:01 -------------------LR------------------- 
2016-12-10 06:04:01 0.015625 
2016-12-10 06:04:01 Epoch 10 
2016-12-10 06:06:12 Training Error = 0.38855137032537 
2016-12-10 06:06:12 Training Loss = 0.022493024197391 
2016-12-10 06:06:14 Valid Error = 0.64398541919806 
2016-12-10 06:06:14 Valid Loss = 0.032478314755913 
2016-12-10 06:06:16 Test Error = 0.66921397379913 
2016-12-10 06:06:16 Test Loss = 0.03383268068351 
2016-12-10 06:06:16 -------------------LR------------------- 
2016-12-10 06:06:16 0.015625 
2016-12-10 06:06:16 Epoch 11 
2016-12-10 06:08:16 Training Error = 0.37694073174025 
2016-12-10 06:08:16 Training Loss = 0.02270358292609 
2016-12-10 06:08:18 Valid Error = 0.41433778857837 
2016-12-10 06:08:18 Valid Loss = 0.023623847509747 
2016-12-10 06:08:20 Test Error = 0.42685589519651 
2016-12-10 06:08:20 Test Loss = 0.025845181222055 
2016-12-10 06:08:20 -------------------LR------------------- 
2016-12-10 06:08:20 0.015625 
2016-12-10 06:08:20 Epoch 12 
2016-12-10 06:09:55 Training Error = 0.38342108815985 
2016-12-10 06:09:55 Training Loss = 0.022790957806869 
2016-12-10 06:09:57 Valid Error = 0.4678007290401 
2016-12-10 06:09:57 Valid Loss = 0.026507060795421 
2016-12-10 06:09:59 Test Error = 0.46834061135371 
2016-12-10 06:09:59 Test Loss = 0.028972537022011 
2016-12-10 06:09:59 -------------------LR------------------- 
2016-12-10 06:09:59 0.015625 
2016-12-10 06:09:59 Epoch 13 
2016-12-10 06:12:00 Training Error = 0.38018090995005 
2016-12-10 06:12:00 Training Loss = 0.022574853575463 
2016-12-10 06:12:01 Valid Error = 0.38396111786148 
2016-12-10 06:12:01 Valid Loss = 0.025064338603864 
2016-12-10 06:12:04 Test Error = 0.39628820960699 
2016-12-10 06:12:04 Test Loss = 0.02778562338212 
2016-12-10 06:12:04 -------------------LR------------------- 
2016-12-10 06:12:04 0.015625 
2016-12-10 06:12:04 Epoch 14 
2016-12-10 06:13:53 Training Error = 0.38625624409343 
2016-12-10 06:13:53 Training Loss = 0.022665397981702 
2016-12-10 06:13:55 Valid Error = 0.37424058323208 
2016-12-10 06:13:55 Valid Loss = 0.026827020026342 
2016-12-10 06:13:57 Test Error = 0.36899563318777 
2016-12-10 06:13:57 Test Loss = 0.029452058754715 
2016-12-10 06:13:57 -------------------LR------------------- 
2016-12-10 06:13:57 0.015625 
2016-12-10 06:13:57 Epoch 15 
2016-12-10 06:15:36 Training Error = 0.38463615498852 
2016-12-10 06:15:36 Training Loss = 0.022594086290319 
2016-12-10 06:15:38 Valid Error = 0.40461725394897 
2016-12-10 06:15:38 Valid Loss = 0.024324610382135 
2016-12-10 06:15:40 Test Error = 0.39410480349345 
2016-12-10 06:15:40 Test Loss = 0.02665345473383 
2016-12-10 06:15:40 -------------------LR------------------- 
2016-12-10 06:15:40 0.015625 
2016-12-10 06:15:40 Epoch 16 
2016-12-10 06:17:18 Training Error = 0.37950587282301 
2016-12-10 06:17:18 Training Loss = 0.022563292677707 
2016-12-10 06:17:20 Valid Error = 0.37424058323208 
2016-12-10 06:17:20 Valid Loss = 0.025022937384046 
2016-12-10 06:17:22 Test Error = 0.36899563318777 
2016-12-10 06:17:22 Test Loss = 0.027422002998053 
2016-12-10 06:17:22 -------------------LR------------------- 
2016-12-10 06:17:22 0.015625 
2016-12-10 06:17:22 Epoch 17 
2016-12-10 06:19:04 Training Error = 0.37964088024841 
2016-12-10 06:19:04 Training Loss = 0.022746650681554 
2016-12-10 06:19:06 Valid Error = 0.39003645200486 
2016-12-10 06:19:06 Valid Loss = 0.025974378182015 
2016-12-10 06:19:08 Test Error = 0.38646288209607 
2016-12-10 06:19:08 Test Loss = 0.028434125376683 
2016-12-10 06:19:08 -------------------LR------------------- 
2016-12-10 06:19:08 0.015625 
2016-12-10 06:19:08 Epoch 18 
2016-12-10 06:20:51 Training Error = 0.37680572431484 
2016-12-10 06:20:51 Training Loss = 0.022709804256379 
2016-12-10 06:20:52 Valid Error = 0.40461725394897 
2016-12-10 06:20:52 Valid Loss = 0.025284092180361 
2016-12-10 06:20:54 Test Error = 0.41484716157205 
2016-12-10 06:20:54 Test Loss = 0.02789484425152 
2016-12-10 06:20:54 -------------------LR------------------- 
2016-12-10 06:20:54 0.015625 
2016-12-10 06:20:54 Epoch 19 
2016-12-10 06:22:39 Training Error = 0.3809909545025 
2016-12-10 06:22:39 Training Loss = 0.02283709206176 
2016-12-10 06:22:41 Valid Error = 0.38760631834751 
2016-12-10 06:22:41 Valid Loss = 0.025995407928354 
2016-12-10 06:22:43 Test Error = 0.40174672489083 
2016-12-10 06:22:43 Test Loss = 0.02872588557823 
2016-12-10 06:22:43 -------------------LR------------------- 
2016-12-10 06:22:43 0.015625 
2016-12-10 06:22:43 Epoch 20 
2016-12-10 06:24:28 Training Error = 0.37653570946402 
2016-12-10 06:24:28 Training Loss = 0.022642312486722 
2016-12-10 06:24:30 Valid Error = 0.37667071688943 
2016-12-10 06:24:30 Valid Loss = 0.026082421407856 
2016-12-10 06:24:32 Test Error = 0.38427947598253 
2016-12-10 06:24:32 Test Loss = 0.028400396347046 
2016-12-10 06:24:32 -------------------LR------------------- 
2016-12-10 06:24:32 0.015625 
2016-12-10 06:24:32 Epoch 21 
2016-12-10 06:26:17 Training Error = 0.38220602133117 
2016-12-10 06:26:17 Training Loss = 0.022698655249046 
2016-12-10 06:26:19 Valid Error = 0.45808019441069 
2016-12-10 06:26:19 Valid Loss = 0.027957562042523 
2016-12-10 06:26:21 Test Error = 0.48471615720524 
2016-12-10 06:26:21 Test Loss = 0.030824512893078 
2016-12-10 06:26:21 -------------------LR------------------- 
2016-12-10 06:26:21 0.015625 
2016-12-10 06:26:21 Epoch 22 
2016-12-10 06:28:22 Training Error = 0.38112596192791 
2016-12-10 06:28:22 Training Loss = 0.02265218265651 
2016-12-10 06:28:24 Valid Error = 0.38153098420413 
2016-12-10 06:28:24 Valid Loss = 0.025453684623352 
2016-12-10 06:28:26 Test Error = 0.39192139737991 
2016-12-10 06:28:26 Test Loss = 0.027983199942346 
2016-12-10 06:28:26 -------------------LR------------------- 
2016-12-10 06:28:26 0.015625 
2016-12-10 06:28:26 Epoch 23 
2016-12-10 06:30:19 Training Error = 0.38274605103281 
2016-12-10 06:30:19 Training Loss = 0.02274488191293 
2016-12-10 06:30:20 Valid Error = 0.37424058323208 
2016-12-10 06:30:20 Valid Loss = 0.026198749988495 
2016-12-10 06:30:22 Test Error = 0.39410480349345 
2016-12-10 06:30:22 Test Loss = 0.028903998393638 
2016-12-10 06:30:22 -------------------LR------------------- 
2016-12-10 06:30:22 0.015625 
2016-12-10 06:30:22 Epoch 24 
2016-12-10 06:32:16 Training Error = 0.38031591737546 
2016-12-10 06:32:16 Training Loss = 0.022751374456439 
2016-12-10 06:32:18 Valid Error = 0.46172539489672 
2016-12-10 06:32:18 Valid Loss = 0.024457292151155 
2016-12-10 06:32:20 Test Error = 0.49017467248908 
2016-12-10 06:32:20 Test Loss = 0.027063599689334 
2016-12-10 06:32:20 -------------------LR------------------- 
2016-12-10 06:32:20 0.015625 
2016-12-10 06:32:20 Epoch 25 
2016-12-10 06:34:10 Training Error = 0.38207101390576 
2016-12-10 06:34:10 Training Loss = 0.022707543811388 
2016-12-10 06:34:12 Valid Error = 0.38153098420413 
2016-12-10 06:34:12 Valid Loss = 0.02637370117598 
2016-12-10 06:34:14 Test Error = 0.39192139737991 
2016-12-10 06:34:14 Test Loss = 0.028919879240148 
2016-12-10 06:34:14 -------------------LR------------------- 
2016-12-10 06:34:14 0.015625 
2016-12-10 06:34:14 Epoch 26 
2016-12-10 06:36:04 Training Error = 0.38112596192791 
2016-12-10 06:36:04 Training Loss = 0.022739936942591 
2016-12-10 06:36:06 Valid Error = 0.37667071688943 
2016-12-10 06:36:06 Valid Loss = 0.02576302212116 
2016-12-10 06:36:08 Test Error = 0.38427947598253 
2016-12-10 06:36:08 Test Loss = 0.02814069482392 
2016-12-10 06:36:08 -------------------LR------------------- 
2016-12-10 06:36:08 0.015625 
2016-12-10 06:36:08 Epoch 27 
2016-12-10 06:38:04 Training Error = 0.38031591737546 
2016-12-10 06:38:04 Training Loss = 0.022879761309227 
2016-12-10 06:38:06 Valid Error = 0.40461725394897 
2016-12-10 06:38:06 Valid Loss = 0.02366928116485 
2016-12-10 06:38:08 Test Error = 0.4061135371179 
2016-12-10 06:38:08 Test Loss = 0.026168082499037 
2016-12-10 06:38:08 -------------------LR------------------- 
2016-12-10 06:38:08 0.015625 
2016-12-10 06:38:08 Epoch 28 
2016-12-10 06:40:01 Training Error = 0.38301606588362 
2016-12-10 06:40:01 Training Loss = 0.022812745974244 
2016-12-10 06:40:03 Valid Error = 0.45808019441069 
2016-12-10 06:40:03 Valid Loss = 0.027302737180466 
2016-12-10 06:40:05 Test Error = 0.46397379912664 
2016-12-10 06:40:05 Test Loss = 0.029895125669592 
2016-12-10 06:40:05 -------------------LR------------------- 
2016-12-10 06:40:05 0.015625 
2016-12-10 06:40:05 Epoch 29 
2016-12-10 06:41:54 Training Error = 0.38004590252464 
2016-12-10 06:41:54 Training Loss = 0.022632964260126 
2016-12-10 06:41:56 Valid Error = 0.39489671931956 
2016-12-10 06:41:56 Valid Loss = 0.024924335832046 
2016-12-10 06:41:58 Test Error = 0.41157205240175 
2016-12-10 06:41:58 Test Loss = 0.027280935409022 
2016-12-10 06:41:58 -------------------LR------------------- 
2016-12-10 06:41:58 0.015625 
2016-12-10 06:41:58 Epoch 30 
2016-12-10 06:43:52 Training Error = 0.3777507762927 
2016-12-10 06:43:52 Training Loss = 0.022928533747483 
2016-12-10 06:43:54 Valid Error = 0.38153098420413 
2016-12-10 06:43:54 Valid Loss = 0.025367480400239 
2016-12-10 06:43:56 Test Error = 0.39192139737991 
2016-12-10 06:43:56 Test Loss = 0.02801496294433 
2016-12-10 06:43:56 -------------------LR------------------- 
2016-12-10 06:43:56 0.015625 
2016-12-10 06:43:56 Epoch 31 
2016-12-10 06:45:53 Training Error = 0.37815579856892 
2016-12-10 06:45:53 Training Loss = 0.022741869349262 
2016-12-10 06:45:55 Valid Error = 0.46415552855407 
2016-12-10 06:45:55 Valid Loss = 0.027994722932015 
2016-12-10 06:45:57 Test Error = 0.47161572052402 
2016-12-10 06:45:57 Test Loss = 0.030404030089285 
2016-12-10 06:45:57 -------------------LR------------------- 
2016-12-10 06:45:57 0.015625 
2016-12-10 06:45:57 Epoch 32 
2016-12-10 06:47:41 Training Error = 0.38301606588362 
2016-12-10 06:47:41 Training Loss = 0.022942697947099 
2016-12-10 06:47:43 Valid Error = 0.47023086269745 
2016-12-10 06:47:43 Valid Loss = 0.02554516263201 
2016-12-10 06:47:45 Test Error = 0.45851528384279 
2016-12-10 06:47:45 Test Loss = 0.027925228287192 
2016-12-10 06:47:45 -------------------LR------------------- 
2016-12-10 06:47:45 0.015625 
2016-12-10 06:47:45 Epoch 33 
2016-12-10 06:49:41 Training Error = 0.38274605103281 
2016-12-10 06:49:41 Training Loss = 0.022815191666063 
2016-12-10 06:49:43 Valid Error = 0.38517618469016 
2016-12-10 06:49:43 Valid Loss = 0.025422937946585 
2016-12-10 06:49:45 Test Error = 0.39956331877729 
2016-12-10 06:49:45 Test Loss = 0.027636695010989 
2016-12-10 06:49:45 -------------------LR------------------- 
2016-12-10 06:49:45 0.015625 
2016-12-10 06:49:45 Epoch 34 
2016-12-10 06:51:52 Training Error = 0.38207101390576 
2016-12-10 06:51:52 Training Loss = 0.022736673550646 
2016-12-10 06:51:55 Valid Error = 0.39611178614824 
2016-12-10 06:51:55 Valid Loss = 0.02422964599962 
2016-12-10 06:51:57 Test Error = 0.4061135371179 
2016-12-10 06:51:57 Test Loss = 0.026533524653491 
2016-12-10 06:51:57 -------------------LR------------------- 
2016-12-10 06:51:57 0.015625 
2016-12-10 06:51:57 Epoch 35 
2016-12-10 06:54:08 Training Error = 0.38382611043607 
2016-12-10 06:54:08 Training Loss = 0.022918463671886 
2016-12-10 06:54:10 Valid Error = 0.47995139732685 
2016-12-10 06:54:10 Valid Loss = 0.026341107314177 
2016-12-10 06:54:12 Test Error = 0.49235807860262 
2016-12-10 06:54:12 Test Loss = 0.029176471616708 
2016-12-10 06:54:12 -------------------LR------------------- 
2016-12-10 06:54:12 0.015625 
2016-12-10 06:54:12 Epoch 36 
2016-12-10 06:56:32 Training Error = 0.38328608073444 
2016-12-10 06:56:32 Training Loss = 0.022727903293072 
2016-12-10 06:56:34 Valid Error = 0.38882138517618 
2016-12-10 06:56:34 Valid Loss = 0.024195540806578 
2016-12-10 06:56:36 Test Error = 0.37772925764192 
2016-12-10 06:56:36 Test Loss = 0.026514673363929 
2016-12-10 06:56:36 -------------------LR------------------- 
2016-12-10 06:56:36 0.015625 
2016-12-10 06:56:36 Epoch 37 
2016-12-10 06:58:46 Training Error = 0.38288105845822 
2016-12-10 06:58:46 Training Loss = 0.022657617916958 
2016-12-10 06:58:48 Valid Error = 0.38882138517618 
2016-12-10 06:58:48 Valid Loss = 0.025064164638926 
2016-12-10 06:58:50 Test Error = 0.4028384279476 
2016-12-10 06:58:50 Test Loss = 0.027358046933716 
2016-12-10 06:58:50 -------------------LR------------------- 
2016-12-10 06:58:50 0.015625 
2016-12-10 06:58:50 Epoch 38 
2016-12-10 07:01:09 Training Error = 0.37883083569596 
2016-12-10 07:01:09 Training Loss = 0.022803495184491 
2016-12-10 07:01:11 Valid Error = 0.40097205346294 
2016-12-10 07:01:11 Valid Loss = 0.025580551054957 
2016-12-10 07:01:13 Test Error = 0.42248908296943 
2016-12-10 07:01:13 Test Loss = 0.028049713620953 
2016-12-10 07:01:13 -------------------LR------------------- 
2016-12-10 07:01:13 0.015625 
2016-12-10 07:01:13 Epoch 39 
2016-12-10 07:03:21 Training Error = 0.38112596192791 
2016-12-10 07:03:21 Training Loss = 0.022750370956692 
2016-12-10 07:03:22 Valid Error = 0.38760631834751 
2016-12-10 07:03:22 Valid Loss = 0.02498097968167 
2016-12-10 07:03:25 Test Error = 0.38755458515284 
2016-12-10 07:03:25 Test Loss = 0.027325362757141 
2016-12-10 07:03:25 -------------------LR------------------- 
2016-12-10 07:03:25 0.015625 
2016-12-10 07:03:25 Epoch 40 
2016-12-10 07:05:41 Training Error = 0.38004590252464 
2016-12-10 07:05:41 Training Loss = 0.022667814287173 
2016-12-10 07:05:44 Valid Error = 0.41190765492102 
2016-12-10 07:05:44 Valid Loss = 0.023597834916732 
2016-12-10 07:05:47 Test Error = 0.41703056768559 
2016-12-10 07:05:47 Test Loss = 0.026026827316658 
2016-12-10 07:05:47 -------------------LR------------------- 
2016-12-10 07:05:47 0.015625 
2016-12-10 07:05:47 Epoch 41 
2016-12-10 07:08:00 Training Error = 0.37667071688943 
2016-12-10 07:08:00 Training Loss = 0.022688713686362 
2016-12-10 07:08:02 Valid Error = 0.3681652490887 
2016-12-10 07:08:02 Valid Loss = 0.025735506153676 
2016-12-10 07:08:04 Test Error = 0.367903930131 
2016-12-10 07:08:04 Test Loss = 0.028448133319032 
2016-12-10 07:08:04 -------------------LR------------------- 
2016-12-10 07:08:04 0.015625 
2016-12-10 07:08:04 Epoch 42 
2016-12-10 07:10:23 Training Error = 0.38328608073444 
2016-12-10 07:10:23 Training Loss = 0.022843679699867 
2016-12-10 07:10:25 Valid Error = 0.47144592952612 
2016-12-10 07:10:25 Valid Loss = 0.026683356684469 
2016-12-10 07:10:27 Test Error = 0.49563318777293 
2016-12-10 07:10:27 Test Loss = 0.028762324062048 
2016-12-10 07:10:27 -------------------LR------------------- 
2016-12-10 07:10:27 0.015625 
2016-12-10 07:10:27 Epoch 43 
2016-12-10 07:12:31 Training Error = 0.38193600648036 
2016-12-10 07:12:31 Training Loss = 0.022850068147376 
2016-12-10 07:12:33 Valid Error = 0.37667071688943 
2016-12-10 07:12:33 Valid Loss = 0.024110093625802 
2016-12-10 07:12:35 Test Error = 0.38427947598253 
2016-12-10 07:12:35 Test Loss = 0.02636425188476 
2016-12-10 07:12:35 -------------------LR------------------- 
2016-12-10 07:12:35 0.015625 
2016-12-10 07:12:35 Epoch 44 
2016-12-10 07:14:54 Training Error = 0.38018090995005 
2016-12-10 07:14:54 Training Loss = 0.022562109309463 
2016-12-10 07:14:56 Valid Error = 0.37667071688943 
2016-12-10 07:14:56 Valid Loss = 0.026682867390014 
2016-12-10 07:14:58 Test Error = 0.38427947598253 
2016-12-10 07:14:58 Test Loss = 0.029094138257644 
2016-12-10 07:14:58 -------------------LR------------------- 
2016-12-10 07:14:58 0.015625 
2016-12-10 07:14:58 Epoch 45 
2016-12-10 07:17:13 Training Error = 0.38409612528689 
2016-12-10 07:17:13 Training Loss = 0.022775109786346 
2016-12-10 07:17:15 Valid Error = 0.39003645200486 
2016-12-10 07:17:15 Valid Loss = 0.02540904144926 
2016-12-10 07:17:17 Test Error = 0.39737991266376 
2016-12-10 07:17:17 Test Loss = 0.027917100747426 
2016-12-10 07:17:17 -------------------LR------------------- 
2016-12-10 07:17:17 0.015625 
2016-12-10 07:17:17 Epoch 46 
2016-12-10 07:19:35 Training Error = 0.3842311327123 
2016-12-10 07:19:35 Training Loss = 0.022722514589739 
2016-12-10 07:19:37 Valid Error = 0.37667071688943 
2016-12-10 07:19:37 Valid Loss = 0.025047546246518 
2016-12-10 07:19:39 Test Error = 0.37227074235808 
2016-12-10 07:19:39 Test Loss = 0.027492940481971 
2016-12-10 07:19:39 -------------------LR------------------- 
2016-12-10 07:19:39 0.015625 
2016-12-10 07:19:39 Epoch 47 
2016-12-10 07:21:57 Training Error = 0.37977588767382 
2016-12-10 07:21:57 Training Loss = 0.02263710924535 
2016-12-10 07:21:59 Valid Error = 0.3730255164034 
2016-12-10 07:21:59 Valid Loss = 0.025278380259291 
2016-12-10 07:22:01 Test Error = 0.37554585152838 
2016-12-10 07:22:01 Test Loss = 0.028050307601106 
2016-12-10 07:22:01 -------------------LR------------------- 
2016-12-10 07:22:01 0.015625 
2016-12-10 07:22:01 Epoch 48 
2016-12-10 07:24:08 Training Error = 0.37923585797219 
2016-12-10 07:24:08 Training Loss = 0.022798726582104 
2016-12-10 07:24:10 Valid Error = 0.38396111786148 
2016-12-10 07:24:10 Valid Loss = 0.024260968100542 
2016-12-10 07:24:12 Test Error = 0.39519650655022 
2016-12-10 07:24:12 Test Loss = 0.02634728528939 
2016-12-10 07:24:12 -------------------LR------------------- 
2016-12-10 07:24:12 0.015625 
2016-12-10 07:24:12 Epoch 49 
2016-12-10 07:26:33 Training Error = 0.37991089509923 
2016-12-10 07:26:33 Training Loss = 0.022691252958296 
2016-12-10 07:26:35 Valid Error = 0.39125151883354 
2016-12-10 07:26:35 Valid Loss = 0.025154864820802 
2016-12-10 07:26:37 Test Error = 0.39301310043668 
2016-12-10 07:26:37 Test Loss = 0.027563889035992 
2016-12-10 07:26:37 -------------------LR------------------- 
2016-12-10 07:26:37 0.015625 
2016-12-10 07:26:37 Epoch 50 
2016-12-10 07:28:55 Training Error = 0.38274605103281 
2016-12-10 07:28:55 Training Loss = 0.022770019390202 
2016-12-10 07:28:57 Valid Error = 0.4131227217497 
2016-12-10 07:28:57 Valid Loss = 0.025626420706434 
2016-12-10 07:28:59 Test Error = 0.41921397379913 
2016-12-10 07:28:59 Test Loss = 0.028317488689049 
2016-12-10 07:28:59 -------------------LR------------------- 
2016-12-10 07:28:59 0.0078125 
2016-12-10 07:28:59 Epoch 51 
2016-12-10 07:31:19 Training Error = 0.37883083569596 
2016-12-10 07:31:19 Training Loss = 0.022806639154685 
2016-12-10 07:31:21 Valid Error = 0.39732685297691 
2016-12-10 07:31:21 Valid Loss = 0.026414795030278 
2016-12-10 07:31:23 Test Error = 0.38318777292576 
2016-12-10 07:31:23 Test Loss = 0.029054889061872 
2016-12-10 07:31:23 -------------------LR------------------- 
2016-12-10 07:31:23 0.0078125 
2016-12-10 07:31:23 Epoch 52 
2016-12-10 07:33:38 Training Error = 0.38396111786148 
2016-12-10 07:33:38 Training Loss = 0.022712497079317 
2016-12-10 07:33:40 Valid Error = 0.41433778857837 
2016-12-10 07:33:40 Valid Loss = 0.023903566053151 
2016-12-10 07:33:42 Test Error = 0.42685589519651 
2016-12-10 07:33:42 Test Loss = 0.026129984491012 
2016-12-10 07:33:42 -------------------LR------------------- 
2016-12-10 07:33:42 0.0078125 
2016-12-10 07:33:42 Epoch 53 
2016-12-10 07:35:50 Training Error = 0.37883083569596 
2016-12-10 07:35:50 Training Loss = 0.0228457023528 
2016-12-10 07:35:52 Valid Error = 0.4823815309842 
2016-12-10 07:35:52 Valid Loss = 0.02550833776253 
2016-12-10 07:35:54 Test Error = 0.5 
2016-12-10 07:35:54 Test Loss = 0.028112325369143 
2016-12-10 07:35:54 -------------------LR------------------- 
2016-12-10 07:35:54 0.0078125 
2016-12-10 07:35:54 Epoch 54 
2016-12-10 07:38:10 Training Error = 0.38112596192791 
2016-12-10 07:38:10 Training Loss = 0.02269466247986 
2016-12-10 07:38:12 Valid Error = 0.44106925880923 
2016-12-10 07:38:12 Valid Loss = 0.026300516940658 
2016-12-10 07:38:14 Test Error = 0.45851528384279 
2016-12-10 07:38:14 Test Loss = 0.029048234247694 
2016-12-10 07:38:14 -------------------LR------------------- 
2016-12-10 07:38:14 0.0078125 
2016-12-10 07:38:14 Epoch 55 
2016-12-10 07:40:34 Training Error = 0.37856082084515 
2016-12-10 07:40:34 Training Loss = 0.022617175522349 
2016-12-10 07:40:36 Valid Error = 0.40826245443499 
2016-12-10 07:40:36 Valid Loss = 0.025425062758617 
2016-12-10 07:40:38 Test Error = 0.41921397379913 
2016-12-10 07:40:38 Test Loss = 0.0279835878073 
2016-12-10 07:40:38 -------------------LR------------------- 
2016-12-10 07:40:38 0.0078125 
2016-12-10 07:40:38 Epoch 56 
2016-12-10 07:42:55 Training Error = 0.37883083569596 
2016-12-10 07:42:55 Training Loss = 0.022699584010647 
2016-12-10 07:42:57 Valid Error = 0.37667071688943 
2016-12-10 07:42:57 Valid Loss = 0.024890320208688 
2016-12-10 07:42:59 Test Error = 0.38427947598253 
2016-12-10 07:42:59 Test Loss = 0.027561620702931 
2016-12-10 07:42:59 -------------------LR------------------- 
2016-12-10 07:42:59 0.0078125 
2016-12-10 07:42:59 Epoch 57 
2016-12-10 07:45:12 Training Error = 0.38504117726475 
2016-12-10 07:45:12 Training Loss = 0.022784042714579 
2016-12-10 07:45:14 Valid Error = 0.45686512758202 
2016-12-10 07:45:14 Valid Loss = 0.027379025199755 
2016-12-10 07:45:16 Test Error = 0.4617903930131 
2016-12-10 07:45:16 Test Loss = 0.029957126972722 
2016-12-10 07:45:16 -------------------LR------------------- 
2016-12-10 07:45:16 0.0078125 
2016-12-10 07:45:16 Epoch 58 
2016-12-10 07:47:27 Training Error = 0.38517618469016 
2016-12-10 07:47:27 Training Loss = 0.022772355889784 
2016-12-10 07:47:29 Valid Error = 0.39489671931956 
2016-12-10 07:47:29 Valid Loss = 0.026171112963904 
2016-12-10 07:47:31 Test Error = 0.39301310043668 
2016-12-10 07:47:31 Test Loss = 0.028559384953742 
2016-12-10 07:47:31 -------------------LR------------------- 
2016-12-10 07:47:31 0.0078125 
2016-12-10 07:47:31 Epoch 59 
2016-12-10 07:49:48 Training Error = 0.37856082084515 
2016-12-10 07:49:48 Training Loss = 0.022712593102834 
2016-12-10 07:49:49 Valid Error = 0.38031591737546 
2016-12-10 07:49:49 Valid Loss = 0.027580342120696 
2016-12-10 07:49:52 Test Error = 0.38100436681223 
2016-12-10 07:49:52 Test Loss = 0.030030111612058 
2016-12-10 07:49:52 -------------------LR------------------- 
2016-12-10 07:49:52 0.0078125 
2016-12-10 07:49:52 Epoch 60 
2016-12-10 07:52:13 Training Error = 0.38369110301067 
2016-12-10 07:52:13 Training Loss = 0.022919797496635 
2016-12-10 07:52:16 Valid Error = 0.38274605103281 
2016-12-10 07:52:16 Valid Loss = 0.025321030446477 
2016-12-10 07:52:18 Test Error = 0.39628820960699 
2016-12-10 07:52:18 Test Loss = 0.027413358912748 
2016-12-10 07:52:18 -------------------LR------------------- 
2016-12-10 07:52:18 0.0078125 
2016-12-10 07:52:18 Epoch 61 
2016-12-10 07:54:35 Training Error = 0.38598622924261 
2016-12-10 07:54:35 Training Loss = 0.022730298596693 
2016-12-10 07:54:39 Valid Error = 0.37667071688943 
2016-12-10 07:54:39 Valid Loss = 0.026202999359619 
2016-12-10 07:54:41 Test Error = 0.38427947598253 
2016-12-10 07:54:41 Test Loss = 0.028857878367106 
2016-12-10 07:54:41 -------------------LR------------------- 
2016-12-10 07:54:41 0.0078125 
2016-12-10 07:54:41 Epoch 62 
2016-12-10 07:56:29 Training Error = 0.37923585797219 
2016-12-10 07:56:29 Training Loss = 0.022699165439695 
2016-12-10 07:56:31 Valid Error = 0.46658566221142 
2016-12-10 07:56:31 Valid Loss = 0.027167798795968 
2016-12-10 07:56:33 Test Error = 0.49454148471616 
2016-12-10 07:56:33 Test Loss = 0.0292947473713 
2016-12-10 07:56:33 -------------------LR------------------- 
2016-12-10 07:56:33 0.0078125 
2016-12-10 07:56:33 Epoch 63 
2016-12-10 07:58:25 Training Error = 0.38045092480086 
2016-12-10 07:58:25 Training Loss = 0.02271894835286 
2016-12-10 07:58:27 Valid Error = 0.38882138517618 
2016-12-10 07:58:27 Valid Loss = 0.02400732231375 
2016-12-10 07:58:29 Test Error = 0.39519650655022 
2016-12-10 07:58:29 Test Loss = 0.026528962294261 
2016-12-10 07:58:29 -------------------LR------------------- 
2016-12-10 07:58:29 0.0078125 
2016-12-10 07:58:29 Epoch 64 
2016-12-10 08:00:25 Training Error = 0.38139597677872 
2016-12-10 08:00:25 Training Loss = 0.022904191761747 
2016-12-10 08:00:27 Valid Error = 0.38517618469016 
2016-12-10 08:00:27 Valid Loss = 0.024436283442201 
2016-12-10 08:00:29 Test Error = 0.37227074235808 
2016-12-10 08:00:29 Test Loss = 0.02690407407985 
2016-12-10 08:00:29 -------------------LR------------------- 
2016-12-10 08:00:29 0.0078125 
2016-12-10 08:00:29 Epoch 65 
2016-12-10 08:02:20 Training Error = 0.38166599162954 
2016-12-10 08:02:20 Training Loss = 0.022847893298351 
2016-12-10 08:02:22 Valid Error = 0.46658566221142 
2016-12-10 08:02:22 Valid Loss = 0.028689220349333 
2016-12-10 08:02:24 Test Error = 0.48799126637555 
2016-12-10 08:02:24 Test Loss = 0.031035582598518 
2016-12-10 08:02:24 -------------------LR------------------- 
2016-12-10 08:02:24 0.0078125 
2016-12-10 08:02:24 Epoch 66 
2016-12-10 08:04:16 Training Error = 0.37734575401647 
2016-12-10 08:04:16 Training Loss = 0.022717544748002 
2016-12-10 08:04:18 Valid Error = 0.37181044957473 
2016-12-10 08:04:18 Valid Loss = 0.025915041113482 
2016-12-10 08:04:20 Test Error = 0.37663755458515 
2016-12-10 08:04:20 Test Loss = 0.028320478196238 
2016-12-10 08:04:20 -------------------LR------------------- 
2016-12-10 08:04:20 0.0078125 
2016-12-10 08:04:20 Epoch 67 
2016-12-10 08:06:15 Training Error = 0.38112596192791 
2016-12-10 08:06:15 Training Loss = 0.022650898788267 
2016-12-10 08:06:17 Valid Error = 0.37667071688943 
2016-12-10 08:06:17 Valid Loss = 0.024795822999215 
2016-12-10 08:06:19 Test Error = 0.38427947598253 
2016-12-10 08:06:19 Test Loss = 0.027240061189614 
2016-12-10 08:06:19 -------------------LR------------------- 
2016-12-10 08:06:19 0.0078125 
2016-12-10 08:06:19 Epoch 68 
2016-12-10 08:08:10 Training Error = 0.37842581341974 
2016-12-10 08:08:10 Training Loss = 0.022715815961394 
2016-12-10 08:08:12 Valid Error = 0.38760631834751 
2016-12-10 08:08:12 Valid Loss = 0.024996992701821 
2016-12-10 08:08:14 Test Error = 0.40065502183406 
2016-12-10 08:08:14 Test Loss = 0.027461799182144 
2016-12-10 08:08:14 -------------------LR------------------- 
2016-12-10 08:08:14 0.0078125 
2016-12-10 08:08:14 Epoch 69 
2016-12-10 08:10:04 Training Error = 0.38180099905495 
2016-12-10 08:10:04 Training Loss = 0.022725781426666 
2016-12-10 08:10:06 Valid Error = 0.40097205346294 
2016-12-10 08:10:06 Valid Loss = 0.02486777353752 
2016-12-10 08:10:08 Test Error = 0.41375545851528 
2016-12-10 08:10:08 Test Loss = 0.027423003636154 
2016-12-10 08:10:08 -------------------LR------------------- 
2016-12-10 08:10:08 0.0078125 
2016-12-10 08:10:08 Epoch 70 
2016-12-10 08:12:08 Training Error = 0.37950587282301 
2016-12-10 08:12:08 Training Loss = 0.022698740430417 
2016-12-10 08:12:10 Valid Error = 0.36695018226002 
2016-12-10 08:12:10 Valid Loss = 0.025560139862665 
2016-12-10 08:12:12 Test Error = 0.37772925764192 
2016-12-10 08:12:12 Test Loss = 0.028065287879869 
2016-12-10 08:12:12 -------------------LR------------------- 
2016-12-10 08:12:12 0.0078125 
2016-12-10 08:12:12 Epoch 71 
2016-12-10 08:14:00 Training Error = 0.38139597677872 
2016-12-10 08:14:00 Training Loss = 0.022752631376037 
2016-12-10 08:14:02 Valid Error = 0.40340218712029 
2016-12-10 08:14:02 Valid Loss = 0.025411876148377 
2016-12-10 08:14:04 Test Error = 0.41266375545852 
2016-12-10 08:14:04 Test Loss = 0.027953509040907 
2016-12-10 08:14:04 -------------------LR------------------- 
2016-12-10 08:14:04 0.0078125 
2016-12-10 08:14:04 Epoch 72 
2016-12-10 08:15:56 Training Error = 0.3826110436074 
2016-12-10 08:15:56 Training Loss = 0.022551656565947 
2016-12-10 08:15:58 Valid Error = 0.38274605103281 
2016-12-10 08:15:58 Valid Loss = 0.025995535366777 
2016-12-10 08:16:00 Test Error = 0.39301310043668 
2016-12-10 08:16:00 Test Loss = 0.027986375677819 
2016-12-10 08:16:00 -------------------LR------------------- 
2016-12-10 08:16:00 0.0078125 
2016-12-10 08:16:00 Epoch 73 
2016-12-10 08:17:54 Training Error = 0.3842311327123 
2016-12-10 08:17:54 Training Loss = 0.022705894562822 
2016-12-10 08:17:56 Valid Error = 0.40218712029162 
2016-12-10 08:17:56 Valid Loss = 0.025149044019882 
2016-12-10 08:17:58 Test Error = 0.42139737991266 
2016-12-10 08:17:58 Test Loss = 0.027293211058074 
2016-12-10 08:17:58 -------------------LR------------------- 
2016-12-10 08:17:58 0.0078125 
2016-12-10 08:17:58 Epoch 74 
2016-12-10 08:19:51 Training Error = 0.3826110436074 
2016-12-10 08:19:51 Training Loss = 0.022754330110951 
2016-12-10 08:19:53 Valid Error = 0.39246658566221 
2016-12-10 08:19:53 Valid Loss = 0.02546151193263 
2016-12-10 08:19:55 Test Error = 0.40938864628821 
2016-12-10 08:19:55 Test Loss = 0.028233688045951 
2016-12-10 08:19:55 -------------------LR------------------- 
2016-12-10 08:19:55 0.0078125 
2016-12-10 08:19:55 Epoch 75 
2016-12-10 08:21:48 Training Error = 0.38544619954097 
2016-12-10 08:21:48 Training Loss = 0.022828728303455 
2016-12-10 08:21:50 Valid Error = 0.37424058323208 
2016-12-10 08:21:50 Valid Loss = 0.026484424619611 
2016-12-10 08:21:52 Test Error = 0.36899563318777 
2016-12-10 08:21:52 Test Loss = 0.029090651923535 
2016-12-10 08:21:52 -------------------LR------------------- 
2016-12-10 08:21:52 0.0078125 
2016-12-10 08:21:52 Epoch 76 
2016-12-10 08:23:43 Training Error = 0.37977588767382 
2016-12-10 08:23:43 Training Loss = 0.022604453902329 
2016-12-10 08:23:45 Valid Error = 0.37545565006075 
2016-12-10 08:23:45 Valid Loss = 0.02570961656902 
2016-12-10 08:23:47 Test Error = 0.39082969432314 
2016-12-10 08:23:47 Test Loss = 0.028369839275585 
2016-12-10 08:23:47 -------------------LR------------------- 
2016-12-10 08:23:47 0.0078125 
2016-12-10 08:23:47 Epoch 77 
2016-12-10 08:25:45 Training Error = 0.37910085054678 
2016-12-10 08:25:45 Training Loss = 0.022637638695411 
2016-12-10 08:25:47 Valid Error = 0.44228432563791 
2016-12-10 08:25:47 Valid Loss = 0.026246503609718 
2016-12-10 08:25:49 Test Error = 0.45633187772926 
2016-12-10 08:25:49 Test Loss = 0.02901418912177 
2016-12-10 08:25:49 -------------------LR------------------- 
2016-12-10 08:25:49 0.0078125 
2016-12-10 08:25:49 Epoch 78 
2016-12-10 08:27:48 Training Error = 0.38112596192791 
2016-12-10 08:27:48 Training Loss = 0.022617178898944 
2016-12-10 08:27:50 Valid Error = 0.38760631834751 
2016-12-10 08:27:50 Valid Loss = 0.02541682812914 
2016-12-10 08:27:52 Test Error = 0.40174672489083 
2016-12-10 08:27:52 Test Loss = 0.028138968018924 
2016-12-10 08:27:52 -------------------LR------------------- 
2016-12-10 08:27:52 0.0078125 
2016-12-10 08:27:52 Epoch 79 
2016-12-10 08:29:40 Training Error = 0.37910085054678 
2016-12-10 08:29:40 Training Loss = 0.022566954335445 
2016-12-10 08:29:42 Valid Error = 0.40097205346294 
2016-12-10 08:29:42 Valid Loss = 0.02593480731588 
2016-12-10 08:29:44 Test Error = 0.40065502183406 
2016-12-10 08:29:44 Test Loss = 0.028564472291984 
2016-12-10 08:29:44 -------------------LR------------------- 
2016-12-10 08:29:44 0.0078125 
2016-12-10 08:29:44 Epoch 80 
2016-12-10 08:31:44 Training Error = 0.3777507762927 
2016-12-10 08:31:44 Training Loss = 0.02280880431559 
2016-12-10 08:31:47 Valid Error = 0.47509113001215 
2016-12-10 08:31:47 Valid Loss = 0.026770124031624 
2016-12-10 08:31:49 Test Error = 0.51091703056769 
2016-12-10 08:31:49 Test Loss = 0.029558342503566 
2016-12-10 08:31:49 -------------------LR------------------- 
2016-12-10 08:31:49 0.0078125 
2016-12-10 08:31:49 Epoch 81 
2016-12-10 08:33:38 Training Error = 0.37869582827055 
2016-12-10 08:33:38 Training Loss = 0.022678488791757 
2016-12-10 08:33:40 Valid Error = 0.38031591737546 
2016-12-10 08:33:40 Valid Loss = 0.026049854393833 
2016-12-10 08:33:42 Test Error = 0.38973799126638 
2016-12-10 08:33:42 Test Loss = 0.02850979608648 
2016-12-10 08:33:42 -------------------LR------------------- 
2016-12-10 08:33:42 0.0078125 
2016-12-10 08:33:42 Epoch 82 
2016-12-10 08:35:39 Training Error = 0.37991089509923 
2016-12-10 08:35:39 Training Loss = 0.022634207777349 
2016-12-10 08:35:41 Valid Error = 0.39246658566221 
2016-12-10 08:35:41 Valid Loss = 0.024885208297546 
2016-12-10 08:35:43 Test Error = 0.40938864628821 
2016-12-10 08:35:43 Test Loss = 0.027563127966488 
2016-12-10 08:35:43 -------------------LR------------------- 
2016-12-10 08:35:43 0.0078125 
2016-12-10 08:35:43 Epoch 83 
2016-12-10 08:37:28 Training Error = 0.38288105845822 
2016-12-10 08:37:28 Training Loss = 0.02259357712832 
2016-12-10 08:37:30 Valid Error = 0.39246658566221 
2016-12-10 08:37:30 Valid Loss = 0.025035153716263 
2016-12-10 08:37:32 Test Error = 0.40065502183406 
2016-12-10 08:37:32 Test Loss = 0.027452495481454 
2016-12-10 08:37:32 -------------------LR------------------- 
2016-12-10 08:37:32 0.0078125 
2016-12-10 08:37:32 Epoch 84 
2016-12-10 08:39:24 Training Error = 0.38288105845822 
2016-12-10 08:39:24 Training Loss = 0.022754115174309 
2016-12-10 08:39:26 Valid Error = 0.38639125151883 
2016-12-10 08:39:26 Valid Loss = 0.02523086199517 
2016-12-10 08:39:28 Test Error = 0.40065502183406 
2016-12-10 08:39:28 Test Loss = 0.027950748434254 
2016-12-10 08:39:28 -------------------LR------------------- 
2016-12-10 08:39:28 0.0078125 
2016-12-10 08:39:28 Epoch 85 
2016-12-10 08:41:28 Training Error = 0.38139597677872 
2016-12-10 08:41:28 Training Loss = 0.022889449617331 
2016-12-10 08:41:29 Valid Error = 0.39246658566221 
2016-12-10 08:41:29 Valid Loss = 0.026133448918841 
2016-12-10 08:41:32 Test Error = 0.40938864628821 
2016-12-10 08:41:32 Test Loss = 0.028815167146571 
2016-12-10 08:41:32 -------------------LR------------------- 
2016-12-10 08:41:32 0.0078125 
2016-12-10 08:41:32 Epoch 86 
2016-12-10 08:43:23 Training Error = 0.37748076144188 
2016-12-10 08:43:23 Training Loss = 0.022763272435235 
2016-12-10 08:43:24 Valid Error = 0.38396111786148 
2016-12-10 08:43:24 Valid Loss = 0.025658601271425 
2016-12-10 08:43:26 Test Error = 0.39519650655022 
2016-12-10 08:43:26 Test Loss = 0.02828035845476 
2016-12-10 08:43:26 -------------------LR------------------- 
2016-12-10 08:43:26 0.0078125 
2016-12-10 08:43:26 Epoch 87 
2016-12-10 08:45:22 Training Error = 0.37869582827055 
2016-12-10 08:45:22 Training Loss = 0.022792651964147 
2016-12-10 08:45:24 Valid Error = 0.44592952612394 
2016-12-10 08:45:24 Valid Loss = 0.027218746450167 
2016-12-10 08:45:26 Test Error = 0.44541484716157 
2016-12-10 08:45:26 Test Loss = 0.029598445443546 
2016-12-10 08:45:26 -------------------LR------------------- 
2016-12-10 08:45:26 0.0078125 
2016-12-10 08:45:26 Epoch 88 
2016-12-10 08:47:21 Training Error = 0.37842581341974 
2016-12-10 08:47:21 Training Loss = 0.022735087135237 
2016-12-10 08:47:23 Valid Error = 0.39975698663426 
2016-12-10 08:47:23 Valid Loss = 0.023401662507292 
2016-12-10 08:47:25 Test Error = 0.4061135371179 
2016-12-10 08:47:25 Test Loss = 0.025979134802725 
2016-12-10 08:47:25 -------------------LR------------------- 
2016-12-10 08:47:25 0.0078125 
2016-12-10 08:47:25 Epoch 89 
2016-12-10 08:49:07 Training Error = 0.3858512218172 
2016-12-10 08:49:07 Training Loss = 0.022902224569027 
2016-12-10 08:49:09 Valid Error = 0.39246658566221 
2016-12-10 08:49:09 Valid Loss = 0.025813028455356 
2016-12-10 08:49:11 Test Error = 0.40938864628821 
2016-12-10 08:49:11 Test Loss = 0.028457962438172 
2016-12-10 08:49:11 -------------------LR------------------- 
2016-12-10 08:49:11 0.0078125 
2016-12-10 08:49:11 Epoch 90 
2016-12-10 08:51:12 Training Error = 0.37748076144188 
2016-12-10 08:51:12 Training Loss = 0.022635283563295 
2016-12-10 08:51:16 Valid Error = 0.39246658566221 
2016-12-10 08:51:16 Valid Loss = 0.024223033691476 
2016-12-10 08:51:18 Test Error = 0.39628820960699 
2016-12-10 08:51:18 Test Loss = 0.026925141923568 
2016-12-10 08:51:18 -------------------LR------------------- 
2016-12-10 08:51:18 0.0078125 
2016-12-10 08:51:18 Epoch 91 
2016-12-10 08:53:13 Training Error = 0.38207101390576 
2016-12-10 08:53:13 Training Loss = 0.022785068764851 
2016-12-10 08:53:15 Valid Error = 0.39489671931956 
2016-12-10 08:53:15 Valid Loss = 0.025128969114997 
2016-12-10 08:53:17 Test Error = 0.39847161572052 
2016-12-10 08:53:17 Test Loss = 0.027367318302977 
2016-12-10 08:53:17 -------------------LR------------------- 
2016-12-10 08:53:17 0.0078125 
2016-12-10 08:53:17 Epoch 92 
2016-12-10 08:55:12 Training Error = 0.38139597677872 
2016-12-10 08:55:12 Training Loss = 0.022695403839026 
2016-12-10 08:55:14 Valid Error = 0.45929526123937 
2016-12-10 08:55:14 Valid Loss = 0.027277099285612 
2016-12-10 08:55:16 Test Error = 0.47707423580786 
2016-12-10 08:55:16 Test Loss = 0.029390614341287 
2016-12-10 08:55:16 -------------------LR------------------- 
2016-12-10 08:55:16 0.0078125 
2016-12-10 08:55:16 Epoch 93 
2016-12-10 08:57:06 Training Error = 0.37977588767382 
2016-12-10 08:57:06 Training Loss = 0.022537774255006 
2016-12-10 08:57:08 Valid Error = 0.38396111786148 
2016-12-10 08:57:08 Valid Loss = 0.025495239609038 
2016-12-10 08:57:10 Test Error = 0.39519650655022 
2016-12-10 08:57:10 Test Loss = 0.027612001222723 
2016-12-10 08:57:10 -------------------LR------------------- 
2016-12-10 08:57:10 0.0078125 
2016-12-10 08:57:10 Epoch 94 
2016-12-10 08:59:01 Training Error = 0.38058593222627 
2016-12-10 08:59:01 Training Loss = 0.022875219475811 
2016-12-10 08:59:03 Valid Error = 0.43863912515188 
2016-12-10 08:59:03 Valid Loss = 0.026737212202501 
2016-12-10 08:59:05 Test Error = 0.43449781659389 
2016-12-10 08:59:05 Test Loss = 0.029189147322786 
2016-12-10 08:59:05 -------------------LR------------------- 
2016-12-10 08:59:05 0.0078125 
2016-12-10 08:59:05 Epoch 95 
2016-12-10 09:00:54 Training Error = 0.37653570946402 
2016-12-10 09:00:54 Training Loss = 0.022803709177966 
2016-12-10 09:00:56 Valid Error = 0.39489671931956 
2016-12-10 09:00:56 Valid Loss = 0.024514392015552 
2016-12-10 09:00:58 Test Error = 0.41048034934498 
2016-12-10 09:00:58 Test Loss = 0.026798547501658 
2016-12-10 09:00:58 -------------------LR------------------- 
2016-12-10 09:00:58 0.0078125 
2016-12-10 09:00:58 Epoch 96 
2016-12-10 09:02:51 Training Error = 0.3778857837181 
2016-12-10 09:02:51 Training Loss = 0.022416980108694 
2016-12-10 09:02:53 Valid Error = 0.40340218712029 
2016-12-10 09:02:53 Valid Loss = 0.024946585855125 
2016-12-10 09:02:55 Test Error = 0.41157205240175 
2016-12-10 09:02:55 Test Loss = 0.027375481755126 
2016-12-10 09:02:55 -------------------LR------------------- 
2016-12-10 09:02:55 0.0078125 
2016-12-10 09:02:55 Epoch 97 
2016-12-10 09:04:52 Training Error = 0.38126096935331 
2016-12-10 09:04:52 Training Loss = 0.022681017925359 
2016-12-10 09:04:54 Valid Error = 0.37667071688943 
2016-12-10 09:04:54 Valid Loss = 0.024422727814111 
2016-12-10 09:04:56 Test Error = 0.38427947598253 
2016-12-10 09:04:56 Test Loss = 0.026775647864622 
2016-12-10 09:04:56 -------------------LR------------------- 
2016-12-10 09:04:56 0.0078125 
2016-12-10 09:04:56 Epoch 98 
2016-12-10 09:06:43 Training Error = 0.38234102875658 
2016-12-10 09:06:43 Training Loss = 0.022696697610522 
2016-12-10 09:06:45 Valid Error = 0.40218712029162 
2016-12-10 09:06:45 Valid Loss = 0.024379231564145 
2016-12-10 09:06:47 Test Error = 0.41593886462882 
2016-12-10 09:06:47 Test Loss = 0.02658533745186 
2016-12-10 09:06:47 -------------------LR------------------- 
2016-12-10 09:06:47 0.0078125 
2016-12-10 09:06:47 Epoch 99 
2016-12-10 09:08:43 Training Error = 0.38085594707709 
2016-12-10 09:08:43 Training Loss = 0.022576398162414 
2016-12-10 09:08:45 Valid Error = 0.38396111786148 
2016-12-10 09:08:45 Valid Loss = 0.024020767443174 
2016-12-10 09:08:47 Test Error = 0.39519650655022 
2016-12-10 09:08:47 Test Loss = 0.026356743195478 
2016-12-10 09:08:47 -------------------LR------------------- 
2016-12-10 09:08:47 0.0078125 
2016-12-10 09:08:47 Epoch 100 
2016-12-10 09:10:38 Training Error = 0.38004590252464 
2016-12-10 09:10:38 Training Loss = 0.022598932491698 
2016-12-10 09:10:40 Valid Error = 0.38760631834751 
2016-12-10 09:10:40 Valid Loss = 0.024924410022975 
2016-12-10 09:10:42 Test Error = 0.40065502183406 
2016-12-10 09:10:42 Test Loss = 0.026923723688313 
2016-12-10 09:10:42 -------------------LR------------------- 
2016-12-10 09:10:42 0.00390625 
2016-12-10 09:10:42 Epoch 101 
2016-12-10 09:12:36 Training Error = 0.38004590252464 
2016-12-10 09:12:36 Training Loss = 0.022583230304451 
2016-12-10 09:12:37 Valid Error = 0.38396111786148 
2016-12-10 09:12:37 Valid Loss = 0.026685836689371 
2016-12-10 09:12:40 Test Error = 0.39519650655022 
2016-12-10 09:12:40 Test Loss = 0.029297996801489 
2016-12-10 09:12:40 -------------------LR------------------- 
2016-12-10 09:12:40 0.00390625 
2016-12-10 09:12:40 Epoch 102 
2016-12-10 09:14:32 Training Error = 0.37505062778453 
2016-12-10 09:14:32 Training Loss = 0.022565593348342 
2016-12-10 09:14:34 Valid Error = 0.38760631834751 
2016-12-10 09:14:34 Valid Loss = 0.023931546743772 
2016-12-10 09:14:36 Test Error = 0.40065502183406 
2016-12-10 09:14:36 Test Loss = 0.026199835627687 
2016-12-10 09:14:36 -------------------LR------------------- 
2016-12-10 09:14:36 0.00390625 
2016-12-10 09:14:36 Epoch 103 
2016-12-10 09:16:25 Training Error = 0.38139597677872 
2016-12-10 09:16:25 Training Loss = 0.022826797622125 
2016-12-10 09:16:27 Valid Error = 0.39368165249089 
2016-12-10 09:16:27 Valid Loss = 0.025388973619469 
2016-12-10 09:16:29 Test Error = 0.37772925764192 
2016-12-10 09:16:29 Test Loss = 0.027977347252416 
2016-12-10 09:16:29 -------------------LR------------------- 
2016-12-10 09:16:29 0.00390625 
2016-12-10 09:16:29 Epoch 104 
2016-12-10 09:18:24 Training Error = 0.38625624409343 
2016-12-10 09:18:24 Training Loss = 0.022911492300167 
2016-12-10 09:18:26 Valid Error = 0.40461725394897 
2016-12-10 09:18:26 Valid Loss = 0.026386091111792 
2016-12-10 09:18:28 Test Error = 0.4061135371179 
2016-12-10 09:18:28 Test Loss = 0.028565327335806 
2016-12-10 09:18:28 -------------------LR------------------- 
2016-12-10 09:18:28 0.00390625 
2016-12-10 09:18:28 Epoch 105 
2016-12-10 09:20:19 Training Error = 0.3762656946132 
2016-12-10 09:20:19 Training Loss = 0.022756588032755 
2016-12-10 09:20:21 Valid Error = 0.38639125151883 
2016-12-10 09:20:21 Valid Loss = 0.026559903035621 
2016-12-10 09:20:23 Test Error = 0.38973799126638 
2016-12-10 09:20:23 Test Loss = 0.029075389862061 
2016-12-10 09:20:23 -------------------LR------------------- 
2016-12-10 09:20:23 0.00390625 
2016-12-10 09:20:23 Epoch 106 
2016-12-10 09:22:19 Training Error = 0.38220602133117 
2016-12-10 09:22:19 Training Loss = 0.022864418615347 
2016-12-10 09:22:21 Valid Error = 0.46415552855407 
2016-12-10 09:22:21 Valid Loss = 0.026300050100052 
2016-12-10 09:22:23 Test Error = 0.44978165938865 
2016-12-10 09:22:23 Test Loss = 0.028515390657911 
2016-12-10 09:22:23 -------------------LR------------------- 
2016-12-10 09:22:23 0.00390625 
2016-12-10 09:22:23 Epoch 107 
2016-12-10 09:24:09 Training Error = 0.37815579856892 
2016-12-10 09:24:09 Training Loss = 0.022832398666254 
2016-12-10 09:24:11 Valid Error = 0.38031591737546 
2016-12-10 09:24:11 Valid Loss = 0.026517799495239 
2016-12-10 09:24:13 Test Error = 0.37882096069869 
2016-12-10 09:24:13 Test Loss = 0.029422033141641 
2016-12-10 09:24:13 -------------------LR------------------- 
2016-12-10 09:24:13 0.00390625 
2016-12-10 09:24:13 Epoch 108 
2016-12-10 09:26:07 Training Error = 0.37815579856892 
2016-12-10 09:26:07 Training Loss = 0.022668715262391 
2016-12-10 09:26:09 Valid Error = 0.37667071688943 
2016-12-10 09:26:09 Valid Loss = 0.026476092189056 
2016-12-10 09:26:11 Test Error = 0.37227074235808 
2016-12-10 09:26:11 Test Loss = 0.029126863311319 
2016-12-10 09:26:11 -------------------LR------------------- 
2016-12-10 09:26:11 0.00390625 
2016-12-10 09:26:11 Epoch 109 
2016-12-10 09:28:04 Training Error = 0.38193600648036 
2016-12-10 09:28:04 Training Loss = 0.022716531602876 
2016-12-10 09:28:06 Valid Error = 0.3681652490887 
2016-12-10 09:28:06 Valid Loss = 0.024539878218646 
2016-12-10 09:28:08 Test Error = 0.367903930131 
2016-12-10 09:28:08 Test Loss = 0.027101286046645 
2016-12-10 09:28:08 -------------------LR------------------- 
2016-12-10 09:28:08 0.00390625 
2016-12-10 09:28:08 Epoch 110 
2016-12-10 09:30:00 Training Error = 0.37964088024841 
2016-12-10 09:30:00 Training Loss = 0.022747104832127 
2016-12-10 09:30:03 Valid Error = 0.40704738760632 
2016-12-10 09:30:03 Valid Loss = 0.025462441371677 
2016-12-10 09:30:05 Test Error = 0.41812227074236 
2016-12-10 09:30:05 Test Loss = 0.028352332283469 
2016-12-10 09:30:05 -------------------LR------------------- 
2016-12-10 09:30:05 0.00390625 
2016-12-10 09:30:05 Epoch 111 
2016-12-10 09:31:59 Training Error = 0.37829080599433 
2016-12-10 09:31:59 Training Loss = 0.022625198520977 
2016-12-10 09:32:01 Valid Error = 0.4678007290401 
2016-12-10 09:32:01 Valid Loss = 0.027361602530263 
2016-12-10 09:32:03 Test Error = 0.49126637554585 
2016-12-10 09:32:03 Test Loss = 0.030046847175149 
2016-12-10 09:32:03 -------------------LR------------------- 
2016-12-10 09:32:03 0.00390625 
2016-12-10 09:32:03 Epoch 112 
2016-12-10 09:33:52 Training Error = 0.3762656946132 
2016-12-10 09:33:52 Training Loss = 0.022750307570742 
2016-12-10 09:33:54 Valid Error = 0.39489671931956 
2016-12-10 09:33:54 Valid Loss = 0.025753351283636 
2016-12-10 09:33:56 Test Error = 0.39847161572052 
2016-12-10 09:33:56 Test Loss = 0.028158102213168 
2016-12-10 09:33:56 -------------------LR------------------- 
2016-12-10 09:33:56 0.00390625 
2016-12-10 09:33:56 Epoch 113 
2016-12-10 09:35:44 Training Error = 0.37761576886729 
2016-12-10 09:35:44 Training Loss = 0.022705897073185 
2016-12-10 09:35:45 Valid Error = 0.38274605103281 
2016-12-10 09:35:45 Valid Loss = 0.026607470471287 
2016-12-10 09:35:47 Test Error = 0.39301310043668 
2016-12-10 09:35:47 Test Loss = 0.029166692490671 
2016-12-10 09:35:47 -------------------LR------------------- 
2016-12-10 09:35:47 0.00390625 
2016-12-10 09:35:47 Epoch 114 
2016-12-10 09:37:39 Training Error = 0.3778857837181 
2016-12-10 09:37:39 Training Loss = 0.022749288178203 
2016-12-10 09:37:41 Valid Error = 0.40826245443499 
2016-12-10 09:37:41 Valid Loss = 0.024800593824315 
2016-12-10 09:37:43 Test Error = 0.41157205240175 
2016-12-10 09:37:43 Test Loss = 0.02691092300415 
2016-12-10 09:37:43 -------------------LR------------------- 
2016-12-10 09:37:43 0.00390625 
2016-12-10 09:37:43 Epoch 115 
2016-12-10 09:39:40 Training Error = 0.37950587282301 
2016-12-10 09:39:40 Training Loss = 0.022766829526814 
2016-12-10 09:39:42 Valid Error = 0.39975698663426 
2016-12-10 09:39:42 Valid Loss = 0.025872730024952 
2016-12-10 09:39:44 Test Error = 0.40720524017467 
2016-12-10 09:39:44 Test Loss = 0.028564223102495 
2016-12-10 09:39:44 -------------------LR------------------- 
2016-12-10 09:39:44 0.00390625 
2016-12-10 09:39:44 Epoch 116 
2016-12-10 09:41:29 Training Error = 0.38220602133117 
2016-12-10 09:41:29 Training Loss = 0.02281261989476 
2016-12-10 09:41:31 Valid Error = 0.39489671931956 
2016-12-10 09:41:31 Valid Loss = 0.025235296352192 
2016-12-10 09:41:33 Test Error = 0.40720524017467 
2016-12-10 09:41:33 Test Loss = 0.027937213533065 
2016-12-10 09:41:33 -------------------LR------------------- 
2016-12-10 09:41:33 0.00390625 
2016-12-10 09:41:33 Epoch 117 
2016-12-10 09:43:24 Training Error = 0.38180099905495 
2016-12-10 09:43:24 Training Loss = 0.022683958007642 
2016-12-10 09:43:26 Valid Error = 0.38396111786148 
2016-12-10 09:43:26 Valid Loss = 0.025926004286753 
2016-12-10 09:43:28 Test Error = 0.39082969432314 
2016-12-10 09:43:28 Test Loss = 0.028805534905078 
2016-12-10 09:43:28 -------------------LR------------------- 
2016-12-10 09:43:28 0.00390625 
2016-12-10 09:43:28 Epoch 118 
2016-12-10 09:45:28 Training Error = 0.38085594707709 
2016-12-10 09:45:28 Training Loss = 0.022759193057106 
2016-12-10 09:45:30 Valid Error = 0.39246658566221 
2016-12-10 09:45:30 Valid Loss = 0.025813002930092 
2016-12-10 09:45:32 Test Error = 0.38973799126638 
2016-12-10 09:45:32 Test Loss = 0.028065406939563 
2016-12-10 09:45:32 -------------------LR------------------- 
2016-12-10 09:45:32 0.00390625 
2016-12-10 09:45:32 Epoch 119 
2016-12-10 09:47:24 Training Error = 0.38247603618199 
2016-12-10 09:47:24 Training Loss = 0.022896054749618 
2016-12-10 09:47:26 Valid Error = 0.41190765492102 
2016-12-10 09:47:26 Valid Loss = 0.025435510057047 
2016-12-10 09:47:28 Test Error = 0.41703056768559 
2016-12-10 09:47:28 Test Loss = 0.027976939416399 
2016-12-10 09:47:28 -------------------LR------------------- 
2016-12-10 09:47:28 0.00390625 
2016-12-10 09:47:28 Epoch 120 
2016-12-10 09:49:24 Training Error = 0.38504117726475 
2016-12-10 09:49:24 Training Loss = 0.022806615733655 
2016-12-10 09:49:27 Valid Error = 0.47630619684083 
2016-12-10 09:49:27 Valid Loss = 0.026826002679789 
2016-12-10 09:49:29 Test Error = 0.49017467248908 
2016-12-10 09:49:29 Test Loss = 0.029387754636652 
2016-12-10 09:49:29 -------------------LR------------------- 
2016-12-10 09:49:29 0.00390625 
2016-12-10 09:49:29 Epoch 121 
2016-12-10 09:51:16 Training Error = 0.38436614013771 
2016-12-10 09:51:16 Training Loss = 0.022807115050814 
2016-12-10 09:51:18 Valid Error = 0.40461725394897 
2016-12-10 09:51:18 Valid Loss = 0.024126788015854 
2016-12-10 09:51:20 Test Error = 0.41484716157205 
2016-12-10 09:51:20 Test Loss = 0.026166852146971 
2016-12-10 09:51:20 -------------------LR------------------- 
2016-12-10 09:51:20 0.00390625 
2016-12-10 09:51:20 Epoch 122 
2016-12-10 09:53:14 Training Error = 0.38153098420413 
2016-12-10 09:53:14 Training Loss = 0.022863698010129 
2016-12-10 09:53:16 Valid Error = 0.46294046172539 
2016-12-10 09:53:16 Valid Loss = 0.027833820815293 
2016-12-10 09:53:18 Test Error = 0.48362445414847 
2016-12-10 09:53:18 Test Loss = 0.03047792114931 
2016-12-10 09:53:18 -------------------LR------------------- 
2016-12-10 09:53:18 0.00390625 
2016-12-10 09:53:18 Epoch 123 
2016-12-10 09:55:17 Training Error = 0.37950587282301 
2016-12-10 09:55:17 Training Loss = 0.022796119622979 
2016-12-10 09:55:19 Valid Error = 0.39611178614824 
2016-12-10 09:55:19 Valid Loss = 0.025770615200727 
2016-12-10 09:55:21 Test Error = 0.40065502183406 
2016-12-10 09:55:21 Test Loss = 0.028335263626248 
2016-12-10 09:55:21 -------------------LR------------------- 
2016-12-10 09:55:21 0.00390625 
2016-12-10 09:55:21 Epoch 124 
2016-12-10 09:57:14 Training Error = 0.38018090995005 
2016-12-10 09:57:14 Training Loss = 0.022694166104756 
2016-12-10 09:57:15 Valid Error = 0.38517618469016 
2016-12-10 09:57:15 Valid Loss = 0.025144382544378 
2016-12-10 09:57:18 Test Error = 0.38973799126638 
2016-12-10 09:57:18 Test Loss = 0.027570845566544 
2016-12-10 09:57:18 -------------------LR------------------- 
2016-12-10 09:57:18 0.00390625 
2016-12-10 09:57:18 Epoch 125 
2016-12-10 09:59:11 Training Error = 0.37815579856892 
2016-12-10 09:59:11 Training Loss = 0.022754796676565 
2016-12-10 09:59:12 Valid Error = 0.46294046172539 
2016-12-10 09:59:12 Valid Loss = 0.027550950834016 
2016-12-10 09:59:15 Test Error = 0.47161572052402 
2016-12-10 09:59:15 Test Loss = 0.030024166294173 
2016-12-10 09:59:15 -------------------LR------------------- 
2016-12-10 09:59:15 0.00390625 
2016-12-10 09:59:15 Epoch 126 
2016-12-10 10:01:06 Training Error = 0.3778857837181 
2016-12-10 10:01:06 Training Loss = 0.022746593780945 
2016-12-10 10:01:08 Valid Error = 0.37667071688943 
2016-12-10 10:01:08 Valid Loss = 0.024679805397524 
2016-12-10 10:01:10 Test Error = 0.38427947598253 
2016-12-10 10:01:10 Test Loss = 0.027237113746942 
2016-12-10 10:01:10 -------------------LR------------------- 
2016-12-10 10:01:10 0.00390625 
2016-12-10 10:01:10 Epoch 127 
2016-12-10 10:02:57 Training Error = 0.38274605103281 
2016-12-10 10:02:57 Training Loss = 0.022888918249592 
2016-12-10 10:02:59 Valid Error = 0.4678007290401 
2016-12-10 10:02:59 Valid Loss = 0.028266458767003 
2016-12-10 10:03:01 Test Error = 0.46506550218341 
2016-12-10 10:03:01 Test Loss = 0.030643455767164 
2016-12-10 10:03:01 -------------------LR------------------- 
2016-12-10 10:03:01 0.00390625 
2016-12-10 10:03:01 Epoch 128 
2016-12-10 10:04:53 Training Error = 0.37923585797219 
2016-12-10 10:04:53 Training Loss = 0.022730517858796 
2016-12-10 10:04:55 Valid Error = 0.39246658566221 
2016-12-10 10:04:55 Valid Loss = 0.024726665287609 
2016-12-10 10:04:57 Test Error = 0.40829694323144 
2016-12-10 10:04:57 Test Loss = 0.027120209965051 
2016-12-10 10:04:57 -------------------LR------------------- 
2016-12-10 10:04:57 0.00390625 
2016-12-10 10:04:57 Epoch 129 
2016-12-10 10:06:53 Training Error = 0.38315107330903 
2016-12-10 10:06:53 Training Loss = 0.022812903822214 
2016-12-10 10:06:55 Valid Error = 0.49453219927096 
2016-12-10 10:06:55 Valid Loss = 0.026483867378231 
2016-12-10 10:06:57 Test Error = 0.50764192139738 
2016-12-10 10:06:57 Test Loss = 0.029041135872112 
2016-12-10 10:06:57 -------------------LR------------------- 
2016-12-10 10:06:57 0.00390625 
2016-12-10 10:06:57 Epoch 130 
2016-12-10 10:08:58 Training Error = 0.3761306871878 
2016-12-10 10:08:58 Training Loss = 0.02259335113155 
2016-12-10 10:09:00 Valid Error = 0.37667071688943 
2016-12-10 10:09:00 Valid Loss = 0.025295410922297 
2016-12-10 10:09:02 Test Error = 0.38427947598253 
2016-12-10 10:09:02 Test Loss = 0.027780372516782 
2016-12-10 10:09:02 -------------------LR------------------- 
2016-12-10 10:09:02 0.00390625 
2016-12-10 10:09:02 Epoch 131 
2016-12-10 10:10:58 Training Error = 0.38004590252464 
2016-12-10 10:10:58 Training Loss = 0.022785339277109 
2016-12-10 10:11:00 Valid Error = 0.39611178614824 
2016-12-10 10:11:00 Valid Loss = 0.025460373232669 
2016-12-10 10:11:02 Test Error = 0.4061135371179 
2016-12-10 10:11:02 Test Loss = 0.027836654550889 
2016-12-10 10:11:02 -------------------LR------------------- 
2016-12-10 10:11:02 0.00390625 
2016-12-10 10:11:02 Epoch 132 
2016-12-10 10:12:58 Training Error = 0.37856082084515 
2016-12-10 10:12:58 Training Loss = 0.02273792857821 
2016-12-10 10:13:00 Valid Error = 0.39246658566221 
2016-12-10 10:13:00 Valid Loss = 0.024802710824113 
2016-12-10 10:13:02 Test Error = 0.40938864628821 
2016-12-10 10:13:02 Test Loss = 0.027517970431085 
2016-12-10 10:13:02 -------------------LR------------------- 
2016-12-10 10:13:02 0.00390625 
2016-12-10 10:13:02 Epoch 133 
2016-12-10 10:14:56 Training Error = 0.38274605103281 
2016-12-10 10:14:56 Training Loss = 0.022636129746495 
2016-12-10 10:14:57 Valid Error = 0.37667071688943 
2016-12-10 10:14:57 Valid Loss = 0.025976877554897 
2016-12-10 10:14:59 Test Error = 0.37227074235808 
2016-12-10 10:14:59 Test Loss = 0.028568338422214 
2016-12-10 10:14:59 -------------------LR------------------- 
2016-12-10 10:14:59 0.00390625 
2016-12-10 10:14:59 Epoch 134 
2016-12-10 10:16:52 Training Error = 0.38004590252464 
2016-12-10 10:16:52 Training Loss = 0.02273612729882 
2016-12-10 10:16:54 Valid Error = 0.37910085054678 
2016-12-10 10:16:54 Valid Loss = 0.026343223923725 
2016-12-10 10:16:56 Test Error = 0.37445414847162 
2016-12-10 10:16:56 Test Loss = 0.028601277529025 
2016-12-10 10:16:56 -------------------LR------------------- 
2016-12-10 10:16:56 0.00390625 
2016-12-10 10:16:56 Epoch 135 
2016-12-10 10:18:53 Training Error = 0.38517618469016 
2016-12-10 10:18:53 Training Loss = 0.022898592562635 
2016-12-10 10:18:54 Valid Error = 0.36938031591738 
2016-12-10 10:18:54 Valid Loss = 0.025674863278533 
2016-12-10 10:18:56 Test Error = 0.36135371179039 
2016-12-10 10:18:56 Test Loss = 0.0283201695517 
2016-12-10 10:18:56 -------------------LR------------------- 
2016-12-10 10:18:56 0.00390625 
2016-12-10 10:18:56 Epoch 136 
2016-12-10 10:20:56 Training Error = 0.38058593222627 
2016-12-10 10:20:56 Training Loss = 0.022700709727454 
2016-12-10 10:20:58 Valid Error = 0.38396111786148 
2016-12-10 10:20:58 Valid Loss = 0.024612650299 
2016-12-10 10:21:00 Test Error = 0.39519650655022 
2016-12-10 10:21:00 Test Loss = 0.027169179589141 
2016-12-10 10:21:00 -------------------LR------------------- 
2016-12-10 10:21:00 0.00390625 
2016-12-10 10:21:00 Epoch 137 
2016-12-10 10:22:52 Training Error = 0.3809909545025 
2016-12-10 10:22:52 Training Loss = 0.022543635322578 
2016-12-10 10:22:54 Valid Error = 0.40340218712029 
2016-12-10 10:22:54 Valid Loss = 0.025413052702623 
2016-12-10 10:22:56 Test Error = 0.40393013100437 
2016-12-10 10:22:56 Test Loss = 0.02738942712896 
2016-12-10 10:22:56 -------------------LR------------------- 
2016-12-10 10:22:56 0.00390625 
2016-12-10 10:22:56 Epoch 138 
2016-12-10 10:24:57 Training Error = 0.38571621439179 
2016-12-10 10:24:57 Training Loss = 0.022869421245671 
2016-12-10 10:24:59 Valid Error = 0.40583232077764 
2016-12-10 10:24:59 Valid Loss = 0.025696628458902 
2016-12-10 10:25:01 Test Error = 0.41703056768559 
2016-12-10 10:25:01 Test Loss = 0.028402556092131 
2016-12-10 10:25:01 -------------------LR------------------- 
2016-12-10 10:25:01 0.00390625 
2016-12-10 10:25:01 Epoch 139 
2016-12-10 10:26:51 Training Error = 0.38436614013771 
2016-12-10 10:26:51 Training Loss = 0.022708805389832 
2016-12-10 10:26:53 Valid Error = 0.39975698663426 
2016-12-10 10:26:53 Valid Loss = 0.024331912269892 
2016-12-10 10:26:55 Test Error = 0.4061135371179 
2016-12-10 10:26:55 Test Loss = 0.026700832161249 
2016-12-10 10:26:55 -------------------LR------------------- 
2016-12-10 10:26:55 0.00390625 
2016-12-10 10:26:55 Epoch 140 
2016-12-10 10:28:57 Training Error = 0.38072093965168 
2016-12-10 10:28:57 Training Loss = 0.022649359836098 
2016-12-10 10:29:01 Valid Error = 0.41190765492102 
2016-12-10 10:29:01 Valid Loss = 0.024605141181075 
2016-12-10 10:29:03 Test Error = 0.41703056768559 
2016-12-10 10:29:03 Test Loss = 0.026891349343693 
2016-12-10 10:29:03 -------------------LR------------------- 
2016-12-10 10:29:03 0.00390625 
2016-12-10 10:29:03 Epoch 141 
2016-12-10 10:31:00 Training Error = 0.38004590252464 
2016-12-10 10:31:00 Training Loss = 0.022726801263718 
2016-12-10 10:31:02 Valid Error = 0.39732685297691 
2016-12-10 10:31:02 Valid Loss = 0.025851555633039 
2016-12-10 10:31:04 Test Error = 0.40393013100437 
2016-12-10 10:31:04 Test Loss = 0.028569808370927 
2016-12-10 10:31:04 -------------------LR------------------- 
2016-12-10 10:31:04 0.00390625 
2016-12-10 10:31:04 Epoch 142 
2016-12-10 10:32:54 Training Error = 0.38207101390576 
2016-12-10 10:32:54 Training Loss = 0.022709028638311 
2016-12-10 10:32:56 Valid Error = 0.39611178614824 
2016-12-10 10:32:56 Valid Loss = 0.024668925593294 
2016-12-10 10:32:58 Test Error = 0.41484716157205 
2016-12-10 10:32:58 Test Loss = 0.027330310307297 
2016-12-10 10:32:58 -------------------LR------------------- 
2016-12-10 10:32:58 0.00390625 
2016-12-10 10:32:58 Epoch 143 
2016-12-10 10:34:55 Training Error = 0.3793708653976 
2016-12-10 10:34:55 Training Loss = 0.022745494374508 
2016-12-10 10:34:56 Valid Error = 0.38396111786148 
2016-12-10 10:34:56 Valid Loss = 0.024149069757616 
2016-12-10 10:34:58 Test Error = 0.39519650655022 
2016-12-10 10:34:58 Test Loss = 0.026430215461581 
2016-12-10 10:34:58 -------------------LR------------------- 
2016-12-10 10:34:58 0.00390625 
2016-12-10 10:34:58 Epoch 144 
2016-12-10 10:36:51 Training Error = 0.38288105845822 
2016-12-10 10:36:51 Training Loss = 0.022771209594271 
2016-12-10 10:36:53 Valid Error = 0.39368165249089 
2016-12-10 10:36:53 Valid Loss = 0.025794075708154 
2016-12-10 10:36:55 Test Error = 0.40502183406114 
2016-12-10 10:36:55 Test Loss = 0.028534252213497 
2016-12-10 10:36:55 -------------------LR------------------- 
2016-12-10 10:36:55 0.00390625 
2016-12-10 10:36:55 Epoch 145 
2016-12-10 10:38:48 Training Error = 0.38193600648036 
2016-12-10 10:38:48 Training Loss = 0.022596074600291 
2016-12-10 10:38:50 Valid Error = 0.4678007290401 
2016-12-10 10:38:50 Valid Loss = 0.025009701746798 
2016-12-10 10:38:52 Test Error = 0.47379912663755 
2016-12-10 10:38:52 Test Loss = 0.027590910219679 
2016-12-10 10:38:52 -------------------LR------------------- 
2016-12-10 10:38:52 0.00390625 
2016-12-10 10:38:52 Epoch 146 
2016-12-10 10:40:51 Training Error = 0.37991089509923 
2016-12-10 10:40:51 Training Loss = 0.022653221814238 
2016-12-10 10:40:52 Valid Error = 0.38153098420413 
2016-12-10 10:40:52 Valid Loss = 0.025855482079218 
2016-12-10 10:40:54 Test Error = 0.39192139737991 
2016-12-10 10:40:54 Test Loss = 0.028411206179974 
2016-12-10 10:40:54 -------------------LR------------------- 
2016-12-10 10:40:54 0.00390625 
2016-12-10 10:40:54 Epoch 147 
2016-12-10 10:42:49 Training Error = 0.37491562035912 
2016-12-10 10:42:49 Training Loss = 0.022809828258696 
2016-12-10 10:42:51 Valid Error = 0.45078979343864 
2016-12-10 10:42:51 Valid Loss = 0.026867914303715 
2016-12-10 10:42:53 Test Error = 0.45414847161572 
2016-12-10 10:42:53 Test Loss = 0.029087555791817 
2016-12-10 10:42:53 -------------------LR------------------- 
2016-12-10 10:42:53 0.00390625 
2016-12-10 10:42:53 Epoch 148 
2016-12-10 10:44:40 Training Error = 0.38315107330903 
2016-12-10 10:44:40 Training Loss = 0.022748537716478 
2016-12-10 10:44:42 Valid Error = 0.38760631834751 
2016-12-10 10:44:42 Valid Loss = 0.025374063699774 
2016-12-10 10:44:44 Test Error = 0.40065502183406 
2016-12-10 10:44:44 Test Loss = 0.028035743161744 
2016-12-10 10:44:44 -------------------LR------------------- 
2016-12-10 10:44:44 0.00390625 
2016-12-10 10:44:44 Epoch 149 
2016-12-10 10:46:37 Training Error = 0.38180099905495 
2016-12-10 10:46:37 Training Loss = 0.02278273398776 
2016-12-10 10:46:39 Valid Error = 0.44471445929526 
2016-12-10 10:46:39 Valid Loss = 0.027695838723703 
2016-12-10 10:46:41 Test Error = 0.45524017467249 
2016-12-10 10:46:41 Test Loss = 0.029983963816774 
2016-12-10 10:46:41 -------------------LR------------------- 
2016-12-10 10:46:41 0.00390625 
2016-12-10 10:46:41 Epoch 150 
2016-12-10 10:48:46 Training Error = 0.38301606588362 
2016-12-10 10:48:46 Training Loss = 0.022781245728679 
2016-12-10 10:48:49 Valid Error = 0.38153098420413 
2016-12-10 10:48:49 Valid Loss = 0.026072600649152 
2016-12-10 10:48:51 Test Error = 0.39192139737991 
2016-12-10 10:48:51 Test Loss = 0.028524497125663 
2016-12-10 10:48:51 -------------------LR------------------- 
2016-12-10 10:48:51 0.001953125 
2016-12-10 10:48:51 Epoch 151 
2016-12-10 10:50:46 Training Error = 0.38193600648036 
2016-12-10 10:50:46 Training Loss = 0.02275507900263 
2016-12-10 10:50:48 Valid Error = 0.3778857837181 
2016-12-10 10:50:48 Valid Loss = 0.027256120849968 
2016-12-10 10:50:50 Test Error = 0.36681222707424 
2016-12-10 10:50:50 Test Loss = 0.029653559890448 
2016-12-10 10:50:50 -------------------LR------------------- 
2016-12-10 10:50:50 0.001953125 
2016-12-10 10:50:50 Epoch 152 
2016-12-10 10:52:40 Training Error = 0.38477116241393 
2016-12-10 10:52:40 Training Loss = 0.02275177809344 
2016-12-10 10:52:42 Valid Error = 0.44835965978129 
2016-12-10 10:52:42 Valid Loss = 0.026597207371028 
2016-12-10 10:52:44 Test Error = 0.43886462882096 
2016-12-10 10:52:44 Test Loss = 0.029124844476288 
2016-12-10 10:52:44 -------------------LR------------------- 
2016-12-10 10:52:44 0.001953125 
2016-12-10 10:52:44 Epoch 153 
2016-12-10 10:54:34 Training Error = 0.38301606588362 
2016-12-10 10:54:34 Training Loss = 0.022813095476024 
2016-12-10 10:54:36 Valid Error = 0.38153098420413 
2016-12-10 10:54:36 Valid Loss = 0.025568489348605 
2016-12-10 10:54:38 Test Error = 0.39192139737991 
2016-12-10 10:54:38 Test Loss = 0.028084894769332 
2016-12-10 10:54:38 -------------------LR------------------- 
2016-12-10 10:54:38 0.001953125 
2016-12-10 10:54:38 Epoch 154 
2016-12-10 10:56:34 Training Error = 0.37856082084515 
2016-12-10 10:56:34 Training Loss = 0.022718519481157 
2016-12-10 10:56:36 Valid Error = 0.36938031591738 
2016-12-10 10:56:36 Valid Loss = 0.025184736765841 
2016-12-10 10:56:38 Test Error = 0.36244541484716 
2016-12-10 10:56:38 Test Loss = 0.027830274955899 
2016-12-10 10:56:38 -------------------LR------------------- 
2016-12-10 10:56:38 0.001953125 
2016-12-10 10:56:38 Epoch 155 
2016-12-10 10:58:34 Training Error = 0.38139597677872 
2016-12-10 10:58:34 Training Loss = 0.022749327338154 
2016-12-10 10:58:36 Valid Error = 0.38517618469016 
2016-12-10 10:58:36 Valid Loss = 0.024633774261894 
2016-12-10 10:58:38 Test Error = 0.38973799126638 
2016-12-10 10:58:38 Test Loss = 0.026908874521068 
2016-12-10 10:58:38 -------------------LR------------------- 
2016-12-10 10:58:38 0.001953125 
2016-12-10 10:58:38 Epoch 156 
2016-12-10 11:00:41 Training Error = 0.3777507762927 
2016-12-10 11:00:41 Training Loss = 0.022773659905043 
2016-12-10 11:00:43 Valid Error = 0.37667071688943 
2016-12-10 11:00:43 Valid Loss = 0.025326842054833 
2016-12-10 11:00:45 Test Error = 0.38427947598253 
2016-12-10 11:00:45 Test Loss = 0.027849960766587 
2016-12-10 11:00:45 -------------------LR------------------- 
2016-12-10 11:00:45 0.001953125 
2016-12-10 11:00:45 Epoch 157 
2016-12-10 11:02:36 Training Error = 0.37977588767382 
2016-12-10 11:02:36 Training Loss = 0.022645362506371 
2016-12-10 11:02:38 Valid Error = 0.40583232077764 
2016-12-10 11:02:38 Valid Loss = 0.025406217279675 
2016-12-10 11:02:40 Test Error = 0.41703056768559 
2016-12-10 11:02:40 Test Loss = 0.028002194591597 
2016-12-10 11:02:40 -------------------LR------------------- 
2016-12-10 11:02:40 0.001953125 
2016-12-10 11:02:40 Epoch 158 
2016-12-10 11:04:23 Training Error = 0.37815579856892 
2016-12-10 11:04:23 Training Loss = 0.022736526114556 
2016-12-10 11:04:25 Valid Error = 0.39489671931956 
2016-12-10 11:04:25 Valid Loss = 0.026312517247621 
2016-12-10 11:04:27 Test Error = 0.39301310043668 
2016-12-10 11:04:27 Test Loss = 0.028752123440013 
2016-12-10 11:04:27 -------------------LR------------------- 
2016-12-10 11:04:27 0.001953125 
2016-12-10 11:04:27 Epoch 159 
2016-12-10 11:06:26 Training Error = 0.37869582827055 
2016-12-10 11:06:26 Training Loss = 0.022657647737847 
2016-12-10 11:06:28 Valid Error = 0.39732685297691 
2016-12-10 11:06:28 Valid Loss = 0.025281198286046 
2016-12-10 11:06:30 Test Error = 0.40829694323144 
2016-12-10 11:06:30 Test Loss = 0.02780778279024 
2016-12-10 11:06:30 -------------------LR------------------- 
2016-12-10 11:06:30 0.001953125 
2016-12-10 11:06:30 Epoch 160 
2016-12-10 11:08:36 Training Error = 0.38058593222627 
2016-12-10 11:08:36 Training Loss = 0.02264955936293 
2016-12-10 11:08:39 Valid Error = 0.46658566221142 
2016-12-10 11:08:39 Valid Loss = 0.02521817127028 
2016-12-10 11:08:41 Test Error = 0.49672489082969 
2016-12-10 11:08:41 Test Loss = 0.027934392498989 
2016-12-10 11:08:41 -------------------LR------------------- 
2016-12-10 11:08:41 0.001953125 
2016-12-10 11:08:41 Epoch 161 
2016-12-10 11:10:34 Training Error = 0.38180099905495 
2016-12-10 11:10:34 Training Loss = 0.02289268552066 
2016-12-10 11:10:35 Valid Error = 0.39732685297691 
2016-12-10 11:10:35 Valid Loss = 0.025720540608851 
2016-12-10 11:10:37 Test Error = 0.39192139737991 
2016-12-10 11:10:37 Test Loss = 0.02844818127389 
2016-12-10 11:10:37 -------------------LR------------------- 
2016-12-10 11:10:37 0.001953125 
2016-12-10 11:10:37 Epoch 162 
2016-12-10 11:12:26 Training Error = 0.38072093965168 
2016-12-10 11:12:26 Training Loss = 0.022918102417562 
2016-12-10 11:12:28 Valid Error = 0.47144592952612 
2016-12-10 11:12:28 Valid Loss = 0.025720403768285 
2016-12-10 11:12:30 Test Error = 0.48471615720524 
2016-12-10 11:12:30 Test Loss = 0.028469301139607 
2016-12-10 11:12:30 -------------------LR------------------- 
2016-12-10 11:12:30 0.001953125 
2016-12-10 11:12:30 Epoch 163 
2016-12-10 11:14:17 Training Error = 0.38207101390576 
2016-12-10 11:14:17 Training Loss = 0.022691164913231 
2016-12-10 11:14:19 Valid Error = 0.38882138517618 
2016-12-10 11:14:19 Valid Loss = 0.025461707368565 
2016-12-10 11:14:21 Test Error = 0.4028384279476 
2016-12-10 11:14:21 Test Loss = 0.027628659790637 
2016-12-10 11:14:21 -------------------LR------------------- 
2016-12-10 11:14:21 0.001953125 
2016-12-10 11:14:21 Epoch 164 
2016-12-10 11:16:24 Training Error = 0.38315107330903 
2016-12-10 11:16:24 Training Loss = 0.022884881437927 
2016-12-10 11:16:26 Valid Error = 0.40947752126367 
2016-12-10 11:16:26 Valid Loss = 0.023843077774966 
2016-12-10 11:16:28 Test Error = 0.40174672489083 
2016-12-10 11:16:28 Test Loss = 0.026401123813554 
2016-12-10 11:16:28 -------------------LR------------------- 
2016-12-10 11:16:28 0.001953125 
2016-12-10 11:16:28 Epoch 165 
2016-12-10 11:18:15 Training Error = 0.38153098420413 
2016-12-10 11:18:15 Training Loss = 0.022723974585155 
2016-12-10 11:18:17 Valid Error = 0.46172539489672 
2016-12-10 11:18:17 Valid Loss = 0.027567741587 
2016-12-10 11:18:19 Test Error = 0.48144104803493 
2016-12-10 11:18:19 Test Loss = 0.030356096492094 
2016-12-10 11:18:19 -------------------LR------------------- 
2016-12-10 11:18:19 0.001953125 
2016-12-10 11:18:19 Epoch 166 
2016-12-10 11:20:13 Training Error = 0.3761306871878 
2016-12-10 11:20:13 Training Loss = 0.022525098897184 
2016-12-10 11:20:15 Valid Error = 0.38153098420413 
2016-12-10 11:20:15 Valid Loss = 0.026601889912825 
2016-12-10 11:20:17 Test Error = 0.39192139737991 
2016-12-10 11:20:17 Test Loss = 0.029097044121985 
2016-12-10 11:20:17 -------------------LR------------------- 
2016-12-10 11:20:17 0.001953125 
2016-12-10 11:20:17 Epoch 167 
2016-12-10 11:22:15 Training Error = 0.38193600648036 
2016-12-10 11:22:15 Training Loss = 0.022799458268822 
2016-12-10 11:22:17 Valid Error = 0.40340218712029 
2016-12-10 11:22:17 Valid Loss = 0.024764288876718 
2016-12-10 11:22:19 Test Error = 0.41157205240175 
2016-12-10 11:22:19 Test Loss = 0.027196845877404 
2016-12-10 11:22:19 -------------------LR------------------- 
2016-12-10 11:22:19 0.001953125 
2016-12-10 11:22:19 Epoch 168 
2016-12-10 11:24:15 Training Error = 0.38045092480086 
2016-12-10 11:24:15 Training Loss = 0.022725635470863 
2016-12-10 11:24:17 Valid Error = 0.40704738760632 
2016-12-10 11:24:17 Valid Loss = 0.025955242906046 
2016-12-10 11:24:19 Test Error = 0.40938864628821 
2016-12-10 11:24:19 Test Loss = 0.028531016648984 
2016-12-10 11:24:19 -------------------LR------------------- 
2016-12-10 11:24:19 0.001953125 
2016-12-10 11:24:19 Epoch 169 
2016-12-10 11:26:04 Training Error = 0.3826110436074 
2016-12-10 11:26:04 Training Loss = 0.022751386412719 
2016-12-10 11:26:06 Valid Error = 0.47023086269745 
2016-12-10 11:26:06 Valid Loss = 0.026841931261325 
2016-12-10 11:26:08 Test Error = 0.48362445414847 
2016-12-10 11:26:08 Test Loss = 0.029160187216366 
2016-12-10 11:26:08 -------------------LR------------------- 
2016-12-10 11:26:08 0.001953125 
2016-12-10 11:26:08 Epoch 170 
2016-12-10 11:28:02 Training Error = 0.37869582827055 
2016-12-10 11:28:02 Training Loss = 0.022491978322091 
2016-12-10 11:28:05 Valid Error = 0.3730255164034 
2016-12-10 11:28:05 Valid Loss = 0.026315920165715 
2016-12-10 11:28:07 Test Error = 0.38755458515284 
2016-12-10 11:28:07 Test Loss = 0.029140938927146 
2016-12-10 11:28:07 -------------------LR------------------- 
2016-12-10 11:28:07 0.001953125 
2016-12-10 11:28:07 Epoch 171 
2016-12-10 11:29:43 Training Error = 0.37748076144188 
2016-12-10 11:29:43 Training Loss = 0.022625058105925 
2016-12-10 11:29:44 Valid Error = 0.38031591737546 
2016-12-10 11:29:44 Valid Loss = 0.024848238601822 
2016-12-10 11:29:46 Test Error = 0.39082969432314 
2016-12-10 11:29:46 Test Loss = 0.027318589163762 
2016-12-10 11:29:46 -------------------LR------------------- 
2016-12-10 11:29:46 0.001953125 
2016-12-10 11:29:46 Epoch 172 
2016-12-10 11:31:26 Training Error = 0.38517618469016 
2016-12-10 11:31:26 Training Loss = 0.022892596144903 
2016-12-10 11:31:28 Valid Error = 0.40097205346294 
2016-12-10 11:31:28 Valid Loss = 0.026048216758787 
2016-12-10 11:31:30 Test Error = 0.40829694323144 
2016-12-10 11:31:30 Test Loss = 0.028472726906047 
2016-12-10 11:31:30 -------------------LR------------------- 
2016-12-10 11:31:30 0.001953125 
2016-12-10 11:31:30 Epoch 173 
2016-12-10 11:33:16 Training Error = 0.38342108815985 
2016-12-10 11:33:16 Training Loss = 0.022822287255153 
2016-12-10 11:33:18 Valid Error = 0.38153098420413 
2016-12-10 11:33:18 Valid Loss = 0.026663869677297 
2016-12-10 11:33:20 Test Error = 0.40065502183406 
2016-12-10 11:33:20 Test Loss = 0.029634835336723 
2016-12-10 11:33:20 -------------------LR------------------- 
2016-12-10 11:33:20 0.001953125 
2016-12-10 11:33:20 Epoch 174 
