2016-12-10 05:49:05 [program started on Sat Dec 10 05:49:05 2016] 
2016-12-10 05:49:05 [command line arguments] 
2016-12-10 05:49:05 stcWeights false 
2016-12-10 05:49:05 LR 0.015625 
2016-12-10 05:49:05 batchSize 100 
2016-12-10 05:49:05 network ./Models/Cifar10_Custom 
2016-12-10 05:49:05 stcNeurons true 
2016-12-10 05:49:05 constBatchSize false 
2016-12-10 05:49:05 chartFileName chart1 
2016-12-10 05:49:05 dp_prepro false 
2016-12-10 05:49:05 nGPU 1 
2016-12-10 05:49:05 dataset Caltech101 
2016-12-10 05:49:05 type cuda 
2016-12-10 05:49:05 momentum 0 
2016-12-10 05:49:05 threads 8 
2016-12-10 05:49:05 weightDecay 0 
2016-12-10 05:49:05 runningVal false 
2016-12-10 05:49:05 convLayerN 6 
2016-12-10 05:49:05 LRDecay 0 
2016-12-10 05:49:05 numHid 2048 
2016-12-10 05:49:05 save /dev/shm/clone/temp/th/Results/Caltech101/model6-10-2048 
2016-12-10 05:49:05 augment false 
2016-12-10 05:49:05 epoch -1 
2016-12-10 05:49:05 modelsFolder ./Models/ 
2016-12-10 05:49:05 format rgb 
2016-12-10 05:49:05 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-10 05:49:05 imageFileExtension svg 
2016-12-10 05:49:05 channel 1 
2016-12-10 05:49:05 devid 11 
2016-12-10 05:49:05 visualize 1 
2016-12-10 05:49:05 LRDecayPerEpoch 0.0001 
2016-12-10 05:49:05 optimization adam 
2016-12-10 05:49:05 SBN true 
2016-12-10 05:49:05 normalization simple 
2016-12-10 05:49:05 title model1 
2016-12-10 05:49:05 load  
2016-12-10 05:49:05 whiten true 
2016-12-10 05:49:05 [----------------------] 
2016-12-10 05:49:07 ==> Network 
2016-12-10 05:49:07 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 2048)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(2048 -> 2048)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(2048 -> 102)
  (38): nn.BatchNormalization
} 
2016-12-10 05:49:07 ==>25772978 Parameters 
2016-12-10 05:49:07 ==> Loss 
2016-12-10 05:49:07 SqrtHingeEmbeddingCriterion 
2016-12-10 05:49:07 
==> Starting Training
 
2016-12-10 05:49:07 Epoch 1 
2016-12-10 05:50:43 Training Error = 0.80450924800864 
2016-12-10 05:50:43 Training Loss = 0.42673221495385 
2016-12-10 05:50:45 Valid Error = 0.81287970838396 
2016-12-10 05:50:45 Valid Loss = 0.070859704573656 
2016-12-10 05:50:47 Test Error = 0.82314410480349 
2016-12-10 05:50:47 Test Loss = 0.072009207089742 
2016-12-10 05:50:47 -------------------LR------------------- 
2016-12-10 05:50:47 0.015625 
2016-12-10 05:50:47 Epoch 2 
2016-12-10 05:52:18 Training Error = 0.68030241663291 
2016-12-10 05:52:18 Training Loss = 0.041920889132631 
2016-12-10 05:52:20 Valid Error = 0.72053462940462 
2016-12-10 05:52:20 Valid Loss = 0.034831377141255 
2016-12-10 05:52:22 Test Error = 0.75218340611354 
2016-12-10 05:52:22 Test Loss = 0.036282951523276 
2016-12-10 05:52:22 -------------------LR------------------- 
2016-12-10 05:52:22 0.015625 
2016-12-10 05:52:22 Epoch 3 
2016-12-10 05:53:55 Training Error = 0.62076414202781 
2016-12-10 05:53:55 Training Loss = 0.029909920622098 
2016-12-10 05:53:57 Valid Error = 0.72053462940462 
2016-12-10 05:53:57 Valid Loss = 0.031218223821104 
2016-12-10 05:53:59 Test Error = 0.75218340611354 
2016-12-10 05:53:59 Test Loss = 0.033330464737088 
2016-12-10 05:53:59 -------------------LR------------------- 
2016-12-10 05:53:59 0.015625 
2016-12-10 05:53:59 Epoch 4 
2016-12-10 05:55:33 Training Error = 0.60213311732145 
2016-12-10 05:55:33 Training Loss = 0.028227717732804 
2016-12-10 05:55:35 Valid Error = 0.74726609963548 
2016-12-10 05:55:35 Valid Loss = 0.030388561312737 
2016-12-10 05:55:37 Test Error = 0.78493449781659 
2016-12-10 05:55:37 Test Loss = 0.032032748839434 
2016-12-10 05:55:37 -------------------LR------------------- 
2016-12-10 05:55:37 0.015625 
2016-12-10 05:55:37 Epoch 5 
2016-12-10 05:57:09 Training Error = 0.58134197380856 
2016-12-10 05:57:09 Training Loss = 0.02737177319353 
2016-12-10 05:57:11 Valid Error = 0.67922235722965 
2016-12-10 05:57:11 Valid Loss = 0.028680856366314 
2016-12-10 05:57:13 Test Error = 0.70305676855895 
2016-12-10 05:57:13 Test Loss = 0.030220931529999 
2016-12-10 05:57:13 -------------------LR------------------- 
2016-12-10 05:57:13 0.015625 
2016-12-10 05:57:13 Epoch 6 
2016-12-10 05:58:49 Training Error = 0.55852571891454 
2016-12-10 05:58:49 Training Loss = 0.026687134373199 
2016-12-10 05:58:51 Valid Error = 0.65370595382746 
2016-12-10 05:58:51 Valid Loss = 0.037487970489302 
2016-12-10 05:58:53 Test Error = 0.71069868995633 
2016-12-10 05:58:53 Test Loss = 0.040684370620578 
2016-12-10 05:58:53 -------------------LR------------------- 
2016-12-10 05:58:53 0.015625 
2016-12-10 05:58:53 Epoch 7 
2016-12-10 06:00:39 Training Error = 0.54326987984339 
2016-12-10 06:00:39 Training Loss = 0.026192981836086 
2016-12-10 06:00:41 Valid Error = 0.65978128797084 
2016-12-10 06:00:41 Valid Loss = 0.030091549605145 
2016-12-10 06:00:43 Test Error = 0.70524017467249 
2016-12-10 06:00:43 Test Loss = 0.032609335918053 
2016-12-10 06:00:43 -------------------LR------------------- 
2016-12-10 06:00:43 0.015625 
2016-12-10 06:00:43 Epoch 8 
2016-12-10 06:02:19 Training Error = 0.51100310517078 
2016-12-10 06:02:19 Training Loss = 0.025190715062474 
2016-12-10 06:02:21 Valid Error = 0.48724179829891 
2016-12-10 06:02:21 Valid Loss = 0.02661180666589 
2016-12-10 06:02:23 Test Error = 0.52947598253275 
2016-12-10 06:02:23 Test Loss = 0.028988655763514 
2016-12-10 06:02:23 -------------------LR------------------- 
2016-12-10 06:02:23 0.015625 
2016-12-10 06:02:23 Epoch 9 
2016-12-10 06:03:57 Training Error = 0.44876468205751 
2016-12-10 06:03:57 Training Loss = 0.02398770754945 
2016-12-10 06:03:59 Valid Error = 0.59052247873633 
2016-12-10 06:03:59 Valid Loss = 0.030145831963121 
2016-12-10 06:04:01 Test Error = 0.62991266375546 
2016-12-10 06:04:01 Test Loss = 0.03372294736376 
2016-12-10 06:04:01 -------------------LR------------------- 
2016-12-10 06:04:01 0.015625 
2016-12-10 06:04:01 Epoch 10 
2016-12-10 06:06:12 Training Error = 0.38855137032537 
2016-12-10 06:06:12 Training Loss = 0.022493024197391 
2016-12-10 06:06:14 Valid Error = 0.64398541919806 
2016-12-10 06:06:14 Valid Loss = 0.032478314755913 
2016-12-10 06:06:16 Test Error = 0.66921397379913 
2016-12-10 06:06:16 Test Loss = 0.03383268068351 
2016-12-10 06:06:16 -------------------LR------------------- 
2016-12-10 06:06:16 0.015625 
2016-12-10 06:06:16 Epoch 11 
2016-12-10 06:08:16 Training Error = 0.37694073174025 
2016-12-10 06:08:16 Training Loss = 0.02270358292609 
2016-12-10 06:08:18 Valid Error = 0.41433778857837 
2016-12-10 06:08:18 Valid Loss = 0.023623847509747 
2016-12-10 06:08:20 Test Error = 0.42685589519651 
2016-12-10 06:08:20 Test Loss = 0.025845181222055 
2016-12-10 06:08:20 -------------------LR------------------- 
2016-12-10 06:08:20 0.015625 
2016-12-10 06:08:20 Epoch 12 
2016-12-10 06:09:55 Training Error = 0.38342108815985 
2016-12-10 06:09:55 Training Loss = 0.022790957806869 
2016-12-10 06:09:57 Valid Error = 0.4678007290401 
2016-12-10 06:09:57 Valid Loss = 0.026507060795421 
2016-12-10 06:09:59 Test Error = 0.46834061135371 
2016-12-10 06:09:59 Test Loss = 0.028972537022011 
2016-12-10 06:09:59 -------------------LR------------------- 
2016-12-10 06:09:59 0.015625 
2016-12-10 06:09:59 Epoch 13 
2016-12-10 06:12:00 Training Error = 0.38018090995005 
2016-12-10 06:12:00 Training Loss = 0.022574853575463 
2016-12-10 06:12:01 Valid Error = 0.38396111786148 
2016-12-10 06:12:01 Valid Loss = 0.025064338603864 
2016-12-10 06:12:04 Test Error = 0.39628820960699 
2016-12-10 06:12:04 Test Loss = 0.02778562338212 
2016-12-10 06:12:04 -------------------LR------------------- 
2016-12-10 06:12:04 0.015625 
2016-12-10 06:12:04 Epoch 14 
2016-12-10 06:13:53 Training Error = 0.38625624409343 
2016-12-10 06:13:53 Training Loss = 0.022665397981702 
2016-12-10 06:13:55 Valid Error = 0.37424058323208 
2016-12-10 06:13:55 Valid Loss = 0.026827020026342 
2016-12-10 06:13:57 Test Error = 0.36899563318777 
2016-12-10 06:13:57 Test Loss = 0.029452058754715 
2016-12-10 06:13:57 -------------------LR------------------- 
2016-12-10 06:13:57 0.015625 
2016-12-10 06:13:57 Epoch 15 
2016-12-10 06:15:36 Training Error = 0.38463615498852 
2016-12-10 06:15:36 Training Loss = 0.022594086290319 
2016-12-10 06:15:38 Valid Error = 0.40461725394897 
2016-12-10 06:15:38 Valid Loss = 0.024324610382135 
2016-12-10 06:15:40 Test Error = 0.39410480349345 
2016-12-10 06:15:40 Test Loss = 0.02665345473383 
2016-12-10 06:15:40 -------------------LR------------------- 
2016-12-10 06:15:40 0.015625 
2016-12-10 06:15:40 Epoch 16 
2016-12-10 06:17:18 Training Error = 0.37950587282301 
2016-12-10 06:17:18 Training Loss = 0.022563292677707 
2016-12-10 06:17:20 Valid Error = 0.37424058323208 
2016-12-10 06:17:20 Valid Loss = 0.025022937384046 
2016-12-10 06:17:22 Test Error = 0.36899563318777 
2016-12-10 06:17:22 Test Loss = 0.027422002998053 
2016-12-10 06:17:22 -------------------LR------------------- 
2016-12-10 06:17:22 0.015625 
2016-12-10 06:17:22 Epoch 17 
2016-12-10 06:19:04 Training Error = 0.37964088024841 
2016-12-10 06:19:04 Training Loss = 0.022746650681554 
2016-12-10 06:19:06 Valid Error = 0.39003645200486 
2016-12-10 06:19:06 Valid Loss = 0.025974378182015 
2016-12-10 06:19:08 Test Error = 0.38646288209607 
2016-12-10 06:19:08 Test Loss = 0.028434125376683 
2016-12-10 06:19:08 -------------------LR------------------- 
2016-12-10 06:19:08 0.015625 
2016-12-10 06:19:08 Epoch 18 
2016-12-10 06:20:51 Training Error = 0.37680572431484 
2016-12-10 06:20:51 Training Loss = 0.022709804256379 
2016-12-10 06:20:52 Valid Error = 0.40461725394897 
2016-12-10 06:20:52 Valid Loss = 0.025284092180361 
2016-12-10 06:20:54 Test Error = 0.41484716157205 
2016-12-10 06:20:54 Test Loss = 0.02789484425152 
2016-12-10 06:20:54 -------------------LR------------------- 
2016-12-10 06:20:54 0.015625 
2016-12-10 06:20:54 Epoch 19 
2016-12-10 06:22:39 Training Error = 0.3809909545025 
2016-12-10 06:22:39 Training Loss = 0.02283709206176 
2016-12-10 06:22:41 Valid Error = 0.38760631834751 
2016-12-10 06:22:41 Valid Loss = 0.025995407928354 
2016-12-10 06:22:43 Test Error = 0.40174672489083 
2016-12-10 06:22:43 Test Loss = 0.02872588557823 
2016-12-10 06:22:43 -------------------LR------------------- 
2016-12-10 06:22:43 0.015625 
2016-12-10 06:22:43 Epoch 20 
2016-12-10 06:24:28 Training Error = 0.37653570946402 
2016-12-10 06:24:28 Training Loss = 0.022642312486722 
2016-12-10 06:24:30 Valid Error = 0.37667071688943 
2016-12-10 06:24:30 Valid Loss = 0.026082421407856 
2016-12-10 06:24:32 Test Error = 0.38427947598253 
2016-12-10 06:24:32 Test Loss = 0.028400396347046 
2016-12-10 06:24:32 -------------------LR------------------- 
2016-12-10 06:24:32 0.015625 
2016-12-10 06:24:32 Epoch 21 
2016-12-10 06:26:17 Training Error = 0.38220602133117 
2016-12-10 06:26:17 Training Loss = 0.022698655249046 
2016-12-10 06:26:19 Valid Error = 0.45808019441069 
2016-12-10 06:26:19 Valid Loss = 0.027957562042523 
2016-12-10 06:26:21 Test Error = 0.48471615720524 
2016-12-10 06:26:21 Test Loss = 0.030824512893078 
2016-12-10 06:26:21 -------------------LR------------------- 
2016-12-10 06:26:21 0.015625 
2016-12-10 06:26:21 Epoch 22 
2016-12-10 06:28:22 Training Error = 0.38112596192791 
2016-12-10 06:28:22 Training Loss = 0.02265218265651 
2016-12-10 06:28:24 Valid Error = 0.38153098420413 
2016-12-10 06:28:24 Valid Loss = 0.025453684623352 
2016-12-10 06:28:26 Test Error = 0.39192139737991 
2016-12-10 06:28:26 Test Loss = 0.027983199942346 
2016-12-10 06:28:26 -------------------LR------------------- 
2016-12-10 06:28:26 0.015625 
2016-12-10 06:28:26 Epoch 23 
2016-12-10 06:30:19 Training Error = 0.38274605103281 
2016-12-10 06:30:19 Training Loss = 0.02274488191293 
2016-12-10 06:30:20 Valid Error = 0.37424058323208 
2016-12-10 06:30:20 Valid Loss = 0.026198749988495 
2016-12-10 06:30:22 Test Error = 0.39410480349345 
2016-12-10 06:30:22 Test Loss = 0.028903998393638 
2016-12-10 06:30:22 -------------------LR------------------- 
2016-12-10 06:30:22 0.015625 
2016-12-10 06:30:22 Epoch 24 
2016-12-10 06:32:16 Training Error = 0.38031591737546 
2016-12-10 06:32:16 Training Loss = 0.022751374456439 
2016-12-10 06:32:18 Valid Error = 0.46172539489672 
2016-12-10 06:32:18 Valid Loss = 0.024457292151155 
2016-12-10 06:32:20 Test Error = 0.49017467248908 
2016-12-10 06:32:20 Test Loss = 0.027063599689334 
2016-12-10 06:32:20 -------------------LR------------------- 
2016-12-10 06:32:20 0.015625 
2016-12-10 06:32:20 Epoch 25 
2016-12-10 06:34:10 Training Error = 0.38207101390576 
2016-12-10 06:34:10 Training Loss = 0.022707543811388 
2016-12-10 06:34:12 Valid Error = 0.38153098420413 
2016-12-10 06:34:12 Valid Loss = 0.02637370117598 
2016-12-10 06:34:14 Test Error = 0.39192139737991 
2016-12-10 06:34:14 Test Loss = 0.028919879240148 
2016-12-10 06:34:14 -------------------LR------------------- 
2016-12-10 06:34:14 0.015625 
2016-12-10 06:34:14 Epoch 26 
2016-12-10 06:36:04 Training Error = 0.38112596192791 
2016-12-10 06:36:04 Training Loss = 0.022739936942591 
2016-12-10 06:36:06 Valid Error = 0.37667071688943 
2016-12-10 06:36:06 Valid Loss = 0.02576302212116 
2016-12-10 06:36:08 Test Error = 0.38427947598253 
2016-12-10 06:36:08 Test Loss = 0.02814069482392 
2016-12-10 06:36:08 -------------------LR------------------- 
2016-12-10 06:36:08 0.015625 
2016-12-10 06:36:08 Epoch 27 
2016-12-10 06:38:04 Training Error = 0.38031591737546 
2016-12-10 06:38:04 Training Loss = 0.022879761309227 
2016-12-10 06:38:06 Valid Error = 0.40461725394897 
2016-12-10 06:38:06 Valid Loss = 0.02366928116485 
2016-12-10 06:38:08 Test Error = 0.4061135371179 
2016-12-10 06:38:08 Test Loss = 0.026168082499037 
2016-12-10 06:38:08 -------------------LR------------------- 
2016-12-10 06:38:08 0.015625 
2016-12-10 06:38:08 Epoch 28 
2016-12-10 06:40:01 Training Error = 0.38301606588362 
2016-12-10 06:40:01 Training Loss = 0.022812745974244 
2016-12-10 06:40:03 Valid Error = 0.45808019441069 
2016-12-10 06:40:03 Valid Loss = 0.027302737180466 
2016-12-10 06:40:05 Test Error = 0.46397379912664 
2016-12-10 06:40:05 Test Loss = 0.029895125669592 
2016-12-10 06:40:05 -------------------LR------------------- 
2016-12-10 06:40:05 0.015625 
2016-12-10 06:40:05 Epoch 29 
2016-12-10 06:41:54 Training Error = 0.38004590252464 
2016-12-10 06:41:54 Training Loss = 0.022632964260126 
2016-12-10 06:41:56 Valid Error = 0.39489671931956 
2016-12-10 06:41:56 Valid Loss = 0.024924335832046 
2016-12-10 06:41:58 Test Error = 0.41157205240175 
2016-12-10 06:41:58 Test Loss = 0.027280935409022 
2016-12-10 06:41:58 -------------------LR------------------- 
2016-12-10 06:41:58 0.015625 
2016-12-10 06:41:58 Epoch 30 
2016-12-10 06:43:52 Training Error = 0.3777507762927 
2016-12-10 06:43:52 Training Loss = 0.022928533747483 
2016-12-10 06:43:54 Valid Error = 0.38153098420413 
2016-12-10 06:43:54 Valid Loss = 0.025367480400239 
2016-12-10 06:43:56 Test Error = 0.39192139737991 
2016-12-10 06:43:56 Test Loss = 0.02801496294433 
2016-12-10 06:43:56 -------------------LR------------------- 
2016-12-10 06:43:56 0.015625 
2016-12-10 06:43:56 Epoch 31 
2016-12-10 06:45:53 Training Error = 0.37815579856892 
2016-12-10 06:45:53 Training Loss = 0.022741869349262 
2016-12-10 06:45:55 Valid Error = 0.46415552855407 
2016-12-10 06:45:55 Valid Loss = 0.027994722932015 
2016-12-10 06:45:57 Test Error = 0.47161572052402 
2016-12-10 06:45:57 Test Loss = 0.030404030089285 
2016-12-10 06:45:57 -------------------LR------------------- 
2016-12-10 06:45:57 0.015625 
2016-12-10 06:45:57 Epoch 32 
2016-12-10 06:47:41 Training Error = 0.38301606588362 
2016-12-10 06:47:41 Training Loss = 0.022942697947099 
2016-12-10 06:47:43 Valid Error = 0.47023086269745 
2016-12-10 06:47:43 Valid Loss = 0.02554516263201 
2016-12-10 06:47:45 Test Error = 0.45851528384279 
2016-12-10 06:47:45 Test Loss = 0.027925228287192 
2016-12-10 06:47:45 -------------------LR------------------- 
2016-12-10 06:47:45 0.015625 
2016-12-10 06:47:45 Epoch 33 
2016-12-10 06:49:41 Training Error = 0.38274605103281 
2016-12-10 06:49:41 Training Loss = 0.022815191666063 
2016-12-10 06:49:43 Valid Error = 0.38517618469016 
2016-12-10 06:49:43 Valid Loss = 0.025422937946585 
2016-12-10 06:49:45 Test Error = 0.39956331877729 
2016-12-10 06:49:45 Test Loss = 0.027636695010989 
2016-12-10 06:49:45 -------------------LR------------------- 
2016-12-10 06:49:45 0.015625 
2016-12-10 06:49:45 Epoch 34 
2016-12-10 06:51:52 Training Error = 0.38207101390576 
2016-12-10 06:51:52 Training Loss = 0.022736673550646 
2016-12-10 06:51:55 Valid Error = 0.39611178614824 
2016-12-10 06:51:55 Valid Loss = 0.02422964599962 
