2016-12-11 13:23:03 [program started on Sun Dec 11 13:23:03 2016] 
2016-12-11 13:23:03 [command line arguments] 
2016-12-11 13:23:03 stcWeights false 
2016-12-11 13:23:03 LR 0.015625 
2016-12-11 13:23:03 batchSize 100 
2016-12-11 13:23:03 network ./Models/Cifar10_Custom 
2016-12-11 13:23:03 stcNeurons true 
2016-12-11 13:23:03 constBatchSize false 
2016-12-11 13:23:03 chartFileName chart1 
2016-12-11 13:23:03 dp_prepro false 
2016-12-11 13:23:03 nGPU 1 
2016-12-11 13:23:03 dataset Caltech101 
2016-12-11 13:23:03 type cuda 
2016-12-11 13:23:03 momentum 0 
2016-12-11 13:23:03 threads 8 
2016-12-11 13:23:03 weightDecay 0 
2016-12-11 13:23:03 runningVal false 
2016-12-11 13:23:03 convLayerN 10 
2016-12-11 13:23:03 LRDecay 0 
2016-12-11 13:23:03 numHid 1024 
2016-12-11 13:23:03 save /dev/shm/clone/temp/th/Results/Caltech101/model10-10 
2016-12-11 13:23:03 augment false 
2016-12-11 13:23:03 epoch -1 
2016-12-11 13:23:03 modelsFolder ./Models/ 
2016-12-11 13:23:03 format rgb 
2016-12-11 13:23:03 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-11 13:23:03 imageFileExtension svg 
2016-12-11 13:23:03 channel 1 
2016-12-11 13:23:03 devid 3 
2016-12-11 13:23:03 visualize 1 
2016-12-11 13:23:03 LRDecayPerEpoch 0.0001 
2016-12-11 13:23:03 optimization adam 
2016-12-11 13:23:03 SBN true 
2016-12-11 13:23:03 normalization simple 
2016-12-11 13:23:03 title model1 
2016-12-11 13:23:03 load  
2016-12-11 13:23:03 whiten true 
2016-12-11 13:23:03 [----------------------] 
2016-12-11 13:23:05 ==> Network 
2016-12-11 13:23:05 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> (43) -> (44) -> (45) -> (46) -> (47) -> (48) -> (49) -> (50) -> (51) -> (52) -> (53) -> (54) -> (55) -> (56) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (29): SpatialBatchNormalizationShiftPow2
  (30): nn.HardTanh
  (31): BinarizedNeurons
  (32): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (33): cudnn.SpatialMaxPooling(2x2, 2,2)
  (34): SpatialBatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (38): SpatialBatchNormalizationShiftPow2
  (39): nn.HardTanh
  (40): BinarizedNeurons
  (41): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (42): cudnn.SpatialMaxPooling(2x2, 2,2)
  (43): SpatialBatchNormalizationShiftPow2
  (44): nn.HardTanh
  (45): BinarizedNeurons
  (46): nn.View(512)
  (47): BinaryLinear(512 -> 1024)
  (48): BatchNormalizationShiftPow2
  (49): nn.HardTanh
  (50): BinarizedNeurons
  (51): BinaryLinear(1024 -> 1024)
  (52): BatchNormalizationShiftPow2
  (53): nn.HardTanh
  (54): BinarizedNeurons
  (55): BinaryLinear(1024 -> 102)
  (56): nn.BatchNormalization
} 
2016-12-11 13:23:05 ==>15707058 Parameters 
2016-12-11 13:23:05 ==> Loss 
2016-12-11 13:23:05 SqrtHingeEmbeddingCriterion 
2016-12-11 13:23:05 
==> Starting Training
 
2016-12-11 13:23:05 Epoch 1 
2016-12-11 13:24:51 Training Error = 0.88038342108816 
2016-12-11 13:24:51 Training Loss = 0.42418396984282 
2016-12-11 13:24:53 Valid Error = 0.86634264884569 
2016-12-11 13:24:53 Valid Loss = 0.068901857341952 
2016-12-11 13:24:55 Test Error = 0.87882096069869 
2016-12-11 13:24:55 Test Loss = 0.069332695661807 
2016-12-11 13:24:55 -------------------LR------------------- 
2016-12-11 13:24:55 0.015625 
2016-12-11 13:24:55 Epoch 2 
2016-12-11 13:26:34 Training Error = 0.76481706493857 
2016-12-11 13:26:34 Training Loss = 0.045478190317875 
2016-12-11 13:26:36 Valid Error = 0.8456865127582 
2016-12-11 13:26:36 Valid Loss = 0.0379454956893 
2016-12-11 13:26:38 Test Error = 0.87008733624454 
2016-12-11 13:26:38 Test Loss = 0.038548522463032 
2016-12-11 13:26:38 -------------------LR------------------- 
2016-12-11 13:26:38 0.015625 
2016-12-11 13:26:38 Epoch 3 
2016-12-11 13:28:25 Training Error = 0.69785338193601 
2016-12-11 13:28:25 Training Loss = 0.034257116088012 
2016-12-11 13:28:27 Valid Error = 0.74240583232078 
2016-12-11 13:28:27 Valid Loss = 0.032277383503503 
2016-12-11 13:28:29 Test Error = 0.74017467248908 
2016-12-11 13:28:29 Test Loss = 0.032645649816476 
2016-12-11 13:28:29 -------------------LR------------------- 
2016-12-11 13:28:29 0.015625 
2016-12-11 13:28:29 Epoch 4 
2016-12-11 13:30:13 Training Error = 0.67814229782638 
2016-12-11 13:30:13 Training Loss = 0.031656197715496 
2016-12-11 13:30:15 Valid Error = 0.67922235722965 
2016-12-11 13:30:15 Valid Loss = 0.02964681466556 
2016-12-11 13:30:18 Test Error = 0.68558951965065 
2016-12-11 13:30:18 Test Loss = 0.030395876323476 
2016-12-11 13:30:18 -------------------LR------------------- 
2016-12-11 13:30:18 0.015625 
2016-12-11 13:30:18 Epoch 5 
2016-12-11 13:32:03 Training Error = 0.67301201566086 
2016-12-11 13:32:03 Training Loss = 0.029890937701171 
2016-12-11 13:32:05 Valid Error = 0.67922235722965 
2016-12-11 13:32:05 Valid Loss = 0.029714843961024 
2016-12-11 13:32:07 Test Error = 0.68558951965065 
2016-12-11 13:32:07 Test Loss = 0.030490559129154 
2016-12-11 13:32:07 -------------------LR------------------- 
2016-12-11 13:32:07 0.015625 
2016-12-11 13:32:07 Epoch 6 
2016-12-11 13:33:47 Training Error = 0.66936681517483 
2016-12-11 13:33:47 Training Loss = 0.029863730111999 
2016-12-11 13:33:49 Valid Error = 0.67922235722965 
2016-12-11 13:33:49 Valid Loss = 0.031406730282563 
2016-12-11 13:33:51 Test Error = 0.68558951965065 
2016-12-11 13:33:51 Test Loss = 0.032632638575984 
2016-12-11 13:33:51 -------------------LR------------------- 
2016-12-11 13:33:51 0.015625 
2016-12-11 13:33:51 Epoch 7 
2016-12-11 13:35:35 Training Error = 0.65789118401512 
2016-12-11 13:35:35 Training Loss = 0.029447875747182 
2016-12-11 13:35:37 Valid Error = 0.72539489671932 
2016-12-11 13:35:37 Valid Loss = 0.03456183016272 
2016-12-11 13:35:39 Test Error = 0.73034934497817 
2016-12-11 13:35:39 Test Loss = 0.035510407232771 
2016-12-11 13:35:39 -------------------LR------------------- 
2016-12-11 13:35:39 0.015625 
2016-12-11 13:35:39 Epoch 8 
2016-12-11 13:37:19 Training Error = 0.6350749291211 
2016-12-11 13:37:19 Training Loss = 0.028129982731211 
2016-12-11 13:37:21 Valid Error = 0.78371810449575 
2016-12-11 13:37:21 Valid Loss = 0.034457828716492 
2016-12-11 13:37:23 Test Error = 0.80676855895197 
2016-12-11 13:37:23 Test Loss = 0.035556907130223 
2016-12-11 13:37:23 -------------------LR------------------- 
2016-12-11 13:37:23 0.015625 
2016-12-11 13:37:23 Epoch 9 
2016-12-11 13:38:53 Training Error = 0.6157688672877 
2016-12-11 13:38:53 Training Loss = 0.027711437768874 
2016-12-11 13:38:55 Valid Error = 0.78736330498177 
2016-12-11 13:38:55 Valid Loss = 0.03426631202275 
2016-12-11 13:38:58 Test Error = 0.7882096069869 
2016-12-11 13:38:58 Test Loss = 0.035199558734894 
2016-12-11 13:38:58 -------------------LR------------------- 
2016-12-11 13:38:58 0.015625 
2016-12-11 13:38:58 Epoch 10 
2016-12-11 13:40:41 Training Error = 0.61657891184015 
2016-12-11 13:40:41 Training Loss = 0.027582640849308 
2016-12-11 13:40:43 Valid Error = 0.69380315917375 
2016-12-11 13:40:43 Valid Loss = 0.031098722512268 
2016-12-11 13:40:45 Test Error = 0.74454148471616 
2016-12-11 13:40:45 Test Loss = 0.032832260533875 
2016-12-11 13:40:45 -------------------LR------------------- 
2016-12-11 13:40:45 0.015625 
2016-12-11 13:40:45 Epoch 11 
2016-12-11 13:42:28 Training Error = 0.60064803564196 
2016-12-11 13:42:28 Training Loss = 0.026947150518736 
2016-12-11 13:42:30 Valid Error = 0.7363304981774 
2016-12-11 13:42:30 Valid Loss = 0.035996107220864 
2016-12-11 13:42:32 Test Error = 0.79039301310044 
2016-12-11 13:42:32 Test Loss = 0.037999149986342 
2016-12-11 13:42:32 -------------------LR------------------- 
2016-12-11 13:42:32 0.015625 
2016-12-11 13:42:32 Epoch 12 
2016-12-11 13:44:22 Training Error = 0.60118806534359 
2016-12-11 13:44:22 Training Loss = 0.02680307658647 
2016-12-11 13:44:24 Valid Error = 0.68408262454435 
2016-12-11 13:44:24 Valid Loss = 0.030774049967587 
2016-12-11 13:44:26 Test Error = 0.7292576419214 
2016-12-11 13:44:26 Test Loss = 0.032902053421619 
2016-12-11 13:44:26 -------------------LR------------------- 
2016-12-11 13:44:26 0.015625 
2016-12-11 13:44:26 Epoch 13 
2016-12-11 13:46:12 Training Error = 0.5997029836641 
2016-12-11 13:46:12 Training Loss = 0.026675868827756 
2016-12-11 13:46:14 Valid Error = 0.60510328068044 
2016-12-11 13:46:14 Valid Loss = 0.027225965272413 
2016-12-11 13:46:16 Test Error = 0.64192139737991 
2016-12-11 13:46:16 Test Loss = 0.028678405303581 
2016-12-11 13:46:16 -------------------LR------------------- 
2016-12-11 13:46:16 0.015625 
2016-12-11 13:46:16 Epoch 14 
2016-12-11 13:48:12 Training Error = 0.59997299851492 
2016-12-11 13:48:12 Training Loss = 0.026804347333009 
2016-12-11 13:48:14 Valid Error = 0.68286755771567 
2016-12-11 13:48:14 Valid Loss = 0.031675786514044 
2016-12-11 13:48:16 Test Error = 0.73580786026201 
2016-12-11 13:48:16 Test Loss = 0.034033564754561 
2016-12-11 13:48:16 -------------------LR------------------- 
2016-12-11 13:48:16 0.015625 
2016-12-11 13:48:16 Epoch 15 
2016-12-11 13:50:14 Training Error = 0.59943296881328 
2016-12-11 13:50:14 Training Loss = 0.026682220525946 
2016-12-11 13:50:16 Valid Error = 0.60510328068044 
2016-12-11 13:50:16 Valid Loss = 0.027348793711278 
2016-12-11 13:50:18 Test Error = 0.64192139737991 
2016-12-11 13:50:18 Test Loss = 0.029118647444482 
2016-12-11 13:50:18 -------------------LR------------------- 
2016-12-11 13:50:18 0.015625 
2016-12-11 13:50:18 Epoch 16 
2016-12-11 13:52:11 Training Error = 0.60388821385176 
2016-12-11 13:52:11 Training Loss = 0.026881611969536 
2016-12-11 13:52:13 Valid Error = 0.68286755771567 
2016-12-11 13:52:13 Valid Loss = 0.030393574974737 
2016-12-11 13:52:15 Test Error = 0.73580786026201 
2016-12-11 13:52:15 Test Loss = 0.032770647189196 
2016-12-11 13:52:15 -------------------LR------------------- 
2016-12-11 13:52:15 0.015625 
2016-12-11 13:52:15 Epoch 17 
2016-12-11 13:54:21 Training Error = 0.59862292426083 
2016-12-11 13:54:21 Training Loss = 0.026621301430525 
2016-12-11 13:54:23 Valid Error = 0.726609963548 
2016-12-11 13:54:23 Valid Loss = 0.034817348667039 
2016-12-11 13:54:25 Test Error = 0.77510917030568 
2016-12-11 13:54:25 Test Loss = 0.036630708049325 
2016-12-11 13:54:25 -------------------LR------------------- 
2016-12-11 13:54:25 0.015625 
2016-12-11 13:54:25 Epoch 18 
2016-12-11 13:56:16 Training Error = 0.60091805049278 
2016-12-11 13:56:16 Training Loss = 0.026804358609696 
2016-12-11 13:56:18 Valid Error = 0.69380315917375 
2016-12-11 13:56:18 Valid Loss = 0.030751664614354 
2016-12-11 13:56:20 Test Error = 0.74454148471616 
2016-12-11 13:56:20 Test Loss = 0.033072006936167 
2016-12-11 13:56:20 -------------------LR------------------- 
2016-12-11 13:56:20 0.015625 
2016-12-11 13:56:20 Epoch 19 
2016-12-11 13:57:55 Training Error = 0.60037802079114 
2016-12-11 13:57:55 Training Loss = 0.026742194387114 
2016-12-11 13:57:57 Valid Error = 0.726609963548 
2016-12-11 13:57:57 Valid Loss = 0.033022591425657 
2016-12-11 13:57:59 Test Error = 0.78056768558952 
2016-12-11 13:57:59 Test Loss = 0.035146552992802 
2016-12-11 13:57:59 -------------------LR------------------- 
2016-12-11 13:57:59 0.015625 
2016-12-11 13:57:59 Epoch 20 
2016-12-11 13:59:34 Training Error = 0.60240313217227 
2016-12-11 13:59:34 Training Loss = 0.026781599309442 
2016-12-11 13:59:36 Valid Error = 0.726609963548 
2016-12-11 13:59:36 Valid Loss = 0.034808041730749 
2016-12-11 13:59:38 Test Error = 0.77510917030568 
2016-12-11 13:59:38 Test Loss = 0.036687543382832 
2016-12-11 13:59:38 -------------------LR------------------- 
2016-12-11 13:59:38 0.015625 
2016-12-11 13:59:38 Epoch 21 
2016-12-11 14:01:10 Training Error = 0.60213311732145 
2016-12-11 14:01:10 Training Loss = 0.026714119021632 
2016-12-11 14:01:12 Valid Error = 0.7363304981774 
2016-12-11 14:01:12 Valid Loss = 0.035867166059356 
2016-12-11 14:01:14 Test Error = 0.79039301310044 
2016-12-11 14:01:14 Test Loss = 0.038064832799575 
2016-12-11 14:01:14 -------------------LR------------------- 
2016-12-11 14:01:14 0.015625 
2016-12-11 14:01:14 Epoch 22 
2016-12-11 14:02:45 Training Error = 0.60159308761982 
2016-12-11 14:02:45 Training Loss = 0.026856251324993 
2016-12-11 14:02:47 Valid Error = 0.60510328068044 
2016-12-11 14:02:47 Valid Loss = 0.027274848964728 
2016-12-11 14:02:49 Test Error = 0.64192139737991 
2016-12-11 14:02:49 Test Loss = 0.028707981661254 
2016-12-11 14:02:49 -------------------LR------------------- 
2016-12-11 14:02:49 0.015625 
2016-12-11 14:02:49 Epoch 23 
2016-12-11 14:04:20 Training Error = 0.60010800594033 
2016-12-11 14:04:20 Training Loss = 0.026867270122567 
2016-12-11 14:04:22 Valid Error = 0.7363304981774 
2016-12-11 14:04:22 Valid Loss = 0.036650941094813 
2016-12-11 14:04:24 Test Error = 0.79039301310044 
2016-12-11 14:04:24 Test Loss = 0.038680391395793 
2016-12-11 14:04:24 -------------------LR------------------- 
2016-12-11 14:04:24 0.015625 
2016-12-11 14:04:24 Epoch 24 
2016-12-11 14:05:55 Training Error = 0.60361819900095 
2016-12-11 14:05:55 Training Loss = 0.026681273787184 
2016-12-11 14:05:57 Valid Error = 0.60510328068044 
2016-12-11 14:05:57 Valid Loss = 0.027690046432739 
2016-12-11 14:05:59 Test Error = 0.64192139737991 
2016-12-11 14:05:59 Test Loss = 0.029282688580307 
2016-12-11 14:05:59 -------------------LR------------------- 
2016-12-11 14:05:59 0.015625 
2016-12-11 14:05:59 Epoch 25 
2016-12-11 14:07:31 Training Error = 0.60199810989604 
2016-12-11 14:07:31 Training Loss = 0.026752308664758 
2016-12-11 14:07:33 Valid Error = 0.68286755771567 
2016-12-11 14:07:33 Valid Loss = 0.032630146370248 
2016-12-11 14:07:35 Test Error = 0.73580786026201 
2016-12-11 14:07:35 Test Loss = 0.035240952024273 
2016-12-11 14:07:35 -------------------LR------------------- 
2016-12-11 14:07:35 0.015625 
2016-12-11 14:07:35 Epoch 26 
2016-12-11 14:09:06 Training Error = 0.5997029836641 
2016-12-11 14:09:06 Training Loss = 0.026731581526043 
2016-12-11 14:09:08 Valid Error = 0.60510328068044 
2016-12-11 14:09:08 Valid Loss = 0.027471295712944 
2016-12-11 14:09:10 Test Error = 0.64192139737991 
2016-12-11 14:09:10 Test Loss = 0.028794932702008 
2016-12-11 14:09:10 -------------------LR------------------- 
2016-12-11 14:09:10 0.015625 
2016-12-11 14:09:10 Epoch 27 
2016-12-11 14:10:42 Training Error = 0.59889293911165 
2016-12-11 14:10:42 Training Loss = 0.02659716752851 
2016-12-11 14:10:44 Valid Error = 0.69380315917375 
2016-12-11 14:10:44 Valid Loss = 0.031069855707618 
2016-12-11 14:10:46 Test Error = 0.74454148471616 
2016-12-11 14:10:46 Test Loss = 0.033310242091908 
2016-12-11 14:10:46 -------------------LR------------------- 
2016-12-11 14:10:46 0.015625 
2016-12-11 14:10:46 Epoch 28 
2016-12-11 14:12:17 Training Error = 0.60199810989604 
2016-12-11 14:12:17 Training Loss = 0.026890915823116 
2016-12-11 14:12:19 Valid Error = 0.7363304981774 
2016-12-11 14:12:19 Valid Loss = 0.034968384531984 
2016-12-11 14:12:22 Test Error = 0.79039301310044 
2016-12-11 14:12:22 Test Loss = 0.036700556166032 
2016-12-11 14:12:22 -------------------LR------------------- 
2016-12-11 14:12:22 0.015625 
2016-12-11 14:12:22 Epoch 29 
2016-12-11 14:13:51 Training Error = 0.60064803564196 
2016-12-11 14:13:51 Training Loss = 0.026865472380765 
2016-12-11 14:13:53 Valid Error = 0.79951397326853 
2016-12-11 14:13:53 Valid Loss = 0.035808157906835 
2016-12-11 14:13:55 Test Error = 0.84497816593886 
2016-12-11 14:13:55 Test Loss = 0.037272239404566 
2016-12-11 14:13:55 -------------------LR------------------- 
2016-12-11 14:13:55 0.015625 
2016-12-11 14:13:55 Epoch 30 
2016-12-11 14:15:27 Training Error = 0.60145808019441 
2016-12-11 14:15:27 Training Loss = 0.026661182967043 
2016-12-11 14:15:29 Valid Error = 0.69380315917375 
2016-12-11 14:15:29 Valid Loss = 0.031090342760244 
2016-12-11 14:15:32 Test Error = 0.74454148471616 
2016-12-11 14:15:32 Test Loss = 0.033368063393761 
2016-12-11 14:15:32 -------------------LR------------------- 
2016-12-11 14:15:32 0.015625 
2016-12-11 14:15:32 Epoch 31 
2016-12-11 14:17:02 Training Error = 0.60091805049278 
2016-12-11 14:17:02 Training Loss = 0.026860294040712 
2016-12-11 14:17:04 Valid Error = 0.72539489671932 
2016-12-11 14:17:04 Valid Loss = 0.031722983797244 
2016-12-11 14:17:06 Test Error = 0.78165938864629 
2016-12-11 14:17:06 Test Loss = 0.033809616154315 
2016-12-11 14:17:06 -------------------LR------------------- 
2016-12-11 14:17:06 0.015625 
2016-12-11 14:17:06 Epoch 32 
2016-12-11 14:18:37 Training Error = 0.60064803564196 
2016-12-11 14:18:37 Training Loss = 0.026762996504754 
2016-12-11 14:18:39 Valid Error = 0.7363304981774 
2016-12-11 14:18:39 Valid Loss = 0.035664121225452 
2016-12-11 14:18:41 Test Error = 0.79039301310044 
2016-12-11 14:18:41 Test Loss = 0.037596837399053 
2016-12-11 14:18:41 -------------------LR------------------- 
2016-12-11 14:18:41 0.015625 
2016-12-11 14:18:41 Epoch 33 
2016-12-11 14:20:12 Training Error = 0.59983799108951 
2016-12-11 14:20:12 Training Loss = 0.026715898410145 
2016-12-11 14:20:14 Valid Error = 0.7363304981774 
2016-12-11 14:20:14 Valid Loss = 0.033298326192214 
2016-12-11 14:20:16 Test Error = 0.79039301310044 
2016-12-11 14:20:16 Test Loss = 0.035383664570603 
2016-12-11 14:20:16 -------------------LR------------------- 
2016-12-11 14:20:16 0.015625 
2016-12-11 14:20:16 Epoch 34 
2016-12-11 14:21:43 Training Error = 0.60024301336574 
2016-12-11 14:21:43 Training Loss = 0.026783239461149 
2016-12-11 14:21:45 Valid Error = 0.60510328068044 
2016-12-11 14:21:45 Valid Loss = 0.027190620246751 
2016-12-11 14:21:47 Test Error = 0.64192139737991 
2016-12-11 14:21:47 Test Loss = 0.028870921434141 
2016-12-11 14:21:47 -------------------LR------------------- 
2016-12-11 14:21:47 0.015625 
2016-12-11 14:21:47 Epoch 35 
2016-12-11 14:23:19 Training Error = 0.59862292426083 
2016-12-11 14:23:19 Training Loss = 0.026634938754555 
2016-12-11 14:23:21 Valid Error = 0.72539489671932 
2016-12-11 14:23:21 Valid Loss = 0.033264189743009 
2016-12-11 14:23:23 Test Error = 0.78165938864629 
2016-12-11 14:23:23 Test Loss = 0.035485410765106 
2016-12-11 14:23:23 -------------------LR------------------- 
2016-12-11 14:23:23 0.015625 
2016-12-11 14:23:23 Epoch 36 
2016-12-11 14:24:54 Training Error = 0.60145808019441 
2016-12-11 14:24:54 Training Loss = 0.026777821947057 
2016-12-11 14:24:56 Valid Error = 0.68286755771567 
2016-12-11 14:24:56 Valid Loss = 0.031151319920955 
2016-12-11 14:24:58 Test Error = 0.73580786026201 
2016-12-11 14:24:58 Test Loss = 0.033073149092057 
2016-12-11 14:24:58 -------------------LR------------------- 
2016-12-11 14:24:58 0.015625 
2016-12-11 14:24:58 Epoch 37 
2016-12-11 14:26:28 Training Error = 0.601323072769 
2016-12-11 14:26:28 Training Loss = 0.026796761224428 
2016-12-11 14:26:30 Valid Error = 0.68286755771567 
2016-12-11 14:26:30 Valid Loss = 0.03305983768603 
2016-12-11 14:26:32 Test Error = 0.73580786026201 
2016-12-11 14:26:32 Test Loss = 0.035415664467157 
2016-12-11 14:26:32 -------------------LR------------------- 
2016-12-11 14:26:32 0.015625 
2016-12-11 14:26:32 Epoch 38 
2016-12-11 14:28:03 Training Error = 0.59956797623869 
2016-12-11 14:28:03 Training Loss = 0.026687405144756 
2016-12-11 14:28:04 Valid Error = 0.68286755771567 
2016-12-11 14:28:04 Valid Loss = 0.029095511046664 
2016-12-11 14:28:07 Test Error = 0.73580786026201 
2016-12-11 14:28:07 Test Loss = 0.030945750872294 
2016-12-11 14:28:07 -------------------LR------------------- 
2016-12-11 14:28:07 0.015625 
2016-12-11 14:28:07 Epoch 39 
2016-12-11 14:29:33 Training Error = 0.59902794653706 
2016-12-11 14:29:33 Training Loss = 0.026613676831613 
2016-12-11 14:29:35 Valid Error = 0.68286755771567 
2016-12-11 14:29:35 Valid Loss = 0.035249543626776 
2016-12-11 14:29:37 Test Error = 0.73580786026201 
2016-12-11 14:29:37 Test Loss = 0.038098658599106 
2016-12-11 14:29:37 -------------------LR------------------- 
2016-12-11 14:29:37 0.015625 
2016-12-11 14:29:38 Epoch 40 
2016-12-11 14:31:11 Training Error = 0.60010800594033 
2016-12-11 14:31:11 Training Loss = 0.026801390471757 
2016-12-11 14:31:13 Valid Error = 0.7363304981774 
2016-12-11 14:31:13 Valid Loss = 0.035735234900768 
2016-12-11 14:31:15 Test Error = 0.79039301310044 
2016-12-11 14:31:15 Test Loss = 0.037596872937446 
2016-12-11 14:31:15 -------------------LR------------------- 
2016-12-11 14:31:15 0.015625 
2016-12-11 14:31:15 Epoch 41 
2016-12-11 14:32:46 Training Error = 0.59956797623869 
2016-12-11 14:32:46 Training Loss = 0.026563630033719 
2016-12-11 14:32:48 Valid Error = 0.726609963548 
2016-12-11 14:32:48 Valid Loss = 0.034367938159575 
2016-12-11 14:32:50 Test Error = 0.78056768558952 
2016-12-11 14:32:50 Test Loss = 0.036322724856582 
2016-12-11 14:32:50 -------------------LR------------------- 
2016-12-11 14:32:50 0.015625 
2016-12-11 14:32:50 Epoch 42 
2016-12-11 14:34:22 Training Error = 0.60078304306737 
2016-12-11 14:34:22 Training Loss = 0.0267560523709 
2016-12-11 14:34:24 Valid Error = 0.60510328068044 
2016-12-11 14:34:24 Valid Loss = 0.026885848490253 
2016-12-11 14:34:26 Test Error = 0.64192139737991 
2016-12-11 14:34:26 Test Loss = 0.028459376774582 
2016-12-11 14:34:26 -------------------LR------------------- 
2016-12-11 14:34:26 0.015625 
2016-12-11 14:34:26 Epoch 43 
2016-12-11 14:35:58 Training Error = 0.60105305791819 
2016-12-11 14:35:58 Training Loss = 0.026711759534136 
2016-12-11 14:36:00 Valid Error = 0.60510328068044 
2016-12-11 14:36:00 Valid Loss = 0.027261345117079 
2016-12-11 14:36:02 Test Error = 0.64192139737991 
2016-12-11 14:36:02 Test Loss = 0.028664842577542 
2016-12-11 14:36:02 -------------------LR------------------- 
2016-12-11 14:36:02 0.015625 
2016-12-11 14:36:02 Epoch 44 
2016-12-11 14:37:30 Training Error = 0.60024301336574 
2016-12-11 14:37:30 Training Loss = 0.026789158088976 
2016-12-11 14:37:32 Valid Error = 0.68286755771567 
2016-12-11 14:37:32 Valid Loss = 0.030583477246103 
2016-12-11 14:37:34 Test Error = 0.73580786026201 
2016-12-11 14:37:34 Test Loss = 0.032625868713155 
2016-12-11 14:37:34 -------------------LR------------------- 
2016-12-11 14:37:34 0.015625 
2016-12-11 14:37:34 Epoch 45 
2016-12-11 14:39:04 Training Error = 0.60010800594033 
2016-12-11 14:39:04 Training Loss = 0.026774357771673 
2016-12-11 14:39:06 Valid Error = 0.68408262454435 
2016-12-11 14:39:06 Valid Loss = 0.030651479072278 
2016-12-11 14:39:08 Test Error = 0.73471615720524 
2016-12-11 14:39:08 Test Loss = 0.032734142752255 
2016-12-11 14:39:08 -------------------LR------------------- 
2016-12-11 14:39:08 0.015625 
2016-12-11 14:39:08 Epoch 46 
2016-12-11 14:40:39 Training Error = 0.60010800594033 
2016-12-11 14:40:39 Training Loss = 0.026780960882278 
2016-12-11 14:40:41 Valid Error = 0.69380315917375 
2016-12-11 14:40:41 Valid Loss = 0.030289461468842 
2016-12-11 14:40:43 Test Error = 0.74454148471616 
2016-12-11 14:40:43 Test Loss = 0.032414739599415 
2016-12-11 14:40:43 -------------------LR------------------- 
2016-12-11 14:40:43 0.015625 
2016-12-11 14:40:43 Epoch 47 
2016-12-11 14:42:14 Training Error = 0.59821790198461 
2016-12-11 14:42:14 Training Loss = 0.02675678061691 
2016-12-11 14:42:16 Valid Error = 0.71567436208991 
2016-12-11 14:42:16 Valid Loss = 0.034657164220728 
2016-12-11 14:42:18 Test Error = 0.76637554585153 
2016-12-11 14:42:18 Test Loss = 0.036450548676883 
2016-12-11 14:42:18 -------------------LR------------------- 
2016-12-11 14:42:18 0.015625 
2016-12-11 14:42:18 Epoch 48 
2016-12-11 14:43:48 Training Error = 0.59929796138788 
2016-12-11 14:43:48 Training Loss = 0.026774574559031 
2016-12-11 14:43:50 Valid Error = 0.79951397326853 
2016-12-11 14:43:50 Valid Loss = 0.038348115207549 
2016-12-11 14:43:53 Test Error = 0.84497816593886 
2016-12-11 14:43:53 Test Loss = 0.039154077698203 
2016-12-11 14:43:53 -------------------LR------------------- 
2016-12-11 14:43:53 0.015625 
2016-12-11 14:43:53 Epoch 49 
2016-12-11 14:45:22 Training Error = 0.60010800594033 
2016-12-11 14:45:22 Training Loss = 0.026824025913669 
2016-12-11 14:45:24 Valid Error = 0.68286755771567 
2016-12-11 14:45:24 Valid Loss = 0.030965975694294 
2016-12-11 14:45:26 Test Error = 0.73580786026201 
2016-12-11 14:45:26 Test Loss = 0.03330892386156 
2016-12-11 14:45:26 -------------------LR------------------- 
2016-12-11 14:45:26 0.015625 
2016-12-11 14:45:26 Epoch 50 
2016-12-11 14:46:58 Training Error = 0.59875793168624 
2016-12-11 14:46:58 Training Loss = 0.026650056599992 
2016-12-11 14:47:00 Valid Error = 0.68286755771567 
2016-12-11 14:47:00 Valid Loss = 0.030431970638049 
2016-12-11 14:47:02 Test Error = 0.73580786026201 
2016-12-11 14:47:02 Test Loss = 0.03262751123017 
2016-12-11 14:47:02 -------------------LR------------------- 
2016-12-11 14:47:02 0.0078125 
2016-12-11 14:47:02 Epoch 51 
2016-12-11 14:48:31 Training Error = 0.60118806534359 
2016-12-11 14:48:31 Training Loss = 0.026663303652353 
2016-12-11 14:48:33 Valid Error = 0.60510328068044 
2016-12-11 14:48:33 Valid Loss = 0.029328282565751 
2016-12-11 14:48:35 Test Error = 0.64192139737991 
2016-12-11 14:48:35 Test Loss = 0.031241649936227 
2016-12-11 14:48:35 -------------------LR------------------- 
2016-12-11 14:48:35 0.0078125 
2016-12-11 14:48:35 Epoch 52 
2016-12-11 14:50:07 Training Error = 0.59902794653706 
2016-12-11 14:50:07 Training Loss = 0.026566681282905 
2016-12-11 14:50:09 Valid Error = 0.7363304981774 
2016-12-11 14:50:09 Valid Loss = 0.033544402451771 
2016-12-11 14:50:11 Test Error = 0.79039301310044 
2016-12-11 14:50:11 Test Loss = 0.035815506448933 
2016-12-11 14:50:11 -------------------LR------------------- 
2016-12-11 14:50:11 0.0078125 
2016-12-11 14:50:11 Epoch 53 
2016-12-11 14:51:43 Training Error = 0.60010800594033 
2016-12-11 14:51:43 Training Loss = 0.026578809370224 
2016-12-11 14:51:45 Valid Error = 0.67314702308627 
2016-12-11 14:51:45 Valid Loss = 0.033126042315349 
2016-12-11 14:51:47 Test Error = 0.72052401746725 
2016-12-11 14:51:47 Test Loss = 0.035646039289587 
2016-12-11 14:51:47 -------------------LR------------------- 
2016-12-11 14:51:47 0.0078125 
2016-12-11 14:51:47 Epoch 54 
2016-12-11 14:53:17 Training Error = 0.60051302821655 
2016-12-11 14:53:17 Training Loss = 0.026639737682182 
2016-12-11 14:53:19 Valid Error = 0.7363304981774 
2016-12-11 14:53:19 Valid Loss = 0.033581879552458 
2016-12-11 14:53:21 Test Error = 0.79039301310044 
2016-12-11 14:53:21 Test Loss = 0.035650329468297 
2016-12-11 14:53:21 -------------------LR------------------- 
2016-12-11 14:53:21 0.0078125 
2016-12-11 14:53:21 Epoch 55 
2016-12-11 14:54:52 Training Error = 0.59713784258134 
2016-12-11 14:54:52 Training Loss = 0.026887393644388 
2016-12-11 14:54:54 Valid Error = 0.60510328068044 
2016-12-11 14:54:54 Valid Loss = 0.027476013435088 
2016-12-11 14:54:56 Test Error = 0.64192139737991 
2016-12-11 14:54:56 Test Loss = 0.029094132479499 
2016-12-11 14:54:56 -------------------LR------------------- 
2016-12-11 14:54:56 0.0078125 
2016-12-11 14:54:56 Epoch 56 
2016-12-11 14:56:25 Training Error = 0.59956797623869 
2016-12-11 14:56:25 Training Loss = 0.026628606998219 
2016-12-11 14:56:27 Valid Error = 0.60510328068044 
2016-12-11 14:56:27 Valid Loss = 0.028319628116499 
2016-12-11 14:56:29 Test Error = 0.64192139737991 
2016-12-11 14:56:29 Test Loss = 0.030045937332453 
2016-12-11 14:56:29 -------------------LR------------------- 
2016-12-11 14:56:29 0.0078125 
2016-12-11 14:56:29 Epoch 57 
2016-12-11 14:58:01 Training Error = 0.59983799108951 
2016-12-11 14:58:01 Training Loss = 0.026728864978609 
2016-12-11 14:58:03 Valid Error = 0.726609963548 
2016-12-11 14:58:03 Valid Loss = 0.032417889589883 
2016-12-11 14:58:05 Test Error = 0.77510917030568 
2016-12-11 14:58:05 Test Loss = 0.03441283234428 
2016-12-11 14:58:05 -------------------LR------------------- 
2016-12-11 14:58:05 0.0078125 
2016-12-11 14:58:05 Epoch 58 
2016-12-11 14:59:36 Training Error = 0.60091805049278 
2016-12-11 14:59:36 Training Loss = 0.026678373356382 
2016-12-11 14:59:38 Valid Error = 0.60510328068044 
2016-12-11 14:59:38 Valid Loss = 0.027387651655048 
2016-12-11 14:59:41 Test Error = 0.64192139737991 
2016-12-11 14:59:41 Test Loss = 0.028837768227446 
2016-12-11 14:59:41 -------------------LR------------------- 
2016-12-11 14:59:41 0.0078125 
2016-12-11 14:59:41 Epoch 59 
2016-12-11 15:01:10 Training Error = 0.60213311732145 
2016-12-11 15:01:10 Training Loss = 0.026692196823391 
2016-12-11 15:01:12 Valid Error = 0.69380315917375 
2016-12-11 15:01:12 Valid Loss = 0.030149201182374 
2016-12-11 15:01:15 Test Error = 0.74454148471616 
2016-12-11 15:01:15 Test Loss = 0.032470702779059 
2016-12-11 15:01:15 -------------------LR------------------- 
2016-12-11 15:01:15 0.0078125 
2016-12-11 15:01:15 Epoch 60 
2016-12-11 15:02:47 Training Error = 0.59862292426083 
2016-12-11 15:02:47 Training Loss = 0.026772525000194 
2016-12-11 15:02:49 Valid Error = 0.68286755771567 
2016-12-11 15:02:49 Valid Loss = 0.029787140774255 
2016-12-11 15:02:51 Test Error = 0.73580786026201 
2016-12-11 15:02:51 Test Loss = 0.031955142432568 
2016-12-11 15:02:51 -------------------LR------------------- 
2016-12-11 15:02:51 0.0078125 
2016-12-11 15:02:51 Epoch 61 
2016-12-11 15:04:19 Training Error = 0.59713784258134 
2016-12-11 15:04:19 Training Loss = 0.026642854048358 
2016-12-11 15:04:21 Valid Error = 0.69380315917375 
2016-12-11 15:04:21 Valid Loss = 0.03060406413778 
2016-12-11 15:04:23 Test Error = 0.74454148471616 
2016-12-11 15:04:23 Test Loss = 0.032850661006628 
2016-12-11 15:04:23 -------------------LR------------------- 
2016-12-11 15:04:23 0.0078125 
2016-12-11 15:04:23 Epoch 62 
2016-12-11 15:05:53 Training Error = 0.59929796138788 
2016-12-11 15:05:53 Training Loss = 0.026815802168646 
2016-12-11 15:05:55 Valid Error = 0.79951397326853 
2016-12-11 15:05:55 Valid Loss = 0.037991028251189 
2016-12-11 15:05:57 Test Error = 0.84497816593886 
2016-12-11 15:05:57 Test Loss = 0.038813798025543 
2016-12-11 15:05:57 -------------------LR------------------- 
2016-12-11 15:05:57 0.0078125 
2016-12-11 15:05:57 Epoch 63 
2016-12-11 15:07:28 Training Error = 0.59983799108951 
2016-12-11 15:07:28 Training Loss = 0.026584299627851 
2016-12-11 15:07:30 Valid Error = 0.68286755771567 
2016-12-11 15:07:30 Valid Loss = 0.031783100181291 
2016-12-11 15:07:32 Test Error = 0.73580786026201 
2016-12-11 15:07:32 Test Loss = 0.03383024412043 
2016-12-11 15:07:32 -------------------LR------------------- 
2016-12-11 15:07:32 0.0078125 
2016-12-11 15:07:32 Epoch 64 
2016-12-11 15:09:02 Training Error = 0.59929796138788 
2016-12-11 15:09:02 Training Loss = 0.02681845267872 
2016-12-11 15:09:04 Valid Error = 0.68286755771567 
2016-12-11 15:09:04 Valid Loss = 0.031943213125064 
2016-12-11 15:09:06 Test Error = 0.73580786026201 
2016-12-11 15:09:06 Test Loss = 0.034388076193192 
2016-12-11 15:09:06 -------------------LR------------------- 
2016-12-11 15:09:06 0.0078125 
2016-12-11 15:09:06 Epoch 65 
2016-12-11 15:10:36 Training Error = 0.59997299851492 
2016-12-11 15:10:36 Training Loss = 0.026573321641482 
2016-12-11 15:10:38 Valid Error = 0.68286755771567 
2016-12-11 15:10:38 Valid Loss = 0.030352506118143 
2016-12-11 15:10:40 Test Error = 0.73580786026201 
2016-12-11 15:10:40 Test Loss = 0.032479556392221 
2016-12-11 15:10:40 -------------------LR------------------- 
2016-12-11 15:10:40 0.0078125 
2016-12-11 15:10:40 Epoch 66 
2016-12-11 15:12:13 Training Error = 0.59862292426083 
2016-12-11 15:12:13 Training Loss = 0.026600677863512 
2016-12-11 15:12:15 Valid Error = 0.68286755771567 
2016-12-11 15:12:15 Valid Loss = 0.033257062441699 
2016-12-11 15:12:17 Test Error = 0.73580786026201 
2016-12-11 15:12:17 Test Loss = 0.036063279918596 
2016-12-11 15:12:17 -------------------LR------------------- 
2016-12-11 15:12:17 0.0078125 
2016-12-11 15:12:17 Epoch 67 
2016-12-11 15:13:47 Training Error = 0.59983799108951 
2016-12-11 15:13:47 Training Loss = 0.026833626792188 
2016-12-11 15:13:49 Valid Error = 0.60510328068044 
2016-12-11 15:13:49 Valid Loss = 0.027250285414659 
2016-12-11 15:13:51 Test Error = 0.64192139737991 
2016-12-11 15:13:51 Test Loss = 0.028814390640633 
2016-12-11 15:13:51 -------------------LR------------------- 
2016-12-11 15:13:51 0.0078125 
2016-12-11 15:13:51 Epoch 68 
2016-12-11 15:15:21 Training Error = 0.60307816929931 
2016-12-11 15:15:21 Training Loss = 0.026758889522606 
2016-12-11 15:15:23 Valid Error = 0.60510328068044 
2016-12-11 15:15:23 Valid Loss = 0.028395762940841 
2016-12-11 15:15:25 Test Error = 0.64192139737991 
2016-12-11 15:15:25 Test Loss = 0.030106717567818 
2016-12-11 15:15:25 -------------------LR------------------- 
2016-12-11 15:15:25 0.0078125 
2016-12-11 15:15:25 Epoch 69 
2016-12-11 15:16:55 Training Error = 0.59916295396247 
2016-12-11 15:16:55 Training Loss = 0.026873531944923 
2016-12-11 15:16:57 Valid Error = 0.65249088699878 
2016-12-11 15:16:57 Valid Loss = 0.031363438769499 
2016-12-11 15:16:59 Test Error = 0.68777292576419 
2016-12-11 15:16:59 Test Loss = 0.033374237079246 
2016-12-11 15:16:59 -------------------LR------------------- 
2016-12-11 15:16:59 0.0078125 
2016-12-11 15:16:59 Epoch 70 
2016-12-11 15:18:33 Training Error = 0.59997299851492 
2016-12-11 15:18:33 Training Loss = 0.026670391298609 
2016-12-11 15:18:35 Valid Error = 0.71567436208991 
2016-12-11 15:18:35 Valid Loss = 0.032137882123902 
2016-12-11 15:18:38 Test Error = 0.76637554585153 
2016-12-11 15:18:38 Test Loss = 0.034230933423136 
2016-12-11 15:18:38 -------------------LR------------------- 
2016-12-11 15:18:38 0.0078125 
2016-12-11 15:18:38 Epoch 71 
2016-12-11 15:20:10 Training Error = 0.60010800594033 
2016-12-11 15:20:10 Training Loss = 0.026787153558526 
2016-12-11 15:20:12 Valid Error = 0.68286755771567 
2016-12-11 15:20:12 Valid Loss = 0.030630320890209 
2016-12-11 15:20:14 Test Error = 0.73580786026201 
2016-12-11 15:20:14 Test Loss = 0.032612391827153 
2016-12-11 15:20:14 -------------------LR------------------- 
2016-12-11 15:20:14 0.0078125 
2016-12-11 15:20:14 Epoch 72 
2016-12-11 15:21:45 Training Error = 0.60051302821655 
2016-12-11 15:21:45 Training Loss = 0.026734683474016 
2016-12-11 15:21:47 Valid Error = 0.68286755771567 
2016-12-11 15:21:47 Valid Loss = 0.030527628054614 
2016-12-11 15:21:49 Test Error = 0.73580786026201 
2016-12-11 15:21:49 Test Loss = 0.032640064230152 
2016-12-11 15:21:49 -------------------LR------------------- 
2016-12-11 15:21:49 0.0078125 
2016-12-11 15:21:49 Epoch 73 
2016-12-11 15:23:19 Training Error = 0.60024301336574 
2016-12-11 15:23:19 Training Loss = 0.026626548901014 
2016-12-11 15:23:21 Valid Error = 0.60510328068044 
2016-12-11 15:23:21 Valid Loss = 0.027098956197074 
2016-12-11 15:23:23 Test Error = 0.64192139737991 
2016-12-11 15:23:23 Test Loss = 0.028603756521262 
2016-12-11 15:23:23 -------------------LR------------------- 
2016-12-11 15:23:23 0.0078125 
2016-12-11 15:23:23 Epoch 74 
2016-12-11 15:24:53 Training Error = 0.60051302821655 
2016-12-11 15:24:53 Training Loss = 0.026606338026544 
2016-12-11 15:24:55 Valid Error = 0.68286755771567 
2016-12-11 15:24:55 Valid Loss = 0.032332269694415 
2016-12-11 15:24:57 Test Error = 0.73580786026201 
2016-12-11 15:24:57 Test Loss = 0.034928732582167 
2016-12-11 15:24:57 -------------------LR------------------- 
2016-12-11 15:24:57 0.0078125 
2016-12-11 15:24:57 Epoch 75 
2016-12-11 15:26:27 Training Error = 0.59983799108951 
2016-12-11 15:26:27 Training Loss = 0.026649939070273 
2016-12-11 15:26:29 Valid Error = 0.7363304981774 
2016-12-11 15:26:29 Valid Loss = 0.035041175445531 
2016-12-11 15:26:32 Test Error = 0.79039301310044 
2016-12-11 15:26:32 Test Loss = 0.036947979973812 
2016-12-11 15:26:32 -------------------LR------------------- 
2016-12-11 15:26:32 0.0078125 
2016-12-11 15:26:32 Epoch 76 
2016-12-11 15:28:04 Training Error = 0.59875793168624 
2016-12-11 15:28:04 Training Loss = 0.026799922836973 
2016-12-11 15:28:06 Valid Error = 0.7363304981774 
2016-12-11 15:28:06 Valid Loss = 0.033430277896761 
2016-12-11 15:28:08 Test Error = 0.79039301310044 
2016-12-11 15:28:08 Test Loss = 0.035349635414049 
2016-12-11 15:28:08 -------------------LR------------------- 
2016-12-11 15:28:08 0.0078125 
2016-12-11 15:28:08 Epoch 77 
2016-12-11 15:29:40 Training Error = 0.59740785743216 
2016-12-11 15:29:40 Training Loss = 0.026712679111969 
2016-12-11 15:29:42 Valid Error = 0.67314702308627 
2016-12-11 15:29:42 Valid Loss = 0.033957897293598 
2016-12-11 15:29:44 Test Error = 0.72052401746725 
2016-12-11 15:29:44 Test Loss = 0.036584488971561 
2016-12-11 15:29:44 -------------------LR------------------- 
2016-12-11 15:29:44 0.0078125 
2016-12-11 15:29:44 Epoch 78 
2016-12-11 15:31:12 Training Error = 0.59956797623869 
2016-12-11 15:31:12 Training Loss = 0.02671054035404 
2016-12-11 15:31:14 Valid Error = 0.7363304981774 
2016-12-11 15:31:14 Valid Loss = 0.032317621755568 
2016-12-11 15:31:16 Test Error = 0.79039301310044 
2016-12-11 15:31:16 Test Loss = 0.034541519950418 
2016-12-11 15:31:16 -------------------LR------------------- 
2016-12-11 15:31:16 0.0078125 
2016-12-11 15:31:16 Epoch 79 
2016-12-11 15:32:49 Training Error = 0.59794788713379 
2016-12-11 15:32:49 Training Loss = 0.026567475230042 
2016-12-11 15:32:51 Valid Error = 0.68286755771567 
2016-12-11 15:32:51 Valid Loss = 0.030577187841223 
2016-12-11 15:32:53 Test Error = 0.73580786026201 
2016-12-11 15:32:53 Test Loss = 0.032868550842884 
2016-12-11 15:32:53 -------------------LR------------------- 
2016-12-11 15:32:53 0.0078125 
2016-12-11 15:32:53 Epoch 80 
2016-12-11 15:34:27 Training Error = 0.5997029836641 
2016-12-11 15:34:27 Training Loss = 0.026743419888707 
2016-12-11 15:34:29 Valid Error = 0.68286755771567 
2016-12-11 15:34:29 Valid Loss = 0.030568370307792 
2016-12-11 15:34:32 Test Error = 0.73580786026201 
2016-12-11 15:34:32 Test Loss = 0.032886742825602 
2016-12-11 15:34:32 -------------------LR------------------- 
2016-12-11 15:34:32 0.0078125 
2016-12-11 15:34:32 Epoch 81 
2016-12-11 15:36:02 Training Error = 0.59983799108951 
2016-12-11 15:36:02 Training Loss = 0.026553300070028 
2016-12-11 15:36:04 Valid Error = 0.60510328068044 
2016-12-11 15:36:04 Valid Loss = 0.027140131093363 
2016-12-11 15:36:06 Test Error = 0.64192139737991 
2016-12-11 15:36:06 Test Loss = 0.028749241595175 
2016-12-11 15:36:06 -------------------LR------------------- 
2016-12-11 15:36:06 0.0078125 
2016-12-11 15:36:06 Epoch 82 
2016-12-11 15:37:38 Training Error = 0.60051302821655 
2016-12-11 15:37:38 Training Loss = 0.026763268330607 
2016-12-11 15:37:40 Valid Error = 0.7363304981774 
2016-12-11 15:37:40 Valid Loss = 0.036948112927909 
2016-12-11 15:37:42 Test Error = 0.79039301310044 
2016-12-11 15:37:42 Test Loss = 0.039097347278221 
2016-12-11 15:37:42 -------------------LR------------------- 
2016-12-11 15:37:42 0.0078125 
2016-12-11 15:37:42 Epoch 83 
2016-12-11 15:39:14 Training Error = 0.59902794653706 
2016-12-11 15:39:14 Training Loss = 0.026750726825561 
2016-12-11 15:39:16 Valid Error = 0.71567436208991 
2016-12-11 15:39:16 Valid Loss = 0.033421151921008 
2016-12-11 15:39:18 Test Error = 0.76637554585153 
2016-12-11 15:39:18 Test Loss = 0.035375774860382 
2016-12-11 15:39:18 -------------------LR------------------- 
2016-12-11 15:39:18 0.0078125 
2016-12-11 15:39:18 Epoch 84 
2016-12-11 15:40:47 Training Error = 0.59848791683543 
2016-12-11 15:40:47 Training Loss = 0.02665234947169 
2016-12-11 15:40:49 Valid Error = 0.7363304981774 
2016-12-11 15:40:49 Valid Loss = 0.03351795639901 
2016-12-11 15:40:51 Test Error = 0.79039301310044 
2016-12-11 15:40:51 Test Loss = 0.035627161138198 
2016-12-11 15:40:51 -------------------LR------------------- 
2016-12-11 15:40:51 0.0078125 
2016-12-11 15:40:51 Epoch 85 
2016-12-11 15:42:21 Training Error = 0.601323072769 
2016-12-11 15:42:21 Training Loss = 0.026732534156037 
2016-12-11 15:42:23 Valid Error = 0.59538274605103 
2016-12-11 15:42:23 Valid Loss = 0.027507636729793 
2016-12-11 15:42:25 Test Error = 0.62663755458515 
2016-12-11 15:42:25 Test Loss = 0.029005140239117 
2016-12-11 15:42:25 -------------------LR------------------- 
2016-12-11 15:42:25 0.0078125 
2016-12-11 15:42:25 Epoch 86 
2016-12-11 15:43:59 Training Error = 0.59875793168624 
2016-12-11 15:43:59 Training Loss = 0.026585934674773 
2016-12-11 15:44:01 Valid Error = 0.68286755771567 
2016-12-11 15:44:01 Valid Loss = 0.031659706732174 
2016-12-11 15:44:03 Test Error = 0.73580786026201 
2016-12-11 15:44:03 Test Loss = 0.033714321351519 
2016-12-11 15:44:03 -------------------LR------------------- 
2016-12-11 15:44:03 0.0078125 
2016-12-11 15:44:03 Epoch 87 
2016-12-11 15:45:35 Training Error = 0.59835290941002 
2016-12-11 15:45:35 Training Loss = 0.026732569299693 
2016-12-11 15:45:37 Valid Error = 0.79951397326853 
2016-12-11 15:45:37 Valid Loss = 0.038198617955235 
2016-12-11 15:45:39 Test Error = 0.84497816593886 
2016-12-11 15:45:39 Test Loss = 0.039072197147444 
2016-12-11 15:45:39 -------------------LR------------------- 
2016-12-11 15:45:39 0.0078125 
2016-12-11 15:45:39 Epoch 88 
2016-12-11 15:47:09 Training Error = 0.59929796138788 
2016-12-11 15:47:09 Training Loss = 0.026761419552359 
2016-12-11 15:47:11 Valid Error = 0.7363304981774 
2016-12-11 15:47:11 Valid Loss = 0.033727342989156 
2016-12-11 15:47:13 Test Error = 0.79039301310044 
2016-12-11 15:47:13 Test Loss = 0.035612699433869 
2016-12-11 15:47:13 -------------------LR------------------- 
2016-12-11 15:47:13 0.0078125 
2016-12-11 15:47:13 Epoch 89 
2016-12-11 15:48:40 Training Error = 0.60010800594033 
2016-12-11 15:48:40 Training Loss = 0.02664063855482 
2016-12-11 15:48:42 Valid Error = 0.7363304981774 
2016-12-11 15:48:42 Valid Loss = 0.034000747794848 
2016-12-11 15:48:44 Test Error = 0.79039301310044 
2016-12-11 15:48:44 Test Loss = 0.035818829414891 
2016-12-11 15:48:44 -------------------LR------------------- 
2016-12-11 15:48:44 0.0078125 
2016-12-11 15:48:44 Epoch 90 
2016-12-11 15:50:18 Training Error = 0.60118806534359 
2016-12-11 15:50:18 Training Loss = 0.02680786867115 
2016-12-11 15:50:20 Valid Error = 0.79951397326853 
2016-12-11 15:50:20 Valid Loss = 0.038598532388074 
2016-12-11 15:50:22 Test Error = 0.84497816593886 
2016-12-11 15:50:22 Test Loss = 0.039332553078147 
2016-12-11 15:50:22 -------------------LR------------------- 
2016-12-11 15:50:22 0.0078125 
2016-12-11 15:50:22 Epoch 91 
2016-12-11 15:51:54 Training Error = 0.59997299851492 
2016-12-11 15:51:54 Training Loss = 0.026569324723501 
2016-12-11 15:51:55 Valid Error = 0.7363304981774 
2016-12-11 15:51:55 Valid Loss = 0.035322016500733 
2016-12-11 15:51:58 Test Error = 0.79039301310044 
2016-12-11 15:51:58 Test Loss = 0.037486354809181 
2016-12-11 15:51:58 -------------------LR------------------- 
2016-12-11 15:51:58 0.0078125 
2016-12-11 15:51:58 Epoch 92 
2016-12-11 15:53:28 Training Error = 0.60051302821655 
2016-12-11 15:53:28 Training Loss = 0.026776471139603 
2016-12-11 15:53:30 Valid Error = 0.64763061968408 
2016-12-11 15:53:30 Valid Loss = 0.031798754966066 
2016-12-11 15:53:33 Test Error = 0.68777292576419 
2016-12-11 15:53:33 Test Loss = 0.033852623621623 
2016-12-11 15:53:33 -------------------LR------------------- 
2016-12-11 15:53:33 0.0078125 
2016-12-11 15:53:33 Epoch 93 
2016-12-11 15:55:02 Training Error = 0.59902794653706 
2016-12-11 15:55:02 Training Loss = 0.026671501679692 
2016-12-11 15:55:04 Valid Error = 0.60510328068044 
2016-12-11 15:55:04 Valid Loss = 0.027381115265052 
2016-12-11 15:55:07 Test Error = 0.64192139737991 
2016-12-11 15:55:07 Test Loss = 0.028979489027285 
2016-12-11 15:55:07 -------------------LR------------------- 
2016-12-11 15:55:07 0.0078125 
2016-12-11 15:55:07 Epoch 94 
2016-12-11 15:56:39 Training Error = 0.59889293911165 
2016-12-11 15:56:39 Training Loss = 0.026727261287002 
2016-12-11 15:56:41 Valid Error = 0.68286755771567 
2016-12-11 15:56:41 Valid Loss = 0.030391763244669 
2016-12-11 15:56:43 Test Error = 0.73580786026201 
2016-12-11 15:56:43 Test Loss = 0.032377666660384 
2016-12-11 15:56:43 -------------------LR------------------- 
2016-12-11 15:56:43 0.0078125 
2016-12-11 15:56:43 Epoch 95 
2016-12-11 15:58:15 Training Error = 0.60051302821655 
2016-12-11 15:58:15 Training Loss = 0.026531346775771 
2016-12-11 15:58:17 Valid Error = 0.72539489671932 
2016-12-11 15:58:17 Valid Loss = 0.032664722089595 
2016-12-11 15:58:19 Test Error = 0.78165938864629 
2016-12-11 15:58:19 Test Loss = 0.034753633480446 
2016-12-11 15:58:19 -------------------LR------------------- 
2016-12-11 15:58:19 0.0078125 
2016-12-11 15:58:19 Epoch 96 
2016-12-11 15:59:50 Training Error = 0.59835290941002 
2016-12-11 15:59:50 Training Loss = 0.026952062213232 
2016-12-11 15:59:52 Valid Error = 0.79951397326853 
2016-12-11 15:59:52 Valid Loss = 0.036433028661698 
2016-12-11 15:59:54 Test Error = 0.84497816593886 
2016-12-11 15:59:54 Test Loss = 0.037713584881203 
2016-12-11 15:59:54 -------------------LR------------------- 
2016-12-11 15:59:54 0.0078125 
2016-12-11 15:59:54 Epoch 97 
2016-12-11 16:01:25 Training Error = 0.59794788713379 
2016-12-11 16:01:25 Training Loss = 0.026541257278058 
2016-12-11 16:01:27 Valid Error = 0.68286755771567 
2016-12-11 16:01:27 Valid Loss = 0.032392764375598 
2016-12-11 16:01:29 Test Error = 0.73580786026201 
2016-12-11 16:01:29 Test Loss = 0.03468287674586 
2016-12-11 16:01:29 -------------------LR------------------- 
2016-12-11 16:01:29 0.0078125 
2016-12-11 16:01:29 Epoch 98 
2016-12-11 16:03:01 Training Error = 0.60010800594033 
2016-12-11 16:03:01 Training Loss = 0.026742369175046 
2016-12-11 16:03:03 Valid Error = 0.72539489671932 
2016-12-11 16:03:03 Valid Loss = 0.032833620970974 
2016-12-11 16:03:05 Test Error = 0.78165938864629 
2016-12-11 16:03:05 Test Loss = 0.034900673969119 
2016-12-11 16:03:05 -------------------LR------------------- 
2016-12-11 16:03:05 0.0078125 
2016-12-11 16:03:05 Epoch 99 
2016-12-11 16:04:35 Training Error = 0.59983799108951 
2016-12-11 16:04:35 Training Loss = 0.026648968550026 
2016-12-11 16:04:37 Valid Error = 0.68286755771567 
2016-12-11 16:04:37 Valid Loss = 0.030172264429389 
2016-12-11 16:04:39 Test Error = 0.73580786026201 
2016-12-11 16:04:39 Test Loss = 0.032199223911061 
2016-12-11 16:04:39 -------------------LR------------------- 
2016-12-11 16:04:39 0.0078125 
2016-12-11 16:04:39 Epoch 100 
2016-12-11 16:06:11 Training Error = 0.60213311732145 
2016-12-11 16:06:11 Training Loss = 0.026944091318168 
2016-12-11 16:06:13 Valid Error = 0.7363304981774 
2016-12-11 16:06:13 Valid Loss = 0.034856513253642 
2016-12-11 16:06:15 Test Error = 0.79039301310044 
2016-12-11 16:06:15 Test Loss = 0.03662469478682 
2016-12-11 16:06:15 -------------------LR------------------- 
2016-12-11 16:06:15 0.00390625 
2016-12-11 16:06:15 Epoch 101 
2016-12-11 16:07:46 Training Error = 0.59875793168624 
2016-12-11 16:07:46 Training Loss = 0.026736190818694 
2016-12-11 16:07:48 Valid Error = 0.67314702308627 
2016-12-11 16:07:48 Valid Loss = 0.032642433402822 
2016-12-11 16:07:50 Test Error = 0.72598253275109 
2016-12-11 16:07:50 Test Loss = 0.035113858783946 
2016-12-11 16:07:50 -------------------LR------------------- 
2016-12-11 16:07:50 0.00390625 
2016-12-11 16:07:50 Epoch 102 
2016-12-11 16:09:21 Training Error = 0.59875793168624 
2016-12-11 16:09:21 Training Loss = 0.026589142340082 
2016-12-11 16:09:23 Valid Error = 0.68286755771567 
2016-12-11 16:09:23 Valid Loss = 0.033858249205762 
2016-12-11 16:09:25 Test Error = 0.73580786026201 
2016-12-11 16:09:25 Test Loss = 0.036542029053557 
2016-12-11 16:09:25 -------------------LR------------------- 
2016-12-11 16:09:25 0.00390625 
2016-12-11 16:09:25 Epoch 103 
2016-12-11 16:10:55 Training Error = 0.59983799108951 
2016-12-11 16:10:55 Training Loss = 0.026474903899548 
2016-12-11 16:10:57 Valid Error = 0.69380315917375 
2016-12-11 16:10:57 Valid Loss = 0.030689695083114 
2016-12-11 16:10:59 Test Error = 0.74454148471616 
2016-12-11 16:10:59 Test Loss = 0.03283270333795 
2016-12-11 16:10:59 -------------------LR------------------- 
2016-12-11 16:10:59 0.00390625 
2016-12-11 16:10:59 Epoch 104 
2016-12-11 16:12:34 Training Error = 0.60051302821655 
2016-12-11 16:12:34 Training Loss = 0.02706712225906 
2016-12-11 16:12:36 Valid Error = 0.7363304981774 
2016-12-11 16:12:36 Valid Loss = 0.033217734390783 
2016-12-11 16:12:38 Test Error = 0.79039301310044 
2016-12-11 16:12:38 Test Loss = 0.035275411306643 
2016-12-11 16:12:38 -------------------LR------------------- 
2016-12-11 16:12:38 0.00390625 
2016-12-11 16:12:38 Epoch 105 
2016-12-11 16:14:09 Training Error = 0.60037802079114 
2016-12-11 16:14:09 Training Loss = 0.026653950511886 
2016-12-11 16:14:11 Valid Error = 0.69380315917375 
2016-12-11 16:14:11 Valid Loss = 0.030371148883704 
2016-12-11 16:14:14 Test Error = 0.74454148471616 
2016-12-11 16:14:14 Test Loss = 0.032536317170835 
2016-12-11 16:14:14 -------------------LR------------------- 
2016-12-11 16:14:14 0.00390625 
2016-12-11 16:14:14 Epoch 106 
2016-12-11 16:15:42 Training Error = 0.60024301336574 
2016-12-11 16:15:42 Training Loss = 0.026818827060447 
2016-12-11 16:15:44 Valid Error = 0.7363304981774 
2016-12-11 16:15:44 Valid Loss = 0.036037665834433 
2016-12-11 16:15:47 Test Error = 0.79039301310044 
2016-12-11 16:15:47 Test Loss = 0.038097849845886 
2016-12-11 16:15:47 -------------------LR------------------- 
2016-12-11 16:15:47 0.00390625 
2016-12-11 16:15:47 Epoch 107 
2016-12-11 16:17:17 Training Error = 0.60024301336574 
2016-12-11 16:17:17 Training Loss = 0.02674921810745 
2016-12-11 16:17:19 Valid Error = 0.7363304981774 
2016-12-11 16:17:19 Valid Loss = 0.035769655430555 
2016-12-11 16:17:21 Test Error = 0.79039301310044 
2016-12-11 16:17:21 Test Loss = 0.037592627375734 
2016-12-11 16:17:21 -------------------LR------------------- 
2016-12-11 16:17:21 0.00390625 
2016-12-11 16:17:21 Epoch 108 
2016-12-11 16:18:51 Training Error = 0.59889293911165 
2016-12-11 16:18:51 Training Loss = 0.026672443957645 
2016-12-11 16:18:53 Valid Error = 0.68286755771567 
2016-12-11 16:18:53 Valid Loss = 0.032004611741709 
2016-12-11 16:18:55 Test Error = 0.73580786026201 
2016-12-11 16:18:55 Test Loss = 0.034413295942194 
2016-12-11 16:18:55 -------------------LR------------------- 
2016-12-11 16:18:55 0.00390625 
2016-12-11 16:18:55 Epoch 109 
2016-12-11 16:20:25 Training Error = 0.59983799108951 
2016-12-11 16:20:25 Training Loss = 0.026575936020567 
2016-12-11 16:20:27 Valid Error = 0.67314702308627 
2016-12-11 16:20:27 Valid Loss = 0.030560040045295 
2016-12-11 16:20:29 Test Error = 0.72598253275109 
2016-12-11 16:20:29 Test Loss = 0.032733116682838 
2016-12-11 16:20:29 -------------------LR------------------- 
2016-12-11 16:20:29 0.00390625 
2016-12-11 16:20:29 Epoch 110 
2016-12-11 16:22:03 Training Error = 0.59929796138788 
2016-12-11 16:22:03 Training Loss = 0.026716873214536 
2016-12-11 16:22:06 Valid Error = 0.59538274605103 
2016-12-11 16:22:06 Valid Loss = 0.027436149642697 
2016-12-11 16:22:08 Test Error = 0.62663755458515 
2016-12-11 16:22:08 Test Loss = 0.029062879945718 
2016-12-11 16:22:08 -------------------LR------------------- 
2016-12-11 16:22:08 0.00390625 
2016-12-11 16:22:08 Epoch 111 
2016-12-11 16:23:37 Training Error = 0.60064803564196 
2016-12-11 16:23:37 Training Loss = 0.026705764942899 
2016-12-11 16:23:39 Valid Error = 0.79951397326853 
2016-12-11 16:23:39 Valid Loss = 0.035216180848908 
2016-12-11 16:23:41 Test Error = 0.84497816593886 
2016-12-11 16:23:41 Test Loss = 0.036855333412395 
2016-12-11 16:23:41 -------------------LR------------------- 
2016-12-11 16:23:41 0.00390625 
2016-12-11 16:23:41 Epoch 112 
2016-12-11 16:25:13 Training Error = 0.59902794653706 
2016-12-11 16:25:13 Training Loss = 0.026628908689127 
2016-12-11 16:25:15 Valid Error = 0.68286755771567 
2016-12-11 16:25:15 Valid Loss = 0.031477547728949 
2016-12-11 16:25:17 Test Error = 0.73580786026201 
2016-12-11 16:25:17 Test Loss = 0.033568741415061 
2016-12-11 16:25:17 -------------------LR------------------- 
2016-12-11 16:25:17 0.00390625 
2016-12-11 16:25:17 Epoch 113 
2016-12-11 16:26:45 Training Error = 0.5980828945592 
2016-12-11 16:26:45 Training Loss = 0.026697097513322 
2016-12-11 16:26:47 Valid Error = 0.67314702308627 
2016-12-11 16:26:47 Valid Loss = 0.0346073938001 
2016-12-11 16:26:49 Test Error = 0.72052401746725 
2016-12-11 16:26:49 Test Loss = 0.037237117570989 
2016-12-11 16:26:49 -------------------LR------------------- 
2016-12-11 16:26:49 0.00390625 
2016-12-11 16:26:49 Epoch 114 
2016-12-11 16:28:22 Training Error = 0.60280815444849 
2016-12-11 16:28:22 Training Loss = 0.026816910416917 
2016-12-11 16:28:24 Valid Error = 0.60510328068044 
2016-12-11 16:28:24 Valid Loss = 0.027319667122745 
2016-12-11 16:28:26 Test Error = 0.64192139737991 
2016-12-11 16:28:26 Test Loss = 0.028877810814801 
2016-12-11 16:28:26 -------------------LR------------------- 
2016-12-11 16:28:26 0.00390625 
2016-12-11 16:28:26 Epoch 115 
2016-12-11 16:29:57 Training Error = 0.60037802079114 
2016-12-11 16:29:57 Training Loss = 0.026704565892723 
2016-12-11 16:29:59 Valid Error = 0.79951397326853 
2016-12-11 16:29:59 Valid Loss = 0.038043948237932 
2016-12-11 16:30:02 Test Error = 0.84497816593886 
2016-12-11 16:30:02 Test Loss = 0.038975502332052 
2016-12-11 16:30:02 -------------------LR------------------- 
2016-12-11 16:30:02 0.00390625 
2016-12-11 16:30:02 Epoch 116 
2016-12-11 16:31:31 Training Error = 0.60024301336574 
2016-12-11 16:31:31 Training Loss = 0.026807381545351 
2016-12-11 16:31:33 Valid Error = 0.68286755771567 
2016-12-11 16:31:33 Valid Loss = 0.032016977185698 
2016-12-11 16:31:35 Test Error = 0.73580786026201 
2016-12-11 16:31:35 Test Loss = 0.034329493522644 
2016-12-11 16:31:35 -------------------LR------------------- 
2016-12-11 16:31:35 0.00390625 
2016-12-11 16:31:35 Epoch 117 
2016-12-11 16:33:06 Training Error = 0.60064803564196 
2016-12-11 16:33:06 Training Loss = 0.026754840649232 
2016-12-11 16:33:08 Valid Error = 0.67314702308627 
2016-12-11 16:33:08 Valid Loss = 0.03113928262693 
2016-12-11 16:33:10 Test Error = 0.72598253275109 
2016-12-11 16:33:10 Test Loss = 0.033305801905838 
2016-12-11 16:33:10 -------------------LR------------------- 
2016-12-11 16:33:10 0.00390625 
2016-12-11 16:33:10 Epoch 118 
2016-12-11 16:34:39 Training Error = 0.60118806534359 
2016-12-11 16:34:39 Training Loss = 0.026551248355584 
2016-12-11 16:34:41 Valid Error = 0.67314702308627 
2016-12-11 16:34:41 Valid Loss = 0.030260707157471 
2016-12-11 16:34:44 Test Error = 0.72598253275109 
2016-12-11 16:34:44 Test Loss = 0.032507950773426 
2016-12-11 16:34:44 -------------------LR------------------- 
2016-12-11 16:34:44 0.00390625 
2016-12-11 16:34:44 Epoch 119 
2016-12-11 16:36:15 Training Error = 0.60253813959768 
2016-12-11 16:36:15 Training Loss = 0.027013092773324 
2016-12-11 16:36:17 Valid Error = 0.79951397326853 
2016-12-11 16:36:17 Valid Loss = 0.037238820205982 
2016-12-11 16:36:19 Test Error = 0.84497816593886 
2016-12-11 16:36:19 Test Loss = 0.038347221524108 
2016-12-11 16:36:19 -------------------LR------------------- 
2016-12-11 16:36:19 0.00390625 
2016-12-11 16:36:19 Epoch 120 
2016-12-11 16:37:54 Training Error = 0.59916295396247 
2016-12-11 16:37:54 Training Loss = 0.026675087953883 
2016-12-11 16:37:56 Valid Error = 0.79951397326853 
2016-12-11 16:37:56 Valid Loss = 0.038060088414659 
2016-12-11 16:37:58 Test Error = 0.84497816593886 
2016-12-11 16:37:58 Test Loss = 0.038962394761104 
2016-12-11 16:37:58 -------------------LR------------------- 
2016-12-11 16:37:58 0.00390625 
2016-12-11 16:37:58 Epoch 121 
2016-12-11 16:39:29 Training Error = 0.60118806534359 
2016-12-11 16:39:29 Training Loss = 0.026852949723387 
2016-12-11 16:39:31 Valid Error = 0.68286755771567 
2016-12-11 16:39:31 Valid Loss = 0.030488654054723 
2016-12-11 16:39:34 Test Error = 0.73580786026201 
2016-12-11 16:39:34 Test Loss = 0.032614826436136 
2016-12-11 16:39:34 -------------------LR------------------- 
2016-12-11 16:39:34 0.00390625 
2016-12-11 16:39:34 Epoch 122 
2016-12-11 16:41:03 Training Error = 0.59929796138788 
2016-12-11 16:41:03 Training Loss = 0.026910355699897 
2016-12-11 16:41:05 Valid Error = 0.68286755771567 
2016-12-11 16:41:05 Valid Loss = 0.031107916586709 
2016-12-11 16:41:08 Test Error = 0.73580786026201 
2016-12-11 16:41:08 Test Loss = 0.033431118712706 
2016-12-11 16:41:08 -------------------LR------------------- 
2016-12-11 16:41:08 0.00390625 
2016-12-11 16:41:08 Epoch 123 
2016-12-11 16:42:36 Training Error = 0.59956797623869 
2016-12-11 16:42:36 Training Loss = 0.026584691178921 
2016-12-11 16:42:38 Valid Error = 0.72539489671932 
2016-12-11 16:42:38 Valid Loss = 0.032005653580086 
2016-12-11 16:42:41 Test Error = 0.78165938864629 
2016-12-11 16:42:41 Test Loss = 0.034039564777823 
2016-12-11 16:42:41 -------------------LR------------------- 
2016-12-11 16:42:41 0.00390625 
2016-12-11 16:42:41 Epoch 124 
2016-12-11 16:44:12 Training Error = 0.59929796138788 
2016-12-11 16:44:12 Training Loss = 0.026683713100515 
2016-12-11 16:44:14 Valid Error = 0.68286755771567 
2016-12-11 16:44:14 Valid Loss = 0.034753909901009 
2016-12-11 16:44:16 Test Error = 0.73580786026201 
2016-12-11 16:44:16 Test Loss = 0.037377060927597 
2016-12-11 16:44:16 -------------------LR------------------- 
2016-12-11 16:44:16 0.00390625 
2016-12-11 16:44:16 Epoch 125 
2016-12-11 16:45:47 Training Error = 0.60226812474686 
2016-12-11 16:45:47 Training Loss = 0.026509486705449 
2016-12-11 16:45:49 Valid Error = 0.726609963548 
2016-12-11 16:45:49 Valid Loss = 0.031537264980827 
2016-12-11 16:45:51 Test Error = 0.78056768558952 
2016-12-11 16:45:51 Test Loss = 0.033573014549181 
2016-12-11 16:45:51 -------------------LR------------------- 
2016-12-11 16:45:51 0.00390625 
2016-12-11 16:45:51 Epoch 126 
2016-12-11 16:47:23 Training Error = 0.59781287970838 
2016-12-11 16:47:23 Training Loss = 0.026789750836655 
2016-12-11 16:47:25 Valid Error = 0.7363304981774 
2016-12-11 16:47:25 Valid Loss = 0.032905614689759 
2016-12-11 16:47:27 Test Error = 0.79039301310044 
2016-12-11 16:47:27 Test Loss = 0.034928786642411 
2016-12-11 16:47:27 -------------------LR------------------- 
2016-12-11 16:47:27 0.00390625 
2016-12-11 16:47:27 Epoch 127 
2016-12-11 16:48:56 Training Error = 0.59956797623869 
2016-12-11 16:48:56 Training Loss = 0.026656398732589 
2016-12-11 16:48:58 Valid Error = 0.68286755771567 
2016-12-11 16:48:58 Valid Loss = 0.034145547444592 
2016-12-11 16:49:00 Test Error = 0.73580786026201 
2016-12-11 16:49:00 Test Loss = 0.036704982028288 
2016-12-11 16:49:00 -------------------LR------------------- 
2016-12-11 16:49:00 0.00390625 
2016-12-11 16:49:00 Epoch 128 
2016-12-11 16:50:29 Training Error = 0.59862292426083 
2016-12-11 16:50:29 Training Loss = 0.02681798287186 
2016-12-11 16:50:31 Valid Error = 0.60510328068044 
2016-12-11 16:50:31 Valid Loss = 0.028133626426385 
2016-12-11 16:50:33 Test Error = 0.64192139737991 
2016-12-11 16:50:33 Test Loss = 0.029721102050706 
2016-12-11 16:50:33 -------------------LR------------------- 
2016-12-11 16:50:33 0.00390625 
2016-12-11 16:50:33 Epoch 129 
2016-12-11 16:52:04 Training Error = 0.59902794653706 
2016-12-11 16:52:04 Training Loss = 0.026707192326393 
2016-12-11 16:52:06 Valid Error = 0.68286755771567 
2016-12-11 16:52:06 Valid Loss = 0.030489461670616 
2016-12-11 16:52:08 Test Error = 0.73580786026201 
2016-12-11 16:52:08 Test Loss = 0.032396041617674 
2016-12-11 16:52:08 -------------------LR------------------- 
2016-12-11 16:52:08 0.00390625 
2016-12-11 16:52:08 Epoch 130 
2016-12-11 16:53:41 Training Error = 0.60064803564196 
2016-12-11 16:53:41 Training Loss = 0.026746938333235 
2016-12-11 16:53:43 Valid Error = 0.68286755771567 
2016-12-11 16:53:43 Valid Loss = 0.030660038137115 
2016-12-11 16:53:45 Test Error = 0.73580786026201 
2016-12-11 16:53:45 Test Loss = 0.032791440543006 
2016-12-11 16:53:45 -------------------LR------------------- 
2016-12-11 16:53:45 0.00390625 
2016-12-11 16:53:45 Epoch 131 
2016-12-11 16:55:16 Training Error = 0.59781287970838 
2016-12-11 16:55:16 Training Loss = 0.026781244516239 
2016-12-11 16:55:18 Valid Error = 0.60510328068044 
2016-12-11 16:55:18 Valid Loss = 0.027713057371752 
2016-12-11 16:55:20 Test Error = 0.64192139737991 
2016-12-11 16:55:20 Test Loss = 0.02916472714555 
2016-12-11 16:55:20 -------------------LR------------------- 
2016-12-11 16:55:20 0.00390625 
2016-12-11 16:55:20 Epoch 132 
2016-12-11 16:56:51 Training Error = 0.59956797623869 
2016-12-11 16:56:51 Training Loss = 0.026576837294977 
2016-12-11 16:56:53 Valid Error = 0.67314702308627 
2016-12-11 16:56:53 Valid Loss = 0.033276678202583 
2016-12-11 16:56:56 Test Error = 0.72598253275109 
2016-12-11 16:56:56 Test Loss = 0.035802306268729 
2016-12-11 16:56:56 -------------------LR------------------- 
2016-12-11 16:56:56 0.00390625 
2016-12-11 16:56:56 Epoch 133 
2016-12-11 16:58:21 Training Error = 0.59997299851492 
2016-12-11 16:58:21 Training Loss = 0.026749713761644 
2016-12-11 16:58:23 Valid Error = 0.68286755771567 
2016-12-11 16:58:23 Valid Loss = 0.033025325013797 
2016-12-11 16:58:26 Test Error = 0.73580786026201 
2016-12-11 16:58:26 Test Loss = 0.035587321141187 
2016-12-11 16:58:26 -------------------LR------------------- 
2016-12-11 16:58:26 0.00390625 
2016-12-11 16:58:26 Epoch 134 
2016-12-11 16:59:57 Training Error = 0.5997029836641 
2016-12-11 16:59:57 Training Loss = 0.026665358306001 
2016-12-11 16:59:59 Valid Error = 0.60510328068044 
2016-12-11 16:59:59 Valid Loss = 0.027152113759564 
2016-12-11 17:00:02 Test Error = 0.64192139737991 
2016-12-11 17:00:02 Test Loss = 0.028546201462839 
2016-12-11 17:00:02 -------------------LR------------------- 
2016-12-11 17:00:02 0.00390625 
2016-12-11 17:00:02 Epoch 135 
2016-12-11 17:01:32 Training Error = 0.60037802079114 
2016-12-11 17:01:32 Training Loss = 0.026956167953021 
2016-12-11 17:01:34 Valid Error = 0.79951397326853 
2016-12-11 17:01:34 Valid Loss = 0.038310266183815 
2016-12-11 17:01:36 Test Error = 0.84497816593886 
2016-12-11 17:01:36 Test Loss = 0.039129330373278 
2016-12-11 17:01:36 -------------------LR------------------- 
2016-12-11 17:01:36 0.00390625 
2016-12-11 17:01:36 Epoch 136 
2016-12-11 17:03:08 Training Error = 0.59943296881328 
2016-12-11 17:03:08 Training Loss = 0.026518864901104 
2016-12-11 17:03:09 Valid Error = 0.66342648845687 
2016-12-11 17:03:09 Valid Loss = 0.0311485350438 
2016-12-11 17:03:12 Test Error = 0.71069868995633 
2016-12-11 17:03:12 Test Loss = 0.033179989094828 
2016-12-11 17:03:12 -------------------LR------------------- 
2016-12-11 17:03:12 0.00390625 
2016-12-11 17:03:12 Epoch 137 
2016-12-11 17:04:41 Training Error = 0.60037802079114 
2016-12-11 17:04:41 Training Loss = 0.02670960839821 
2016-12-11 17:04:43 Valid Error = 0.69380315917375 
2016-12-11 17:04:43 Valid Loss = 0.030394934520268 
2016-12-11 17:04:45 Test Error = 0.74454148471616 
2016-12-11 17:04:45 Test Loss = 0.032627697458454 
2016-12-11 17:04:45 -------------------LR------------------- 
2016-12-11 17:04:45 0.00390625 
2016-12-11 17:04:45 Epoch 138 
2016-12-11 17:06:12 Training Error = 0.59997299851492 
2016-12-11 17:06:12 Training Loss = 0.026783760689131 
2016-12-11 17:06:14 Valid Error = 0.67314702308627 
2016-12-11 17:06:14 Valid Loss = 0.030791664553533 
2016-12-11 17:06:17 Test Error = 0.72598253275109 
2016-12-11 17:06:17 Test Loss = 0.032846058331284 
2016-12-11 17:06:17 -------------------LR------------------- 
2016-12-11 17:06:17 0.00390625 
2016-12-11 17:06:17 Epoch 139 
2016-12-11 17:07:49 Training Error = 0.59862292426083 
2016-12-11 17:07:49 Training Loss = 0.026742151314872 
2016-12-11 17:07:51 Valid Error = 0.67314702308627 
2016-12-11 17:07:51 Valid Loss = 0.03075968655016 
2016-12-11 17:07:54 Test Error = 0.72052401746725 
2016-12-11 17:07:54 Test Loss = 0.032761510961196 
2016-12-11 17:07:54 -------------------LR------------------- 
2016-12-11 17:07:54 0.00390625 
2016-12-11 17:07:54 Epoch 140 
2016-12-11 17:09:26 Training Error = 0.59983799108951 
2016-12-11 17:09:26 Training Loss = 0.026606439161969 
2016-12-11 17:09:28 Valid Error = 0.60510328068044 
2016-12-11 17:09:28 Valid Loss = 0.027241000137264 
2016-12-11 17:09:30 Test Error = 0.64192139737991 
2016-12-11 17:09:30 Test Loss = 0.028645702221814 
2016-12-11 17:09:30 -------------------LR------------------- 
2016-12-11 17:09:30 0.00390625 
2016-12-11 17:09:30 Epoch 141 
2016-12-11 17:11:02 Training Error = 0.59929796138788 
2016-12-11 17:11:02 Training Loss = 0.02682081915306 
2016-12-11 17:11:04 Valid Error = 0.60510328068044 
2016-12-11 17:11:04 Valid Loss = 0.028018181394241 
2016-12-11 17:11:06 Test Error = 0.64192139737991 
2016-12-11 17:11:06 Test Loss = 0.029596177970662 
2016-12-11 17:11:06 -------------------LR------------------- 
2016-12-11 17:11:06 0.00390625 
2016-12-11 17:11:06 Epoch 142 
2016-12-11 17:12:37 Training Error = 0.5997029836641 
2016-12-11 17:12:37 Training Loss = 0.026656253335278 
2016-12-11 17:12:39 Valid Error = 0.79951397326853 
2016-12-11 17:12:39 Valid Loss = 0.034848242460964 
2016-12-11 17:12:41 Test Error = 0.84497816593886 
2016-12-11 17:12:41 Test Loss = 0.036231054137735 
2016-12-11 17:12:41 -------------------LR------------------- 
2016-12-11 17:12:41 0.00390625 
2016-12-11 17:12:41 Epoch 143 
2016-12-11 17:14:10 Training Error = 0.59916295396247 
2016-12-11 17:14:10 Training Loss = 0.026681482825471 
2016-12-11 17:14:12 Valid Error = 0.7363304981774 
2016-12-11 17:14:12 Valid Loss = 0.032542114994952 
2016-12-11 17:14:14 Test Error = 0.79039301310044 
2016-12-11 17:14:14 Test Loss = 0.034298487289279 
2016-12-11 17:14:14 -------------------LR------------------- 
2016-12-11 17:14:14 0.00390625 
2016-12-11 17:14:14 Epoch 144 
2016-12-11 17:15:42 Training Error = 0.59889293911165 
2016-12-11 17:15:42 Training Loss = 0.026772720157399 
2016-12-11 17:15:44 Valid Error = 0.7363304981774 
2016-12-11 17:15:44 Valid Loss = 0.036297059293564 
2016-12-11 17:15:46 Test Error = 0.79039301310044 
2016-12-11 17:15:46 Test Loss = 0.038172560308494 
2016-12-11 17:15:46 -------------------LR------------------- 
2016-12-11 17:15:46 0.00390625 
2016-12-11 17:15:46 Epoch 145 
2016-12-11 17:17:17 Training Error = 0.59956797623869 
2016-12-11 17:17:17 Training Loss = 0.026534420769244 
2016-12-11 17:17:19 Valid Error = 0.68286755771567 
2016-12-11 17:17:19 Valid Loss = 0.030057759835569 
2016-12-11 17:17:21 Test Error = 0.73580786026201 
2016-12-11 17:17:21 Test Loss = 0.032371755712173 
2016-12-11 17:17:21 -------------------LR------------------- 
2016-12-11 17:17:21 0.00390625 
2016-12-11 17:17:21 Epoch 146 
2016-12-11 17:18:52 Training Error = 0.59835290941002 
2016-12-11 17:18:52 Training Loss = 0.026586847619093 
2016-12-11 17:18:54 Valid Error = 0.68286755771567 
2016-12-11 17:18:54 Valid Loss = 0.030428642966005 
2016-12-11 17:18:57 Test Error = 0.73580786026201 
2016-12-11 17:18:57 Test Loss = 0.032404240972856 
2016-12-11 17:18:57 -------------------LR------------------- 
2016-12-11 17:18:57 0.00390625 
2016-12-11 17:18:57 Epoch 147 
2016-12-11 17:20:26 Training Error = 0.59916295396247 
2016-12-11 17:20:26 Training Loss = 0.026629431044065 
2016-12-11 17:20:28 Valid Error = 0.67314702308627 
2016-12-11 17:20:28 Valid Loss = 0.033443607808379 
2016-12-11 17:20:31 Test Error = 0.72598253275109 
2016-12-11 17:20:31 Test Loss = 0.036087501338884 
2016-12-11 17:20:31 -------------------LR------------------- 
2016-12-11 17:20:31 0.00390625 
2016-12-11 17:20:31 Epoch 148 
2016-12-11 17:22:00 Training Error = 0.60010800594033 
2016-12-11 17:22:00 Training Loss = 0.026779634454693 
2016-12-11 17:22:02 Valid Error = 0.7363304981774 
2016-12-11 17:22:02 Valid Loss = 0.034626025754281 
2016-12-11 17:22:04 Test Error = 0.79039301310044 
2016-12-11 17:22:04 Test Loss = 0.036291843161863 
2016-12-11 17:22:04 -------------------LR------------------- 
2016-12-11 17:22:04 0.00390625 
2016-12-11 17:22:04 Epoch 149 
2016-12-11 17:23:34 Training Error = 0.601323072769 
2016-12-11 17:23:34 Training Loss = 0.026576469539639 
2016-12-11 17:23:36 Valid Error = 0.7363304981774 
2016-12-11 17:23:36 Valid Loss = 0.03377092442933 
2016-12-11 17:23:38 Test Error = 0.79039301310044 
2016-12-11 17:23:38 Test Loss = 0.035836369308771 
2016-12-11 17:23:38 -------------------LR------------------- 
2016-12-11 17:23:38 0.00390625 
2016-12-11 17:23:38 Epoch 150 
2016-12-11 17:25:09 Training Error = 0.60024301336574 
2016-12-11 17:25:09 Training Loss = 0.026803024165192 
2016-12-11 17:25:11 Valid Error = 0.60510328068044 
2016-12-11 17:25:11 Valid Loss = 0.027708725506037 
2016-12-11 17:25:13 Test Error = 0.64192139737991 
2016-12-11 17:25:13 Test Loss = 0.029155671044892 
2016-12-11 17:25:13 -------------------LR------------------- 
2016-12-11 17:25:13 0.001953125 
2016-12-11 17:25:13 Epoch 151 
2016-12-11 17:26:46 Training Error = 0.60037802079114 
2016-12-11 17:26:46 Training Loss = 0.026755174718406 
2016-12-11 17:26:48 Valid Error = 0.7363304981774 
2016-12-11 17:26:48 Valid Loss = 0.033345974554243 
2016-12-11 17:26:50 Test Error = 0.79039301310044 
2016-12-11 17:26:50 Test Loss = 0.035283941960802 
2016-12-11 17:26:50 -------------------LR------------------- 
2016-12-11 17:26:50 0.001953125 
2016-12-11 17:26:50 Epoch 152 
2016-12-11 17:28:21 Training Error = 0.59956797623869 
2016-12-11 17:28:21 Training Loss = 0.026632683516929 
2016-12-11 17:28:23 Valid Error = 0.78979343863913 
2016-12-11 17:28:23 Valid Loss = 0.038038806255832 
2016-12-11 17:28:26 Test Error = 0.8296943231441 
2016-12-11 17:28:26 Test Loss = 0.038987868458617 
2016-12-11 17:28:26 -------------------LR------------------- 
2016-12-11 17:28:26 0.001953125 
2016-12-11 17:28:26 Epoch 153 
2016-12-11 17:29:55 Training Error = 0.60172809504523 
2016-12-11 17:29:55 Training Loss = 0.026750294491779 
2016-12-11 17:29:57 Valid Error = 0.78979343863913 
2016-12-11 17:29:57 Valid Loss = 0.036463294701785 
2016-12-11 17:29:59 Test Error = 0.8296943231441 
2016-12-11 17:29:59 Test Loss = 0.037795464422189 
2016-12-11 17:29:59 -------------------LR------------------- 
2016-12-11 17:29:59 0.001953125 
2016-12-11 17:29:59 Epoch 154 
2016-12-11 17:31:29 Training Error = 0.60024301336574 
2016-12-11 17:31:29 Training Loss = 0.026846254145376 
2016-12-11 17:31:31 Valid Error = 0.726609963548 
2016-12-11 17:31:31 Valid Loss = 0.033761146070606 
2016-12-11 17:31:34 Test Error = 0.77510917030568 
2016-12-11 17:31:34 Test Loss = 0.035671490454206 
2016-12-11 17:31:34 -------------------LR------------------- 
2016-12-11 17:31:34 0.001953125 
2016-12-11 17:31:34 Epoch 155 
2016-12-11 17:33:03 Training Error = 0.59956797623869 
2016-12-11 17:33:03 Training Loss = 0.026776896207295 
2016-12-11 17:33:05 Valid Error = 0.69380315917375 
2016-12-11 17:33:05 Valid Loss = 0.031155410864887 
2016-12-11 17:33:08 Test Error = 0.74454148471616 
2016-12-11 17:33:08 Test Loss = 0.033598971226636 
2016-12-11 17:33:08 -------------------LR------------------- 
2016-12-11 17:33:08 0.001953125 
2016-12-11 17:33:08 Epoch 156 
2016-12-11 17:34:38 Training Error = 0.59862292426083 
2016-12-11 17:34:38 Training Loss = 0.026777895231986 
2016-12-11 17:34:40 Valid Error = 0.79951397326853 
2016-12-11 17:34:40 Valid Loss = 0.037889974496012 
2016-12-11 17:34:42 Test Error = 0.84497816593886 
2016-12-11 17:34:42 Test Loss = 0.038855302913516 
2016-12-11 17:34:42 -------------------LR------------------- 
2016-12-11 17:34:42 0.001953125 
2016-12-11 17:34:42 Epoch 157 
2016-12-11 17:36:13 Training Error = 0.59929796138788 
2016-12-11 17:36:13 Training Loss = 0.026762816020777 
2016-12-11 17:36:15 Valid Error = 0.68286755771567 
2016-12-11 17:36:15 Valid Loss = 0.032955781503576 
2016-12-11 17:36:17 Test Error = 0.73580786026201 
2016-12-11 17:36:17 Test Loss = 0.035515673889833 
2016-12-11 17:36:17 -------------------LR------------------- 
2016-12-11 17:36:17 0.001953125 
2016-12-11 17:36:17 Epoch 158 
2016-12-11 17:37:48 Training Error = 0.60024301336574 
2016-12-11 17:37:48 Training Loss = 0.026762224841719 
2016-12-11 17:37:50 Valid Error = 0.7363304981774 
2016-12-11 17:37:50 Valid Loss = 0.035183074104184 
2016-12-11 17:37:52 Test Error = 0.79039301310044 
2016-12-11 17:37:52 Test Loss = 0.037002220574547 
2016-12-11 17:37:52 -------------------LR------------------- 
2016-12-11 17:37:52 0.001953125 
2016-12-11 17:37:52 Epoch 159 
2016-12-11 17:39:24 Training Error = 0.60051302821655 
2016-12-11 17:39:24 Training Loss = 0.026734037515763 
2016-12-11 17:39:26 Valid Error = 0.68286755771567 
2016-12-11 17:39:26 Valid Loss = 0.0299843738914 
2016-12-11 17:39:28 Test Error = 0.73580786026201 
2016-12-11 17:39:28 Test Loss = 0.032047875628752 
2016-12-11 17:39:28 -------------------LR------------------- 
2016-12-11 17:39:28 0.001953125 
2016-12-11 17:39:28 Epoch 160 
2016-12-11 17:40:58 Training Error = 0.59929796138788 
2016-12-11 17:40:58 Training Loss = 0.026745312079707 
2016-12-11 17:41:01 Valid Error = 0.68286755771567 
2016-12-11 17:41:01 Valid Loss = 0.031707884056884 
2016-12-11 17:41:03 Test Error = 0.73580786026201 
2016-12-11 17:41:03 Test Loss = 0.033712935260698 
2016-12-11 17:41:03 -------------------LR------------------- 
2016-12-11 17:41:03 0.001953125 
2016-12-11 17:41:03 Epoch 161 
2016-12-11 17:42:33 Training Error = 0.60226812474686 
2016-12-11 17:42:33 Training Loss = 0.027016285895055 
2016-12-11 17:42:35 Valid Error = 0.79951397326853 
2016-12-11 17:42:35 Valid Loss = 0.038022614002363 
2016-12-11 17:42:37 Test Error = 0.84497816593886 
2016-12-11 17:42:37 Test Loss = 0.038811395158955 
2016-12-11 17:42:37 -------------------LR------------------- 
2016-12-11 17:42:37 0.001953125 
2016-12-11 17:42:37 Epoch 162 
2016-12-11 17:44:09 Training Error = 0.60172809504523 
2016-12-11 17:44:09 Training Loss = 0.026589281101031 
2016-12-11 17:44:11 Valid Error = 0.67314702308627 
2016-12-11 17:44:11 Valid Loss = 0.034585605674455 
2016-12-11 17:44:13 Test Error = 0.72598253275109 
2016-12-11 17:44:13 Test Loss = 0.037285585581088 
2016-12-11 17:44:13 -------------------LR------------------- 
2016-12-11 17:44:13 0.001953125 
2016-12-11 17:44:13 Epoch 163 
2016-12-11 17:45:43 Training Error = 0.60024301336574 
2016-12-11 17:45:43 Training Loss = 0.026782764979771 
2016-12-11 17:45:45 Valid Error = 0.64763061968408 
2016-12-11 17:45:45 Valid Loss = 0.031964185678045 
2016-12-11 17:45:47 Test Error = 0.68777292576419 
2016-12-11 17:45:47 Test Loss = 0.033891635455337 
2016-12-11 17:45:47 -------------------LR------------------- 
2016-12-11 17:45:47 0.001953125 
2016-12-11 17:45:47 Epoch 164 
2016-12-11 17:47:19 Training Error = 0.59916295396247 
2016-12-11 17:47:19 Training Loss = 0.026574766796978 
2016-12-11 17:47:21 Valid Error = 0.68286755771567 
2016-12-11 17:47:21 Valid Loss = 0.030394019224184 
2016-12-11 17:47:23 Test Error = 0.73580786026201 
2016-12-11 17:47:23 Test Loss = 0.032784765888663 
2016-12-11 17:47:23 -------------------LR------------------- 
2016-12-11 17:47:23 0.001953125 
2016-12-11 17:47:23 Epoch 165 
2016-12-11 17:48:52 Training Error = 0.59875793168624 
2016-12-11 17:48:52 Training Loss = 0.026591434034958 
2016-12-11 17:48:54 Valid Error = 0.60510328068044 
2016-12-11 17:48:54 Valid Loss = 0.027355761595315 
2016-12-11 17:48:56 Test Error = 0.64192139737991 
2016-12-11 17:48:56 Test Loss = 0.0289208650028 
2016-12-11 17:48:56 -------------------LR------------------- 
2016-12-11 17:48:56 0.001953125 
2016-12-11 17:48:56 Epoch 166 
2016-12-11 17:50:27 Training Error = 0.59956797623869 
2016-12-11 17:50:27 Training Loss = 0.026721223143391 
2016-12-11 17:50:29 Valid Error = 0.79951397326853 
2016-12-11 17:50:29 Valid Loss = 0.037401109749455 
2016-12-11 17:50:31 Test Error = 0.84497816593886 
2016-12-11 17:50:31 Test Loss = 0.038467071776297 
2016-12-11 17:50:31 -------------------LR------------------- 
2016-12-11 17:50:31 0.001953125 
2016-12-11 17:50:31 Epoch 167 
2016-12-11 17:52:01 Training Error = 0.60051302821655 
2016-12-11 17:52:01 Training Loss = 0.026705050793104 
2016-12-11 17:52:03 Valid Error = 0.60510328068044 
2016-12-11 17:52:03 Valid Loss = 0.027044208443864 
2016-12-11 17:52:05 Test Error = 0.64192139737991 
2016-12-11 17:52:05 Test Loss = 0.028667187746833 
2016-12-11 17:52:05 -------------------LR------------------- 
2016-12-11 17:52:05 0.001953125 
2016-12-11 17:52:05 Epoch 168 
2016-12-11 17:53:35 Training Error = 0.60024301336574 
2016-12-11 17:53:35 Training Loss = 0.02689643160609 
2016-12-11 17:53:37 Valid Error = 0.79951397326853 
2016-12-11 17:53:37 Valid Loss = 0.035097383956425 
2016-12-11 17:53:39 Test Error = 0.84497816593886 
2016-12-11 17:53:39 Test Loss = 0.036649141928729 
2016-12-11 17:53:39 -------------------LR------------------- 
2016-12-11 17:53:39 0.001953125 
2016-12-11 17:53:40 Epoch 169 
2016-12-11 17:55:10 Training Error = 0.59902794653706 
2016-12-11 17:55:10 Training Loss = 0.027094216676742 
2016-12-11 17:55:12 Valid Error = 0.7363304981774 
2016-12-11 17:55:12 Valid Loss = 0.03480130134099 
2016-12-11 17:55:15 Test Error = 0.79039301310044 
2016-12-11 17:55:15 Test Loss = 0.037128774297004 
2016-12-11 17:55:15 -------------------LR------------------- 
2016-12-11 17:55:15 0.001953125 
2016-12-11 17:55:15 Epoch 170 
2016-12-11 17:56:49 Training Error = 0.59902794653706 
2016-12-11 17:56:49 Training Loss = 0.026822709051679 
2016-12-11 17:56:51 Valid Error = 0.72539489671932 
2016-12-11 17:56:51 Valid Loss = 0.03123457529672 
2016-12-11 17:56:53 Test Error = 0.78165938864629 
2016-12-11 17:56:53 Test Loss = 0.032937036551681 
2016-12-11 17:56:53 -------------------LR------------------- 
2016-12-11 17:56:53 0.001953125 
2016-12-11 17:56:53 Epoch 171 
2016-12-11 17:58:22 Training Error = 0.60037802079114 
2016-12-11 17:58:22 Training Loss = 0.026681246674695 
2016-12-11 17:58:24 Valid Error = 0.60510328068044 
2016-12-11 17:58:24 Valid Loss = 0.02740881801792 
2016-12-11 17:58:27 Test Error = 0.64192139737991 
2016-12-11 17:58:27 Test Loss = 0.028920149279576 
2016-12-11 17:58:27 -------------------LR------------------- 
2016-12-11 17:58:27 0.001953125 
2016-12-11 17:58:27 Epoch 172 
2016-12-11 17:59:56 Training Error = 0.59956797623869 
2016-12-11 17:59:56 Training Loss = 0.026579158021444 
2016-12-11 17:59:58 Valid Error = 0.67314702308627 
2016-12-11 17:59:58 Valid Loss = 0.030557252060591 
2016-12-11 18:00:00 Test Error = 0.72598253275109 
2016-12-11 18:00:00 Test Loss = 0.032658463562236 
2016-12-11 18:00:00 -------------------LR------------------- 
2016-12-11 18:00:00 0.001953125 
2016-12-11 18:00:00 Epoch 173 
2016-12-11 18:01:31 Training Error = 0.59997299851492 
2016-12-11 18:01:31 Training Loss = 0.026627033705938 
2016-12-11 18:01:33 Valid Error = 0.68286755771567 
2016-12-11 18:01:33 Valid Loss = 0.035072519443834 
2016-12-11 18:01:35 Test Error = 0.73580786026201 
2016-12-11 18:01:35 Test Loss = 0.038035374323527 
2016-12-11 18:01:35 -------------------LR------------------- 
2016-12-11 18:01:35 0.001953125 
2016-12-11 18:01:35 Epoch 174 
2016-12-11 18:03:06 Training Error = 0.60010800594033 
2016-12-11 18:03:06 Training Loss = 0.026641592477038 
2016-12-11 18:03:08 Valid Error = 0.60510328068044 
2016-12-11 18:03:08 Valid Loss = 0.027321091110173 
2016-12-11 18:03:10 Test Error = 0.64192139737991 
2016-12-11 18:03:10 Test Loss = 0.02877661633959 
2016-12-11 18:03:10 -------------------LR------------------- 
2016-12-11 18:03:10 0.001953125 
2016-12-11 18:03:10 Epoch 175 
2016-12-11 18:04:43 Training Error = 0.59929796138788 
2016-12-11 18:04:43 Training Loss = 0.026796052485732 
2016-12-11 18:04:45 Valid Error = 0.60510328068044 
2016-12-11 18:04:45 Valid Loss = 0.027059969073208 
2016-12-11 18:04:47 Test Error = 0.64192139737991 
2016-12-11 18:04:47 Test Loss = 0.028581468479306 
2016-12-11 18:04:47 -------------------LR------------------- 
2016-12-11 18:04:47 0.001953125 
2016-12-11 18:04:47 Epoch 176 
2016-12-11 18:06:15 Training Error = 0.59740785743216 
2016-12-11 18:06:15 Training Loss = 0.026866338390418 
2016-12-11 18:06:17 Valid Error = 0.60510328068044 
2016-12-11 18:06:17 Valid Loss = 0.027579244881222 
2016-12-11 18:06:20 Test Error = 0.64192139737991 
2016-12-11 18:06:20 Test Loss = 0.029073762323342 
2016-12-11 18:06:20 -------------------LR------------------- 
2016-12-11 18:06:20 0.001953125 
2016-12-11 18:06:20 Epoch 177 
2016-12-11 18:07:48 Training Error = 0.59997299851492 
2016-12-11 18:07:48 Training Loss = 0.026697146539483 
2016-12-11 18:07:50 Valid Error = 0.60510328068044 
2016-12-11 18:07:50 Valid Loss = 0.026820495249907 
2016-12-11 18:07:53 Test Error = 0.64192139737991 
2016-12-11 18:07:53 Test Loss = 0.02867619713615 
2016-12-11 18:07:53 -------------------LR------------------- 
2016-12-11 18:07:53 0.001953125 
2016-12-11 18:07:53 Epoch 178 
2016-12-11 18:09:24 Training Error = 0.60024301336574 
2016-12-11 18:09:24 Training Loss = 0.02652790309646 
2016-12-11 18:09:26 Valid Error = 0.68286755771567 
2016-12-11 18:09:26 Valid Loss = 0.032002788058418 
2016-12-11 18:09:28 Test Error = 0.73580786026201 
2016-12-11 18:09:28 Test Loss = 0.034285735410803 
2016-12-11 18:09:28 -------------------LR------------------- 
2016-12-11 18:09:28 0.001953125 
2016-12-11 18:09:28 Epoch 179 
2016-12-11 18:10:59 Training Error = 0.59916295396247 
2016-12-11 18:10:59 Training Loss = 0.026804949961145 
2016-12-11 18:11:01 Valid Error = 0.79951397326853 
2016-12-11 18:11:01 Valid Loss = 0.037894761856164 
2016-12-11 18:11:03 Test Error = 0.84497816593886 
2016-12-11 18:11:03 Test Loss = 0.038824511976803 
2016-12-11 18:11:03 -------------------LR------------------- 
2016-12-11 18:11:03 0.001953125 
2016-12-11 18:11:03 Epoch 180 
2016-12-11 18:12:37 Training Error = 0.59835290941002 
2016-12-11 18:12:37 Training Loss = 0.026682527935694 
2016-12-11 18:12:39 Valid Error = 0.7363304981774 
2016-12-11 18:12:39 Valid Loss = 0.033423614733213 
2016-12-11 18:12:42 Test Error = 0.79039301310044 
2016-12-11 18:12:42 Test Loss = 0.035469640900107 
2016-12-11 18:12:42 -------------------LR------------------- 
2016-12-11 18:12:42 0.001953125 
2016-12-11 18:12:42 Epoch 181 
2016-12-11 18:14:11 Training Error = 0.59848791683543 
2016-12-11 18:14:11 Training Loss = 0.026606770417314 
2016-12-11 18:14:14 Valid Error = 0.68286755771567 
2016-12-11 18:14:14 Valid Loss = 0.031990368832148 
2016-12-11 18:14:16 Test Error = 0.73580786026201 
2016-12-11 18:14:16 Test Loss = 0.034330233751559 
2016-12-11 18:14:16 -------------------LR------------------- 
2016-12-11 18:14:16 0.001953125 
2016-12-11 18:14:16 Epoch 182 
2016-12-11 18:15:44 Training Error = 0.59997299851492 
2016-12-11 18:15:44 Training Loss = 0.026661525207007 
2016-12-11 18:15:45 Valid Error = 0.79951397326853 
2016-12-11 18:15:45 Valid Loss = 0.03463402699959 
2016-12-11 18:15:48 Test Error = 0.84497816593886 
2016-12-11 18:15:48 Test Loss = 0.036222752346712 
2016-12-11 18:15:48 -------------------LR------------------- 
2016-12-11 18:15:48 0.001953125 
2016-12-11 18:15:48 Epoch 183 
2016-12-11 18:17:18 Training Error = 0.59929796138788 
2016-12-11 18:17:18 Training Loss = 0.026808164302708 
2016-12-11 18:17:20 Valid Error = 0.69380315917375 
2016-12-11 18:17:20 Valid Loss = 0.030506529313456 
2016-12-11 18:17:23 Test Error = 0.74454148471616 
2016-12-11 18:17:23 Test Loss = 0.032709348968431 
2016-12-11 18:17:23 -------------------LR------------------- 
2016-12-11 18:17:23 0.001953125 
2016-12-11 18:17:23 Epoch 184 
2016-12-11 18:18:55 Training Error = 0.60024301336574 
2016-12-11 18:18:55 Training Loss = 0.026708305591117 
2016-12-11 18:18:57 Valid Error = 0.60510328068044 
2016-12-11 18:18:57 Valid Loss = 0.027449312845143 
2016-12-11 18:18:59 Test Error = 0.64192139737991 
2016-12-11 18:18:59 Test Loss = 0.028762990343804 
2016-12-11 18:18:59 -------------------LR------------------- 
2016-12-11 18:18:59 0.001953125 
2016-12-11 18:18:59 Epoch 185 
2016-12-11 18:20:29 Training Error = 0.60078304306737 
2016-12-11 18:20:29 Training Loss = 0.026806343051544 
2016-12-11 18:20:31 Valid Error = 0.60510328068044 
2016-12-11 18:20:31 Valid Loss = 0.027264228705894 
2016-12-11 18:20:33 Test Error = 0.64192139737991 
2016-12-11 18:20:33 Test Loss = 0.028628102433448 
2016-12-11 18:20:33 -------------------LR------------------- 
2016-12-11 18:20:33 0.001953125 
2016-12-11 18:20:33 Epoch 186 
2016-12-11 18:22:05 Training Error = 0.59983799108951 
2016-12-11 18:22:05 Training Loss = 0.02677948770532 
2016-12-11 18:22:07 Valid Error = 0.60510328068044 
2016-12-11 18:22:07 Valid Loss = 0.028522274526466 
2016-12-11 18:22:10 Test Error = 0.64192139737991 
2016-12-11 18:22:10 Test Loss = 0.03040192340402 
2016-12-11 18:22:10 -------------------LR------------------- 
2016-12-11 18:22:10 0.001953125 
2016-12-11 18:22:10 Epoch 187 
2016-12-11 18:23:38 Training Error = 0.59902794653706 
2016-12-11 18:23:38 Training Loss = 0.026722850002428 
2016-12-11 18:23:40 Valid Error = 0.68286755771567 
2016-12-11 18:23:40 Valid Loss = 0.030647425679103 
2016-12-11 18:23:42 Test Error = 0.73580786026201 
2016-12-11 18:23:42 Test Loss = 0.032747910200381 
2016-12-11 18:23:42 -------------------LR------------------- 
2016-12-11 18:23:42 0.001953125 
2016-12-11 18:23:42 Epoch 188 
2016-12-11 18:25:12 Training Error = 0.59875793168624 
2016-12-11 18:25:12 Training Loss = 0.026808487212023 
2016-12-11 18:25:14 Valid Error = 0.7363304981774 
2016-12-11 18:25:14 Valid Loss = 0.033713758417498 
2016-12-11 18:25:16 Test Error = 0.79039301310044 
2016-12-11 18:25:16 Test Loss = 0.035762836839639 
2016-12-11 18:25:16 -------------------LR------------------- 
2016-12-11 18:25:16 0.001953125 
2016-12-11 18:25:16 Epoch 189 
2016-12-11 18:26:48 Training Error = 0.60172809504523 
2016-12-11 18:26:48 Training Loss = 0.026750053989898 
2016-12-11 18:26:50 Valid Error = 0.68286755771567 
2016-12-11 18:26:50 Valid Loss = 0.032790103112702 
2016-12-11 18:26:52 Test Error = 0.73580786026201 
2016-12-11 18:26:52 Test Loss = 0.035244399725222 
2016-12-11 18:26:52 -------------------LR------------------- 
2016-12-11 18:26:52 0.001953125 
2016-12-11 18:26:52 Epoch 190 
2016-12-11 18:28:25 Training Error = 0.59754286485757 
2016-12-11 18:28:25 Training Loss = 0.026615946333571 
2016-12-11 18:28:27 Valid Error = 0.7363304981774 
2016-12-11 18:28:27 Valid Loss = 0.035483730352658 
2016-12-11 18:28:29 Test Error = 0.79039301310044 
2016-12-11 18:28:29 Test Loss = 0.037467626571655 
2016-12-11 18:28:29 -------------------LR------------------- 
2016-12-11 18:28:29 0.001953125 
2016-12-11 18:28:29 Epoch 191 
2016-12-11 18:30:00 Training Error = 0.60226812474686 
2016-12-11 18:30:00 Training Loss = 0.026674033545913 
2016-12-11 18:30:02 Valid Error = 0.68286755771567 
2016-12-11 18:30:02 Valid Loss = 0.03112421792238 
2016-12-11 18:30:04 Test Error = 0.73580786026201 
2016-12-11 18:30:04 Test Loss = 0.033396743409774 
2016-12-11 18:30:04 -------------------LR------------------- 
2016-12-11 18:30:04 0.001953125 
2016-12-11 18:30:04 Epoch 192 
2016-12-11 18:31:33 Training Error = 0.601323072769 
2016-12-11 18:31:33 Training Loss = 0.026987149144733 
2016-12-11 18:31:35 Valid Error = 0.726609963548 
2016-12-11 18:31:35 Valid Loss = 0.033549632413647 
2016-12-11 18:31:37 Test Error = 0.77510917030568 
2016-12-11 18:31:37 Test Loss = 0.035515017939549 
2016-12-11 18:31:37 -------------------LR------------------- 
2016-12-11 18:31:37 0.001953125 
2016-12-11 18:31:37 Epoch 193 
2016-12-11 18:33:08 Training Error = 0.59997299851492 
2016-12-11 18:33:08 Training Loss = 0.026754149057084 
2016-12-11 18:33:10 Valid Error = 0.59538274605103 
2016-12-11 18:33:10 Valid Loss = 0.02700337027582 
2016-12-11 18:33:12 Test Error = 0.632096069869 
2016-12-11 18:33:12 Test Loss = 0.028700146039327 
2016-12-11 18:33:12 -------------------LR------------------- 
2016-12-11 18:33:12 0.001953125 
2016-12-11 18:33:12 Epoch 194 
2016-12-11 18:34:45 Training Error = 0.5997029836641 
2016-12-11 18:34:45 Training Loss = 0.026642136472102 
2016-12-11 18:34:47 Valid Error = 0.7363304981774 
2016-12-11 18:34:47 Valid Loss = 0.031638401628071 
2016-12-11 18:34:49 Test Error = 0.79039301310044 
2016-12-11 18:34:49 Test Loss = 0.033876757154278 
2016-12-11 18:34:49 -------------------LR------------------- 
2016-12-11 18:34:49 0.001953125 
2016-12-11 18:34:49 Epoch 195 
2016-12-11 18:36:20 Training Error = 0.60105305791819 
2016-12-11 18:36:20 Training Loss = 0.026784704928928 
2016-12-11 18:36:22 Valid Error = 0.79951397326853 
2016-12-11 18:36:22 Valid Loss = 0.038757294863251 
2016-12-11 18:36:24 Test Error = 0.84497816593886 
2016-12-11 18:36:24 Test Loss = 0.039535164159887 
2016-12-11 18:36:24 -------------------LR------------------- 
2016-12-11 18:36:24 0.001953125 
2016-12-11 18:36:25 Epoch 196 
2016-12-11 18:37:59 Training Error = 0.59713784258134 
2016-12-11 18:37:59 Training Loss = 0.026712062913341 
2016-12-11 18:38:01 Valid Error = 0.7363304981774 
2016-12-11 18:38:01 Valid Loss = 0.036184922558256 
2016-12-11 18:38:03 Test Error = 0.79039301310044 
2016-12-11 18:38:03 Test Loss = 0.038127598014532 
2016-12-11 18:38:03 -------------------LR------------------- 
2016-12-11 18:38:03 0.001953125 
2016-12-11 18:38:03 Epoch 197 
2016-12-11 18:39:32 Training Error = 0.59983799108951 
2016-12-11 18:39:32 Training Loss = 0.026763046183439 
2016-12-11 18:39:34 Valid Error = 0.68286755771567 
2016-12-11 18:39:34 Valid Loss = 0.031793511735678 
2016-12-11 18:39:36 Test Error = 0.73580786026201 
2016-12-11 18:39:36 Test Loss = 0.0342769557074 
2016-12-11 18:39:36 -------------------LR------------------- 
2016-12-11 18:39:36 0.001953125 
2016-12-11 18:39:36 Epoch 198 
2016-12-11 18:41:04 Training Error = 0.60010800594033 
2016-12-11 18:41:04 Training Loss = 0.026695662672825 
2016-12-11 18:41:06 Valid Error = 0.60510328068044 
2016-12-11 18:41:06 Valid Loss = 0.027381830312113 
2016-12-11 18:41:08 Test Error = 0.64192139737991 
2016-12-11 18:41:08 Test Loss = 0.028995227290135 
2016-12-11 18:41:08 -------------------LR------------------- 
2016-12-11 18:41:08 0.001953125 
2016-12-11 18:41:08 Epoch 199 
2016-12-11 18:42:41 Training Error = 0.59916295396247 
2016-12-11 18:42:41 Training Loss = 0.02656619926474 
2016-12-11 18:42:43 Valid Error = 0.68286755771567 
2016-12-11 18:42:43 Valid Loss = 0.030529898755239 
2016-12-11 18:42:45 Test Error = 0.73580786026201 
2016-12-11 18:42:45 Test Loss = 0.032464473284927 
2016-12-11 18:42:45 -------------------LR------------------- 
2016-12-11 18:42:45 0.001953125 
2016-12-11 18:42:45 Epoch 200 
2016-12-11 18:44:19 Training Error = 0.59889293911165 
2016-12-11 18:44:19 Training Loss = 0.026710952536532 
2016-12-11 18:44:21 Valid Error = 0.68286755771567 
2016-12-11 18:44:21 Valid Loss = 0.031020752224855 
2016-12-11 18:44:23 Test Error = 0.73580786026201 
2016-12-11 18:44:23 Test Loss = 0.033457294838101 
2016-12-11 18:44:23 -------------------LR------------------- 
2016-12-11 18:44:23 0.0009765625 
2016-12-11 18:44:23 Epoch 201 
2016-12-11 18:45:54 Training Error = 0.59605778317807 
2016-12-11 18:45:54 Training Loss = 0.026843847060716 
2016-12-11 18:45:56 Valid Error = 0.79951397326853 
2016-12-11 18:45:56 Valid Loss = 0.036063845042671 
2016-12-11 18:45:58 Test Error = 0.84497816593886 
2016-12-11 18:45:58 Test Loss = 0.037458886081097 
2016-12-11 18:45:58 -------------------LR------------------- 
2016-12-11 18:45:58 0.0009765625 
2016-12-11 18:45:58 Epoch 202 
2016-12-11 18:47:27 Training Error = 0.60024301336574 
2016-12-11 18:47:27 Training Loss = 0.026694280728038 
2016-12-11 18:47:29 Valid Error = 0.69380315917375 
2016-12-11 18:47:29 Valid Loss = 0.031562715143578 
2016-12-11 18:47:31 Test Error = 0.74454148471616 
2016-12-11 18:47:31 Test Loss = 0.033977078363007 
2016-12-11 18:47:31 -------------------LR------------------- 
2016-12-11 18:47:31 0.0009765625 
2016-12-11 18:47:31 Epoch 203 
2016-12-11 18:49:03 Training Error = 0.59983799108951 
2016-12-11 18:49:03 Training Loss = 0.026713519200201 
2016-12-11 18:49:05 Valid Error = 0.7363304981774 
2016-12-11 18:49:05 Valid Loss = 0.033299453733906 
2016-12-11 18:49:07 Test Error = 0.79039301310044 
2016-12-11 18:49:07 Test Loss = 0.035293616210713 
2016-12-11 18:49:07 -------------------LR------------------- 
2016-12-11 18:49:07 0.0009765625 
2016-12-11 18:49:07 Epoch 204 
2016-12-11 18:50:38 Training Error = 0.60010800594033 
2016-12-11 18:50:38 Training Loss = 0.026734444834249 
2016-12-11 18:50:40 Valid Error = 0.68286755771567 
2016-12-11 18:50:40 Valid Loss = 0.031598370859114 
2016-12-11 18:50:42 Test Error = 0.73580786026201 
2016-12-11 18:50:42 Test Loss = 0.033716688679714 
2016-12-11 18:50:42 -------------------LR------------------- 
2016-12-11 18:50:42 0.0009765625 
2016-12-11 18:50:42 Epoch 205 
2016-12-11 18:52:13 Training Error = 0.60213311732145 
2016-12-11 18:52:13 Training Loss = 0.026711193068332 
2016-12-11 18:52:15 Valid Error = 0.79951397326853 
2016-12-11 18:52:15 Valid Loss = 0.035687146054487 
2016-12-11 18:52:17 Test Error = 0.84497816593886 
2016-12-11 18:52:17 Test Loss = 0.037317577894996 
2016-12-11 18:52:17 -------------------LR------------------- 
2016-12-11 18:52:17 0.0009765625 
2016-12-11 18:52:17 Epoch 206 
2016-12-11 18:53:49 Training Error = 0.60375320642635 
2016-12-11 18:53:49 Training Loss = 0.026760177808917 
2016-12-11 18:53:51 Valid Error = 0.68286755771567 
2016-12-11 18:53:51 Valid Loss = 0.031442950177263 
2016-12-11 18:53:53 Test Error = 0.73580786026201 
2016-12-11 18:53:53 Test Loss = 0.033817526303086 
2016-12-11 18:53:53 -------------------LR------------------- 
2016-12-11 18:53:53 0.0009765625 
2016-12-11 18:53:53 Epoch 207 
2016-12-11 18:55:23 Training Error = 0.6029431618739 
2016-12-11 18:55:23 Training Loss = 0.026700143092108 
2016-12-11 18:55:25 Valid Error = 0.68286755771567 
2016-12-11 18:55:25 Valid Loss = 0.031963744319342 
2016-12-11 18:55:27 Test Error = 0.73580786026201 
2016-12-11 18:55:27 Test Loss = 0.034509991842158 
2016-12-11 18:55:27 -------------------LR------------------- 
2016-12-11 18:55:27 0.0009765625 
2016-12-11 18:55:27 Epoch 208 
2016-12-11 18:56:58 Training Error = 0.59943296881328 
2016-12-11 18:56:58 Training Loss = 0.02671229312017 
2016-12-11 18:57:00 Valid Error = 0.68286755771567 
2016-12-11 18:57:00 Valid Loss = 0.033934884584005 
2016-12-11 18:57:02 Test Error = 0.73580786026201 
2016-12-11 18:57:02 Test Loss = 0.036510772059945 
2016-12-11 18:57:02 -------------------LR------------------- 
2016-12-11 18:57:02 0.0009765625 
2016-12-11 18:57:02 Epoch 209 
2016-12-11 18:58:30 Training Error = 0.60105305791819 
2016-12-11 18:58:30 Training Loss = 0.026698133371391 
2016-12-11 18:58:32 Valid Error = 0.7363304981774 
2016-12-11 18:58:32 Valid Loss = 0.035339653533302 
2016-12-11 18:58:34 Test Error = 0.79039301310044 
2016-12-11 18:58:34 Test Loss = 0.037299445825465 
2016-12-11 18:58:34 -------------------LR------------------- 
2016-12-11 18:58:34 0.0009765625 
2016-12-11 18:58:34 Epoch 210 
2016-12-11 19:00:08 Training Error = 0.5997029836641 
2016-12-11 19:00:08 Training Loss = 0.02680284882874 
2016-12-11 19:00:10 Valid Error = 0.7363304981774 
2016-12-11 19:00:10 Valid Loss = 0.03210394647296 
2016-12-11 19:00:12 Test Error = 0.79039301310044 
2016-12-11 19:00:12 Test Loss = 0.034133766071469 
2016-12-11 19:00:12 -------------------LR------------------- 
2016-12-11 19:00:12 0.0009765625 
2016-12-11 19:00:12 Epoch 211 
2016-12-11 19:01:44 Training Error = 0.60091805049278 
2016-12-11 19:01:44 Training Loss = 0.026779604603886 
2016-12-11 19:01:46 Valid Error = 0.7363304981774 
2016-12-11 19:01:46 Valid Loss = 0.035176577620901 
2016-12-11 19:01:48 Test Error = 0.79039301310044 
2016-12-11 19:01:48 Test Loss = 0.037098905086517 
2016-12-11 19:01:48 -------------------LR------------------- 
2016-12-11 19:01:48 0.0009765625 
2016-12-11 19:01:48 Epoch 212 
2016-12-11 19:03:16 Training Error = 0.60037802079114 
2016-12-11 19:03:16 Training Loss = 0.026543157966108 
2016-12-11 19:03:18 Valid Error = 0.67314702308627 
2016-12-11 19:03:18 Valid Loss = 0.033761340993433 
2016-12-11 19:03:20 Test Error = 0.72598253275109 
2016-12-11 19:03:20 Test Loss = 0.036140106173123 
2016-12-11 19:03:20 -------------------LR------------------- 
2016-12-11 19:03:20 0.0009765625 
2016-12-11 19:03:20 Epoch 213 
2016-12-11 19:04:51 Training Error = 0.60024301336574 
2016-12-11 19:04:51 Training Loss = 0.026844598722057 
2016-12-11 19:04:53 Valid Error = 0.79951397326853 
2016-12-11 19:04:53 Valid Loss = 0.03820205791098 
2016-12-11 19:04:55 Test Error = 0.84497816593886 
2016-12-11 19:04:55 Test Loss = 0.03898889689352 
2016-12-11 19:04:55 -------------------LR------------------- 
2016-12-11 19:04:55 0.0009765625 
2016-12-11 19:04:55 Epoch 214 
2016-12-11 19:06:27 Training Error = 0.60010800594033 
2016-12-11 19:06:27 Training Loss = 0.026832777675483 
2016-12-11 19:06:29 Valid Error = 0.7363304981774 
2016-12-11 19:06:29 Valid Loss = 0.034028425159763 
2016-12-11 19:06:31 Test Error = 0.79039301310044 
2016-12-11 19:06:31 Test Loss = 0.036044286484812 
2016-12-11 19:06:31 -------------------LR------------------- 
2016-12-11 19:06:31 0.0009765625 
2016-12-11 19:06:31 Epoch 215 
2016-12-11 19:07:59 Training Error = 0.60037802079114 
2016-12-11 19:07:59 Training Loss = 0.026656687837489 
2016-12-11 19:08:01 Valid Error = 0.68286755771567 
2016-12-11 19:08:01 Valid Loss = 0.033178621382269 
2016-12-11 19:08:03 Test Error = 0.73580786026201 
2016-12-11 19:08:03 Test Loss = 0.035717245391771 
2016-12-11 19:08:03 -------------------LR------------------- 
2016-12-11 19:08:03 0.0009765625 
2016-12-11 19:08:03 Epoch 216 
2016-12-11 19:09:35 Training Error = 0.59956797623869 
2016-12-11 19:09:35 Training Loss = 0.026763828775529 
2016-12-11 19:09:37 Valid Error = 0.68286755771567 
2016-12-11 19:09:37 Valid Loss = 0.033460429839206 
2016-12-11 19:09:39 Test Error = 0.73580786026201 
2016-12-11 19:09:39 Test Loss = 0.035857335782519 
2016-12-11 19:09:39 -------------------LR------------------- 
2016-12-11 19:09:39 0.0009765625 
2016-12-11 19:09:39 Epoch 217 
2016-12-11 19:11:08 Training Error = 0.59997299851492 
2016-12-11 19:11:08 Training Loss = 0.02672813499586 
2016-12-11 19:11:10 Valid Error = 0.60510328068044 
2016-12-11 19:11:10 Valid Loss = 0.027151609751224 
2016-12-11 19:11:12 Test Error = 0.64192139737991 
2016-12-11 19:11:12 Test Loss = 0.028901682283364 
2016-12-11 19:11:12 -------------------LR------------------- 
2016-12-11 19:11:12 0.0009765625 
2016-12-11 19:11:12 Epoch 218 
2016-12-11 19:12:43 Training Error = 0.60010800594033 
2016-12-11 19:12:43 Training Loss = 0.026777764636128 
2016-12-11 19:12:45 Valid Error = 0.68286755771567 
2016-12-11 19:12:45 Valid Loss = 0.034444056578948 
2016-12-11 19:12:47 Test Error = 0.73580786026201 
2016-12-11 19:12:47 Test Loss = 0.037257380775377 
2016-12-11 19:12:47 -------------------LR------------------- 
2016-12-11 19:12:47 0.0009765625 
2016-12-11 19:12:47 Epoch 219 
2016-12-11 19:14:19 Training Error = 0.60051302821655 
2016-12-11 19:14:19 Training Loss = 0.026690830608977 
2016-12-11 19:14:21 Valid Error = 0.68286755771567 
2016-12-11 19:14:21 Valid Loss = 0.030451483575189 
2016-12-11 19:14:23 Test Error = 0.73580786026201 
2016-12-11 19:14:23 Test Loss = 0.032675875682457 
2016-12-11 19:14:23 -------------------LR------------------- 
2016-12-11 19:14:23 0.0009765625 
2016-12-11 19:14:23 Epoch 220 
2016-12-11 19:15:54 Training Error = 0.59956797623869 
2016-12-11 19:15:54 Training Loss = 0.026648854951119 
2016-12-11 19:15:56 Valid Error = 0.60510328068044 
2016-12-11 19:15:56 Valid Loss = 0.027264364180583 
2016-12-11 19:15:58 Test Error = 0.64192139737991 
2016-12-11 19:15:58 Test Loss = 0.028740507490495 
2016-12-11 19:15:58 -------------------LR------------------- 
2016-12-11 19:15:58 0.0009765625 
2016-12-11 19:15:58 Epoch 221 
2016-12-11 19:17:30 Training Error = 0.59713784258134 
2016-12-11 19:17:30 Training Loss = 0.026536203948946 
2016-12-11 19:17:32 Valid Error = 0.67314702308627 
2016-12-11 19:17:32 Valid Loss = 0.030141445115467 
2016-12-11 19:17:34 Test Error = 0.72598253275109 
2016-12-11 19:17:34 Test Loss = 0.032368934341505 
2016-12-11 19:17:34 -------------------LR------------------- 
2016-12-11 19:17:34 0.0009765625 
2016-12-11 19:17:34 Epoch 222 
2016-12-11 19:19:02 Training Error = 0.59943296881328 
2016-12-11 19:19:02 Training Loss = 0.0265908114208 
2016-12-11 19:19:04 Valid Error = 0.68286755771567 
2016-12-11 19:19:04 Valid Loss = 0.030755818453636 
2016-12-11 19:19:06 Test Error = 0.73580786026201 
2016-12-11 19:19:06 Test Loss = 0.032788591085696 
2016-12-11 19:19:06 -------------------LR------------------- 
2016-12-11 19:19:06 0.0009765625 
2016-12-11 19:19:06 Epoch 223 
2016-12-11 19:20:38 Training Error = 0.59943296881328 
2016-12-11 19:20:38 Training Loss = 0.026773234063726 
2016-12-11 19:20:40 Valid Error = 0.65856622114216 
2016-12-11 19:20:40 Valid Loss = 0.031656884737874 
2016-12-11 19:20:43 Test Error = 0.69650655021834 
2016-12-11 19:20:43 Test Loss = 0.033537288768619 
2016-12-11 19:20:43 -------------------LR------------------- 
2016-12-11 19:20:43 0.0009765625 
2016-12-11 19:20:43 Epoch 224 
2016-12-11 19:22:14 Training Error = 0.59902794653706 
2016-12-11 19:22:14 Training Loss = 0.026660111626234 
2016-12-11 19:22:16 Valid Error = 0.7363304981774 
2016-12-11 19:22:16 Valid Loss = 0.035951012129629 
2016-12-11 19:22:18 Test Error = 0.79039301310044 
2016-12-11 19:22:18 Test Loss = 0.03785918709811 
2016-12-11 19:22:18 -------------------LR------------------- 
2016-12-11 19:22:18 0.0009765625 
2016-12-11 19:22:18 Epoch 225 
2016-12-11 19:23:49 Training Error = 0.60010800594033 
2016-12-11 19:23:49 Training Loss = 0.026567578315913 
2016-12-11 19:23:51 Valid Error = 0.60510328068044 
2016-12-11 19:23:51 Valid Loss = 0.027181846775475 
2016-12-11 19:23:53 Test Error = 0.64192139737991 
2016-12-11 19:23:53 Test Loss = 0.028819212969612 
2016-12-11 19:23:53 -------------------LR------------------- 
2016-12-11 19:23:53 0.0009765625 
2016-12-11 19:23:54 Epoch 226 
2016-12-11 19:25:22 Training Error = 0.60118806534359 
2016-12-11 19:25:22 Training Loss = 0.026691829599475 
2016-12-11 19:25:24 Valid Error = 0.68286755771567 
2016-12-11 19:25:24 Valid Loss = 0.031412462973624 
2016-12-11 19:25:26 Test Error = 0.73580786026201 
2016-12-11 19:25:26 Test Loss = 0.03393224362766 
2016-12-11 19:25:26 -------------------LR------------------- 
2016-12-11 19:25:26 0.0009765625 
2016-12-11 19:25:26 Epoch 227 
2016-12-11 19:26:56 Training Error = 0.59835290941002 
2016-12-11 19:26:56 Training Loss = 0.026834674904304 
2016-12-11 19:26:58 Valid Error = 0.7363304981774 
2016-12-11 19:26:58 Valid Loss = 0.038292599752386 
2016-12-11 19:27:00 Test Error = 0.79039301310044 
2016-12-11 19:27:00 Test Loss = 0.03968391493255 
2016-12-11 19:27:00 -------------------LR------------------- 
2016-12-11 19:27:00 0.0009765625 
2016-12-11 19:27:00 Epoch 228 
2016-12-11 19:28:32 Training Error = 0.60172809504523 
2016-12-11 19:28:32 Training Loss = 0.026688287568649 
2016-12-11 19:28:34 Valid Error = 0.7363304981774 
2016-12-11 19:28:34 Valid Loss = 0.033936905206419 
2016-12-11 19:28:36 Test Error = 0.79039301310044 
2016-12-11 19:28:36 Test Loss = 0.035858456041299 
2016-12-11 19:28:36 -------------------LR------------------- 
2016-12-11 19:28:36 0.0009765625 
2016-12-11 19:28:36 Epoch 229 
2016-12-11 19:30:07 Training Error = 0.59875793168624 
2016-12-11 19:30:07 Training Loss = 0.026701733298707 
2016-12-11 19:30:09 Valid Error = 0.60510328068044 
2016-12-11 19:30:09 Valid Loss = 0.027366360708361 
2016-12-11 19:30:11 Test Error = 0.64192139737991 
2016-12-11 19:30:11 Test Loss = 0.029179286536048 
2016-12-11 19:30:11 -------------------LR------------------- 
2016-12-11 19:30:11 0.0009765625 
2016-12-11 19:30:11 Epoch 230 
2016-12-11 19:31:45 Training Error = 0.60078304306737 
2016-12-11 19:31:45 Training Loss = 0.026754710996541 
2016-12-11 19:31:47 Valid Error = 0.60510328068044 
2016-12-11 19:31:47 Valid Loss = 0.029604321489102 
2016-12-11 19:31:49 Test Error = 0.64192139737991 
2016-12-11 19:31:49 Test Loss = 0.03136163407681 
2016-12-11 19:31:49 -------------------LR------------------- 
2016-12-11 19:31:49 0.0009765625 
2016-12-11 19:31:49 Epoch 231 
2016-12-11 19:33:18 Training Error = 0.59902794653706 
2016-12-11 19:33:18 Training Loss = 0.026762173712665 
2016-12-11 19:33:20 Valid Error = 0.72539489671932 
2016-12-11 19:33:20 Valid Loss = 0.033209496487539 
2016-12-11 19:33:23 Test Error = 0.78165938864629 
2016-12-11 19:33:23 Test Loss = 0.035376919166715 
2016-12-11 19:33:23 -------------------LR------------------- 
2016-12-11 19:33:23 0.0009765625 
2016-12-11 19:33:23 Epoch 232 
2016-12-11 19:34:53 Training Error = 0.59997299851492 
2016-12-11 19:34:53 Training Loss = 0.026644098510172 
2016-12-11 19:34:55 Valid Error = 0.726609963548 
2016-12-11 19:34:55 Valid Loss = 0.035954053061607 
2016-12-11 19:34:57 Test Error = 0.77510917030568 
2016-12-11 19:34:57 Test Loss = 0.037824016496247 
2016-12-11 19:34:57 -------------------LR------------------- 
2016-12-11 19:34:57 0.0009765625 
2016-12-11 19:34:57 Epoch 233 
2016-12-11 19:36:27 Training Error = 0.59821790198461 
2016-12-11 19:36:27 Training Loss = 0.026579569836357 
2016-12-11 19:36:29 Valid Error = 0.7363304981774 
2016-12-11 19:36:29 Valid Loss = 0.035345222608287 
2016-12-11 19:36:31 Test Error = 0.79039301310044 
2016-12-11 19:36:31 Test Loss = 0.037341068099527 
2016-12-11 19:36:31 -------------------LR------------------- 
2016-12-11 19:36:31 0.0009765625 
2016-12-11 19:36:31 Epoch 234 
2016-12-11 19:38:03 Training Error = 0.59956797623869 
2016-12-11 19:38:03 Training Loss = 0.026732589765846 
2016-12-11 19:38:05 Valid Error = 0.7363304981774 
2016-12-11 19:38:05 Valid Loss = 0.034342556666434 
2016-12-11 19:38:07 Test Error = 0.79039301310044 
2016-12-11 19:38:07 Test Loss = 0.036285376146728 
2016-12-11 19:38:07 -------------------LR------------------- 
2016-12-11 19:38:07 0.0009765625 
2016-12-11 19:38:07 Epoch 235 
2016-12-11 19:39:38 Training Error = 0.59740785743216 
2016-12-11 19:39:38 Training Loss = 0.026593201132382 
2016-12-11 19:39:40 Valid Error = 0.60510328068044 
2016-12-11 19:39:40 Valid Loss = 0.027259262986873 
2016-12-11 19:39:42 Test Error = 0.64192139737991 
2016-12-11 19:39:42 Test Loss = 0.028833937738456 
2016-12-11 19:39:42 -------------------LR------------------- 
2016-12-11 19:39:42 0.0009765625 
2016-12-11 19:39:42 Epoch 236 
2016-12-11 19:41:13 Training Error = 0.60051302821655 
2016-12-11 19:41:13 Training Loss = 0.026588628784237 
2016-12-11 19:41:15 Valid Error = 0.67314702308627 
2016-12-11 19:41:15 Valid Loss = 0.031450534035358 
2016-12-11 19:41:17 Test Error = 0.72598253275109 
2016-12-11 19:41:17 Test Loss = 0.033866958047829 
2016-12-11 19:41:17 -------------------LR------------------- 
2016-12-11 19:41:17 0.0009765625 
2016-12-11 19:41:17 Epoch 237 
2016-12-11 19:42:46 Training Error = 0.60145808019441 
2016-12-11 19:42:46 Training Loss = 0.026688566627823 
2016-12-11 19:42:48 Valid Error = 0.60510328068044 
2016-12-11 19:42:48 Valid Loss = 0.027357919231739 
2016-12-11 19:42:51 Test Error = 0.64192139737991 
2016-12-11 19:42:51 Test Loss = 0.028837214002422 
2016-12-11 19:42:51 -------------------LR------------------- 
2016-12-11 19:42:51 0.0009765625 
2016-12-11 19:42:51 Epoch 238 
2016-12-11 19:44:22 Training Error = 0.59875793168624 
2016-12-11 19:44:22 Training Loss = 0.026629360367804 
2016-12-11 19:44:24 Valid Error = 0.59538274605103 
2016-12-11 19:44:24 Valid Loss = 0.02696195252095 
2016-12-11 19:44:26 Test Error = 0.62663755458515 
2016-12-11 19:44:26 Test Loss = 0.02860207567028 
2016-12-11 19:44:26 -------------------LR------------------- 
2016-12-11 19:44:26 0.0009765625 
2016-12-11 19:44:26 Epoch 239 
2016-12-11 19:45:56 Training Error = 0.59983799108951 
2016-12-11 19:45:56 Training Loss = 0.026599144296798 
2016-12-11 19:45:59 Valid Error = 0.726609963548 
2016-12-11 19:45:59 Valid Loss = 0.033564262747866 
2016-12-11 19:46:01 Test Error = 0.78056768558952 
2016-12-11 19:46:01 Test Loss = 0.035670405602923 
2016-12-11 19:46:01 -------------------LR------------------- 
2016-12-11 19:46:01 0.0009765625 
2016-12-11 19:46:01 Epoch 240 
2016-12-11 19:47:35 Training Error = 0.59862292426083 
2016-12-11 19:47:35 Training Loss = 0.026784444956775 
2016-12-11 19:47:37 Valid Error = 0.60510328068044 
2016-12-11 19:47:37 Valid Loss = 0.028416379159109 
2016-12-11 19:47:39 Test Error = 0.64192139737991 
2016-12-11 19:47:39 Test Loss = 0.030195167821996 
2016-12-11 19:47:39 -------------------LR------------------- 
2016-12-11 19:47:39 0.0009765625 
2016-12-11 19:47:39 Epoch 241 
2016-12-11 19:49:11 Training Error = 0.59619279060348 
2016-12-11 19:49:11 Training Loss = 0.026549912631679 
2016-12-11 19:49:13 Valid Error = 0.68286755771567 
2016-12-11 19:49:13 Valid Loss = 0.034825267829689 
2016-12-11 19:49:15 Test Error = 0.73580786026201 
2016-12-11 19:49:15 Test Loss = 0.037630528552859 
2016-12-11 19:49:15 -------------------LR------------------- 
2016-12-11 19:49:15 0.0009765625 
2016-12-11 19:49:15 Epoch 242 
2016-12-11 19:50:43 Training Error = 0.60118806534359 
2016-12-11 19:50:43 Training Loss = 0.026684777112546 
2016-12-11 19:50:45 Valid Error = 0.65856622114216 
2016-12-11 19:50:45 Valid Loss = 0.031591121568433 
2016-12-11 19:50:47 Test Error = 0.69650655021834 
2016-12-11 19:50:47 Test Loss = 0.033579255805296 
2016-12-11 19:50:47 -------------------LR------------------- 
2016-12-11 19:50:47 0.0009765625 
2016-12-11 19:50:47 Epoch 243 
2016-12-11 19:52:18 Training Error = 0.59983799108951 
2016-12-11 19:52:18 Training Loss = 0.026866156755264 
2016-12-11 19:52:20 Valid Error = 0.7363304981774 
2016-12-11 19:52:20 Valid Loss = 0.034390436714319 
2016-12-11 19:52:22 Test Error = 0.79039301310044 
2016-12-11 19:52:22 Test Loss = 0.036205385077233 
2016-12-11 19:52:22 -------------------LR------------------- 
2016-12-11 19:52:22 0.0009765625 
2016-12-11 19:52:22 Epoch 244 
2016-12-11 19:53:53 Training Error = 0.60199810989604 
2016-12-11 19:53:53 Training Loss = 0.02668951437244 
2016-12-11 19:53:55 Valid Error = 0.68286755771567 
2016-12-11 19:53:55 Valid Loss = 0.030162238333954 
2016-12-11 19:53:57 Test Error = 0.73580786026201 
2016-12-11 19:53:57 Test Loss = 0.032592682333554 
2016-12-11 19:53:57 -------------------LR------------------- 
2016-12-11 19:53:57 0.0009765625 
2016-12-11 19:53:57 Epoch 245 
2016-12-11 19:55:28 Training Error = 0.60037802079114 
2016-12-11 19:55:28 Training Loss = 0.026644659935304 
2016-12-11 19:55:30 Valid Error = 0.68286755771567 
2016-12-11 19:55:30 Valid Loss = 0.031606767933918 
2016-12-11 19:55:33 Test Error = 0.73580786026201 
2016-12-11 19:55:33 Test Loss = 0.034034179827746 
2016-12-11 19:55:33 -------------------LR------------------- 
2016-12-11 19:55:33 0.0009765625 
2016-12-11 19:55:33 Epoch 246 
2016-12-11 19:57:00 Training Error = 0.59997299851492 
2016-12-11 19:57:00 Training Loss = 0.026910003103618 
2016-12-11 19:57:02 Valid Error = 0.78979343863913 
2016-12-11 19:57:02 Valid Loss = 0.038980953646189 
2016-12-11 19:57:04 Test Error = 0.83515283842795 
2016-12-11 19:57:04 Test Loss = 0.039700940206939 
2016-12-11 19:57:04 -------------------LR------------------- 
2016-12-11 19:57:04 0.0009765625 
2016-12-11 19:57:04 Epoch 247 
2016-12-11 19:58:33 Training Error = 0.60064803564196 
2016-12-11 19:58:33 Training Loss = 0.026668406138701 
2016-12-11 19:58:35 Valid Error = 0.68286755771567 
2016-12-11 19:58:35 Valid Loss = 0.030909015655156 
2016-12-11 19:58:37 Test Error = 0.73580786026201 
2016-12-11 19:58:37 Test Loss = 0.033107212870729 
2016-12-11 19:58:37 -------------------LR------------------- 
2016-12-11 19:58:37 0.0009765625 
2016-12-11 19:58:37 Epoch 248 
2016-12-11 20:00:07 Training Error = 0.59848791683543 
2016-12-11 20:00:07 Training Loss = 0.026677917736919 
2016-12-11 20:00:09 Valid Error = 0.68286755771567 
2016-12-11 20:00:09 Valid Loss = 0.035388031309387 
2016-12-11 20:00:11 Test Error = 0.73580786026201 
2016-12-11 20:00:11 Test Loss = 0.038153853164 
2016-12-11 20:00:11 -------------------LR------------------- 
2016-12-11 20:00:11 0.0009765625 
2016-12-11 20:00:11 Epoch 249 
2016-12-11 20:01:42 Training Error = 0.60078304306737 
2016-12-11 20:01:42 Training Loss = 0.026662136513134 
2016-12-11 20:01:44 Valid Error = 0.7363304981774 
2016-12-11 20:01:44 Valid Loss = 0.035983383469231 
2016-12-11 20:01:46 Test Error = 0.79039301310044 
2016-12-11 20:01:46 Test Loss = 0.037800153573354 
2016-12-11 20:01:46 -------------------LR------------------- 
2016-12-11 20:01:46 0.0009765625 
2016-12-11 20:01:46 Epoch 250 
2016-12-11 20:03:18 Training Error = 0.60172809504523 
2016-12-11 20:03:18 Training Loss = 0.026719805586216 
2016-12-11 20:03:20 Valid Error = 0.7363304981774 
2016-12-11 20:03:20 Valid Loss = 0.035873385320347 
2016-12-11 20:03:22 Test Error = 0.79039301310044 
2016-12-11 20:03:22 Test Loss = 0.037908097585042 
2016-12-11 20:03:22 -------------------LR------------------- 
2016-12-11 20:03:22 0.00048828125 
2016-12-11 20:03:22 Epoch 251 
2016-12-11 20:04:51 Training Error = 0.59754286485757 
2016-12-11 20:04:51 Training Loss = 0.026550294064362 
2016-12-11 20:04:53 Valid Error = 0.68286755771567 
2016-12-11 20:04:53 Valid Loss = 0.032670517235167 
2016-12-11 20:04:55 Test Error = 0.73580786026201 
2016-12-11 20:04:55 Test Loss = 0.035166510647418 
2016-12-11 20:04:55 -------------------LR------------------- 
2016-12-11 20:04:55 0.00048828125 
2016-12-11 20:04:55 Epoch 252 
2016-12-11 20:06:26 Training Error = 0.59848791683543 
2016-12-11 20:06:26 Training Loss = 0.026727419716259 
2016-12-11 20:06:28 Valid Error = 0.72539489671932 
2016-12-11 20:06:28 Valid Loss = 0.032891710445241 
2016-12-11 20:06:30 Test Error = 0.78165938864629 
2016-12-11 20:06:30 Test Loss = 0.034975038210551 
2016-12-11 20:06:30 -------------------LR------------------- 
2016-12-11 20:06:30 0.00048828125 
2016-12-11 20:06:30 Epoch 253 
2016-12-11 20:07:59 Training Error = 0.60078304306737 
2016-12-11 20:07:59 Training Loss = 0.026747472249805 
2016-12-11 20:08:01 Valid Error = 0.60510328068044 
2016-12-11 20:08:01 Valid Loss = 0.027248620592171 
2016-12-11 20:08:03 Test Error = 0.64192139737991 
2016-12-11 20:08:03 Test Loss = 0.028703367149129 
2016-12-11 20:08:03 -------------------LR------------------- 
2016-12-11 20:08:03 0.00048828125 
2016-12-11 20:08:03 Epoch 254 
2016-12-11 20:09:35 Training Error = 0.59916295396247 
2016-12-11 20:09:35 Training Loss = 0.026786104600125 
2016-12-11 20:09:37 Valid Error = 0.7363304981774 
2016-12-11 20:09:37 Valid Loss = 0.03578136288353 
2016-12-11 20:09:39 Test Error = 0.79039301310044 
2016-12-11 20:09:39 Test Loss = 0.037758591670616 
2016-12-11 20:09:39 -------------------LR------------------- 
2016-12-11 20:09:39 0.00048828125 
2016-12-11 20:09:39 Epoch 255 
2016-12-11 20:11:10 Training Error = 0.59902794653706 
2016-12-11 20:11:10 Training Loss = 0.026593809222908 
2016-12-11 20:11:12 Valid Error = 0.60510328068044 
2016-12-11 20:11:12 Valid Loss = 0.027117017504053 
2016-12-11 20:11:14 Test Error = 0.64192139737991 
2016-12-11 20:11:14 Test Loss = 0.028521883300706 
2016-12-11 20:11:14 -------------------LR------------------- 
2016-12-11 20:11:14 0.00048828125 
2016-12-11 20:11:14 Epoch 256 
2016-12-11 20:12:43 Training Error = 0.60159308761982 
2016-12-11 20:12:43 Training Loss = 0.026702810116153 
2016-12-11 20:12:45 Valid Error = 0.68286755771567 
2016-12-11 20:12:45 Valid Loss = 0.034865207063256 
2016-12-11 20:12:47 Test Error = 0.73580786026201 
2016-12-11 20:12:47 Test Loss = 0.037515332530527 
2016-12-11 20:12:47 -------------------LR------------------- 
2016-12-11 20:12:47 0.00048828125 
2016-12-11 20:12:47 Epoch 257 
2016-12-11 20:14:18 Training Error = 0.60091805049278 
2016-12-11 20:14:18 Training Loss = 0.026734367906302 
2016-12-11 20:14:20 Valid Error = 0.60510328068044 
2016-12-11 20:14:20 Valid Loss = 0.027323673237812 
2016-12-11 20:14:22 Test Error = 0.64192139737991 
2016-12-11 20:14:22 Test Loss = 0.028867435632967 
2016-12-11 20:14:22 -------------------LR------------------- 
2016-12-11 20:14:22 0.00048828125 
2016-12-11 20:14:22 Epoch 258 
2016-12-11 20:15:51 Training Error = 0.60037802079114 
2016-12-11 20:15:51 Training Loss = 0.026640794727315 
2016-12-11 20:15:53 Valid Error = 0.60510328068044 
2016-12-11 20:15:53 Valid Loss = 0.0276493106476 
2016-12-11 20:15:55 Test Error = 0.64192139737991 
2016-12-11 20:15:55 Test Loss = 0.029267548112308 
2016-12-11 20:15:55 -------------------LR------------------- 
2016-12-11 20:15:55 0.00048828125 
2016-12-11 20:15:55 Epoch 259 
2016-12-11 20:17:26 Training Error = 0.59902794653706 
2016-12-11 20:17:26 Training Loss = 0.026659424429358 
2016-12-11 20:17:28 Valid Error = 0.60510328068044 
2016-12-11 20:17:28 Valid Loss = 0.02749349964312 
2016-12-11 20:17:30 Test Error = 0.64192139737991 
2016-12-11 20:17:30 Test Loss = 0.029012620234022 
2016-12-11 20:17:30 -------------------LR------------------- 
2016-12-11 20:17:30 0.00048828125 
2016-12-11 20:17:31 Epoch 260 
2016-12-11 20:19:03 Training Error = 0.5997029836641 
2016-12-11 20:19:03 Training Loss = 0.026542149992728 
2016-12-11 20:19:05 Valid Error = 0.67314702308627 
2016-12-11 20:19:05 Valid Loss = 0.030853437572037 
2016-12-11 20:19:07 Test Error = 0.72598253275109 
2016-12-11 20:19:07 Test Loss = 0.032837336867463 
2016-12-11 20:19:07 -------------------LR------------------- 
2016-12-11 20:19:07 0.00048828125 
2016-12-11 20:19:07 Epoch 261 
2016-12-11 20:20:35 Training Error = 0.59794788713379 
2016-12-11 20:20:35 Training Loss = 0.026633737947694 
2016-12-11 20:20:37 Valid Error = 0.68286755771567 
2016-12-11 20:20:37 Valid Loss = 0.035244097278303 
2016-12-11 20:20:39 Test Error = 0.73580786026201 
2016-12-11 20:20:39 Test Loss = 0.03793492195653 
2016-12-11 20:20:39 -------------------LR------------------- 
2016-12-11 20:20:39 0.00048828125 
2016-12-11 20:20:39 Epoch 262 
2016-12-11 20:22:10 Training Error = 0.60024301336574 
2016-12-11 20:22:10 Training Loss = 0.026718871115748 
2016-12-11 20:22:12 Valid Error = 0.7363304981774 
2016-12-11 20:22:12 Valid Loss = 0.036337539891103 
2016-12-11 20:22:14 Test Error = 0.79039301310044 
2016-12-11 20:22:14 Test Loss = 0.038362812808916 
2016-12-11 20:22:14 -------------------LR------------------- 
2016-12-11 20:22:14 0.00048828125 
2016-12-11 20:22:14 Epoch 263 
2016-12-11 20:23:43 Training Error = 0.60307816929931 
2016-12-11 20:23:43 Training Loss = 0.026740774439252 
2016-12-11 20:23:45 Valid Error = 0.68286755771567 
2016-12-11 20:23:45 Valid Loss = 0.030908855956037 
2016-12-11 20:23:48 Test Error = 0.73580786026201 
2016-12-11 20:23:48 Test Loss = 0.033135565495959 
2016-12-11 20:23:48 -------------------LR------------------- 
2016-12-11 20:23:48 0.00048828125 
2016-12-11 20:23:48 Epoch 264 
2016-12-11 20:25:18 Training Error = 0.60037802079114 
2016-12-11 20:25:18 Training Loss = 0.026694886058875 
2016-12-11 20:25:20 Valid Error = 0.60510328068044 
2016-12-11 20:25:20 Valid Loss = 0.027142593891115 
2016-12-11 20:25:22 Test Error = 0.64192139737991 
2016-12-11 20:25:22 Test Loss = 0.028923536590501 
2016-12-11 20:25:22 -------------------LR------------------- 
2016-12-11 20:25:22 0.00048828125 
2016-12-11 20:25:22 Epoch 265 
2016-12-11 20:26:53 Training Error = 0.59916295396247 
2016-12-11 20:26:53 Training Loss = 0.02680105053842 
2016-12-11 20:26:55 Valid Error = 0.79951397326853 
2016-12-11 20:26:55 Valid Loss = 0.035097824852609 
2016-12-11 20:26:58 Test Error = 0.84497816593886 
2016-12-11 20:26:58 Test Loss = 0.036384796899908 
2016-12-11 20:26:58 -------------------LR------------------- 
2016-12-11 20:26:58 0.00048828125 
2016-12-11 20:26:58 Epoch 266 
2016-12-11 20:28:27 Training Error = 0.59997299851492 
2016-12-11 20:28:27 Training Loss = 0.026844312802839 
2016-12-11 20:28:29 Valid Error = 0.68286755771567 
2016-12-11 20:28:29 Valid Loss = 0.0310557543144 
2016-12-11 20:28:31 Test Error = 0.73580786026201 
2016-12-11 20:28:31 Test Loss = 0.033227231885873 
2016-12-11 20:28:31 -------------------LR------------------- 
2016-12-11 20:28:31 0.00048828125 
2016-12-11 20:28:31 Epoch 267 
2016-12-11 20:30:02 Training Error = 0.60037802079114 
2016-12-11 20:30:02 Training Loss = 0.026675615419304 
2016-12-11 20:30:04 Valid Error = 0.68286755771567 
2016-12-11 20:30:04 Valid Loss = 0.031723753211963 
2016-12-11 20:30:06 Test Error = 0.73580786026201 
2016-12-11 20:30:06 Test Loss = 0.034194155356463 
2016-12-11 20:30:06 -------------------LR------------------- 
2016-12-11 20:30:06 0.00048828125 
2016-12-11 20:30:06 Epoch 268 
2016-12-11 20:31:38 Training Error = 0.60078304306737 
2016-12-11 20:31:38 Training Loss = 0.026874411110473 
2016-12-11 20:31:40 Valid Error = 0.7363304981774 
2016-12-11 20:31:40 Valid Loss = 0.031531966876902 
2016-12-11 20:31:42 Test Error = 0.79039301310044 
2016-12-11 20:31:42 Test Loss = 0.033280961307825 
2016-12-11 20:31:42 -------------------LR------------------- 
2016-12-11 20:31:42 0.00048828125 
2016-12-11 20:31:42 Epoch 269 
2016-12-11 20:33:11 Training Error = 0.60159308761982 
2016-12-11 20:33:11 Training Loss = 0.026791695008692 
2016-12-11 20:33:13 Valid Error = 0.68286755771567 
2016-12-11 20:33:13 Valid Loss = 0.03392065256532 
2016-12-11 20:33:15 Test Error = 0.73580786026201 
2016-12-11 20:33:15 Test Loss = 0.036417381426867 
2016-12-11 20:33:15 -------------------LR------------------- 
2016-12-11 20:33:15 0.00048828125 
2016-12-11 20:33:15 Epoch 270 
2016-12-11 20:34:47 Training Error = 0.60064803564196 
2016-12-11 20:34:47 Training Loss = 0.026727966929773 
2016-12-11 20:34:49 Valid Error = 0.7363304981774 
2016-12-11 20:34:49 Valid Loss = 0.037370849751021 
2016-12-11 20:34:51 Test Error = 0.79039301310044 
2016-12-11 20:34:51 Test Loss = 0.039269143113903 
2016-12-11 20:34:51 -------------------LR------------------- 
2016-12-11 20:34:51 0.00048828125 
2016-12-11 20:34:51 Epoch 271 
2016-12-11 20:36:22 Training Error = 0.59902794653706 
2016-12-11 20:36:22 Training Loss = 0.026673284406333 
2016-12-11 20:36:24 Valid Error = 0.69380315917375 
2016-12-11 20:36:24 Valid Loss = 0.030656537576935 
2016-12-11 20:36:26 Test Error = 0.74454148471616 
2016-12-11 20:36:26 Test Loss = 0.032830868449866 
2016-12-11 20:36:26 -------------------LR------------------- 
2016-12-11 20:36:26 0.00048828125 
2016-12-11 20:36:27 Epoch 272 
2016-12-11 20:37:58 Training Error = 0.60010800594033 
2016-12-11 20:37:58 Training Loss = 0.026649220099213 
2016-12-11 20:38:00 Valid Error = 0.69380315917375 
2016-12-11 20:38:00 Valid Loss = 0.030290080210787 
2016-12-11 20:38:03 Test Error = 0.74454148471616 
2016-12-11 20:38:03 Test Loss = 0.032523910961899 
2016-12-11 20:38:03 -------------------LR------------------- 
2016-12-11 20:38:03 0.00048828125 
2016-12-11 20:38:03 Epoch 273 
2016-12-11 20:39:35 Training Error = 0.60010800594033 
2016-12-11 20:39:35 Training Loss = 0.02674439510057 
2016-12-11 20:39:37 Valid Error = 0.72539489671932 
2016-12-11 20:39:37 Valid Loss = 0.032245760721906 
2016-12-11 20:39:39 Test Error = 0.78165938864629 
2016-12-11 20:39:39 Test Loss = 0.034241421736923 
2016-12-11 20:39:39 -------------------LR------------------- 
2016-12-11 20:39:39 0.00048828125 
2016-12-11 20:39:39 Epoch 274 
2016-12-11 20:41:09 Training Error = 0.60064803564196 
2016-12-11 20:41:09 Training Loss = 0.026509805446023 
2016-12-11 20:41:11 Valid Error = 0.60510328068044 
2016-12-11 20:41:11 Valid Loss = 0.027468164004396 
2016-12-11 20:41:13 Test Error = 0.64192139737991 
2016-12-11 20:41:13 Test Loss = 0.029093664206711 
2016-12-11 20:41:13 -------------------LR------------------- 
2016-12-11 20:41:13 0.00048828125 
2016-12-11 20:41:13 Epoch 275 
2016-12-11 20:42:43 Training Error = 0.59767787228298 
2016-12-11 20:42:43 Training Loss = 0.026712142736326 
2016-12-11 20:42:45 Valid Error = 0.60510328068044 
2016-12-11 20:42:45 Valid Loss = 0.026861069160643 
2016-12-11 20:42:47 Test Error = 0.64192139737991 
2016-12-11 20:42:47 Test Loss = 0.028376571271934 
2016-12-11 20:42:47 -------------------LR------------------- 
2016-12-11 20:42:47 0.00048828125 
2016-12-11 20:42:47 Epoch 276 
2016-12-11 20:44:16 Training Error = 0.60118806534359 
2016-12-11 20:44:16 Training Loss = 0.02681183320659 
2016-12-11 20:44:18 Valid Error = 0.726609963548 
2016-12-11 20:44:18 Valid Loss = 0.031899934801017 
2016-12-11 20:44:20 Test Error = 0.77510917030568 
2016-12-11 20:44:20 Test Loss = 0.033878742339564 
2016-12-11 20:44:20 -------------------LR------------------- 
2016-12-11 20:44:20 0.00048828125 
2016-12-11 20:44:20 Epoch 277 
2016-12-11 20:45:52 Training Error = 0.60145808019441 
2016-12-11 20:45:52 Training Loss = 0.02682665082716 
2016-12-11 20:45:54 Valid Error = 0.72539489671932 
2016-12-11 20:45:54 Valid Loss = 0.032059369966638 
2016-12-11 20:45:56 Test Error = 0.78165938864629 
2016-12-11 20:45:56 Test Loss = 0.034012649087345 
2016-12-11 20:45:56 -------------------LR------------------- 
2016-12-11 20:45:56 0.00048828125 
2016-12-11 20:45:56 Epoch 278 
2016-12-11 20:47:28 Training Error = 0.60064803564196 
2016-12-11 20:47:28 Training Loss = 0.026776856712534 
2016-12-11 20:47:30 Valid Error = 0.68286755771567 
2016-12-11 20:47:30 Valid Loss = 0.034169959158363 
2016-12-11 20:47:32 Test Error = 0.73580786026201 
2016-12-11 20:47:32 Test Loss = 0.036759344110302 
2016-12-11 20:47:32 -------------------LR------------------- 
2016-12-11 20:47:32 0.00048828125 
2016-12-11 20:47:32 Epoch 279 
2016-12-11 20:49:03 Training Error = 0.59997299851492 
2016-12-11 20:49:03 Training Loss = 0.026961427191726 
2016-12-11 20:49:05 Valid Error = 0.726609963548 
2016-12-11 20:49:05 Valid Loss = 0.032182505532536 
2016-12-11 20:49:07 Test Error = 0.77510917030568 
2016-12-11 20:49:07 Test Loss = 0.03395766693003 
2016-12-11 20:49:07 -------------------LR------------------- 
2016-12-11 20:49:07 0.00048828125 
2016-12-11 20:49:07 Epoch 280 
2016-12-11 20:50:37 Training Error = 0.59983799108951 
2016-12-11 20:50:37 Training Loss = 0.026601304965549 
2016-12-11 20:50:39 Valid Error = 0.7363304981774 
2016-12-11 20:50:39 Valid Loss = 0.035606238381524 
2016-12-11 20:50:41 Test Error = 0.79039301310044 
2016-12-11 20:50:41 Test Loss = 0.037428168324863 
2016-12-11 20:50:41 -------------------LR------------------- 
2016-12-11 20:50:41 0.00048828125 
2016-12-11 20:50:41 Epoch 281 
2016-12-11 20:52:11 Training Error = 0.59889293911165 
2016-12-11 20:52:11 Training Loss = 0.026458087334156 
2016-12-11 20:52:13 Valid Error = 0.7363304981774 
2016-12-11 20:52:13 Valid Loss = 0.036717543316981 
2016-12-11 20:52:15 Test Error = 0.79039301310044 
2016-12-11 20:52:15 Test Loss = 0.038932898184832 
2016-12-11 20:52:15 -------------------LR------------------- 
2016-12-11 20:52:15 0.00048828125 
2016-12-11 20:52:15 Epoch 282 
2016-12-11 20:53:46 Training Error = 0.60253813959768 
2016-12-11 20:53:46 Training Loss = 0.026742113940099 
2016-12-11 20:53:48 Valid Error = 0.68286755771567 
2016-12-11 20:53:48 Valid Loss = 0.032497956345589 
2016-12-11 20:53:50 Test Error = 0.73580786026201 
2016-12-11 20:53:50 Test Loss = 0.034984717705671 
2016-12-11 20:53:50 -------------------LR------------------- 
2016-12-11 20:53:50 0.00048828125 
2016-12-11 20:53:50 Epoch 283 
2016-12-11 20:55:21 Training Error = 0.59713784258134 
2016-12-11 20:55:21 Training Loss = 0.026791054440168 
2016-12-11 20:55:23 Valid Error = 0.60510328068044 
2016-12-11 20:55:23 Valid Loss = 0.027439281842672 
2016-12-11 20:55:26 Test Error = 0.64192139737991 
2016-12-11 20:55:26 Test Loss = 0.02878053261252 
2016-12-11 20:55:26 -------------------LR------------------- 
2016-12-11 20:55:26 0.00048828125 
2016-12-11 20:55:26 Epoch 284 
2016-12-11 20:56:57 Training Error = 0.59929796138788 
2016-12-11 20:56:57 Training Loss = 0.026666537918675 
2016-12-11 20:56:59 Valid Error = 0.60510328068044 
2016-12-11 20:56:59 Valid Loss = 0.028458906272895 
2016-12-11 20:57:01 Test Error = 0.64192139737991 
2016-12-11 20:57:01 Test Loss = 0.030379586921019 
2016-12-11 20:57:01 -------------------LR------------------- 
2016-12-11 20:57:01 0.00048828125 
2016-12-11 20:57:01 Epoch 285 
2016-12-11 20:58:33 Training Error = 0.59902794653706 
2016-12-11 20:58:33 Training Loss = 0.026805711946033 
2016-12-11 20:58:35 Valid Error = 0.64763061968408 
2016-12-11 20:58:35 Valid Loss = 0.031403742265643 
2016-12-11 20:58:37 Test Error = 0.68777292576419 
2016-12-11 20:58:37 Test Loss = 0.033487563544629 
2016-12-11 20:58:37 -------------------LR------------------- 
2016-12-11 20:58:37 0.00048828125 
2016-12-11 20:58:37 Epoch 286 
2016-12-11 21:00:05 Training Error = 0.60145808019441 
2016-12-11 21:00:05 Training Loss = 0.026637003867099 
2016-12-11 21:00:07 Valid Error = 0.68286755771567 
2016-12-11 21:00:07 Valid Loss = 0.030112022897833 
2016-12-11 21:00:09 Test Error = 0.73580786026201 
2016-12-11 21:00:09 Test Loss = 0.032145696602616 
2016-12-11 21:00:09 -------------------LR------------------- 
2016-12-11 21:00:09 0.00048828125 
2016-12-11 21:00:09 Epoch 287 
2016-12-11 21:01:40 Training Error = 0.60024301336574 
2016-12-11 21:01:40 Training Loss = 0.026841409717777 
2016-12-11 21:01:42 Valid Error = 0.79951397326853 
2016-12-11 21:01:42 Valid Loss = 0.037975602810769 
2016-12-11 21:01:44 Test Error = 0.84497816593886 
2016-12-11 21:01:44 Test Loss = 0.038950485547384 
2016-12-11 21:01:44 -------------------LR------------------- 
2016-12-11 21:01:44 0.00048828125 
2016-12-11 21:01:44 Epoch 288 
2016-12-11 21:03:16 Training Error = 0.59713784258134 
2016-12-11 21:03:16 Training Loss = 0.026636067846532 
2016-12-11 21:03:18 Valid Error = 0.726609963548 
2016-12-11 21:03:18 Valid Loss = 0.034577404317434 
2016-12-11 21:03:21 Test Error = 0.77510917030568 
2016-12-11 21:03:21 Test Loss = 0.036725951540704 
2016-12-11 21:03:21 -------------------LR------------------- 
2016-12-11 21:03:21 0.00048828125 
2016-12-11 21:03:21 Epoch 289 
2016-12-11 21:04:52 Training Error = 0.60024301336574 
2016-12-11 21:04:52 Training Loss = 0.026742024617057 
2016-12-11 21:04:54 Valid Error = 0.65856622114216 
2016-12-11 21:04:54 Valid Loss = 0.032284368565783 
2016-12-11 21:04:56 Test Error = 0.69650655021834 
2016-12-11 21:04:56 Test Loss = 0.034058424556957 
2016-12-11 21:04:56 -------------------LR------------------- 
2016-12-11 21:04:56 0.00048828125 
2016-12-11 21:04:56 Epoch 290 
2016-12-11 21:06:29 Training Error = 0.60010800594033 
2016-12-11 21:06:29 Training Loss = 0.026746547725332 
2016-12-11 21:06:31 Valid Error = 0.68286755771567 
2016-12-11 21:06:31 Valid Loss = 0.030044388723631 
2016-12-11 21:06:33 Test Error = 0.73580786026201 
2016-12-11 21:06:33 Test Loss = 0.032276215487835 
2016-12-11 21:06:33 -------------------LR------------------- 
2016-12-11 21:06:33 0.00048828125 
2016-12-11 21:06:33 Epoch 291 
2016-12-11 21:07:59 Training Error = 0.59902794653706 
2016-12-11 21:07:59 Training Loss = 0.026667593777013 
2016-12-11 21:08:01 Valid Error = 0.68286755771567 
2016-12-11 21:08:01 Valid Loss = 0.030624828289842 
2016-12-11 21:08:04 Test Error = 0.73580786026201 
2016-12-11 21:08:04 Test Loss = 0.032619995509877 
2016-12-11 21:08:04 -------------------LR------------------- 
2016-12-11 21:08:04 0.00048828125 
2016-12-11 21:08:04 Epoch 292 
2016-12-11 21:09:34 Training Error = 0.60172809504523 
2016-12-11 21:09:34 Training Loss = 0.026771735157686 
2016-12-11 21:09:36 Valid Error = 0.79951397326853 
2016-12-11 21:09:36 Valid Loss = 0.038688165798912 
2016-12-11 21:09:39 Test Error = 0.84497816593886 
2016-12-11 21:09:39 Test Loss = 0.039529771262524 
2016-12-11 21:09:39 -------------------LR------------------- 
2016-12-11 21:09:39 0.00048828125 
2016-12-11 21:09:39 Epoch 293 
2016-12-11 21:11:10 Training Error = 0.60199810989604 
2016-12-11 21:11:10 Training Loss = 0.026785468433996 
2016-12-11 21:11:12 Valid Error = 0.59538274605103 
2016-12-11 21:11:12 Valid Loss = 0.027147765228714 
2016-12-11 21:11:14 Test Error = 0.632096069869 
2016-12-11 21:11:14 Test Loss = 0.028637602993086 
2016-12-11 21:11:14 -------------------LR------------------- 
2016-12-11 21:11:14 0.00048828125 
2016-12-11 21:11:14 Epoch 294 
2016-12-11 21:12:44 Training Error = 0.59875793168624 
2016-12-11 21:12:44 Training Loss = 0.026585151860427 
2016-12-11 21:12:46 Valid Error = 0.67314702308627 
2016-12-11 21:12:46 Valid Loss = 0.030581111541196 
2016-12-11 21:12:48 Test Error = 0.72598253275109 
2016-12-11 21:12:48 Test Loss = 0.032885409878749 
2016-12-11 21:12:48 -------------------LR------------------- 
2016-12-11 21:12:48 0.00048828125 
2016-12-11 21:12:48 Epoch 295 
2016-12-11 21:14:19 Training Error = 0.59875793168624 
2016-12-11 21:14:19 Training Loss = 0.026796709672232 
2016-12-11 21:14:21 Valid Error = 0.79951397326853 
2016-12-11 21:14:21 Valid Loss = 0.035838945798376 
2016-12-11 21:14:23 Test Error = 0.84497816593886 
2016-12-11 21:14:23 Test Loss = 0.03729149500529 
2016-12-11 21:14:23 -------------------LR------------------- 
2016-12-11 21:14:23 0.00048828125 
2016-12-11 21:14:23 Epoch 296 
2016-12-11 21:15:52 Training Error = 0.59983799108951 
2016-12-11 21:15:52 Training Loss = 0.026789910103649 
2016-12-11 21:15:54 Valid Error = 0.7363304981774 
2016-12-11 21:15:54 Valid Loss = 0.033527075913951 
2016-12-11 21:15:56 Test Error = 0.79039301310044 
2016-12-11 21:15:56 Test Loss = 0.035399980554394 
2016-12-11 21:15:56 -------------------LR------------------- 
2016-12-11 21:15:56 0.00048828125 
2016-12-11 21:15:56 Epoch 297 
2016-12-11 21:17:25 Training Error = 0.60024301336574 
2016-12-11 21:17:25 Training Loss = 0.026899905238788 
2016-12-11 21:17:27 Valid Error = 0.79951397326853 
2016-12-11 21:17:27 Valid Loss = 0.036787768132061 
2016-12-11 21:17:29 Test Error = 0.84497816593886 
2016-12-11 21:17:29 Test Loss = 0.037951371118134 
2016-12-11 21:17:29 -------------------LR------------------- 
2016-12-11 21:17:29 0.00048828125 
2016-12-11 21:17:29 Epoch 298 
2016-12-11 21:18:59 Training Error = 0.59956797623869 
2016-12-11 21:18:59 Training Loss = 0.026632098818938 
2016-12-11 21:19:01 Valid Error = 0.7363304981774 
2016-12-11 21:19:01 Valid Loss = 0.033261681661762 
2016-12-11 21:19:03 Test Error = 0.79039301310044 
2016-12-11 21:19:03 Test Loss = 0.035245754298042 
2016-12-11 21:19:03 -------------------LR------------------- 
2016-12-11 21:19:03 0.00048828125 
2016-12-11 21:19:03 Epoch 299 
2016-12-11 21:20:33 Training Error = 0.59862292426083 
2016-12-11 21:20:33 Training Loss = 0.02676449638673 
2016-12-11 21:20:35 Valid Error = 0.68286755771567 
2016-12-11 21:20:35 Valid Loss = 0.031147022527355 
2016-12-11 21:20:37 Test Error = 0.73580786026201 
2016-12-11 21:20:37 Test Loss = 0.033288585083157 
2016-12-11 21:20:37 -------------------LR------------------- 
2016-12-11 21:20:37 0.00048828125 
2016-12-11 21:20:37 Epoch 300 
2016-12-11 21:22:09 Training Error = 0.59767787228298 
2016-12-11 21:22:09 Training Loss = 0.026728991533951 
2016-12-11 21:22:11 Valid Error = 0.7363304981774 
2016-12-11 21:22:11 Valid Loss = 0.034174514081066 
2016-12-11 21:22:13 Test Error = 0.79039301310044 
2016-12-11 21:22:13 Test Loss = 0.036063114839442 
2016-12-11 21:22:13 -------------------LR------------------- 
2016-12-11 21:22:13 0.000244140625 
2016-12-11 21:22:13 Epoch 301 
2016-12-11 21:23:42 Training Error = 0.5997029836641 
2016-12-11 21:23:42 Training Loss = 0.026834460024651 
2016-12-11 21:23:44 Valid Error = 0.79951397326853 
2016-12-11 21:23:44 Valid Loss = 0.036036899657347 
2016-12-11 21:23:47 Test Error = 0.84497816593886 
2016-12-11 21:23:47 Test Loss = 0.037278835633222 
2016-12-11 21:23:47 -------------------LR------------------- 
2016-12-11 21:23:47 0.000244140625 
2016-12-11 21:23:47 Epoch 302 
2016-12-11 21:25:15 Training Error = 0.601323072769 
2016-12-11 21:25:15 Training Loss = 0.026815062856808 
2016-12-11 21:25:17 Valid Error = 0.69380315917375 
2016-12-11 21:25:17 Valid Loss = 0.030664508064735 
2016-12-11 21:25:20 Test Error = 0.74454148471616 
2016-12-11 21:25:20 Test Loss = 0.032841322160235 
2016-12-11 21:25:20 -------------------LR------------------- 
2016-12-11 21:25:20 0.000244140625 
2016-12-11 21:25:20 Epoch 303 
2016-12-11 21:26:51 Training Error = 0.60024301336574 
2016-12-11 21:26:51 Training Loss = 0.026664242216051 
2016-12-11 21:26:53 Valid Error = 0.68286755771567 
2016-12-11 21:26:53 Valid Loss = 0.031998098275308 
2016-12-11 21:26:56 Test Error = 0.73580786026201 
2016-12-11 21:26:56 Test Loss = 0.034298784798267 
2016-12-11 21:26:56 -------------------LR------------------- 
2016-12-11 21:26:56 0.000244140625 
2016-12-11 21:26:56 Epoch 304 
2016-12-11 21:28:26 Training Error = 0.59997299851492 
2016-12-11 21:28:26 Training Loss = 0.026733584429459 
2016-12-11 21:28:28 Valid Error = 0.75698663426488 
2016-12-11 21:28:28 Valid Loss = 0.031957309177634 
2016-12-11 21:28:30 Test Error = 0.79912663755459 
2016-12-11 21:28:30 Test Loss = 0.033564586592656 
2016-12-11 21:28:30 -------------------LR------------------- 
2016-12-11 21:28:30 0.000244140625 
2016-12-11 21:28:30 Epoch 305 
2016-12-11 21:30:00 Training Error = 0.59875793168624 
2016-12-11 21:30:00 Training Loss = 0.026697680267989 
2016-12-11 21:30:02 Valid Error = 0.68286755771567 
2016-12-11 21:30:02 Valid Loss = 0.031041094285019 
2016-12-11 21:30:04 Test Error = 0.73580786026201 
2016-12-11 21:30:04 Test Loss = 0.033300728442622 
2016-12-11 21:30:04 -------------------LR------------------- 
2016-12-11 21:30:04 0.000244140625 
2016-12-11 21:30:04 Epoch 306 
2016-12-11 21:31:34 Training Error = 0.60051302821655 
2016-12-11 21:31:34 Training Loss = 0.026675029119924 
2016-12-11 21:31:36 Valid Error = 0.68286755771567 
2016-12-11 21:31:36 Valid Loss = 0.030861784340679 
2016-12-11 21:31:38 Test Error = 0.73580786026201 
2016-12-11 21:31:38 Test Loss = 0.032855573915968 
2016-12-11 21:31:38 -------------------LR------------------- 
2016-12-11 21:31:38 0.000244140625 
2016-12-11 21:31:38 Epoch 307 
2016-12-11 21:33:07 Training Error = 0.60037802079114 
2016-12-11 21:33:07 Training Loss = 0.026687951000509 
2016-12-11 21:33:09 Valid Error = 0.60510328068044 
2016-12-11 21:33:09 Valid Loss = 0.027033870025285 
2016-12-11 21:33:11 Test Error = 0.64192139737991 
2016-12-11 21:33:11 Test Loss = 0.02856496033014 
2016-12-11 21:33:11 -------------------LR------------------- 
2016-12-11 21:33:11 0.000244140625 
2016-12-11 21:33:11 Epoch 308 
2016-12-11 21:34:39 Training Error = 0.59794788713379 
2016-12-11 21:34:39 Training Loss = 0.026523699278702 
2016-12-11 21:34:41 Valid Error = 0.7363304981774 
2016-12-11 21:34:41 Valid Loss = 0.034575952036855 
2016-12-11 21:34:43 Test Error = 0.79039301310044 
2016-12-11 21:34:43 Test Loss = 0.036552924810671 
2016-12-11 21:34:43 -------------------LR------------------- 
2016-12-11 21:34:43 0.000244140625 
2016-12-11 21:34:43 Epoch 309 
2016-12-11 21:36:13 Training Error = 0.59916295396247 
2016-12-11 21:36:13 Training Loss = 0.026750278564795 
2016-12-11 21:36:15 Valid Error = 0.68286755771567 
2016-12-11 21:36:15 Valid Loss = 0.034403051289801 
2016-12-11 21:36:17 Test Error = 0.73580786026201 
2016-12-11 21:36:17 Test Loss = 0.036975775849585 
2016-12-11 21:36:17 -------------------LR------------------- 
2016-12-11 21:36:17 0.000244140625 
2016-12-11 21:36:17 Epoch 310 
2016-12-11 21:37:50 Training Error = 0.59956797623869 
2016-12-11 21:37:50 Training Loss = 0.026719273714124 
2016-12-11 21:37:52 Valid Error = 0.60510328068044 
2016-12-11 21:37:52 Valid Loss = 0.027417580121347 
2016-12-11 21:37:54 Test Error = 0.64192139737991 
2016-12-11 21:37:54 Test Loss = 0.02876727328581 
2016-12-11 21:37:54 -------------------LR------------------- 
2016-12-11 21:37:54 0.000244140625 
2016-12-11 21:37:54 Epoch 311 
2016-12-11 21:39:24 Training Error = 0.60078304306737 
2016-12-11 21:39:24 Training Loss = 0.026769414116355 
2016-12-11 21:39:26 Valid Error = 0.79951397326853 
2016-12-11 21:39:26 Valid Loss = 0.037238291937078 
2016-12-11 21:39:29 Test Error = 0.84497816593886 
2016-12-11 21:39:29 Test Loss = 0.038210970467212 
2016-12-11 21:39:29 -------------------LR------------------- 
2016-12-11 21:39:29 0.000244140625 
2016-12-11 21:39:29 Epoch 312 
2016-12-11 21:41:00 Training Error = 0.60064803564196 
2016-12-11 21:41:00 Training Loss = 0.026700985002562 
2016-12-11 21:41:02 Valid Error = 0.68286755771567 
2016-12-11 21:41:02 Valid Loss = 0.030571641335718 
2016-12-11 21:41:04 Test Error = 0.73580786026201 
2016-12-11 21:41:04 Test Loss = 0.032603152190938 
2016-12-11 21:41:04 -------------------LR------------------- 
2016-12-11 21:41:04 0.000244140625 
2016-12-11 21:41:04 Epoch 313 
2016-12-11 21:42:34 Training Error = 0.60186310247064 
2016-12-11 21:42:34 Training Loss = 0.026550952205426 
2016-12-11 21:42:36 Valid Error = 0.67314702308627 
2016-12-11 21:42:36 Valid Loss = 0.030337503268274 
2016-12-11 21:42:39 Test Error = 0.72598253275109 
2016-12-11 21:42:39 Test Loss = 0.032505574104833 
2016-12-11 21:42:39 -------------------LR------------------- 
2016-12-11 21:42:39 0.000244140625 
2016-12-11 21:42:39 Epoch 314 
2016-12-11 21:44:10 Training Error = 0.60064803564196 
2016-12-11 21:44:10 Training Loss = 0.026514690201846 
2016-12-11 21:44:12 Valid Error = 0.7363304981774 
2016-12-11 21:44:12 Valid Loss = 0.034040815565321 
2016-12-11 21:44:14 Test Error = 0.79039301310044 
2016-12-11 21:44:14 Test Loss = 0.036074034718906 
2016-12-11 21:44:14 -------------------LR------------------- 
2016-12-11 21:44:14 0.000244140625 
2016-12-11 21:44:14 Epoch 315 
2016-12-11 21:45:43 Training Error = 0.60037802079114 
2016-12-11 21:45:43 Training Loss = 0.02659243986128 
2016-12-11 21:45:45 Valid Error = 0.68286755771567 
2016-12-11 21:45:45 Valid Loss = 0.030455859698185 
2016-12-11 21:45:47 Test Error = 0.73580786026201 
2016-12-11 21:45:47 Test Loss = 0.032458864735622 
2016-12-11 21:45:47 -------------------LR------------------- 
2016-12-11 21:45:47 0.000244140625 
2016-12-11 21:45:47 Epoch 316 
2016-12-11 21:47:18 Training Error = 0.60037802079114 
2016-12-11 21:47:18 Training Loss = 0.026879136351399 
2016-12-11 21:47:20 Valid Error = 0.79951397326853 
2016-12-11 21:47:20 Valid Loss = 0.037792295799389 
2016-12-11 21:47:23 Test Error = 0.84497816593886 
2016-12-11 21:47:23 Test Loss = 0.038650396328346 
2016-12-11 21:47:23 -------------------LR------------------- 
2016-12-11 21:47:23 0.000244140625 
2016-12-11 21:47:23 Epoch 317 
2016-12-11 21:48:54 Training Error = 0.59983799108951 
2016-12-11 21:48:54 Training Loss = 0.026784890560432 
2016-12-11 21:48:56 Valid Error = 0.79951397326853 
2016-12-11 21:48:56 Valid Loss = 0.036546692417756 
2016-12-11 21:48:58 Test Error = 0.84497816593886 
2016-12-11 21:48:58 Test Loss = 0.03780832194347 
2016-12-11 21:48:58 -------------------LR------------------- 
2016-12-11 21:48:58 0.000244140625 
2016-12-11 21:48:58 Epoch 318 
2016-12-11 21:50:26 Training Error = 0.60037802079114 
2016-12-11 21:50:26 Training Loss = 0.026815638108881 
2016-12-11 21:50:28 Valid Error = 0.68286755771567 
2016-12-11 21:50:28 Valid Loss = 0.033931601581174 
2016-12-11 21:50:30 Test Error = 0.73580786026201 
2016-12-11 21:50:30 Test Loss = 0.036519395463607 
2016-12-11 21:50:30 -------------------LR------------------- 
2016-12-11 21:50:30 0.000244140625 
2016-12-11 21:50:30 Epoch 319 
2016-12-11 21:52:01 Training Error = 0.59943296881328 
2016-12-11 21:52:01 Training Loss = 0.026588412509779 
2016-12-11 21:52:03 Valid Error = 0.7363304981774 
2016-12-11 21:52:03 Valid Loss = 0.033716651083247 
2016-12-11 21:52:06 Test Error = 0.79039301310044 
2016-12-11 21:52:06 Test Loss = 0.035701049870136 
2016-12-11 21:52:06 -------------------LR------------------- 
2016-12-11 21:52:06 0.000244140625 
2016-12-11 21:52:06 Epoch 320 
2016-12-11 21:53:37 Training Error = 0.59767787228298 
2016-12-11 21:53:37 Training Loss = 0.026761263624916 
2016-12-11 21:53:40 Valid Error = 0.7363304981774 
2016-12-11 21:53:40 Valid Loss = 0.032065812132852 
2016-12-11 21:53:42 Test Error = 0.79039301310044 
2016-12-11 21:53:42 Test Loss = 0.033994723048865 
2016-12-11 21:53:42 -------------------LR------------------- 
2016-12-11 21:53:42 0.000244140625 
2016-12-11 21:53:42 Epoch 321 
2016-12-11 21:55:12 Training Error = 0.59889293911165 
2016-12-11 21:55:12 Training Loss = 0.026699793420786 
2016-12-11 21:55:14 Valid Error = 0.60510328068044 
2016-12-11 21:55:14 Valid Loss = 0.028945594997899 
2016-12-11 21:55:17 Test Error = 0.64192139737991 
2016-12-11 21:55:17 Test Loss = 0.030760875842151 
2016-12-11 21:55:17 -------------------LR------------------- 
2016-12-11 21:55:17 0.000244140625 
2016-12-11 21:55:17 Epoch 322 
2016-12-11 21:56:45 Training Error = 0.59956797623869 
2016-12-11 21:56:45 Training Loss = 0.026740353352238 
2016-12-11 21:56:47 Valid Error = 0.79951397326853 
2016-12-11 21:56:47 Valid Loss = 0.038325410224818 
2016-12-11 21:56:50 Test Error = 0.84497816593886 
2016-12-11 21:56:50 Test Loss = 0.039164834733103 
2016-12-11 21:56:50 -------------------LR------------------- 
2016-12-11 21:56:50 0.000244140625 
2016-12-11 21:56:50 Epoch 323 
2016-12-11 21:58:21 Training Error = 0.60024301336574 
2016-12-11 21:58:21 Training Loss = 0.026628097549852 
2016-12-11 21:58:23 Valid Error = 0.79951397326853 
2016-12-11 21:58:23 Valid Loss = 0.036738095722088 
2016-12-11 21:58:25 Test Error = 0.84497816593886 
2016-12-11 21:58:25 Test Loss = 0.038012198438831 
2016-12-11 21:58:25 -------------------LR------------------- 
2016-12-11 21:58:25 0.000244140625 
2016-12-11 21:58:25 Epoch 324 
2016-12-11 21:59:54 Training Error = 0.59821790198461 
2016-12-11 21:59:54 Training Loss = 0.026760521396669 
2016-12-11 21:59:56 Valid Error = 0.60510328068044 
2016-12-11 21:59:56 Valid Loss = 0.027198508066515 
2016-12-11 21:59:58 Test Error = 0.64192139737991 
2016-12-11 21:59:58 Test Loss = 0.028837585720361 
2016-12-11 21:59:58 -------------------LR------------------- 
2016-12-11 21:59:58 0.000244140625 
2016-12-11 21:59:58 Epoch 325 
2016-12-11 22:01:26 Training Error = 0.59713784258134 
2016-12-11 22:01:26 Training Loss = 0.02677595198317 
2016-12-11 22:01:28 Valid Error = 0.68286755771567 
2016-12-11 22:01:28 Valid Loss = 0.03201856783171 
2016-12-11 22:01:31 Test Error = 0.73580786026201 
2016-12-11 22:01:31 Test Loss = 0.034671256588955 
2016-12-11 22:01:31 -------------------LR------------------- 
2016-12-11 22:01:31 0.000244140625 
2016-12-11 22:01:31 Epoch 326 
2016-12-11 22:03:04 Training Error = 0.60159308761982 
2016-12-11 22:03:04 Training Loss = 0.026696727957133 
2016-12-11 22:03:06 Valid Error = 0.60510328068044 
2016-12-11 22:03:06 Valid Loss = 0.028914337382236 
2016-12-11 22:03:09 Test Error = 0.64192139737991 
2016-12-11 22:03:09 Test Loss = 0.03064674280204 
2016-12-11 22:03:09 -------------------LR------------------- 
2016-12-11 22:03:09 0.000244140625 
2016-12-11 22:03:09 Epoch 327 
2016-12-11 22:04:41 Training Error = 0.59997299851492 
2016-12-11 22:04:41 Training Loss = 0.026740926360372 
2016-12-11 22:04:43 Valid Error = 0.68286755771567 
2016-12-11 22:04:43 Valid Loss = 0.033884819603852 
2016-12-11 22:04:45 Test Error = 0.73580786026201 
2016-12-11 22:04:45 Test Loss = 0.036394570911632 
2016-12-11 22:04:45 -------------------LR------------------- 
2016-12-11 22:04:45 0.000244140625 
2016-12-11 22:04:45 Epoch 328 
2016-12-11 22:06:15 Training Error = 0.59956797623869 
2016-12-11 22:06:15 Training Loss = 0.026626721922289 
2016-12-11 22:06:17 Valid Error = 0.68286755771567 
2016-12-11 22:06:17 Valid Loss = 0.031020362451468 
2016-12-11 22:06:20 Test Error = 0.73580786026201 
2016-12-11 22:06:20 Test Loss = 0.033153599673626 
2016-12-11 22:06:20 -------------------LR------------------- 
2016-12-11 22:06:20 0.000244140625 
2016-12-11 22:06:20 Epoch 329 
2016-12-11 22:07:50 Training Error = 0.59767787228298 
2016-12-11 22:07:50 Training Loss = 0.026741661640242 
2016-12-11 22:07:52 Valid Error = 0.60510328068044 
2016-12-11 22:07:52 Valid Loss = 0.027452807840642 
2016-12-11 22:07:54 Test Error = 0.64192139737991 
2016-12-11 22:07:54 Test Loss = 0.028947648777681 
2016-12-11 22:07:54 -------------------LR------------------- 
2016-12-11 22:07:54 0.000244140625 
2016-12-11 22:07:54 Epoch 330 
2016-12-11 22:09:25 Training Error = 0.59929796138788 
2016-12-11 22:09:25 Training Loss = 0.026750176177038 
2016-12-11 22:09:27 Valid Error = 0.59538274605103 
2016-12-11 22:09:27 Valid Loss = 0.028619014577025 
2016-12-11 22:09:29 Test Error = 0.62663755458515 
2016-12-11 22:09:29 Test Loss = 0.030341339550766 
2016-12-11 22:09:29 -------------------LR------------------- 
2016-12-11 22:09:29 0.000244140625 
2016-12-11 22:09:29 Epoch 331 
2016-12-11 22:11:00 Training Error = 0.60118806534359 
2016-12-11 22:11:00 Training Loss = 0.026823117980102 
2016-12-11 22:11:02 Valid Error = 0.60510328068044 
2016-12-11 22:11:02 Valid Loss = 0.027148583482542 
2016-12-11 22:11:05 Test Error = 0.64192139737991 
2016-12-11 22:11:05 Test Loss = 0.028634190493939 
2016-12-11 22:11:05 -------------------LR------------------- 
2016-12-11 22:11:05 0.000244140625 
2016-12-11 22:11:05 Epoch 332 
2016-12-11 22:12:34 Training Error = 0.60078304306737 
2016-12-11 22:12:34 Training Loss = 0.026751147421045 
2016-12-11 22:12:36 Valid Error = 0.7363304981774 
2016-12-11 22:12:36 Valid Loss = 0.035066061306262 
2016-12-11 22:12:38 Test Error = 0.79039301310044 
2016-12-11 22:12:38 Test Loss = 0.036623612272973 
2016-12-11 22:12:38 -------------------LR------------------- 
2016-12-11 22:12:38 0.000244140625 
2016-12-11 22:12:38 Epoch 333 
2016-12-11 22:14:09 Training Error = 0.59875793168624 
2016-12-11 22:14:09 Training Loss = 0.026768810962495 
2016-12-11 22:14:11 Valid Error = 0.68286755771567 
2016-12-11 22:14:11 Valid Loss = 0.03463108245945 
2016-12-11 22:14:13 Test Error = 0.73580786026201 
2016-12-11 22:14:13 Test Loss = 0.037210997918073 
2016-12-11 22:14:13 -------------------LR------------------- 
2016-12-11 22:14:13 0.000244140625 
2016-12-11 22:14:13 Epoch 334 
2016-12-11 22:15:46 Training Error = 0.60145808019441 
2016-12-11 22:15:46 Training Loss = 0.02684243540047 
2016-12-11 22:15:48 Valid Error = 0.73025516403402 
2016-12-11 22:15:48 Valid Loss = 0.031950204901096 
2016-12-11 22:15:50 Test Error = 0.78165938864629 
2016-12-11 22:15:50 Test Loss = 0.034113844282487 
2016-12-11 22:15:50 -------------------LR------------------- 
2016-12-11 22:15:50 0.000244140625 
2016-12-11 22:15:50 Epoch 335 
2016-12-11 22:17:16 Training Error = 0.59754286485757 
2016-12-11 22:17:16 Training Loss = 0.026807348966198 
2016-12-11 22:17:18 Valid Error = 0.65856622114216 
2016-12-11 22:17:18 Valid Loss = 0.031675383616682 
2016-12-11 22:17:20 Test Error = 0.69650655021834 
2016-12-11 22:17:20 Test Loss = 0.033455888477026 
2016-12-11 22:17:20 -------------------LR------------------- 
2016-12-11 22:17:20 0.000244140625 
2016-12-11 22:17:20 Epoch 336 
2016-12-11 22:18:51 Training Error = 0.59875793168624 
2016-12-11 22:18:51 Training Loss = 0.026777442427777 
2016-12-11 22:18:53 Valid Error = 0.79951397326853 
2016-12-11 22:18:53 Valid Loss = 0.038613148637146 
2016-12-11 22:18:55 Test Error = 0.84497816593886 
2016-12-11 22:18:55 Test Loss = 0.039392695707433 
2016-12-11 22:18:55 -------------------LR------------------- 
2016-12-11 22:18:55 0.000244140625 
2016-12-11 22:18:55 Epoch 337 
2016-12-11 22:20:25 Training Error = 0.60118806534359 
2016-12-11 22:20:25 Training Loss = 0.026664803047073 
2016-12-11 22:20:27 Valid Error = 0.60510328068044 
2016-12-11 22:20:27 Valid Loss = 0.027187341117516 
2016-12-11 22:20:30 Test Error = 0.64192139737991 
2016-12-11 22:20:30 Test Loss = 0.028578226641113 
2016-12-11 22:20:30 -------------------LR------------------- 
2016-12-11 22:20:30 0.000244140625 
2016-12-11 22:20:30 Epoch 338 
2016-12-11 22:22:01 Training Error = 0.59740785743216 
2016-12-11 22:22:01 Training Loss = 0.02669414322512 
2016-12-11 22:22:03 Valid Error = 0.7363304981774 
2016-12-11 22:22:03 Valid Loss = 0.033678332154719 
2016-12-11 22:22:05 Test Error = 0.79039301310044 
2016-12-11 22:22:05 Test Loss = 0.035493279728235 
2016-12-11 22:22:05 -------------------LR------------------- 
2016-12-11 22:22:05 0.000244140625 
2016-12-11 22:22:05 Epoch 339 
2016-12-11 22:23:35 Training Error = 0.59983799108951 
2016-12-11 22:23:35 Training Loss = 0.026945801855492 
2016-12-11 22:23:37 Valid Error = 0.60510328068044 
2016-12-11 22:23:37 Valid Loss = 0.027388983427761 
2016-12-11 22:23:39 Test Error = 0.64192139737991 
2016-12-11 22:23:39 Test Loss = 0.029005903122472 
2016-12-11 22:23:39 -------------------LR------------------- 
2016-12-11 22:23:39 0.000244140625 
2016-12-11 22:23:39 Epoch 340 
2016-12-11 22:25:08 Training Error = 0.59916295396247 
2016-12-11 22:25:08 Training Loss = 0.026559698675816 
2016-12-11 22:25:10 Valid Error = 0.69380315917375 
2016-12-11 22:25:10 Valid Loss = 0.034359971299659 
2016-12-11 22:25:12 Test Error = 0.74454148471616 
2016-12-11 22:25:12 Test Loss = 0.037174361584233 
2016-12-11 22:25:12 -------------------LR------------------- 
2016-12-11 22:25:12 0.000244140625 
2016-12-11 22:25:12 Epoch 341 
2016-12-11 22:26:42 Training Error = 0.59686782773053 
2016-12-11 22:26:42 Training Loss = 0.026558283190189 
2016-12-11 22:26:44 Valid Error = 0.78979343863913 
2016-12-11 22:26:44 Valid Loss = 0.036993960725366 
2016-12-11 22:26:46 Test Error = 0.8296943231441 
2016-12-11 22:26:46 Test Loss = 0.038141026122897 
2016-12-11 22:26:46 -------------------LR------------------- 
2016-12-11 22:26:46 0.000244140625 
2016-12-11 22:26:46 Epoch 342 
2016-12-11 22:28:16 Training Error = 0.59902794653706 
2016-12-11 22:28:16 Training Loss = 0.026744076986874 
2016-12-11 22:28:18 Valid Error = 0.60510328068044 
2016-12-11 22:28:18 Valid Loss = 0.027661568534253 
2016-12-11 22:28:20 Test Error = 0.64192139737991 
2016-12-11 22:28:20 Test Loss = 0.029259753844317 
2016-12-11 22:28:20 -------------------LR------------------- 
2016-12-11 22:28:20 0.000244140625 
2016-12-11 22:28:20 Epoch 343 
2016-12-11 22:29:52 Training Error = 0.59916295396247 
2016-12-11 22:29:52 Training Loss = 0.026609848207675 
2016-12-11 22:29:54 Valid Error = 0.60510328068044 
2016-12-11 22:29:54 Valid Loss = 0.027150853373759 
2016-12-11 22:29:56 Test Error = 0.64192139737991 
2016-12-11 22:29:56 Test Loss = 0.028788102402407 
2016-12-11 22:29:56 -------------------LR------------------- 
2016-12-11 22:29:56 0.000244140625 
2016-12-11 22:29:56 Epoch 344 
2016-12-11 22:31:27 Training Error = 0.60091805049278 
2016-12-11 22:31:27 Training Loss = 0.026731059638414 
2016-12-11 22:31:29 Valid Error = 0.60510328068044 
2016-12-11 22:31:29 Valid Loss = 0.027543766259854 
2016-12-11 22:31:31 Test Error = 0.64192139737991 
2016-12-11 22:31:31 Test Loss = 0.029149628115635 
2016-12-11 22:31:31 -------------------LR------------------- 
2016-12-11 22:31:31 0.000244140625 
2016-12-11 22:31:31 Epoch 345 
2016-12-11 22:32:59 Training Error = 0.59997299851492 
2016-12-11 22:32:59 Training Loss = 0.026717884330856 
2016-12-11 22:33:01 Valid Error = 0.60510328068044 
2016-12-11 22:33:01 Valid Loss = 0.026949216006685 
2016-12-11 22:33:04 Test Error = 0.64192139737991 
2016-12-11 22:33:04 Test Loss = 0.028520305390451 
2016-12-11 22:33:04 -------------------LR------------------- 
2016-12-11 22:33:04 0.000244140625 
2016-12-11 22:33:04 Epoch 346 
2016-12-11 22:34:34 Training Error = 0.59889293911165 
2016-12-11 22:34:34 Training Loss = 0.026770843622687 
2016-12-11 22:34:36 Valid Error = 0.79951397326853 
2016-12-11 22:34:36 Valid Loss = 0.038038525550194 
2016-12-11 22:34:38 Test Error = 0.84497816593886 
2016-12-11 22:34:38 Test Loss = 0.038885769956252 
2016-12-11 22:34:38 -------------------LR------------------- 
2016-12-11 22:34:38 0.000244140625 
2016-12-11 22:34:38 Epoch 347 
2016-12-11 22:36:09 Training Error = 0.59997299851492 
2016-12-11 22:36:09 Training Loss = 0.02664884732315 
2016-12-11 22:36:11 Valid Error = 0.68286755771567 
2016-12-11 22:36:11 Valid Loss = 0.032932094361866 
2016-12-11 22:36:14 Test Error = 0.73580786026201 
2016-12-11 22:36:14 Test Loss = 0.03544597046048 
2016-12-11 22:36:14 -------------------LR------------------- 
2016-12-11 22:36:14 0.000244140625 
2016-12-11 22:36:14 Epoch 348 
2016-12-11 22:37:45 Training Error = 0.60118806534359 
2016-12-11 22:37:45 Training Loss = 0.026956529442425 
2016-12-11 22:37:47 Valid Error = 0.79951397326853 
2016-12-11 22:37:47 Valid Loss = 0.03582385812687 
2016-12-11 22:37:49 Test Error = 0.84497816593886 
2016-12-11 22:37:49 Test Loss = 0.037339868779276 
2016-12-11 22:37:49 -------------------LR------------------- 
2016-12-11 22:37:49 0.000244140625 
2016-12-11 22:37:49 Epoch 349 
2016-12-11 22:39:18 Training Error = 0.59821790198461 
2016-12-11 22:39:18 Training Loss = 0.026631125329567 
2016-12-11 22:39:20 Valid Error = 0.69380315917375 
2016-12-11 22:39:20 Valid Loss = 0.030203821598337 
2016-12-11 22:39:23 Test Error = 0.74454148471616 
2016-12-11 22:39:23 Test Loss = 0.032556033471051 
2016-12-11 22:39:23 -------------------LR------------------- 
2016-12-11 22:39:23 0.000244140625 
2016-12-11 22:39:23 Epoch 350 
2016-12-11 22:40:54 Training Error = 0.60037802079114 
2016-12-11 22:40:54 Training Loss = 0.026706329502423 
2016-12-11 22:40:56 Valid Error = 0.60510328068044 
2016-12-11 22:40:56 Valid Loss = 0.028005954048292 
2016-12-11 22:40:58 Test Error = 0.64192139737991 
2016-12-11 22:40:58 Test Loss = 0.029509448621787 
2016-12-11 22:40:58 -------------------LR------------------- 
2016-12-11 22:40:58 0.0001220703125 
2016-12-11 22:40:58 Epoch 351 
2016-12-11 22:42:28 Training Error = 0.60078304306737 
2016-12-11 22:42:28 Training Loss = 0.026690398440463 
2016-12-11 22:42:30 Valid Error = 0.726609963548 
2016-12-11 22:42:30 Valid Loss = 0.033106510805183 
2016-12-11 22:42:32 Test Error = 0.77510917030568 
2016-12-11 22:42:32 Test Loss = 0.035167025902692 
2016-12-11 22:42:32 -------------------LR------------------- 
2016-12-11 22:42:32 0.0001220703125 
2016-12-11 22:42:32 Epoch 352 
2016-12-11 22:44:00 Training Error = 0.59983799108951 
2016-12-11 22:44:00 Training Loss = 0.026711462050437 
2016-12-11 22:44:02 Valid Error = 0.7363304981774 
2016-12-11 22:44:02 Valid Loss = 0.031785591402277 
2016-12-11 22:44:05 Test Error = 0.79039301310044 
2016-12-11 22:44:05 Test Loss = 0.033918119159399 
2016-12-11 22:44:05 -------------------LR------------------- 
2016-12-11 22:44:05 0.0001220703125 
2016-12-11 22:44:05 Epoch 353 
2016-12-11 22:45:37 Training Error = 0.59902794653706 
2016-12-11 22:45:37 Training Loss = 0.026750477765366 
2016-12-11 22:45:39 Valid Error = 0.68408262454435 
2016-12-11 22:45:39 Valid Loss = 0.030705985246062 
2016-12-11 22:45:41 Test Error = 0.73471615720524 
2016-12-11 22:45:41 Test Loss = 0.033120989724702 
2016-12-11 22:45:41 -------------------LR------------------- 
2016-12-11 22:45:41 0.0001220703125 
2016-12-11 22:45:41 Epoch 354 
2016-12-11 22:47:12 Training Error = 0.59956797623869 
2016-12-11 22:47:12 Training Loss = 0.026669140310136 
2016-12-11 22:47:14 Valid Error = 0.60510328068044 
2016-12-11 22:47:14 Valid Loss = 0.027259761155911 
2016-12-11 22:47:16 Test Error = 0.64192139737991 
2016-12-11 22:47:16 Test Loss = 0.028895611706902 
2016-12-11 22:47:16 -------------------LR------------------- 
2016-12-11 22:47:16 0.0001220703125 
2016-12-11 22:47:16 Epoch 355 
2016-12-11 22:48:46 Training Error = 0.59848791683543 
2016-12-11 22:48:46 Training Loss = 0.026639886946193 
2016-12-11 22:48:48 Valid Error = 0.7363304981774 
2016-12-11 22:48:48 Valid Loss = 0.033601835683924 
2016-12-11 22:48:50 Test Error = 0.79039301310044 
2016-12-11 22:48:50 Test Loss = 0.035579356165493 
2016-12-11 22:48:50 -------------------LR------------------- 
2016-12-11 22:48:50 0.0001220703125 
2016-12-11 22:48:50 Epoch 356 
2016-12-11 22:50:20 Training Error = 0.60199810989604 
2016-12-11 22:50:20 Training Loss = 0.02697455073053 
2016-12-11 22:50:22 Valid Error = 0.7363304981774 
2016-12-11 22:50:22 Valid Loss = 0.036127119325401 
2016-12-11 22:50:24 Test Error = 0.79039301310044 
2016-12-11 22:50:24 Test Loss = 0.038000539443072 
2016-12-11 22:50:24 -------------------LR------------------- 
2016-12-11 22:50:24 0.0001220703125 
2016-12-11 22:50:24 Epoch 357 
2016-12-11 22:51:55 Training Error = 0.60105305791819 
2016-12-11 22:51:55 Training Loss = 0.02683045050784 
2016-12-11 22:51:56 Valid Error = 0.68286755771567 
2016-12-11 22:51:56 Valid Loss = 0.030207285583386 
2016-12-11 22:51:59 Test Error = 0.73580786026201 
2016-12-11 22:51:59 Test Loss = 0.032162793542825 
2016-12-11 22:51:59 -------------------LR------------------- 
2016-12-11 22:51:59 0.0001220703125 
2016-12-11 22:51:59 Epoch 358 
2016-12-11 22:53:30 Training Error = 0.59943296881328 
2016-12-11 22:53:30 Training Loss = 0.02683873634374 
2016-12-11 22:53:32 Valid Error = 0.60510328068044 
2016-12-11 22:53:32 Valid Loss = 0.027462218366722 
2016-12-11 22:53:34 Test Error = 0.64192139737991 
2016-12-11 22:53:34 Test Loss = 0.029077522941664 
2016-12-11 22:53:34 -------------------LR------------------- 
2016-12-11 22:53:34 0.0001220703125 
2016-12-11 22:53:34 Epoch 359 
2016-12-11 22:55:04 Training Error = 0.60051302821655 
2016-12-11 22:55:04 Training Loss = 0.02662942104393 
2016-12-11 22:55:06 Valid Error = 0.7363304981774 
2016-12-11 22:55:06 Valid Loss = 0.032997044198969 
2016-12-11 22:55:09 Test Error = 0.79039301310044 
2016-12-11 22:55:09 Test Loss = 0.035060584358141 
2016-12-11 22:55:09 -------------------LR------------------- 
2016-12-11 22:55:09 0.0001220703125 
2016-12-11 22:55:09 Epoch 360 
2016-12-11 22:56:40 Training Error = 0.60226812474686 
2016-12-11 22:56:40 Training Loss = 0.026765774442101 
2016-12-11 22:56:43 Valid Error = 0.68286755771567 
2016-12-11 22:56:43 Valid Loss = 0.031279515227303 
2016-12-11 22:56:45 Test Error = 0.73580786026201 
2016-12-11 22:56:45 Test Loss = 0.033390417398191 
2016-12-11 22:56:45 -------------------LR------------------- 
2016-12-11 22:56:45 0.0001220703125 
2016-12-11 22:56:45 Epoch 361 
2016-12-11 22:58:16 Training Error = 0.59889293911165 
2016-12-11 22:58:16 Training Loss = 0.0267101489084 
2016-12-11 22:58:18 Valid Error = 0.79951397326853 
2016-12-11 22:58:18 Valid Loss = 0.038521601669804 
2016-12-11 22:58:20 Test Error = 0.84497816593886 
2016-12-11 22:58:20 Test Loss = 0.039272977193197 
2016-12-11 22:58:20 -------------------LR------------------- 
2016-12-11 22:58:20 0.0001220703125 
2016-12-11 22:58:20 Epoch 362 
2016-12-11 22:59:49 Training Error = 0.60091805049278 
2016-12-11 22:59:49 Training Loss = 0.026712191215394 
2016-12-11 22:59:51 Valid Error = 0.60510328068044 
2016-12-11 22:59:51 Valid Loss = 0.027022965223351 
2016-12-11 22:59:53 Test Error = 0.64192139737991 
2016-12-11 22:59:53 Test Loss = 0.028731121661616 
2016-12-11 22:59:53 -------------------LR------------------- 
2016-12-11 22:59:53 0.0001220703125 
2016-12-11 22:59:53 Epoch 363 
2016-12-11 23:01:24 Training Error = 0.59781287970838 
2016-12-11 23:01:24 Training Loss = 0.026691714436222 
2016-12-11 23:01:26 Valid Error = 0.60510328068044 
2016-12-11 23:01:26 Valid Loss = 0.027204436280233 
2016-12-11 23:01:29 Test Error = 0.64192139737991 
2016-12-11 23:01:29 Test Loss = 0.028709267756518 
2016-12-11 23:01:29 -------------------LR------------------- 
2016-12-11 23:01:29 0.0001220703125 
2016-12-11 23:01:29 Epoch 364 
2016-12-11 23:03:00 Training Error = 0.60118806534359 
2016-12-11 23:03:00 Training Loss = 0.026794673649693 
2016-12-11 23:03:02 Valid Error = 0.68286755771567 
2016-12-11 23:03:02 Valid Loss = 0.034686761241615 
2016-12-11 23:03:04 Test Error = 0.73580786026201 
2016-12-11 23:03:04 Test Loss = 0.037240277140748 
2016-12-11 23:03:04 -------------------LR------------------- 
2016-12-11 23:03:04 0.0001220703125 
2016-12-11 23:03:04 Epoch 365 
2016-12-11 23:04:33 Training Error = 0.60010800594033 
2016-12-11 23:04:33 Training Loss = 0.026735373423458 
2016-12-11 23:04:35 Valid Error = 0.68286755771567 
2016-12-11 23:04:35 Valid Loss = 0.029048544480921 
2016-12-11 23:04:37 Test Error = 0.73580786026201 
2016-12-11 23:04:37 Test Loss = 0.030871839074528 
2016-12-11 23:04:37 -------------------LR------------------- 
2016-12-11 23:04:37 0.0001220703125 
2016-12-11 23:04:37 Epoch 366 
2016-12-11 23:06:08 Training Error = 0.60064803564196 
2016-12-11 23:06:08 Training Loss = 0.026658840023436 
2016-12-11 23:06:10 Valid Error = 0.60510328068044 
2016-12-11 23:06:10 Valid Loss = 0.027540833918651 
2016-12-11 23:06:12 Test Error = 0.64192139737991 
2016-12-11 23:06:12 Test Loss = 0.029017402751773 
2016-12-11 23:06:12 -------------------LR------------------- 
2016-12-11 23:06:12 0.0001220703125 
2016-12-11 23:06:12 Epoch 367 
2016-12-11 23:07:43 Training Error = 0.59916295396247 
2016-12-11 23:07:43 Training Loss = 0.02653292762621 
2016-12-11 23:07:45 Valid Error = 0.67314702308627 
2016-12-11 23:07:45 Valid Loss = 0.031095506025442 
2016-12-11 23:07:47 Test Error = 0.72598253275109 
2016-12-11 23:07:47 Test Loss = 0.033175796779932 
2016-12-11 23:07:47 -------------------LR------------------- 
2016-12-11 23:07:47 0.0001220703125 
2016-12-11 23:07:47 Epoch 368 
2016-12-11 23:09:17 Training Error = 0.60105305791819 
2016-12-11 23:09:17 Training Loss = 0.026796997798346 
2016-12-11 23:09:19 Valid Error = 0.79951397326853 
2016-12-11 23:09:19 Valid Loss = 0.038929561475151 
2016-12-11 23:09:22 Test Error = 0.84497816593886 
2016-12-11 23:09:22 Test Loss = 0.03955993087619 
2016-12-11 23:09:22 -------------------LR------------------- 
2016-12-11 23:09:22 0.0001220703125 
2016-12-11 23:09:22 Epoch 369 
2016-12-11 23:10:51 Training Error = 0.60159308761982 
2016-12-11 23:10:51 Training Loss = 0.02676407221519 
2016-12-11 23:10:53 Valid Error = 0.59538274605103 
2016-12-11 23:10:53 Valid Loss = 0.027092257181081 
2016-12-11 23:10:55 Test Error = 0.632096069869 
2016-12-11 23:10:55 Test Loss = 0.02868594528647 
2016-12-11 23:10:55 -------------------LR------------------- 
2016-12-11 23:10:55 0.0001220703125 
2016-12-11 23:10:55 Epoch 370 
2016-12-11 23:12:28 Training Error = 0.60267314702309 
2016-12-11 23:12:28 Training Loss = 0.026805567808178 
2016-12-11 23:12:30 Valid Error = 0.7363304981774 
2016-12-11 23:12:30 Valid Loss = 0.03430791776989 
2016-12-11 23:12:32 Test Error = 0.79039301310044 
2016-12-11 23:12:32 Test Loss = 0.036122134320876 
2016-12-11 23:12:32 -------------------LR------------------- 
2016-12-11 23:12:32 0.0001220703125 
2016-12-11 23:12:32 Epoch 371 
2016-12-11 23:14:04 Training Error = 0.59848791683543 
2016-12-11 23:14:04 Training Loss = 0.026777326596329 
2016-12-11 23:14:06 Valid Error = 0.60510328068044 
2016-12-11 23:14:06 Valid Loss = 0.027478783164747 
2016-12-11 23:14:08 Test Error = 0.64192139737991 
2016-12-11 23:14:08 Test Loss = 0.029027106322494 
2016-12-11 23:14:08 -------------------LR------------------- 
2016-12-11 23:14:08 0.0001220703125 
2016-12-11 23:14:08 Epoch 372 
2016-12-11 23:15:39 Training Error = 0.60105305791819 
2016-12-11 23:15:39 Training Loss = 0.026681797690797 
2016-12-11 23:15:41 Valid Error = 0.69380315917375 
2016-12-11 23:15:41 Valid Loss = 0.030692756091305 
2016-12-11 23:15:44 Test Error = 0.74454148471616 
2016-12-11 23:15:44 Test Loss = 0.033026531397128 
2016-12-11 23:15:44 -------------------LR------------------- 
2016-12-11 23:15:44 0.0001220703125 
2016-12-11 23:15:44 Epoch 373 
2016-12-11 23:17:12 Training Error = 0.59983799108951 
2016-12-11 23:17:12 Training Loss = 0.026663549447082 
2016-12-11 23:17:14 Valid Error = 0.60510328068044 
2016-12-11 23:17:14 Valid Loss = 0.026948542246665 
2016-12-11 23:17:16 Test Error = 0.64192139737991 
2016-12-11 23:17:16 Test Loss = 0.028817298982658 
2016-12-11 23:17:16 -------------------LR------------------- 
2016-12-11 23:17:16 0.0001220703125 
2016-12-11 23:17:16 Epoch 374 
2016-12-11 23:18:47 Training Error = 0.60037802079114 
2016-12-11 23:18:47 Training Loss = 0.026756842703512 
2016-12-11 23:18:49 Valid Error = 0.65856622114216 
2016-12-11 23:18:49 Valid Loss = 0.031941925869799 
2016-12-11 23:18:51 Test Error = 0.69650655021834 
2016-12-11 23:18:51 Test Loss = 0.033934897843529 
2016-12-11 23:18:51 -------------------LR------------------- 
2016-12-11 23:18:51 0.0001220703125 
2016-12-11 23:18:51 Epoch 375 
2016-12-11 23:20:21 Training Error = 0.59821790198461 
2016-12-11 23:20:21 Training Loss = 0.026783029087897 
2016-12-11 23:20:23 Valid Error = 0.69380315917375 
2016-12-11 23:20:23 Valid Loss = 0.031579185818998 
2016-12-11 23:20:26 Test Error = 0.74454148471616 
2016-12-11 23:20:26 Test Loss = 0.033782191538343 
2016-12-11 23:20:26 -------------------LR------------------- 
2016-12-11 23:20:26 0.0001220703125 
2016-12-11 23:20:26 Epoch 376 
2016-12-11 23:21:56 Training Error = 0.5997029836641 
2016-12-11 23:21:56 Training Loss = 0.026746276201521 
2016-12-11 23:21:58 Valid Error = 0.7363304981774 
2016-12-11 23:21:58 Valid Loss = 0.033777059071035 
2016-12-11 23:22:01 Test Error = 0.79039301310044 
2016-12-11 23:22:01 Test Loss = 0.035704622614617 
2016-12-11 23:22:01 -------------------LR------------------- 
2016-12-11 23:22:01 0.0001220703125 
2016-12-11 23:22:01 Epoch 377 
2016-12-11 23:23:32 Training Error = 0.59875793168624 
2016-12-11 23:23:32 Training Loss = 0.026685384687322 
2016-12-11 23:23:34 Valid Error = 0.726609963548 
2016-12-11 23:23:34 Valid Loss = 0.033649391318131 
2016-12-11 23:23:36 Test Error = 0.78056768558952 
2016-12-11 23:23:36 Test Loss = 0.035778765276367 
2016-12-11 23:23:36 -------------------LR------------------- 
2016-12-11 23:23:36 0.0001220703125 
2016-12-11 23:23:36 Epoch 378 
2016-12-11 23:25:09 Training Error = 0.59889293911165 
2016-12-11 23:25:09 Training Loss = 0.02677347218347 
2016-12-11 23:25:11 Valid Error = 0.7363304981774 
2016-12-11 23:25:11 Valid Loss = 0.032111080394072 
2016-12-11 23:25:13 Test Error = 0.79039301310044 
2016-12-11 23:25:13 Test Loss = 0.033980168417388 
2016-12-11 23:25:13 -------------------LR------------------- 
2016-12-11 23:25:13 0.0001220703125 
2016-12-11 23:25:13 Epoch 379 
2016-12-11 23:26:44 Training Error = 0.60024301336574 
2016-12-11 23:26:44 Training Loss = 0.026865391197169 
2016-12-11 23:26:46 Valid Error = 0.7363304981774 
2016-12-11 23:26:46 Valid Loss = 0.035483976297107 
2016-12-11 23:26:48 Test Error = 0.79039301310044 
2016-12-11 23:26:48 Test Loss = 0.037555048577926 
2016-12-11 23:26:48 -------------------LR------------------- 
2016-12-11 23:26:48 0.0001220703125 
2016-12-11 23:26:48 Epoch 380 
2016-12-11 23:28:23 Training Error = 0.59997299851492 
2016-12-11 23:28:23 Training Loss = 0.02683316746417 
2016-12-11 23:28:25 Valid Error = 0.68286755771567 
2016-12-11 23:28:25 Valid Loss = 0.033290064237984 
2016-12-11 23:28:28 Test Error = 0.73580786026201 
2016-12-11 23:28:28 Test Loss = 0.035944698978873 
2016-12-11 23:28:28 -------------------LR------------------- 
2016-12-11 23:28:28 0.0001220703125 
2016-12-11 23:28:28 Epoch 381 
