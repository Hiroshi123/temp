2016-12-10 05:48:54 [program started on Sat Dec 10 05:48:54 2016] 
2016-12-10 05:48:54 [command line arguments] 
2016-12-10 05:48:54 stcWeights false 
2016-12-10 05:48:54 LR 0.015625 
2016-12-10 05:48:54 batchSize 100 
2016-12-10 05:48:54 network ./Models/Cifar10_Custom 
2016-12-10 05:48:54 stcNeurons true 
2016-12-10 05:48:54 constBatchSize false 
2016-12-10 05:48:54 chartFileName chart1 
2016-12-10 05:48:54 dp_prepro false 
2016-12-10 05:48:54 nGPU 1 
2016-12-10 05:48:54 dataset Caltech101 
2016-12-10 05:48:54 type cuda 
2016-12-10 05:48:54 momentum 0 
2016-12-10 05:48:54 threads 8 
2016-12-10 05:48:54 weightDecay 0 
2016-12-10 05:48:54 runningVal false 
2016-12-10 05:48:54 convLayerN 6 
2016-12-10 05:48:54 LRDecay 0 
2016-12-10 05:48:54 numHid 1024 
2016-12-10 05:48:54 save /dev/shm/clone/temp/th/Results/Caltech101/model6-20 
2016-12-10 05:48:54 augment false 
2016-12-10 05:48:54 epoch -1 
2016-12-10 05:48:54 modelsFolder ./Models/ 
2016-12-10 05:48:54 format rgb 
2016-12-10 05:48:54 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-10 05:48:54 imageFileExtension svg 
2016-12-10 05:48:54 channel 2 
2016-12-10 05:48:54 devid 9 
2016-12-10 05:48:54 visualize 1 
2016-12-10 05:48:54 LRDecayPerEpoch 0.0001 
2016-12-10 05:48:54 optimization adam 
2016-12-10 05:48:54 SBN true 
2016-12-10 05:48:54 normalization simple 
2016-12-10 05:48:54 title model1 
2016-12-10 05:48:54 load  
2016-12-10 05:48:54 whiten true 
2016-12-10 05:48:54 [----------------------] 
2016-12-10 05:48:57 ==> Network 
2016-12-10 05:48:57 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 256, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(512 -> 1024, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(16384)
  (29): BinaryLinear(16384 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 102)
  (38): nn.BatchNormalization
} 
2016-12-10 05:48:57 ==>36238898 Parameters 
2016-12-10 05:48:57 ==> Loss 
2016-12-10 05:48:57 SqrtHingeEmbeddingCriterion 
2016-12-10 05:48:57 
==> Starting Training
 
2016-12-10 05:48:57 Epoch 1 
2016-12-10 05:51:53 Training Error = 0.85176184690158 
2016-12-10 05:51:53 Training Loss = 0.41678155225225 
2016-12-10 05:51:58 Valid Error = 0.78857837181045 
2016-12-10 05:51:58 Valid Loss = 0.066351739396152 
2016-12-10 05:52:03 Test Error = 0.81222707423581 
2016-12-10 05:52:03 Test Loss = 0.06710181834651 
2016-12-10 05:52:03 -------------------LR------------------- 
2016-12-10 05:52:03 0.015625 
2016-12-10 05:52:03 Epoch 2 
2016-12-10 05:54:57 Training Error = 0.6576211691643 
2016-12-10 05:54:57 Training Loss = 0.041400096227252 
2016-12-10 05:55:02 Valid Error = 0.65370595382746 
2016-12-10 05:55:02 Valid Loss = 0.031305983668872 
2016-12-10 05:55:07 Test Error = 0.66703056768559 
2016-12-10 05:55:07 Test Loss = 0.031981168391658 
2016-12-10 05:55:07 -------------------LR------------------- 
2016-12-10 05:55:07 0.015625 
2016-12-10 05:55:07 Epoch 3 
2016-12-10 05:57:58 Training Error = 0.64169029296611 
2016-12-10 05:57:58 Training Loss = 0.030003006794962 
2016-12-10 05:58:03 Valid Error = 0.64277035236938 
2016-12-10 05:58:03 Valid Loss = 0.029079531999974 
2016-12-10 05:58:08 Test Error = 0.65829694323144 
2016-12-10 05:58:08 Test Loss = 0.030291933807672 
2016-12-10 05:58:08 -------------------LR------------------- 
2016-12-10 05:58:08 0.015625 
2016-12-10 05:58:08 Epoch 4 
2016-12-10 06:01:09 Training Error = 0.62265424598353 
2016-12-10 06:01:09 Training Loss = 0.02843572322443 
2016-12-10 06:01:14 Valid Error = 0.72053462940462 
2016-12-10 06:01:14 Valid Loss = 0.031489385605039 
2016-12-10 06:01:19 Test Error = 0.75218340611354 
2016-12-10 06:01:19 Test Loss = 0.033243965111527 
2016-12-10 06:01:19 -------------------LR------------------- 
2016-12-10 06:01:19 0.015625 
2016-12-10 06:01:19 Epoch 5 
2016-12-10 06:04:14 Training Error = 0.6045632509788 
2016-12-10 06:04:14 Training Loss = 0.027386623376157 
2016-12-10 06:04:19 Valid Error = 0.75698663426488 
2016-12-10 06:04:19 Valid Loss = 0.031190703929436 
2016-12-10 06:04:24 Test Error = 0.79148471615721 
2016-12-10 06:04:24 Test Loss = 0.033131150722504 
2016-12-10 06:04:24 -------------------LR------------------- 
2016-12-10 06:04:24 0.015625 
2016-12-10 06:04:24 Epoch 6 
2016-12-10 06:07:43 Training Error = 0.59862292426083 
2016-12-10 06:07:43 Training Loss = 0.027017089369317 
2016-12-10 06:07:47 Valid Error = 0.75212636695018 
2016-12-10 06:07:47 Valid Loss = 0.031569546526712 
2016-12-10 06:07:53 Test Error = 0.78711790393013 
2016-12-10 06:07:53 Test Loss = 0.033022454205681 
2016-12-10 06:07:53 -------------------LR------------------- 
2016-12-10 06:07:53 0.015625 
2016-12-10 06:07:53 Epoch 7 
2016-12-10 06:10:50 Training Error = 0.57270149858242 
2016-12-10 06:10:50 Training Loss = 0.02643348687009 
2016-12-10 06:10:54 Valid Error = 0.75212636695018 
2016-12-10 06:10:54 Valid Loss = 0.032658202827253 
2016-12-10 06:11:00 Test Error = 0.79257641921397 
2016-12-10 06:11:00 Test Loss = 0.034492416681028 
2016-12-10 06:11:00 -------------------LR------------------- 
2016-12-10 06:11:00 0.015625 
2016-12-10 06:11:00 Epoch 8 
2016-12-10 06:14:06 Training Error = 0.55879573376536 
2016-12-10 06:14:06 Training Loss = 0.02633024545593 
2016-12-10 06:14:11 Valid Error = 0.63304981773998 
2016-12-10 06:14:11 Valid Loss = 0.027398126328817 
2016-12-10 06:14:16 Test Error = 0.65393013100437 
2016-12-10 06:14:16 Test Loss = 0.029348771067227 
2016-12-10 06:14:16 -------------------LR------------------- 
2016-12-10 06:14:16 0.015625 
2016-12-10 06:14:16 Epoch 9 
2016-12-10 06:17:15 Training Error = 0.53989469420818 
2016-12-10 06:17:15 Training Loss = 0.025366207388514 
2016-12-10 06:17:20 Valid Error = 0.76549210206561 
2016-12-10 06:17:20 Valid Loss = 0.030762870725701 
2016-12-10 06:17:25 Test Error = 0.78930131004367 
2016-12-10 06:17:25 Test Loss = 0.032407367996141 
2016-12-10 06:17:25 -------------------LR------------------- 
2016-12-10 06:17:25 0.015625 
2016-12-10 06:17:25 Epoch 10 
2016-12-10 06:20:30 Training Error = 0.52328878088295 
2016-12-10 06:20:30 Training Loss = 0.025216583961465 
2016-12-10 06:20:35 Valid Error = 0.62940461725395 
2016-12-10 06:20:35 Valid Loss = 0.028655032459348 
2016-12-10 06:20:40 Test Error = 0.69323144104803 
2016-12-10 06:20:40 Test Loss = 0.03225135790133 
2016-12-10 06:20:40 -------------------LR------------------- 
2016-12-10 06:20:40 0.015625 
2016-12-10 06:20:40 Epoch 11 
2016-12-10 06:23:34 Training Error = 0.51262319427569 
2016-12-10 06:23:34 Training Loss = 0.024839863431131 
2016-12-10 06:23:39 Valid Error = 0.54070473876063 
2016-12-10 06:23:39 Valid Loss = 0.027960706817231 
2016-12-10 06:23:44 Test Error = 0.58624454148472 
2016-12-10 06:23:44 Test Loss = 0.0318394093046 
2016-12-10 06:23:44 -------------------LR------------------- 
2016-12-10 06:23:44 0.015625 
2016-12-10 06:23:44 Epoch 12 
2016-12-10 06:26:44 Training Error = 0.51815849871743 
2016-12-10 06:26:44 Training Loss = 0.025018939563741 
2016-12-10 06:26:49 Valid Error = 0.54070473876063 
2016-12-10 06:26:49 Valid Loss = 0.028419643473284 
2016-12-10 06:26:55 Test Error = 0.58624454148472 
2016-12-10 06:26:55 Test Loss = 0.032320691090004 
2016-12-10 06:26:55 -------------------LR------------------- 
2016-12-10 06:26:55 0.015625 
2016-12-10 06:26:55 Epoch 13 
2016-12-10 06:30:01 Training Error = 0.5161333873363 
2016-12-10 06:30:01 Training Loss = 0.02482661565786 
2016-12-10 06:30:06 Valid Error = 0.53462940461725 
2016-12-10 06:30:06 Valid Loss = 0.02692799770438 
2016-12-10 06:30:11 Test Error = 0.58187772925764 
2016-12-10 06:30:11 Test Loss = 0.030875250311459 
2016-12-10 06:30:11 -------------------LR------------------- 
2016-12-10 06:30:11 0.015625 
2016-12-10 06:30:11 Epoch 14 
2016-12-10 06:33:12 Training Error = 0.51667341703794 
2016-12-10 06:33:12 Training Loss = 0.02473149223577 
2016-12-10 06:33:17 Valid Error = 0.61846901579587 
2016-12-10 06:33:17 Valid Loss = 0.029242709391924 
2016-12-10 06:33:22 Test Error = 0.68013100436681 
2016-12-10 06:33:22 Test Loss = 0.033461987738516 
2016-12-10 06:33:22 -------------------LR------------------- 
2016-12-10 06:33:22 0.015625 
2016-12-10 06:33:22 Epoch 15 
2016-12-10 06:36:23 Training Error = 0.51383826110436 
2016-12-10 06:36:23 Training Loss = 0.024821977336467 
2016-12-10 06:36:28 Valid Error = 0.54070473876063 
2016-12-10 06:36:28 Valid Loss = 0.029676759030948 
2016-12-10 06:36:33 Test Error = 0.58624454148472 
2016-12-10 06:36:33 Test Loss = 0.034113179393843 
2016-12-10 06:36:33 -------------------LR------------------- 
2016-12-10 06:36:33 0.015625 
2016-12-10 06:36:33 Epoch 16 
2016-12-10 06:39:35 Training Error = 0.5176184690158 
2016-12-10 06:39:35 Training Loss = 0.024969122835902 
2016-12-10 06:39:40 Valid Error = 0.54070473876063 
2016-12-10 06:39:40 Valid Loss = 0.029388266293583 
2016-12-10 06:39:45 Test Error = 0.58624454148472 
2016-12-10 06:39:45 Test Loss = 0.033552919556113 
2016-12-10 06:39:45 -------------------LR------------------- 
2016-12-10 06:39:45 0.015625 
2016-12-10 06:39:45 Epoch 17 
2016-12-10 06:42:45 Training Error = 0.51505332793304 
2016-12-10 06:42:45 Training Loss = 0.02481570291813 
2016-12-10 06:42:50 Valid Error = 0.54434993924666 
2016-12-10 06:42:50 Valid Loss = 0.028134881139106 
2016-12-10 06:42:55 Test Error = 0.59170305676856 
2016-12-10 06:42:55 Test Loss = 0.032055079329248 
2016-12-10 06:42:55 -------------------LR------------------- 
2016-12-10 06:42:55 0.015625 
2016-12-10 06:42:55 Epoch 18 
2016-12-10 06:45:58 Training Error = 0.51194815714864 
2016-12-10 06:45:58 Training Loss = 0.024876526307748 
2016-12-10 06:46:03 Valid Error = 0.54434993924666 
2016-12-10 06:46:03 Valid Loss = 0.02921734113116 
2016-12-10 06:46:08 Test Error = 0.59170305676856 
2016-12-10 06:46:08 Test Loss = 0.033483777307997 
2016-12-10 06:46:08 -------------------LR------------------- 
2016-12-10 06:46:08 0.015625 
2016-12-10 06:46:08 Epoch 19 
2016-12-10 06:49:16 Training Error = 0.51694343188875 
2016-12-10 06:49:16 Training Loss = 0.024771387976781 
2016-12-10 06:49:20 Valid Error = 0.54678007290401 
2016-12-10 06:49:20 Valid Loss = 0.02767225671833 
2016-12-10 06:49:26 Test Error = 0.58951965065502 
2016-12-10 06:49:26 Test Loss = 0.031714524699192 
2016-12-10 06:49:26 -------------------LR------------------- 
2016-12-10 06:49:26 0.015625 
2016-12-10 06:49:26 Epoch 20 
2016-12-10 06:52:48 Training Error = 0.51802349129202 
2016-12-10 06:52:48 Training Loss = 0.024727094563004 
2016-12-10 06:52:53 Valid Error = 0.54070473876063 
2016-12-10 06:52:53 Valid Loss = 0.028363407283522 
2016-12-10 06:52:58 Test Error = 0.58624454148472 
2016-12-10 06:52:58 Test Loss = 0.032398407730402 
2016-12-10 06:52:58 -------------------LR------------------- 
2016-12-10 06:52:58 0.015625 
2016-12-10 06:52:58 Epoch 21 
2016-12-10 06:56:12 Training Error = 0.51667341703794 
2016-12-10 06:56:12 Training Loss = 0.024757547327606 
2016-12-10 06:56:17 Valid Error = 0.54799513973269 
2016-12-10 06:56:17 Valid Loss = 0.028261277427431 
2016-12-10 06:56:22 Test Error = 0.59061135371179 
2016-12-10 06:56:22 Test Loss = 0.03252649419448 
2016-12-10 06:56:22 -------------------LR------------------- 
2016-12-10 06:56:22 0.015625 
2016-12-10 06:56:22 Epoch 22 
2016-12-10 06:59:34 Training Error = 0.51437829080599 
2016-12-10 06:59:34 Training Loss = 0.024858542814709 
2016-12-10 06:59:39 Valid Error = 0.61603888213852 
2016-12-10 06:59:39 Valid Loss = 0.029218424191538 
2016-12-10 06:59:44 Test Error = 0.67685589519651 
2016-12-10 06:59:44 Test Loss = 0.033311559677124 
2016-12-10 06:59:44 -------------------LR------------------- 
2016-12-10 06:59:44 0.015625 
2016-12-10 06:59:44 Epoch 23 
2016-12-10 07:02:55 Training Error = 0.5145132982314 
2016-12-10 07:02:55 Training Loss = 0.024953442036605 
2016-12-10 07:03:00 Valid Error = 0.53462940461725 
2016-12-10 07:03:00 Valid Loss = 0.027509648181322 
2016-12-10 07:03:06 Test Error = 0.57751091703057 
2016-12-10 07:03:06 Test Loss = 0.031557319491517 
2016-12-10 07:03:06 -------------------LR------------------- 
2016-12-10 07:03:06 0.015625 
2016-12-10 07:03:06 Epoch 24 
2016-12-10 07:06:18 Training Error = 0.51532334278385 
2016-12-10 07:06:18 Training Loss = 0.024775103058802 
2016-12-10 07:06:23 Valid Error = 0.54191980558931 
2016-12-10 07:06:23 Valid Loss = 0.028436919806118 
2016-12-10 07:06:28 Test Error = 0.58187772925764 
2016-12-10 07:06:28 Test Loss = 0.032352761642606 
2016-12-10 07:06:28 -------------------LR------------------- 
2016-12-10 07:06:28 0.015625 
2016-12-10 07:06:28 Epoch 25 
2016-12-10 07:09:43 Training Error = 0.51721344673957 
2016-12-10 07:09:43 Training Loss = 0.024860945278991 
2016-12-10 07:09:48 Valid Error = 0.61846901579587 
2016-12-10 07:09:48 Valid Loss = 0.02829014117512 
2016-12-10 07:09:53 Test Error = 0.68013100436681 
2016-12-10 07:09:53 Test Loss = 0.032225620325874 
2016-12-10 07:09:53 -------------------LR------------------- 
2016-12-10 07:09:53 0.015625 
2016-12-10 07:09:53 Epoch 26 
2016-12-10 07:13:04 Training Error = 0.51788848386661 
2016-12-10 07:13:04 Training Loss = 0.024795763222688 
2016-12-10 07:13:09 Valid Error = 0.54070473876063 
2016-12-10 07:13:09 Valid Loss = 0.028221246289904 
2016-12-10 07:13:14 Test Error = 0.58624454148472 
2016-12-10 07:13:14 Test Loss = 0.032188026951809 
2016-12-10 07:13:14 -------------------LR------------------- 
2016-12-10 07:13:14 0.015625 
2016-12-10 07:13:14 Epoch 27 
2016-12-10 07:16:31 Training Error = 0.51356824625354 
2016-12-10 07:16:31 Training Loss = 0.024746968131328 
2016-12-10 07:16:35 Valid Error = 0.61846901579587 
2016-12-10 07:16:35 Valid Loss = 0.02915448109196 
2016-12-10 07:16:41 Test Error = 0.68013100436681 
2016-12-10 07:16:41 Test Loss = 0.033459201326557 
2016-12-10 07:16:41 -------------------LR------------------- 
2016-12-10 07:16:41 0.015625 
2016-12-10 07:16:41 Epoch 28 
2016-12-10 07:19:54 Training Error = 0.51410827595518 
2016-12-10 07:19:54 Training Loss = 0.025102884914138 
2016-12-10 07:19:59 Valid Error = 0.53462940461725 
2016-12-10 07:19:59 Valid Loss = 0.026994985609532 
2016-12-10 07:20:04 Test Error = 0.58187772925764 
2016-12-10 07:20:04 Test Loss = 0.031162195299186 
2016-12-10 07:20:04 -------------------LR------------------- 
2016-12-10 07:20:04 0.015625 
2016-12-10 07:20:04 Epoch 29 
2016-12-10 07:23:18 Training Error = 0.51653840961253 
2016-12-10 07:23:18 Training Loss = 0.024805504218492 
2016-12-10 07:23:23 Valid Error = 0.6221142162819 
2016-12-10 07:23:23 Valid Loss = 0.029569313704792 
2016-12-10 07:23:28 Test Error = 0.68558951965065 
2016-12-10 07:23:28 Test Loss = 0.033726201038735 
2016-12-10 07:23:28 -------------------LR------------------- 
2016-12-10 07:23:28 0.015625 
2016-12-10 07:23:28 Epoch 30 
2016-12-10 07:26:51 Training Error = 0.51572836506008 
2016-12-10 07:26:51 Training Loss = 0.024761325892458 
2016-12-10 07:26:56 Valid Error = 0.6221142162819 
2016-12-10 07:26:56 Valid Loss = 0.029157791340047 
2016-12-10 07:27:01 Test Error = 0.68558951965065 
2016-12-10 07:27:01 Test Loss = 0.032991451824413 
2016-12-10 07:27:01 -------------------LR------------------- 
2016-12-10 07:27:01 0.015625 
2016-12-10 07:27:02 Epoch 31 
2016-12-10 07:30:17 Training Error = 0.51586337248549 
2016-12-10 07:30:17 Training Loss = 0.024966057942138 
2016-12-10 07:30:22 Valid Error = 0.53098420413123 
2016-12-10 07:30:22 Valid Loss = 0.026952899825542 
2016-12-10 07:30:27 Test Error = 0.5764192139738 
2016-12-10 07:30:27 Test Loss = 0.031125472050087 
2016-12-10 07:30:27 -------------------LR------------------- 
2016-12-10 07:30:27 0.015625 
2016-12-10 07:30:27 Epoch 32 
2016-12-10 07:33:41 Training Error = 0.51734845416498 
2016-12-10 07:33:41 Training Loss = 0.024976577473844 
2016-12-10 07:33:46 Valid Error = 0.53948967193196 
2016-12-10 07:33:46 Valid Loss = 0.027296506118016 
2016-12-10 07:33:51 Test Error = 0.58624454148472 
2016-12-10 07:33:51 Test Loss = 0.031491150238935 
2016-12-10 07:33:51 -------------------LR------------------- 
2016-12-10 07:33:51 0.015625 
2016-12-10 07:33:51 Epoch 33 
2016-12-10 07:37:02 Training Error = 0.51518833535844 
2016-12-10 07:37:02 Training Loss = 0.024789914384943 
2016-12-10 07:37:07 Valid Error = 0.52976913730255 
2016-12-10 07:37:07 Valid Loss = 0.028628109354429 
2016-12-10 07:37:12 Test Error = 0.57860262008734 
2016-12-10 07:37:12 Test Loss = 0.03260010098476 
2016-12-10 07:37:12 -------------------LR------------------- 
2016-12-10 07:37:12 0.015625 
2016-12-10 07:37:12 Epoch 34 
2016-12-10 07:40:30 Training Error = 0.51370325367895 
2016-12-10 07:40:30 Training Loss = 0.024715785788599 
2016-12-10 07:40:35 Valid Error = 0.54070473876063 
2016-12-10 07:40:35 Valid Loss = 0.02847715930843 
2016-12-10 07:40:40 Test Error = 0.58624454148472 
2016-12-10 07:40:40 Test Loss = 0.032457269855574 
2016-12-10 07:40:40 -------------------LR------------------- 
2016-12-10 07:40:40 0.015625 
2016-12-10 07:40:40 Epoch 35 
2016-12-10 07:43:54 Training Error = 0.51194815714864 
2016-12-10 07:43:54 Training Loss = 0.024815357197567 
2016-12-10 07:43:59 Valid Error = 0.54434993924666 
2016-12-10 07:43:59 Valid Loss = 0.028878326856854 
2016-12-10 07:44:04 Test Error = 0.59170305676856 
2016-12-10 07:44:04 Test Loss = 0.033158310628405 
2016-12-10 07:44:04 -------------------LR------------------- 
2016-12-10 07:44:04 0.015625 
2016-12-10 07:44:04 Epoch 36 
2016-12-10 07:47:17 Training Error = 0.51221817199946 
2016-12-10 07:47:17 Training Loss = 0.024818491532355 
2016-12-10 07:47:22 Valid Error = 0.53462940461725 
2016-12-10 07:47:22 Valid Loss = 0.027553298291106 
2016-12-10 07:47:27 Test Error = 0.57751091703057 
2016-12-10 07:47:27 Test Loss = 0.0315469975378 
2016-12-10 07:47:27 -------------------LR------------------- 
2016-12-10 07:47:27 0.015625 
2016-12-10 07:47:27 Epoch 37 
2016-12-10 07:50:43 Training Error = 0.5159983799109 
2016-12-10 07:50:43 Training Loss = 0.024869631805562 
2016-12-10 07:50:48 Valid Error = 0.54070473876063 
2016-12-10 07:50:48 Valid Loss = 0.029082834204569 
2016-12-10 07:50:53 Test Error = 0.58624454148472 
2016-12-10 07:50:53 Test Loss = 0.033262898389031 
2016-12-10 07:50:53 -------------------LR------------------- 
2016-12-10 07:50:53 0.015625 
2016-12-10 07:50:53 Epoch 38 
2016-12-10 07:54:10 Training Error = 0.51788848386661 
2016-12-10 07:54:10 Training Loss = 0.024884373085172 
2016-12-10 07:54:15 Valid Error = 0.6221142162819 
2016-12-10 07:54:15 Valid Loss = 0.02909873059045 
2016-12-10 07:54:20 Test Error = 0.68558951965065 
2016-12-10 07:54:20 Test Loss = 0.033304693521238 
2016-12-10 07:54:20 -------------------LR------------------- 
2016-12-10 07:54:20 0.015625 
2016-12-10 07:54:20 Epoch 39 
2016-12-10 07:57:23 Training Error = 0.51572836506008 
2016-12-10 07:57:23 Training Loss = 0.024866012038971 
2016-12-10 07:57:28 Valid Error = 0.55771567436209 
2016-12-10 07:57:28 Valid Loss = 0.027666630457215 
2016-12-10 07:57:33 Test Error = 0.59934497816594 
2016-12-10 07:57:33 Test Loss = 0.031883116703407 
2016-12-10 07:57:33 -------------------LR------------------- 
2016-12-10 07:57:33 0.015625 
2016-12-10 07:57:33 Epoch 40 
2016-12-10 08:00:46 Training Error = 0.51113811259619 
2016-12-10 08:00:46 Training Loss = 0.024770080755894 
2016-12-10 08:00:51 Valid Error = 0.54070473876063 
2016-12-10 08:00:51 Valid Loss = 0.028173823622667 
2016-12-10 08:00:56 Test Error = 0.58624454148472 
2016-12-10 08:00:56 Test Loss = 0.032148143824409 
2016-12-10 08:00:56 -------------------LR------------------- 
2016-12-10 08:00:56 0.015625 
2016-12-10 08:00:56 Epoch 41 
2016-12-10 08:03:58 Training Error = 0.5145132982314 
2016-12-10 08:03:58 Training Loss = 0.024902454976742 
2016-12-10 08:04:02 Valid Error = 0.6221142162819 
2016-12-10 08:04:02 Valid Loss = 0.02886255960048 
2016-12-10 08:04:08 Test Error = 0.68013100436681 
2016-12-10 08:04:08 Test Loss = 0.033065322240194 
2016-12-10 08:04:08 -------------------LR------------------- 
2016-12-10 08:04:08 0.015625 
2016-12-10 08:04:08 Epoch 42 
2016-12-10 08:07:09 Training Error = 0.51397326852977 
2016-12-10 08:07:09 Training Loss = 0.024957564512621 
2016-12-10 08:07:14 Valid Error = 0.53827460510328 
2016-12-10 08:07:14 Valid Loss = 0.027470993731434 
2016-12-10 08:07:19 Test Error = 0.58296943231441 
2016-12-10 08:07:19 Test Loss = 0.031518629261092 
2016-12-10 08:07:19 -------------------LR------------------- 
2016-12-10 08:07:19 0.015625 
2016-12-10 08:07:19 Epoch 43 
2016-12-10 08:10:19 Training Error = 0.5177534764412 
2016-12-10 08:10:19 Training Loss = 0.024690075560355 
2016-12-10 08:10:24 Valid Error = 0.6221142162819 
2016-12-10 08:10:24 Valid Loss = 0.02924810463928 
2016-12-10 08:10:29 Test Error = 0.68558951965065 
2016-12-10 08:10:29 Test Loss = 0.033398330295787 
2016-12-10 08:10:29 -------------------LR------------------- 
2016-12-10 08:10:29 0.015625 
2016-12-10 08:10:29 Epoch 44 
2016-12-10 08:13:31 Training Error = 0.51518833535844 
2016-12-10 08:13:31 Training Loss = 0.024721252464202 
2016-12-10 08:13:36 Valid Error = 0.61846901579587 
2016-12-10 08:13:36 Valid Loss = 0.029222728551829 
2016-12-10 08:13:41 Test Error = 0.68013100436681 
2016-12-10 08:13:41 Test Loss = 0.033269793790929 
2016-12-10 08:13:41 -------------------LR------------------- 
2016-12-10 08:13:41 0.015625 
2016-12-10 08:13:41 Epoch 45 
2016-12-10 08:16:44 Training Error = 0.51815849871743 
2016-12-10 08:16:44 Training Loss = 0.024695802304279 
2016-12-10 08:16:49 Valid Error = 0.61846901579587 
2016-12-10 08:16:49 Valid Loss = 0.029409844124872 
2016-12-10 08:16:54 Test Error = 0.68013100436681 
2016-12-10 08:16:54 Test Loss = 0.03345517134199 
2016-12-10 08:16:54 -------------------LR------------------- 
2016-12-10 08:16:54 0.015625 
2016-12-10 08:16:54 Epoch 46 
2016-12-10 08:19:55 Training Error = 0.51370325367895 
2016-12-10 08:19:55 Training Loss = 0.024852028948787 
2016-12-10 08:19:59 Valid Error = 0.62575941676792 
2016-12-10 08:19:59 Valid Loss = 0.029373096951348 
2016-12-10 08:20:05 Test Error = 0.68449781659389 
2016-12-10 08:20:05 Test Loss = 0.033386021520577 
2016-12-10 08:20:05 -------------------LR------------------- 
2016-12-10 08:20:05 0.015625 
2016-12-10 08:20:05 Epoch 47 
2016-12-10 08:23:07 Training Error = 0.51370325367895 
2016-12-10 08:23:07 Training Loss = 0.024847170872337 
2016-12-10 08:23:11 Valid Error = 0.61846901579587 
2016-12-10 08:23:11 Valid Loss = 0.028727310143084 
2016-12-10 08:23:17 Test Error = 0.68013100436681 
2016-12-10 08:23:17 Test Loss = 0.032671770843805 
2016-12-10 08:23:17 -------------------LR------------------- 
2016-12-10 08:23:17 0.015625 
2016-12-10 08:23:17 Epoch 48 
2016-12-10 08:26:20 Training Error = 0.51545835020926 
2016-12-10 08:26:20 Training Loss = 0.025000864985276 
2016-12-10 08:26:25 Valid Error = 0.54434993924666 
2016-12-10 08:26:25 Valid Loss = 0.028406038297852 
2016-12-10 08:26:30 Test Error = 0.59170305676856 
2016-12-10 08:26:30 Test Loss = 0.032423674246844 
2016-12-10 08:26:30 -------------------LR------------------- 
2016-12-10 08:26:30 0.015625 
2016-12-10 08:26:30 Epoch 49 
2016-12-10 08:29:31 Training Error = 0.51424328338059 
2016-12-10 08:29:31 Training Loss = 0.024937983836113 
2016-12-10 08:29:36 Valid Error = 0.54070473876063 
2016-12-10 08:29:36 Valid Loss = 0.028982389391716 
2016-12-10 08:29:41 Test Error = 0.58624454148472 
2016-12-10 08:29:41 Test Loss = 0.033263115190992 
2016-12-10 08:29:41 -------------------LR------------------- 
2016-12-10 08:29:41 0.015625 
2016-12-10 08:29:41 Epoch 50 
2016-12-10 08:32:52 Training Error = 0.51680842446335 
2016-12-10 08:32:52 Training Loss = 0.02485300296958 
2016-12-10 08:32:57 Valid Error = 0.54070473876063 
2016-12-10 08:32:57 Valid Loss = 0.028648631905385 
2016-12-10 08:33:02 Test Error = 0.58624454148472 
2016-12-10 08:33:02 Test Loss = 0.032619677113552 
2016-12-10 08:33:02 -------------------LR------------------- 
2016-12-10 08:33:02 0.0078125 
2016-12-10 08:33:02 Epoch 51 
2016-12-10 08:36:06 Training Error = 0.51869852841906 
2016-12-10 08:36:06 Training Loss = 0.024861400976813 
2016-12-10 08:36:10 Valid Error = 0.54678007290401 
2016-12-10 08:36:10 Valid Loss = 0.02809450861201 
2016-12-10 08:36:16 Test Error = 0.58951965065502 
2016-12-10 08:36:16 Test Loss = 0.032246035744162 
2016-12-10 08:36:16 -------------------LR------------------- 
2016-12-10 08:36:16 0.0078125 
2016-12-10 08:36:16 Epoch 52 
2016-12-10 08:39:16 Training Error = 0.51748346159039 
2016-12-10 08:39:16 Training Loss = 0.024753083049015 
2016-12-10 08:39:21 Valid Error = 0.62454434993925 
2016-12-10 08:39:21 Valid Loss = 0.028559056294961 
2016-12-10 08:39:26 Test Error = 0.68340611353712 
2016-12-10 08:39:26 Test Loss = 0.032664654974844 
2016-12-10 08:39:26 -------------------LR------------------- 
2016-12-10 08:39:26 0.0078125 
2016-12-10 08:39:26 Epoch 53 
2016-12-10 08:42:28 Training Error = 0.51329823140273 
2016-12-10 08:42:28 Training Loss = 0.024882663243113 
2016-12-10 08:42:33 Valid Error = 0.54434993924666 
2016-12-10 08:42:33 Valid Loss = 0.02802648924625 
2016-12-10 08:42:38 Test Error = 0.58624454148472 
2016-12-10 08:42:38 Test Loss = 0.032198658139098 
2016-12-10 08:42:38 -------------------LR------------------- 
2016-12-10 08:42:38 0.0078125 
2016-12-10 08:42:38 Epoch 54 
2016-12-10 08:45:44 Training Error = 0.51694343188875 
2016-12-10 08:45:44 Training Loss = 0.024779736933633 
2016-12-10 08:45:48 Valid Error = 0.54799513973269 
2016-12-10 08:45:48 Valid Loss = 0.028449869252543 
2016-12-10 08:45:54 Test Error = 0.59061135371179 
2016-12-10 08:45:54 Test Loss = 0.032500260708379 
2016-12-10 08:45:54 -------------------LR------------------- 
2016-12-10 08:45:54 0.0078125 
2016-12-10 08:45:54 Epoch 55 
2016-12-10 08:48:55 Training Error = 0.51802349129202 
2016-12-10 08:48:55 Training Loss = 0.024771406817325 
2016-12-10 08:49:00 Valid Error = 0.54434993924666 
2016-12-10 08:49:00 Valid Loss = 0.029205694853542 
2016-12-10 08:49:05 Test Error = 0.59170305676856 
2016-12-10 08:49:05 Test Loss = 0.033509046199275 
2016-12-10 08:49:05 -------------------LR------------------- 
2016-12-10 08:49:05 0.0078125 
2016-12-10 08:49:05 Epoch 56 
2016-12-10 08:52:06 Training Error = 0.51248818685028 
2016-12-10 08:52:06 Training Loss = 0.024705941461871 
2016-12-10 08:52:11 Valid Error = 0.61846901579587 
2016-12-10 08:52:11 Valid Loss = 0.029298813937231 
2016-12-10 08:52:16 Test Error = 0.68013100436681 
2016-12-10 08:52:16 Test Loss = 0.033248673869114 
2016-12-10 08:52:16 -------------------LR------------------- 
2016-12-10 08:52:16 0.0078125 
2016-12-10 08:52:16 Epoch 57 
2016-12-10 08:55:21 Training Error = 0.51235317942487 
2016-12-10 08:55:21 Training Loss = 0.024882237307765 
2016-12-10 08:55:25 Valid Error = 0.54434993924666 
2016-12-10 08:55:25 Valid Loss = 0.029559046116654 
2016-12-10 08:55:30 Test Error = 0.59170305676856 
2016-12-10 08:55:30 Test Loss = 0.033927692619025 
2016-12-10 08:55:30 -------------------LR------------------- 
2016-12-10 08:55:30 0.0078125 
2016-12-10 08:55:31 Epoch 58 
2016-12-10 08:58:31 Training Error = 0.51694343188875 
2016-12-10 08:58:31 Training Loss = 0.024880046013156 
2016-12-10 08:58:36 Valid Error = 0.54434993924666 
2016-12-10 08:58:36 Valid Loss = 0.029476769055179 
2016-12-10 08:58:41 Test Error = 0.59170305676856 
2016-12-10 08:58:41 Test Loss = 0.03355212763244 
2016-12-10 08:58:41 -------------------LR------------------- 
2016-12-10 08:58:41 0.0078125 
2016-12-10 08:58:41 Epoch 59 
2016-12-10 09:01:43 Training Error = 0.51221817199946 
2016-12-10 09:01:43 Training Loss = 0.02468523731107 
2016-12-10 09:01:48 Valid Error = 0.61846901579587 
2016-12-10 09:01:48 Valid Loss = 0.028878404444407 
2016-12-10 09:01:53 Test Error = 0.68013100436681 
2016-12-10 09:01:53 Test Loss = 0.032999541731442 
2016-12-10 09:01:53 -------------------LR------------------- 
2016-12-10 09:01:53 0.0078125 
2016-12-10 09:01:53 Epoch 60 
2016-12-10 09:05:04 Training Error = 0.51869852841906 
2016-12-10 09:05:04 Training Loss = 0.0249640512917 
2016-12-10 09:05:09 Valid Error = 0.55164034021871 
2016-12-10 09:05:09 Valid Loss = 0.0283500880532 
2016-12-10 09:05:14 Test Error = 0.59606986899563 
2016-12-10 09:05:14 Test Loss = 0.03253928380854 
2016-12-10 09:05:14 -------------------LR------------------- 
2016-12-10 09:05:14 0.0078125 
2016-12-10 09:05:14 Epoch 61 
2016-12-10 09:08:16 Training Error = 0.51464830565681 
2016-12-10 09:08:16 Training Loss = 0.024743139397686 
2016-12-10 09:08:21 Valid Error = 0.54070473876063 
2016-12-10 09:08:21 Valid Loss = 0.028881101811532 
2016-12-10 09:08:26 Test Error = 0.58624454148472 
2016-12-10 09:08:26 Test Loss = 0.033084039557214 
2016-12-10 09:08:26 -------------------LR------------------- 
2016-12-10 09:08:26 0.0078125 
2016-12-10 09:08:26 Epoch 62 
2016-12-10 09:11:24 Training Error = 0.51383826110436 
2016-12-10 09:11:24 Training Loss = 0.024851961942614 
2016-12-10 09:11:29 Valid Error = 0.54434993924666 
2016-12-10 09:11:29 Valid Loss = 0.028282672477015 
2016-12-10 09:11:34 Test Error = 0.59170305676856 
2016-12-10 09:11:34 Test Loss = 0.032159743533415 
2016-12-10 09:11:34 -------------------LR------------------- 
2016-12-10 09:11:34 0.0078125 
2016-12-10 09:11:34 Epoch 63 
2016-12-10 09:14:37 Training Error = 0.51680842446335 
2016-12-10 09:14:37 Training Loss = 0.024967129727461 
2016-12-10 09:14:41 Valid Error = 0.54070473876063 
2016-12-10 09:14:41 Valid Loss = 0.028273585678062 
2016-12-10 09:14:47 Test Error = 0.58624454148472 
2016-12-10 09:14:47 Test Loss = 0.032432260924695 
2016-12-10 09:14:47 -------------------LR------------------- 
2016-12-10 09:14:47 0.0078125 
2016-12-10 09:14:47 Epoch 64 
2016-12-10 09:17:48 Training Error = 0.51491832050763 
2016-12-10 09:17:48 Training Loss = 0.024826047663328 
2016-12-10 09:17:53 Valid Error = 0.54678007290401 
2016-12-10 09:17:53 Valid Loss = 0.027656379454717 
2016-12-10 09:17:58 Test Error = 0.58951965065502 
2016-12-10 09:17:58 Test Loss = 0.031831323455362 
2016-12-10 09:17:58 -------------------LR------------------- 
2016-12-10 09:17:58 0.0078125 
2016-12-10 09:17:58 Epoch 65 
2016-12-10 09:21:02 Training Error = 0.51856352099365 
2016-12-10 09:21:02 Training Loss = 0.025044877378035 
2016-12-10 09:21:07 Valid Error = 0.54070473876063 
2016-12-10 09:21:07 Valid Loss = 0.029171519184176 
2016-12-10 09:21:12 Test Error = 0.58624454148472 
2016-12-10 09:21:12 Test Loss = 0.033337463808995 
2016-12-10 09:21:12 -------------------LR------------------- 
2016-12-10 09:21:12 0.0078125 
2016-12-10 09:21:12 Epoch 66 
2016-12-10 09:24:11 Training Error = 0.51572836506008 
2016-12-10 09:24:11 Training Loss = 0.024864133436985 
2016-12-10 09:24:16 Valid Error = 0.6221142162819 
2016-12-10 09:24:16 Valid Loss = 0.029417428568343 
2016-12-10 09:24:21 Test Error = 0.68558951965065 
2016-12-10 09:24:21 Test Loss = 0.033665227759118 
2016-12-10 09:24:21 -------------------LR------------------- 
2016-12-10 09:24:21 0.0078125 
2016-12-10 09:24:21 Epoch 67 
2016-12-10 09:27:24 Training Error = 0.51208316457405 
2016-12-10 09:27:24 Training Loss = 0.024825637834479 
2016-12-10 09:27:29 Valid Error = 0.61846901579587 
2016-12-10 09:27:29 Valid Loss = 0.028401076951081 
2016-12-10 09:27:34 Test Error = 0.68013100436681 
2016-12-10 09:27:34 Test Loss = 0.032422073252061 
2016-12-10 09:27:34 -------------------LR------------------- 
2016-12-10 09:27:34 0.0078125 
2016-12-10 09:27:34 Epoch 68 
2016-12-10 09:30:34 Training Error = 0.51370325367895 
2016-12-10 09:30:34 Training Loss = 0.024873214878399 
2016-12-10 09:30:39 Valid Error = 0.6221142162819 
2016-12-10 09:30:39 Valid Loss = 0.029493226483768 
2016-12-10 09:30:44 Test Error = 0.68558951965065 
2016-12-10 09:30:44 Test Loss = 0.033891976244309 
2016-12-10 09:30:44 -------------------LR------------------- 
2016-12-10 09:30:44 0.0078125 
2016-12-10 09:30:44 Epoch 69 
2016-12-10 09:33:46 Training Error = 0.51586337248549 
2016-12-10 09:33:46 Training Loss = 0.024923120206945 
2016-12-10 09:33:51 Valid Error = 0.54434993924666 
2016-12-10 09:33:51 Valid Loss = 0.028677476270639 
2016-12-10 09:33:56 Test Error = 0.59170305676856 
2016-12-10 09:33:56 Test Loss = 0.032867521173814 
2016-12-10 09:33:56 -------------------LR------------------- 
2016-12-10 09:33:56 0.0078125 
2016-12-10 09:33:56 Epoch 70 
2016-12-10 09:37:06 Training Error = 0.5192385581207 
2016-12-10 09:37:06 Training Loss = 0.0249476321565 
2016-12-10 09:37:11 Valid Error = 0.61846901579587 
2016-12-10 09:37:11 Valid Loss = 0.029095462605031 
2016-12-10 09:37:16 Test Error = 0.68013100436681 
2016-12-10 09:37:16 Test Loss = 0.033147278748307 
2016-12-10 09:37:16 -------------------LR------------------- 
2016-12-10 09:37:16 0.0078125 
2016-12-10 09:37:16 Epoch 71 
2016-12-10 09:40:19 Training Error = 0.52045362494937 
2016-12-10 09:40:19 Training Loss = 0.024842103271769 
2016-12-10 09:40:24 Valid Error = 0.61846901579587 
2016-12-10 09:40:24 Valid Loss = 0.02916352635093 
2016-12-10 09:40:29 Test Error = 0.68013100436681 
2016-12-10 09:40:29 Test Loss = 0.033219240431692 
2016-12-10 09:40:29 -------------------LR------------------- 
2016-12-10 09:40:29 0.0078125 
2016-12-10 09:40:29 Epoch 72 
2016-12-10 09:43:29 Training Error = 0.5145132982314 
2016-12-10 09:43:29 Training Loss = 0.024885233645257 
2016-12-10 09:43:34 Valid Error = 0.54070473876063 
2016-12-10 09:43:34 Valid Loss = 0.02908453469883 
2016-12-10 09:43:39 Test Error = 0.58624454148472 
2016-12-10 09:43:39 Test Loss = 0.033249582571142 
2016-12-10 09:43:39 -------------------LR------------------- 
2016-12-10 09:43:39 0.0078125 
2016-12-10 09:43:39 Epoch 73 
2016-12-10 09:46:43 Training Error = 0.51370325367895 
2016-12-10 09:46:43 Training Loss = 0.024785443987165 
2016-12-10 09:46:47 Valid Error = 0.61846901579587 
2016-12-10 09:46:47 Valid Loss = 0.029012515086212 
2016-12-10 09:46:53 Test Error = 0.68013100436681 
2016-12-10 09:46:53 Test Loss = 0.033101048469543 
2016-12-10 09:46:53 -------------------LR------------------- 
2016-12-10 09:46:53 0.0078125 
2016-12-10 09:46:53 Epoch 74 
2016-12-10 09:49:53 Training Error = 0.51464830565681 
2016-12-10 09:49:53 Training Loss = 0.024813345458016 
2016-12-10 09:49:58 Valid Error = 0.61846901579587 
2016-12-10 09:49:58 Valid Loss = 0.028770101853841 
2016-12-10 09:50:03 Test Error = 0.68013100436681 
2016-12-10 09:50:03 Test Loss = 0.032699433812908 
2016-12-10 09:50:03 -------------------LR------------------- 
2016-12-10 09:50:03 0.0078125 
2016-12-10 09:50:03 Epoch 75 
2016-12-10 09:53:04 Training Error = 0.51640340218712 
2016-12-10 09:53:04 Training Loss = 0.024890186457273 
2016-12-10 09:53:09 Valid Error = 0.6221142162819 
2016-12-10 09:53:09 Valid Loss = 0.028845573780132 
2016-12-10 09:53:14 Test Error = 0.68558951965065 
2016-12-10 09:53:14 Test Loss = 0.032870530502469 
2016-12-10 09:53:14 -------------------LR------------------- 
2016-12-10 09:53:14 0.0078125 
2016-12-10 09:53:14 Epoch 76 
2016-12-10 09:56:16 Training Error = 0.51491832050763 
2016-12-10 09:56:16 Training Loss = 0.024939153287658 
2016-12-10 09:56:21 Valid Error = 0.54434993924666 
2016-12-10 09:56:21 Valid Loss = 0.028139426392272 
2016-12-10 09:56:26 Test Error = 0.59170305676856 
2016-12-10 09:56:26 Test Loss = 0.031941518633973 
2016-12-10 09:56:26 -------------------LR------------------- 
2016-12-10 09:56:26 0.0078125 
2016-12-10 09:56:26 Epoch 77 
2016-12-10 09:59:28 Training Error = 0.51478331308222 
2016-12-10 09:59:28 Training Loss = 0.024923870868131 
2016-12-10 09:59:33 Valid Error = 0.54434993924666 
2016-12-10 09:59:33 Valid Loss = 0.027746368723294 
2016-12-10 09:59:38 Test Error = 0.59170305676856 
2016-12-10 09:59:38 Test Loss = 0.031423067990471 
2016-12-10 09:59:38 -------------------LR------------------- 
2016-12-10 09:59:38 0.0078125 
2016-12-10 09:59:38 Epoch 78 
2016-12-10 10:02:39 Training Error = 0.51424328338059 
2016-12-10 10:02:39 Training Loss = 0.024814529561418 
2016-12-10 10:02:44 Valid Error = 0.54070473876063 
2016-12-10 10:02:44 Valid Loss = 0.028151085822772 
2016-12-10 10:02:49 Test Error = 0.58624454148472 
2016-12-10 10:02:49 Test Loss = 0.032217245924707 
2016-12-10 10:02:49 -------------------LR------------------- 
2016-12-10 10:02:49 0.0078125 
2016-12-10 10:02:49 Epoch 79 
2016-12-10 10:05:51 Training Error = 0.51059808289456 
2016-12-10 10:05:51 Training Loss = 0.024683370179533 
2016-12-10 10:05:56 Valid Error = 0.54434993924666 
2016-12-10 10:05:56 Valid Loss = 0.028188640995212 
2016-12-10 10:06:01 Test Error = 0.59170305676856 
2016-12-10 10:06:01 Test Loss = 0.032050049258213 
2016-12-10 10:06:01 -------------------LR------------------- 
2016-12-10 10:06:01 0.0078125 
2016-12-10 10:06:01 Epoch 80 
2016-12-10 10:09:11 Training Error = 0.51343323882814 
2016-12-10 10:09:11 Training Loss = 0.024728484298179 
2016-12-10 10:09:16 Valid Error = 0.54070473876063 
2016-12-10 10:09:16 Valid Loss = 0.028300911044379 
2016-12-10 10:09:21 Test Error = 0.58624454148472 
2016-12-10 10:09:21 Test Loss = 0.032264189776252 
2016-12-10 10:09:21 -------------------LR------------------- 
2016-12-10 10:09:21 0.0078125 
2016-12-10 10:09:21 Epoch 81 
2016-12-10 10:12:26 Training Error = 0.5128932091265 
2016-12-10 10:12:26 Training Loss = 0.024835432609323 
2016-12-10 10:12:30 Valid Error = 0.54070473876063 
2016-12-10 10:12:30 Valid Loss = 0.028585162468567 
2016-12-10 10:12:36 Test Error = 0.58624454148472 
2016-12-10 10:12:36 Test Loss = 0.032468128484838 
2016-12-10 10:12:36 -------------------LR------------------- 
2016-12-10 10:12:36 0.0078125 
2016-12-10 10:12:36 Epoch 82 
2016-12-10 10:15:38 Training Error = 0.5128932091265 
2016-12-10 10:15:38 Training Loss = 0.024926641666188 
2016-12-10 10:15:42 Valid Error = 0.61846901579587 
2016-12-10 10:15:42 Valid Loss = 0.028708980495622 
2016-12-10 10:15:48 Test Error = 0.67467248908297 
2016-12-10 10:15:48 Test Loss = 0.033006489248837 
2016-12-10 10:15:48 -------------------LR------------------- 
2016-12-10 10:15:48 0.0078125 
2016-12-10 10:15:48 Epoch 83 
2016-12-10 10:18:50 Training Error = 0.51680842446335 
2016-12-10 10:18:50 Training Loss = 0.024823342738788 
2016-12-10 10:18:54 Valid Error = 0.61239368165249 
2016-12-10 10:18:54 Valid Loss = 0.028468538576809 
2016-12-10 10:19:00 Test Error = 0.67139737991266 
2016-12-10 10:19:00 Test Loss = 0.03264859010659 
2016-12-10 10:19:00 -------------------LR------------------- 
2016-12-10 10:19:00 0.0078125 
2016-12-10 10:19:00 Epoch 84 
2016-12-10 10:22:04 Training Error = 0.51478331308222 
2016-12-10 10:22:04 Training Loss = 0.025004494586734 
2016-12-10 10:22:09 Valid Error = 0.55042527339004 
2016-12-10 10:22:09 Valid Loss = 0.028150818508503 
2016-12-10 10:22:14 Test Error = 0.59497816593886 
2016-12-10 10:22:14 Test Loss = 0.032323769887288 
2016-12-10 10:22:14 -------------------LR------------------- 
2016-12-10 10:22:14 0.0078125 
2016-12-10 10:22:14 Epoch 85 
2016-12-10 10:25:17 Training Error = 0.51572836506008 
2016-12-10 10:25:17 Training Loss = 0.024999666211496 
2016-12-10 10:25:22 Valid Error = 0.54434993924666 
2016-12-10 10:25:22 Valid Loss = 0.028727645852343 
2016-12-10 10:25:27 Test Error = 0.59170305676856 
2016-12-10 10:25:27 Test Loss = 0.032959616941564 
2016-12-10 10:25:27 -------------------LR------------------- 
2016-12-10 10:25:27 0.0078125 
2016-12-10 10:25:27 Epoch 86 
2016-12-10 10:28:30 Training Error = 0.51464830565681 
2016-12-10 10:28:30 Training Loss = 0.024784370356826 
2016-12-10 10:28:35 Valid Error = 0.6221142162819 
2016-12-10 10:28:35 Valid Loss = 0.029411169154926 
2016-12-10 10:28:40 Test Error = 0.68558951965065 
2016-12-10 10:28:40 Test Loss = 0.033506896374272 
2016-12-10 10:28:40 -------------------LR------------------- 
2016-12-10 10:28:40 0.0078125 
2016-12-10 10:28:40 Epoch 87 
2016-12-10 10:31:44 Training Error = 0.5145132982314 
2016-12-10 10:31:44 Training Loss = 0.024923211875082 
2016-12-10 10:31:49 Valid Error = 0.61846901579587 
2016-12-10 10:31:49 Valid Loss = 0.029224055627084 
2016-12-10 10:31:54 Test Error = 0.68013100436681 
2016-12-10 10:31:54 Test Loss = 0.033578017590093 
2016-12-10 10:31:54 -------------------LR------------------- 
2016-12-10 10:31:54 0.0078125 
2016-12-10 10:31:54 Epoch 88 
2016-12-10 10:34:56 Training Error = 0.51329823140273 
2016-12-10 10:34:56 Training Loss = 0.024918585273465 
2016-12-10 10:35:01 Valid Error = 0.54434993924666 
2016-12-10 10:35:01 Valid Loss = 0.028487085080614 
2016-12-10 10:35:06 Test Error = 0.59170305676856 
2016-12-10 10:35:06 Test Loss = 0.032281428374496 
2016-12-10 10:35:06 -------------------LR------------------- 
2016-12-10 10:35:06 0.0078125 
2016-12-10 10:35:06 Epoch 89 
2016-12-10 10:38:09 Training Error = 0.51626839476171 
2016-12-10 10:38:09 Training Loss = 0.024689736706247 
2016-12-10 10:38:14 Valid Error = 0.52612393681652 
2016-12-10 10:38:14 Valid Loss = 0.027122938129569 
2016-12-10 10:38:19 Test Error = 0.5764192139738 
2016-12-10 10:38:19 Test Loss = 0.031347091824401 
2016-12-10 10:38:19 -------------------LR------------------- 
2016-12-10 10:38:19 0.0078125 
2016-12-10 10:38:19 Epoch 90 
2016-12-10 10:41:33 Training Error = 0.51248818685028 
2016-12-10 10:41:33 Training Loss = 0.024793540742306 
2016-12-10 10:41:38 Valid Error = 0.54799513973269 
2016-12-10 10:41:38 Valid Loss = 0.026427390194418 
2016-12-10 10:41:43 Test Error = 0.58515283842795 
2016-12-10 10:41:43 Test Loss = 0.030226209490907 
2016-12-10 10:41:43 -------------------LR------------------- 
2016-12-10 10:41:43 0.0078125 
2016-12-10 10:41:43 Epoch 91 
2016-12-10 10:44:42 Training Error = 0.51194815714864 
2016-12-10 10:44:42 Training Loss = 0.024870786773368 
2016-12-10 10:44:47 Valid Error = 0.61846901579587 
2016-12-10 10:44:47 Valid Loss = 0.028996402190876 
2016-12-10 10:44:52 Test Error = 0.68013100436681 
2016-12-10 10:44:52 Test Loss = 0.033258881662406 
2016-12-10 10:44:52 -------------------LR------------------- 
2016-12-10 10:44:52 0.0078125 
2016-12-10 10:44:52 Epoch 92 
2016-12-10 10:47:56 Training Error = 0.51640340218712 
2016-12-10 10:47:56 Training Loss = 0.025057831548554 
2016-12-10 10:48:01 Valid Error = 0.54434993924666 
2016-12-10 10:48:01 Valid Loss = 0.028560298447403 
2016-12-10 10:48:06 Test Error = 0.59170305676856 
2016-12-10 10:48:06 Test Loss = 0.032576340376162 
2016-12-10 10:48:06 -------------------LR------------------- 
2016-12-10 10:48:06 0.0078125 
2016-12-10 10:48:06 Epoch 93 
2016-12-10 10:51:10 Training Error = 0.51383826110436 
2016-12-10 10:51:10 Training Loss = 0.024960216948921 
2016-12-10 10:51:15 Valid Error = 0.6221142162819 
2016-12-10 10:51:15 Valid Loss = 0.028664523817841 
2016-12-10 10:51:20 Test Error = 0.68558951965065 
2016-12-10 10:51:20 Test Loss = 0.032722668722564 
2016-12-10 10:51:20 -------------------LR------------------- 
2016-12-10 10:51:20 0.0078125 
2016-12-10 10:51:20 Epoch 94 
2016-12-10 10:54:21 Training Error = 0.51437829080599 
2016-12-10 10:54:21 Training Loss = 0.024908868734465 
2016-12-10 10:54:26 Valid Error = 0.62575941676792 
2016-12-10 10:54:26 Valid Loss = 0.029843951123472 
2016-12-10 10:54:31 Test Error = 0.68777292576419 
2016-12-10 10:54:31 Test Loss = 0.034295199936511 
2016-12-10 10:54:31 -------------------LR------------------- 
2016-12-10 10:54:31 0.0078125 
2016-12-10 10:54:31 Epoch 95 
2016-12-10 10:57:34 Training Error = 0.5128932091265 
2016-12-10 10:57:34 Training Loss = 0.024919175123256 
2016-12-10 10:57:38 Valid Error = 0.61239368165249 
2016-12-10 10:57:38 Valid Loss = 0.029625220147455 
2016-12-10 10:57:44 Test Error = 0.67139737991266 
2016-12-10 10:57:44 Test Loss = 0.03392488896613 
2016-12-10 10:57:44 -------------------LR------------------- 
2016-12-10 10:57:44 0.0078125 
2016-12-10 10:57:44 Epoch 96 
2016-12-10 11:00:49 Training Error = 0.51343323882814 
2016-12-10 11:00:49 Training Loss = 0.024608227856063 
2016-12-10 11:00:54 Valid Error = 0.54070473876063 
2016-12-10 11:00:54 Valid Loss = 0.028920998977556 
2016-12-10 11:00:59 Test Error = 0.58624454148472 
2016-12-10 11:00:59 Test Loss = 0.033278235921673 
2016-12-10 11:00:59 -------------------LR------------------- 
2016-12-10 11:00:59 0.0078125 
2016-12-10 11:00:59 Epoch 97 
2016-12-10 11:03:58 Training Error = 0.51640340218712 
2016-12-10 11:03:58 Training Loss = 0.024909498985141 
2016-12-10 11:04:02 Valid Error = 0.54434993924666 
2016-12-10 11:04:02 Valid Loss = 0.028838338769723 
2016-12-10 11:04:08 Test Error = 0.59170305676856 
2016-12-10 11:04:08 Test Loss = 0.032945841826645 
2016-12-10 11:04:08 -------------------LR------------------- 
2016-12-10 11:04:08 0.0078125 
2016-12-10 11:04:08 Epoch 98 
2016-12-10 11:07:13 Training Error = 0.51248818685028 
2016-12-10 11:07:13 Training Loss = 0.024732551549062 
2016-12-10 11:07:18 Valid Error = 0.54070473876063 
2016-12-10 11:07:18 Valid Loss = 0.028615309359439 
2016-12-10 11:07:23 Test Error = 0.58624454148472 
2016-12-10 11:07:23 Test Loss = 0.032764064396129 
2016-12-10 11:07:23 -------------------LR------------------- 
2016-12-10 11:07:23 0.0078125 
2016-12-10 11:07:23 Epoch 99 
2016-12-10 11:10:27 Training Error = 0.51491832050763 
2016-12-10 11:10:27 Training Loss = 0.02485746495579 
2016-12-10 11:10:32 Valid Error = 0.54070473876063 
2016-12-10 11:10:32 Valid Loss = 0.028480369023689 
2016-12-10 11:10:37 Test Error = 0.58624454148472 
2016-12-10 11:10:37 Test Loss = 0.032563790003459 
2016-12-10 11:10:37 -------------------LR------------------- 
2016-12-10 11:10:37 0.0078125 
2016-12-10 11:10:37 Epoch 100 
2016-12-10 11:13:47 Training Error = 0.51802349129202 
2016-12-10 11:13:47 Training Loss = 0.024822484349982 
2016-12-10 11:13:52 Valid Error = 0.54070473876063 
2016-12-10 11:13:52 Valid Loss = 0.027740844295842 
2016-12-10 11:13:57 Test Error = 0.58624454148472 
2016-12-10 11:13:57 Test Loss = 0.031669483016519 
2016-12-10 11:13:57 -------------------LR------------------- 
2016-12-10 11:13:57 0.00390625 
2016-12-10 11:13:57 Epoch 101 
2016-12-10 11:16:59 Training Error = 0.51140812744701 
2016-12-10 11:16:59 Training Loss = 0.024886733664006 
2016-12-10 11:17:04 Valid Error = 0.54434993924666 
2016-12-10 11:17:04 Valid Loss = 0.027078604445693 
2016-12-10 11:17:09 Test Error = 0.59170305676856 
2016-12-10 11:17:09 Test Loss = 0.031090043124031 
2016-12-10 11:17:09 -------------------LR------------------- 
2016-12-10 11:17:09 0.00390625 
2016-12-10 11:17:09 Epoch 102 
2016-12-10 11:20:10 Training Error = 0.5161333873363 
2016-12-10 11:20:10 Training Loss = 0.024789623350968 
2016-12-10 11:20:15 Valid Error = 0.61239368165249 
2016-12-10 11:20:15 Valid Loss = 0.029311736991169 
2016-12-10 11:20:20 Test Error = 0.67139737991266 
2016-12-10 11:20:20 Test Loss = 0.033565693256902 
2016-12-10 11:20:20 -------------------LR------------------- 
2016-12-10 11:20:20 0.00390625 
2016-12-10 11:20:20 Epoch 103 
2016-12-10 11:23:24 Training Error = 0.51262319427569 
2016-12-10 11:23:24 Training Loss = 0.024955746431466 
2016-12-10 11:23:29 Valid Error = 0.54070473876063 
2016-12-10 11:23:29 Valid Loss = 0.028763458730371 
2016-12-10 11:23:34 Test Error = 0.58624454148472 
2016-12-10 11:23:34 Test Loss = 0.032839314722547 
2016-12-10 11:23:34 -------------------LR------------------- 
2016-12-10 11:23:34 0.00390625 
2016-12-10 11:23:34 Epoch 104 
2016-12-10 11:26:36 Training Error = 0.51680842446335 
2016-12-10 11:26:36 Training Loss = 0.0249287146717 
2016-12-10 11:26:40 Valid Error = 0.54434993924666 
2016-12-10 11:26:40 Valid Loss = 0.027116666061923 
2016-12-10 11:26:46 Test Error = 0.58624454148472 
2016-12-10 11:26:46 Test Loss = 0.031173782161638 
2016-12-10 11:26:46 -------------------LR------------------- 
2016-12-10 11:26:46 0.00390625 
2016-12-10 11:26:46 Epoch 105 
2016-12-10 11:29:41 Training Error = 0.51383826110436 
2016-12-10 11:29:41 Training Loss = 0.024741096005052 
2016-12-10 11:29:46 Valid Error = 0.61846901579587 
2016-12-10 11:29:46 Valid Loss = 0.029559362992719 
2016-12-10 11:29:51 Test Error = 0.68013100436681 
2016-12-10 11:29:51 Test Loss = 0.033766354392557 
2016-12-10 11:29:51 -------------------LR------------------- 
2016-12-10 11:29:51 0.00390625 
2016-12-10 11:29:51 Epoch 106 
2016-12-10 11:32:48 Training Error = 0.5177534764412 
2016-12-10 11:32:48 Training Loss = 0.024828956055485 
2016-12-10 11:32:53 Valid Error = 0.54434993924666 
2016-12-10 11:32:53 Valid Loss = 0.028532693502837 
2016-12-10 11:32:58 Test Error = 0.59170305676856 
2016-12-10 11:32:58 Test Loss = 0.032773968603097 
2016-12-10 11:32:58 -------------------LR------------------- 
2016-12-10 11:32:58 0.00390625 
2016-12-10 11:32:58 Epoch 107 
2016-12-10 11:35:58 Training Error = 0.51437829080599 
2016-12-10 11:35:58 Training Loss = 0.024971250264429 
2016-12-10 11:36:03 Valid Error = 0.54434993924666 
2016-12-10 11:36:03 Valid Loss = 0.028970142995768 
2016-12-10 11:36:08 Test Error = 0.59170305676856 
2016-12-10 11:36:08 Test Loss = 0.033083161447562 
2016-12-10 11:36:08 -------------------LR------------------- 
2016-12-10 11:36:08 0.00390625 
2016-12-10 11:36:08 Epoch 108 
2016-12-10 11:39:03 Training Error = 0.51140812744701 
2016-12-10 11:39:03 Training Loss = 0.024790869798847 
2016-12-10 11:39:08 Valid Error = 0.54434993924666 
2016-12-10 11:39:08 Valid Loss = 0.028588082856546 
2016-12-10 11:39:13 Test Error = 0.59170305676856 
2016-12-10 11:39:13 Test Loss = 0.032437331854128 
2016-12-10 11:39:13 -------------------LR------------------- 
2016-12-10 11:39:13 0.00390625 
2016-12-10 11:39:13 Epoch 109 
2016-12-10 11:42:11 Training Error = 0.5128932091265 
2016-12-10 11:42:11 Training Loss = 0.024821771265879 
2016-12-10 11:42:16 Valid Error = 0.53098420413123 
2016-12-10 11:42:16 Valid Loss = 0.027797444249527 
2016-12-10 11:42:21 Test Error = 0.58187772925764 
2016-12-10 11:42:21 Test Loss = 0.032231008398767 
2016-12-10 11:42:21 -------------------LR------------------- 
2016-12-10 11:42:21 0.00390625 
2016-12-10 11:42:21 Epoch 110 
2016-12-10 11:45:29 Training Error = 0.51545835020926 
2016-12-10 11:45:29 Training Loss = 0.02485105842569 
2016-12-10 11:45:34 Valid Error = 0.53462940461725 
2016-12-10 11:45:34 Valid Loss = 0.027953810435732 
2016-12-10 11:45:39 Test Error = 0.57751091703057 
2016-12-10 11:45:39 Test Loss = 0.031883689207189 
2016-12-10 11:45:39 -------------------LR------------------- 
2016-12-10 11:45:39 0.00390625 
2016-12-10 11:45:39 Epoch 111 
2016-12-10 11:48:34 Training Error = 0.51505332793304 
2016-12-10 11:48:34 Training Loss = 0.024686768202154 
2016-12-10 11:48:39 Valid Error = 0.61846901579587 
2016-12-10 11:48:39 Valid Loss = 0.029442734251739 
2016-12-10 11:48:44 Test Error = 0.68013100436681 
2016-12-10 11:48:44 Test Loss = 0.033704945489472 
2016-12-10 11:48:44 -------------------LR------------------- 
2016-12-10 11:48:44 0.00390625 
2016-12-10 11:48:44 Epoch 112 
2016-12-10 11:51:41 Training Error = 0.51640340218712 
2016-12-10 11:51:41 Training Loss = 0.024925727800072 
2016-12-10 11:51:46 Valid Error = 0.53827460510328 
2016-12-10 11:51:46 Valid Loss = 0.027263277788624 
2016-12-10 11:51:51 Test Error = 0.58296943231441 
2016-12-10 11:51:51 Test Loss = 0.031468514629439 
2016-12-10 11:51:51 -------------------LR------------------- 
2016-12-10 11:51:51 0.00390625 
2016-12-10 11:51:51 Epoch 113 
2016-12-10 11:54:49 Training Error = 0.51559335763467 
2016-12-10 11:54:49 Training Loss = 0.024799259401637 
2016-12-10 11:54:53 Valid Error = 0.54070473876063 
2016-12-10 11:54:53 Valid Loss = 0.028273331328776 
2016-12-10 11:54:59 Test Error = 0.58624454148472 
2016-12-10 11:54:59 Test Loss = 0.03213093770719 
2016-12-10 11:54:59 -------------------LR------------------- 
2016-12-10 11:54:59 0.00390625 
2016-12-10 11:54:59 Epoch 114 
2016-12-10 11:57:57 Training Error = 0.51383826110436 
2016-12-10 11:57:57 Training Loss = 0.024842862155035 
2016-12-10 11:58:01 Valid Error = 0.61239368165249 
2016-12-10 11:58:01 Valid Loss = 0.029842850357291 
2016-12-10 11:58:07 Test Error = 0.67139737991266 
2016-12-10 11:58:07 Test Loss = 0.034318517516641 
2016-12-10 11:58:07 -------------------LR------------------- 
2016-12-10 11:58:07 0.00390625 
2016-12-10 11:58:07 Epoch 115 
2016-12-10 12:01:04 Training Error = 0.51181314972323 
2016-12-10 12:01:04 Training Loss = 0.024818471254265 
2016-12-10 12:01:09 Valid Error = 0.6221142162819 
2016-12-10 12:01:09 Valid Loss = 0.028713754486087 
2016-12-10 12:01:14 Test Error = 0.68558951965065 
2016-12-10 12:01:14 Test Loss = 0.032932741370856 
2016-12-10 12:01:14 -------------------LR------------------- 
2016-12-10 12:01:14 0.00390625 
2016-12-10 12:01:14 Epoch 116 
2016-12-10 12:04:09 Training Error = 0.51653840961253 
2016-12-10 12:04:09 Training Loss = 0.024965428608984 
2016-12-10 12:04:13 Valid Error = 0.54434993924666 
2016-12-10 12:04:13 Valid Loss = 0.028892425063027 
2016-12-10 12:04:19 Test Error = 0.59170305676856 
2016-12-10 12:04:19 Test Loss = 0.0330091678021 
2016-12-10 12:04:19 -------------------LR------------------- 
2016-12-10 12:04:19 0.00390625 
2016-12-10 12:04:19 Epoch 117 
2016-12-10 12:07:15 Training Error = 0.51343323882814 
2016-12-10 12:07:15 Training Loss = 0.024957019621406 
2016-12-10 12:07:20 Valid Error = 0.61603888213852 
2016-12-10 12:07:20 Valid Loss = 0.028934718431301 
2016-12-10 12:07:25 Test Error = 0.6735807860262 
2016-12-10 12:07:25 Test Loss = 0.032990542897991 
2016-12-10 12:07:25 -------------------LR------------------- 
2016-12-10 12:07:25 0.00390625 
2016-12-10 12:07:25 Epoch 118 
2016-12-10 12:10:23 Training Error = 0.52099365465101 
2016-12-10 12:10:23 Training Loss = 0.024938948510719 
2016-12-10 12:10:28 Valid Error = 0.61846901579587 
2016-12-10 12:10:28 Valid Loss = 0.028918563909261 
2016-12-10 12:10:33 Test Error = 0.68013100436681 
2016-12-10 12:10:33 Test Loss = 0.032902609656839 
2016-12-10 12:10:33 -------------------LR------------------- 
2016-12-10 12:10:33 0.00390625 
2016-12-10 12:10:33 Epoch 119 
2016-12-10 12:13:31 Training Error = 0.51667341703794 
2016-12-10 12:13:31 Training Loss = 0.024878071591389 
2016-12-10 12:13:36 Valid Error = 0.61239368165249 
2016-12-10 12:13:36 Valid Loss = 0.028729241383711 
2016-12-10 12:13:41 Test Error = 0.67139737991266 
2016-12-10 12:13:41 Test Loss = 0.032921932295257 
2016-12-10 12:13:41 -------------------LR------------------- 
2016-12-10 12:13:41 0.00390625 
2016-12-10 12:13:41 Epoch 120 
2016-12-10 12:16:46 Training Error = 0.5159983799109 
2016-12-10 12:16:46 Training Loss = 0.024866550139953 
2016-12-10 12:16:51 Valid Error = 0.54434993924666 
2016-12-10 12:16:51 Valid Loss = 0.028817234485565 
2016-12-10 12:16:56 Test Error = 0.59170305676856 
2016-12-10 12:16:56 Test Loss = 0.032916736397089 
2016-12-10 12:16:56 -------------------LR------------------- 
2016-12-10 12:16:56 0.00390625 
2016-12-10 12:16:56 Epoch 121 
2016-12-10 12:19:55 Training Error = 0.51505332793304 
2016-12-10 12:19:55 Training Loss = 0.024903965542719 
2016-12-10 12:20:00 Valid Error = 0.61846901579587 
2016-12-10 12:20:00 Valid Loss = 0.029542089738527 
2016-12-10 12:20:05 Test Error = 0.68013100436681 
2016-12-10 12:20:05 Test Loss = 0.033567244641921 
2016-12-10 12:20:05 -------------------LR------------------- 
2016-12-10 12:20:05 0.00390625 
2016-12-10 12:20:05 Epoch 122 
2016-12-10 12:23:01 Training Error = 0.51532334278385 
2016-12-10 12:23:01 Training Loss = 0.024805955474027 
2016-12-10 12:23:06 Valid Error = 0.54070473876063 
2016-12-10 12:23:06 Valid Loss = 0.028016273127797 
2016-12-10 12:23:11 Test Error = 0.58624454148472 
2016-12-10 12:23:11 Test Loss = 0.03187442519618 
2016-12-10 12:23:11 -------------------LR------------------- 
2016-12-10 12:23:11 0.00390625 
2016-12-10 12:23:11 Epoch 123 
2016-12-10 12:26:08 Training Error = 0.51518833535844 
2016-12-10 12:26:08 Training Loss = 0.024843497205604 
2016-12-10 12:26:13 Valid Error = 0.54070473876063 
2016-12-10 12:26:13 Valid Loss = 0.028574258671166 
2016-12-10 12:26:18 Test Error = 0.58078602620087 
2016-12-10 12:26:18 Test Loss = 0.032947266821768 
2016-12-10 12:26:18 -------------------LR------------------- 
2016-12-10 12:26:18 0.00390625 
2016-12-10 12:26:18 Epoch 124 
2016-12-10 12:29:16 Training Error = 0.51437829080599 
2016-12-10 12:29:16 Training Loss = 0.024897189417963 
2016-12-10 12:29:21 Valid Error = 0.54434993924666 
2016-12-10 12:29:21 Valid Loss = 0.028115080609131 
2016-12-10 12:29:26 Test Error = 0.59170305676856 
2016-12-10 12:29:26 Test Loss = 0.032113306213828 
2016-12-10 12:29:26 -------------------LR------------------- 
2016-12-10 12:29:26 0.00390625 
2016-12-10 12:29:26 Epoch 125 
2016-12-10 12:32:23 Training Error = 0.5161333873363 
2016-12-10 12:32:23 Training Loss = 0.024782723182657 
2016-12-10 12:32:28 Valid Error = 0.6221142162819 
2016-12-10 12:32:28 Valid Loss = 0.029111489717556 
2016-12-10 12:32:33 Test Error = 0.68558951965065 
2016-12-10 12:32:33 Test Loss = 0.033209421120438 
2016-12-10 12:32:33 -------------------LR------------------- 
2016-12-10 12:32:33 0.00390625 
2016-12-10 12:32:33 Epoch 126 
2016-12-10 12:35:32 Training Error = 0.51343323882814 
2016-12-10 12:35:32 Training Loss = 0.024832760369366 
2016-12-10 12:35:37 Valid Error = 0.54434993924666 
2016-12-10 12:35:37 Valid Loss = 0.02936691872446 
2016-12-10 12:35:42 Test Error = 0.59170305676856 
2016-12-10 12:35:42 Test Loss = 0.03363588589313 
2016-12-10 12:35:42 -------------------LR------------------- 
2016-12-10 12:35:42 0.00390625 
2016-12-10 12:35:42 Epoch 127 
2016-12-10 12:38:38 Training Error = 0.51545835020926 
2016-12-10 12:38:38 Training Loss = 0.024776253069994 
2016-12-10 12:38:42 Valid Error = 0.61846901579587 
2016-12-10 12:38:42 Valid Loss = 0.028911949006674 
2016-12-10 12:38:47 Test Error = 0.68013100436681 
2016-12-10 12:38:47 Test Loss = 0.032942409253588 
2016-12-10 12:38:47 -------------------LR------------------- 
2016-12-10 12:38:47 0.00390625 
2016-12-10 12:38:47 Epoch 128 
2016-12-10 12:41:46 Training Error = 0.51437829080599 
2016-12-10 12:41:46 Training Loss = 0.024694459150441 
2016-12-10 12:41:51 Valid Error = 0.54070473876063 
2016-12-10 12:41:51 Valid Loss = 0.028136063272488 
2016-12-10 12:41:56 Test Error = 0.58624454148472 
2016-12-10 12:41:56 Test Loss = 0.032296747544233 
2016-12-10 12:41:56 -------------------LR------------------- 
2016-12-10 12:41:56 0.00390625 
2016-12-10 12:41:56 Epoch 129 
2016-12-10 12:44:53 Training Error = 0.51748346159039 
2016-12-10 12:44:53 Training Loss = 0.024902455355718 
2016-12-10 12:44:58 Valid Error = 0.53098420413123 
2016-12-10 12:44:58 Valid Loss = 0.026715701205199 
2016-12-10 12:45:03 Test Error = 0.5764192139738 
2016-12-10 12:45:03 Test Loss = 0.030741894273197 
2016-12-10 12:45:03 -------------------LR------------------- 
2016-12-10 12:45:03 0.00390625 
2016-12-10 12:45:03 Epoch 130 
