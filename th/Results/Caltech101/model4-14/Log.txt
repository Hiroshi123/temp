2016-12-10 05:59:23 [program started on Sat Dec 10 05:59:23 2016] 
2016-12-10 05:59:23 [command line arguments] 
2016-12-10 05:59:23 stcWeights false 
2016-12-10 05:59:23 LR 0.015625 
2016-12-10 05:59:23 batchSize 100 
2016-12-10 05:59:23 network ./Models/Cifar10_Custom 
2016-12-10 05:59:23 stcNeurons true 
2016-12-10 05:59:23 constBatchSize false 
2016-12-10 05:59:23 chartFileName chart1 
2016-12-10 05:59:23 dp_prepro false 
2016-12-10 05:59:23 nGPU 1 
2016-12-10 05:59:23 dataset Caltech101 
2016-12-10 05:59:23 type cuda 
2016-12-10 05:59:23 momentum 0 
2016-12-10 05:59:23 threads 8 
2016-12-10 05:59:23 weightDecay 0 
2016-12-10 05:59:23 runningVal false 
2016-12-10 05:59:23 convLayerN 4 
2016-12-10 05:59:23 LRDecay 0 
2016-12-10 05:59:23 numHid 1024 
2016-12-10 05:59:23 save /dev/shm/clone/temp/th/Results/Caltech101/model4-14 
2016-12-10 05:59:23 augment false 
2016-12-10 05:59:23 epoch -1 
2016-12-10 05:59:23 modelsFolder ./Models/ 
2016-12-10 05:59:23 format rgb 
2016-12-10 05:59:23 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-10 05:59:23 imageFileExtension svg 
2016-12-10 05:59:23 channel 1.4 
2016-12-10 05:59:23 devid 12 
2016-12-10 05:59:23 visualize 1 
2016-12-10 05:59:23 LRDecayPerEpoch 0.0001 
2016-12-10 05:59:23 optimization adam 
2016-12-10 05:59:23 SBN true 
2016-12-10 05:59:23 normalization simple 
2016-12-10 05:59:23 title model1 
2016-12-10 05:59:23 load  
2016-12-10 05:59:23 whiten true 
2016-12-10 05:59:23 [----------------------] 
2016-12-10 05:59:24 ==> Network 
2016-12-10 05:59:24 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 179, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(179 -> 179, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(179 -> 358, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(358 -> 358, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): nn.View(22912)
  (20): BinaryLinear(22912 -> 1024)
  (21): BatchNormalizationShiftPow2
  (22): nn.HardTanh
  (23): BinarizedNeurons
  (24): BinaryLinear(1024 -> 1024)
  (25): BatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): BinaryLinear(1024 -> 102)
  (29): nn.BatchNormalization
} 
2016-12-10 05:59:24 ==>26648000 Parameters 
2016-12-10 05:59:24 ==> Loss 
2016-12-10 05:59:24 SqrtHingeEmbeddingCriterion 
2016-12-10 05:59:24 
==> Starting Training
 
2016-12-10 05:59:24 Epoch 1 
2016-12-10 06:01:02 Training Error = 0.73768057243148 
2016-12-10 06:01:02 Training Loss = 0.4060539490373 
2016-12-10 06:01:05 Valid Error = 0.71445929526124 
2016-12-10 06:01:05 Valid Loss = 0.0674211758448 
2016-12-10 06:01:08 Test Error = 0.74781659388646 
2016-12-10 06:01:08 Test Loss = 0.068326414295271 
2016-12-10 06:01:08 -------------------LR------------------- 
2016-12-10 06:01:08 0.015625 
2016-12-10 06:01:08 Epoch 2 
2016-12-10 06:02:41 Training Error = 0.5916025381396 
2016-12-10 06:02:41 Training Loss = 0.037960940440629 
2016-12-10 06:02:43 Valid Error = 0.60996354799514 
2016-12-10 06:02:43 Valid Loss = 0.027909651468387 
2016-12-10 06:02:46 Test Error = 0.62336244541485 
2016-12-10 06:02:46 Test Loss = 0.030076390079423 
2016-12-10 06:02:46 -------------------LR------------------- 
2016-12-10 06:02:46 0.015625 
2016-12-10 06:02:46 Epoch 3 
2016-12-10 06:04:22 Training Error = 0.53030916700419 
2016-12-10 06:04:22 Training Loss = 0.027271823407911 
2016-12-10 06:04:25 Valid Error = 0.61117861482382 
2016-12-10 06:04:25 Valid Loss = 0.030527468413309 
2016-12-10 06:04:27 Test Error = 0.61681222707424 
2016-12-10 06:04:27 Test Loss = 0.032957169457978 
2016-12-10 06:04:27 -------------------LR------------------- 
2016-12-10 06:04:27 0.015625 
2016-12-10 06:04:27 Epoch 4 
2016-12-10 06:06:22 Training Error = 0.504792763602 
2016-12-10 06:06:22 Training Loss = 0.025740377501302 
2016-12-10 06:06:25 Valid Error = 0.48724179829891 
2016-12-10 06:06:25 Valid Loss = 0.025492914107145 
2016-12-10 06:06:28 Test Error = 0.54039301310044 
2016-12-10 06:06:28 Test Loss = 0.02906716412189 
2016-12-10 06:06:28 -------------------LR------------------- 
2016-12-10 06:06:28 0.015625 
2016-12-10 06:06:28 Epoch 5 
2016-12-10 06:08:15 Training Error = 0.48575671661941 
2016-12-10 06:08:15 Training Loss = 0.025216637220481 
2016-12-10 06:08:17 Valid Error = 0.48481166464156 
2016-12-10 06:08:17 Valid Loss = 0.026058438788809 
2016-12-10 06:08:20 Test Error = 0.53165938864629 
2016-12-10 06:08:20 Test Loss = 0.030601412156049 
2016-12-10 06:08:20 -------------------LR------------------- 
2016-12-10 06:08:20 0.015625 
2016-12-10 06:08:20 Epoch 6 
2016-12-10 06:09:55 Training Error = 0.47414607803429 
2016-12-10 06:09:55 Training Loss = 0.024451427842255 
2016-12-10 06:09:58 Valid Error = 0.56014580801944 
2016-12-10 06:09:58 Valid Loss = 0.026044430398033 
2016-12-10 06:10:00 Test Error = 0.5971615720524 
2016-12-10 06:10:00 Test Loss = 0.029400528533786 
2016-12-10 06:10:00 -------------------LR------------------- 
2016-12-10 06:10:00 0.015625 
2016-12-10 06:10:00 Epoch 7 
2016-12-10 06:11:49 Training Error = 0.42203321182665 
2016-12-10 06:11:49 Training Loss = 0.022798010537426 
2016-12-10 06:11:52 Valid Error = 0.40583232077764 
2016-12-10 06:11:52 Valid Loss = 0.022715540346892 
2016-12-10 06:11:55 Test Error = 0.4443231441048 
2016-12-10 06:11:55 Test Loss = 0.026898138382856 
2016-12-10 06:11:55 -------------------LR------------------- 
2016-12-10 06:11:55 0.015625 
2016-12-10 06:11:55 Epoch 8 
2016-12-10 06:13:39 Training Error = 0.37370055353044 
2016-12-10 06:13:39 Training Loss = 0.021930821383322 
2016-12-10 06:13:41 Valid Error = 0.38396111786148 
2016-12-10 06:13:41 Valid Loss = 0.021414446428304 
2016-12-10 06:13:44 Test Error = 0.42685589519651 
2016-12-10 06:13:44 Test Loss = 0.025469981343138 
2016-12-10 06:13:44 -------------------LR------------------- 
2016-12-10 06:13:44 0.015625 
2016-12-10 06:13:44 Epoch 9 
2016-12-10 06:15:18 Training Error = 0.30943701903605 
2016-12-10 06:15:18 Training Loss = 0.020585360791859 
2016-12-10 06:15:20 Valid Error = 0.43013365735115 
2016-12-10 06:15:20 Valid Loss = 0.024030584566767 
2016-12-10 06:15:23 Test Error = 0.4443231441048 
2016-12-10 06:15:23 Test Loss = 0.026018334407432 
2016-12-10 06:15:23 -------------------LR------------------- 
2016-12-10 06:15:23 0.015625 
2016-12-10 06:15:23 Epoch 10 
2016-12-10 06:17:06 Training Error = 0.25529904144728 
2016-12-10 06:17:06 Training Loss = 0.019120637512207 
2016-12-10 06:17:09 Valid Error = 0.24422843256379 
2016-12-10 06:17:09 Valid Loss = 0.01753809009728 
2016-12-10 06:17:11 Test Error = 0.26091703056769 
2016-12-10 06:17:11 Test Loss = 0.020174425452363 
2016-12-10 06:17:11 -------------------LR------------------- 
2016-12-10 06:17:11 0.015625 
2016-12-10 06:17:11 Epoch 11 
2016-12-10 06:18:49 Training Error = 0.20750641285271 
2016-12-10 06:18:49 Training Loss = 0.017981435514676 
2016-12-10 06:18:51 Valid Error = 0.35722964763062 
2016-12-10 06:18:51 Valid Loss = 0.021231783543209 
2016-12-10 06:18:54 Test Error = 0.37554585152838 
2016-12-10 06:18:54 Test Loss = 0.023499814042858 
2016-12-10 06:18:54 -------------------LR------------------- 
2016-12-10 06:18:54 0.015625 
2016-12-10 06:18:54 Epoch 12 
2016-12-10 06:20:31 Training Error = 0.20885648710679 
2016-12-10 06:20:31 Training Loss = 0.01792822005328 
2016-12-10 06:20:33 Valid Error = 0.39246658566221 
2016-12-10 06:20:33 Valid Loss = 0.021099373858185 
2016-12-10 06:20:36 Test Error = 0.41266375545852 
2016-12-10 06:20:36 Test Loss = 0.023416651576173 
2016-12-10 06:20:36 -------------------LR------------------- 
2016-12-10 06:20:36 0.015625 
2016-12-10 06:20:36 Epoch 13 
2016-12-10 06:22:13 Training Error = 0.21439179154854 
2016-12-10 06:22:13 Training Loss = 0.018039269701818 
2016-12-10 06:22:15 Valid Error = 0.36452004860267 
2016-12-10 06:22:15 Valid Loss = 0.021168979208634 
2016-12-10 06:22:18 Test Error = 0.39737991266376 
2016-12-10 06:22:18 Test Loss = 0.023458053953507 
2016-12-10 06:22:18 -------------------LR------------------- 
2016-12-10 06:22:18 0.015625 
2016-12-10 06:22:18 Epoch 14 
2016-12-10 06:23:55 Training Error = 0.21371675442149 
2016-12-10 06:23:55 Training Loss = 0.018084704058422 
2016-12-10 06:23:58 Valid Error = 0.38639125151883 
2016-12-10 06:23:58 Valid Loss = 0.021402545114849 
2016-12-10 06:24:00 Test Error = 0.40174672489083 
2016-12-10 06:24:00 Test Loss = 0.0236140888719 
2016-12-10 06:24:00 -------------------LR------------------- 
2016-12-10 06:24:00 0.015625 
2016-12-10 06:24:00 Epoch 15 
2016-12-10 06:25:37 Training Error = 0.20872147968138 
2016-12-10 06:25:37 Training Loss = 0.017928637074133 
2016-12-10 06:25:39 Valid Error = 0.37181044957473 
2016-12-10 06:25:39 Valid Loss = 0.02157927982236 
2016-12-10 06:25:42 Test Error = 0.39301310043668 
2016-12-10 06:25:42 Test Loss = 0.023839775571636 
2016-12-10 06:25:42 -------------------LR------------------- 
2016-12-10 06:25:42 0.015625 
2016-12-10 06:25:42 Epoch 16 
2016-12-10 06:27:33 Training Error = 0.20818144997975 
2016-12-10 06:27:33 Training Loss = 0.018000215042072 
2016-12-10 06:27:35 Valid Error = 0.3681652490887 
2016-12-10 06:27:35 Valid Loss = 0.021164899668685 
2016-12-10 06:27:38 Test Error = 0.39519650655022 
2016-12-10 06:27:38 Test Loss = 0.023289006766151 
2016-12-10 06:27:38 -------------------LR------------------- 
2016-12-10 06:27:38 0.015625 
2016-12-10 06:27:38 Epoch 17 
2016-12-10 06:29:21 Training Error = 0.20993654651006 
2016-12-10 06:29:21 Training Loss = 0.017936899625776 
2016-12-10 06:29:24 Valid Error = 0.3730255164034 
2016-12-10 06:29:24 Valid Loss = 0.022167263972304 
2016-12-10 06:29:26 Test Error = 0.38973799126638 
2016-12-10 06:29:26 Test Loss = 0.024227360229866 
2016-12-10 06:29:26 -------------------LR------------------- 
2016-12-10 06:29:26 0.015625 
2016-12-10 06:29:26 Epoch 18 
2016-12-10 06:31:09 Training Error = 0.20885648710679 
2016-12-10 06:31:09 Training Loss = 0.017999556472166 
2016-12-10 06:31:12 Valid Error = 0.37181044957473 
2016-12-10 06:31:12 Valid Loss = 0.021708051047904 
2016-12-10 06:31:14 Test Error = 0.39737991266376 
2016-12-10 06:31:14 Test Loss = 0.023828375975291 
2016-12-10 06:31:14 -------------------LR------------------- 
2016-12-10 06:31:14 0.015625 
2016-12-10 06:31:14 Epoch 19 
2016-12-10 06:32:57 Training Error = 0.21479681382476 
2016-12-10 06:32:57 Training Loss = 0.017992522954006 
2016-12-10 06:32:59 Valid Error = 0.34021871202916 
2016-12-10 06:32:59 Valid Loss = 0.020755610941621 
2016-12-10 06:33:02 Test Error = 0.34934497816594 
2016-12-10 06:33:02 Test Loss = 0.022852543110941 
2016-12-10 06:33:02 -------------------LR------------------- 
2016-12-10 06:33:02 0.015625 
2016-12-10 06:33:02 Epoch 20 
2016-12-10 06:34:46 Training Error = 0.21115161333873 
2016-12-10 06:34:46 Training Loss = 0.01798322402142 
2016-12-10 06:34:48 Valid Error = 0.35722964763062 
2016-12-10 06:34:48 Valid Loss = 0.020989451298628 
2016-12-10 06:34:51 Test Error = 0.35917030567686 
2016-12-10 06:34:51 Test Loss = 0.02327374383515 
2016-12-10 06:34:51 -------------------LR------------------- 
2016-12-10 06:34:51 0.015625 
2016-12-10 06:34:51 Epoch 21 
2016-12-10 06:36:35 Training Error = 0.21304171729445 
2016-12-10 06:36:35 Training Loss = 0.018102751149695 
2016-12-10 06:36:37 Valid Error = 0.37059538274605 
2016-12-10 06:36:37 Valid Loss = 0.021665480955991 
2016-12-10 06:36:40 Test Error = 0.39192139737991 
2016-12-10 06:36:40 Test Loss = 0.023918076346902 
2016-12-10 06:36:40 -------------------LR------------------- 
2016-12-10 06:36:40 0.015625 
2016-12-10 06:36:40 Epoch 22 
2016-12-10 06:38:23 Training Error = 0.21088159848792 
2016-12-10 06:38:23 Training Loss = 0.017933095024102 
2016-12-10 06:38:25 Valid Error = 0.35722964763062 
2016-12-10 06:38:25 Valid Loss = 0.021412597508822 
2016-12-10 06:38:28 Test Error = 0.3853711790393 
2016-12-10 06:38:28 Test Loss = 0.023599728864782 
2016-12-10 06:38:28 -------------------LR------------------- 
2016-12-10 06:38:28 0.015625 
2016-12-10 06:38:28 Epoch 23 
2016-12-10 06:40:08 Training Error = 0.20993654651006 
2016-12-10 06:40:08 Training Loss = 0.017885149432698 
2016-12-10 06:40:11 Valid Error = 0.38031591737546 
2016-12-10 06:40:11 Valid Loss = 0.021337557268084 
2016-12-10 06:40:14 Test Error = 0.40174672489083 
2016-12-10 06:40:14 Test Loss = 0.023672264575958 
2016-12-10 06:40:14 -------------------LR------------------- 
2016-12-10 06:40:14 0.015625 
2016-12-10 06:40:14 Epoch 24 
2016-12-10 06:41:54 Training Error = 0.21250168759282 
2016-12-10 06:41:54 Training Loss = 0.018178549580436 
2016-12-10 06:41:57 Valid Error = 0.33657351154313 
2016-12-10 06:41:57 Valid Loss = 0.020641965100945 
2016-12-10 06:42:00 Test Error = 0.35917030567686 
2016-12-10 06:42:00 Test Loss = 0.0230484957882 
2016-12-10 06:42:00 -------------------LR------------------- 
2016-12-10 06:42:00 0.015625 
2016-12-10 06:42:00 Epoch 25 
2016-12-10 06:43:40 Training Error = 0.21344673957068 
2016-12-10 06:43:40 Training Loss = 0.018033160114021 
2016-12-10 06:43:43 Valid Error = 0.36573511543135 
2016-12-10 06:43:43 Valid Loss = 0.021642515430557 
2016-12-10 06:43:46 Test Error = 0.38755458515284 
2016-12-10 06:43:46 Test Loss = 0.023812167345309 
2016-12-10 06:43:46 -------------------LR------------------- 
2016-12-10 06:43:46 0.015625 
2016-12-10 06:43:46 Epoch 26 
2016-12-10 06:45:29 Training Error = 0.21398676927231 
2016-12-10 06:45:29 Training Loss = 0.017995446580732 
2016-12-10 06:45:31 Valid Error = 0.38274605103281 
2016-12-10 06:45:31 Valid Loss = 0.02195856169339 
2016-12-10 06:45:34 Test Error = 0.40174672489083 
2016-12-10 06:45:34 Test Loss = 0.024171085806454 
2016-12-10 06:45:34 -------------------LR------------------- 
2016-12-10 06:45:34 0.015625 
2016-12-10 06:45:34 Epoch 27 
2016-12-10 06:47:14 Training Error = 0.21344673957068 
2016-12-10 06:47:14 Training Loss = 0.017935434564044 
2016-12-10 06:47:17 Valid Error = 0.3730255164034 
2016-12-10 06:47:17 Valid Loss = 0.021876405016924 
2016-12-10 06:47:19 Test Error = 0.39956331877729 
2016-12-10 06:47:19 Test Loss = 0.023889185213575 
2016-12-10 06:47:19 -------------------LR------------------- 
2016-12-10 06:47:19 0.015625 
2016-12-10 06:47:19 Epoch 28 
2016-12-10 06:49:07 Training Error = 0.21236668016741 
2016-12-10 06:49:07 Training Loss = 0.017942132710832 
2016-12-10 06:49:09 Valid Error = 0.34993924665857 
2016-12-10 06:49:09 Valid Loss = 0.020292343829091 
2016-12-10 06:49:12 Test Error = 0.3471615720524 
2016-12-10 06:49:12 Test Loss = 0.022393724647223 
2016-12-10 06:49:12 -------------------LR------------------- 
2016-12-10 06:49:12 0.015625 
2016-12-10 06:49:12 Epoch 29 
2016-12-10 06:51:02 Training Error = 0.20710139057648 
2016-12-10 06:51:02 Training Loss = 0.017946114263169 
2016-12-10 06:51:05 Valid Error = 0.37424058323208 
2016-12-10 06:51:05 Valid Loss = 0.021150853557321 
2016-12-10 06:51:07 Test Error = 0.40065502183406 
2016-12-10 06:51:07 Test Loss = 0.023640595950332 
2016-12-10 06:51:07 -------------------LR------------------- 
2016-12-10 06:51:07 0.015625 
2016-12-10 06:51:07 Epoch 30 
2016-12-10 06:53:03 Training Error = 0.21142162818955 
2016-12-10 06:53:03 Training Loss = 0.01796287076008 
2016-12-10 06:53:05 Valid Error = 0.36087484811665 
2016-12-10 06:53:05 Valid Loss = 0.020425351876319 
2016-12-10 06:53:08 Test Error = 0.3853711790393 
2016-12-10 06:53:08 Test Loss = 0.022724533903833 
2016-12-10 06:53:08 -------------------LR------------------- 
2016-12-10 06:53:08 0.015625 
2016-12-10 06:53:08 Epoch 31 
2016-12-10 06:55:04 Training Error = 0.20926150938302 
2016-12-10 06:55:04 Training Loss = 0.018118947193135 
2016-12-10 06:55:06 Valid Error = 0.37667071688943 
2016-12-10 06:55:06 Valid Loss = 0.021899603395353 
2016-12-10 06:55:09 Test Error = 0.39737991266376 
2016-12-10 06:55:09 Test Loss = 0.024088936899223 
2016-12-10 06:55:09 -------------------LR------------------- 
2016-12-10 06:55:09 0.015625 
2016-12-10 06:55:09 Epoch 32 
2016-12-10 06:57:04 Training Error = 0.21196165789118 
2016-12-10 06:57:04 Training Loss = 0.018107273894665 
2016-12-10 06:57:06 Valid Error = 0.3730255164034 
2016-12-10 06:57:06 Valid Loss = 0.022128444352565 
2016-12-10 06:57:09 Test Error = 0.39628820960699 
2016-12-10 06:57:09 Test Loss = 0.024368863704158 
2016-12-10 06:57:09 -------------------LR------------------- 
2016-12-10 06:57:09 0.015625 
2016-12-10 06:57:09 Epoch 33 
2016-12-10 06:59:01 Training Error = 0.21182665046578 
2016-12-10 06:59:01 Training Loss = 0.018104749602274 
2016-12-10 06:59:04 Valid Error = 0.37545565006075 
2016-12-10 06:59:04 Valid Loss = 0.021842763896601 
2016-12-10 06:59:06 Test Error = 0.38755458515284 
2016-12-10 06:59:06 Test Loss = 0.023995042772854 
2016-12-10 06:59:06 -------------------LR------------------- 
2016-12-10 06:59:06 0.015625 
2016-12-10 06:59:06 Epoch 34 
2016-12-10 07:01:01 Training Error = 0.21344673957068 
2016-12-10 07:01:01 Training Loss = 0.017915394484006 
2016-12-10 07:01:04 Valid Error = 0.36573511543135 
2016-12-10 07:01:04 Valid Loss = 0.021008413682847 
2016-12-10 07:01:07 Test Error = 0.38427947598253 
2016-12-10 07:01:07 Test Loss = 0.023258035715889 
2016-12-10 07:01:07 -------------------LR------------------- 
2016-12-10 07:01:07 0.015625 
2016-12-10 07:01:07 Epoch 35 
2016-12-10 07:02:56 Training Error = 0.20953152423383 
2016-12-10 07:02:56 Training Loss = 0.017950320183819 
2016-12-10 07:02:59 Valid Error = 0.3730255164034 
2016-12-10 07:02:59 Valid Loss = 0.021394427791739 
2016-12-10 07:03:01 Test Error = 0.39956331877729 
2016-12-10 07:03:01 Test Loss = 0.023637961350235 
2016-12-10 07:03:01 -------------------LR------------------- 
2016-12-10 07:03:01 0.015625 
2016-12-10 07:03:01 Epoch 36 
2016-12-10 07:04:55 Training Error = 0.20791143512893 
2016-12-10 07:04:55 Training Loss = 0.017972271638758 
2016-12-10 07:04:57 Valid Error = 0.36573511543135 
2016-12-10 07:04:57 Valid Loss = 0.020916951562438 
2016-12-10 07:05:00 Test Error = 0.37772925764192 
2016-12-10 07:05:00 Test Loss = 0.02318279021394 
2016-12-10 07:05:00 -------------------LR------------------- 
2016-12-10 07:05:00 0.015625 
2016-12-10 07:05:00 Epoch 37 
2016-12-10 07:06:54 Training Error = 0.21479681382476 
2016-12-10 07:06:54 Training Loss = 0.01803922622068 
2016-12-10 07:06:56 Valid Error = 0.3681652490887 
2016-12-10 07:06:56 Valid Loss = 0.020622769585498 
2016-12-10 07:06:59 Test Error = 0.38755458515284 
2016-12-10 07:06:59 Test Loss = 0.0228731378387 
2016-12-10 07:06:59 -------------------LR------------------- 
2016-12-10 07:06:59 0.015625 
2016-12-10 07:06:59 Epoch 38 
2016-12-10 07:08:53 Training Error = 0.21020656136087 
2016-12-10 07:08:53 Training Loss = 0.018109992264321 
2016-12-10 07:08:56 Valid Error = 0.38031591737546 
2016-12-10 07:08:56 Valid Loss = 0.021549863931841 
2016-12-10 07:08:58 Test Error = 0.39956331877729 
2016-12-10 07:08:58 Test Loss = 0.023775319258372 
2016-12-10 07:08:58 -------------------LR------------------- 
2016-12-10 07:08:58 0.015625 
2016-12-10 07:08:58 Epoch 39 
2016-12-10 07:10:55 Training Error = 0.2106115836371 
2016-12-10 07:10:55 Training Loss = 0.017922559599605 
2016-12-10 07:10:57 Valid Error = 0.3778857837181 
2016-12-10 07:10:57 Valid Loss = 0.02156503996976 
2016-12-10 07:11:00 Test Error = 0.39737991266376 
2016-12-10 07:11:00 Test Loss = 0.023911409228456 
2016-12-10 07:11:00 -------------------LR------------------- 
2016-12-10 07:11:00 0.015625 
2016-12-10 07:11:00 Epoch 40 
2016-12-10 07:12:54 Training Error = 0.20926150938302 
2016-12-10 07:12:54 Training Loss = 0.018052418717528 
2016-12-10 07:12:57 Valid Error = 0.3730255164034 
2016-12-10 07:12:57 Valid Loss = 0.021141256585518 
2016-12-10 07:12:59 Test Error = 0.39956331877729 
2016-12-10 07:12:59 Test Loss = 0.023424279381247 
2016-12-10 07:12:59 -------------------LR------------------- 
2016-12-10 07:12:59 0.015625 
2016-12-10 07:12:59 Epoch 41 
2016-12-10 07:14:56 Training Error = 0.21263669501823 
2016-12-10 07:14:56 Training Loss = 0.01812422882707 
2016-12-10 07:14:59 Valid Error = 0.35358444714459 
2016-12-10 07:14:59 Valid Loss = 0.021643037856545 
2016-12-10 07:15:02 Test Error = 0.37008733624454 
2016-12-10 07:15:02 Test Loss = 0.023968918762955 
2016-12-10 07:15:02 -------------------LR------------------- 
2016-12-10 07:15:02 0.015625 
2016-12-10 07:15:02 Epoch 42 
2016-12-10 07:16:58 Training Error = 0.21331173214527 
2016-12-10 07:16:58 Training Loss = 0.01806373121616 
2016-12-10 07:17:01 Valid Error = 0.3681652490887 
2016-12-10 07:17:01 Valid Loss = 0.02155245901001 
2016-12-10 07:17:03 Test Error = 0.38755458515284 
2016-12-10 07:17:03 Test Loss = 0.02393169001972 
2016-12-10 07:17:03 -------------------LR------------------- 
2016-12-10 07:17:03 0.015625 
2016-12-10 07:17:03 Epoch 43 
2016-12-10 07:19:00 Training Error = 0.21371675442149 
2016-12-10 07:19:00 Training Loss = 0.017942090967857 
2016-12-10 07:19:03 Valid Error = 0.3730255164034 
2016-12-10 07:19:03 Valid Loss = 0.021819375412047 
2016-12-10 07:19:05 Test Error = 0.39956331877729 
2016-12-10 07:19:05 Test Loss = 0.02409962534437 
2016-12-10 07:19:05 -------------------LR------------------- 
2016-12-10 07:19:05 0.015625 
2016-12-10 07:19:05 Epoch 44 
2016-12-10 07:21:00 Training Error = 0.20912650195761 
2016-12-10 07:21:00 Training Loss = 0.018029494063861 
2016-12-10 07:21:02 Valid Error = 0.37181044957473 
2016-12-10 07:21:02 Valid Loss = 0.021841645973858 
2016-12-10 07:21:05 Test Error = 0.4028384279476 
2016-12-10 07:21:05 Test Loss = 0.024086008763781 
2016-12-10 07:21:05 -------------------LR------------------- 
2016-12-10 07:21:05 0.015625 
2016-12-10 07:21:05 Epoch 45 
2016-12-10 07:22:59 Training Error = 0.21209666531659 
2016-12-10 07:22:59 Training Loss = 0.018000609716136 
2016-12-10 07:23:01 Valid Error = 0.36938031591738 
2016-12-10 07:23:01 Valid Loss = 0.022123090861997 
2016-12-10 07:23:04 Test Error = 0.38864628820961 
2016-12-10 07:23:04 Test Loss = 0.02442441035252 
2016-12-10 07:23:04 -------------------LR------------------- 
2016-12-10 07:23:04 0.015625 
2016-12-10 07:23:04 Epoch 46 
2016-12-10 07:24:57 Training Error = 0.20939651680842 
2016-12-10 07:24:57 Training Loss = 0.017990564625915 
2016-12-10 07:24:59 Valid Error = 0.3778857837181 
2016-12-10 07:24:59 Valid Loss = 0.021445533435905 
2016-12-10 07:25:02 Test Error = 0.39737991266376 
2016-12-10 07:25:02 Test Loss = 0.023781387590895 
2016-12-10 07:25:02 -------------------LR------------------- 
2016-12-10 07:25:02 0.015625 
2016-12-10 07:25:02 Epoch 47 
2016-12-10 07:26:55 Training Error = 0.21277170244363 
2016-12-10 07:26:55 Training Loss = 0.018139182450324 
2016-12-10 07:26:58 Valid Error = 0.37059538274605 
2016-12-10 07:26:58 Valid Loss = 0.021257881528784 
2016-12-10 07:27:00 Test Error = 0.39519650655022 
2016-12-10 07:27:00 Test Loss = 0.023496782732945 
2016-12-10 07:27:00 -------------------LR------------------- 
2016-12-10 07:27:00 0.015625 
2016-12-10 07:27:00 Epoch 48 
2016-12-10 07:28:57 Training Error = 0.21169164304037 
2016-12-10 07:28:57 Training Loss = 0.018035843042254 
2016-12-10 07:28:59 Valid Error = 0.34264884568651 
2016-12-10 07:28:59 Valid Loss = 0.020556787149556 
2016-12-10 07:29:02 Test Error = 0.34606986899563 
2016-12-10 07:29:02 Test Loss = 0.022891815783931 
2016-12-10 07:29:02 -------------------LR------------------- 
2016-12-10 07:29:02 0.015625 
2016-12-10 07:29:02 Epoch 49 
2016-12-10 07:30:58 Training Error = 0.20831645740516 
2016-12-10 07:30:58 Training Loss = 0.017969520135732 
2016-12-10 07:31:01 Valid Error = 0.3730255164034 
2016-12-10 07:31:01 Valid Loss = 0.021401450079567 
2016-12-10 07:31:04 Test Error = 0.39956331877729 
2016-12-10 07:31:04 Test Loss = 0.023760485415365 
2016-12-10 07:31:04 -------------------LR------------------- 
2016-12-10 07:31:04 0.015625 
2016-12-10 07:31:04 Epoch 50 
2016-12-10 07:33:04 Training Error = 0.21425678412313 
2016-12-10 07:33:04 Training Loss = 0.017970869327549 
2016-12-10 07:33:07 Valid Error = 0.37545565006075 
2016-12-10 07:33:07 Valid Loss = 0.021390315911598 
2016-12-10 07:33:10 Test Error = 0.39737991266376 
2016-12-10 07:33:10 Test Loss = 0.023933114771749 
2016-12-10 07:33:10 -------------------LR------------------- 
2016-12-10 07:33:10 0.0078125 
2016-12-10 07:33:10 Epoch 51 
2016-12-10 07:34:58 Training Error = 0.21155663561496 
2016-12-10 07:34:58 Training Loss = 0.018216959889017 
2016-12-10 07:35:01 Valid Error = 0.363304981774 
2016-12-10 07:35:01 Valid Loss = 0.020997893447348 
2016-12-10 07:35:03 Test Error = 0.38973799126638 
2016-12-10 07:35:03 Test Loss = 0.023470437732397 
2016-12-10 07:35:03 -------------------LR------------------- 
2016-12-10 07:35:03 0.0078125 
2016-12-10 07:35:03 Epoch 52 
2016-12-10 07:36:57 Training Error = 0.21155663561496 
2016-12-10 07:36:57 Training Loss = 0.017997908719559 
2016-12-10 07:37:00 Valid Error = 0.3730255164034 
2016-12-10 07:37:00 Valid Loss = 0.021898455108963 
2016-12-10 07:37:02 Test Error = 0.39956331877729 
2016-12-10 07:37:02 Test Loss = 0.024048660390517 
2016-12-10 07:37:02 -------------------LR------------------- 
2016-12-10 07:37:02 0.0078125 
2016-12-10 07:37:02 Epoch 53 
2016-12-10 07:38:58 Training Error = 0.2106115836371 
2016-12-10 07:38:58 Training Loss = 0.018053725149117 
2016-12-10 07:39:00 Valid Error = 0.35965978128797 
2016-12-10 07:39:00 Valid Loss = 0.021053100695063 
2016-12-10 07:39:03 Test Error = 0.38973799126638 
2016-12-10 07:39:03 Test Loss = 0.023342126378826 
2016-12-10 07:39:03 -------------------LR------------------- 
2016-12-10 07:39:03 0.0078125 
2016-12-10 07:39:03 Epoch 54 
2016-12-10 07:41:00 Training Error = 0.21277170244363 
2016-12-10 07:41:00 Training Loss = 0.018103770810082 
2016-12-10 07:41:02 Valid Error = 0.3730255164034 
2016-12-10 07:41:02 Valid Loss = 0.022046724756502 
2016-12-10 07:41:05 Test Error = 0.39956331877729 
2016-12-10 07:41:05 Test Loss = 0.02430180164412 
2016-12-10 07:41:05 -------------------LR------------------- 
2016-12-10 07:41:05 0.0078125 
2016-12-10 07:41:05 Epoch 55 
2016-12-10 07:42:59 Training Error = 0.21047657621169 
2016-12-10 07:42:59 Training Loss = 0.018066880144392 
2016-12-10 07:43:01 Valid Error = 0.39003645200486 
2016-12-10 07:43:01 Valid Loss = 0.021990566371099 
2016-12-10 07:43:04 Test Error = 0.40829694323144 
2016-12-10 07:43:04 Test Loss = 0.024185657183329 
2016-12-10 07:43:04 -------------------LR------------------- 
2016-12-10 07:43:04 0.0078125 
2016-12-10 07:43:04 Epoch 56 
2016-12-10 07:44:58 Training Error = 0.21088159848792 
2016-12-10 07:44:58 Training Loss = 0.018070103806497 
2016-12-10 07:45:01 Valid Error = 0.3681652490887 
2016-12-10 07:45:01 Valid Loss = 0.021880156768252 
2016-12-10 07:45:04 Test Error = 0.38755458515284 
2016-12-10 07:45:04 Test Loss = 0.024165679782045 
2016-12-10 07:45:04 -------------------LR------------------- 
2016-12-10 07:45:04 0.0078125 
2016-12-10 07:45:04 Epoch 57 
2016-12-10 07:46:55 Training Error = 0.20980153908465 
2016-12-10 07:46:55 Training Loss = 0.018197896250378 
2016-12-10 07:46:57 Valid Error = 0.3778857837181 
2016-12-10 07:46:57 Valid Loss = 0.022044727382893 
2016-12-10 07:47:00 Test Error = 0.40393013100437 
2016-12-10 07:47:00 Test Loss = 0.024317715429792 
2016-12-10 07:47:00 -------------------LR------------------- 
2016-12-10 07:47:00 0.0078125 
2016-12-10 07:47:00 Epoch 58 
2016-12-10 07:48:55 Training Error = 0.21169164304037 
2016-12-10 07:48:55 Training Loss = 0.018023184035984 
2016-12-10 07:48:58 Valid Error = 0.36087484811665 
2016-12-10 07:48:58 Valid Loss = 0.021249800802485 
2016-12-10 07:49:00 Test Error = 0.382096069869 
2016-12-10 07:49:00 Test Loss = 0.023441122419694 
2016-12-10 07:49:00 -------------------LR------------------- 
2016-12-10 07:49:00 0.0078125 
2016-12-10 07:49:00 Epoch 59 
2016-12-10 07:50:56 Training Error = 0.21047657621169 
2016-12-10 07:50:56 Training Loss = 0.01803570541681 
2016-12-10 07:50:58 Valid Error = 0.36208991494532 
2016-12-10 07:50:58 Valid Loss = 0.021730364128937 
2016-12-10 07:51:01 Test Error = 0.38973799126638 
2016-12-10 07:51:01 Test Loss = 0.023955668477451 
2016-12-10 07:51:01 -------------------LR------------------- 
2016-12-10 07:51:01 0.0078125 
2016-12-10 07:51:01 Epoch 60 
2016-12-10 07:53:02 Training Error = 0.20912650195761 
2016-12-10 07:53:02 Training Loss = 0.017877733272264 
2016-12-10 07:53:04 Valid Error = 0.37545565006075 
2016-12-10 07:53:04 Valid Loss = 0.021960649630377 
2016-12-10 07:53:07 Test Error = 0.39410480349345 
2016-12-10 07:53:07 Test Loss = 0.024153271534864 
2016-12-10 07:53:07 -------------------LR------------------- 
2016-12-10 07:53:07 0.0078125 
2016-12-10 07:53:07 Epoch 61 
2016-12-10 07:55:01 Training Error = 0.20669636830026 
2016-12-10 07:55:01 Training Loss = 0.01803348055714 
2016-12-10 07:55:03 Valid Error = 0.38396111786148 
2016-12-10 07:55:03 Valid Loss = 0.021506767319924 
2016-12-10 07:55:06 Test Error = 0.39956331877729 
2016-12-10 07:55:06 Test Loss = 0.023697827311123 
2016-12-10 07:55:06 -------------------LR------------------- 
2016-12-10 07:55:06 0.0078125 
2016-12-10 07:55:06 Epoch 62 
2016-12-10 07:56:44 Training Error = 0.21344673957068 
2016-12-10 07:56:44 Training Loss = 0.018132176996368 
2016-12-10 07:56:47 Valid Error = 0.35479951397327 
2016-12-10 07:56:47 Valid Loss = 0.021431680292504 
2016-12-10 07:56:49 Test Error = 0.37772925764192 
2016-12-10 07:56:49 Test Loss = 0.02370340310826 
2016-12-10 07:56:49 -------------------LR------------------- 
2016-12-10 07:56:49 0.0078125 
2016-12-10 07:56:49 Epoch 63 
2016-12-10 07:58:34 Training Error = 0.21007155393547 
2016-12-10 07:58:34 Training Loss = 0.01807343878795 
2016-12-10 07:58:37 Valid Error = 0.37059538274605 
2016-12-10 07:58:37 Valid Loss = 0.021811786473469 
2016-12-10 07:58:40 Test Error = 0.39519650655022 
2016-12-10 07:58:40 Test Loss = 0.024072211854598 
2016-12-10 07:58:40 -------------------LR------------------- 
2016-12-10 07:58:40 0.0078125 
2016-12-10 07:58:40 Epoch 64 
2016-12-10 08:00:24 Training Error = 0.20953152423383 
2016-12-10 08:00:24 Training Loss = 0.017833165366977 
2016-12-10 08:00:26 Valid Error = 0.37059538274605 
2016-12-10 08:00:26 Valid Loss = 0.020926748598978 
2016-12-10 08:00:29 Test Error = 0.39519650655022 
2016-12-10 08:00:29 Test Loss = 0.023209201579 
2016-12-10 08:00:29 -------------------LR------------------- 
2016-12-10 08:00:29 0.0078125 
2016-12-10 08:00:29 Epoch 65 
2016-12-10 08:02:08 Training Error = 0.21182665046578 
2016-12-10 08:02:08 Training Loss = 0.018046113402636 
2016-12-10 08:02:11 Valid Error = 0.35601458080194 
2016-12-10 08:02:11 Valid Loss = 0.020964825893878 
2016-12-10 08:02:14 Test Error = 0.37445414847162 
2016-12-10 08:02:14 Test Loss = 0.023504763790205 
2016-12-10 08:02:14 -------------------LR------------------- 
2016-12-10 08:02:14 0.0078125 
2016-12-10 08:02:14 Epoch 66 
2016-12-10 08:03:56 Training Error = 0.21425678412313 
2016-12-10 08:03:56 Training Loss = 0.017975255481424 
2016-12-10 08:03:59 Valid Error = 0.36087484811665 
2016-12-10 08:03:59 Valid Loss = 0.021377257079442 
2016-12-10 08:04:01 Test Error = 0.3853711790393 
2016-12-10 08:04:01 Test Loss = 0.023785968986212 
2016-12-10 08:04:01 -------------------LR------------------- 
2016-12-10 08:04:01 0.0078125 
2016-12-10 08:04:02 Epoch 67 
2016-12-10 08:05:44 Training Error = 0.20764142027812 
2016-12-10 08:05:44 Training Loss = 0.018024273549141 
2016-12-10 08:05:46 Valid Error = 0.363304981774 
2016-12-10 08:05:46 Valid Loss = 0.021580230916688 
2016-12-10 08:05:49 Test Error = 0.38318777292576 
2016-12-10 08:05:49 Test Loss = 0.023791068432378 
2016-12-10 08:05:49 -------------------LR------------------- 
2016-12-10 08:05:49 0.0078125 
2016-12-10 08:05:49 Epoch 68 
2016-12-10 08:07:30 Training Error = 0.20764142027812 
2016-12-10 08:07:30 Training Loss = 0.018038381925239 
2016-12-10 08:07:32 Valid Error = 0.3730255164034 
2016-12-10 08:07:32 Valid Loss = 0.021698499630603 
2016-12-10 08:07:35 Test Error = 0.39956331877729 
2016-12-10 08:07:35 Test Loss = 0.023918870579963 
2016-12-10 08:07:35 -------------------LR------------------- 
2016-12-10 08:07:35 0.0078125 
2016-12-10 08:07:35 Epoch 69 
2016-12-10 08:09:17 Training Error = 0.21790198460915 
2016-12-10 08:09:17 Training Loss = 0.018024562346301 
2016-12-10 08:09:19 Valid Error = 0.38517618469016 
2016-12-10 08:09:19 Valid Loss = 0.02154633368734 
2016-12-10 08:09:22 Test Error = 0.40829694323144 
2016-12-10 08:09:22 Test Loss = 0.023797662519941 
2016-12-10 08:09:22 -------------------LR------------------- 
2016-12-10 08:09:22 0.0078125 
2016-12-10 08:09:22 Epoch 70 
2016-12-10 08:11:12 Training Error = 0.21331173214527 
2016-12-10 08:11:12 Training Loss = 0.018093165052683 
2016-12-10 08:11:15 Valid Error = 0.34264884568651 
2016-12-10 08:11:15 Valid Loss = 0.02100838150526 
2016-12-10 08:11:17 Test Error = 0.35698689956332 
2016-12-10 08:11:17 Test Loss = 0.023183984597524 
2016-12-10 08:11:17 -------------------LR------------------- 
2016-12-10 08:11:17 0.0078125 
2016-12-10 08:11:17 Epoch 71 
2016-12-10 08:12:57 Training Error = 0.21088159848792 
2016-12-10 08:12:57 Training Loss = 0.018165753227968 
2016-12-10 08:12:59 Valid Error = 0.38031591737546 
2016-12-10 08:12:59 Valid Loss = 0.020977468256631 
2016-12-10 08:13:02 Test Error = 0.40502183406114 
2016-12-10 08:13:02 Test Loss = 0.023195190495136 
2016-12-10 08:13:02 -------------------LR------------------- 
2016-12-10 08:13:02 0.0078125 
2016-12-10 08:13:02 Epoch 72 
2016-12-10 08:14:42 Training Error = 0.20683137572566 
2016-12-10 08:14:42 Training Loss = 0.017829200109915 
2016-12-10 08:14:44 Valid Error = 0.35479951397327 
2016-12-10 08:14:44 Valid Loss = 0.021101750681614 
2016-12-10 08:14:47 Test Error = 0.38100436681223 
2016-12-10 08:14:47 Test Loss = 0.023352890070747 
2016-12-10 08:14:47 -------------------LR------------------- 
2016-12-10 08:14:47 0.0078125 
2016-12-10 08:14:47 Epoch 73 
2016-12-10 08:16:30 Training Error = 0.21520183610099 
2016-12-10 08:16:30 Training Loss = 0.018057571798658 
2016-12-10 08:16:32 Valid Error = 0.38274605103281 
2016-12-10 08:16:32 Valid Loss = 0.021821717091263 
2016-12-10 08:16:35 Test Error = 0.40938864628821 
2016-12-10 08:16:35 Test Loss = 0.02402012277117 
2016-12-10 08:16:35 -------------------LR------------------- 
2016-12-10 08:16:35 0.0078125 
2016-12-10 08:16:35 Epoch 74 
2016-12-10 08:18:17 Training Error = 0.20791143512893 
2016-12-10 08:18:17 Training Loss = 0.017891959920361 
2016-12-10 08:18:20 Valid Error = 0.3730255164034 
2016-12-10 08:18:20 Valid Loss = 0.020775510613255 
2016-12-10 08:18:22 Test Error = 0.39956331877729 
2016-12-10 08:18:22 Test Loss = 0.023135607794219 
2016-12-10 08:18:22 -------------------LR------------------- 
2016-12-10 08:18:22 0.0078125 
2016-12-10 08:18:22 Epoch 75 
2016-12-10 08:20:04 Training Error = 0.21007155393547 
2016-12-10 08:20:04 Training Loss = 0.0180667163539 
2016-12-10 08:20:06 Valid Error = 0.3730255164034 
2016-12-10 08:20:06 Valid Loss = 0.021819662365304 
2016-12-10 08:20:09 Test Error = 0.39956331877729 
2016-12-10 08:20:09 Test Loss = 0.024102575021632 
2016-12-10 08:20:09 -------------------LR------------------- 
2016-12-10 08:20:09 0.0078125 
2016-12-10 08:20:09 Epoch 76 
2016-12-10 08:21:51 Training Error = 0.2089914945322 
2016-12-10 08:21:51 Training Loss = 0.017976245423503 
2016-12-10 08:21:53 Valid Error = 0.36938031591738 
2016-12-10 08:21:53 Valid Loss = 0.02206086544215 
2016-12-10 08:21:56 Test Error = 0.39519650655022 
2016-12-10 08:21:56 Test Loss = 0.024398887933469 
2016-12-10 08:21:56 -------------------LR------------------- 
2016-12-10 08:21:56 0.0078125 
2016-12-10 08:21:56 Epoch 77 
2016-12-10 08:23:36 Training Error = 0.20939651680842 
2016-12-10 08:23:36 Training Loss = 0.018067319698672 
2016-12-10 08:23:38 Valid Error = 0.36573511543135 
2016-12-10 08:23:38 Valid Loss = 0.021835978335364 
2016-12-10 08:23:41 Test Error = 0.39082969432314 
2016-12-10 08:23:41 Test Loss = 0.024057065271864 
2016-12-10 08:23:41 -------------------LR------------------- 
2016-12-10 08:23:41 0.0078125 
2016-12-10 08:23:41 Epoch 78 
2016-12-10 08:25:24 Training Error = 0.21020656136087 
2016-12-10 08:25:24 Training Loss = 0.017949239901446 
2016-12-10 08:25:27 Valid Error = 0.36087484811665 
2016-12-10 08:25:27 Valid Loss = 0.020927581411313 
2016-12-10 08:25:29 Test Error = 0.3853711790393 
2016-12-10 08:25:29 Test Loss = 0.023160303732928 
2016-12-10 08:25:29 -------------------LR------------------- 
2016-12-10 08:25:29 0.0078125 
2016-12-10 08:25:29 Epoch 79 
2016-12-10 08:27:12 Training Error = 0.21250168759282 
2016-12-10 08:27:12 Training Loss = 0.018118794685029 
2016-12-10 08:27:15 Valid Error = 0.37424058323208 
2016-12-10 08:27:15 Valid Loss = 0.021668321425754 
2016-12-10 08:27:17 Test Error = 0.39301310043668 
2016-12-10 08:27:17 Test Loss = 0.023805736803541 
2016-12-10 08:27:17 -------------------LR------------------- 
2016-12-10 08:27:17 0.0078125 
2016-12-10 08:27:17 Epoch 80 
2016-12-10 08:29:04 Training Error = 0.21034156878628 
2016-12-10 08:29:04 Training Loss = 0.017983913315489 
2016-12-10 08:29:06 Valid Error = 0.37181044957473 
2016-12-10 08:29:06 Valid Loss = 0.020770124778881 
2016-12-10 08:29:09 Test Error = 0.3853711790393 
2016-12-10 08:29:09 Test Loss = 0.023006898795857 
2016-12-10 08:29:09 -------------------LR------------------- 
2016-12-10 08:29:09 0.0078125 
2016-12-10 08:29:09 Epoch 81 
2016-12-10 08:30:50 Training Error = 0.2106115836371 
2016-12-10 08:30:50 Training Loss = 0.017992478127929 
2016-12-10 08:30:53 Valid Error = 0.363304981774 
2016-12-10 08:30:53 Valid Loss = 0.022044389700702 
2016-12-10 08:30:55 Test Error = 0.38973799126638 
2016-12-10 08:30:55 Test Loss = 0.024069371868582 
2016-12-10 08:30:55 -------------------LR------------------- 
2016-12-10 08:30:55 0.0078125 
2016-12-10 08:30:55 Epoch 82 
2016-12-10 08:32:38 Training Error = 0.21020656136087 
2016-12-10 08:32:38 Training Loss = 0.018169024571295 
2016-12-10 08:32:41 Valid Error = 0.36938031591738 
2016-12-10 08:32:41 Valid Loss = 0.021247745357455 
2016-12-10 08:32:43 Test Error = 0.39519650655022 
2016-12-10 08:32:43 Test Loss = 0.023637237165488 
2016-12-10 08:32:43 -------------------LR------------------- 
2016-12-10 08:32:43 0.0078125 
2016-12-10 08:32:43 Epoch 83 
2016-12-10 08:34:27 Training Error = 0.21101660591333 
2016-12-10 08:34:27 Training Loss = 0.018001803375159 
2016-12-10 08:34:30 Valid Error = 0.35601458080194 
2016-12-10 08:34:30 Valid Loss = 0.021141978714901 
2016-12-10 08:34:32 Test Error = 0.37445414847162 
2016-12-10 08:34:32 Test Loss = 0.023434447428759 
2016-12-10 08:34:32 -------------------LR------------------- 
2016-12-10 08:34:32 0.0078125 
2016-12-10 08:34:32 Epoch 84 
2016-12-10 08:36:13 Training Error = 0.21047657621169 
2016-12-10 08:36:13 Training Loss = 0.018042042059947 
2016-12-10 08:36:16 Valid Error = 0.37181044957473 
2016-12-10 08:36:16 Valid Loss = 0.021610229696708 
2016-12-10 08:36:19 Test Error = 0.4028384279476 
2016-12-10 08:36:19 Test Loss = 0.024000088719761 
2016-12-10 08:36:19 -------------------LR------------------- 
2016-12-10 08:36:19 0.0078125 
2016-12-10 08:36:19 Epoch 85 
2016-12-10 08:37:59 Training Error = 0.21277170244363 
2016-12-10 08:37:59 Training Loss = 0.018098548894859 
2016-12-10 08:38:01 Valid Error = 0.36573511543135 
2016-12-10 08:38:01 Valid Loss = 0.021813664032991 
2016-12-10 08:38:04 Test Error = 0.38755458515284 
2016-12-10 08:38:04 Test Loss = 0.024165063736485 
2016-12-10 08:38:04 -------------------LR------------------- 
2016-12-10 08:38:04 0.0078125 
2016-12-10 08:38:04 Epoch 86 
2016-12-10 08:39:44 Training Error = 0.212231672742 
2016-12-10 08:39:44 Training Loss = 0.017999667829982 
2016-12-10 08:39:47 Valid Error = 0.33657351154313 
2016-12-10 08:39:47 Valid Loss = 0.020763872563416 
2016-12-10 08:39:49 Test Error = 0.35152838427948 
2016-12-10 08:39:49 Test Loss = 0.022929884218702 
2016-12-10 08:39:49 -------------------LR------------------- 
2016-12-10 08:39:49 0.0078125 
2016-12-10 08:39:49 Epoch 87 
2016-12-10 08:41:34 Training Error = 0.21614688807884 
2016-12-10 08:41:34 Training Loss = 0.018065931244324 
2016-12-10 08:41:36 Valid Error = 0.3778857837181 
2016-12-10 08:41:36 Valid Loss = 0.022315309793195 
2016-12-10 08:41:39 Test Error = 0.39737991266376 
2016-12-10 08:41:39 Test Loss = 0.024578391692218 
2016-12-10 08:41:39 -------------------LR------------------- 
2016-12-10 08:41:39 0.0078125 
2016-12-10 08:41:39 Epoch 88 
2016-12-10 08:43:19 Training Error = 0.21250168759282 
2016-12-10 08:43:19 Training Loss = 0.017998156525997 
2016-12-10 08:43:22 Valid Error = 0.37181044957473 
2016-12-10 08:43:22 Valid Loss = 0.021298127528042 
2016-12-10 08:43:24 Test Error = 0.38646288209607 
2016-12-10 08:43:24 Test Loss = 0.023457501233793 
2016-12-10 08:43:24 -------------------LR------------------- 
2016-12-10 08:43:24 0.0078125 
2016-12-10 08:43:24 Epoch 89 
2016-12-10 08:45:08 Training Error = 0.212231672742 
2016-12-10 08:45:08 Training Loss = 0.017919235044278 
2016-12-10 08:45:11 Valid Error = 0.3730255164034 
2016-12-10 08:45:11 Valid Loss = 0.021313927388388 
2016-12-10 08:45:13 Test Error = 0.39301310043668 
2016-12-10 08:45:13 Test Loss = 0.023592111512726 
2016-12-10 08:45:13 -------------------LR------------------- 
2016-12-10 08:45:13 0.0078125 
2016-12-10 08:45:13 Epoch 90 
2016-12-10 08:47:02 Training Error = 0.2106115836371 
2016-12-10 08:47:02 Training Loss = 0.018003295942604 
2016-12-10 08:47:05 Valid Error = 0.36087484811665 
2016-12-10 08:47:05 Valid Loss = 0.020968121583459 
2016-12-10 08:47:08 Test Error = 0.37663755458515 
2016-12-10 08:47:08 Test Loss = 0.023229704155641 
2016-12-10 08:47:08 -------------------LR------------------- 
2016-12-10 08:47:08 0.0078125 
2016-12-10 08:47:08 Epoch 91 
2016-12-10 08:48:46 Training Error = 0.20980153908465 
2016-12-10 08:48:46 Training Loss = 0.018044619364876 
2016-12-10 08:48:48 Valid Error = 0.36087484811665 
2016-12-10 08:48:48 Valid Loss = 0.021805035077206 
2016-12-10 08:48:51 Test Error = 0.382096069869 
2016-12-10 08:48:51 Test Loss = 0.024053448714462 
2016-12-10 08:48:51 -------------------LR------------------- 
2016-12-10 08:48:51 0.0078125 
2016-12-10 08:48:51 Epoch 92 
2016-12-10 08:50:33 Training Error = 0.20777642770352 
2016-12-10 08:50:33 Training Loss = 0.018008076259068 
2016-12-10 08:50:36 Valid Error = 0.33535844471446 
2016-12-10 08:50:36 Valid Loss = 0.020431447301476 
2016-12-10 08:50:38 Test Error = 0.33078602620087 
2016-12-10 08:50:38 Test Loss = 0.022744284779418 
2016-12-10 08:50:38 -------------------LR------------------- 
2016-12-10 08:50:38 0.0078125 
2016-12-10 08:50:38 Epoch 93 
2016-12-10 08:52:19 Training Error = 0.20885648710679 
2016-12-10 08:52:19 Training Loss = 0.017811575314533 
2016-12-10 08:52:21 Valid Error = 0.37667071688943 
2016-12-10 08:52:21 Valid Loss = 0.021073562988472 
2016-12-10 08:52:24 Test Error = 0.39737991266376 
2016-12-10 08:52:24 Test Loss = 0.023366279022366 
2016-12-10 08:52:24 -------------------LR------------------- 
2016-12-10 08:52:24 0.0078125 
2016-12-10 08:52:24 Epoch 94 
2016-12-10 08:54:09 Training Error = 0.20885648710679 
2016-12-10 08:54:09 Training Loss = 0.018083863311967 
2016-12-10 08:54:11 Valid Error = 0.38274605103281 
2016-12-10 08:54:11 Valid Loss = 0.021964271005564 
2016-12-10 08:54:14 Test Error = 0.40938864628821 
2016-12-10 08:54:14 Test Loss = 0.024204732090819 
2016-12-10 08:54:14 -------------------LR------------------- 
2016-12-10 08:54:14 0.0078125 
2016-12-10 08:54:14 Epoch 95 
2016-12-10 08:55:55 Training Error = 0.21520183610099 
2016-12-10 08:55:55 Training Loss = 0.018037346877838 
2016-12-10 08:55:57 Valid Error = 0.35601458080194 
2016-12-10 08:55:57 Valid Loss = 0.021137639578967 
2016-12-10 08:56:00 Test Error = 0.37772925764192 
2016-12-10 08:56:00 Test Loss = 0.023548707634795 
2016-12-10 08:56:00 -------------------LR------------------- 
2016-12-10 08:56:00 0.0078125 
2016-12-10 08:56:00 Epoch 96 
2016-12-10 08:57:42 Training Error = 0.20885648710679 
2016-12-10 08:57:42 Training Loss = 0.017906813104881 
2016-12-10 08:57:45 Valid Error = 0.3778857837181 
2016-12-10 08:57:45 Valid Loss = 0.021408989022737 
2016-12-10 08:57:47 Test Error = 0.40502183406114 
2016-12-10 08:57:47 Test Loss = 0.023540218830109 
2016-12-10 08:57:47 -------------------LR------------------- 
2016-12-10 08:57:47 0.0078125 
2016-12-10 08:57:47 Epoch 97 
2016-12-10 08:59:28 Training Error = 0.21047657621169 
2016-12-10 08:59:28 Training Loss = 0.017908292590514 
2016-12-10 08:59:31 Valid Error = 0.35965978128797 
2016-12-10 08:59:31 Valid Loss = 0.020935401136003 
2016-12-10 08:59:33 Test Error = 0.37991266375546 
2016-12-10 08:59:33 Test Loss = 0.023164182597516 
2016-12-10 08:59:33 -------------------LR------------------- 
2016-12-10 08:59:33 0.0078125 
2016-12-10 08:59:33 Epoch 98 
2016-12-10 09:01:13 Training Error = 0.21128662076414 
2016-12-10 09:01:13 Training Loss = 0.018097045716073 
2016-12-10 09:01:15 Valid Error = 0.36573511543135 
2016-12-10 09:01:15 Valid Loss = 0.022010910429489 
2016-12-10 09:01:18 Test Error = 0.39082969432314 
2016-12-10 09:01:18 Test Loss = 0.02426593505635 
2016-12-10 09:01:18 -------------------LR------------------- 
2016-12-10 09:01:18 0.0078125 
2016-12-10 09:01:18 Epoch 99 
2016-12-10 09:03:00 Training Error = 0.21425678412313 
2016-12-10 09:03:00 Training Loss = 0.017886893660459 
2016-12-10 09:03:02 Valid Error = 0.38396111786148 
2016-12-10 09:03:02 Valid Loss = 0.021094154920882 
2016-12-10 09:03:05 Test Error = 0.4028384279476 
2016-12-10 09:03:05 Test Loss = 0.023351355038437 
2016-12-10 09:03:05 -------------------LR------------------- 
2016-12-10 09:03:05 0.0078125 
2016-12-10 09:03:05 Epoch 100 
2016-12-10 09:04:53 Training Error = 0.21074659106251 
2016-12-10 09:04:53 Training Loss = 0.017819434679389 
2016-12-10 09:04:55 Valid Error = 0.36573511543135 
2016-12-10 09:04:55 Valid Loss = 0.021960889258551 
2016-12-10 09:04:58 Test Error = 0.39082969432314 
2016-12-10 09:04:58 Test Loss = 0.024119308901768 
2016-12-10 09:04:58 -------------------LR------------------- 
2016-12-10 09:04:58 0.00390625 
2016-12-10 09:04:58 Epoch 101 
2016-12-10 09:06:38 Training Error = 0.2106115836371 
2016-12-10 09:06:38 Training Loss = 0.018051543784832 
2016-12-10 09:06:40 Valid Error = 0.3730255164034 
2016-12-10 09:06:40 Valid Loss = 0.021312075953959 
2016-12-10 09:06:43 Test Error = 0.39956331877729 
2016-12-10 09:06:43 Test Loss = 0.023583599473916 
2016-12-10 09:06:43 -------------------LR------------------- 
2016-12-10 09:06:43 0.00390625 
2016-12-10 09:06:43 Epoch 102 
2016-12-10 09:08:26 Training Error = 0.21304171729445 
2016-12-10 09:08:26 Training Loss = 0.017970643326504 
2016-12-10 09:08:28 Valid Error = 0.37545565006075 
2016-12-10 09:08:28 Valid Loss = 0.021639394938093 
2016-12-10 09:08:31 Test Error = 0.39192139737991 
2016-12-10 09:08:31 Test Loss = 0.023862854116103 
2016-12-10 09:08:31 -------------------LR------------------- 
2016-12-10 09:08:31 0.00390625 
2016-12-10 09:08:31 Epoch 103 
2016-12-10 09:10:08 Training Error = 0.20939651680842 
2016-12-10 09:10:08 Training Loss = 0.017922960992665 
2016-12-10 09:10:10 Valid Error = 0.3681652490887 
2016-12-10 09:10:10 Valid Loss = 0.02079288496397 
2016-12-10 09:10:13 Test Error = 0.38755458515284 
2016-12-10 09:10:13 Test Loss = 0.023274403450536 
2016-12-10 09:10:13 -------------------LR------------------- 
2016-12-10 09:10:13 0.00390625 
2016-12-10 09:10:13 Epoch 104 
2016-12-10 09:11:55 Training Error = 0.20602133117321 
2016-12-10 09:11:55 Training Loss = 0.017808603024238 
2016-12-10 09:11:58 Valid Error = 0.37667071688943 
2016-12-10 09:11:58 Valid Loss = 0.02123854047886 
2016-12-10 09:12:00 Test Error = 0.40174672489083 
2016-12-10 09:12:00 Test Loss = 0.023437807933957 
2016-12-10 09:12:00 -------------------LR------------------- 
2016-12-10 09:12:00 0.00390625 
2016-12-10 09:12:00 Epoch 105 
2016-12-10 09:13:42 Training Error = 0.21587687322803 
2016-12-10 09:13:42 Training Loss = 0.018155166601756 
2016-12-10 09:13:45 Valid Error = 0.37424058323208 
2016-12-10 09:13:45 Valid Loss = 0.021262068073215 
2016-12-10 09:13:48 Test Error = 0.39301310043668 
2016-12-10 09:13:48 Test Loss = 0.023333195863986 
2016-12-10 09:13:48 -------------------LR------------------- 
2016-12-10 09:13:48 0.00390625 
2016-12-10 09:13:48 Epoch 106 
2016-12-10 09:15:26 Training Error = 0.21277170244363 
2016-12-10 09:15:26 Training Loss = 0.017938977620671 
2016-12-10 09:15:29 Valid Error = 0.34264884568651 
2016-12-10 09:15:29 Valid Loss = 0.021111507327242 
2016-12-10 09:15:32 Test Error = 0.3471615720524 
2016-12-10 09:15:32 Test Loss = 0.023462412675222 
2016-12-10 09:15:32 -------------------LR------------------- 
2016-12-10 09:15:32 0.00390625 
2016-12-10 09:15:32 Epoch 107 
2016-12-10 09:17:12 Training Error = 0.20831645740516 
2016-12-10 09:17:12 Training Loss = 0.017969969845441 
2016-12-10 09:17:14 Valid Error = 0.38153098420413 
2016-12-10 09:17:14 Valid Loss = 0.021733625866737 
2016-12-10 09:17:17 Test Error = 0.40174672489083 
2016-12-10 09:17:17 Test Loss = 0.023899636595857 
2016-12-10 09:17:17 -------------------LR------------------- 
2016-12-10 09:17:17 0.00390625 
2016-12-10 09:17:17 Epoch 108 
2016-12-10 09:19:00 Training Error = 0.20885648710679 
2016-12-10 09:19:00 Training Loss = 0.01800143833107 
2016-12-10 09:19:02 Valid Error = 0.37059538274605 
2016-12-10 09:19:02 Valid Loss = 0.021444094073335 
2016-12-10 09:19:05 Test Error = 0.39192139737991 
2016-12-10 09:19:05 Test Loss = 0.023673167051054 
2016-12-10 09:19:05 -------------------LR------------------- 
2016-12-10 09:19:05 0.00390625 
2016-12-10 09:19:05 Epoch 109 
2016-12-10 09:20:46 Training Error = 0.20818144997975 
2016-12-10 09:20:46 Training Loss = 0.018082793504161 
2016-12-10 09:20:49 Valid Error = 0.37059538274605 
2016-12-10 09:20:49 Valid Loss = 0.021010161751518 
2016-12-10 09:20:51 Test Error = 0.39192139737991 
2016-12-10 09:20:51 Test Loss = 0.023324511640212 
2016-12-10 09:20:51 -------------------LR------------------- 
2016-12-10 09:20:51 0.00390625 
2016-12-10 09:20:51 Epoch 110 
2016-12-10 09:22:37 Training Error = 0.21155663561496 
2016-12-10 09:22:37 Training Loss = 0.01793347102289 
2016-12-10 09:22:40 Valid Error = 0.3778857837181 
2016-12-10 09:22:40 Valid Loss = 0.021205219790217 
2016-12-10 09:22:42 Test Error = 0.39737991266376 
2016-12-10 09:22:42 Test Loss = 0.023624869262471 
2016-12-10 09:22:42 -------------------LR------------------- 
2016-12-10 09:22:42 0.00390625 
2016-12-10 09:22:42 Epoch 111 
2016-12-10 09:24:21 Training Error = 0.21371675442149 
2016-12-10 09:24:21 Training Loss = 0.018075106664777 
2016-12-10 09:24:24 Valid Error = 0.3681652490887 
2016-12-10 09:24:24 Valid Loss = 0.021411443198846 
2016-12-10 09:24:26 Test Error = 0.39519650655022 
2016-12-10 09:24:26 Test Loss = 0.023593010201174 
2016-12-10 09:24:26 -------------------LR------------------- 
2016-12-10 09:24:26 0.00390625 
2016-12-10 09:24:26 Epoch 112 
2016-12-10 09:26:08 Training Error = 0.20777642770352 
2016-12-10 09:26:08 Training Loss = 0.017903099373498 
2016-12-10 09:26:11 Valid Error = 0.37059538274605 
2016-12-10 09:26:11 Valid Loss = 0.022082944528345 
2016-12-10 09:26:13 Test Error = 0.39192139737991 
2016-12-10 09:26:13 Test Loss = 0.024143105637793 
2016-12-10 09:26:13 -------------------LR------------------- 
2016-12-10 09:26:13 0.00390625 
2016-12-10 09:26:13 Epoch 113 
2016-12-10 09:27:54 Training Error = 0.2138517618469 
2016-12-10 09:27:54 Training Loss = 0.017891444201786 
2016-12-10 09:27:57 Valid Error = 0.33049817739976 
2016-12-10 09:27:57 Valid Loss = 0.021500987242352 
2016-12-10 09:28:00 Test Error = 0.34279475982533 
2016-12-10 09:28:00 Test Loss = 0.023705574073044 
2016-12-10 09:28:00 -------------------LR------------------- 
2016-12-10 09:28:00 0.00390625 
2016-12-10 09:28:00 Epoch 114 
2016-12-10 09:29:38 Training Error = 0.20696638315107 
2016-12-10 09:29:38 Training Loss = 0.018065488119686 
2016-12-10 09:29:41 Valid Error = 0.36087484811665 
2016-12-10 09:29:41 Valid Loss = 0.021175670423234 
2016-12-10 09:29:43 Test Error = 0.3853711790393 
2016-12-10 09:29:43 Test Loss = 0.023671236673991 
2016-12-10 09:29:43 -------------------LR------------------- 
2016-12-10 09:29:43 0.00390625 
2016-12-10 09:29:43 Epoch 115 
2016-12-10 09:31:25 Training Error = 0.20953152423383 
2016-12-10 09:31:25 Training Loss = 0.017824705862977 
2016-12-10 09:31:27 Valid Error = 0.37545565006075 
2016-12-10 09:31:27 Valid Loss = 0.021253736780891 
2016-12-10 09:31:30 Test Error = 0.39410480349345 
2016-12-10 09:31:30 Test Loss = 0.023429303384295 
2016-12-10 09:31:30 -------------------LR------------------- 
2016-12-10 09:31:30 0.00390625 
2016-12-10 09:31:30 Epoch 116 
2016-12-10 09:33:10 Training Error = 0.2138517618469 
2016-12-10 09:33:10 Training Loss = 0.018048172130994 
2016-12-10 09:33:12 Valid Error = 0.363304981774 
2016-12-10 09:33:12 Valid Loss = 0.020824970615015 
2016-12-10 09:33:15 Test Error = 0.38318777292576 
2016-12-10 09:33:15 Test Loss = 0.023245451571895 
2016-12-10 09:33:15 -------------------LR------------------- 
2016-12-10 09:33:15 0.00390625 
2016-12-10 09:33:15 Epoch 117 
2016-12-10 09:34:56 Training Error = 0.21182665046578 
2016-12-10 09:34:56 Training Loss = 0.017957586132801 
2016-12-10 09:34:59 Valid Error = 0.34993924665857 
2016-12-10 09:34:59 Valid Loss = 0.020134032042492 
2016-12-10 09:35:01 Test Error = 0.34934497816594 
2016-12-10 09:35:01 Test Loss = 0.022154254342995 
2016-12-10 09:35:01 -------------------LR------------------- 
2016-12-10 09:35:01 0.00390625 
2016-12-10 09:35:01 Epoch 118 
2016-12-10 09:36:44 Training Error = 0.21290670986904 
2016-12-10 09:36:44 Training Loss = 0.018101221055032 
2016-12-10 09:36:46 Valid Error = 0.363304981774 
2016-12-10 09:36:46 Valid Loss = 0.022041276146023 
2016-12-10 09:36:49 Test Error = 0.38318777292576 
2016-12-10 09:36:49 Test Loss = 0.024157672395893 
2016-12-10 09:36:49 -------------------LR------------------- 
2016-12-10 09:36:49 0.00390625 
2016-12-10 09:36:49 Epoch 119 
2016-12-10 09:38:28 Training Error = 0.21128662076414 
2016-12-10 09:38:28 Training Loss = 0.018030634573572 
2016-12-10 09:38:31 Valid Error = 0.3730255164034 
2016-12-10 09:38:31 Valid Loss = 0.022041579699374 
2016-12-10 09:38:33 Test Error = 0.39956331877729 
2016-12-10 09:38:33 Test Loss = 0.02438012861738 
2016-12-10 09:38:33 -------------------LR------------------- 
2016-12-10 09:38:33 0.00390625 
2016-12-10 09:38:33 Epoch 120 
2016-12-10 09:40:22 Training Error = 0.2089914945322 
2016-12-10 09:40:22 Training Loss = 0.017946749443389 
2016-12-10 09:40:25 Valid Error = 0.37059538274605 
2016-12-10 09:40:25 Valid Loss = 0.021459504066345 
2016-12-10 09:40:28 Test Error = 0.39519650655022 
2016-12-10 09:40:28 Test Loss = 0.023743585979237 
2016-12-10 09:40:28 -------------------LR------------------- 
2016-12-10 09:40:28 0.00390625 
2016-12-10 09:40:28 Epoch 121 
2016-12-10 09:42:06 Training Error = 0.20804644255434 
2016-12-10 09:42:06 Training Loss = 0.01796279134599 
2016-12-10 09:42:08 Valid Error = 0.37545565006075 
2016-12-10 09:42:08 Valid Loss = 0.022008621997766 
2016-12-10 09:42:11 Test Error = 0.39737991266376 
2016-12-10 09:42:11 Test Loss = 0.024329462977017 
2016-12-10 09:42:11 -------------------LR------------------- 
2016-12-10 09:42:11 0.00390625 
2016-12-10 09:42:11 Epoch 122 
2016-12-10 09:43:54 Training Error = 0.21101660591333 
2016-12-10 09:43:54 Training Loss = 0.017906617786682 
2016-12-10 09:43:56 Valid Error = 0.3730255164034 
2016-12-10 09:43:56 Valid Loss = 0.021767486632971 
2016-12-10 09:43:59 Test Error = 0.39956331877729 
2016-12-10 09:43:59 Test Loss = 0.023914542675018 
2016-12-10 09:43:59 -------------------LR------------------- 
2016-12-10 09:43:59 0.00390625 
2016-12-10 09:43:59 Epoch 123 
2016-12-10 09:45:43 Training Error = 0.21317672471986 
2016-12-10 09:45:43 Training Loss = 0.018064031771563 
2016-12-10 09:45:45 Valid Error = 0.3681652490887 
2016-12-10 09:45:45 Valid Loss = 0.021939211216029 
2016-12-10 09:45:48 Test Error = 0.38755458515284 
2016-12-10 09:45:48 Test Loss = 0.024303828071145 
2016-12-10 09:45:48 -------------------LR------------------- 
2016-12-10 09:45:48 0.00390625 
2016-12-10 09:45:48 Epoch 124 
2016-12-10 09:47:29 Training Error = 0.21020656136087 
2016-12-10 09:47:29 Training Loss = 0.017885730677159 
2016-12-10 09:47:31 Valid Error = 0.37545565006075 
2016-12-10 09:47:31 Valid Loss = 0.021129948290006 
2016-12-10 09:47:34 Test Error = 0.39410480349345 
2016-12-10 09:47:34 Test Loss = 0.023451241530624 
2016-12-10 09:47:34 -------------------LR------------------- 
2016-12-10 09:47:34 0.00390625 
2016-12-10 09:47:34 Epoch 125 
2016-12-10 09:49:16 Training Error = 0.21007155393547 
2016-12-10 09:49:16 Training Loss = 0.01801513326807 
2016-12-10 09:49:18 Valid Error = 0.3681652490887 
2016-12-10 09:49:18 Valid Loss = 0.0211157702415 
2016-12-10 09:49:21 Test Error = 0.39192139737991 
2016-12-10 09:49:21 Test Loss = 0.023297196846382 
2016-12-10 09:49:21 -------------------LR------------------- 
2016-12-10 09:49:21 0.00390625 
2016-12-10 09:49:21 Epoch 126 
2016-12-10 09:50:58 Training Error = 0.20858647225597 
2016-12-10 09:50:58 Training Loss = 0.01783970229205 
2016-12-10 09:51:00 Valid Error = 0.3778857837181 
2016-12-10 09:51:00 Valid Loss = 0.021452057037975 
2016-12-10 09:51:03 Test Error = 0.40720524017467 
2016-12-10 09:51:03 Test Loss = 0.02373414218192 
2016-12-10 09:51:03 -------------------LR------------------- 
2016-12-10 09:51:03 0.00390625 
2016-12-10 09:51:03 Epoch 127 
2016-12-10 09:52:45 Training Error = 0.21169164304037 
2016-12-10 09:52:45 Training Loss = 0.017956236616147 
2016-12-10 09:52:47 Valid Error = 0.3681652490887 
2016-12-10 09:52:47 Valid Loss = 0.021604669984118 
2016-12-10 09:52:50 Test Error = 0.38755458515284 
2016-12-10 09:52:50 Test Loss = 0.023710749401766 
2016-12-10 09:52:50 -------------------LR------------------- 
2016-12-10 09:52:50 0.00390625 
2016-12-10 09:52:50 Epoch 128 
2016-12-10 09:54:32 Training Error = 0.21304171729445 
2016-12-10 09:54:32 Training Loss = 0.018031882657034 
2016-12-10 09:54:35 Valid Error = 0.37424058323208 
2016-12-10 09:54:35 Valid Loss = 0.021712074102727 
2016-12-10 09:54:37 Test Error = 0.39628820960699 
2016-12-10 09:54:37 Test Loss = 0.023954582092809 
2016-12-10 09:54:37 -------------------LR------------------- 
2016-12-10 09:54:37 0.00390625 
2016-12-10 09:54:37 Epoch 129 
2016-12-10 09:56:21 Training Error = 0.21263669501823 
2016-12-10 09:56:21 Training Loss = 0.018124644866288 
2016-12-10 09:56:23 Valid Error = 0.38031591737546 
2016-12-10 09:56:23 Valid Loss = 0.02253052040744 
2016-12-10 09:56:26 Test Error = 0.40502183406114 
2016-12-10 09:56:26 Test Loss = 0.024957716801587 
2016-12-10 09:56:26 -------------------LR------------------- 
2016-12-10 09:56:26 0.00390625 
2016-12-10 09:56:26 Epoch 130 
2016-12-10 09:58:16 Training Error = 0.20750641285271 
2016-12-10 09:58:16 Training Loss = 0.01795073556624 
2016-12-10 09:58:19 Valid Error = 0.363304981774 
2016-12-10 09:58:19 Valid Loss = 0.021207538542224 
2016-12-10 09:58:22 Test Error = 0.38318777292576 
2016-12-10 09:58:22 Test Loss = 0.023425877393461 
2016-12-10 09:58:22 -------------------LR------------------- 
2016-12-10 09:58:22 0.00390625 
2016-12-10 09:58:22 Epoch 131 
2016-12-10 10:00:02 Training Error = 0.21128662076414 
2016-12-10 10:00:02 Training Loss = 0.017866138166896 
2016-12-10 10:00:05 Valid Error = 0.38274605103281 
2016-12-10 10:00:05 Valid Loss = 0.021222322736261 
2016-12-10 10:00:07 Test Error = 0.40174672489083 
2016-12-10 10:00:07 Test Loss = 0.023488699669931 
2016-12-10 10:00:07 -------------------LR------------------- 
2016-12-10 10:00:07 0.00390625 
2016-12-10 10:00:07 Epoch 132 
2016-12-10 10:01:49 Training Error = 0.21007155393547 
2016-12-10 10:01:49 Training Loss = 0.017972661011426 
2016-12-10 10:01:51 Valid Error = 0.37667071688943 
2016-12-10 10:01:51 Valid Loss = 0.021362472628852 
2016-12-10 10:01:54 Test Error = 0.39737991266376 
2016-12-10 10:01:54 Test Loss = 0.023607406597511 
2016-12-10 10:01:54 -------------------LR------------------- 
2016-12-10 10:01:54 0.00390625 
2016-12-10 10:01:54 Epoch 133 
2016-12-10 10:03:34 Training Error = 0.21236668016741 
2016-12-10 10:03:34 Training Loss = 0.017993830036694 
2016-12-10 10:03:36 Valid Error = 0.3730255164034 
2016-12-10 10:03:36 Valid Loss = 0.021352577780394 
2016-12-10 10:03:39 Test Error = 0.38973799126638 
2016-12-10 10:03:39 Test Loss = 0.023570214617486 
2016-12-10 10:03:39 -------------------LR------------------- 
2016-12-10 10:03:39 0.00390625 
2016-12-10 10:03:39 Epoch 134 
2016-12-10 10:05:23 Training Error = 0.21074659106251 
2016-12-10 10:05:23 Training Loss = 0.018052452604577 
2016-12-10 10:05:25 Valid Error = 0.38274605103281 
2016-12-10 10:05:25 Valid Loss = 0.021435212495484 
2016-12-10 10:05:28 Test Error = 0.41266375545852 
2016-12-10 10:05:28 Test Loss = 0.023856896727693 
2016-12-10 10:05:28 -------------------LR------------------- 
2016-12-10 10:05:28 0.00390625 
2016-12-10 10:05:28 Epoch 135 
2016-12-10 10:07:10 Training Error = 0.21290670986904 
2016-12-10 10:07:10 Training Loss = 0.017932512416181 
2016-12-10 10:07:13 Valid Error = 0.36573511543135 
2016-12-10 10:07:13 Valid Loss = 0.021077572706128 
2016-12-10 10:07:16 Test Error = 0.39082969432314 
2016-12-10 10:07:16 Test Loss = 0.023367910646925 
2016-12-10 10:07:16 -------------------LR------------------- 
2016-12-10 10:07:16 0.00390625 
2016-12-10 10:07:16 Epoch 136 
2016-12-10 10:08:57 Training Error = 0.20818144997975 
2016-12-10 10:08:57 Training Loss = 0.018030511037219 
2016-12-10 10:09:00 Valid Error = 0.36938031591738 
2016-12-10 10:09:00 Valid Loss = 0.021990073705314 
2016-12-10 10:09:03 Test Error = 0.39519650655022 
2016-12-10 10:09:03 Test Loss = 0.024202462430094 
2016-12-10 10:09:03 -------------------LR------------------- 
2016-12-10 10:09:03 0.00390625 
2016-12-10 10:09:03 Epoch 137 
2016-12-10 10:10:45 Training Error = 0.20764142027812 
2016-12-10 10:10:45 Training Loss = 0.017866784269046 
2016-12-10 10:10:48 Valid Error = 0.37424058323208 
2016-12-10 10:10:48 Valid Loss = 0.022174773961066 
2016-12-10 10:10:50 Test Error = 0.39301310043668 
2016-12-10 10:10:50 Test Loss = 0.024373753603767 
2016-12-10 10:10:50 -------------------LR------------------- 
2016-12-10 10:10:50 0.00390625 
2016-12-10 10:10:50 Epoch 138 
2016-12-10 10:12:33 Training Error = 0.21466180639935 
2016-12-10 10:12:33 Training Loss = 0.018053453836165 
2016-12-10 10:12:35 Valid Error = 0.3584447144593 
2016-12-10 10:12:35 Valid Loss = 0.020921775237554 
2016-12-10 10:12:38 Test Error = 0.37008733624454 
2016-12-10 10:12:38 Test Loss = 0.023260446483014 
2016-12-10 10:12:38 -------------------LR------------------- 
2016-12-10 10:12:38 0.00390625 
2016-12-10 10:12:38 Epoch 139 
2016-12-10 10:14:19 Training Error = 0.20858647225597 
2016-12-10 10:14:19 Training Loss = 0.017981350571234 
2016-12-10 10:14:22 Valid Error = 0.38274605103281 
2016-12-10 10:14:22 Valid Loss = 0.022004173327951 
2016-12-10 10:14:24 Test Error = 0.40938864628821 
2016-12-10 10:14:24 Test Loss = 0.024154297866073 
2016-12-10 10:14:24 -------------------LR------------------- 
2016-12-10 10:14:24 0.00390625 
2016-12-10 10:14:24 Epoch 140 
2016-12-10 10:16:11 Training Error = 0.21209666531659 
2016-12-10 10:16:11 Training Loss = 0.017918649937392 
2016-12-10 10:16:13 Valid Error = 0.38031591737546 
2016-12-10 10:16:13 Valid Loss = 0.021033908413635 
2016-12-10 10:16:16 Test Error = 0.40174672489083 
2016-12-10 10:16:16 Test Loss = 0.023309185944351 
2016-12-10 10:16:16 -------------------LR------------------- 
2016-12-10 10:16:16 0.00390625 
2016-12-10 10:16:16 Epoch 141 
2016-12-10 10:17:58 Training Error = 0.20993654651006 
2016-12-10 10:17:58 Training Loss = 0.01804258678447 
2016-12-10 10:18:00 Valid Error = 0.3730255164034 
2016-12-10 10:18:00 Valid Loss = 0.021974215701277 
2016-12-10 10:18:03 Test Error = 0.39956331877729 
2016-12-10 10:18:03 Test Loss = 0.024224615471036 
2016-12-10 10:18:03 -------------------LR------------------- 
2016-12-10 10:18:03 0.00390625 
2016-12-10 10:18:03 Epoch 142 
2016-12-10 10:19:47 Training Error = 0.21020656136087 
2016-12-10 10:19:47 Training Loss = 0.018002003249623 
2016-12-10 10:19:50 Valid Error = 0.36573511543135 
2016-12-10 10:19:50 Valid Loss = 0.02184392169715 
2016-12-10 10:19:52 Test Error = 0.39082969432314 
2016-12-10 10:19:52 Test Loss = 0.023947879697762 
2016-12-10 10:19:52 -------------------LR------------------- 
2016-12-10 10:19:52 0.00390625 
2016-12-10 10:19:52 Epoch 143 
2016-12-10 10:21:35 Training Error = 0.20845146483057 
2016-12-10 10:21:35 Training Loss = 0.017989586742697 
2016-12-10 10:21:38 Valid Error = 0.36573511543135 
2016-12-10 10:21:38 Valid Loss = 0.021135207882002 
2016-12-10 10:21:41 Test Error = 0.37772925764192 
2016-12-10 10:21:41 Test Loss = 0.023506128778645 
2016-12-10 10:21:41 -------------------LR------------------- 
2016-12-10 10:21:41 0.00390625 
2016-12-10 10:21:41 Epoch 144 
2016-12-10 10:23:24 Training Error = 0.21074659106251 
2016-12-10 10:23:24 Training Loss = 0.017991858745044 
2016-12-10 10:23:27 Valid Error = 0.37059538274605 
2016-12-10 10:23:27 Valid Loss = 0.020702670130685 
2016-12-10 10:23:29 Test Error = 0.39519650655022 
2016-12-10 10:23:29 Test Loss = 0.02311373797585 
2016-12-10 10:23:29 -------------------LR------------------- 
2016-12-10 10:23:29 0.00390625 
2016-12-10 10:23:29 Epoch 145 
2016-12-10 10:25:13 Training Error = 0.20791143512893 
2016-12-10 10:25:13 Training Loss = 0.017866536972659 
2016-12-10 10:25:16 Valid Error = 0.3730255164034 
2016-12-10 10:25:16 Valid Loss = 0.021324590148377 
2016-12-10 10:25:18 Test Error = 0.39956331877729 
2016-12-10 10:25:18 Test Loss = 0.02340088780721 
2016-12-10 10:25:18 -------------------LR------------------- 
2016-12-10 10:25:18 0.00390625 
2016-12-10 10:25:18 Epoch 146 
2016-12-10 10:27:01 Training Error = 0.20683137572566 
2016-12-10 10:27:01 Training Loss = 0.018010653491336 
2016-12-10 10:27:04 Valid Error = 0.36087484811665 
2016-12-10 10:27:04 Valid Loss = 0.021213799397399 
2016-12-10 10:27:06 Test Error = 0.3853711790393 
2016-12-10 10:27:06 Test Loss = 0.023802465831532 
2016-12-10 10:27:06 -------------------LR------------------- 
2016-12-10 10:27:06 0.00390625 
2016-12-10 10:27:06 Epoch 147 
2016-12-10 10:28:49 Training Error = 0.21277170244363 
2016-12-10 10:28:49 Training Loss = 0.017935805728745 
2016-12-10 10:28:51 Valid Error = 0.36695018226002 
2016-12-10 10:28:51 Valid Loss = 0.022083697234567 
2016-12-10 10:28:54 Test Error = 0.39519650655022 
2016-12-10 10:28:54 Test Loss = 0.024301920413971 
2016-12-10 10:28:54 -------------------LR------------------- 
2016-12-10 10:28:54 0.00390625 
2016-12-10 10:28:54 Epoch 148 
2016-12-10 10:30:40 Training Error = 0.2106115836371 
2016-12-10 10:30:40 Training Loss = 0.017886603632338 
2016-12-10 10:30:42 Valid Error = 0.34750911300122 
2016-12-10 10:30:42 Valid Loss = 0.020751662749825 
2016-12-10 10:30:45 Test Error = 0.33951965065502 
2016-12-10 10:30:45 Test Loss = 0.022885378351399 
2016-12-10 10:30:45 -------------------LR------------------- 
2016-12-10 10:30:45 0.00390625 
2016-12-10 10:30:45 Epoch 149 
2016-12-10 10:32:27 Training Error = 0.20683137572566 
2016-12-10 10:32:27 Training Loss = 0.017930986934772 
2016-12-10 10:32:30 Valid Error = 0.38760631834751 
2016-12-10 10:32:30 Valid Loss = 0.021446116777084 
2016-12-10 10:32:33 Test Error = 0.41593886462882 
2016-12-10 10:32:33 Test Loss = 0.023673649647657 
2016-12-10 10:32:33 -------------------LR------------------- 
2016-12-10 10:32:33 0.00390625 
2016-12-10 10:32:33 Epoch 150 
2016-12-10 10:34:23 Training Error = 0.21250168759282 
2016-12-10 10:34:23 Training Loss = 0.018039888329599 
2016-12-10 10:34:25 Valid Error = 0.38031591737546 
2016-12-10 10:34:25 Valid Loss = 0.021451222353884 
2016-12-10 10:34:28 Test Error = 0.40502183406114 
2016-12-10 10:34:28 Test Loss = 0.023594755920709 
2016-12-10 10:34:28 -------------------LR------------------- 
2016-12-10 10:34:28 0.001953125 
2016-12-10 10:34:28 Epoch 151 
2016-12-10 10:36:12 Training Error = 0.20912650195761 
2016-12-10 10:36:12 Training Loss = 0.017722640528176 
2016-12-10 10:36:15 Valid Error = 0.35965978128797 
2016-12-10 10:36:15 Valid Loss = 0.020081448079375 
2016-12-10 10:36:17 Test Error = 0.34934497816594 
2016-12-10 10:36:17 Test Loss = 0.022287029939539 
2016-12-10 10:36:17 -------------------LR------------------- 
2016-12-10 10:36:17 0.001953125 
2016-12-10 10:36:17 Epoch 152 
2016-12-10 10:38:00 Training Error = 0.21209666531659 
2016-12-10 10:38:00 Training Loss = 0.018089773087987 
2016-12-10 10:38:02 Valid Error = 0.35115431348724 
2016-12-10 10:38:02 Valid Loss = 0.021000112107365 
2016-12-10 10:38:05 Test Error = 0.3438864628821 
2016-12-10 10:38:05 Test Loss = 0.02325389733034 
2016-12-10 10:38:05 -------------------LR------------------- 
2016-12-10 10:38:05 0.001953125 
2016-12-10 10:38:05 Epoch 153 
2016-12-10 10:39:45 Training Error = 0.21155663561496 
2016-12-10 10:39:45 Training Loss = 0.017987685259651 
2016-12-10 10:39:47 Valid Error = 0.35722964763062 
2016-12-10 10:39:47 Valid Loss = 0.021346951790286 
2016-12-10 10:39:50 Test Error = 0.37554585152838 
2016-12-10 10:39:50 Test Loss = 0.023612059518403 
2016-12-10 10:39:50 -------------------LR------------------- 
2016-12-10 10:39:50 0.001953125 
2016-12-10 10:39:50 Epoch 154 
2016-12-10 10:41:35 Training Error = 0.21290670986904 
2016-12-10 10:41:35 Training Loss = 0.018062235418866 
2016-12-10 10:41:37 Valid Error = 0.34750911300122 
2016-12-10 10:41:37 Valid Loss = 0.020594790278821 
2016-12-10 10:41:40 Test Error = 0.3646288209607 
2016-12-10 10:41:40 Test Loss = 0.022935983377344 
2016-12-10 10:41:40 -------------------LR------------------- 
2016-12-10 10:41:40 0.001953125 
2016-12-10 10:41:40 Epoch 155 
2016-12-10 10:43:21 Training Error = 0.20980153908465 
2016-12-10 10:43:21 Training Loss = 0.01805525431771 
2016-12-10 10:43:23 Valid Error = 0.35722964763062 
2016-12-10 10:43:23 Valid Loss = 0.020864367910076 
2016-12-10 10:43:26 Test Error = 0.3853711790393 
2016-12-10 10:43:26 Test Loss = 0.023190353328106 
2016-12-10 10:43:26 -------------------LR------------------- 
2016-12-10 10:43:26 0.001953125 
2016-12-10 10:43:26 Epoch 156 
2016-12-10 10:45:06 Training Error = 0.21196165789118 
2016-12-10 10:45:06 Training Loss = 0.017961577698096 
2016-12-10 10:45:08 Valid Error = 0.38396111786148 
2016-12-10 10:45:08 Valid Loss = 0.022272644910192 
2016-12-10 10:45:11 Test Error = 0.4028384279476 
2016-12-10 10:45:11 Test Loss = 0.024350158719455 
2016-12-10 10:45:11 -------------------LR------------------- 
2016-12-10 10:45:11 0.001953125 
2016-12-10 10:45:11 Epoch 157 
2016-12-10 10:46:55 Training Error = 0.20953152423383 
2016-12-10 10:46:55 Training Loss = 0.018018898595815 
2016-12-10 10:46:57 Valid Error = 0.37059538274605 
2016-12-10 10:46:57 Valid Loss = 0.022055398182762 
2016-12-10 10:47:00 Test Error = 0.39519650655022 
2016-12-10 10:47:00 Test Loss = 0.024232990143346 
2016-12-10 10:47:00 -------------------LR------------------- 
2016-12-10 10:47:00 0.001953125 
2016-12-10 10:47:00 Epoch 158 
2016-12-10 10:48:45 Training Error = 0.21371675442149 
2016-12-10 10:48:45 Training Loss = 0.017880027920592 
2016-12-10 10:48:48 Valid Error = 0.39246658566221 
2016-12-10 10:48:48 Valid Loss = 0.021069289707286 
2016-12-10 10:48:50 Test Error = 0.41266375545852 
2016-12-10 10:48:50 Test Loss = 0.023383246431164 
2016-12-10 10:48:50 -------------------LR------------------- 
2016-12-10 10:48:50 0.001953125 
2016-12-10 10:48:50 Epoch 159 
2016-12-10 10:50:33 Training Error = 0.21128662076414 
2016-12-10 10:50:33 Training Loss = 0.018137006535606 
2016-12-10 10:50:35 Valid Error = 0.3778857837181 
2016-12-10 10:50:35 Valid Loss = 0.02169556562361 
2016-12-10 10:50:38 Test Error = 0.39519650655022 
2016-12-10 10:50:38 Test Loss = 0.023800434187347 
2016-12-10 10:50:38 -------------------LR------------------- 
2016-12-10 10:50:38 0.001953125 
2016-12-10 10:50:38 Epoch 160 
2016-12-10 10:52:24 Training Error = 0.20980153908465 
2016-12-10 10:52:24 Training Loss = 0.017954940516653 
2016-12-10 10:52:27 Valid Error = 0.3681652490887 
2016-12-10 10:52:27 Valid Loss = 0.021053041059027 
2016-12-10 10:52:29 Test Error = 0.38755458515284 
2016-12-10 10:52:29 Test Loss = 0.023368211802314 
2016-12-10 10:52:29 -------------------LR------------------- 
2016-12-10 10:52:29 0.001953125 
2016-12-10 10:52:29 Epoch 161 
2016-12-10 10:54:12 Training Error = 0.21115161333873 
2016-12-10 10:54:12 Training Loss = 0.018022021162387 
2016-12-10 10:54:14 Valid Error = 0.37545565006075 
2016-12-10 10:54:14 Valid Loss = 0.021466215967827 
2016-12-10 10:54:17 Test Error = 0.40065502183406 
2016-12-10 10:54:17 Test Loss = 0.02372726949991 
2016-12-10 10:54:17 -------------------LR------------------- 
2016-12-10 10:54:17 0.001953125 
2016-12-10 10:54:17 Epoch 162 
2016-12-10 10:56:00 Training Error = 0.20858647225597 
2016-12-10 10:56:00 Training Loss = 0.017876751053612 
2016-12-10 10:56:02 Valid Error = 0.37545565006075 
2016-12-10 10:56:02 Valid Loss = 0.021322437773106 
2016-12-10 10:56:05 Test Error = 0.40065502183406 
2016-12-10 10:56:05 Test Loss = 0.02349059083415 
2016-12-10 10:56:05 -------------------LR------------------- 
2016-12-10 10:56:05 0.001953125 
2016-12-10 10:56:05 Epoch 163 
2016-12-10 10:57:47 Training Error = 0.21034156878628 
2016-12-10 10:57:47 Training Loss = 0.017730411012366 
2016-12-10 10:57:50 Valid Error = 0.37059538274605 
2016-12-10 10:57:50 Valid Loss = 0.020726996556685 
2016-12-10 10:57:52 Test Error = 0.39519650655022 
2016-12-10 10:57:52 Test Loss = 0.023033943559609 
2016-12-10 10:57:52 -------------------LR------------------- 
2016-12-10 10:57:52 0.001953125 
2016-12-10 10:57:52 Epoch 164 
2016-12-10 10:59:39 Training Error = 0.20993654651006 
2016-12-10 10:59:39 Training Loss = 0.018082789943777 
2016-12-10 10:59:41 Valid Error = 0.3584447144593 
2016-12-10 10:59:41 Valid Loss = 0.020977254843886 
2016-12-10 10:59:44 Test Error = 0.37882096069869 
2016-12-10 10:59:44 Test Loss = 0.023237999635584 
2016-12-10 10:59:44 -------------------LR------------------- 
2016-12-10 10:59:44 0.001953125 
2016-12-10 10:59:44 Epoch 165 
2016-12-10 11:01:26 Training Error = 0.21250168759282 
2016-12-10 11:01:26 Training Loss = 0.01804477794373 
2016-12-10 11:01:28 Valid Error = 0.36208991494532 
2016-12-10 11:01:28 Valid Loss = 0.021383183190144 
2016-12-10 11:01:31 Test Error = 0.39301310043668 
2016-12-10 11:01:31 Test Loss = 0.023722443515179 
2016-12-10 11:01:31 -------------------LR------------------- 
2016-12-10 11:01:31 0.001953125 
2016-12-10 11:01:31 Epoch 166 
2016-12-10 11:03:11 Training Error = 0.20723639800189 
2016-12-10 11:03:11 Training Loss = 0.018024759783064 
2016-12-10 11:03:14 Valid Error = 0.3584447144593 
2016-12-10 11:03:14 Valid Loss = 0.022064548328743 
2016-12-10 11:03:17 Test Error = 0.37772925764192 
2016-12-10 11:03:17 Test Loss = 0.024262379421907 
2016-12-10 11:03:17 -------------------LR------------------- 
2016-12-10 11:03:17 0.001953125 
2016-12-10 11:03:17 Epoch 167 
2016-12-10 11:04:55 Training Error = 0.21142162818955 
2016-12-10 11:04:55 Training Loss = 0.018015211067948 
2016-12-10 11:04:57 Valid Error = 0.38274605103281 
2016-12-10 11:04:57 Valid Loss = 0.021808941555574 
2016-12-10 11:05:00 Test Error = 0.40938864628821 
2016-12-10 11:05:00 Test Loss = 0.024021256091548 
2016-12-10 11:05:00 -------------------LR------------------- 
2016-12-10 11:05:00 0.001953125 
2016-12-10 11:05:00 Epoch 168 
2016-12-10 11:06:45 Training Error = 0.21196165789118 
2016-12-10 11:06:45 Training Loss = 0.018051566164389 
2016-12-10 11:06:48 Valid Error = 0.37059538274605 
2016-12-10 11:06:48 Valid Loss = 0.021295271516919 
2016-12-10 11:06:51 Test Error = 0.39519650655022 
2016-12-10 11:06:51 Test Loss = 0.023477624537898 
2016-12-10 11:06:51 -------------------LR------------------- 
2016-12-10 11:06:51 0.001953125 
2016-12-10 11:06:51 Epoch 169 
2016-12-10 11:08:35 Training Error = 0.21101660591333 
2016-12-10 11:08:35 Training Loss = 0.017994012133459 
2016-12-10 11:08:38 Valid Error = 0.3778857837181 
2016-12-10 11:08:38 Valid Loss = 0.021649318321801 
2016-12-10 11:08:40 Test Error = 0.39737991266376 
2016-12-10 11:08:40 Test Loss = 0.023889059244418 
2016-12-10 11:08:40 -------------------LR------------------- 
2016-12-10 11:08:40 0.001953125 
2016-12-10 11:08:41 Epoch 170 
2016-12-10 11:10:30 Training Error = 0.2089914945322 
2016-12-10 11:10:30 Training Loss = 0.018109942027145 
2016-12-10 11:10:32 Valid Error = 0.38274605103281 
2016-12-10 11:10:32 Valid Loss = 0.02221469474085 
2016-12-10 11:10:35 Test Error = 0.40938864628821 
2016-12-10 11:10:35 Test Loss = 0.024574618030997 
2016-12-10 11:10:35 -------------------LR------------------- 
2016-12-10 11:10:35 0.001953125 
2016-12-10 11:10:35 Epoch 171 
2016-12-10 11:12:16 Training Error = 0.21371675442149 
2016-12-10 11:12:16 Training Loss = 0.017989585966222 
2016-12-10 11:12:18 Valid Error = 0.34872417982989 
2016-12-10 11:12:18 Valid Loss = 0.02008303369188 
2016-12-10 11:12:21 Test Error = 0.35589519650655 
2016-12-10 11:12:21 Test Loss = 0.022481181350409 
2016-12-10 11:12:21 -------------------LR------------------- 
2016-12-10 11:12:21 0.001953125 
2016-12-10 11:12:21 Epoch 172 
2016-12-10 11:14:02 Training Error = 0.20764142027812 
2016-12-10 11:14:02 Training Loss = 0.017993765218897 
2016-12-10 11:14:04 Valid Error = 0.35965978128797 
2016-12-10 11:14:04 Valid Loss = 0.021127034684434 
2016-12-10 11:14:07 Test Error = 0.38973799126638 
2016-12-10 11:14:07 Test Loss = 0.023461551161373 
2016-12-10 11:14:07 -------------------LR------------------- 
2016-12-10 11:14:07 0.001953125 
2016-12-10 11:14:07 Epoch 173 
2016-12-10 11:15:52 Training Error = 0.21169164304037 
2016-12-10 11:15:52 Training Loss = 0.018050390345754 
2016-12-10 11:15:55 Valid Error = 0.3681652490887 
2016-12-10 11:15:55 Valid Loss = 0.021980852013433 
2016-12-10 11:15:58 Test Error = 0.39519650655022 
2016-12-10 11:15:58 Test Loss = 0.024155867015614 
2016-12-10 11:15:58 -------------------LR------------------- 
2016-12-10 11:15:58 0.001953125 
2016-12-10 11:15:58 Epoch 174 
2016-12-10 11:17:37 Training Error = 0.20966653165924 
2016-12-10 11:17:37 Training Loss = 0.017923610578265 
2016-12-10 11:17:40 Valid Error = 0.35722964763062 
2016-12-10 11:17:40 Valid Loss = 0.021003903490785 
2016-12-10 11:17:42 Test Error = 0.382096069869 
2016-12-10 11:17:42 Test Loss = 0.023387180234872 
2016-12-10 11:17:42 -------------------LR------------------- 
2016-12-10 11:17:42 0.001953125 
2016-12-10 11:17:42 Epoch 175 
2016-12-10 11:19:27 Training Error = 0.21439179154854 
2016-12-10 11:19:27 Training Loss = 0.018028572675205 
2016-12-10 11:19:29 Valid Error = 0.38760631834751 
2016-12-10 11:19:29 Valid Loss = 0.02171258300365 
2016-12-10 11:19:32 Test Error = 0.39847161572052 
2016-12-10 11:19:32 Test Loss = 0.023918872973498 
2016-12-10 11:19:32 -------------------LR------------------- 
2016-12-10 11:19:32 0.001953125 
2016-12-10 11:19:32 Epoch 176 
2016-12-10 11:21:14 Training Error = 0.21007155393547 
2016-12-10 11:21:14 Training Loss = 0.018091303162704 
2016-12-10 11:21:16 Valid Error = 0.3681652490887 
2016-12-10 11:21:16 Valid Loss = 0.020790199152592 
2016-12-10 11:21:19 Test Error = 0.3853711790393 
2016-12-10 11:21:19 Test Loss = 0.023433541699952 
2016-12-10 11:21:19 -------------------LR------------------- 
2016-12-10 11:21:19 0.001953125 
2016-12-10 11:21:19 Epoch 177 
2016-12-10 11:23:04 Training Error = 0.21196165789118 
2016-12-10 11:23:04 Training Loss = 0.018085779348564 
2016-12-10 11:23:06 Valid Error = 0.3681652490887 
2016-12-10 11:23:06 Valid Loss = 0.022154996108973 
2016-12-10 11:23:09 Test Error = 0.39192139737991 
2016-12-10 11:23:09 Test Loss = 0.024362003803253 
2016-12-10 11:23:09 -------------------LR------------------- 
2016-12-10 11:23:09 0.001953125 
2016-12-10 11:23:09 Epoch 178 
2016-12-10 11:24:50 Training Error = 0.20615633859862 
2016-12-10 11:24:50 Training Loss = 0.017895120715115 
2016-12-10 11:24:53 Valid Error = 0.35601458080194 
2016-12-10 11:24:53 Valid Loss = 0.021028190212425 
2016-12-10 11:24:55 Test Error = 0.36135371179039 
2016-12-10 11:24:55 Test Loss = 0.023309778886683 
2016-12-10 11:24:55 -------------------LR------------------- 
2016-12-10 11:24:55 0.001953125 
2016-12-10 11:24:55 Epoch 179 
2016-12-10 11:26:35 Training Error = 0.21007155393547 
2016-12-10 11:26:35 Training Loss = 0.017884662984355 
2016-12-10 11:26:38 Valid Error = 0.3778857837181 
2016-12-10 11:26:38 Valid Loss = 0.021288241340975 
2016-12-10 11:26:40 Test Error = 0.39737991266376 
2016-12-10 11:26:40 Test Loss = 0.023355276846418 
2016-12-10 11:26:40 -------------------LR------------------- 
2016-12-10 11:26:40 0.001953125 
2016-12-10 11:26:40 Epoch 180 
2016-12-10 11:28:24 Training Error = 0.20966653165924 
2016-12-10 11:28:24 Training Loss = 0.017916332714319 
2016-12-10 11:28:27 Valid Error = 0.3778857837181 
2016-12-10 11:28:27 Valid Loss = 0.022101722493975 
2016-12-10 11:28:30 Test Error = 0.40502183406114 
2016-12-10 11:28:30 Test Loss = 0.024258390220941 
2016-12-10 11:28:30 -------------------LR------------------- 
2016-12-10 11:28:30 0.001953125 
2016-12-10 11:28:30 Epoch 181 
2016-12-10 11:30:05 Training Error = 0.21196165789118 
2016-12-10 11:30:05 Training Loss = 0.018091181648034 
2016-12-10 11:30:07 Valid Error = 0.36573511543135 
2016-12-10 11:30:07 Valid Loss = 0.02244323979434 
2016-12-10 11:30:10 Test Error = 0.39082969432314 
2016-12-10 11:30:10 Test Loss = 0.024802602646398 
2016-12-10 11:30:10 -------------------LR------------------- 
2016-12-10 11:30:10 0.001953125 
2016-12-10 11:30:10 Epoch 182 
2016-12-10 11:31:47 Training Error = 0.21182665046578 
2016-12-10 11:31:47 Training Loss = 0.017995174762003 
2016-12-10 11:31:49 Valid Error = 0.37424058323208 
2016-12-10 11:31:49 Valid Loss = 0.021459429568274 
2016-12-10 11:31:52 Test Error = 0.39410480349345 
2016-12-10 11:31:52 Test Loss = 0.023638127457862 
2016-12-10 11:31:52 -------------------LR------------------- 
2016-12-10 11:31:52 0.001953125 
2016-12-10 11:31:52 Epoch 183 
2016-12-10 11:33:31 Training Error = 0.21115161333873 
2016-12-10 11:33:31 Training Loss = 0.018011116547856 
2016-12-10 11:33:34 Valid Error = 0.38031591737546 
2016-12-10 11:33:34 Valid Loss = 0.021415033867111 
2016-12-10 11:33:36 Test Error = 0.39956331877729 
2016-12-10 11:33:36 Test Loss = 0.023708402035283 
2016-12-10 11:33:36 -------------------LR------------------- 
2016-12-10 11:33:36 0.001953125 
2016-12-10 11:33:36 Epoch 184 
2016-12-10 11:35:14 Training Error = 0.20858647225597 
2016-12-10 11:35:14 Training Loss = 0.018183162940673 
2016-12-10 11:35:17 Valid Error = 0.37059538274605 
2016-12-10 11:35:17 Valid Loss = 0.020905461565635 
2016-12-10 11:35:19 Test Error = 0.39192139737991 
2016-12-10 11:35:19 Test Loss = 0.023194523745892 
2016-12-10 11:35:19 -------------------LR------------------- 
2016-12-10 11:35:19 0.001953125 
2016-12-10 11:35:19 Epoch 185 
2016-12-10 11:36:58 Training Error = 0.20669636830026 
2016-12-10 11:36:58 Training Loss = 0.017872929769849 
2016-12-10 11:37:00 Valid Error = 0.37667071688943 
2016-12-10 11:37:00 Valid Loss = 0.021853619375226 
2016-12-10 11:37:03 Test Error = 0.39847161572052 
2016-12-10 11:37:03 Test Loss = 0.023862518908931 
2016-12-10 11:37:03 -------------------LR------------------- 
2016-12-10 11:37:03 0.001953125 
2016-12-10 11:37:03 Epoch 186 
2016-12-10 11:38:37 Training Error = 0.21209666531659 
2016-12-10 11:38:37 Training Loss = 0.018043225824265 
2016-12-10 11:38:40 Valid Error = 0.37059538274605 
2016-12-10 11:38:40 Valid Loss = 0.020965198077091 
2016-12-10 11:38:42 Test Error = 0.39192139737991 
2016-12-10 11:38:42 Test Loss = 0.023387664103041 
2016-12-10 11:38:42 -------------------LR------------------- 
2016-12-10 11:38:42 0.001953125 
2016-12-10 11:38:42 Epoch 187 
2016-12-10 11:40:23 Training Error = 0.21466180639935 
2016-12-10 11:40:23 Training Loss = 0.018185560312992 
2016-12-10 11:40:25 Valid Error = 0.35601458080194 
2016-12-10 11:40:25 Valid Loss = 0.021251901549079 
2016-12-10 11:40:28 Test Error = 0.37445414847162 
2016-12-10 11:40:28 Test Loss = 0.023650750253715 
2016-12-10 11:40:28 -------------------LR------------------- 
2016-12-10 11:40:28 0.001953125 
2016-12-10 11:40:28 Epoch 188 
2016-12-10 11:42:06 Training Error = 0.21155663561496 
2016-12-10 11:42:06 Training Loss = 0.018019612839643 
2016-12-10 11:42:08 Valid Error = 0.38153098420413 
2016-12-10 11:42:08 Valid Loss = 0.021365541427596 
2016-12-10 11:42:11 Test Error = 0.4028384279476 
2016-12-10 11:42:11 Test Loss = 0.023760329816856 
2016-12-10 11:42:11 -------------------LR------------------- 
2016-12-10 11:42:11 0.001953125 
2016-12-10 11:42:11 Epoch 189 
2016-12-10 11:43:52 Training Error = 0.21047657621169 
2016-12-10 11:43:52 Training Loss = 0.018030711649691 
2016-12-10 11:43:54 Valid Error = 0.37059538274605 
2016-12-10 11:43:54 Valid Loss = 0.021445519907226 
2016-12-10 11:43:57 Test Error = 0.39519650655022 
2016-12-10 11:43:57 Test Loss = 0.023932453753901 
2016-12-10 11:43:57 -------------------LR------------------- 
2016-12-10 11:43:57 0.001953125 
2016-12-10 11:43:57 Epoch 190 
2016-12-10 11:45:39 Training Error = 0.21236668016741 
2016-12-10 11:45:39 Training Loss = 0.018046672106546 
2016-12-10 11:45:42 Valid Error = 0.3584447144593 
2016-12-10 11:45:42 Valid Loss = 0.020969463596631 
2016-12-10 11:45:44 Test Error = 0.37772925764192 
2016-12-10 11:45:44 Test Loss = 0.023204168469298 
2016-12-10 11:45:44 -------------------LR------------------- 
2016-12-10 11:45:44 0.001953125 
2016-12-10 11:45:44 Epoch 191 
2016-12-10 11:47:18 Training Error = 0.21506682867558 
2016-12-10 11:47:18 Training Loss = 0.017898226991399 
2016-12-10 11:47:21 Valid Error = 0.363304981774 
2016-12-10 11:47:21 Valid Loss = 0.02040879900261 
2016-12-10 11:47:24 Test Error = 0.38973799126638 
2016-12-10 11:47:24 Test Loss = 0.022832655785131 
2016-12-10 11:47:24 -------------------LR------------------- 
2016-12-10 11:47:24 0.001953125 
2016-12-10 11:47:24 Epoch 192 
2016-12-10 11:49:02 Training Error = 0.21020656136087 
2016-12-10 11:49:02 Training Loss = 0.017816281816071 
2016-12-10 11:49:05 Valid Error = 0.38153098420413 
2016-12-10 11:49:05 Valid Loss = 0.021727351547925 
2016-12-10 11:49:07 Test Error = 0.40938864628821 
2016-12-10 11:49:07 Test Loss = 0.024025489246144 
2016-12-10 11:49:07 -------------------LR------------------- 
2016-12-10 11:49:07 0.001953125 
2016-12-10 11:49:07 Epoch 193 
2016-12-10 11:50:47 Training Error = 0.21182665046578 
2016-12-10 11:50:47 Training Loss = 0.017982218696601 
2016-12-10 11:50:49 Valid Error = 0.37059538274605 
2016-12-10 11:50:49 Valid Loss = 0.021188341227289 
2016-12-10 11:50:52 Test Error = 0.39192139737991 
2016-12-10 11:50:52 Test Loss = 0.023495890149883 
2016-12-10 11:50:52 -------------------LR------------------- 
2016-12-10 11:50:52 0.001953125 
2016-12-10 11:50:52 Epoch 194 
2016-12-10 11:52:29 Training Error = 0.21155663561496 
2016-12-10 11:52:29 Training Loss = 0.018004967339923 
2016-12-10 11:52:32 Valid Error = 0.3730255164034 
2016-12-10 11:52:32 Valid Loss = 0.021762207087619 
2016-12-10 11:52:34 Test Error = 0.38973799126638 
2016-12-10 11:52:34 Test Loss = 0.023942631384906 
2016-12-10 11:52:34 -------------------LR------------------- 
2016-12-10 11:52:34 0.001953125 
2016-12-10 11:52:34 Epoch 195 
2016-12-10 11:54:11 Training Error = 0.21682192520589 
2016-12-10 11:54:11 Training Loss = 0.018109923383212 
2016-12-10 11:54:14 Valid Error = 0.3778857837181 
2016-12-10 11:54:14 Valid Loss = 0.020865362893116 
2016-12-10 11:54:17 Test Error = 0.39192139737991 
2016-12-10 11:54:17 Test Loss = 0.023070360127617 
2016-12-10 11:54:17 -------------------LR------------------- 
2016-12-10 11:54:17 0.001953125 
2016-12-10 11:54:17 Epoch 196 
2016-12-10 11:55:50 Training Error = 0.20615633859862 
2016-12-10 11:55:50 Training Loss = 0.017949055074911 
2016-12-10 11:55:53 Valid Error = 0.38031591737546 
2016-12-10 11:55:53 Valid Loss = 0.021165323187888 
2016-12-10 11:55:55 Test Error = 0.40174672489083 
2016-12-10 11:55:55 Test Loss = 0.023515009141436 
2016-12-10 11:55:55 -------------------LR------------------- 
2016-12-10 11:55:55 0.001953125 
2016-12-10 11:55:55 Epoch 197 
2016-12-10 11:57:34 Training Error = 0.20831645740516 
2016-12-10 11:57:34 Training Loss = 0.018003118510384 
2016-12-10 11:57:36 Valid Error = 0.38396111786148 
2016-12-10 11:57:36 Valid Loss = 0.02135904019988 
2016-12-10 11:57:39 Test Error = 0.4061135371179 
2016-12-10 11:57:39 Test Loss = 0.02367531191134 
2016-12-10 11:57:39 -------------------LR------------------- 
2016-12-10 11:57:39 0.001953125 
2016-12-10 11:57:39 Epoch 198 
2016-12-10 11:59:14 Training Error = 0.21115161333873 
2016-12-10 11:59:14 Training Loss = 0.018003859010442 
2016-12-10 11:59:17 Valid Error = 0.363304981774 
2016-12-10 11:59:17 Valid Loss = 0.021113428070858 
2016-12-10 11:59:20 Test Error = 0.38318777292576 
2016-12-10 11:59:20 Test Loss = 0.023492621917351 
2016-12-10 11:59:20 -------------------LR------------------- 
2016-12-10 11:59:20 0.001953125 
2016-12-10 11:59:20 Epoch 199 
2016-12-10 12:00:59 Training Error = 0.21371675442149 
2016-12-10 12:00:59 Training Loss = 0.018174363360864 
2016-12-10 12:01:02 Valid Error = 0.38031591737546 
2016-12-10 12:01:02 Valid Loss = 0.021341741756473 
2016-12-10 12:01:04 Test Error = 0.40502183406114 
2016-12-10 12:01:04 Test Loss = 0.023683606989243 
2016-12-10 12:01:04 -------------------LR------------------- 
2016-12-10 12:01:04 0.001953125 
2016-12-10 12:01:04 Epoch 200 
2016-12-10 12:02:49 Training Error = 0.21317672471986 
2016-12-10 12:02:49 Training Loss = 0.018235757900776 
2016-12-10 12:02:51 Valid Error = 0.35358444714459 
2016-12-10 12:02:51 Valid Loss = 0.021385808245323 
2016-12-10 12:02:54 Test Error = 0.37336244541485 
2016-12-10 12:02:54 Test Loss = 0.023652321759392 
2016-12-10 12:02:54 -------------------LR------------------- 
2016-12-10 12:02:54 0.0009765625 
2016-12-10 12:02:54 Epoch 201 
2016-12-10 12:04:24 Training Error = 0.21034156878628 
2016-12-10 12:04:24 Training Loss = 0.017793463704655 
2016-12-10 12:04:26 Valid Error = 0.40097205346294 
2016-12-10 12:04:26 Valid Loss = 0.021157069876981 
2016-12-10 12:04:29 Test Error = 0.41593886462882 
2016-12-10 12:04:29 Test Loss = 0.023380462870878 
2016-12-10 12:04:29 -------------------LR------------------- 
2016-12-10 12:04:29 0.0009765625 
2016-12-10 12:04:29 Epoch 202 
2016-12-10 12:06:08 Training Error = 0.20993654651006 
2016-12-10 12:06:08 Training Loss = 0.018168189701825 
2016-12-10 12:06:11 Valid Error = 0.3681652490887 
2016-12-10 12:06:11 Valid Loss = 0.020781627852684 
2016-12-10 12:06:13 Test Error = 0.38755458515284 
2016-12-10 12:06:13 Test Loss = 0.023382032487907 
2016-12-10 12:06:13 -------------------LR------------------- 
2016-12-10 12:06:13 0.0009765625 
2016-12-10 12:06:13 Epoch 203 
2016-12-10 12:07:51 Training Error = 0.21034156878628 
2016-12-10 12:07:51 Training Loss = 0.018066389325709 
2016-12-10 12:07:53 Valid Error = 0.36938031591738 
2016-12-10 12:07:53 Valid Loss = 0.02165831956559 
2016-12-10 12:07:56 Test Error = 0.39192139737991 
2016-12-10 12:07:56 Test Loss = 0.023803466909072 
2016-12-10 12:07:56 -------------------LR------------------- 
2016-12-10 12:07:56 0.0009765625 
2016-12-10 12:07:56 Epoch 204 
2016-12-10 12:09:35 Training Error = 0.21182665046578 
2016-12-10 12:09:35 Training Loss = 0.018019101484995 
2016-12-10 12:09:38 Valid Error = 0.35358444714459 
2016-12-10 12:09:38 Valid Loss = 0.021535450432284 
2016-12-10 12:09:40 Test Error = 0.37336244541485 
2016-12-10 12:09:40 Test Loss = 0.023682236503152 
2016-12-10 12:09:40 -------------------LR------------------- 
2016-12-10 12:09:40 0.0009765625 
2016-12-10 12:09:40 Epoch 205 
2016-12-10 12:11:17 Training Error = 0.21250168759282 
2016-12-10 12:11:17 Training Loss = 0.017991405484923 
2016-12-10 12:11:20 Valid Error = 0.3730255164034 
2016-12-10 12:11:20 Valid Loss = 0.021205444032409 
2016-12-10 12:11:22 Test Error = 0.39956331877729 
2016-12-10 12:11:22 Test Loss = 0.023371877184101 
2016-12-10 12:11:22 -------------------LR------------------- 
2016-12-10 12:11:22 0.0009765625 
2016-12-10 12:11:22 Epoch 206 
2016-12-10 12:13:00 Training Error = 0.20993654651006 
2016-12-10 12:13:00 Training Loss = 0.017944088790708 
2016-12-10 12:13:02 Valid Error = 0.3584447144593 
2016-12-10 12:13:02 Valid Loss = 0.020665506935824 
2016-12-10 12:13:05 Test Error = 0.37772925764192 
2016-12-10 12:13:05 Test Loss = 0.023217020857568 
2016-12-10 12:13:05 -------------------LR------------------- 
2016-12-10 12:13:05 0.0009765625 
2016-12-10 12:13:05 Epoch 207 
2016-12-10 12:14:44 Training Error = 0.20939651680842 
2016-12-10 12:14:44 Training Loss = 0.017955421789688 
2016-12-10 12:14:46 Valid Error = 0.36087484811665 
2016-12-10 12:14:46 Valid Loss = 0.021385691329206 
2016-12-10 12:14:49 Test Error = 0.382096069869 
2016-12-10 12:14:49 Test Loss = 0.023745952138714 
2016-12-10 12:14:49 -------------------LR------------------- 
2016-12-10 12:14:49 0.0009765625 
2016-12-10 12:14:49 Epoch 208 
2016-12-10 12:16:25 Training Error = 0.2106115836371 
2016-12-10 12:16:25 Training Loss = 0.017900816647256 
2016-12-10 12:16:28 Valid Error = 0.37181044957473 
2016-12-10 12:16:28 Valid Loss = 0.02157889557752 
2016-12-10 12:16:31 Test Error = 0.3853711790393 
2016-12-10 12:16:31 Test Loss = 0.023852497596367 
2016-12-10 12:16:31 -------------------LR------------------- 
2016-12-10 12:16:31 0.0009765625 
2016-12-10 12:16:31 Epoch 209 
2016-12-10 12:18:10 Training Error = 0.20926150938302 
2016-12-10 12:18:10 Training Loss = 0.018149338465244 
2016-12-10 12:18:12 Valid Error = 0.3584447144593 
2016-12-10 12:18:12 Valid Loss = 0.020952523117593 
2016-12-10 12:18:15 Test Error = 0.37882096069869 
2016-12-10 12:18:15 Test Loss = 0.023275958940095 
2016-12-10 12:18:15 -------------------LR------------------- 
2016-12-10 12:18:15 0.0009765625 
2016-12-10 12:18:15 Epoch 210 
2016-12-10 12:20:00 Training Error = 0.21425678412313 
2016-12-10 12:20:00 Training Loss = 0.01801014913778 
2016-12-10 12:20:03 Valid Error = 0.38031591737546 
2016-12-10 12:20:03 Valid Loss = 0.021697477745583 
2016-12-10 12:20:05 Test Error = 0.40502183406114 
2016-12-10 12:20:05 Test Loss = 0.024055460387585 
2016-12-10 12:20:05 -------------------LR------------------- 
2016-12-10 12:20:05 0.0009765625 
2016-12-10 12:20:05 Epoch 211 
2016-12-10 12:21:42 Training Error = 0.20602133117321 
2016-12-10 12:21:42 Training Loss = 0.017942166424065 
2016-12-10 12:21:44 Valid Error = 0.3681652490887 
2016-12-10 12:21:44 Valid Loss = 0.021720697363748 
2016-12-10 12:21:47 Test Error = 0.39519650655022 
2016-12-10 12:21:47 Test Loss = 0.023956610791823 
2016-12-10 12:21:47 -------------------LR------------------- 
2016-12-10 12:21:47 0.0009765625 
2016-12-10 12:21:47 Epoch 212 
2016-12-10 12:23:26 Training Error = 0.2025111381126 
2016-12-10 12:23:26 Training Loss = 0.017978327978937 
2016-12-10 12:23:29 Valid Error = 0.36208991494532 
2016-12-10 12:23:29 Valid Loss = 0.022177209864063 
2016-12-10 12:23:31 Test Error = 0.37554585152838 
2016-12-10 12:23:31 Test Loss = 0.024501375675201 
2016-12-10 12:23:31 -------------------LR------------------- 
2016-12-10 12:23:31 0.0009765625 
2016-12-10 12:23:31 Epoch 213 
2016-12-10 12:25:09 Training Error = 0.21101660591333 
2016-12-10 12:25:09 Training Loss = 0.018063879839045 
2016-12-10 12:25:12 Valid Error = 0.3730255164034 
2016-12-10 12:25:12 Valid Loss = 0.021257048131074 
2016-12-10 12:25:14 Test Error = 0.39956331877729 
2016-12-10 12:25:14 Test Loss = 0.023479331250284 
2016-12-10 12:25:14 -------------------LR------------------- 
2016-12-10 12:25:14 0.0009765625 
2016-12-10 12:25:14 Epoch 214 
2016-12-10 12:26:50 Training Error = 0.21169164304037 
2016-12-10 12:26:50 Training Loss = 0.018139456853502 
2016-12-10 12:26:53 Valid Error = 0.38396111786148 
2016-12-10 12:26:53 Valid Loss = 0.021410841197919 
2016-12-10 12:26:56 Test Error = 0.4028384279476 
2016-12-10 12:26:56 Test Loss = 0.02366861817416 
2016-12-10 12:26:56 -------------------LR------------------- 
2016-12-10 12:26:56 0.0009765625 
2016-12-10 12:26:56 Epoch 215 
2016-12-10 12:28:35 Training Error = 0.21290670986904 
2016-12-10 12:28:35 Training Loss = 0.018012860224249 
2016-12-10 12:28:38 Valid Error = 0.36208991494532 
2016-12-10 12:28:38 Valid Loss = 0.02050720147634 
2016-12-10 12:28:40 Test Error = 0.37445414847162 
2016-12-10 12:28:40 Test Loss = 0.022743040215735 
2016-12-10 12:28:40 -------------------LR------------------- 
2016-12-10 12:28:40 0.0009765625 
2016-12-10 12:28:40 Epoch 216 
2016-12-10 12:30:15 Training Error = 0.20858647225597 
2016-12-10 12:30:15 Training Loss = 0.018095026699034 
2016-12-10 12:30:18 Valid Error = 0.3584447144593 
2016-12-10 12:30:18 Valid Loss = 0.021616782408564 
2016-12-10 12:30:20 Test Error = 0.3853711790393 
2016-12-10 12:30:20 Test Loss = 0.023770013547411 
2016-12-10 12:30:20 -------------------LR------------------- 
2016-12-10 12:30:20 0.0009765625 
2016-12-10 12:30:20 Epoch 217 
2016-12-10 12:31:59 Training Error = 0.20669636830026 
2016-12-10 12:31:59 Training Loss = 0.017996074701446 
2016-12-10 12:32:02 Valid Error = 0.363304981774 
2016-12-10 12:32:02 Valid Loss = 0.020902577886485 
2016-12-10 12:32:04 Test Error = 0.38973799126638 
2016-12-10 12:32:04 Test Loss = 0.023346210610633 
2016-12-10 12:32:04 -------------------LR------------------- 
2016-12-10 12:32:04 0.0009765625 
2016-12-10 12:32:04 Epoch 218 
2016-12-10 12:33:45 Training Error = 0.21493182125017 
2016-12-10 12:33:45 Training Loss = 0.018051400460493 
2016-12-10 12:33:47 Valid Error = 0.37059538274605 
2016-12-10 12:33:47 Valid Loss = 0.021531881961315 
2016-12-10 12:33:50 Test Error = 0.39519650655022 
2016-12-10 12:33:50 Test Loss = 0.02394414247251 
2016-12-10 12:33:50 -------------------LR------------------- 
2016-12-10 12:33:50 0.0009765625 
2016-12-10 12:33:50 Epoch 219 
2016-12-10 12:35:27 Training Error = 0.21020656136087 
2016-12-10 12:35:27 Training Loss = 0.01798850264064 
2016-12-10 12:35:29 Valid Error = 0.35601458080194 
2016-12-10 12:35:29 Valid Loss = 0.021581555455316 
2016-12-10 12:35:32 Test Error = 0.37445414847162 
2016-12-10 12:35:32 Test Loss = 0.02389535668317 
2016-12-10 12:35:32 -------------------LR------------------- 
2016-12-10 12:35:32 0.0009765625 
2016-12-10 12:35:32 Epoch 220 
2016-12-10 12:37:12 Training Error = 0.21182665046578 
2016-12-10 12:37:12 Training Loss = 0.018008855844991 
2016-12-10 12:37:14 Valid Error = 0.37424058323208 
2016-12-10 12:37:14 Valid Loss = 0.021165589624094 
2016-12-10 12:37:17 Test Error = 0.39628820960699 
2016-12-10 12:37:17 Test Loss = 0.023322920341118 
2016-12-10 12:37:17 -------------------LR------------------- 
2016-12-10 12:37:17 0.0009765625 
2016-12-10 12:37:17 Epoch 221 
2016-12-10 12:38:53 Training Error = 0.21101660591333 
2016-12-10 12:38:53 Training Loss = 0.018036063501125 
2016-12-10 12:38:56 Valid Error = 0.37059538274605 
2016-12-10 12:38:56 Valid Loss = 0.02238050445097 
2016-12-10 12:38:58 Test Error = 0.39192139737991 
2016-12-10 12:38:58 Test Loss = 0.02455754069721 
2016-12-10 12:38:58 -------------------LR------------------- 
2016-12-10 12:38:58 0.0009765625 
2016-12-10 12:38:58 Epoch 222 
2016-12-10 12:40:38 Training Error = 0.21304171729445 
2016-12-10 12:40:38 Training Loss = 0.018052075638402 
2016-12-10 12:40:41 Valid Error = 0.38274605103281 
2016-12-10 12:40:41 Valid Loss = 0.021546192405869 
2016-12-10 12:40:43 Test Error = 0.40938864628821 
2016-12-10 12:40:43 Test Loss = 0.023893504488702 
2016-12-10 12:40:43 -------------------LR------------------- 
2016-12-10 12:40:43 0.0009765625 
2016-12-10 12:40:43 Epoch 223 
2016-12-10 12:42:23 Training Error = 0.21371675442149 
2016-12-10 12:42:23 Training Loss = 0.018013905682105 
2016-12-10 12:42:26 Valid Error = 0.37059538274605 
2016-12-10 12:42:26 Valid Loss = 0.021465058369631 
2016-12-10 12:42:29 Test Error = 0.39519650655022 
2016-12-10 12:42:29 Test Loss = 0.023554784082899 
2016-12-10 12:42:29 -------------------LR------------------- 
2016-12-10 12:42:29 0.0009765625 
2016-12-10 12:42:29 Epoch 224 
2016-12-10 12:44:03 Training Error = 0.21142162818955 
2016-12-10 12:44:03 Training Loss = 0.017939137387743 
2016-12-10 12:44:05 Valid Error = 0.38396111786148 
2016-12-10 12:44:05 Valid Loss = 0.020851760355487 
2016-12-10 12:44:08 Test Error = 0.4061135371179 
2016-12-10 12:44:08 Test Loss = 0.02326536174849 
2016-12-10 12:44:08 -------------------LR------------------- 
2016-12-10 12:44:08 0.0009765625 
2016-12-10 12:44:08 Epoch 225 
2016-12-10 12:45:47 Training Error = 0.21412177669772 
2016-12-10 12:45:47 Training Loss = 0.018061854138628 
2016-12-10 12:45:50 Valid Error = 0.38031591737546 
2016-12-10 12:45:50 Valid Loss = 0.021181472513817 
2016-12-10 12:45:52 Test Error = 0.40174672489083 
2016-12-10 12:45:52 Test Loss = 0.023508056378832 
2016-12-10 12:45:52 -------------------LR------------------- 
2016-12-10 12:45:52 0.0009765625 
2016-12-10 12:45:52 Epoch 226 
