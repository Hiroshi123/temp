2016-12-10 05:59:23 [program started on Sat Dec 10 05:59:23 2016] 
2016-12-10 05:59:23 [command line arguments] 
2016-12-10 05:59:23 stcWeights false 
2016-12-10 05:59:23 LR 0.015625 
2016-12-10 05:59:23 batchSize 100 
2016-12-10 05:59:23 network ./Models/Cifar10_Custom 
2016-12-10 05:59:23 stcNeurons true 
2016-12-10 05:59:23 constBatchSize false 
2016-12-10 05:59:23 chartFileName chart1 
2016-12-10 05:59:23 dp_prepro false 
2016-12-10 05:59:23 nGPU 1 
2016-12-10 05:59:23 dataset Caltech101 
2016-12-10 05:59:23 type cuda 
2016-12-10 05:59:23 momentum 0 
2016-12-10 05:59:23 threads 8 
2016-12-10 05:59:23 weightDecay 0 
2016-12-10 05:59:23 runningVal false 
2016-12-10 05:59:23 convLayerN 4 
2016-12-10 05:59:23 LRDecay 0 
2016-12-10 05:59:23 numHid 1024 
2016-12-10 05:59:23 save /dev/shm/clone/temp/th/Results/Caltech101/model4-14 
2016-12-10 05:59:23 augment false 
2016-12-10 05:59:23 epoch -1 
2016-12-10 05:59:23 modelsFolder ./Models/ 
2016-12-10 05:59:23 format rgb 
2016-12-10 05:59:23 preProcDir /dev/shm/clone/temp/th/PreProcData/Caltech101 
2016-12-10 05:59:23 imageFileExtension svg 
2016-12-10 05:59:23 channel 1.4 
2016-12-10 05:59:23 devid 12 
2016-12-10 05:59:23 visualize 1 
2016-12-10 05:59:23 LRDecayPerEpoch 0.0001 
2016-12-10 05:59:23 optimization adam 
2016-12-10 05:59:23 SBN true 
2016-12-10 05:59:23 normalization simple 
2016-12-10 05:59:23 title model1 
2016-12-10 05:59:23 load  
2016-12-10 05:59:23 whiten true 
2016-12-10 05:59:23 [----------------------] 
2016-12-10 05:59:24 ==> Network 
2016-12-10 05:59:24 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 179, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(179 -> 179, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(179 -> 358, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(358 -> 358, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): nn.View(22912)
  (20): BinaryLinear(22912 -> 1024)
  (21): BatchNormalizationShiftPow2
  (22): nn.HardTanh
  (23): BinarizedNeurons
  (24): BinaryLinear(1024 -> 1024)
  (25): BatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): BinaryLinear(1024 -> 102)
  (29): nn.BatchNormalization
} 
2016-12-10 05:59:24 ==>26648000 Parameters 
2016-12-10 05:59:24 ==> Loss 
2016-12-10 05:59:24 SqrtHingeEmbeddingCriterion 
2016-12-10 05:59:24 
==> Starting Training
 
2016-12-10 05:59:24 Epoch 1 
2016-12-10 06:01:02 Training Error = 0.73768057243148 
2016-12-10 06:01:02 Training Loss = 0.4060539490373 
2016-12-10 06:01:05 Valid Error = 0.71445929526124 
2016-12-10 06:01:05 Valid Loss = 0.0674211758448 
2016-12-10 06:01:08 Test Error = 0.74781659388646 
2016-12-10 06:01:08 Test Loss = 0.068326414295271 
2016-12-10 06:01:08 -------------------LR------------------- 
2016-12-10 06:01:08 0.015625 
2016-12-10 06:01:08 Epoch 2 
2016-12-10 06:02:41 Training Error = 0.5916025381396 
2016-12-10 06:02:41 Training Loss = 0.037960940440629 
2016-12-10 06:02:43 Valid Error = 0.60996354799514 
2016-12-10 06:02:43 Valid Loss = 0.027909651468387 
2016-12-10 06:02:46 Test Error = 0.62336244541485 
2016-12-10 06:02:46 Test Loss = 0.030076390079423 
2016-12-10 06:02:46 -------------------LR------------------- 
2016-12-10 06:02:46 0.015625 
2016-12-10 06:02:46 Epoch 3 
2016-12-10 06:04:22 Training Error = 0.53030916700419 
2016-12-10 06:04:22 Training Loss = 0.027271823407911 
2016-12-10 06:04:25 Valid Error = 0.61117861482382 
2016-12-10 06:04:25 Valid Loss = 0.030527468413309 
2016-12-10 06:04:27 Test Error = 0.61681222707424 
2016-12-10 06:04:27 Test Loss = 0.032957169457978 
2016-12-10 06:04:27 -------------------LR------------------- 
2016-12-10 06:04:27 0.015625 
2016-12-10 06:04:27 Epoch 4 
2016-12-10 06:06:22 Training Error = 0.504792763602 
2016-12-10 06:06:22 Training Loss = 0.025740377501302 
2016-12-10 06:06:25 Valid Error = 0.48724179829891 
2016-12-10 06:06:25 Valid Loss = 0.025492914107145 
2016-12-10 06:06:28 Test Error = 0.54039301310044 
2016-12-10 06:06:28 Test Loss = 0.02906716412189 
2016-12-10 06:06:28 -------------------LR------------------- 
2016-12-10 06:06:28 0.015625 
2016-12-10 06:06:28 Epoch 5 
2016-12-10 06:08:15 Training Error = 0.48575671661941 
2016-12-10 06:08:15 Training Loss = 0.025216637220481 
2016-12-10 06:08:17 Valid Error = 0.48481166464156 
2016-12-10 06:08:17 Valid Loss = 0.026058438788809 
2016-12-10 06:08:20 Test Error = 0.53165938864629 
2016-12-10 06:08:20 Test Loss = 0.030601412156049 
2016-12-10 06:08:20 -------------------LR------------------- 
2016-12-10 06:08:20 0.015625 
2016-12-10 06:08:20 Epoch 6 
2016-12-10 06:09:55 Training Error = 0.47414607803429 
2016-12-10 06:09:55 Training Loss = 0.024451427842255 
2016-12-10 06:09:58 Valid Error = 0.56014580801944 
2016-12-10 06:09:58 Valid Loss = 0.026044430398033 
2016-12-10 06:10:00 Test Error = 0.5971615720524 
2016-12-10 06:10:00 Test Loss = 0.029400528533786 
2016-12-10 06:10:00 -------------------LR------------------- 
2016-12-10 06:10:00 0.015625 
2016-12-10 06:10:00 Epoch 7 
2016-12-10 06:11:49 Training Error = 0.42203321182665 
2016-12-10 06:11:49 Training Loss = 0.022798010537426 
2016-12-10 06:11:52 Valid Error = 0.40583232077764 
2016-12-10 06:11:52 Valid Loss = 0.022715540346892 
2016-12-10 06:11:55 Test Error = 0.4443231441048 
2016-12-10 06:11:55 Test Loss = 0.026898138382856 
2016-12-10 06:11:55 -------------------LR------------------- 
2016-12-10 06:11:55 0.015625 
2016-12-10 06:11:55 Epoch 8 
2016-12-10 06:13:39 Training Error = 0.37370055353044 
2016-12-10 06:13:39 Training Loss = 0.021930821383322 
2016-12-10 06:13:41 Valid Error = 0.38396111786148 
2016-12-10 06:13:41 Valid Loss = 0.021414446428304 
2016-12-10 06:13:44 Test Error = 0.42685589519651 
2016-12-10 06:13:44 Test Loss = 0.025469981343138 
2016-12-10 06:13:44 -------------------LR------------------- 
2016-12-10 06:13:44 0.015625 
2016-12-10 06:13:44 Epoch 9 
2016-12-10 06:15:18 Training Error = 0.30943701903605 
2016-12-10 06:15:18 Training Loss = 0.020585360791859 
2016-12-10 06:15:20 Valid Error = 0.43013365735115 
2016-12-10 06:15:20 Valid Loss = 0.024030584566767 
2016-12-10 06:15:23 Test Error = 0.4443231441048 
2016-12-10 06:15:23 Test Loss = 0.026018334407432 
2016-12-10 06:15:23 -------------------LR------------------- 
2016-12-10 06:15:23 0.015625 
2016-12-10 06:15:23 Epoch 10 
2016-12-10 06:17:06 Training Error = 0.25529904144728 
2016-12-10 06:17:06 Training Loss = 0.019120637512207 
2016-12-10 06:17:09 Valid Error = 0.24422843256379 
2016-12-10 06:17:09 Valid Loss = 0.01753809009728 
2016-12-10 06:17:11 Test Error = 0.26091703056769 
2016-12-10 06:17:11 Test Loss = 0.020174425452363 
2016-12-10 06:17:11 -------------------LR------------------- 
2016-12-10 06:17:11 0.015625 
2016-12-10 06:17:11 Epoch 11 
2016-12-10 06:18:49 Training Error = 0.20750641285271 
2016-12-10 06:18:49 Training Loss = 0.017981435514676 
2016-12-10 06:18:51 Valid Error = 0.35722964763062 
2016-12-10 06:18:51 Valid Loss = 0.021231783543209 
2016-12-10 06:18:54 Test Error = 0.37554585152838 
2016-12-10 06:18:54 Test Loss = 0.023499814042858 
2016-12-10 06:18:54 -------------------LR------------------- 
2016-12-10 06:18:54 0.015625 
2016-12-10 06:18:54 Epoch 12 
2016-12-10 06:20:31 Training Error = 0.20885648710679 
2016-12-10 06:20:31 Training Loss = 0.01792822005328 
2016-12-10 06:20:33 Valid Error = 0.39246658566221 
2016-12-10 06:20:33 Valid Loss = 0.021099373858185 
2016-12-10 06:20:36 Test Error = 0.41266375545852 
2016-12-10 06:20:36 Test Loss = 0.023416651576173 
2016-12-10 06:20:36 -------------------LR------------------- 
2016-12-10 06:20:36 0.015625 
2016-12-10 06:20:36 Epoch 13 
2016-12-10 06:22:13 Training Error = 0.21439179154854 
2016-12-10 06:22:13 Training Loss = 0.018039269701818 
2016-12-10 06:22:15 Valid Error = 0.36452004860267 
2016-12-10 06:22:15 Valid Loss = 0.021168979208634 
2016-12-10 06:22:18 Test Error = 0.39737991266376 
2016-12-10 06:22:18 Test Loss = 0.023458053953507 
2016-12-10 06:22:18 -------------------LR------------------- 
2016-12-10 06:22:18 0.015625 
2016-12-10 06:22:18 Epoch 14 
2016-12-10 06:23:55 Training Error = 0.21371675442149 
2016-12-10 06:23:55 Training Loss = 0.018084704058422 
2016-12-10 06:23:58 Valid Error = 0.38639125151883 
2016-12-10 06:23:58 Valid Loss = 0.021402545114849 
2016-12-10 06:24:00 Test Error = 0.40174672489083 
2016-12-10 06:24:00 Test Loss = 0.0236140888719 
2016-12-10 06:24:00 -------------------LR------------------- 
2016-12-10 06:24:00 0.015625 
2016-12-10 06:24:00 Epoch 15 
2016-12-10 06:25:37 Training Error = 0.20872147968138 
2016-12-10 06:25:37 Training Loss = 0.017928637074133 
2016-12-10 06:25:39 Valid Error = 0.37181044957473 
2016-12-10 06:25:39 Valid Loss = 0.02157927982236 
2016-12-10 06:25:42 Test Error = 0.39301310043668 
2016-12-10 06:25:42 Test Loss = 0.023839775571636 
2016-12-10 06:25:42 -------------------LR------------------- 
2016-12-10 06:25:42 0.015625 
2016-12-10 06:25:42 Epoch 16 
2016-12-10 06:27:33 Training Error = 0.20818144997975 
2016-12-10 06:27:33 Training Loss = 0.018000215042072 
2016-12-10 06:27:35 Valid Error = 0.3681652490887 
2016-12-10 06:27:35 Valid Loss = 0.021164899668685 
2016-12-10 06:27:38 Test Error = 0.39519650655022 
2016-12-10 06:27:38 Test Loss = 0.023289006766151 
2016-12-10 06:27:38 -------------------LR------------------- 
2016-12-10 06:27:38 0.015625 
2016-12-10 06:27:38 Epoch 17 
2016-12-10 06:29:21 Training Error = 0.20993654651006 
2016-12-10 06:29:21 Training Loss = 0.017936899625776 
2016-12-10 06:29:24 Valid Error = 0.3730255164034 
2016-12-10 06:29:24 Valid Loss = 0.022167263972304 
2016-12-10 06:29:26 Test Error = 0.38973799126638 
2016-12-10 06:29:26 Test Loss = 0.024227360229866 
2016-12-10 06:29:26 -------------------LR------------------- 
2016-12-10 06:29:26 0.015625 
2016-12-10 06:29:26 Epoch 18 
2016-12-10 06:31:09 Training Error = 0.20885648710679 
2016-12-10 06:31:09 Training Loss = 0.017999556472166 
2016-12-10 06:31:12 Valid Error = 0.37181044957473 
2016-12-10 06:31:12 Valid Loss = 0.021708051047904 
2016-12-10 06:31:14 Test Error = 0.39737991266376 
2016-12-10 06:31:14 Test Loss = 0.023828375975291 
2016-12-10 06:31:14 -------------------LR------------------- 
2016-12-10 06:31:14 0.015625 
2016-12-10 06:31:14 Epoch 19 
2016-12-10 06:32:57 Training Error = 0.21479681382476 
2016-12-10 06:32:57 Training Loss = 0.017992522954006 
2016-12-10 06:32:59 Valid Error = 0.34021871202916 
2016-12-10 06:32:59 Valid Loss = 0.020755610941621 
2016-12-10 06:33:02 Test Error = 0.34934497816594 
2016-12-10 06:33:02 Test Loss = 0.022852543110941 
2016-12-10 06:33:02 -------------------LR------------------- 
2016-12-10 06:33:02 0.015625 
2016-12-10 06:33:02 Epoch 20 
2016-12-10 06:34:46 Training Error = 0.21115161333873 
2016-12-10 06:34:46 Training Loss = 0.01798322402142 
2016-12-10 06:34:48 Valid Error = 0.35722964763062 
2016-12-10 06:34:48 Valid Loss = 0.020989451298628 
2016-12-10 06:34:51 Test Error = 0.35917030567686 
2016-12-10 06:34:51 Test Loss = 0.02327374383515 
2016-12-10 06:34:51 -------------------LR------------------- 
2016-12-10 06:34:51 0.015625 
2016-12-10 06:34:51 Epoch 21 
2016-12-10 06:36:35 Training Error = 0.21304171729445 
2016-12-10 06:36:35 Training Loss = 0.018102751149695 
2016-12-10 06:36:37 Valid Error = 0.37059538274605 
2016-12-10 06:36:37 Valid Loss = 0.021665480955991 
2016-12-10 06:36:40 Test Error = 0.39192139737991 
2016-12-10 06:36:40 Test Loss = 0.023918076346902 
2016-12-10 06:36:40 -------------------LR------------------- 
2016-12-10 06:36:40 0.015625 
2016-12-10 06:36:40 Epoch 22 
2016-12-10 06:38:23 Training Error = 0.21088159848792 
2016-12-10 06:38:23 Training Loss = 0.017933095024102 
2016-12-10 06:38:25 Valid Error = 0.35722964763062 
2016-12-10 06:38:25 Valid Loss = 0.021412597508822 
2016-12-10 06:38:28 Test Error = 0.3853711790393 
2016-12-10 06:38:28 Test Loss = 0.023599728864782 
2016-12-10 06:38:28 -------------------LR------------------- 
2016-12-10 06:38:28 0.015625 
2016-12-10 06:38:28 Epoch 23 
2016-12-10 06:40:08 Training Error = 0.20993654651006 
2016-12-10 06:40:08 Training Loss = 0.017885149432698 
2016-12-10 06:40:11 Valid Error = 0.38031591737546 
2016-12-10 06:40:11 Valid Loss = 0.021337557268084 
2016-12-10 06:40:14 Test Error = 0.40174672489083 
2016-12-10 06:40:14 Test Loss = 0.023672264575958 
2016-12-10 06:40:14 -------------------LR------------------- 
2016-12-10 06:40:14 0.015625 
2016-12-10 06:40:14 Epoch 24 
2016-12-10 06:41:54 Training Error = 0.21250168759282 
2016-12-10 06:41:54 Training Loss = 0.018178549580436 
2016-12-10 06:41:57 Valid Error = 0.33657351154313 
2016-12-10 06:41:57 Valid Loss = 0.020641965100945 
2016-12-10 06:42:00 Test Error = 0.35917030567686 
2016-12-10 06:42:00 Test Loss = 0.0230484957882 
2016-12-10 06:42:00 -------------------LR------------------- 
2016-12-10 06:42:00 0.015625 
2016-12-10 06:42:00 Epoch 25 
2016-12-10 06:43:40 Training Error = 0.21344673957068 
2016-12-10 06:43:40 Training Loss = 0.018033160114021 
2016-12-10 06:43:43 Valid Error = 0.36573511543135 
2016-12-10 06:43:43 Valid Loss = 0.021642515430557 
2016-12-10 06:43:46 Test Error = 0.38755458515284 
2016-12-10 06:43:46 Test Loss = 0.023812167345309 
2016-12-10 06:43:46 -------------------LR------------------- 
2016-12-10 06:43:46 0.015625 
2016-12-10 06:43:46 Epoch 26 
2016-12-10 06:45:29 Training Error = 0.21398676927231 
2016-12-10 06:45:29 Training Loss = 0.017995446580732 
2016-12-10 06:45:31 Valid Error = 0.38274605103281 
2016-12-10 06:45:31 Valid Loss = 0.02195856169339 
2016-12-10 06:45:34 Test Error = 0.40174672489083 
2016-12-10 06:45:34 Test Loss = 0.024171085806454 
2016-12-10 06:45:34 -------------------LR------------------- 
2016-12-10 06:45:34 0.015625 
2016-12-10 06:45:34 Epoch 27 
2016-12-10 06:47:14 Training Error = 0.21344673957068 
2016-12-10 06:47:14 Training Loss = 0.017935434564044 
2016-12-10 06:47:17 Valid Error = 0.3730255164034 
2016-12-10 06:47:17 Valid Loss = 0.021876405016924 
2016-12-10 06:47:19 Test Error = 0.39956331877729 
2016-12-10 06:47:19 Test Loss = 0.023889185213575 
2016-12-10 06:47:19 -------------------LR------------------- 
2016-12-10 06:47:19 0.015625 
2016-12-10 06:47:19 Epoch 28 
2016-12-10 06:49:07 Training Error = 0.21236668016741 
2016-12-10 06:49:07 Training Loss = 0.017942132710832 
2016-12-10 06:49:09 Valid Error = 0.34993924665857 
2016-12-10 06:49:09 Valid Loss = 0.020292343829091 
2016-12-10 06:49:12 Test Error = 0.3471615720524 
2016-12-10 06:49:12 Test Loss = 0.022393724647223 
2016-12-10 06:49:12 -------------------LR------------------- 
2016-12-10 06:49:12 0.015625 
2016-12-10 06:49:12 Epoch 29 
2016-12-10 06:51:02 Training Error = 0.20710139057648 
2016-12-10 06:51:02 Training Loss = 0.017946114263169 
2016-12-10 06:51:05 Valid Error = 0.37424058323208 
2016-12-10 06:51:05 Valid Loss = 0.021150853557321 
2016-12-10 06:51:07 Test Error = 0.40065502183406 
2016-12-10 06:51:07 Test Loss = 0.023640595950332 
2016-12-10 06:51:07 -------------------LR------------------- 
2016-12-10 06:51:07 0.015625 
2016-12-10 06:51:07 Epoch 30 
