2016-12-09 23:43:48 [program started on Fri Dec  9 23:43:48 2016] 
2016-12-09 23:43:48 [command line arguments] 
2016-12-09 23:43:48 stcWeights false 
2016-12-09 23:43:48 LR 0.015625 
2016-12-09 23:43:48 batchSize 300 
2016-12-09 23:43:48 network ./Models/Cifar10_Custom 
2016-12-09 23:43:48 stcNeurons true 
2016-12-09 23:43:48 constBatchSize false 
2016-12-09 23:43:48 chartFileName chart1 
2016-12-09 23:43:48 dp_prepro false 
2016-12-09 23:43:48 nGPU 1 
2016-12-09 23:43:48 dataset Cifar100 
2016-12-09 23:43:48 type cuda 
2016-12-09 23:43:48 momentum 0 
2016-12-09 23:43:48 threads 8 
2016-12-09 23:43:48 weightDecay 0 
2016-12-09 23:43:48 runningVal false 
2016-12-09 23:43:48 convLayerN 2 
2016-12-09 23:43:48 LRDecay 0 
2016-12-09 23:43:48 numHid 1024 
2016-12-09 23:43:48 save /dev/shm/temp/th/Results/Cifar100/model2-10 
2016-12-09 23:43:48 augment false 
2016-12-09 23:43:48 epoch -1 
2016-12-09 23:43:48 modelsFolder ./Models/ 
2016-12-09 23:43:48 format rgb 
2016-12-09 23:43:48 preProcDir /dev/shm/temp/th/PreProcData/Cifar100 
2016-12-09 23:43:48 imageFileExtension svg 
2016-12-09 23:43:48 channel 1 
2016-12-09 23:43:48 devid 6 
2016-12-09 23:43:48 visualize 1 
2016-12-09 23:43:48 LRDecayPerEpoch 0.0001 
2016-12-09 23:43:48 optimization adam 
2016-12-09 23:43:48 SBN true 
2016-12-09 23:43:48 normalization simple 
2016-12-09 23:43:48 title model1 
2016-12-09 23:43:48 load  
2016-12-09 23:43:48 whiten true 
2016-12-09 23:43:48 [----------------------] 
2016-12-09 23:43:51 ==> Network 
2016-12-09 23:43:51 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): nn.View(32768)
  (11): BinaryLinear(32768 -> 1024)
  (12): BatchNormalizationShiftPow2
  (13): nn.HardTanh
  (14): BinarizedNeurons
  (15): BinaryLinear(1024 -> 1024)
  (16): BatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): BinaryLinear(1024 -> 100)
  (20): nn.BatchNormalization
} 
2016-12-09 23:43:51 ==>34863532 Parameters 
2016-12-09 23:43:51 ==> Loss 
2016-12-09 23:43:51 SqrtHingeEmbeddingCriterion 
2016-12-09 23:43:51 
==> Starting Training
 
2016-12-09 23:43:51 Epoch 1 
2016-12-09 23:50:20 Training Error = 0.90873333333333 
2016-12-09 23:50:20 Training Loss = 0.22746662174479 
2016-12-09 23:50:26 Valid Error = 0.87997599519904 
2016-12-09 23:50:26 Valid Loss = 0.039704238481152 
2016-12-09 23:50:38 Test Error = 0.8735 
2016-12-09 23:50:38 Test Loss = 0.039653740527583 
2016-12-09 23:50:38 -------------------LR------------------- 
2016-12-09 23:50:38 0.015625 
2016-12-09 23:50:38 Epoch 2 
2016-12-09 23:57:04 Training Error = 0.81557777777778 
2016-12-09 23:57:04 Training Loss = 0.037802869167752 
2016-12-09 23:57:10 Valid Error = 0.81636327265453 
2016-12-09 23:57:10 Valid Loss = 0.037647159676773 
2016-12-09 23:57:22 Test Error = 0.818 
2016-12-09 23:57:22 Test Loss = 0.037675296948003 
2016-12-09 23:57:22 -------------------LR------------------- 
2016-12-09 23:57:22 0.015625 
2016-12-09 23:57:22 Epoch 3 
2016-12-10 00:03:48 Training Error = 0.7588 
2016-12-10 00:03:48 Training Loss = 0.036865922281901 
2016-12-10 00:03:54 Valid Error = 0.7873574714943 
2016-12-10 00:03:54 Valid Loss = 0.037172655606512 
2016-12-10 00:04:06 Test Error = 0.7842 
2016-12-10 00:04:06 Test Loss = 0.037230249322629 
2016-12-10 00:04:06 -------------------LR------------------- 
2016-12-10 00:04:06 0.015625 
2016-12-10 00:04:06 Epoch 4 
2016-12-10 00:10:33 Training Error = 0.71528888888889 
2016-12-10 00:10:33 Training Loss = 0.036273504882813 
2016-12-10 00:10:39 Valid Error = 0.74934986997399 
2016-12-10 00:10:39 Valid Loss = 0.036924022310494 
2016-12-10 00:10:51 Test Error = 0.7513 
2016-12-10 00:10:51 Test Loss = 0.036986386976055 
2016-12-10 00:10:51 -------------------LR------------------- 
2016-12-10 00:10:51 0.015625 
2016-12-10 00:10:51 Epoch 5 
2016-12-10 00:17:15 Training Error = 0.68271111111111 
2016-12-10 00:17:15 Training Loss = 0.03580315741645 
2016-12-10 00:17:21 Valid Error = 0.74234846969394 
2016-12-10 00:17:21 Valid Loss = 0.036969249633103 
2016-12-10 00:17:33 Test Error = 0.738 
2016-12-10 00:17:33 Test Loss = 0.036971241012274 
2016-12-10 00:17:33 -------------------LR------------------- 
2016-12-10 00:17:33 0.015625 
2016-12-10 00:17:33 Epoch 6 
2016-12-10 00:24:01 Training Error = 0.65517777777778 
2016-12-10 00:24:01 Training Loss = 0.035430208957248 
2016-12-10 00:24:07 Valid Error = 0.74834966993399 
2016-12-10 00:24:07 Valid Loss = 0.037121268361425 
2016-12-10 00:24:20 Test Error = 0.7435 
2016-12-10 00:24:20 Test Loss = 0.037148669134402 
2016-12-10 00:24:20 -------------------LR------------------- 
2016-12-10 00:24:20 0.015625 
2016-12-10 00:24:20 Epoch 7 
2016-12-10 00:30:41 Training Error = 0.63526666666667 
2016-12-10 00:30:41 Training Loss = 0.035115406195747 
2016-12-10 00:30:47 Valid Error = 0.73674734946989 
2016-12-10 00:30:47 Valid Loss = 0.037119528963512 
2016-12-10 00:30:59 Test Error = 0.7379 
2016-12-10 00:30:59 Test Loss = 0.037171695185643 
2016-12-10 00:30:59 -------------------LR------------------- 
2016-12-10 00:30:59 0.015625 
2016-12-10 00:30:59 Epoch 8 
2016-12-10 00:37:29 Training Error = 0.61866666666667 
2016-12-10 00:37:29 Training Loss = 0.034873431315104 
2016-12-10 00:37:35 Valid Error = 0.7379475895179 
2016-12-10 00:37:35 Valid Loss = 0.037221962234147 
2016-12-10 00:37:47 Test Error = 0.7334 
2016-12-10 00:37:47 Test Loss = 0.037199293996774 
2016-12-10 00:37:47 -------------------LR------------------- 
2016-12-10 00:37:47 0.015625 
2016-12-10 00:37:47 Epoch 9 
2016-12-10 00:44:16 Training Error = 0.60222222222222 
2016-12-10 00:44:16 Training Loss = 0.034652017293294 
2016-12-10 00:44:22 Valid Error = 0.74474894978996 
2016-12-10 00:44:22 Valid Loss = 0.037481929177136 
2016-12-10 00:44:35 Test Error = 0.7431 
2016-12-10 00:44:35 Test Loss = 0.037424084831687 
2016-12-10 00:44:35 -------------------LR------------------- 
2016-12-10 00:44:35 0.015625 
2016-12-10 00:44:35 Epoch 10 
2016-12-10 00:50:57 Training Error = 0.59053333333333 
2016-12-10 00:50:57 Training Loss = 0.034450952324761 
2016-12-10 00:51:03 Valid Error = 0.72974594918984 
2016-12-10 00:51:03 Valid Loss = 0.037374819036685 
2016-12-10 00:51:16 Test Error = 0.7311 
2016-12-10 00:51:16 Test Loss = 0.037376672512877 
2016-12-10 00:51:16 -------------------LR------------------- 
2016-12-10 00:51:16 0.015625 
2016-12-10 00:51:16 Epoch 11 
2016-12-10 00:57:47 Training Error = 0.58148888888889 
2016-12-10 00:57:47 Training Loss = 0.034302539048937 
2016-12-10 00:57:53 Valid Error = 0.73814762952591 
2016-12-10 00:57:53 Valid Loss = 0.037303014010915 
2016-12-10 00:58:06 Test Error = 0.7404 
2016-12-10 00:58:06 Test Loss = 0.037392045892454 
2016-12-10 00:58:06 -------------------LR------------------- 
2016-12-10 00:58:06 0.015625 
2016-12-10 00:58:06 Epoch 12 
2016-12-10 01:04:26 Training Error = 0.57482222222222 
2016-12-10 01:04:26 Training Loss = 0.034191144124349 
2016-12-10 01:04:32 Valid Error = 0.72614522904581 
2016-12-10 01:04:32 Valid Loss = 0.037322649105477 
2016-12-10 01:04:45 Test Error = 0.7304 
2016-12-10 01:04:45 Test Loss = 0.037271600162282 
2016-12-10 01:04:45 -------------------LR------------------- 
2016-12-10 01:04:45 0.015625 
2016-12-10 01:04:45 Epoch 13 
2016-12-10 01:11:13 Training Error = 0.57071111111111 
2016-12-10 01:11:13 Training Loss = 0.034089998196072 
2016-12-10 01:11:19 Valid Error = 0.73974794958992 
2016-12-10 01:11:19 Valid Loss = 0.037358064886896 
2016-12-10 01:11:32 Test Error = 0.7381 
2016-12-10 01:11:32 Test Loss = 0.037419700712316 
2016-12-10 01:11:32 -------------------LR------------------- 
2016-12-10 01:11:32 0.015625 
2016-12-10 01:11:32 Epoch 14 
2016-12-10 01:18:03 Training Error = 0.56664444444444 
2016-12-10 01:18:03 Training Loss = 0.033994146199544 
2016-12-10 01:18:09 Valid Error = 0.73634726945389 
2016-12-10 01:18:09 Valid Loss = 0.03748071609243 
2016-12-10 01:18:21 Test Error = 0.7443 
2016-12-10 01:18:21 Test Loss = 0.037627957003724 
2016-12-10 01:18:21 -------------------LR------------------- 
2016-12-10 01:18:21 0.015625 
2016-12-10 01:18:21 Epoch 15 
2016-12-10 01:24:42 Training Error = 0.55911111111111 
2016-12-10 01:24:42 Training Loss = 0.033891301472982 
2016-12-10 01:24:48 Valid Error = 0.73974794958992 
2016-12-10 01:24:48 Valid Loss = 0.037408250347411 
2016-12-10 01:25:01 Test Error = 0.7416 
2016-12-10 01:25:01 Test Loss = 0.03749622706993 
2016-12-10 01:25:01 -------------------LR------------------- 
2016-12-10 01:25:01 0.015625 
2016-12-10 01:25:01 Epoch 16 
2016-12-10 01:31:27 Training Error = 0.556 
2016-12-10 01:31:27 Training Loss = 0.033833966552734 
2016-12-10 01:31:33 Valid Error = 0.7373474694939 
2016-12-10 01:31:33 Valid Loss = 0.037496746651167 
2016-12-10 01:31:46 Test Error = 0.7398 
2016-12-10 01:31:46 Test Loss = 0.03760169803395 
2016-12-10 01:31:46 -------------------LR------------------- 
2016-12-10 01:31:46 0.015625 
2016-12-10 01:31:46 Epoch 17 
2016-12-10 01:38:10 Training Error = 0.55142222222222 
2016-12-10 01:38:10 Training Loss = 0.033752763902452 
2016-12-10 01:38:16 Valid Error = 0.74454890978196 
2016-12-10 01:38:16 Valid Loss = 0.037494766514096 
2016-12-10 01:38:29 Test Error = 0.7386 
2016-12-10 01:38:29 Test Loss = 0.037563766898361 
2016-12-10 01:38:29 -------------------LR------------------- 
2016-12-10 01:38:29 0.015625 
2016-12-10 01:38:29 Epoch 18 
2016-12-10 01:44:48 Training Error = 0.5518 
2016-12-10 01:44:48 Training Loss = 0.033714919514974 
2016-12-10 01:44:54 Valid Error = 0.74234846969394 
2016-12-10 01:44:54 Valid Loss = 0.037621072882941 
2016-12-10 01:45:06 Test Error = 0.7406 
2016-12-10 01:45:06 Test Loss = 0.037628421289781 
2016-12-10 01:45:06 -------------------LR------------------- 
2016-12-10 01:45:06 0.015625 
2016-12-10 01:45:06 Epoch 19 
2016-12-10 01:51:37 Training Error = 0.5476 
2016-12-10 01:51:37 Training Loss = 0.033639235636393 
2016-12-10 01:51:43 Valid Error = 0.73574714942989 
2016-12-10 01:51:43 Valid Loss = 0.037507607295823 
2016-12-10 01:51:55 Test Error = 0.737 
2016-12-10 01:51:55 Test Loss = 0.037502882834042 
2016-12-10 01:51:55 -------------------LR------------------- 
2016-12-10 01:51:55 0.015625 
2016-12-10 01:51:55 Epoch 20 
2016-12-10 01:58:23 Training Error = 0.54593333333333 
2016-12-10 01:58:23 Training Loss = 0.033600569797092 
2016-12-10 01:58:29 Valid Error = 0.74554910982196 
2016-12-10 01:58:29 Valid Loss = 0.03770601504141 
2016-12-10 01:58:41 Test Error = 0.7416 
2016-12-10 01:58:41 Test Loss = 0.037778390263576 
2016-12-10 01:58:41 -------------------LR------------------- 
2016-12-10 01:58:41 0.015625 
2016-12-10 01:58:41 Epoch 21 
2016-12-10 02:05:07 Training Error = 0.54466666666667 
2016-12-10 02:05:07 Training Loss = 0.033548686401367 
2016-12-10 02:05:13 Valid Error = 0.73614722944589 
2016-12-10 02:05:13 Valid Loss = 0.037466904988234 
2016-12-10 02:05:26 Test Error = 0.7401 
2016-12-10 02:05:26 Test Loss = 0.037555255336387 
2016-12-10 02:05:26 -------------------LR------------------- 
2016-12-10 02:05:26 0.015625 
2016-12-10 02:05:26 Epoch 22 
2016-12-10 02:11:49 Training Error = 0.54062222222222 
2016-12-10 02:11:49 Training Loss = 0.033521888400608 
2016-12-10 02:11:55 Valid Error = 0.72774554910982 
2016-12-10 02:11:55 Valid Loss = 0.037170396474608 
2016-12-10 02:12:08 Test Error = 0.7272 
2016-12-10 02:12:08 Test Loss = 0.037271104102041 
2016-12-10 02:12:08 -------------------LR------------------- 
2016-12-10 02:12:08 0.015625 
2016-12-10 02:12:08 Epoch 23 
2016-12-10 02:18:39 Training Error = 0.54277777777778 
2016-12-10 02:18:39 Training Loss = 0.033464671346029 
2016-12-10 02:18:45 Valid Error = 0.72954590918184 
2016-12-10 02:18:45 Valid Loss = 0.037413764088663 
2016-12-10 02:18:58 Test Error = 0.7296 
2016-12-10 02:18:58 Test Loss = 0.037406683259852 
2016-12-10 02:18:58 -------------------LR------------------- 
2016-12-10 02:18:58 0.015625 
2016-12-10 02:18:58 Epoch 24 
2016-12-10 02:25:17 Training Error = 0.54146666666667 
2016-12-10 02:25:17 Training Loss = 0.033434446899414 
2016-12-10 02:25:23 Valid Error = 0.74754950990198 
2016-12-10 02:25:23 Valid Loss = 0.037741718838525 
2016-12-10 02:25:35 Test Error = 0.7415 
2016-12-10 02:25:35 Test Loss = 0.037707796194039 
2016-12-10 02:25:35 -------------------LR------------------- 
2016-12-10 02:25:35 0.015625 
2016-12-10 02:25:35 Epoch 25 
2016-12-10 02:31:59 Training Error = 0.54022222222222 
2016-12-10 02:31:59 Training Loss = 0.033382467922635 
2016-12-10 02:32:05 Valid Error = 0.7371474294859 
2016-12-10 02:32:05 Valid Loss = 0.037497811954899 
2016-12-10 02:32:18 Test Error = 0.7387 
2016-12-10 02:32:18 Test Loss = 0.037564879114488 
2016-12-10 02:32:18 -------------------LR------------------- 
2016-12-10 02:32:18 0.015625 
2016-12-10 02:32:18 Epoch 26 
2016-12-10 02:38:45 Training Error = 0.53973333333333 
2016-12-10 02:38:45 Training Loss = 0.033355579210069 
2016-12-10 02:38:51 Valid Error = 0.74094818963793 
2016-12-10 02:38:51 Valid Loss = 0.037595147453095 
2016-12-10 02:39:04 Test Error = 0.7409 
2016-12-10 02:39:04 Test Loss = 0.037670831747616 
2016-12-10 02:39:04 -------------------LR------------------- 
2016-12-10 02:39:04 0.015625 
2016-12-10 02:39:04 Epoch 27 
2016-12-10 02:45:26 Training Error = 0.54133333333333 
2016-12-10 02:45:26 Training Loss = 0.033329645046658 
2016-12-10 02:45:33 Valid Error = 0.73974794958992 
2016-12-10 02:45:33 Valid Loss = 0.037448058254517 
2016-12-10 02:45:45 Test Error = 0.7338 
2016-12-10 02:45:45 Test Loss = 0.037471061616785 
2016-12-10 02:45:45 -------------------LR------------------- 
2016-12-10 02:45:45 0.015625 
2016-12-10 02:45:45 Epoch 28 
2016-12-10 02:52:15 Training Error = 0.53802222222222 
2016-12-10 02:52:15 Training Loss = 0.033287481811523 
2016-12-10 02:52:21 Valid Error = 0.74274854970994 
2016-12-10 02:52:21 Valid Loss = 0.037570315099211 
2016-12-10 02:52:34 Test Error = 0.7461 
2016-12-10 02:52:34 Test Loss = 0.037630461569393 
2016-12-10 02:52:34 -------------------LR------------------- 
2016-12-10 02:52:34 0.015625 
2016-12-10 02:52:34 Epoch 29 
2016-12-10 02:58:49 Training Error = 0.53595555555556 
2016-12-10 02:58:49 Training Loss = 0.033241303710938 
2016-12-10 02:58:55 Valid Error = 0.75455091018204 
2016-12-10 02:58:55 Valid Loss = 0.037765893705035 
2016-12-10 02:59:08 Test Error = 0.75 
2016-12-10 02:59:08 Test Loss = 0.037848616955327 
2016-12-10 02:59:08 -------------------LR------------------- 
2016-12-10 02:59:08 0.015625 
2016-12-10 02:59:08 Epoch 30 
2016-12-10 03:05:38 Training Error = 0.53584444444444 
2016-12-10 03:05:38 Training Loss = 0.033234925238715 
2016-12-10 03:05:44 Valid Error = 0.73074614922985 
2016-12-10 03:05:44 Valid Loss = 0.037357968665565 
2016-12-10 03:05:57 Test Error = 0.731 
2016-12-10 03:05:57 Test Loss = 0.037362518220789 
2016-12-10 03:05:57 -------------------LR------------------- 
2016-12-10 03:05:57 0.015625 
2016-12-10 03:05:57 Epoch 31 
2016-12-10 03:12:20 Training Error = 0.53335555555556 
2016-12-10 03:12:20 Training Loss = 0.033199787448459 
2016-12-10 03:12:26 Valid Error = 0.74154830966193 
2016-12-10 03:12:26 Valid Loss = 0.037401501515361 
2016-12-10 03:12:38 Test Error = 0.7388 
2016-12-10 03:12:38 Test Loss = 0.037421770013547 
2016-12-10 03:12:38 -------------------LR------------------- 
2016-12-10 03:12:38 0.015625 
2016-12-10 03:12:38 Epoch 32 
2016-12-10 03:19:02 Training Error = 0.53715555555556 
2016-12-10 03:19:02 Training Loss = 0.03317411706543 
2016-12-10 03:19:08 Valid Error = 0.73294658931786 
2016-12-10 03:19:08 Valid Loss = 0.037645073265521 
2016-12-10 03:19:21 Test Error = 0.7357 
2016-12-10 03:19:21 Test Loss = 0.037762017223882 
2016-12-10 03:19:21 -------------------LR------------------- 
2016-12-10 03:19:21 0.015625 
2016-12-10 03:19:21 Epoch 33 
2016-12-10 03:25:46 Training Error = 0.53664444444444 
2016-12-10 03:25:46 Training Loss = 0.033154355577257 
2016-12-10 03:25:52 Valid Error = 0.73354670934187 
2016-12-10 03:25:52 Valid Loss = 0.037142325123482 
2016-12-10 03:26:05 Test Error = 0.7295 
2016-12-10 03:26:05 Test Loss = 0.037278022796032 
2016-12-10 03:26:05 -------------------LR------------------- 
2016-12-10 03:26:05 0.015625 
2016-12-10 03:26:05 Epoch 34 
2016-12-10 03:32:29 Training Error = 0.53455555555556 
2016-12-10 03:32:29 Training Loss = 0.033111459893121 
2016-12-10 03:32:35 Valid Error = 0.75775155031006 
2016-12-10 03:32:35 Valid Loss = 0.038014420809865 
2016-12-10 03:32:48 Test Error = 0.7529 
2016-12-10 03:32:48 Test Loss = 0.038029219174853 
2016-12-10 03:32:48 -------------------LR------------------- 
2016-12-10 03:32:48 0.015625 
2016-12-10 03:32:48 Epoch 35 
2016-12-10 03:39:05 Training Error = 0.53364444444444 
2016-12-10 03:39:05 Training Loss = 0.033097856241862 
2016-12-10 03:39:12 Valid Error = 0.73294658931786 
2016-12-10 03:39:12 Valid Loss = 0.037197220080469 
2016-12-10 03:39:24 Test Error = 0.7372 
2016-12-10 03:39:24 Test Loss = 0.037264109921923 
2016-12-10 03:39:24 -------------------LR------------------- 
2016-12-10 03:39:24 0.015625 
2016-12-10 03:39:24 Epoch 36 
2016-12-10 03:45:48 Training Error = 0.54066666666667 
2016-12-10 03:45:48 Training Loss = 0.033106726982964 
2016-12-10 03:45:55 Valid Error = 0.73494698939788 
2016-12-10 03:45:55 Valid Loss = 0.037470764543844 
2016-12-10 03:46:07 Test Error = 0.7316 
2016-12-10 03:46:07 Test Loss = 0.037422613764744 
2016-12-10 03:46:07 -------------------LR------------------- 
2016-12-10 03:46:07 0.015625 
2016-12-10 03:46:07 Epoch 37 
2016-12-10 03:52:24 Training Error = 0.53715555555556 
2016-12-10 03:52:24 Training Loss = 0.033053962090386 
2016-12-10 03:52:30 Valid Error = 0.73914782956591 
2016-12-10 03:52:30 Valid Loss = 0.037380705197633 
2016-12-10 03:52:43 Test Error = 0.7421 
2016-12-10 03:52:43 Test Loss = 0.037511731914445 
2016-12-10 03:52:43 -------------------LR------------------- 
2016-12-10 03:52:43 0.015625 
2016-12-10 03:52:43 Epoch 38 
2016-12-10 03:59:08 Training Error = 0.53584444444444 
2016-12-10 03:59:08 Training Loss = 0.032993384792752 
2016-12-10 03:59:15 Valid Error = 0.7369473894779 
2016-12-10 03:59:15 Valid Loss = 0.03742466263297 
2016-12-10 03:59:27 Test Error = 0.736 
2016-12-10 03:59:27 Test Loss = 0.037525129520192 
2016-12-10 03:59:27 -------------------LR------------------- 
2016-12-10 03:59:27 0.015625 
2016-12-10 03:59:27 Epoch 39 
2016-12-10 04:05:48 Training Error = 0.53277777777778 
2016-12-10 04:05:48 Training Loss = 0.032962669596354 
2016-12-10 04:05:55 Valid Error = 0.750550110022 
2016-12-10 04:05:55 Valid Loss = 0.037672982872581 
2016-12-10 04:06:07 Test Error = 0.7422 
2016-12-10 04:06:07 Test Loss = 0.0377056766884 
2016-12-10 04:06:07 -------------------LR------------------- 
2016-12-10 04:06:07 0.015625 
2016-12-10 04:06:07 Epoch 40 
2016-12-10 04:12:40 Training Error = 0.53573333333333 
2016-12-10 04:12:40 Training Loss = 0.03297319938151 
2016-12-10 04:12:47 Valid Error = 0.7369473894779 
2016-12-10 04:12:47 Valid Loss = 0.037296393673234 
2016-12-10 04:12:59 Test Error = 0.73 
2016-12-10 04:12:59 Test Loss = 0.037352450830796 
2016-12-10 04:12:59 -------------------LR------------------- 
2016-12-10 04:12:59 0.015625 
2016-12-10 04:12:59 Epoch 41 
2016-12-10 04:19:15 Training Error = 0.53148888888889 
2016-12-10 04:19:15 Training Loss = 0.032916743218316 
2016-12-10 04:19:21 Valid Error = 0.74174834966993 
2016-12-10 04:19:21 Valid Loss = 0.03759127187042 
2016-12-10 04:19:34 Test Error = 0.7363 
2016-12-10 04:19:34 Test Loss = 0.037686346226113 
2016-12-10 04:19:34 -------------------LR------------------- 
2016-12-10 04:19:34 0.015625 
2016-12-10 04:19:34 Epoch 42 
2016-12-10 04:26:02 Training Error = 0.53122222222222 
2016-12-10 04:26:02 Training Loss = 0.032940292995877 
2016-12-10 04:26:08 Valid Error = 0.73574714942989 
2016-12-10 04:26:08 Valid Loss = 0.037210786344021 
2016-12-10 04:26:20 Test Error = 0.7308 
2016-12-10 04:26:20 Test Loss = 0.037306447017894 
2016-12-10 04:26:20 -------------------LR------------------- 
2016-12-10 04:26:20 0.015625 
2016-12-10 04:26:20 Epoch 43 
2016-12-10 04:32:35 Training Error = 0.53157777777778 
2016-12-10 04:32:35 Training Loss = 0.032875842800564 
2016-12-10 04:32:41 Valid Error = 0.75195039007802 
2016-12-10 04:32:41 Valid Loss = 0.037761249968247 
2016-12-10 04:32:53 Test Error = 0.7496 
2016-12-10 04:32:53 Test Loss = 0.03782677600337 
2016-12-10 04:32:53 -------------------LR------------------- 
2016-12-10 04:32:53 0.015625 
2016-12-10 04:32:53 Epoch 44 
2016-12-10 04:39:20 Training Error = 0.53235555555556 
2016-12-10 04:39:20 Training Loss = 0.032840026801215 
2016-12-10 04:39:26 Valid Error = 0.74134826965393 
2016-12-10 04:39:26 Valid Loss = 0.037519948011446 
2016-12-10 04:39:39 Test Error = 0.7401 
2016-12-10 04:39:39 Test Loss = 0.037608222093769 
2016-12-10 04:39:39 -------------------LR------------------- 
2016-12-10 04:39:39 0.015625 
2016-12-10 04:39:39 Epoch 45 
2016-12-10 04:46:07 Training Error = 0.53124444444444 
2016-12-10 04:46:07 Training Loss = 0.032860355726454 
2016-12-10 04:46:14 Valid Error = 0.73354670934187 
2016-12-10 04:46:14 Valid Loss = 0.037222515404266 
2016-12-10 04:46:26 Test Error = 0.7326 
2016-12-10 04:46:26 Test Loss = 0.037247651193656 
2016-12-10 04:46:26 -------------------LR------------------- 
2016-12-10 04:46:26 0.015625 
2016-12-10 04:46:26 Epoch 46 
2016-12-10 04:52:40 Training Error = 0.52737777777778 
2016-12-10 04:52:40 Training Loss = 0.032815676079644 
2016-12-10 04:52:46 Valid Error = 0.74454890978196 
2016-12-10 04:52:46 Valid Loss = 0.037631635136707 
2016-12-10 04:52:59 Test Error = 0.7435 
2016-12-10 04:52:59 Test Loss = 0.037645587756587 
2016-12-10 04:52:59 -------------------LR------------------- 
2016-12-10 04:52:59 0.015625 
2016-12-10 04:52:59 Epoch 47 
2016-12-10 04:59:28 Training Error = 0.52837777777778 
2016-12-10 04:59:28 Training Loss = 0.032789656643338 
2016-12-10 04:59:35 Valid Error = 0.73074614922985 
2016-12-10 04:59:35 Valid Loss = 0.037281675919426 
2016-12-10 04:59:47 Test Error = 0.7286 
2016-12-10 04:59:47 Test Loss = 0.037349344560212 
2016-12-10 04:59:47 -------------------LR------------------- 
2016-12-10 04:59:47 0.015625 
2016-12-10 04:59:47 Epoch 48 
2016-12-10 05:06:08 Training Error = 0.5306 
2016-12-10 05:06:08 Training Loss = 0.032767831244575 
2016-12-10 05:06:15 Valid Error = 0.74734946989398 
2016-12-10 05:06:15 Valid Loss = 0.037495309218812 
2016-12-10 05:06:27 Test Error = 0.7412 
2016-12-10 05:06:27 Test Loss = 0.03751780610926 
2016-12-10 05:06:27 -------------------LR------------------- 
2016-12-10 05:06:27 0.015625 
2016-12-10 05:06:27 Epoch 49 
2016-12-10 05:12:46 Training Error = 0.52868888888889 
2016-12-10 05:12:46 Training Loss = 0.032735129272461 
2016-12-10 05:12:52 Valid Error = 0.71994398879776 
2016-12-10 05:12:52 Valid Loss = 0.036782246698268 
2016-12-10 05:13:05 Test Error = 0.7247 
2016-12-10 05:13:05 Test Loss = 0.036836713693656 
2016-12-10 05:13:05 -------------------LR------------------- 
2016-12-10 05:13:05 0.015625 
2016-12-10 05:13:05 Epoch 50 
2016-12-10 05:19:33 Training Error = 0.532 
2016-12-10 05:19:33 Training Loss = 0.032721513821072 
2016-12-10 05:19:40 Valid Error = 0.72914582916583 
2016-12-10 05:19:40 Valid Loss = 0.037204561357069 
2016-12-10 05:19:52 Test Error = 0.7357 
2016-12-10 05:19:52 Test Loss = 0.037317860203163 
2016-12-10 05:19:52 -------------------LR------------------- 
2016-12-10 05:19:52 0.0078125 
2016-12-10 05:19:52 Epoch 51 
2016-12-10 05:26:21 Training Error = 0.46293333333333 
2016-12-10 05:26:21 Training Loss = 0.031438612928602 
2016-12-10 05:26:27 Valid Error = 0.70814162832567 
2016-12-10 05:26:27 Valid Loss = 0.037260151053983 
2016-12-10 05:26:40 Test Error = 0.7131 
2016-12-10 05:26:40 Test Loss = 0.037373426639332 
2016-12-10 05:26:40 -------------------LR------------------- 
2016-12-10 05:26:40 0.0078125 
2016-12-10 05:26:40 Epoch 52 
2016-12-10 05:33:00 Training Error = 0.43464444444444 
2016-12-10 05:33:00 Training Loss = 0.030998534722222 
2016-12-10 05:33:07 Valid Error = 0.72654530906181 
2016-12-10 05:33:07 Valid Loss = 0.037961223197935 
2016-12-10 05:33:19 Test Error = 0.7198 
2016-12-10 05:33:19 Test Loss = 0.037956165807387 
2016-12-10 05:33:19 -------------------LR------------------- 
2016-12-10 05:33:19 0.0078125 
2016-12-10 05:33:19 Epoch 53 
2016-12-10 05:39:45 Training Error = 0.42148888888889 
2016-12-10 05:39:45 Training Loss = 0.0308617449273 
2016-12-10 05:39:52 Valid Error = 0.71994398879776 
2016-12-10 05:39:52 Valid Loss = 0.038055708904607 
2016-12-10 05:40:04 Test Error = 0.7165 
2016-12-10 05:40:04 Test Loss = 0.038168713588341 
2016-12-10 05:40:04 -------------------LR------------------- 
2016-12-10 05:40:04 0.0078125 
2016-12-10 05:40:04 Epoch 54 
2016-12-10 05:46:29 Training Error = 0.41688888888889 
2016-12-10 05:46:29 Training Loss = 0.030800355780707 
2016-12-10 05:46:36 Valid Error = 0.73234646929386 
2016-12-10 05:46:36 Valid Loss = 0.038733018369315 
2016-12-10 05:46:48 Test Error = 0.7312 
2016-12-10 05:46:48 Test Loss = 0.038792830672919 
2016-12-10 05:46:48 -------------------LR------------------- 
2016-12-10 05:46:48 0.0078125 
2016-12-10 05:46:48 Epoch 55 
2016-12-10 05:53:15 Training Error = 0.41295555555556 
2016-12-10 05:53:15 Training Loss = 0.03076495574273 
2016-12-10 05:53:21 Valid Error = 0.72674534906981 
2016-12-10 05:53:21 Valid Loss = 0.038174548090868 
2016-12-10 05:53:34 Test Error = 0.7227 
2016-12-10 05:53:34 Test Loss = 0.038128534863042 
2016-12-10 05:53:34 -------------------LR------------------- 
2016-12-10 05:53:34 0.0078125 
2016-12-10 05:53:34 Epoch 56 
2016-12-10 05:59:53 Training Error = 0.40726666666667 
2016-12-10 05:59:53 Training Loss = 0.030696005411784 
2016-12-10 05:59:59 Valid Error = 0.73494698939788 
2016-12-10 05:59:59 Valid Loss = 0.038625942942347 
2016-12-10 06:00:12 Test Error = 0.7314 
2016-12-10 06:00:12 Test Loss = 0.038657605399337 
2016-12-10 06:00:12 -------------------LR------------------- 
2016-12-10 06:00:12 0.0078125 
2016-12-10 06:00:12 Epoch 57 
2016-12-10 06:06:38 Training Error = 0.40342222222222 
2016-12-10 06:06:38 Training Loss = 0.030685175184462 
2016-12-10 06:06:44 Valid Error = 0.72434486897379 
2016-12-10 06:06:44 Valid Loss = 0.038429036099904 
2016-12-10 06:06:57 Test Error = 0.7217 
2016-12-10 06:06:57 Test Loss = 0.038567062976314 
2016-12-10 06:06:57 -------------------LR------------------- 
2016-12-10 06:06:57 0.0078125 
2016-12-10 06:06:57 Epoch 58 
2016-12-10 06:13:22 Training Error = 0.40624444444444 
2016-12-10 06:13:22 Training Loss = 0.030674975789388 
2016-12-10 06:13:28 Valid Error = 0.71974394878976 
2016-12-10 06:13:28 Valid Loss = 0.038436213270175 
2016-12-10 06:13:40 Test Error = 0.7211 
2016-12-10 06:13:40 Test Loss = 0.038440352196787 
2016-12-10 06:13:40 -------------------LR------------------- 
2016-12-10 06:13:40 0.0078125 
2016-12-10 06:13:41 Epoch 59 
2016-12-10 06:20:09 Training Error = 0.40224444444444 
2016-12-10 06:20:09 Training Loss = 0.030630512980143 
2016-12-10 06:20:15 Valid Error = 0.72594518903781 
2016-12-10 06:20:15 Valid Loss = 0.0385949134002 
2016-12-10 06:20:28 Test Error = 0.7312 
2016-12-10 06:20:28 Test Loss = 0.038681153929467 
2016-12-10 06:20:28 -------------------LR------------------- 
2016-12-10 06:20:28 0.0078125 
2016-12-10 06:20:28 Epoch 60 
2016-12-10 06:26:49 Training Error = 0.40224444444444 
2016-12-10 06:26:49 Training Loss = 0.030645013237847 
2016-12-10 06:26:55 Valid Error = 0.70734146829366 
2016-12-10 06:26:55 Valid Loss = 0.038059008292314 
2016-12-10 06:27:07 Test Error = 0.713 
2016-12-10 06:27:07 Test Loss = 0.038187372364717 
2016-12-10 06:27:07 -------------------LR------------------- 
2016-12-10 06:27:07 0.0078125 
2016-12-10 06:27:07 Epoch 61 
2016-12-10 06:33:34 Training Error = 0.40037777777778 
2016-12-10 06:33:34 Training Loss = 0.030611099799262 
2016-12-10 06:33:40 Valid Error = 0.74214842968594 
2016-12-10 06:33:40 Valid Loss = 0.038969127134601 
2016-12-10 06:33:53 Test Error = 0.7392 
2016-12-10 06:33:53 Test Loss = 0.038986172066483 
2016-12-10 06:33:53 -------------------LR------------------- 
2016-12-10 06:33:53 0.0078125 
2016-12-10 06:33:53 Epoch 62 
2016-12-10 06:40:17 Training Error = 0.398 
2016-12-10 06:40:17 Training Loss = 0.03055286066352 
2016-12-10 06:40:23 Valid Error = 0.74234846969394 
2016-12-10 06:40:23 Valid Loss = 0.039125844420094 
2016-12-10 06:40:35 Test Error = 0.7346 
2016-12-10 06:40:35 Test Loss = 0.039177086295334 
2016-12-10 06:40:35 -------------------LR------------------- 
2016-12-10 06:40:35 0.0078125 
2016-12-10 06:40:35 Epoch 63 
2016-12-10 06:46:50 Training Error = 0.3996 
2016-12-10 06:46:50 Training Loss = 0.030594543511285 
2016-12-10 06:46:56 Valid Error = 0.72314462892579 
2016-12-10 06:46:56 Valid Loss = 0.038469146696642 
2016-12-10 06:47:08 Test Error = 0.7217 
2016-12-10 06:47:08 Test Loss = 0.03858062432981 
2016-12-10 06:47:08 -------------------LR------------------- 
2016-12-10 06:47:08 0.0078125 
2016-12-10 06:47:08 Epoch 64 
2016-12-10 06:53:38 Training Error = 0.39808888888889 
2016-12-10 06:53:38 Training Loss = 0.030599016303168 
2016-12-10 06:53:45 Valid Error = 0.74034806961392 
2016-12-10 06:53:45 Valid Loss = 0.038997100839099 
2016-12-10 06:53:57 Test Error = 0.7391 
2016-12-10 06:53:57 Test Loss = 0.038985497687845 
2016-12-10 06:53:57 -------------------LR------------------- 
2016-12-10 06:53:57 0.0078125 
2016-12-10 06:53:57 Epoch 65 
2016-12-10 07:00:17 Training Error = 0.39857777777778 
2016-12-10 07:00:17 Training Loss = 0.03056823167589 
2016-12-10 07:00:23 Valid Error = 0.73114622924585 
2016-12-10 07:00:23 Valid Loss = 0.038847262993314 
2016-12-10 07:00:36 Test Error = 0.7239 
2016-12-10 07:00:36 Test Loss = 0.038852564194623 
2016-12-10 07:00:36 -------------------LR------------------- 
2016-12-10 07:00:36 0.0078125 
2016-12-10 07:00:36 Epoch 66 
2016-12-10 07:07:03 Training Error = 0.39537777777778 
2016-12-10 07:07:03 Training Loss = 0.030551629503038 
2016-12-10 07:07:09 Valid Error = 0.73154630926185 
2016-12-10 07:07:09 Valid Loss = 0.038859905182555 
2016-12-10 07:07:21 Test Error = 0.7315 
2016-12-10 07:07:21 Test Loss = 0.039043997581332 
2016-12-10 07:07:21 -------------------LR------------------- 
2016-12-10 07:07:21 0.0078125 
2016-12-10 07:07:21 Epoch 67 
2016-12-10 07:13:48 Training Error = 0.3956 
2016-12-10 07:13:48 Training Loss = 0.03060362890625 
2016-12-10 07:13:54 Valid Error = 0.73314662932587 
2016-12-10 07:13:54 Valid Loss = 0.038830357955766 
2016-12-10 07:14:07 Test Error = 0.7337 
2016-12-10 07:14:07 Test Loss = 0.038923583475749 
2016-12-10 07:14:07 -------------------LR------------------- 
2016-12-10 07:14:07 0.0078125 
2016-12-10 07:14:07 Epoch 68 
2016-12-10 07:20:27 Training Error = 0.39582222222222 
2016-12-10 07:20:27 Training Loss = 0.030543549479167 
2016-12-10 07:20:33 Valid Error = 0.72074414882977 
2016-12-10 07:20:33 Valid Loss = 0.038631377059451 
2016-12-10 07:20:46 Test Error = 0.718 
2016-12-10 07:20:46 Test Loss = 0.038680991258808 
2016-12-10 07:20:46 -------------------LR------------------- 
2016-12-10 07:20:46 0.0078125 
2016-12-10 07:20:46 Epoch 69 
2016-12-10 07:27:07 Training Error = 0.39313333333333 
2016-12-10 07:27:07 Training Loss = 0.030513814032661 
2016-12-10 07:27:13 Valid Error = 0.73294658931786 
2016-12-10 07:27:13 Valid Loss = 0.038557935999217 
2016-12-10 07:27:26 Test Error = 0.7291 
2016-12-10 07:27:26 Test Loss = 0.038548583116718 
2016-12-10 07:27:26 -------------------LR------------------- 
2016-12-10 07:27:26 0.0078125 
2016-12-10 07:27:26 Epoch 70 
2016-12-10 07:33:56 Training Error = 0.39708888888889 
2016-12-10 07:33:56 Training Loss = 0.030525941840278 
2016-12-10 07:34:03 Valid Error = 0.74334866973395 
2016-12-10 07:34:03 Valid Loss = 0.039023941240603 
2016-12-10 07:34:15 Test Error = 0.7335 
2016-12-10 07:34:15 Test Loss = 0.03904015529857 
2016-12-10 07:34:15 -------------------LR------------------- 
2016-12-10 07:34:15 0.0078125 
2016-12-10 07:34:15 Epoch 71 
2016-12-10 07:40:40 Training Error = 0.39188888888889 
2016-12-10 07:40:40 Training Loss = 0.030452172905816 
2016-12-10 07:40:46 Valid Error = 0.71834366873375 
2016-12-10 07:40:46 Valid Loss = 0.03819501160131 
2016-12-10 07:40:59 Test Error = 0.7114 
2016-12-10 07:40:59 Test Loss = 0.038267830403646 
2016-12-10 07:40:59 -------------------LR------------------- 
2016-12-10 07:40:59 0.0078125 
2016-12-10 07:40:59 Epoch 72 
2016-12-10 07:47:22 Training Error = 0.3942 
2016-12-10 07:47:22 Training Loss = 0.030511187323676 
2016-12-10 07:47:28 Valid Error = 0.73354670934187 
2016-12-10 07:47:28 Valid Loss = 0.039203091093585 
2016-12-10 07:47:41 Test Error = 0.7345 
2016-12-10 07:47:41 Test Loss = 0.039195962075626 
2016-12-10 07:47:41 -------------------LR------------------- 
2016-12-10 07:47:41 0.0078125 
2016-12-10 07:47:41 Epoch 73 
2016-12-10 07:54:06 Training Error = 0.39284444444444 
2016-12-10 07:54:06 Training Loss = 0.030478930121528 
2016-12-10 07:54:13 Valid Error = 0.7255451090218 
2016-12-10 07:54:13 Valid Loss = 0.039302335254753 
2016-12-10 07:54:25 Test Error = 0.7299 
2016-12-10 07:54:25 Test Loss = 0.039298305855545 
2016-12-10 07:54:25 -------------------LR------------------- 
2016-12-10 07:54:25 0.0078125 
2016-12-10 07:54:25 Epoch 74 
2016-12-10 08:00:48 Training Error = 0.39251111111111 
2016-12-10 08:00:48 Training Loss = 0.030498895955404 
2016-12-10 08:00:55 Valid Error = 0.7251450290058 
2016-12-10 08:00:55 Valid Loss = 0.03908671809689 
2016-12-10 08:01:07 Test Error = 0.7315 
2016-12-10 08:01:07 Test Loss = 0.039141515814089 
2016-12-10 08:01:07 -------------------LR------------------- 
2016-12-10 08:01:07 0.0078125 
2016-12-10 08:01:07 Epoch 75 
2016-12-10 08:07:32 Training Error = 0.39231111111111 
2016-12-10 08:07:32 Training Loss = 0.030486300984701 
2016-12-10 08:07:38 Valid Error = 0.73834766953391 
2016-12-10 08:07:38 Valid Loss = 0.039424785071334 
2016-12-10 08:07:51 Test Error = 0.7317 
2016-12-10 08:07:51 Test Loss = 0.039365493265788 
2016-12-10 08:07:51 -------------------LR------------------- 
2016-12-10 08:07:51 0.0078125 
2016-12-10 08:07:51 Epoch 76 
2016-12-10 08:14:22 Training Error = 0.39384444444444 
2016-12-10 08:14:22 Training Loss = 0.03046344265408 
2016-12-10 08:14:28 Valid Error = 0.73894778955791 
2016-12-10 08:14:28 Valid Loss = 0.039448002112277 
2016-12-10 08:14:41 Test Error = 0.7345 
2016-12-10 08:14:41 Test Loss = 0.039388979803347 
2016-12-10 08:14:41 -------------------LR------------------- 
2016-12-10 08:14:41 0.0078125 
2016-12-10 08:14:41 Epoch 77 
2016-12-10 08:20:57 Training Error = 0.3886 
2016-12-10 08:20:57 Training Loss = 0.030452605957031 
2016-12-10 08:21:03 Valid Error = 0.74454890978196 
2016-12-10 08:21:03 Valid Loss = 0.039187183555357 
2016-12-10 08:21:16 Test Error = 0.7419 
2016-12-10 08:21:16 Test Loss = 0.039151896069097 
2016-12-10 08:21:16 -------------------LR------------------- 
2016-12-10 08:21:16 0.0078125 
2016-12-10 08:21:16 Epoch 78 
2016-12-10 08:27:47 Training Error = 0.39113333333333 
2016-12-10 08:27:47 Training Loss = 0.030464957248264 
2016-12-10 08:27:53 Valid Error = 0.73394678935787 
2016-12-10 08:27:53 Valid Loss = 0.038921208090035 
2016-12-10 08:28:06 Test Error = 0.7295 
2016-12-10 08:28:06 Test Loss = 0.038908205458697 
2016-12-10 08:28:06 -------------------LR------------------- 
2016-12-10 08:28:06 0.0078125 
2016-12-10 08:28:06 Epoch 79 
2016-12-10 08:34:30 Training Error = 0.39155555555556 
2016-12-10 08:34:30 Training Loss = 0.030457488674588 
2016-12-10 08:34:37 Valid Error = 0.73314662932587 
2016-12-10 08:34:37 Valid Loss = 0.03913706473015 
2016-12-10 08:34:49 Test Error = 0.728 
2016-12-10 08:34:49 Test Loss = 0.039159712039723 
2016-12-10 08:34:49 -------------------LR------------------- 
2016-12-10 08:34:49 0.0078125 
2016-12-10 08:34:49 Epoch 80 
2016-12-10 08:41:12 Training Error = 0.3912 
2016-12-10 08:41:12 Training Loss = 0.030411120619032 
2016-12-10 08:41:18 Valid Error = 0.72954590918184 
2016-12-10 08:41:18 Valid Loss = 0.03876209798586 
2016-12-10 08:41:31 Test Error = 0.7356 
2016-12-10 08:41:31 Test Loss = 0.038797160937739 
2016-12-10 08:41:31 -------------------LR------------------- 
2016-12-10 08:41:31 0.0078125 
2016-12-10 08:41:31 Epoch 81 
2016-12-10 08:48:03 Training Error = 0.39 
2016-12-10 08:48:03 Training Loss = 0.030430930053711 
2016-12-10 08:48:09 Valid Error = 0.73674734946989 
2016-12-10 08:48:09 Valid Loss = 0.038832155692198 
2016-12-10 08:48:21 Test Error = 0.7339 
2016-12-10 08:48:21 Test Loss = 0.03887673106474 
2016-12-10 08:48:21 -------------------LR------------------- 
2016-12-10 08:48:21 0.0078125 
2016-12-10 08:48:21 Epoch 82 
2016-12-10 08:54:47 Training Error = 0.38911111111111 
2016-12-10 08:54:47 Training Loss = 0.030419041870117 
2016-12-10 08:54:54 Valid Error = 0.73314662932587 
2016-12-10 08:54:54 Valid Loss = 0.038851562386939 
2016-12-10 08:55:06 Test Error = 0.7326 
2016-12-10 08:55:06 Test Loss = 0.03894517214906 
2016-12-10 08:55:06 -------------------LR------------------- 
2016-12-10 08:55:06 0.0078125 
2016-12-10 08:55:06 Epoch 83 
2016-12-10 09:01:29 Training Error = 0.38937777777778 
2016-12-10 09:01:29 Training Loss = 0.030397609592014 
2016-12-10 09:01:35 Valid Error = 0.74054810962192 
2016-12-10 09:01:35 Valid Loss = 0.0392731521629 
2016-12-10 09:01:48 Test Error = 0.7398 
2016-12-10 09:01:48 Test Loss = 0.039308555423512 
2016-12-10 09:01:48 -------------------LR------------------- 
2016-12-10 09:01:48 0.0078125 
2016-12-10 09:01:48 Epoch 84 
2016-12-10 09:08:10 Training Error = 0.38917777777778 
2016-12-10 09:08:10 Training Loss = 0.030395109836155 
2016-12-10 09:08:16 Valid Error = 0.73334666933387 
2016-12-10 09:08:16 Valid Loss = 0.03869794796064 
2016-12-10 09:08:29 Test Error = 0.7196 
2016-12-10 09:08:29 Test Loss = 0.038651466788498 
2016-12-10 09:08:29 -------------------LR------------------- 
2016-12-10 09:08:29 0.0078125 
2016-12-10 09:08:29 Epoch 85 
2016-12-10 09:14:58 Training Error = 0.38717777777778 
2016-12-10 09:14:58 Training Loss = 0.030405275594075 
2016-12-10 09:15:04 Valid Error = 0.7251450290058 
2016-12-10 09:15:04 Valid Loss = 0.038789299876181 
2016-12-10 09:15:17 Test Error = 0.7247 
2016-12-10 09:15:17 Test Loss = 0.03875263450473 
2016-12-10 09:15:17 -------------------LR------------------- 
2016-12-10 09:15:17 0.0078125 
2016-12-10 09:15:17 Epoch 86 
2016-12-10 09:21:39 Training Error = 0.38675555555556 
2016-12-10 09:21:39 Training Loss = 0.030377512234158 
2016-12-10 09:21:45 Valid Error = 0.73274654930986 
2016-12-10 09:21:45 Valid Loss = 0.03876148760062 
2016-12-10 09:21:58 Test Error = 0.7341 
2016-12-10 09:21:58 Test Loss = 0.038832809238808 
2016-12-10 09:21:58 -------------------LR------------------- 
2016-12-10 09:21:58 0.0078125 
2016-12-10 09:21:58 Epoch 87 
2016-12-10 09:28:23 Training Error = 0.38713333333333 
2016-12-10 09:28:23 Training Loss = 0.030378481323242 
2016-12-10 09:28:30 Valid Error = 0.73954790958192 
2016-12-10 09:28:30 Valid Loss = 0.039117633647808 
2016-12-10 09:28:42 Test Error = 0.7343 
2016-12-10 09:28:42 Test Loss = 0.03912182264141 
2016-12-10 09:28:42 -------------------LR------------------- 
2016-12-10 09:28:42 0.0078125 
2016-12-10 09:28:42 Epoch 88 
2016-12-10 09:35:04 Training Error = 0.38988888888889 
2016-12-10 09:35:04 Training Loss = 0.030412114393446 
2016-12-10 09:35:11 Valid Error = 0.72914582916583 
2016-12-10 09:35:11 Valid Loss = 0.038556510979568 
2016-12-10 09:35:23 Test Error = 0.7228 
2016-12-10 09:35:23 Test Loss = 0.03868703101663 
2016-12-10 09:35:23 -------------------LR------------------- 
2016-12-10 09:35:23 0.0078125 
2016-12-10 09:35:23 Epoch 89 
2016-12-10 09:41:50 Training Error = 0.3872 
2016-12-10 09:41:50 Training Loss = 0.030357575113932 
2016-12-10 09:41:57 Valid Error = 0.72854570914183 
2016-12-10 09:41:57 Valid Loss = 0.039042415482456 
2016-12-10 09:42:09 Test Error = 0.7249 
2016-12-10 09:42:09 Test Loss = 0.039013890703987 
2016-12-10 09:42:09 -------------------LR------------------- 
2016-12-10 09:42:09 0.0078125 
2016-12-10 09:42:09 Epoch 90 
2016-12-10 09:48:30 Training Error = 0.38444444444444 
2016-12-10 09:48:30 Training Loss = 0.030328864312066 
2016-12-10 09:48:36 Valid Error = 0.72854570914183 
2016-12-10 09:48:36 Valid Loss = 0.038854749066786 
2016-12-10 09:48:49 Test Error = 0.721 
2016-12-10 09:48:49 Test Loss = 0.038797862034218 
2016-12-10 09:48:49 -------------------LR------------------- 
2016-12-10 09:48:49 0.0078125 
2016-12-10 09:48:49 Epoch 91 
2016-12-10 09:55:10 Training Error = 0.38815555555556 
2016-12-10 09:55:10 Training Loss = 0.030333314548069 
2016-12-10 09:55:17 Valid Error = 0.75295059011802 
2016-12-10 09:55:17 Valid Loss = 0.0394563777727 
2016-12-10 09:55:29 Test Error = 0.7505 
2016-12-10 09:55:29 Test Loss = 0.039342578723384 
2016-12-10 09:55:29 -------------------LR------------------- 
2016-12-10 09:55:29 0.0078125 
2016-12-10 09:55:29 Epoch 92 
2016-12-10 10:01:50 Training Error = 0.38944444444444 
2016-12-10 10:01:50 Training Loss = 0.030355812432183 
2016-12-10 10:01:56 Valid Error = 0.74534906981396 
2016-12-10 10:01:56 Valid Loss = 0.03916085259083 
2016-12-10 10:02:09 Test Error = 0.7398 
2016-12-10 10:02:09 Test Loss = 0.039166764711866 
2016-12-10 10:02:09 -------------------LR------------------- 
2016-12-10 10:02:09 0.0078125 
2016-12-10 10:02:09 Epoch 93 
2016-12-10 10:08:36 Training Error = 0.3844 
2016-12-10 10:08:36 Training Loss = 0.030344215535482 
2016-12-10 10:08:42 Valid Error = 0.73414682936587 
2016-12-10 10:08:42 Valid Loss = 0.038747177019682 
2016-12-10 10:08:55 Test Error = 0.7261 
2016-12-10 10:08:55 Test Loss = 0.038639466468961 
2016-12-10 10:08:55 -------------------LR------------------- 
2016-12-10 10:08:55 0.0078125 
2016-12-10 10:08:55 Epoch 94 
2016-12-10 10:15:12 Training Error = 0.3856 
2016-12-10 10:15:12 Training Loss = 0.030337859564887 
2016-12-10 10:15:18 Valid Error = 0.7375475095019 
2016-12-10 10:15:18 Valid Loss = 0.039344019346118 
2016-12-10 10:15:31 Test Error = 0.7303 
2016-12-10 10:15:31 Test Loss = 0.039276590085497 
2016-12-10 10:15:31 -------------------LR------------------- 
2016-12-10 10:15:31 0.0078125 
2016-12-10 10:15:31 Epoch 95 
2016-12-10 10:22:03 Training Error = 0.38784444444444 
2016-12-10 10:22:03 Training Loss = 0.030316696112739 
2016-12-10 10:22:09 Valid Error = 0.73254650930186 
2016-12-10 10:22:09 Valid Loss = 0.03908473741977 
2016-12-10 10:22:21 Test Error = 0.7364 
2016-12-10 10:22:21 Test Loss = 0.039117777267157 
2016-12-10 10:22:21 -------------------LR------------------- 
2016-12-10 10:22:21 0.0078125 
2016-12-10 10:22:21 Epoch 96 
2016-12-10 10:28:41 Training Error = 0.38364444444444 
2016-12-10 10:28:41 Training Loss = 0.030328929836697 
2016-12-10 10:28:47 Valid Error = 0.72914582916583 
2016-12-10 10:28:47 Valid Loss = 0.039270434818086 
2016-12-10 10:28:59 Test Error = 0.7284 
2016-12-10 10:28:59 Test Loss = 0.039137138935164 
2016-12-10 10:28:59 -------------------LR------------------- 
2016-12-10 10:28:59 0.0078125 
2016-12-10 10:28:59 Epoch 97 
2016-12-10 10:35:20 Training Error = 0.38002222222222 
2016-12-10 10:35:20 Training Loss = 0.030284709459093 
2016-12-10 10:35:26 Valid Error = 0.73914782956591 
2016-12-10 10:35:26 Valid Loss = 0.039061362025402 
2016-12-10 10:35:39 Test Error = 0.7389 
2016-12-10 10:35:39 Test Loss = 0.038991225298713 
2016-12-10 10:35:39 -------------------LR------------------- 
2016-12-10 10:35:39 0.0078125 
2016-12-10 10:35:39 Epoch 98 
2016-12-10 10:42:10 Training Error = 0.38264444444444 
2016-12-10 10:42:10 Training Loss = 0.030294300198025 
2016-12-10 10:42:16 Valid Error = 0.73414682936587 
2016-12-10 10:42:16 Valid Loss = 0.03924205086761 
2016-12-10 10:42:29 Test Error = 0.7377 
2016-12-10 10:42:29 Test Loss = 0.0392156688017 
2016-12-10 10:42:29 -------------------LR------------------- 
2016-12-10 10:42:29 0.0078125 
2016-12-10 10:42:29 Epoch 99 
2016-12-10 10:48:48 Training Error = 0.38348888888889 
2016-12-10 10:48:48 Training Loss = 0.030285893608941 
2016-12-10 10:48:54 Valid Error = 0.74934986997399 
2016-12-10 10:48:54 Valid Loss = 0.039163872906727 
2016-12-10 10:49:06 Test Error = 0.7415 
2016-12-10 10:49:06 Test Loss = 0.039151378885905 
2016-12-10 10:49:06 -------------------LR------------------- 
2016-12-10 10:49:06 0.0078125 
2016-12-10 10:49:06 Epoch 100 
2016-12-10 10:55:40 Training Error = 0.38871111111111 
2016-12-10 10:55:40 Training Loss = 0.030315043402778 
2016-12-10 10:55:47 Valid Error = 0.73394678935787 
2016-12-10 10:55:47 Valid Loss = 0.038703860045142 
2016-12-10 10:55:59 Test Error = 0.7339 
2016-12-10 10:55:59 Test Loss = 0.038731965038823 
2016-12-10 10:55:59 -------------------LR------------------- 
2016-12-10 10:55:59 0.00390625 
2016-12-10 10:55:59 Epoch 101 
2016-12-10 11:02:21 Training Error = 0.32275555555556 
2016-12-10 11:02:21 Training Loss = 0.028855740356445 
2016-12-10 11:02:27 Valid Error = 0.72334466893379 
2016-12-10 11:02:27 Valid Loss = 0.03928366036486 
2016-12-10 11:02:39 Test Error = 0.723 
2016-12-10 11:02:39 Test Loss = 0.039213459209367 
2016-12-10 11:02:39 -------------------LR------------------- 
2016-12-10 11:02:39 0.00390625 
2016-12-10 11:02:40 Epoch 102 
2016-12-10 11:09:02 Training Error = 0.29413333333333 
2016-12-10 11:09:02 Training Loss = 0.028340513739692 
2016-12-10 11:09:08 Valid Error = 0.73174634926985 
2016-12-10 11:09:08 Valid Loss = 0.039651120605228 
2016-12-10 11:09:21 Test Error = 0.7238 
2016-12-10 11:09:21 Test Loss = 0.0396822265625 
2016-12-10 11:09:21 -------------------LR------------------- 
2016-12-10 11:09:21 0.00390625 
2016-12-10 11:09:21 Epoch 103 
2016-12-10 11:15:42 Training Error = 0.27995555555556 
2016-12-10 11:15:42 Training Loss = 0.028141686469184 
2016-12-10 11:15:49 Valid Error = 0.72574514902981 
2016-12-10 11:15:49 Valid Loss = 0.040048723940051 
2016-12-10 11:16:01 Test Error = 0.7238 
2016-12-10 11:16:01 Test Loss = 0.040035031307445 
2016-12-10 11:16:01 -------------------LR------------------- 
2016-12-10 11:16:01 0.00390625 
2016-12-10 11:16:01 Epoch 104 
2016-12-10 11:22:29 Training Error = 0.27133333333333 
2016-12-10 11:22:29 Training Loss = 0.028053433254666 
2016-12-10 11:22:35 Valid Error = 0.73414682936587 
2016-12-10 11:22:35 Valid Loss = 0.040652310600134 
2016-12-10 11:22:47 Test Error = 0.7281 
2016-12-10 11:22:47 Test Loss = 0.040604577457204 
2016-12-10 11:22:47 -------------------LR------------------- 
2016-12-10 11:22:47 0.00390625 
2016-12-10 11:22:48 Epoch 105 
2016-12-10 11:29:06 Training Error = 0.2674 
2016-12-10 11:29:06 Training Loss = 0.027951112358941 
2016-12-10 11:29:12 Valid Error = 0.72174434886977 
2016-12-10 11:29:12 Valid Loss = 0.040013655651881 
2016-12-10 11:29:25 Test Error = 0.7174 
2016-12-10 11:29:25 Test Loss = 0.040041261291504 
2016-12-10 11:29:25 -------------------LR------------------- 
2016-12-10 11:29:25 0.00390625 
2016-12-10 11:29:25 Epoch 106 
2016-12-10 11:35:53 Training Error = 0.26471111111111 
2016-12-10 11:35:53 Training Loss = 0.027902875854492 
2016-12-10 11:36:00 Valid Error = 0.71994398879776 
2016-12-10 11:36:00 Valid Loss = 0.039845031430369 
2016-12-10 11:36:12 Test Error = 0.7239 
2016-12-10 11:36:12 Test Loss = 0.039814876960306 
2016-12-10 11:36:12 -------------------LR------------------- 
2016-12-10 11:36:12 0.00390625 
2016-12-10 11:36:12 Epoch 107 
