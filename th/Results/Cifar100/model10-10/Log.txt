2016-12-10 16:39:49 [program started on Sat Dec 10 16:39:49 2016] 
2016-12-10 16:39:49 [command line arguments] 
2016-12-10 16:39:49 stcWeights false 
2016-12-10 16:39:49 LR 0.015625 
2016-12-10 16:39:49 batchSize 300 
2016-12-10 16:39:49 network ./Models/Cifar10_Custom 
2016-12-10 16:39:49 stcNeurons true 
2016-12-10 16:39:49 constBatchSize false 
2016-12-10 16:39:49 chartFileName chart1 
2016-12-10 16:39:49 dp_prepro false 
2016-12-10 16:39:49 nGPU 3 
2016-12-10 16:39:49 dataset Cifar100 
2016-12-10 16:39:49 type cuda 
2016-12-10 16:39:49 momentum 0 
2016-12-10 16:39:49 threads 8 
2016-12-10 16:39:49 weightDecay 0 
2016-12-10 16:39:49 runningVal false 
2016-12-10 16:39:49 convLayerN 10 
2016-12-10 16:39:49 LRDecay 0 
2016-12-10 16:39:49 numHid 1024 
2016-12-10 16:39:49 save /dev/shm/clone/temp/th/Results/Cifar100/model10-10 
2016-12-10 16:39:49 augment false 
2016-12-10 16:39:49 epoch -1 
2016-12-10 16:39:49 modelsFolder ./Models/ 
2016-12-10 16:39:49 format rgb 
2016-12-10 16:39:49 preProcDir /dev/shm/clone/temp/th/PreProcData/Cifar100 
2016-12-10 16:39:49 imageFileExtension svg 
2016-12-10 16:39:49 channel 1 
2016-12-10 16:39:49 devid 4 
2016-12-10 16:39:49 visualize 1 
2016-12-10 16:39:49 LRDecayPerEpoch 0.0001 
2016-12-10 16:39:49 optimization adam 
2016-12-10 16:39:49 SBN true 
2016-12-10 16:39:49 normalization simple 
2016-12-10 16:39:49 title model1 
2016-12-10 16:39:49 load  
2016-12-10 16:39:49 whiten true 
2016-12-10 16:39:49 [----------------------] 
2016-12-10 16:39:55 ==> Network 
2016-12-10 16:39:55 DataParallelTable: 3 x nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> (43) -> (44) -> (45) -> (46) -> (47) -> (48) -> (49) -> (50) -> (51) -> (52) -> (53) -> (54) -> (55) -> (56) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (29): SpatialBatchNormalizationShiftPow2
  (30): nn.HardTanh
  (31): BinarizedNeurons
  (32): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (33): cudnn.SpatialMaxPooling(2x2, 2,2)
  (34): SpatialBatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (38): SpatialBatchNormalizationShiftPow2
  (39): nn.HardTanh
  (40): BinarizedNeurons
  (41): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (42): cudnn.SpatialMaxPooling(2x2, 2,2)
  (43): SpatialBatchNormalizationShiftPow2
  (44): nn.HardTanh
  (45): BinarizedNeurons
  (46): nn.View(512)
  (47): BinaryLinear(512 -> 1024)
  (48): BatchNormalizationShiftPow2
  (49): nn.HardTanh
  (50): BinarizedNeurons
  (51): BinaryLinear(1024 -> 1024)
  (52): BatchNormalizationShiftPow2
  (53): nn.HardTanh
  (54): BinarizedNeurons
  (55): BinaryLinear(1024 -> 100)
  (56): nn.BatchNormalization
} 
2016-12-10 16:39:55 ==>15705004 Parameters 
2016-12-10 16:39:55 ==> Loss 
2016-12-10 16:39:55 SqrtHingeEmbeddingCriterion 
2016-12-10 16:39:55 
==> Starting Training
 
2016-12-10 16:39:55 Epoch 1 
2016-12-10 16:44:48 Training Error = 0.98444444444444 
2016-12-10 16:44:48 Training Loss = 0.22999924197049 
2016-12-10 16:44:52 Valid Error = 0.97619523904781 
2016-12-10 16:44:52 Valid Loss = 0.041275278339316 
2016-12-10 16:45:08 Test Error = 0.9773 
2016-12-10 16:45:08 Test Loss = 0.041153007417567 
2016-12-10 16:45:08 -------------------LR------------------- 
2016-12-10 16:45:08 0.015625 
2016-12-10 16:45:09 Epoch 2 
2016-12-10 16:49:51 Training Error = 0.98233333333333 
2016-12-10 16:49:51 Training Loss = 0.040632346733941 
2016-12-10 16:49:56 Valid Error = 0.97759551910382 
2016-12-10 16:49:56 Valid Loss = 0.040292102220373 
2016-12-10 16:50:12 Test Error = 0.9798 
2016-12-10 16:50:12 Test Loss = 0.040187424154843 
2016-12-10 16:50:12 -------------------LR------------------- 
2016-12-10 16:50:12 0.015625 
2016-12-10 16:50:12 Epoch 3 
2016-12-10 16:56:26 Training Error = 0.98011111111111 
2016-12-10 16:56:26 Training Loss = 0.039982876519097 
2016-12-10 16:56:31 Valid Error = 0.9751950390078 
2016-12-10 16:56:31 Valid Loss = 0.039927643603472 
2016-12-10 16:56:47 Test Error = 0.9758 
2016-12-10 16:56:47 Test Loss = 0.03981992112702 
2016-12-10 16:56:47 -------------------LR------------------- 
2016-12-10 16:56:47 0.015625 
2016-12-10 16:56:47 Epoch 4 
2016-12-10 17:03:10 Training Error = 0.9762 
2016-12-10 17:03:10 Training Loss = 0.039715322862413 
2016-12-10 17:03:14 Valid Error = 0.9743948789758 
2016-12-10 17:03:14 Valid Loss = 0.039802225972415 
2016-12-10 17:03:31 Test Error = 0.9754 
2016-12-10 17:03:31 Test Loss = 0.039772325732661 
2016-12-10 17:03:31 -------------------LR------------------- 
2016-12-10 17:03:31 0.015625 
2016-12-10 17:03:31 Epoch 5 
2016-12-10 17:09:38 Training Error = 0.97311111111111 
2016-12-10 17:09:38 Training Loss = 0.039566083170573 
2016-12-10 17:09:43 Valid Error = 0.96839367873575 
2016-12-10 17:09:43 Valid Loss = 0.03966435754836 
2016-12-10 17:09:59 Test Error = 0.9724 
2016-12-10 17:09:59 Test Loss = 0.039645582401051 
2016-12-10 17:09:59 -------------------LR------------------- 
2016-12-10 17:09:59 0.015625 
2016-12-10 17:10:00 Epoch 6 
2016-12-10 17:16:29 Training Error = 0.96955555555556 
2016-12-10 17:16:29 Training Loss = 0.039468072401259 
2016-12-10 17:16:34 Valid Error = 0.96639327865573 
2016-12-10 17:16:34 Valid Loss = 0.039590490782795 
2016-12-10 17:16:50 Test Error = 0.9704 
2016-12-10 17:16:50 Test Loss = 0.039602778445973 
2016-12-10 17:16:50 -------------------LR------------------- 
2016-12-10 17:16:50 0.015625 
2016-12-10 17:16:50 Epoch 7 
2016-12-10 17:23:04 Training Error = 0.96384444444444 
2016-12-10 17:23:04 Training Loss = 0.039392341959635 
2016-12-10 17:23:09 Valid Error = 0.96319263852771 
2016-12-10 17:23:09 Valid Loss = 0.039481119477741 
2016-12-10 17:23:25 Test Error = 0.9634 
2016-12-10 17:23:25 Test Loss = 0.039500625819786 
2016-12-10 17:23:25 -------------------LR------------------- 
2016-12-10 17:23:25 0.015625 
2016-12-10 17:23:25 Epoch 8 
2016-12-10 17:29:55 Training Error = 0.95948888888889 
2016-12-10 17:29:55 Training Loss = 0.039306797770182 
2016-12-10 17:30:00 Valid Error = 0.95919183836767 
2016-12-10 17:30:00 Valid Loss = 0.039409604360844 
2016-12-10 17:30:17 Test Error = 0.9614 
2016-12-10 17:30:17 Test Loss = 0.03943737783993 
2016-12-10 17:30:17 -------------------LR------------------- 
2016-12-10 17:30:17 0.015625 
2016-12-10 17:30:17 Epoch 9 
2016-12-10 17:36:40 Training Error = 0.95664444444444 
2016-12-10 17:36:40 Training Loss = 0.03923563164605 
2016-12-10 17:36:45 Valid Error = 0.95919183836767 
2016-12-10 17:36:45 Valid Loss = 0.039311602944977 
2016-12-10 17:37:01 Test Error = 0.9575 
2016-12-10 17:37:01 Test Loss = 0.03938911746156 
2016-12-10 17:37:01 -------------------LR------------------- 
2016-12-10 17:37:01 0.015625 
2016-12-10 17:37:01 Epoch 10 
2016-12-10 17:43:12 Training Error = 0.95457777777778 
2016-12-10 17:43:12 Training Loss = 0.039148926323785 
2016-12-10 17:43:17 Valid Error = 0.95299059811962 
2016-12-10 17:43:17 Valid Loss = 0.039355391685372 
2016-12-10 17:43:33 Test Error = 0.9545 
2016-12-10 17:43:33 Test Loss = 0.039436903022317 
2016-12-10 17:43:33 -------------------LR------------------- 
2016-12-10 17:43:33 0.015625 
2016-12-10 17:43:33 Epoch 11 
2016-12-10 17:49:57 Training Error = 0.95206666666667 
2016-12-10 17:49:57 Training Loss = 0.039087386311849 
2016-12-10 17:50:02 Valid Error = 0.9505901180236 
2016-12-10 17:50:02 Valid Loss = 0.03923279294277 
2016-12-10 17:50:18 Test Error = 0.9524 
2016-12-10 17:50:18 Test Loss = 0.039342585993748 
2016-12-10 17:50:18 -------------------LR------------------- 
2016-12-10 17:50:18 0.015625 
2016-12-10 17:50:18 Epoch 12 
2016-12-10 17:56:23 Training Error = 0.95004444444444 
2016-12-10 17:56:23 Training Loss = 0.039025720784505 
2016-12-10 17:56:27 Valid Error = 0.94618923784757 
2016-12-10 17:56:27 Valid Loss = 0.039248813262227 
2016-12-10 17:56:44 Test Error = 0.9468 
2016-12-10 17:56:44 Test Loss = 0.039365944955863 
2016-12-10 17:56:44 -------------------LR------------------- 
2016-12-10 17:56:44 0.015625 
2016-12-10 17:56:44 Epoch 13 
2016-12-10 18:03:00 Training Error = 0.94611111111111 
2016-12-10 18:03:00 Training Loss = 0.038966646674262 
2016-12-10 18:03:05 Valid Error = 0.93958791758352 
2016-12-10 18:03:05 Valid Loss = 0.039183716495073 
2016-12-10 18:03:21 Test Error = 0.9439 
2016-12-10 18:03:21 Test Loss = 0.03931980378394 
2016-12-10 18:03:21 -------------------LR------------------- 
2016-12-10 18:03:21 0.015625 
2016-12-10 18:03:21 Epoch 14 
2016-12-10 18:09:16 Training Error = 0.9416 
2016-12-10 18:09:16 Training Loss = 0.038899674560547 
2016-12-10 18:09:21 Valid Error = 0.94078815763153 
2016-12-10 18:09:21 Valid Loss = 0.039013374587061 
2016-12-10 18:09:37 Test Error = 0.9431 
2016-12-10 18:09:37 Test Loss = 0.039167718146829 
2016-12-10 18:09:37 -------------------LR------------------- 
2016-12-10 18:09:37 0.015625 
2016-12-10 18:09:37 Epoch 15 
2016-12-10 18:16:04 Training Error = 0.93717777777778 
2016-12-10 18:16:04 Training Loss = 0.038839964029948 
2016-12-10 18:16:09 Valid Error = 0.92858571714343 
2016-12-10 18:16:09 Valid Loss = 0.038797519363823 
2016-12-10 18:16:25 Test Error = 0.9329 
2016-12-10 18:16:25 Test Loss = 0.03895146259981 
2016-12-10 18:16:25 -------------------LR------------------- 
2016-12-10 18:16:25 0.015625 
2016-12-10 18:16:25 Epoch 16 
2016-12-10 18:22:33 Training Error = 0.93242222222222 
2016-12-10 18:22:33 Training Loss = 0.03876261062283 
2016-12-10 18:22:38 Valid Error = 0.92678535707141 
2016-12-10 18:22:38 Valid Loss = 0.038831858025383 
2016-12-10 18:22:54 Test Error = 0.9322 
2016-12-10 18:22:54 Test Loss = 0.039032799275716 
2016-12-10 18:22:54 -------------------LR------------------- 
2016-12-10 18:22:54 0.015625 
2016-12-10 18:22:55 Epoch 17 
2016-12-10 18:29:12 Training Error = 0.92282222222222 
2016-12-10 18:29:12 Training Loss = 0.038651256863064 
2016-12-10 18:29:16 Valid Error = 0.91738347669534 
2016-12-10 18:29:16 Valid Loss = 0.038779052361513 
2016-12-10 18:29:33 Test Error = 0.9258 
2016-12-10 18:29:33 Test Loss = 0.039043634422153 
2016-12-10 18:29:33 -------------------LR------------------- 
2016-12-10 18:29:33 0.015625 
2016-12-10 18:29:33 Epoch 18 
2016-12-10 18:35:29 Training Error = 0.91437777777778 
2016-12-10 18:35:29 Training Loss = 0.038517544976128 
2016-12-10 18:35:34 Valid Error = 0.90838167633527 
2016-12-10 18:35:34 Valid Loss = 0.038883923788481 
2016-12-10 18:35:51 Test Error = 0.9123 
2016-12-10 18:35:51 Test Loss = 0.039135172466203 
2016-12-10 18:35:51 -------------------LR------------------- 
2016-12-10 18:35:51 0.015625 
2016-12-10 18:35:51 Epoch 19 
2016-12-10 18:42:11 Training Error = 0.90608888888889 
2016-12-10 18:42:11 Training Loss = 0.038396091471354 
2016-12-10 18:42:16 Valid Error = 0.91018203640728 
2016-12-10 18:42:16 Valid Loss = 0.038825826640575 
2016-12-10 18:42:32 Test Error = 0.9152 
2016-12-10 18:42:32 Test Loss = 0.039032281374464 
2016-12-10 18:42:32 -------------------LR------------------- 
2016-12-10 18:42:32 0.015625 
2016-12-10 18:42:32 Epoch 20 
2016-12-10 18:48:32 Training Error = 0.89817777777778 
2016-12-10 18:48:32 Training Loss = 0.038244357259115 
2016-12-10 18:48:36 Valid Error = 0.90818163632727 
2016-12-10 18:48:36 Valid Loss = 0.038888581680808 
2016-12-10 18:48:53 Test Error = 0.9093 
2016-12-10 18:48:53 Test Loss = 0.039107580865598 
2016-12-10 18:48:53 -------------------LR------------------- 
2016-12-10 18:48:53 0.015625 
2016-12-10 18:48:53 Epoch 21 
2016-12-10 18:55:13 Training Error = 0.89062222222222 
2016-12-10 18:55:13 Training Loss = 0.038110368408203 
2016-12-10 18:55:18 Valid Error = 0.90458091618324 
2016-12-10 18:55:18 Valid Loss = 0.039019222651102 
2016-12-10 18:55:35 Test Error = 0.9027 
2016-12-10 18:55:35 Test Loss = 0.039271496103324 
2016-12-10 18:55:35 -------------------LR------------------- 
2016-12-10 18:55:35 0.015625 
2016-12-10 18:55:35 Epoch 22 
2016-12-10 19:01:48 Training Error = 0.88322222222222 
2016-12-10 19:01:48 Training Loss = 0.03797966273329 
2016-12-10 19:01:53 Valid Error = 0.89877975595119 
2016-12-10 19:01:53 Valid Loss = 0.038968604008765 
2016-12-10 19:02:09 Test Error = 0.8936 
2016-12-10 19:02:09 Test Loss = 0.03917128942153 
2016-12-10 19:02:09 -------------------LR------------------- 
2016-12-10 19:02:09 0.015625 
2016-12-10 19:02:09 Epoch 23 
2016-12-10 19:08:30 Training Error = 0.87008888888889 
2016-12-10 19:08:30 Training Loss = 0.037823884765625 
2016-12-10 19:08:34 Valid Error = 0.8879775955191 
2016-12-10 19:08:34 Valid Loss = 0.038896851753839 
2016-12-10 19:08:51 Test Error = 0.8907 
2016-12-10 19:08:51 Test Loss = 0.039053625966988 
2016-12-10 19:08:51 -------------------LR------------------- 
2016-12-10 19:08:51 0.015625 
2016-12-10 19:08:51 Epoch 24 
2016-12-10 19:15:05 Training Error = 0.86113333333333 
2016-12-10 19:15:05 Training Loss = 0.037651430338542 
2016-12-10 19:15:10 Valid Error = 0.88157631526305 
2016-12-10 19:15:10 Valid Loss = 0.03893128463049 
2016-12-10 19:15:26 Test Error = 0.8829 
2016-12-10 19:15:26 Test Loss = 0.039165744736615 
2016-12-10 19:15:26 -------------------LR------------------- 
2016-12-10 19:15:26 0.015625 
2016-12-10 19:15:26 Epoch 25 
2016-12-10 19:21:35 Training Error = 0.85026666666667 
2016-12-10 19:21:35 Training Loss = 0.037467093451606 
2016-12-10 19:21:40 Valid Error = 0.87837567513503 
2016-12-10 19:21:40 Valid Loss = 0.038575339141133 
2016-12-10 19:21:57 Test Error = 0.8691 
2016-12-10 19:21:57 Test Loss = 0.038738627534754 
2016-12-10 19:21:57 -------------------LR------------------- 
2016-12-10 19:21:57 0.015625 
2016-12-10 19:21:57 Epoch 26 
2016-12-10 19:28:27 Training Error = 0.83844444444444 
2016-12-10 19:28:27 Training Loss = 0.037268685519748 
2016-12-10 19:28:32 Valid Error = 0.86037207441488 
2016-12-10 19:28:32 Valid Loss = 0.03855559352176 
2016-12-10 19:28:48 Test Error = 0.8628 
2016-12-10 19:28:48 Test Loss = 0.038809727178835 
2016-12-10 19:28:48 -------------------LR------------------- 
2016-12-10 19:28:48 0.015625 
2016-12-10 19:28:48 Epoch 27 
2016-12-10 19:34:45 Training Error = 0.82748888888889 
2016-12-10 19:34:45 Training Loss = 0.037045396538628 
2016-12-10 19:34:50 Valid Error = 0.85657131426285 
2016-12-10 19:34:50 Valid Loss = 0.03847479387329 
2016-12-10 19:35:06 Test Error = 0.8507 
2016-12-10 19:35:06 Test Loss = 0.038492507515702 
2016-12-10 19:35:06 -------------------LR------------------- 
2016-12-10 19:35:06 0.015625 
2016-12-10 19:35:06 Epoch 28 
2016-12-10 19:41:34 Training Error = 0.81553333333333 
2016-12-10 19:41:34 Training Loss = 0.036839212510851 
2016-12-10 19:41:39 Valid Error = 0.85157031406281 
2016-12-10 19:41:39 Valid Loss = 0.038126141104236 
2016-12-10 19:41:56 Test Error = 0.8349 
2016-12-10 19:41:56 Test Loss = 0.038058493191588 
2016-12-10 19:41:56 -------------------LR------------------- 
2016-12-10 19:41:56 0.015625 
2016-12-10 19:41:56 Epoch 29 
2016-12-10 19:48:11 Training Error = 0.80193333333333 
2016-12-10 19:48:11 Training Loss = 0.036530204725477 
2016-12-10 19:48:15 Valid Error = 0.84516903380676 
2016-12-10 19:48:15 Valid Loss = 0.038362377586895 
2016-12-10 19:48:32 Test Error = 0.8341 
2016-12-10 19:48:32 Test Loss = 0.038405701431574 
2016-12-10 19:48:32 -------------------LR------------------- 
2016-12-10 19:48:32 0.015625 
2016-12-10 19:48:32 Epoch 30 
2016-12-10 19:54:56 Training Error = 0.79264444444444 
2016-12-10 19:54:56 Training Loss = 0.0362717890625 
2016-12-10 19:55:01 Valid Error = 0.83196639327866 
2016-12-10 19:55:01 Valid Loss = 0.038051173014034 
2016-12-10 19:55:17 Test Error = 0.8215 
2016-12-10 19:55:17 Test Loss = 0.038047338597915 
2016-12-10 19:55:17 -------------------LR------------------- 
2016-12-10 19:55:17 0.015625 
2016-12-10 19:55:17 Epoch 31 
2016-12-10 20:01:27 Training Error = 0.7792 
2016-12-10 20:01:27 Training Loss = 0.035991302001953 
2016-12-10 20:01:32 Valid Error = 0.79915983196639 
2016-12-10 20:01:32 Valid Loss = 0.036562228392653 
2016-12-10 20:01:48 Test Error = 0.7898 
2016-12-10 20:01:48 Test Loss = 0.03655131150788 
2016-12-10 20:01:48 -------------------LR------------------- 
2016-12-10 20:01:48 0.015625 
2016-12-10 20:01:48 Epoch 32 
2016-12-10 20:08:07 Training Error = 0.76684444444444 
2016-12-10 20:08:07 Training Loss = 0.035723210883247 
2016-12-10 20:08:11 Valid Error = 0.8003600720144 
2016-12-10 20:08:11 Valid Loss = 0.037226247105386 
2016-12-10 20:08:28 Test Error = 0.7963 
2016-12-10 20:08:28 Test Loss = 0.03714983029833 
2016-12-10 20:08:28 -------------------LR------------------- 
2016-12-10 20:08:28 0.015625 
2016-12-10 20:08:28 Epoch 33 
2016-12-10 20:14:29 Training Error = 0.75628888888889 
2016-12-10 20:14:29 Training Loss = 0.035475384982639 
2016-12-10 20:14:33 Valid Error = 0.78335667133427 
2016-12-10 20:14:33 Valid Loss = 0.036812939423055 
2016-12-10 20:14:50 Test Error = 0.7753 
2016-12-10 20:14:50 Test Loss = 0.036816558927648 
2016-12-10 20:14:50 -------------------LR------------------- 
2016-12-10 20:14:50 0.015625 
2016-12-10 20:14:50 Epoch 34 
2016-12-10 20:21:00 Training Error = 0.74435555555556 
2016-12-10 20:21:00 Training Loss = 0.035235243896484 
2016-12-10 20:21:05 Valid Error = 0.78635727145429 
2016-12-10 20:21:05 Valid Loss = 0.036958680675032 
2016-12-10 20:21:21 Test Error = 0.7807 
2016-12-10 20:21:21 Test Loss = 0.036905869487688 
2016-12-10 20:21:21 -------------------LR------------------- 
2016-12-10 20:21:21 0.015625 
2016-12-10 20:21:21 Epoch 35 
2016-12-10 20:27:35 Training Error = 0.73537777777778 
2016-12-10 20:27:35 Training Loss = 0.034994342976888 
2016-12-10 20:27:40 Valid Error = 0.750350070014 
2016-12-10 20:27:40 Valid Loss = 0.035510357539724 
2016-12-10 20:27:56 Test Error = 0.7405 
2016-12-10 20:27:56 Test Loss = 0.035344309159821 
2016-12-10 20:27:56 -------------------LR------------------- 
2016-12-10 20:27:56 0.015625 
2016-12-10 20:27:56 Epoch 36 
2016-12-10 20:34:24 Training Error = 0.72491111111111 
2016-12-10 20:34:24 Training Loss = 0.034753693657769 
2016-12-10 20:34:28 Valid Error = 0.76075215043009 
2016-12-10 20:34:28 Valid Loss = 0.036212453894973 
2016-12-10 20:34:45 Test Error = 0.7539 
2016-12-10 20:34:45 Test Loss = 0.036097033691406 
2016-12-10 20:34:45 -------------------LR------------------- 
2016-12-10 20:34:45 0.015625 
2016-12-10 20:34:45 Epoch 37 
2016-12-10 20:40:54 Training Error = 0.7146 
2016-12-10 20:40:54 Training Loss = 0.034506283243815 
2016-12-10 20:40:59 Valid Error = 0.74454890978196 
2016-12-10 20:40:59 Valid Loss = 0.03611388752293 
2016-12-10 20:41:15 Test Error = 0.7439 
2016-12-10 20:41:15 Test Loss = 0.03594461406633 
2016-12-10 20:41:15 -------------------LR------------------- 
2016-12-10 20:41:15 0.015625 
2016-12-10 20:41:15 Epoch 38 
2016-12-10 20:47:39 Training Error = 0.70044444444444 
2016-12-10 20:47:39 Training Loss = 0.034300536336263 
2016-12-10 20:47:44 Valid Error = 0.73654730946189 
2016-12-10 20:47:44 Valid Loss = 0.035608857979485 
2016-12-10 20:48:01 Test Error = 0.7299 
2016-12-10 20:48:01 Test Loss = 0.035372119409898 
2016-12-10 20:48:01 -------------------LR------------------- 
2016-12-10 20:48:01 0.015625 
2016-12-10 20:48:01 Epoch 39 
2016-12-10 20:54:10 Training Error = 0.69433333333333 
2016-12-10 20:54:10 Training Loss = 0.03410474093967 
2016-12-10 20:54:15 Valid Error = 0.749949989998 
2016-12-10 20:54:15 Valid Loss = 0.036564406958631 
2016-12-10 20:54:31 Test Error = 0.7497 
2016-12-10 20:54:31 Test Loss = 0.036402262100519 
2016-12-10 20:54:31 -------------------LR------------------- 
2016-12-10 20:54:31 0.015625 
2016-12-10 20:54:31 Epoch 40 
2016-12-10 21:00:46 Training Error = 0.68326666666667 
2016-12-10 21:00:46 Training Loss = 0.033917993665907 
2016-12-10 21:00:51 Valid Error = 0.72774554910982 
2016-12-10 21:00:51 Valid Loss = 0.035691941796962 
2016-12-10 21:01:08 Test Error = 0.725 
2016-12-10 21:01:08 Test Loss = 0.035426089298024 
2016-12-10 21:01:08 -------------------LR------------------- 
2016-12-10 21:01:08 0.015625 
2016-12-10 21:01:08 Epoch 41 
2016-12-10 21:07:44 Training Error = 0.67184444444444 
2016-12-10 21:07:44 Training Loss = 0.033634211208767 
2016-12-10 21:07:48 Valid Error = 0.70614122824565 
2016-12-10 21:07:48 Valid Loss = 0.034433962878886 
2016-12-10 21:08:05 Test Error = 0.6977 
2016-12-10 21:08:05 Test Loss = 0.034151642743279 
2016-12-10 21:08:05 -------------------LR------------------- 
2016-12-10 21:08:05 0.015625 
2016-12-10 21:08:05 Epoch 42 
2016-12-10 21:14:05 Training Error = 0.6684 
2016-12-10 21:14:05 Training Loss = 0.033533014594184 
2016-12-10 21:14:09 Valid Error = 0.6877375475095 
2016-12-10 21:14:09 Valid Loss = 0.033972880032342 
2016-12-10 21:14:26 Test Error = 0.6833 
2016-12-10 21:14:26 Test Loss = 0.033719784306545 
2016-12-10 21:14:26 -------------------LR------------------- 
2016-12-10 21:14:26 0.015625 
2016-12-10 21:14:26 Epoch 43 
2016-12-10 21:20:51 Training Error = 0.66035555555556 
2016-12-10 21:20:51 Training Loss = 0.033346166666667 
2016-12-10 21:20:56 Valid Error = 0.70794158831766 
2016-12-10 21:20:56 Valid Loss = 0.034732139796235 
2016-12-10 21:21:12 Test Error = 0.7007 
2016-12-10 21:21:12 Test Loss = 0.034437318570006 
2016-12-10 21:21:12 -------------------LR------------------- 
2016-12-10 21:21:12 0.015625 
2016-12-10 21:21:12 Epoch 44 
2016-12-10 21:27:09 Training Error = 0.65335555555556 
2016-12-10 21:27:09 Training Loss = 0.03318671339247 
2016-12-10 21:27:13 Valid Error = 0.70674134826965 
2016-12-10 21:27:13 Valid Loss = 0.034643919771431 
2016-12-10 21:27:30 Test Error = 0.6869 
2016-12-10 21:27:30 Test Loss = 0.034285899682138 
2016-12-10 21:27:30 -------------------LR------------------- 
2016-12-10 21:27:30 0.015625 
2016-12-10 21:27:30 Epoch 45 
2016-12-10 21:33:53 Training Error = 0.64673333333333 
2016-12-10 21:33:53 Training Loss = 0.032992441433377 
2016-12-10 21:33:58 Valid Error = 0.67393478695739 
2016-12-10 21:33:58 Valid Loss = 0.033282697701104 
2016-12-10 21:34:14 Test Error = 0.6647 
2016-12-10 21:34:14 Test Loss = 0.033216989644368 
2016-12-10 21:34:14 -------------------LR------------------- 
2016-12-10 21:34:14 0.015625 
2016-12-10 21:34:14 Epoch 46 
2016-12-10 21:40:29 Training Error = 0.63942222222222 
2016-12-10 21:40:29 Training Loss = 0.032864066419813 
2016-12-10 21:40:33 Valid Error = 0.67213442688538 
2016-12-10 21:40:33 Valid Loss = 0.033527339914931 
2016-12-10 21:40:50 Test Error = 0.6624 
2016-12-10 21:40:50 Test Loss = 0.033272543963264 
2016-12-10 21:40:50 -------------------LR------------------- 
2016-12-10 21:40:50 0.015625 
2016-12-10 21:40:50 Epoch 47 
2016-12-10 21:47:04 Training Error = 0.63875555555556 
2016-12-10 21:47:04 Training Loss = 0.0327289660102 
2016-12-10 21:47:09 Valid Error = 0.67693538707742 
2016-12-10 21:47:09 Valid Loss = 0.033720576835931 
2016-12-10 21:47:26 Test Error = 0.6718 
2016-12-10 21:47:26 Test Loss = 0.03363819657868 
2016-12-10 21:47:26 -------------------LR------------------- 
2016-12-10 21:47:26 0.015625 
2016-12-10 21:47:26 Epoch 48 
2016-12-10 21:53:38 Training Error = 0.62668888888889 
2016-12-10 21:53:38 Training Loss = 0.032524484605577 
2016-12-10 21:53:42 Valid Error = 0.65593118623725 
2016-12-10 21:53:42 Valid Loss = 0.032897265721223 
2016-12-10 21:53:59 Test Error = 0.6515 
2016-12-10 21:53:59 Test Loss = 0.032887221452302 
2016-12-10 21:53:59 -------------------LR------------------- 
2016-12-10 21:53:59 0.015625 
2016-12-10 21:53:59 Epoch 49 
2016-12-10 22:00:18 Training Error = 0.62357777777778 
2016-12-10 22:00:18 Training Loss = 0.03244388410102 
2016-12-10 22:00:22 Valid Error = 0.65633126625325 
2016-12-10 22:00:22 Valid Loss = 0.033344991981536 
2016-12-10 22:00:39 Test Error = 0.6579 
2016-12-10 22:00:39 Test Loss = 0.033273849577062 
2016-12-10 22:00:39 -------------------LR------------------- 
2016-12-10 22:00:39 0.015625 
2016-12-10 22:00:39 Epoch 50 
2016-12-10 22:06:38 Training Error = 0.6182 
2016-12-10 22:06:38 Training Loss = 0.032322437554253 
2016-12-10 22:06:43 Valid Error = 0.65333066613323 
2016-12-10 22:06:43 Valid Loss = 0.033035839123284 
2016-12-10 22:06:59 Test Error = 0.6486 
2016-12-10 22:06:59 Test Loss = 0.03289165428012 
2016-12-10 22:06:59 -------------------LR------------------- 
2016-12-10 22:06:59 0.0078125 
2016-12-10 22:06:59 Epoch 51 
2016-12-10 22:13:23 Training Error = 0.59704444444444 
2016-12-10 22:13:23 Training Loss = 0.031646828911675 
2016-12-10 22:13:28 Valid Error = 0.64392878575715 
2016-12-10 22:13:28 Valid Loss = 0.033055901932423 
2016-12-10 22:13:44 Test Error = 0.639 
2016-12-10 22:13:44 Test Loss = 0.032884856788785 
2016-12-10 22:13:44 -------------------LR------------------- 
2016-12-10 22:13:44 0.0078125 
2016-12-10 22:13:45 Epoch 52 
2016-12-10 22:19:46 Training Error = 0.59082222222222 
2016-12-10 22:19:46 Training Loss = 0.031418785007053 
2016-12-10 22:19:50 Valid Error = 0.63012602520504 
2016-12-10 22:19:50 Valid Loss = 0.032566998719807 
2016-12-10 22:20:07 Test Error = 0.6301 
2016-12-10 22:20:07 Test Loss = 0.032572132275151 
2016-12-10 22:20:07 -------------------LR------------------- 
2016-12-10 22:20:07 0.0078125 
2016-12-10 22:20:08 Epoch 53 
2016-12-10 22:26:38 Training Error = 0.58517777777778 
2016-12-10 22:26:38 Training Loss = 0.031318853325738 
2016-12-10 22:26:43 Valid Error = 0.62412482496499 
2016-12-10 22:26:43 Valid Loss = 0.032167075486145 
2016-12-10 22:27:00 Test Error = 0.6147 
2016-12-10 22:27:00 Test Loss = 0.031732032596364 
2016-12-10 22:27:00 -------------------LR------------------- 
2016-12-10 22:27:00 0.0078125 
2016-12-10 22:27:00 Epoch 54 
2016-12-10 22:33:15 Training Error = 0.58004444444444 
2016-12-10 22:33:15 Training Loss = 0.031277140136719 
2016-12-10 22:33:20 Valid Error = 0.63352670534107 
2016-12-10 22:33:20 Valid Loss = 0.032944118723548 
2016-12-10 22:33:36 Test Error = 0.6236 
2016-12-10 22:33:36 Test Loss = 0.032680455645393 
2016-12-10 22:33:36 -------------------LR------------------- 
2016-12-10 22:33:36 0.0078125 
2016-12-10 22:33:36 Epoch 55 
2016-12-10 22:39:53 Training Error = 0.5788 
2016-12-10 22:39:53 Training Loss = 0.031186611423069 
2016-12-10 22:39:58 Valid Error = 0.62852570514103 
2016-12-10 22:39:58 Valid Loss = 0.032640271055631 
2016-12-10 22:40:15 Test Error = 0.6205 
2016-12-10 22:40:15 Test Loss = 0.032329274794635 
2016-12-10 22:40:15 -------------------LR------------------- 
2016-12-10 22:40:15 0.0078125 
2016-12-10 22:40:15 Epoch 56 
2016-12-10 22:46:38 Training Error = 0.57671111111111 
2016-12-10 22:46:38 Training Loss = 0.031070482720269 
2016-12-10 22:46:42 Valid Error = 0.61352270454091 
2016-12-10 22:46:42 Valid Loss = 0.032246560996403 
2016-12-10 22:46:59 Test Error = 0.6141 
2016-12-10 22:46:59 Test Loss = 0.03209069148045 
2016-12-10 22:46:59 -------------------LR------------------- 
2016-12-10 22:46:59 0.0078125 
2016-12-10 22:46:59 Epoch 57 
2016-12-10 22:52:58 Training Error = 0.57397777777778 
2016-12-10 22:52:58 Training Loss = 0.031015593221029 
2016-12-10 22:53:03 Valid Error = 0.61852370474095 
2016-12-10 22:53:03 Valid Loss = 0.032440401775748 
2016-12-10 22:53:20 Test Error = 0.6148 
2016-12-10 22:53:20 Test Loss = 0.032383351254931 
2016-12-10 22:53:20 -------------------LR------------------- 
2016-12-10 22:53:20 0.0078125 
2016-12-10 22:53:20 Epoch 58 
2016-12-10 22:59:46 Training Error = 0.56835555555556 
2016-12-10 22:59:46 Training Loss = 0.030949307169596 
2016-12-10 22:59:51 Valid Error = 0.60752150430086 
2016-12-10 22:59:51 Valid Loss = 0.031964927339718 
2016-12-10 23:00:07 Test Error = 0.6085 
2016-12-10 23:00:07 Test Loss = 0.031828138403799 
2016-12-10 23:00:07 -------------------LR------------------- 
2016-12-10 23:00:07 0.0078125 
2016-12-10 23:00:07 Epoch 59 
2016-12-10 23:06:07 Training Error = 0.56551111111111 
2016-12-10 23:06:07 Training Loss = 0.030812204101563 
2016-12-10 23:06:11 Valid Error = 0.61392278455691 
2016-12-10 23:06:11 Valid Loss = 0.032265978878817 
2016-12-10 23:06:28 Test Error = 0.6071 
2016-12-10 23:06:28 Test Loss = 0.032148727746103 
2016-12-10 23:06:28 -------------------LR------------------- 
2016-12-10 23:06:28 0.0078125 
2016-12-10 23:06:28 Epoch 60 
2016-12-10 23:12:53 Training Error = 0.56248888888889 
2016-12-10 23:12:53 Training Loss = 0.030782397583008 
2016-12-10 23:12:58 Valid Error = 0.60392078415683 
2016-12-10 23:12:58 Valid Loss = 0.031661676173934 
2016-12-10 23:13:14 Test Error = 0.6072 
2016-12-10 23:13:14 Test Loss = 0.031775079315784 
2016-12-10 23:13:14 -------------------LR------------------- 
2016-12-10 23:13:14 0.0078125 
2016-12-10 23:13:14 Epoch 61 
2016-12-10 23:19:16 Training Error = 0.56057777777778 
2016-12-10 23:19:16 Training Loss = 0.030689025580512 
2016-12-10 23:19:20 Valid Error = 0.60892178435687 
2016-12-10 23:19:20 Valid Loss = 0.032089482487306 
2016-12-10 23:19:37 Test Error = 0.6055 
2016-12-10 23:19:37 Test Loss = 0.031841926604626 
2016-12-10 23:19:37 -------------------LR------------------- 
2016-12-10 23:19:37 0.0078125 
2016-12-10 23:19:37 Epoch 62 
2016-12-10 23:25:55 Training Error = 0.5588 
2016-12-10 23:25:55 Training Loss = 0.030638465033637 
2016-12-10 23:25:59 Valid Error = 0.5995199039808 
2016-12-10 23:25:59 Valid Loss = 0.031278104614655 
2016-12-10 23:26:16 Test Error = 0.5955 
2016-12-10 23:26:16 Test Loss = 0.031271505647547 
2016-12-10 23:26:16 -------------------LR------------------- 
2016-12-10 23:26:16 0.0078125 
2016-12-10 23:26:16 Epoch 63 
2016-12-10 23:32:22 Training Error = 0.55488888888889 
2016-12-10 23:32:22 Training Loss = 0.030578681694878 
2016-12-10 23:32:26 Valid Error = 0.60352070414083 
2016-12-10 23:32:26 Valid Loss = 0.031979599286188 
2016-12-10 23:32:43 Test Error = 0.5996 
2016-12-10 23:32:43 Test Loss = 0.031875262570849 
2016-12-10 23:32:43 -------------------LR------------------- 
2016-12-10 23:32:43 0.0078125 
2016-12-10 23:32:43 Epoch 64 
2016-12-10 23:38:59 Training Error = 0.54986666666667 
2016-12-10 23:38:59 Training Loss = 0.030469082261827 
2016-12-10 23:39:04 Valid Error = 0.59411882376475 
2016-12-10 23:39:04 Valid Loss = 0.031645217733433 
2016-12-10 23:39:20 Test Error = 0.5941 
2016-12-10 23:39:20 Test Loss = 0.031640388967477 
2016-12-10 23:39:20 -------------------LR------------------- 
2016-12-10 23:39:20 0.0078125 
2016-12-10 23:39:21 Epoch 65 
2016-12-10 23:45:32 Training Error = 0.54715555555556 
2016-12-10 23:45:32 Training Loss = 0.030418797770182 
2016-12-10 23:45:36 Valid Error = 0.5995199039808 
2016-12-10 23:45:36 Valid Loss = 0.031456058597142 
2016-12-10 23:45:53 Test Error = 0.5981 
2016-12-10 23:45:53 Test Loss = 0.03160873448989 
2016-12-10 23:45:53 -------------------LR------------------- 
2016-12-10 23:45:53 0.0078125 
2016-12-10 23:45:54 Epoch 66 
2016-12-10 23:52:13 Training Error = 0.54622222222222 
2016-12-10 23:52:13 Training Loss = 0.030390582614475 
2016-12-10 23:52:18 Valid Error = 0.59531906381276 
2016-12-10 23:52:18 Valid Loss = 0.031577582653714 
2016-12-10 23:52:35 Test Error = 0.5926 
2016-12-10 23:52:35 Test Loss = 0.031539910529642 
2016-12-10 23:52:35 -------------------LR------------------- 
2016-12-10 23:52:35 0.0078125 
2016-12-10 23:52:35 Epoch 67 
2016-12-10 23:58:45 Training Error = 0.54522222222222 
2016-12-10 23:58:45 Training Loss = 0.030336285956489 
2016-12-10 23:58:49 Valid Error = 0.57711542308462 
2016-12-10 23:58:49 Valid Loss = 0.030869015794304 
2016-12-10 23:59:06 Test Error = 0.5783 
2016-12-10 23:59:06 Test Loss = 0.030814894163842 
2016-12-10 23:59:06 -------------------LR------------------- 
2016-12-10 23:59:06 0.0078125 
2016-12-10 23:59:06 Epoch 68 
2016-12-11 00:05:25 Training Error = 0.54264444444444 
2016-12-11 00:05:25 Training Loss = 0.030221708129883 
2016-12-11 00:05:30 Valid Error = 0.57771554310862 
2016-12-11 00:05:30 Valid Loss = 0.031346540022897 
2016-12-11 00:05:47 Test Error = 0.5844 
2016-12-11 00:05:47 Test Loss = 0.031305983090868 
2016-12-11 00:05:47 -------------------LR------------------- 
2016-12-11 00:05:47 0.0078125 
2016-12-11 00:05:47 Epoch 69 
2016-12-11 00:12:37 Training Error = 0.54144444444444 
2016-12-11 00:12:37 Training Loss = 0.030202660210503 
2016-12-11 00:12:41 Valid Error = 0.58871774354871 
2016-12-11 00:12:41 Valid Loss = 0.031390997923061 
2016-12-11 00:12:58 Test Error = 0.5939 
2016-12-11 00:12:58 Test Loss = 0.031453494741402 
2016-12-11 00:12:58 -------------------LR------------------- 
2016-12-11 00:12:58 0.0078125 
2016-12-11 00:12:58 Epoch 70 
2016-12-11 00:20:08 Training Error = 0.53675555555556 
2016-12-11 00:20:08 Training Loss = 0.030073374620226 
2016-12-11 00:20:12 Valid Error = 0.58271654330866 
2016-12-11 00:20:12 Valid Loss = 0.031482627800846 
2016-12-11 00:20:29 Test Error = 0.5817 
2016-12-11 00:20:29 Test Loss = 0.031091455915862 
2016-12-11 00:20:29 -------------------LR------------------- 
2016-12-11 00:20:29 0.0078125 
2016-12-11 00:20:29 Epoch 71 
2016-12-11 00:27:29 Training Error = 0.53675555555556 
2016-12-11 00:27:29 Training Loss = 0.03014102194553 
2016-12-11 00:27:33 Valid Error = 0.58211642328466 
2016-12-11 00:27:33 Valid Loss = 0.031178040508797 
2016-12-11 00:27:50 Test Error = 0.5835 
2016-12-11 00:27:50 Test Loss = 0.031038988719267 
2016-12-11 00:27:50 -------------------LR------------------- 
2016-12-11 00:27:50 0.0078125 
2016-12-11 00:27:50 Epoch 72 
2016-12-11 00:34:33 Training Error = 0.53586666666667 
2016-12-11 00:34:33 Training Loss = 0.030044339816623 
2016-12-11 00:34:38 Valid Error = 0.59411882376475 
2016-12-11 00:34:38 Valid Loss = 0.031835294716031 
2016-12-11 00:34:55 Test Error = 0.5875 
2016-12-11 00:34:55 Test Loss = 0.03155002674776 
2016-12-11 00:34:55 -------------------LR------------------- 
2016-12-11 00:34:55 0.0078125 
2016-12-11 00:34:55 Epoch 73 
2016-12-11 00:41:59 Training Error = 0.53337777777778 
2016-12-11 00:41:59 Training Loss = 0.029957897935655 
2016-12-11 00:42:03 Valid Error = 0.57711542308462 
2016-12-11 00:42:03 Valid Loss = 0.030857083685267 
2016-12-11 00:42:20 Test Error = 0.5733 
2016-12-11 00:42:20 Test Loss = 0.030593914166619 
2016-12-11 00:42:20 -------------------LR------------------- 
2016-12-11 00:42:20 0.0078125 
2016-12-11 00:42:20 Epoch 74 
2016-12-11 00:48:50 Training Error = 0.5304 
2016-12-11 00:48:50 Training Loss = 0.029936269883898 
2016-12-11 00:48:54 Valid Error = 0.57271454290858 
2016-12-11 00:48:54 Valid Loss = 0.030732368687994 
2016-12-11 00:49:11 Test Error = 0.5718 
2016-12-11 00:49:11 Test Loss = 0.030565801642923 
2016-12-11 00:49:11 -------------------LR------------------- 
2016-12-11 00:49:11 0.0078125 
2016-12-11 00:49:11 Epoch 75 
2016-12-11 00:56:04 Training Error = 0.52828888888889 
2016-12-11 00:56:04 Training Loss = 0.029879279703776 
2016-12-11 00:56:09 Valid Error = 0.57191438287658 
2016-12-11 00:56:09 Valid Loss = 0.030944487201128 
2016-12-11 00:56:26 Test Error = 0.5724 
2016-12-11 00:56:26 Test Loss = 0.030995280157351 
2016-12-11 00:56:26 -------------------LR------------------- 
2016-12-11 00:56:26 0.0078125 
2016-12-11 00:56:26 Epoch 76 
2016-12-11 01:02:52 Training Error = 0.52235555555556 
2016-12-11 01:02:52 Training Loss = 0.029786280422635 
2016-12-11 01:02:57 Valid Error = 0.55191038207642 
2016-12-11 01:02:57 Valid Loss = 0.029992340647184 
2016-12-11 01:03:14 Test Error = 0.558 
2016-12-11 01:03:14 Test Loss = 0.030033322741939 
2016-12-11 01:03:14 -------------------LR------------------- 
2016-12-11 01:03:14 0.0078125 
2016-12-11 01:03:14 Epoch 77 
2016-12-11 01:10:06 Training Error = 0.52344444444444 
2016-12-11 01:10:06 Training Loss = 0.029802635253906 
2016-12-11 01:10:10 Valid Error = 0.57071414282857 
2016-12-11 01:10:10 Valid Loss = 0.030756623085436 
2016-12-11 01:10:27 Test Error = 0.5671 
2016-12-11 01:10:27 Test Loss = 0.030527208605 
2016-12-11 01:10:27 -------------------LR------------------- 
2016-12-11 01:10:27 0.0078125 
2016-12-11 01:10:27 Epoch 78 
2016-12-11 01:16:58 Training Error = 0.523 
2016-12-11 01:16:58 Training Loss = 0.029746197007921 
2016-12-11 01:17:02 Valid Error = 0.56971394278856 
2016-12-11 01:17:02 Valid Loss = 0.030540153462674 
2016-12-11 01:17:19 Test Error = 0.5693 
2016-12-11 01:17:19 Test Loss = 0.03045227616254 
2016-12-11 01:17:19 -------------------LR------------------- 
2016-12-11 01:17:19 0.0078125 
2016-12-11 01:17:20 Epoch 79 
2016-12-11 01:24:08 Training Error = 0.51908888888889 
2016-12-11 01:24:08 Training Loss = 0.029627514431424 
2016-12-11 01:24:13 Valid Error = 0.57211442288458 
2016-12-11 01:24:13 Valid Loss = 0.031421647583453 
2016-12-11 01:24:29 Test Error = 0.5724 
2016-12-11 01:24:29 Test Loss = 0.031125833937701 
2016-12-11 01:24:29 -------------------LR------------------- 
2016-12-11 01:24:29 0.0078125 
2016-12-11 01:24:30 Epoch 80 
2016-12-11 01:31:13 Training Error = 0.52148888888889 
2016-12-11 01:31:13 Training Loss = 0.029662238593207 
2016-12-11 01:31:17 Valid Error = 0.57331466293259 
2016-12-11 01:31:17 Valid Loss = 0.031091649812087 
2016-12-11 01:31:34 Test Error = 0.5715 
2016-12-11 01:31:34 Test Loss = 0.030919768628887 
2016-12-11 01:31:34 -------------------LR------------------- 
2016-12-11 01:31:34 0.0078125 
2016-12-11 01:31:34 Epoch 81 
2016-12-11 01:38:31 Training Error = 0.51648888888889 
2016-12-11 01:38:31 Training Loss = 0.029553918524848 
2016-12-11 01:38:35 Valid Error = 0.5623124624925 
2016-12-11 01:38:35 Valid Loss = 0.030588738311247 
2016-12-11 01:38:52 Test Error = 0.5672 
2016-12-11 01:38:52 Test Loss = 0.030613466838762 
2016-12-11 01:38:52 -------------------LR------------------- 
2016-12-11 01:38:52 0.0078125 
2016-12-11 01:38:53 Epoch 82 
2016-12-11 01:45:29 Training Error = 0.51262222222222 
2016-12-11 01:45:29 Training Loss = 0.029535427652995 
2016-12-11 01:45:34 Valid Error = 0.55231046209242 
2016-12-11 01:45:34 Valid Loss = 0.030280272931129 
2016-12-11 01:45:50 Test Error = 0.5563 
2016-12-11 01:45:50 Test Loss = 0.030349964934704 
2016-12-11 01:45:50 -------------------LR------------------- 
2016-12-11 01:45:50 0.0078125 
2016-12-11 01:45:50 Epoch 83 
2016-12-11 01:52:51 Training Error = 0.51335555555556 
2016-12-11 01:52:51 Training Loss = 0.029483689493815 
2016-12-11 01:52:56 Valid Error = 0.57151430286057 
2016-12-11 01:52:56 Valid Loss = 0.031731929034606 
2016-12-11 01:53:13 Test Error = 0.5782 
2016-12-11 01:53:13 Test Loss = 0.03160973851821 
2016-12-11 01:53:13 -------------------LR------------------- 
2016-12-11 01:53:13 0.0078125 
2016-12-11 01:53:13 Epoch 84 
2016-12-11 01:59:55 Training Error = 0.51182222222222 
2016-12-11 01:59:55 Training Loss = 0.02946857820638 
2016-12-11 02:00:00 Valid Error = 0.56491298259652 
2016-12-11 02:00:00 Valid Loss = 0.030542124328102 
2016-12-11 02:00:16 Test Error = 0.5655 
2016-12-11 02:00:16 Test Loss = 0.030831477475634 
2016-12-11 02:00:16 -------------------LR------------------- 
2016-12-11 02:00:16 0.0078125 
2016-12-11 02:00:16 Epoch 85 
2016-12-11 02:07:18 Training Error = 0.51248888888889 
2016-12-11 02:07:18 Training Loss = 0.02944885953776 
2016-12-11 02:07:23 Valid Error = 0.55631126225245 
2016-12-11 02:07:23 Valid Loss = 0.030488454222635 
2016-12-11 02:07:39 Test Error = 0.5601 
2016-12-11 02:07:39 Test Loss = 0.030488534456141 
2016-12-11 02:07:39 -------------------LR------------------- 
2016-12-11 02:07:39 0.0078125 
2016-12-11 02:07:39 Epoch 86 
2016-12-11 02:14:29 Training Error = 0.50686666666667 
2016-12-11 02:14:29 Training Loss = 0.029340734320747 
2016-12-11 02:14:33 Valid Error = 0.56051210242048 
2016-12-11 02:14:33 Valid Loss = 0.030658547031554 
2016-12-11 02:14:50 Test Error = 0.5571 
2016-12-11 02:14:50 Test Loss = 0.030568795896044 
2016-12-11 02:14:50 -------------------LR------------------- 
2016-12-11 02:14:50 0.0078125 
2016-12-11 02:14:50 Epoch 87 
2016-12-11 02:21:17 Training Error = 0.50557777777778 
2016-12-11 02:21:17 Training Loss = 0.029303968370226 
2016-12-11 02:21:22 Valid Error = 0.5623124624925 
2016-12-11 02:21:22 Valid Loss = 0.030753902890029 
2016-12-11 02:21:38 Test Error = 0.5547 
2016-12-11 02:21:38 Test Loss = 0.030536307061887 
2016-12-11 02:21:38 -------------------LR------------------- 
2016-12-11 02:21:38 0.0078125 
2016-12-11 02:21:38 Epoch 88 
2016-12-11 02:28:37 Training Error = 0.50497777777778 
2016-12-11 02:28:37 Training Loss = 0.029276254448785 
2016-12-11 02:28:41 Valid Error = 0.54710942188438 
2016-12-11 02:28:41 Valid Loss = 0.029715804433978 
2016-12-11 02:28:58 Test Error = 0.5481 
2016-12-11 02:28:58 Test Loss = 0.029678717190612 
2016-12-11 02:28:58 -------------------LR------------------- 
2016-12-11 02:28:58 0.0078125 
2016-12-11 02:28:58 Epoch 89 
2016-12-11 02:35:28 Training Error = 0.50586666666667 
2016-12-11 02:35:28 Training Loss = 0.029255285658095 
2016-12-11 02:35:33 Valid Error = 0.55311062212442 
2016-12-11 02:35:33 Valid Loss = 0.030038949356733 
2016-12-11 02:35:49 Test Error = 0.5529 
2016-12-11 02:35:49 Test Loss = 0.029889895899156 
2016-12-11 02:35:49 -------------------LR------------------- 
2016-12-11 02:35:49 0.0078125 
2016-12-11 02:35:49 Epoch 90 
2016-12-11 02:42:37 Training Error = 0.50031111111111 
2016-12-11 02:42:37 Training Loss = 0.029190734388563 
2016-12-11 02:42:41 Valid Error = 0.55191038207642 
2016-12-11 02:42:41 Valid Loss = 0.030104034461114 
2016-12-11 02:42:58 Test Error = 0.5548 
2016-12-11 02:42:58 Test Loss = 0.030403416293275 
2016-12-11 02:42:58 -------------------LR------------------- 
2016-12-11 02:42:58 0.0078125 
2016-12-11 02:42:58 Epoch 91 
2016-12-11 02:49:30 Training Error = 0.50173333333333 
2016-12-11 02:49:30 Training Loss = 0.029156308742947 
2016-12-11 02:49:35 Valid Error = 0.56731346269254 
2016-12-11 02:49:35 Valid Loss = 0.031280913051538 
2016-12-11 02:49:51 Test Error = 0.5702 
2016-12-11 02:49:51 Test Loss = 0.031267336108638 
2016-12-11 02:49:51 -------------------LR------------------- 
2016-12-11 02:49:51 0.0078125 
2016-12-11 02:49:51 Epoch 92 
2016-12-11 02:56:43 Training Error = 0.50342222222222 
2016-12-11 02:56:43 Training Loss = 0.029166283067491 
2016-12-11 02:56:48 Valid Error = 0.54810962192438 
2016-12-11 02:56:48 Valid Loss = 0.030058026074334 
2016-12-11 02:57:05 Test Error = 0.5489 
2016-12-11 02:57:05 Test Loss = 0.02982062701057 
2016-12-11 02:57:05 -------------------LR------------------- 
2016-12-11 02:57:05 0.0078125 
2016-12-11 02:57:05 Epoch 93 
2016-12-11 03:03:38 Training Error = 0.49866666666667 
2016-12-11 03:03:38 Training Loss = 0.029067987630208 
2016-12-11 03:03:43 Valid Error = 0.54370874174835 
2016-12-11 03:03:43 Valid Loss = 0.02997440769317 
2016-12-11 03:03:59 Test Error = 0.5416 
2016-12-11 03:03:59 Test Loss = 0.029815693574793 
2016-12-11 03:03:59 -------------------LR------------------- 
2016-12-11 03:03:59 0.0078125 
2016-12-11 03:03:59 Epoch 94 
2016-12-11 03:10:58 Training Error = 0.49817777777778 
2016-12-11 03:10:58 Training Loss = 0.02903517578125 
2016-12-11 03:11:02 Valid Error = 0.54830966193239 
2016-12-11 03:11:02 Valid Loss = 0.029864484031678 
2016-12-11 03:11:19 Test Error = 0.5489 
2016-12-11 03:11:19 Test Loss = 0.029980537354712 
2016-12-11 03:11:19 -------------------LR------------------- 
2016-12-11 03:11:19 0.0078125 
2016-12-11 03:11:19 Epoch 95 
2016-12-11 03:17:51 Training Error = 0.49537777777778 
2016-12-11 03:17:51 Training Loss = 0.029012856730143 
2016-12-11 03:17:56 Valid Error = 0.53270654130826 
2016-12-11 03:17:56 Valid Loss = 0.029506864736904 
2016-12-11 03:18:13 Test Error = 0.5418 
2016-12-11 03:18:13 Test Loss = 0.02974598125383 
2016-12-11 03:18:13 -------------------LR------------------- 
2016-12-11 03:18:13 0.0078125 
2016-12-11 03:18:13 Epoch 96 
2016-12-11 03:25:07 Training Error = 0.49593333333333 
2016-12-11 03:25:07 Training Loss = 0.028979969712999 
2016-12-11 03:25:12 Valid Error = 0.55391078215643 
2016-12-11 03:25:12 Valid Loss = 0.030116880333014 
2016-12-11 03:25:29 Test Error = 0.5522 
2016-12-11 03:25:29 Test Loss = 0.029935947133981 
2016-12-11 03:25:29 -------------------LR------------------- 
2016-12-11 03:25:29 0.0078125 
2016-12-11 03:25:29 Epoch 97 
2016-12-11 03:32:09 Training Error = 0.49613333333333 
2016-12-11 03:32:09 Training Loss = 0.028995447943793 
2016-12-11 03:32:14 Valid Error = 0.55131026205241 
2016-12-11 03:32:14 Valid Loss = 0.030426443318168 
2016-12-11 03:32:30 Test Error = 0.5567 
2016-12-11 03:32:30 Test Loss = 0.030471039775774 
2016-12-11 03:32:30 -------------------LR------------------- 
2016-12-11 03:32:30 0.0078125 
2016-12-11 03:32:30 Epoch 98 
2016-12-11 03:39:15 Training Error = 0.49073333333333 
2016-12-11 03:39:15 Training Loss = 0.028882780205621 
2016-12-11 03:39:20 Valid Error = 0.54850970194039 
2016-12-11 03:39:20 Valid Loss = 0.030211747671487 
2016-12-11 03:39:37 Test Error = 0.5471 
2016-12-11 03:39:37 Test Loss = 0.030168416490742 
2016-12-11 03:39:37 -------------------LR------------------- 
2016-12-11 03:39:37 0.0078125 
2016-12-11 03:39:37 Epoch 99 
2016-12-11 03:46:36 Training Error = 0.48711111111111 
2016-12-11 03:46:36 Training Loss = 0.028789118706597 
2016-12-11 03:46:40 Valid Error = 0.5495099019804 
2016-12-11 03:46:40 Valid Loss = 0.030311801642706 
2016-12-11 03:46:57 Test Error = 0.5566 
2016-12-11 03:46:57 Test Loss = 0.030655828857422 
2016-12-11 03:46:57 -------------------LR------------------- 
2016-12-11 03:46:57 0.0078125 
2016-12-11 03:46:57 Epoch 100 
2016-12-11 03:53:42 Training Error = 0.48895555555556 
2016-12-11 03:53:42 Training Loss = 0.028768343655056 
2016-12-11 03:53:47 Valid Error = 0.55251050210042 
2016-12-11 03:53:47 Valid Loss = 0.030745602864126 
2016-12-11 03:54:04 Test Error = 0.5521 
2016-12-11 03:54:04 Test Loss = 0.030555804233925 
2016-12-11 03:54:04 -------------------LR------------------- 
2016-12-11 03:54:04 0.00390625 
2016-12-11 03:54:04 Epoch 101 
2016-12-11 04:00:54 Training Error = 0.475 
2016-12-11 04:00:54 Training Loss = 0.028194319268121 
2016-12-11 04:00:59 Valid Error = 0.52950590118024 
2016-12-11 04:00:59 Valid Loss = 0.029604631917654 
2016-12-11 04:01:16 Test Error = 0.5343 
2016-12-11 04:01:16 Test Loss = 0.029677440149644 
2016-12-11 04:01:16 -------------------LR------------------- 
2016-12-11 04:01:16 0.00390625 
2016-12-11 04:01:16 Epoch 102 
2016-12-11 04:07:52 Training Error = 0.46913333333333 
2016-12-11 04:07:52 Training Loss = 0.02807394535319 
2016-12-11 04:07:57 Valid Error = 0.54010802160432 
2016-12-11 04:07:57 Valid Loss = 0.030367391564541 
2016-12-11 04:08:14 Test Error = 0.5363 
2016-12-11 04:08:14 Test Loss = 0.029949468994141 
2016-12-11 04:08:14 -------------------LR------------------- 
2016-12-11 04:08:14 0.00390625 
2016-12-11 04:08:14 Epoch 103 
2016-12-11 04:14:59 Training Error = 0.46608888888889 
2016-12-11 04:14:59 Training Loss = 0.027991139322917 
2016-12-11 04:15:04 Valid Error = 0.53010602120424 
2016-12-11 04:15:04 Valid Loss = 0.029797717025355 
2016-12-11 04:15:20 Test Error = 0.5277 
2016-12-11 04:15:20 Test Loss = 0.029645653159946 
2016-12-11 04:15:20 -------------------LR------------------- 
2016-12-11 04:15:20 0.00390625 
2016-12-11 04:15:21 Epoch 104 
2016-12-11 04:21:52 Training Error = 0.4638 
2016-12-11 04:21:52 Training Loss = 0.027934178900825 
2016-12-11 04:21:56 Valid Error = 0.53530706141228 
2016-12-11 04:21:56 Valid Loss = 0.029865843262176 
2016-12-11 04:22:13 Test Error = 0.5362 
2016-12-11 04:22:13 Test Loss = 0.029823687295353 
2016-12-11 04:22:13 -------------------LR------------------- 
2016-12-11 04:22:13 0.00390625 
2016-12-11 04:22:13 Epoch 105 
2016-12-11 04:29:11 Training Error = 0.46133333333333 
2016-12-11 04:29:11 Training Loss = 0.027890718017578 
2016-12-11 04:29:16 Valid Error = 0.5375075015003 
2016-12-11 04:29:16 Valid Loss = 0.030014251834675 
2016-12-11 04:29:33 Test Error = 0.5414 
2016-12-11 04:29:33 Test Loss = 0.030004213011499 
2016-12-11 04:29:33 -------------------LR------------------- 
2016-12-11 04:29:33 0.00390625 
2016-12-11 04:29:33 Epoch 106 
2016-12-11 04:36:05 Training Error = 0.45986666666667 
2016-12-11 04:36:05 Training Loss = 0.027821943291558 
2016-12-11 04:36:10 Valid Error = 0.53150630126025 
2016-12-11 04:36:10 Valid Loss = 0.029879948124147 
2016-12-11 04:36:26 Test Error = 0.5373 
2016-12-11 04:36:26 Test Loss = 0.029973808857039 
2016-12-11 04:36:26 -------------------LR------------------- 
2016-12-11 04:36:26 0.00390625 
2016-12-11 04:36:26 Epoch 107 
2016-12-11 04:43:17 Training Error = 0.45744444444444 
2016-12-11 04:43:17 Training Loss = 0.027783762722439 
2016-12-11 04:43:22 Valid Error = 0.52330466093219 
2016-12-11 04:43:22 Valid Loss = 0.029171813424795 
2016-12-11 04:43:39 Test Error = 0.5277 
2016-12-11 04:43:39 Test Loss = 0.029323312228334 
2016-12-11 04:43:39 -------------------LR------------------- 
2016-12-11 04:43:39 0.00390625 
2016-12-11 04:43:39 Epoch 108 
2016-12-11 04:50:06 Training Error = 0.45657777777778 
2016-12-11 04:50:06 Training Loss = 0.02769557571072 
2016-12-11 04:50:10 Valid Error = 0.5253050610122 
2016-12-11 04:50:10 Valid Loss = 0.029717570924547 
2016-12-11 04:50:27 Test Error = 0.5291 
2016-12-11 04:50:27 Test Loss = 0.029597406005859 
2016-12-11 04:50:27 -------------------LR------------------- 
2016-12-11 04:50:27 0.00390625 
2016-12-11 04:50:27 Epoch 109 
2016-12-11 04:57:29 Training Error = 0.45533333333333 
2016-12-11 04:57:29 Training Loss = 0.027749543809679 
2016-12-11 04:57:33 Valid Error = 0.52190438087618 
2016-12-11 04:57:33 Valid Loss = 0.029152431728669 
2016-12-11 04:57:50 Test Error = 0.5202 
2016-12-11 04:57:50 Test Loss = 0.029360992670994 
2016-12-11 04:57:50 -------------------LR------------------- 
2016-12-11 04:57:50 0.00390625 
2016-12-11 04:57:50 Epoch 110 
2016-12-11 05:04:32 Training Error = 0.45382222222222 
2016-12-11 05:04:32 Training Loss = 0.027701375339084 
2016-12-11 05:04:36 Valid Error = 0.5253050610122 
2016-12-11 05:04:36 Valid Loss = 0.029804168810024 
2016-12-11 05:04:53 Test Error = 0.5311 
2016-12-11 05:04:53 Test Loss = 0.029903564542883 
2016-12-11 05:04:53 -------------------LR------------------- 
2016-12-11 05:04:53 0.00390625 
2016-12-11 05:04:53 Epoch 111 
2016-12-11 05:11:45 Training Error = 0.45313333333333 
2016-12-11 05:11:45 Training Loss = 0.027652226291233 
2016-12-11 05:11:50 Valid Error = 0.52650530106021 
2016-12-11 05:11:50 Valid Loss = 0.030128682397896 
2016-12-11 05:12:07 Test Error = 0.5281 
2016-12-11 05:12:07 Test Loss = 0.030201846732345 
2016-12-11 05:12:07 -------------------LR------------------- 
2016-12-11 05:12:07 0.00390625 
2016-12-11 05:12:07 Epoch 112 
2016-12-11 05:18:41 Training Error = 0.45275555555556 
2016-12-11 05:18:41 Training Loss = 0.027674471394857 
2016-12-11 05:18:46 Valid Error = 0.5255051010202 
2016-12-11 05:18:46 Valid Loss = 0.029830471768982 
2016-12-11 05:19:02 Test Error = 0.5259 
2016-12-11 05:19:02 Test Loss = 0.029608860330021 
2016-12-11 05:19:02 -------------------LR------------------- 
2016-12-11 05:19:02 0.00390625 
2016-12-11 05:19:03 Epoch 113 
2016-12-11 05:25:56 Training Error = 0.45284444444444 
2016-12-11 05:25:56 Training Loss = 0.02766980738661 
2016-12-11 05:26:00 Valid Error = 0.5251050210042 
2016-12-11 05:26:00 Valid Loss = 0.029784464119507 
2016-12-11 05:26:17 Test Error = 0.5316 
2016-12-11 05:26:17 Test Loss = 0.029901167087929 
2016-12-11 05:26:17 -------------------LR------------------- 
2016-12-11 05:26:17 0.00390625 
2016-12-11 05:26:17 Epoch 114 
2016-12-11 05:33:02 Training Error = 0.44977777777778 
2016-12-11 05:33:02 Training Loss = 0.027569246351454 
2016-12-11 05:33:06 Valid Error = 0.53630726145229 
2016-12-11 05:33:06 Valid Loss = 0.030305190591101 
2016-12-11 05:33:23 Test Error = 0.5306 
2016-12-11 05:33:23 Test Loss = 0.029805288875804 
2016-12-11 05:33:23 -------------------LR------------------- 
2016-12-11 05:33:23 0.00390625 
2016-12-11 05:33:23 Epoch 115 
2016-12-11 05:40:14 Training Error = 0.45008888888889 
2016-12-11 05:40:14 Training Loss = 0.027565072482639 
2016-12-11 05:40:18 Valid Error = 0.51930386077215 
2016-12-11 05:40:18 Valid Loss = 0.029315330321496 
2016-12-11 05:40:35 Test Error = 0.5175 
2016-12-11 05:40:35 Test Loss = 0.029070915760713 
2016-12-11 05:40:35 -------------------LR------------------- 
2016-12-11 05:40:35 0.00390625 
2016-12-11 05:40:35 Epoch 116 
2016-12-11 05:47:36 Training Error = 0.44842222222222 
2016-12-11 05:47:36 Training Loss = 0.027594931043837 
2016-12-11 05:47:41 Valid Error = 0.52630526105221 
2016-12-11 05:47:41 Valid Loss = 0.029952659150628 
2016-12-11 05:47:57 Test Error = 0.5248 
2016-12-11 05:47:57 Test Loss = 0.029745248054056 
2016-12-11 05:47:57 -------------------LR------------------- 
2016-12-11 05:47:57 0.00390625 
2016-12-11 05:47:57 Epoch 117 
2016-12-11 05:54:26 Training Error = 0.44544444444444 
2016-12-11 05:54:26 Training Loss = 0.027499073825412 
2016-12-11 05:54:31 Valid Error = 0.52830566113223 
2016-12-11 05:54:31 Valid Loss = 0.030092988131624 
2016-12-11 05:54:47 Test Error = 0.5284 
2016-12-11 05:54:47 Test Loss = 0.02997158463422 
2016-12-11 05:54:47 -------------------LR------------------- 
2016-12-11 05:54:47 0.00390625 
2016-12-11 05:54:47 Epoch 118 
2016-12-11 06:01:38 Training Error = 0.44817777777778 
2016-12-11 06:01:38 Training Loss = 0.027503955593533 
2016-12-11 06:01:43 Valid Error = 0.51470294058812 
2016-12-11 06:01:43 Valid Loss = 0.029419253535529 
2016-12-11 06:02:00 Test Error = 0.5205 
2016-12-11 06:02:00 Test Loss = 0.029446330889534 
2016-12-11 06:02:00 -------------------LR------------------- 
2016-12-11 06:02:00 0.00390625 
2016-12-11 06:02:00 Epoch 119 
2016-12-11 06:08:33 Training Error = 0.44657777777778 
2016-12-11 06:08:33 Training Loss = 0.027501828097873 
2016-12-11 06:08:37 Valid Error = 0.5253050610122 
2016-12-11 06:08:37 Valid Loss = 0.030054100143819 
2016-12-11 06:08:54 Test Error = 0.5214 
2016-12-11 06:08:54 Test Loss = 0.029737816156126 
2016-12-11 06:08:54 -------------------LR------------------- 
2016-12-11 06:08:54 0.00390625 
2016-12-11 06:08:55 Epoch 120 
2016-12-11 06:15:57 Training Error = 0.44308888888889 
2016-12-11 06:15:57 Training Loss = 0.02743099609375 
2016-12-11 06:16:02 Valid Error = 0.52390478095619 
2016-12-11 06:16:02 Valid Loss = 0.02959233256389 
2016-12-11 06:16:18 Test Error = 0.5205 
2016-12-11 06:16:18 Test Loss = 0.029531833783318 
2016-12-11 06:16:18 -------------------LR------------------- 
2016-12-11 06:16:18 0.00390625 
2016-12-11 06:16:18 Epoch 121 
2016-12-11 06:22:50 Training Error = 0.44213333333333 
2016-12-11 06:22:50 Training Loss = 0.027378740410699 
2016-12-11 06:22:55 Valid Error = 0.52650530106021 
2016-12-11 06:22:55 Valid Loss = 0.030034473478351 
2016-12-11 06:23:12 Test Error = 0.5341 
2016-12-11 06:23:12 Test Loss = 0.030088947610294 
2016-12-11 06:23:12 -------------------LR------------------- 
2016-12-11 06:23:12 0.00390625 
2016-12-11 06:23:12 Epoch 122 
2016-12-11 06:29:57 Training Error = 0.4438 
2016-12-11 06:29:57 Training Loss = 0.027381484836155 
2016-12-11 06:30:02 Valid Error = 0.52050410082016 
2016-12-11 06:30:02 Valid Loss = 0.029329933077949 
2016-12-11 06:30:18 Test Error = 0.5205 
2016-12-11 06:30:18 Test Loss = 0.029549061404957 
2016-12-11 06:30:18 -------------------LR------------------- 
2016-12-11 06:30:18 0.00390625 
2016-12-11 06:30:18 Epoch 123 
2016-12-11 06:36:44 Training Error = 0.44008888888889 
2016-12-11 06:36:44 Training Loss = 0.027343754218207 
2016-12-11 06:36:49 Valid Error = 0.51970394078816 
2016-12-11 06:36:49 Valid Loss = 0.029724289716525 
2016-12-11 06:37:05 Test Error = 0.5214 
2016-12-11 06:37:05 Test Loss = 0.029578397743375 
2016-12-11 06:37:05 -------------------LR------------------- 
2016-12-11 06:37:05 0.00390625 
2016-12-11 06:37:05 Epoch 124 
2016-12-11 06:44:05 Training Error = 0.43882222222222 
2016-12-11 06:44:05 Training Loss = 0.027295627712674 
2016-12-11 06:44:10 Valid Error = 0.51890378075615 
2016-12-11 06:44:10 Valid Loss = 0.029817616432995 
2016-12-11 06:44:26 Test Error = 0.5243 
2016-12-11 06:44:26 Test Loss = 0.029838887741986 
2016-12-11 06:44:26 -------------------LR------------------- 
2016-12-11 06:44:26 0.00390625 
2016-12-11 06:44:26 Epoch 125 
2016-12-11 06:51:10 Training Error = 0.4382 
2016-12-11 06:51:10 Training Loss = 0.027294904459635 
2016-12-11 06:51:15 Valid Error = 0.51010202040408 
2016-12-11 06:51:15 Valid Loss = 0.029374656359862 
2016-12-11 06:51:32 Test Error = 0.5202 
2016-12-11 06:51:32 Test Loss = 0.029712632123162 
2016-12-11 06:51:32 -------------------LR------------------- 
2016-12-11 06:51:32 0.00390625 
2016-12-11 06:51:32 Epoch 126 
2016-12-11 06:58:20 Training Error = 0.43811111111111 
2016-12-11 06:58:20 Training Loss = 0.027316578735352 
2016-12-11 06:58:25 Valid Error = 0.52410482096419 
2016-12-11 06:58:25 Valid Loss = 0.029906024495876 
2016-12-11 06:58:42 Test Error = 0.522 
2016-12-11 06:58:42 Test Loss = 0.029711059061686 
2016-12-11 06:58:42 -------------------LR------------------- 
2016-12-11 06:58:42 0.00390625 
2016-12-11 06:58:42 Epoch 127 
2016-12-11 07:05:10 Training Error = 0.43668888888889 
2016-12-11 07:05:10 Training Loss = 0.027259694661458 
2016-12-11 07:05:14 Valid Error = 0.5129025805161 
2016-12-11 07:05:14 Valid Loss = 0.029553680200414 
2016-12-11 07:05:32 Test Error = 0.519 
2016-12-11 07:05:32 Test Loss = 0.02963118947347 
2016-12-11 07:05:32 -------------------LR------------------- 
2016-12-11 07:05:32 0.00390625 
2016-12-11 07:05:32 Epoch 128 
2016-12-11 07:12:24 Training Error = 0.43724444444444 
2016-12-11 07:12:24 Training Loss = 0.027286886366102 
2016-12-11 07:12:29 Valid Error = 0.51850370074015 
2016-12-11 07:12:29 Valid Loss = 0.029854787446948 
2016-12-11 07:12:46 Test Error = 0.5234 
2016-12-11 07:12:46 Test Loss = 0.029776062999052 
2016-12-11 07:12:46 -------------------LR------------------- 
2016-12-11 07:12:46 0.00390625 
2016-12-11 07:12:46 Epoch 129 
2016-12-11 07:19:22 Training Error = 0.43673333333333 
2016-12-11 07:19:22 Training Loss = 0.027304612128364 
2016-12-11 07:19:26 Valid Error = 0.52350470094019 
2016-12-11 07:19:26 Valid Loss = 0.029708415231339 
2016-12-11 07:19:43 Test Error = 0.5224 
2016-12-11 07:19:43 Test Loss = 0.029445398876714 
2016-12-11 07:19:43 -------------------LR------------------- 
2016-12-11 07:19:43 0.00390625 
2016-12-11 07:19:43 Epoch 130 
2016-12-11 07:26:47 Training Error = 0.43802222222222 
2016-12-11 07:26:47 Training Loss = 0.027266145534939 
2016-12-11 07:26:52 Valid Error = 0.51470294058812 
2016-12-11 07:26:52 Valid Loss = 0.029722967200937 
2016-12-11 07:27:09 Test Error = 0.5206 
2016-12-11 07:27:09 Test Loss = 0.029787706113329 
2016-12-11 07:27:09 -------------------LR------------------- 
2016-12-11 07:27:09 0.00390625 
2016-12-11 07:27:09 Epoch 131 
2016-12-11 07:33:53 Training Error = 0.43464444444444 
2016-12-11 07:33:53 Training Loss = 0.027226238023546 
2016-12-11 07:33:58 Valid Error = 0.51690338067614 
2016-12-11 07:33:58 Valid Loss = 0.029180615748564 
2016-12-11 07:34:14 Test Error = 0.5161 
2016-12-11 07:34:14 Test Loss = 0.029304988546932 
2016-12-11 07:34:14 -------------------LR------------------- 
2016-12-11 07:34:14 0.00390625 
2016-12-11 07:34:15 Epoch 132 
2016-12-11 07:40:47 Training Error = 0.43744444444444 
2016-12-11 07:40:47 Training Loss = 0.027188252305773 
2016-12-11 07:40:52 Valid Error = 0.51410282056411 
2016-12-11 07:40:52 Valid Loss = 0.029588020071973 
2016-12-11 07:41:09 Test Error = 0.5148 
2016-12-11 07:41:09 Test Loss = 0.029565213670918 
2016-12-11 07:41:09 -------------------LR------------------- 
2016-12-11 07:41:09 0.00390625 
2016-12-11 07:41:09 Epoch 133 
2016-12-11 07:48:09 Training Error = 0.43375555555556 
2016-12-11 07:48:09 Training Loss = 0.027161658691406 
2016-12-11 07:48:13 Valid Error = 0.51330266053211 
2016-12-11 07:48:13 Valid Loss = 0.029378464463479 
2016-12-11 07:48:30 Test Error = 0.515 
2016-12-11 07:48:30 Test Loss = 0.029598630359126 
2016-12-11 07:48:30 -------------------LR------------------- 
2016-12-11 07:48:30 0.00390625 
2016-12-11 07:48:30 Epoch 134 
2016-12-11 07:55:01 Training Error = 0.43313333333333 
2016-12-11 07:55:01 Training Loss = 0.027150805270725 
2016-12-11 07:55:05 Valid Error = 0.51750350070014 
2016-12-11 07:55:05 Valid Loss = 0.02973033468194 
2016-12-11 07:55:22 Test Error = 0.5213 
2016-12-11 07:55:22 Test Loss = 0.029857838559618 
2016-12-11 07:55:22 -------------------LR------------------- 
2016-12-11 07:55:22 0.00390625 
2016-12-11 07:55:22 Epoch 135 
2016-12-11 08:02:18 Training Error = 0.43593333333333 
2016-12-11 08:02:18 Training Loss = 0.027183020968967 
2016-12-11 08:02:23 Valid Error = 0.51730346069214 
2016-12-11 08:02:23 Valid Loss = 0.029844706259545 
2016-12-11 08:02:40 Test Error = 0.5237 
2016-12-11 08:02:40 Test Loss = 0.029847689579982 
2016-12-11 08:02:40 -------------------LR------------------- 
2016-12-11 08:02:40 0.00390625 
2016-12-11 08:02:40 Epoch 136 
2016-12-11 08:09:11 Training Error = 0.43271111111111 
2016-12-11 08:09:11 Training Loss = 0.027149963270399 
2016-12-11 08:09:16 Valid Error = 0.50930186037207 
2016-12-11 08:09:16 Valid Loss = 0.029626407048888 
2016-12-11 08:09:32 Test Error = 0.52 
2016-12-11 08:09:32 Test Loss = 0.029774071248372 
2016-12-11 08:09:32 -------------------LR------------------- 
2016-12-11 08:09:32 0.00390625 
2016-12-11 08:09:32 Epoch 137 
2016-12-11 08:16:19 Training Error = 0.43077777777778 
2016-12-11 08:16:19 Training Loss = 0.027016218600803 
2016-12-11 08:16:24 Valid Error = 0.51810362072414 
2016-12-11 08:16:24 Valid Loss = 0.029758763750561 
2016-12-11 08:16:41 Test Error = 0.5231 
2016-12-11 08:16:41 Test Loss = 0.029905281545602 
2016-12-11 08:16:41 -------------------LR------------------- 
2016-12-11 08:16:41 0.00390625 
2016-12-11 08:16:41 Epoch 138 
2016-12-11 08:23:14 Training Error = 0.43191111111111 
2016-12-11 08:23:14 Training Loss = 0.027047926513672 
2016-12-11 08:23:18 Valid Error = 0.51910382076415 
2016-12-11 08:23:18 Valid Loss = 0.0298803795902 
2016-12-11 08:23:35 Test Error = 0.5247 
2016-12-11 08:23:35 Test Loss = 0.029603814936619 
2016-12-11 08:23:35 -------------------LR------------------- 
2016-12-11 08:23:35 0.00390625 
2016-12-11 08:23:35 Epoch 139 
2016-12-11 08:30:19 Training Error = 0.43131111111111 
2016-12-11 08:30:19 Training Loss = 0.02704290886773 
2016-12-11 08:30:24 Valid Error = 0.51790358071614 
2016-12-11 08:30:24 Valid Loss = 0.029617868059132 
2016-12-11 08:30:41 Test Error = 0.5162 
2016-12-11 08:30:41 Test Loss = 0.029466312722599 
2016-12-11 08:30:41 -------------------LR------------------- 
2016-12-11 08:30:41 0.00390625 
2016-12-11 08:30:41 Epoch 140 
2016-12-11 08:37:20 Training Error = 0.43006666666667 
2016-12-11 08:37:20 Training Loss = 0.026976489366319 
2016-12-11 08:37:25 Valid Error = 0.51830366073215 
2016-12-11 08:37:25 Valid Loss = 0.030083160248239 
2016-12-11 08:37:42 Test Error = 0.5176 
2016-12-11 08:37:42 Test Loss = 0.029948681191837 
2016-12-11 08:37:42 -------------------LR------------------- 
2016-12-11 08:37:42 0.00390625 
2016-12-11 08:37:42 Epoch 141 
2016-12-11 08:44:37 Training Error = 0.43004444444444 
2016-12-11 08:44:37 Training Loss = 0.027071805528429 
2016-12-11 08:44:41 Valid Error = 0.52090418083617 
2016-12-11 08:44:41 Valid Loss = 0.029548673500199 
2016-12-11 08:44:58 Test Error = 0.5242 
2016-12-11 08:44:58 Test Loss = 0.029754092108035 
2016-12-11 08:44:58 -------------------LR------------------- 
2016-12-11 08:44:58 0.00390625 
2016-12-11 08:44:58 Epoch 142 
2016-12-11 08:51:31 Training Error = 0.42546666666667 
2016-12-11 08:51:31 Training Loss = 0.026973320963542 
2016-12-11 08:51:35 Valid Error = 0.50810162032406 
2016-12-11 08:51:35 Valid Loss = 0.029496284366239 
2016-12-11 08:51:52 Test Error = 0.5127 
2016-12-11 08:51:52 Test Loss = 0.029608569694968 
2016-12-11 08:51:52 -------------------LR------------------- 
2016-12-11 08:51:52 0.00390625 
2016-12-11 08:51:52 Epoch 143 
2016-12-11 08:58:39 Training Error = 0.4268 
2016-12-11 08:58:39 Training Loss = 0.026952672593859 
2016-12-11 08:58:44 Valid Error = 0.50850170034007 
2016-12-11 08:58:44 Valid Loss = 0.029317544355702 
2016-12-11 08:59:01 Test Error = 0.5123 
2016-12-11 08:59:01 Test Loss = 0.029611332134172 
2016-12-11 08:59:01 -------------------LR------------------- 
2016-12-11 08:59:01 0.00390625 
2016-12-11 08:59:01 Epoch 144 
2016-12-11 09:05:45 Training Error = 0.42626666666667 
2016-12-11 09:05:45 Training Loss = 0.026880576049805 
2016-12-11 09:05:50 Valid Error = 0.50410082016403 
2016-12-11 09:05:50 Valid Loss = 0.029052394790642 
2016-12-11 09:06:07 Test Error = 0.5055 
2016-12-11 09:06:07 Test Loss = 0.029210603601792 
2016-12-11 09:06:07 -------------------LR------------------- 
2016-12-11 09:06:07 0.00390625 
2016-12-11 09:06:07 Epoch 145 
2016-12-11 09:13:02 Training Error = 0.42715555555556 
2016-12-11 09:13:02 Training Loss = 0.026995776787652 
2016-12-11 09:13:06 Valid Error = 0.51590318063613 
2016-12-11 09:13:06 Valid Loss = 0.029907198045749 
2016-12-11 09:13:23 Test Error = 0.5242 
2016-12-11 09:13:23 Test Loss = 0.029887397646437 
2016-12-11 09:13:23 -------------------LR------------------- 
2016-12-11 09:13:23 0.00390625 
2016-12-11 09:13:23 Epoch 146 
2016-12-11 09:19:58 Training Error = 0.42611111111111 
2016-12-11 09:19:58 Training Loss = 0.026895701321072 
2016-12-11 09:20:03 Valid Error = 0.50750150030006 
2016-12-11 09:20:03 Valid Loss = 0.029101123281417 
2016-12-11 09:20:19 Test Error = 0.508 
2016-12-11 09:20:19 Test Loss = 0.029168968021168 
2016-12-11 09:20:19 -------------------LR------------------- 
2016-12-11 09:20:19 0.00390625 
2016-12-11 09:20:19 Epoch 147 
2016-12-11 09:27:02 Training Error = 0.4236 
2016-12-11 09:27:02 Training Loss = 0.026882424845378 
2016-12-11 09:27:06 Valid Error = 0.50530106021204 
2016-12-11 09:27:06 Valid Loss = 0.029236203137942 
2016-12-11 09:27:23 Test Error = 0.5107 
2016-12-11 09:27:23 Test Loss = 0.029221033163632 
2016-12-11 09:27:23 -------------------LR------------------- 
2016-12-11 09:27:23 0.00390625 
2016-12-11 09:27:23 Epoch 148 
2016-12-11 09:34:18 Training Error = 0.42204444444444 
2016-12-11 09:34:18 Training Loss = 0.026899531670464 
2016-12-11 09:34:22 Valid Error = 0.51510302060412 
2016-12-11 09:34:22 Valid Loss = 0.029970451902396 
2016-12-11 09:34:39 Test Error = 0.519 
2016-12-11 09:34:39 Test Loss = 0.029991996376187 
2016-12-11 09:34:39 -------------------LR------------------- 
2016-12-11 09:34:39 0.00390625 
2016-12-11 09:34:39 Epoch 149 
2016-12-11 09:41:09 Training Error = 0.42364444444444 
2016-12-11 09:41:09 Training Loss = 0.026916946085612 
2016-12-11 09:41:13 Valid Error = 0.51650330066013 
2016-12-11 09:41:13 Valid Loss = 0.029466682495274 
2016-12-11 09:41:30 Test Error = 0.5195 
2016-12-11 09:41:30 Test Loss = 0.029670828127394 
2016-12-11 09:41:30 -------------------LR------------------- 
2016-12-11 09:41:30 0.00390625 
2016-12-11 09:41:30 Epoch 150 
2016-12-11 09:48:38 Training Error = 0.42382222222222 
2016-12-11 09:48:38 Training Loss = 0.026871914238824 
2016-12-11 09:48:42 Valid Error = 0.52390478095619 
2016-12-11 09:48:42 Valid Loss = 0.029898857754925 
2016-12-11 09:48:59 Test Error = 0.5173 
2016-12-11 09:48:59 Test Loss = 0.02946560196222 
2016-12-11 09:48:59 -------------------LR------------------- 
2016-12-11 09:48:59 0.001953125 
2016-12-11 09:48:59 Epoch 151 
2016-12-11 09:55:32 Training Error = 0.40911111111111 
2016-12-11 09:55:32 Training Loss = 0.026317430080838 
2016-12-11 09:55:37 Valid Error = 0.50470094018804 
2016-12-11 09:55:37 Valid Loss = 0.029110110147378 
2016-12-11 09:55:54 Test Error = 0.5089 
2016-12-11 09:55:54 Test Loss = 0.029102558390299 
2016-12-11 09:55:54 -------------------LR------------------- 
2016-12-11 09:55:54 0.001953125 
2016-12-11 09:55:54 Epoch 152 
2016-12-11 10:02:50 Training Error = 0.4086 
2016-12-11 10:02:50 Training Loss = 0.02620637757704 
2016-12-11 10:02:55 Valid Error = 0.51110222044409 
2016-12-11 10:02:55 Valid Loss = 0.029352131079556 
2016-12-11 10:03:11 Test Error = 0.5136 
2016-12-11 10:03:11 Test Loss = 0.029569697361366 
2016-12-11 10:03:11 -------------------LR------------------- 
2016-12-11 10:03:11 0.001953125 
2016-12-11 10:03:11 Epoch 153 
2016-12-11 10:09:36 Training Error = 0.40426666666667 
2016-12-11 10:09:36 Training Loss = 0.026147866644965 
2016-12-11 10:09:40 Valid Error = 0.50490098019604 
2016-12-11 10:09:40 Valid Loss = 0.029180329342191 
2016-12-11 10:09:57 Test Error = 0.5168 
2016-12-11 10:09:57 Test Loss = 0.029695937033261 
2016-12-11 10:09:57 -------------------LR------------------- 
2016-12-11 10:09:57 0.001953125 
2016-12-11 10:09:57 Epoch 154 
2016-12-11 10:16:52 Training Error = 0.404 
2016-12-11 10:16:52 Training Loss = 0.026143783447266 
2016-12-11 10:16:57 Valid Error = 0.50090018003601 
2016-12-11 10:16:57 Valid Loss = 0.028905489074003 
2016-12-11 10:17:14 Test Error = 0.5069 
2016-12-11 10:17:14 Test Loss = 0.029048667817957 
2016-12-11 10:17:14 -------------------LR------------------- 
2016-12-11 10:17:14 0.001953125 
2016-12-11 10:17:14 Epoch 155 
2016-12-11 10:23:57 Training Error = 0.40208888888889 
2016-12-11 10:23:57 Training Loss = 0.026125563395182 
2016-12-11 10:24:01 Valid Error = 0.50870174034807 
2016-12-11 10:24:01 Valid Loss = 0.029593514082793 
2016-12-11 10:24:18 Test Error = 0.5021 
2016-12-11 10:24:18 Test Loss = 0.029579938342525 
2016-12-11 10:24:18 -------------------LR------------------- 
2016-12-11 10:24:18 0.001953125 
2016-12-11 10:24:18 Epoch 156 
2016-12-11 10:31:04 Training Error = 0.4022 
2016-12-11 10:31:04 Training Loss = 0.026082603868273 
2016-12-11 10:31:08 Valid Error = 0.50070014002801 
2016-12-11 10:31:08 Valid Loss = 0.029394977095308 
2016-12-11 10:31:25 Test Error = 0.5028 
2016-12-11 10:31:25 Test Loss = 0.029238989676681 
2016-12-11 10:31:25 -------------------LR------------------- 
2016-12-11 10:31:25 0.001953125 
2016-12-11 10:31:25 Epoch 157 
2016-12-11 10:37:52 Training Error = 0.3992 
2016-12-11 10:37:52 Training Loss = 0.026036121975369 
2016-12-11 10:37:57 Valid Error = 0.50770154030806 
2016-12-11 10:37:57 Valid Loss = 0.029735417708877 
2016-12-11 10:38:14 Test Error = 0.5086 
2016-12-11 10:38:14 Test Loss = 0.029801274617513 
2016-12-11 10:38:14 -------------------LR------------------- 
2016-12-11 10:38:14 0.001953125 
2016-12-11 10:38:14 Epoch 158 
2016-12-11 10:45:10 Training Error = 0.40193333333333 
2016-12-11 10:45:10 Training Loss = 0.02606589960395 
2016-12-11 10:45:15 Valid Error = 0.49809961992398 
2016-12-11 10:45:15 Valid Loss = 0.029372496607193 
2016-12-11 10:45:32 Test Error = 0.5023 
2016-12-11 10:45:32 Test Loss = 0.029401877668792 
2016-12-11 10:45:32 -------------------LR------------------- 
2016-12-11 10:45:32 0.001953125 
2016-12-11 10:45:32 Epoch 159 
2016-12-11 10:52:07 Training Error = 0.39737777777778 
2016-12-11 10:52:07 Training Loss = 0.025949956054688 
2016-12-11 10:52:12 Valid Error = 0.49929985997199 
2016-12-11 10:52:12 Valid Loss = 0.029095998686346 
2016-12-11 10:52:28 Test Error = 0.5 
2016-12-11 10:52:28 Test Loss = 0.029231684217266 
2016-12-11 10:52:28 -------------------LR------------------- 
2016-12-11 10:52:28 0.001953125 
2016-12-11 10:52:28 Epoch 160 
2016-12-11 10:59:23 Training Error = 0.39764444444444 
2016-12-11 10:59:23 Training Loss = 0.026029648084852 
2016-12-11 10:59:28 Valid Error = 0.50510102020404 
2016-12-11 10:59:28 Valid Loss = 0.029431953616457 
2016-12-11 10:59:44 Test Error = 0.4999 
2016-12-11 10:59:44 Test Loss = 0.029125266460344 
2016-12-11 10:59:44 -------------------LR------------------- 
2016-12-11 10:59:44 0.001953125 
2016-12-11 10:59:44 Epoch 161 
2016-12-11 11:06:33 Training Error = 0.39666666666667 
2016-12-11 11:06:33 Training Loss = 0.02595353757053 
2016-12-11 11:06:37 Valid Error = 0.49289857971594 
2016-12-11 11:06:37 Valid Loss = 0.029082313150152 
2016-12-11 11:06:54 Test Error = 0.497 
2016-12-11 11:06:54 Test Loss = 0.029039716324152 
2016-12-11 11:06:54 -------------------LR------------------- 
2016-12-11 11:06:54 0.001953125 
2016-12-11 11:06:54 Epoch 162 
2016-12-11 11:13:29 Training Error = 0.39442222222222 
2016-12-11 11:13:29 Training Loss = 0.025924976169162 
2016-12-11 11:13:33 Valid Error = 0.49209841968394 
2016-12-11 11:13:33 Valid Loss = 0.028872336402688 
2016-12-11 11:13:50 Test Error = 0.4977 
2016-12-11 11:13:50 Test Loss = 0.028981885723039 
2016-12-11 11:13:50 -------------------LR------------------- 
2016-12-11 11:13:50 0.001953125 
2016-12-11 11:13:50 Epoch 163 
2016-12-11 11:20:41 Training Error = 0.39451111111111 
2016-12-11 11:20:41 Training Loss = 0.025914417399089 
2016-12-11 11:20:46 Valid Error = 0.49589917983597 
2016-12-11 11:20:46 Valid Loss = 0.029158553868165 
2016-12-11 11:21:03 Test Error = 0.5023 
2016-12-11 11:21:03 Test Loss = 0.029368131719851 
2016-12-11 11:21:03 -------------------LR------------------- 
2016-12-11 11:21:03 0.001953125 
2016-12-11 11:21:03 Epoch 164 
2016-12-11 11:27:27 Training Error = 0.39513333333333 
2016-12-11 11:27:27 Training Loss = 0.026027433566623 
2016-12-11 11:27:32 Valid Error = 0.49589917983597 
2016-12-11 11:27:32 Valid Loss = 0.029145795028947 
2016-12-11 11:27:49 Test Error = 0.5055 
2016-12-11 11:27:49 Test Loss = 0.029318135250316 
2016-12-11 11:27:49 -------------------LR------------------- 
2016-12-11 11:27:49 0.001953125 
2016-12-11 11:27:49 Epoch 165 
2016-12-11 11:34:43 Training Error = 0.3946 
2016-12-11 11:34:43 Training Loss = 0.025924061279297 
2016-12-11 11:34:48 Valid Error = 0.499699939988 
2016-12-11 11:34:48 Valid Loss = 0.029404838184489 
2016-12-11 11:35:04 Test Error = 0.5024 
2016-12-11 11:35:04 Test Loss = 0.029466412742465 
2016-12-11 11:35:04 -------------------LR------------------- 
2016-12-11 11:35:04 0.001953125 
2016-12-11 11:35:04 Epoch 166 
2016-12-11 11:41:50 Training Error = 0.39548888888889 
2016-12-11 11:41:50 Training Loss = 0.025903711439345 
2016-12-11 11:41:54 Valid Error = 0.49709941988398 
2016-12-11 11:41:54 Valid Loss = 0.02893398344104 
2016-12-11 11:42:11 Test Error = 0.5047 
2016-12-11 11:42:11 Test Loss = 0.029287635055243 
2016-12-11 11:42:11 -------------------LR------------------- 
2016-12-11 11:42:11 0.001953125 
2016-12-11 11:42:11 Epoch 167 
2016-12-11 11:48:59 Training Error = 0.3926 
2016-12-11 11:48:59 Training Loss = 0.02589420300293 
2016-12-11 11:49:03 Valid Error = 0.50530106021204 
2016-12-11 11:49:03 Valid Loss = 0.029981649433572 
2016-12-11 11:49:20 Test Error = 0.5054 
2016-12-11 11:49:20 Test Loss = 0.029793630203546 
2016-12-11 11:49:20 -------------------LR------------------- 
2016-12-11 11:49:20 0.001953125 
2016-12-11 11:49:20 Epoch 168 
2016-12-11 11:55:48 Training Error = 0.3944 
2016-12-11 11:55:48 Training Loss = 0.025892624511719 
2016-12-11 11:55:53 Valid Error = 0.49469893978796 
2016-12-11 11:55:53 Valid Loss = 0.029119895536487 
2016-12-11 11:56:10 Test Error = 0.5005 
2016-12-11 11:56:10 Test Loss = 0.029133410195743 
2016-12-11 11:56:10 -------------------LR------------------- 
2016-12-11 11:56:10 0.001953125 
2016-12-11 11:56:10 Epoch 169 
2016-12-11 12:02:59 Training Error = 0.39433333333333 
2016-12-11 12:02:59 Training Loss = 0.025919228597005 
2016-12-11 12:03:04 Valid Error = 0.49909981996399 
2016-12-11 12:03:04 Valid Loss = 0.029071312403681 
2016-12-11 12:03:21 Test Error = 0.4982 
2016-12-11 12:03:21 Test Loss = 0.029104318446739 
2016-12-11 12:03:21 -------------------LR------------------- 
2016-12-11 12:03:21 0.001953125 
2016-12-11 12:03:21 Epoch 170 
2016-12-11 12:09:52 Training Error = 0.39137777777778 
2016-12-11 12:09:52 Training Loss = 0.025840813110352 
2016-12-11 12:09:57 Valid Error = 0.50450090018004 
2016-12-11 12:09:57 Valid Loss = 0.029807191595832 
2016-12-11 12:10:13 Test Error = 0.5071 
2016-12-11 12:10:13 Test Loss = 0.029812320484835 
2016-12-11 12:10:13 -------------------LR------------------- 
2016-12-11 12:10:13 0.001953125 
2016-12-11 12:10:13 Epoch 171 
2016-12-11 12:17:06 Training Error = 0.39353333333333 
2016-12-11 12:17:06 Training Loss = 0.025876877292209 
2016-12-11 12:17:11 Valid Error = 0.49909981996399 
2016-12-11 12:17:11 Valid Loss = 0.029348361905773 
2016-12-11 12:17:28 Test Error = 0.4969 
2016-12-11 12:17:28 Test Loss = 0.0292981129665 
2016-12-11 12:17:28 -------------------LR------------------- 
2016-12-11 12:17:28 0.001953125 
2016-12-11 12:17:28 Epoch 172 
2016-12-11 12:23:57 Training Error = 0.39253333333333 
2016-12-11 12:23:57 Training Loss = 0.025887561265734 
2016-12-11 12:24:02 Valid Error = 0.49769953990798 
2016-12-11 12:24:02 Valid Loss = 0.028973615774496 
2016-12-11 12:24:18 Test Error = 0.4921 
2016-12-11 12:24:18 Test Loss = 0.028832377056047 
2016-12-11 12:24:18 -------------------LR------------------- 
2016-12-11 12:24:18 0.001953125 
2016-12-11 12:24:18 Epoch 173 
2016-12-11 12:31:12 Training Error = 0.3932 
2016-12-11 12:31:12 Training Loss = 0.025830364067925 
2016-12-11 12:31:17 Valid Error = 0.500100020004 
2016-12-11 12:31:17 Valid Loss = 0.029120437197188 
2016-12-11 12:31:33 Test Error = 0.5014 
2016-12-11 12:31:33 Test Loss = 0.029159649628284 
2016-12-11 12:31:33 -------------------LR------------------- 
2016-12-11 12:31:33 0.001953125 
2016-12-11 12:31:33 Epoch 174 
2016-12-11 12:38:02 Training Error = 0.38955555555556 
2016-12-11 12:38:02 Training Loss = 0.025785262315538 
2016-12-11 12:38:06 Valid Error = 0.48629725945189 
2016-12-11 12:38:06 Valid Loss = 0.028582491731958 
2016-12-11 12:38:23 Test Error = 0.4973 
2016-12-11 12:38:23 Test Loss = 0.02893438056497 
2016-12-11 12:38:23 -------------------LR------------------- 
2016-12-11 12:38:23 0.001953125 
2016-12-11 12:38:23 Epoch 175 
2016-12-11 12:45:23 Training Error = 0.39046666666667 
2016-12-11 12:45:23 Training Loss = 0.025887745659722 
2016-12-11 12:45:28 Valid Error = 0.48889777955591 
2016-12-11 12:45:28 Valid Loss = 0.028870250417822 
2016-12-11 12:45:44 Test Error = 0.4952 
2016-12-11 12:45:44 Test Loss = 0.029144431798598 
2016-12-11 12:45:44 -------------------LR------------------- 
2016-12-11 12:45:44 0.001953125 
2016-12-11 12:45:44 Epoch 176 
2016-12-11 12:52:29 Training Error = 0.39 
2016-12-11 12:52:29 Training Loss = 0.025797721869575 
2016-12-11 12:52:33 Valid Error = 0.49749949989998 
2016-12-11 12:52:33 Valid Loss = 0.029669722002153 
2016-12-11 12:52:50 Test Error = 0.4983 
2016-12-11 12:52:50 Test Loss = 0.029390235960717 
2016-12-11 12:52:50 -------------------LR------------------- 
2016-12-11 12:52:50 0.001953125 
2016-12-11 12:52:50 Epoch 177 
2016-12-11 12:59:41 Training Error = 0.39255555555556 
2016-12-11 12:59:41 Training Loss = 0.025833615437826 
2016-12-11 12:59:46 Valid Error = 0.49649929985997 
2016-12-11 12:59:46 Valid Loss = 0.029119312581885 
2016-12-11 13:00:02 Test Error = 0.4999 
2016-12-11 13:00:02 Test Loss = 0.029184471848432 
2016-12-11 13:00:02 -------------------LR------------------- 
2016-12-11 13:00:02 0.001953125 
2016-12-11 13:00:03 Epoch 178 
2016-12-11 13:07:03 Training Error = 0.38751111111111 
2016-12-11 13:07:03 Training Loss = 0.025788503634983 
2016-12-11 13:07:07 Valid Error = 0.50390078015603 
2016-12-11 13:07:07 Valid Loss = 0.029619517959262 
2016-12-11 13:07:24 Test Error = 0.5039 
2016-12-11 13:07:24 Test Loss = 0.029276167716232 
2016-12-11 13:07:24 -------------------LR------------------- 
2016-12-11 13:07:24 0.001953125 
2016-12-11 13:07:24 Epoch 179 
2016-12-11 13:13:55 Training Error = 0.38964444444444 
2016-12-11 13:13:55 Training Loss = 0.025810983832465 
2016-12-11 13:14:00 Valid Error = 0.49369873974795 
2016-12-11 13:14:00 Valid Loss = 0.029109545606763 
2016-12-11 13:14:16 Test Error = 0.4961 
2016-12-11 13:14:16 Test Loss = 0.029123480104933 
2016-12-11 13:14:16 -------------------LR------------------- 
2016-12-11 13:14:16 0.001953125 
2016-12-11 13:14:16 Epoch 180 
2016-12-11 13:20:28 Training Error = 0.38917777777778 
2016-12-11 13:20:28 Training Loss = 0.025795731621636 
2016-12-11 13:20:33 Valid Error = 0.49209841968394 
2016-12-11 13:20:33 Valid Loss = 0.02895026833939 
2016-12-11 13:20:49 Test Error = 0.4949 
2016-12-11 13:20:49 Test Loss = 0.029117742052265 
2016-12-11 13:20:49 -------------------LR------------------- 
2016-12-11 13:20:49 0.001953125 
2016-12-11 13:20:50 Epoch 181 
2016-12-11 13:28:13 Training Error = 0.38813333333333 
2016-12-11 13:28:13 Training Loss = 0.025747183336046 
2016-12-11 13:28:18 Valid Error = 0.49369873974795 
2016-12-11 13:28:18 Valid Loss = 0.028698802676545 
2016-12-11 13:28:35 Test Error = 0.4982 
2016-12-11 13:28:35 Test Loss = 0.028843380587709 
2016-12-11 13:28:35 -------------------LR------------------- 
2016-12-11 13:28:35 0.001953125 
2016-12-11 13:28:35 Epoch 182 
2016-12-11 13:36:07 Training Error = 0.39002222222222 
2016-12-11 13:36:07 Training Loss = 0.025769117445204 
2016-12-11 13:36:11 Valid Error = 0.48869773954791 
2016-12-11 13:36:11 Valid Loss = 0.029002422040262 
2016-12-11 13:36:28 Test Error = 0.4989 
2016-12-11 13:36:28 Test Loss = 0.029357103893804 
2016-12-11 13:36:28 -------------------LR------------------- 
2016-12-11 13:36:28 0.001953125 
2016-12-11 13:36:28 Epoch 183 
2016-12-11 13:43:39 Training Error = 0.38855555555556 
2016-12-11 13:43:39 Training Loss = 0.025759623304579 
2016-12-11 13:43:44 Valid Error = 0.49689937987598 
2016-12-11 13:43:44 Valid Loss = 0.029309673079971 
2016-12-11 13:44:01 Test Error = 0.5013 
2016-12-11 13:44:01 Test Loss = 0.029545391127642 
2016-12-11 13:44:01 -------------------LR------------------- 
2016-12-11 13:44:01 0.001953125 
2016-12-11 13:44:02 Epoch 184 
