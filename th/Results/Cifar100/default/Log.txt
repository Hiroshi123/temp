2016-12-07 05:06:52 [program started on Wed Dec  7 05:06:52 2016] 
2016-12-07 05:06:52 [command line arguments] 
2016-12-07 05:06:52 stcWeights false 
2016-12-07 05:06:52 modelsFolder ./Models/ 
2016-12-07 05:06:52 chartFileName chart1 
2016-12-07 05:06:52 LR 0.015625 
2016-12-07 05:06:52 preProcDir /dev/shm/temp/th/PreProcData/Cifar100 
2016-12-07 05:06:52 devid 6 
2016-12-07 05:06:52 LRDecay 0 
2016-12-07 05:06:52 batchSize 1000 
2016-12-07 05:06:52 whiten true 
2016-12-07 05:06:52 dp_prepro false 
2016-12-07 05:06:52 network ./Models/Cifar10_Default 
2016-12-07 05:06:52 stcNeurons true 
2016-12-07 05:06:52 constBatchSize false 
2016-12-07 05:06:52 type cuda 
2016-12-07 05:06:52 save /dev/shm/temp/th/Results/Cifar100/default 
2016-12-07 05:06:52 augment false 
2016-12-07 05:06:52 epoch -1 
2016-12-07 05:06:52 title model1 
2016-12-07 05:06:52 nGPU 3 
2016-12-07 05:06:52 format rgb 
2016-12-07 05:06:52 SBN true 
2016-12-07 05:06:52 dataset Cifar100 
2016-12-07 05:06:52 normalization simple 
2016-12-07 05:06:52 momentum 0 
2016-12-07 05:06:52 visualize 1 
2016-12-07 05:06:52 LRDecayPerEpoch 0.0001 
2016-12-07 05:06:52 threads 8 
2016-12-07 05:06:52 optimization adam 
2016-12-07 05:06:52 load  
2016-12-07 05:06:52 weightDecay 0 
2016-12-07 05:06:52 runningVal false 
2016-12-07 05:06:52 imageFileExtension svg 
2016-12-07 05:06:52 [----------------------] 
2016-12-07 05:06:56 ==> Network 
2016-12-07 05:06:56 DataParallelTable: 3 x nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 100)
  (38): nn.BatchNormalization
} 
2016-12-07 05:06:56 ==>14125996 Parameters 
2016-12-07 05:06:56 ==> Loss 
2016-12-07 05:06:56 SqrtHingeEmbeddingCriterion 
2016-12-07 05:06:56 
==> Starting Training
 
2016-12-07 05:06:56 Epoch 1 
2016-12-07 05:09:53 Training Error = 0.95133333333333 
2016-12-07 05:09:53 Training Loss = 0.61505191059028 
2016-12-07 05:09:57 Valid Error = 0.94138827765553 
2016-12-07 05:09:57 Valid Loss = 0.248398531903 
2016-12-07 05:10:05 Test Error = 0.9402 
2016-12-07 05:10:05 Test Loss = 0.24852318945312 
2016-12-07 05:10:05 -------------------LR------------------- 
2016-12-07 05:10:05 0.015625 
2016-12-07 05:10:05 Epoch 2 
2016-12-07 05:13:03 Training Error = 0.92197777777778 
2016-12-07 05:13:03 Training Loss = 0.10427617100694 
2016-12-07 05:13:07 Valid Error = 0.93238647729546 
2016-12-07 05:13:07 Valid Loss = 0.064051408418184 
2016-12-07 05:13:15 Test Error = 0.9337 
2016-12-07 05:13:15 Test Loss = 0.064161846679687 
2016-12-07 05:13:15 -------------------LR------------------- 
2016-12-07 05:13:15 0.015625 
2016-12-07 05:13:15 Epoch 3 
2016-12-07 05:16:12 Training Error = 0.91113333333333 
2016-12-07 05:16:12 Training Loss = 0.045057611545139 
2016-12-07 05:16:16 Valid Error = 0.92018403680736 
2016-12-07 05:16:16 Valid Loss = 0.043989720172321 
2016-12-07 05:16:24 Test Error = 0.9241 
2016-12-07 05:16:24 Test Loss = 0.044126552246094 
2016-12-07 05:16:24 -------------------LR------------------- 
2016-12-07 05:16:24 0.015625 
2016-12-07 05:16:24 Epoch 4 
2016-12-07 05:19:24 Training Error = 0.88733333333333 
2016-12-07 05:19:24 Training Loss = 0.039369035427517 
2016-12-07 05:19:28 Valid Error = 0.89777955591118 
2016-12-07 05:19:28 Valid Loss = 0.041052737678108 
2016-12-07 05:19:36 Test Error = 0.9036 
2016-12-07 05:19:36 Test Loss = 0.041235417480469 
2016-12-07 05:19:36 -------------------LR------------------- 
2016-12-07 05:19:36 0.015625 
2016-12-07 05:19:36 Epoch 5 
2016-12-07 05:22:35 Training Error = 0.87026666666667 
2016-12-07 05:22:35 Training Loss = 0.038538682562934 
2016-12-07 05:22:39 Valid Error = 0.8875775155031 
2016-12-07 05:22:39 Valid Loss = 0.040662103229206 
2016-12-07 05:22:47 Test Error = 0.8929 
2016-12-07 05:22:47 Test Loss = 0.040778143798828 
2016-12-07 05:22:47 -------------------LR------------------- 
2016-12-07 05:22:47 0.015625 
2016-12-07 05:22:47 Epoch 6 
2016-12-07 05:25:45 Training Error = 0.85328888888889 
2016-12-07 05:25:45 Training Loss = 0.038134874674479 
2016-12-07 05:25:49 Valid Error = 0.87657531506301 
2016-12-07 05:25:49 Valid Loss = 0.039884614437191 
2016-12-07 05:25:57 Test Error = 0.8787 
2016-12-07 05:25:57 Test Loss = 0.040022882568359 
2016-12-07 05:25:57 -------------------LR------------------- 
2016-12-07 05:25:57 0.015625 
2016-12-07 05:25:57 Epoch 7 
2016-12-07 05:28:58 Training Error = 0.84006666666667 
2016-12-07 05:28:58 Training Loss = 0.037827655978733 
2016-12-07 05:29:02 Valid Error = 0.85717143428686 
2016-12-07 05:29:02 Valid Loss = 0.039212356810424 
2016-12-07 05:29:10 Test Error = 0.8622 
2016-12-07 05:29:10 Test Loss = 0.039314407714844 
2016-12-07 05:29:10 -------------------LR------------------- 
2016-12-07 05:29:10 0.015625 
2016-12-07 05:29:10 Epoch 8 
2016-12-07 05:32:04 Training Error = 0.82195555555556 
2016-12-07 05:32:04 Training Loss = 0.037549356391059 
2016-12-07 05:32:08 Valid Error = 0.84616923384677 
2016-12-07 05:32:08 Valid Loss = 0.038663159571192 
2016-12-07 05:32:16 Test Error = 0.8511 
2016-12-07 05:32:16 Test Loss = 0.038757477050781 
2016-12-07 05:32:16 -------------------LR------------------- 
2016-12-07 05:32:16 0.015625 
2016-12-07 05:32:16 Epoch 9 
2016-12-07 05:35:09 Training Error = 0.80784444444444 
2016-12-07 05:35:09 Training Loss = 0.037297546061198 
2016-12-07 05:35:13 Valid Error = 0.82996599319864 
2016-12-07 05:35:13 Valid Loss = 0.038016784708537 
2016-12-07 05:35:21 Test Error = 0.8333 
2016-12-07 05:35:21 Test Loss = 0.038135010742188 
2016-12-07 05:35:21 -------------------LR------------------- 
2016-12-07 05:35:21 0.015625 
2016-12-07 05:35:22 Epoch 10 
2016-12-07 05:38:40 Training Error = 0.79344444444444 
2016-12-07 05:38:40 Training Loss = 0.037058475965712 
2016-12-07 05:38:44 Valid Error = 0.81476295259052 
2016-12-07 05:38:44 Valid Loss = 0.037638968604835 
2016-12-07 05:38:52 Test Error = 0.8196 
2016-12-07 05:38:52 Test Loss = 0.037752516601562 
2016-12-07 05:38:52 -------------------LR------------------- 
2016-12-07 05:38:52 0.015625 
2016-12-07 05:38:52 Epoch 11 
2016-12-07 05:42:05 Training Error = 0.78286666666667 
2016-12-07 05:42:05 Training Loss = 0.036845667751736 
2016-12-07 05:42:09 Valid Error = 0.80716143228646 
2016-12-07 05:42:09 Valid Loss = 0.037396372010683 
2016-12-07 05:42:17 Test Error = 0.8112 
2016-12-07 05:42:17 Test Loss = 0.037524010253906 
2016-12-07 05:42:17 -------------------LR------------------- 
2016-12-07 05:42:17 0.015625 
2016-12-07 05:42:17 Epoch 12 
2016-12-07 05:45:27 Training Error = 0.77 
2016-12-07 05:45:27 Training Loss = 0.036617752007378 
2016-12-07 05:45:31 Valid Error = 0.78835767153431 
2016-12-07 05:45:31 Valid Loss = 0.036790076770618 
2016-12-07 05:45:39 Test Error = 0.7899 
2016-12-07 05:45:39 Test Loss = 0.0369388359375 
2016-12-07 05:45:39 -------------------LR------------------- 
2016-12-07 05:45:39 0.015625 
2016-12-07 05:45:39 Epoch 13 
2016-12-07 05:48:54 Training Error = 0.76042222222222 
2016-12-07 05:48:54 Training Loss = 0.036415957899306 
2016-12-07 05:48:58 Valid Error = 0.78035607121424 
2016-12-07 05:48:58 Valid Loss = 0.036585389133274 
2016-12-07 05:49:06 Test Error = 0.7821 
2016-12-07 05:49:06 Test Loss = 0.036728683105469 
2016-12-07 05:49:06 -------------------LR------------------- 
2016-12-07 05:49:06 0.015625 
2016-12-07 05:49:06 Epoch 14 
2016-12-07 05:52:20 Training Error = 0.75188888888889 
2016-12-07 05:52:20 Training Loss = 0.036205354492188 
2016-12-07 05:52:24 Valid Error = 0.77195439087818 
2016-12-07 05:52:24 Valid Loss = 0.03624495999955 
2016-12-07 05:52:32 Test Error = 0.7663 
2016-12-07 05:52:32 Test Loss = 0.036382388671875 
2016-12-07 05:52:32 -------------------LR------------------- 
2016-12-07 05:52:32 0.015625 
2016-12-07 05:52:32 Epoch 15 
2016-12-07 05:55:38 Training Error = 0.74302222222222 
2016-12-07 05:55:38 Training Loss = 0.036011552300347 
2016-12-07 05:55:42 Valid Error = 0.75355071014203 
2016-12-07 05:55:42 Valid Loss = 0.035967271883211 
2016-12-07 05:55:50 Test Error = 0.7585 
2016-12-07 05:55:50 Test Loss = 0.036122099609375 
2016-12-07 05:55:50 -------------------LR------------------- 
2016-12-07 05:55:50 0.015625 
2016-12-07 05:55:50 Epoch 16 
2016-12-07 05:58:59 Training Error = 0.734 
2016-12-07 05:58:59 Training Loss = 0.035834139051649 
2016-12-07 05:59:03 Valid Error = 0.75275055011002 
2016-12-07 05:59:03 Valid Loss = 0.035818500846061 
2016-12-07 05:59:11 Test Error = 0.7523 
2016-12-07 05:59:11 Test Loss = 0.035893301513672 
2016-12-07 05:59:11 -------------------LR------------------- 
2016-12-07 05:59:11 0.015625 
2016-12-07 05:59:11 Epoch 17 
2016-12-07 06:02:20 Training Error = 0.72477777777778 
2016-12-07 06:02:20 Training Loss = 0.03564010563151 
2016-12-07 06:02:24 Valid Error = 0.72374474894979 
2016-12-07 06:02:24 Valid Loss = 0.035326900476649 
2016-12-07 06:02:32 Test Error = 0.7291 
2016-12-07 06:02:32 Test Loss = 0.035461919677734 
2016-12-07 06:02:32 -------------------LR------------------- 
2016-12-07 06:02:32 0.015625 
2016-12-07 06:02:32 Epoch 18 
2016-12-07 06:05:39 Training Error = 0.71673333333333 
2016-12-07 06:05:39 Training Loss = 0.035442107367622 
2016-12-07 06:05:43 Valid Error = 0.71654330866173 
2016-12-07 06:05:43 Valid Loss = 0.035201793297692 
2016-12-07 06:05:51 Test Error = 0.7215 
2016-12-07 06:05:51 Test Loss = 0.035385175048828 
2016-12-07 06:05:51 -------------------LR------------------- 
2016-12-07 06:05:51 0.015625 
2016-12-07 06:05:51 Epoch 19 
2016-12-07 06:09:03 Training Error = 0.70715555555556 
2016-12-07 06:09:03 Training Loss = 0.035274150390625 
2016-12-07 06:09:07 Valid Error = 0.7119423884777 
2016-12-07 06:09:07 Valid Loss = 0.034932230302079 
2016-12-07 06:09:15 Test Error = 0.717 
2016-12-07 06:09:15 Test Loss = 0.035107227050781 
2016-12-07 06:09:15 -------------------LR------------------- 
2016-12-07 06:09:15 0.015625 
2016-12-07 06:09:15 Epoch 20 
2016-12-07 06:12:31 Training Error = 0.69817777777778 
2016-12-07 06:12:31 Training Loss = 0.035072450032552 
2016-12-07 06:12:35 Valid Error = 0.70534106821364 
2016-12-07 06:12:35 Valid Loss = 0.034769360715207 
2016-12-07 06:12:43 Test Error = 0.7082 
2016-12-07 06:12:43 Test Loss = 0.034868359619141 
2016-12-07 06:12:43 -------------------LR------------------- 
2016-12-07 06:12:43 0.0078125 
2016-12-07 06:12:43 Epoch 21 
2016-12-07 06:15:58 Training Error = 0.68753333333333 
2016-12-07 06:15:58 Training Loss = 0.034838182834201 
2016-12-07 06:16:02 Valid Error = 0.70154030806161 
2016-12-07 06:16:02 Valid Loss = 0.034428444772409 
2016-12-07 06:16:10 Test Error = 0.7006 
2016-12-07 06:16:10 Test Loss = 0.034487857666016 
2016-12-07 06:16:10 -------------------LR------------------- 
2016-12-07 06:16:10 0.0078125 
2016-12-07 06:16:10 Epoch 22 
2016-12-07 06:19:19 Training Error = 0.68191111111111 
2016-12-07 06:19:19 Training Loss = 0.034708655870226 
2016-12-07 06:19:23 Valid Error = 0.69473894778956 
2016-12-07 06:19:23 Valid Loss = 0.034541125305481 
2016-12-07 06:19:31 Test Error = 0.7007 
2016-12-07 06:19:31 Test Loss = 0.034634879638672 
2016-12-07 06:19:31 -------------------LR------------------- 
2016-12-07 06:19:31 0.0078125 
2016-12-07 06:19:31 Epoch 23 
2016-12-07 06:22:42 Training Error = 0.67773333333333 
2016-12-07 06:22:42 Training Loss = 0.034624826280382 
2016-12-07 06:22:46 Valid Error = 0.69413882776555 
2016-12-07 06:22:46 Valid Loss = 0.034385789281469 
2016-12-07 06:22:54 Test Error = 0.6951 
2016-12-07 06:22:54 Test Loss = 0.034431649414063 
2016-12-07 06:22:54 -------------------LR------------------- 
2016-12-07 06:22:54 0.0078125 
2016-12-07 06:22:54 Epoch 24 
2016-12-07 06:26:01 Training Error = 0.67655555555556 
2016-12-07 06:26:01 Training Loss = 0.034534499348958 
2016-12-07 06:26:05 Valid Error = 0.69073814762953 
2016-12-07 06:26:05 Valid Loss = 0.034171489448922 
2016-12-07 06:26:13 Test Error = 0.6886 
2016-12-07 06:26:13 Test Loss = 0.034140218505859 
2016-12-07 06:26:13 -------------------LR------------------- 
2016-12-07 06:26:13 0.0078125 
2016-12-07 06:26:13 Epoch 25 
2016-12-07 06:29:22 Training Error = 0.66953333333333 
2016-12-07 06:29:22 Training Loss = 0.03445576030816 
2016-12-07 06:29:26 Valid Error = 0.68933786757351 
2016-12-07 06:29:26 Valid Loss = 0.034349436772221 
2016-12-07 06:29:34 Test Error = 0.6962 
2016-12-07 06:29:34 Test Loss = 0.034400883056641 
2016-12-07 06:29:34 -------------------LR------------------- 
2016-12-07 06:29:34 0.0078125 
2016-12-07 06:29:34 Epoch 26 
2016-12-07 06:32:43 Training Error = 0.66495555555556 
2016-12-07 06:32:43 Training Loss = 0.034342496419271 
2016-12-07 06:32:47 Valid Error = 0.68113622724545 
2016-12-07 06:32:47 Valid Loss = 0.034088680555556 
2016-12-07 06:32:55 Test Error = 0.6885 
2016-12-07 06:32:55 Test Loss = 0.034100668212891 
2016-12-07 06:32:55 -------------------LR------------------- 
2016-12-07 06:32:55 0.0078125 
2016-12-07 06:32:55 Epoch 27 
2016-12-07 06:36:07 Training Error = 0.66388888888889 
2016-12-07 06:36:07 Training Loss = 0.034283069932726 
2016-12-07 06:36:11 Valid Error = 0.67853570714143 
2016-12-07 06:36:11 Valid Loss = 0.033972135386852 
2016-12-07 06:36:19 Test Error = 0.6829 
2016-12-07 06:36:19 Test Loss = 0.034021570800781 
2016-12-07 06:36:19 -------------------LR------------------- 
2016-12-07 06:36:19 0.0078125 
2016-12-07 06:36:19 Epoch 28 
2016-12-07 06:39:29 Training Error = 0.65793333333333 
2016-12-07 06:39:29 Training Loss = 0.034181476019965 
2016-12-07 06:39:33 Valid Error = 0.68313662732547 
2016-12-07 06:39:33 Valid Loss = 0.033830636742211 
2016-12-07 06:39:41 Test Error = 0.6782 
2016-12-07 06:39:41 Test Loss = 0.033829414306641 
2016-12-07 06:39:41 -------------------LR------------------- 
2016-12-07 06:39:41 0.0078125 
2016-12-07 06:39:41 Epoch 29 
2016-12-07 06:42:54 Training Error = 0.6574 
2016-12-07 06:42:54 Training Loss = 0.034110752387153 
2016-12-07 06:42:58 Valid Error = 0.66853370674135 
2016-12-07 06:42:58 Valid Loss = 0.033689335337779 
2016-12-07 06:43:06 Test Error = 0.6722 
2016-12-07 06:43:06 Test Loss = 0.033776407958984 
2016-12-07 06:43:06 -------------------LR------------------- 
2016-12-07 06:43:06 0.0078125 
2016-12-07 06:43:06 Epoch 30 
2016-12-07 06:46:19 Training Error = 0.64942222222222 
2016-12-07 06:46:19 Training Loss = 0.033999095269097 
2016-12-07 06:46:24 Valid Error = 0.66053210642128 
2016-12-07 06:46:24 Valid Loss = 0.033536534773543 
2016-12-07 06:46:32 Test Error = 0.6687 
2016-12-07 06:46:32 Test Loss = 0.033564833496094 
2016-12-07 06:46:32 -------------------LR------------------- 
2016-12-07 06:46:32 0.0078125 
2016-12-07 06:46:32 Epoch 31 
2016-12-07 06:49:44 Training Error = 0.64846666666667 
2016-12-07 06:49:44 Training Loss = 0.033925442057292 
2016-12-07 06:49:48 Valid Error = 0.66613322664533 
2016-12-07 06:49:48 Valid Loss = 0.033553301927904 
2016-12-07 06:49:56 Test Error = 0.6672 
2016-12-07 06:49:56 Test Loss = 0.033555978027344 
2016-12-07 06:49:56 -------------------LR------------------- 
2016-12-07 06:49:56 0.0078125 
2016-12-07 06:49:56 Epoch 32 
2016-12-07 06:53:02 Training Error = 0.64304444444444 
2016-12-07 06:53:02 Training Loss = 0.033843896755642 
2016-12-07 06:53:06 Valid Error = 0.65553110622124 
2016-12-07 06:53:06 Valid Loss = 0.033372524710746 
2016-12-07 06:53:14 Test Error = 0.6588 
2016-12-07 06:53:14 Test Loss = 0.03334140234375 
2016-12-07 06:53:14 -------------------LR------------------- 
2016-12-07 06:53:14 0.0078125 
2016-12-07 06:53:14 Epoch 33 
2016-12-07 06:56:24 Training Error = 0.64048888888889 
2016-12-07 06:56:24 Training Loss = 0.033747966525608 
2016-12-07 06:56:28 Valid Error = 0.6495299059812 
2016-12-07 06:56:28 Valid Loss = 0.033198773094872 
2016-12-07 06:56:36 Test Error = 0.6562 
2016-12-07 06:56:36 Test Loss = 0.033216994873047 
2016-12-07 06:56:36 -------------------LR------------------- 
2016-12-07 06:56:36 0.0078125 
2016-12-07 06:56:36 Epoch 34 
2016-12-07 06:59:46 Training Error = 0.63844444444444 
2016-12-07 06:59:46 Training Loss = 0.033686302137587 
2016-12-07 06:59:50 Valid Error = 0.65373074614923 
2016-12-07 06:59:50 Valid Loss = 0.033331821452312 
2016-12-07 06:59:58 Test Error = 0.6634 
2016-12-07 06:59:58 Test Loss = 0.033354278320312 
2016-12-07 06:59:58 -------------------LR------------------- 
2016-12-07 06:59:58 0.0078125 
2016-12-07 06:59:58 Epoch 35 
2016-12-07 07:03:05 Training Error = 0.6352 
2016-12-07 07:03:05 Training Loss = 0.033615886773003 
2016-12-07 07:03:09 Valid Error = 0.64912982596519 
2016-12-07 07:03:09 Valid Loss = 0.032923684555161 
2016-12-07 07:03:17 Test Error = 0.6507 
2016-12-07 07:03:17 Test Loss = 0.032898420898438 
2016-12-07 07:03:17 -------------------LR------------------- 
2016-12-07 07:03:17 0.0078125 
2016-12-07 07:03:17 Epoch 36 
2016-12-07 07:06:27 Training Error = 0.63091111111111 
2016-12-07 07:06:27 Training Loss = 0.033531957899306 
2016-12-07 07:06:31 Valid Error = 0.64592918583717 
2016-12-07 07:06:31 Valid Loss = 0.033030066101746 
2016-12-07 07:06:39 Test Error = 0.6515 
2016-12-07 07:06:39 Test Loss = 0.033014245605469 
2016-12-07 07:06:39 -------------------LR------------------- 
2016-12-07 07:06:39 0.0078125 
2016-12-07 07:06:39 Epoch 37 
2016-12-07 07:09:48 Training Error = 0.62755555555556 
2016-12-07 07:09:48 Training Loss = 0.033438867947049 
2016-12-07 07:09:52 Valid Error = 0.64512902580516 
2016-12-07 07:09:52 Valid Loss = 0.033012126722914 
2016-12-07 07:10:00 Test Error = 0.6509 
2016-12-07 07:10:00 Test Loss = 0.032980886230469 
2016-12-07 07:10:00 -------------------LR------------------- 
2016-12-07 07:10:00 0.0078125 
2016-12-07 07:10:00 Epoch 38 
2016-12-07 07:13:10 Training Error = 0.62324444444444 
2016-12-07 07:13:10 Training Loss = 0.03337958062066 
2016-12-07 07:13:15 Valid Error = 0.64392878575715 
2016-12-07 07:13:15 Valid Loss = 0.032823373524892 
2016-12-07 07:13:23 Test Error = 0.6451 
2016-12-07 07:13:23 Test Loss = 0.032857176757812 
2016-12-07 07:13:23 -------------------LR------------------- 
2016-12-07 07:13:23 0.0078125 
2016-12-07 07:13:23 Epoch 39 
2016-12-07 07:16:31 Training Error = 0.62111111111111 
2016-12-07 07:16:31 Training Loss = 0.033278585286458 
2016-12-07 07:16:35 Valid Error = 0.6375275055011 
2016-12-07 07:16:35 Valid Loss = 0.032665519697432 
2016-12-07 07:16:43 Test Error = 0.6361 
2016-12-07 07:16:43 Test Loss = 0.032597075683594 
2016-12-07 07:16:43 -------------------LR------------------- 
2016-12-07 07:16:43 0.0078125 
2016-12-07 07:16:43 Epoch 40 
2016-12-07 07:20:03 Training Error = 0.61764444444444 
2016-12-07 07:20:03 Training Loss = 0.033231680013021 
2016-12-07 07:20:07 Valid Error = 0.63872774554911 
2016-12-07 07:20:07 Valid Loss = 0.032745882448366 
2016-12-07 07:20:15 Test Error = 0.6444 
2016-12-07 07:20:15 Test Loss = 0.032806924316406 
2016-12-07 07:20:15 -------------------LR------------------- 
2016-12-07 07:20:15 0.00390625 
2016-12-07 07:20:15 Epoch 41 
2016-12-07 07:23:27 Training Error = 0.6114 
2016-12-07 07:23:27 Training Loss = 0.033021024088542 
2016-12-07 07:23:31 Valid Error = 0.63252650530106 
2016-12-07 07:23:31 Valid Loss = 0.032429981749327 
2016-12-07 07:23:39 Test Error = 0.628 
2016-12-07 07:23:39 Test Loss = 0.032371945556641 
2016-12-07 07:23:39 -------------------LR------------------- 
2016-12-07 07:23:39 0.00390625 
2016-12-07 07:23:39 Epoch 42 
2016-12-07 07:26:51 Training Error = 0.608 
2016-12-07 07:26:51 Training Loss = 0.032957247558594 
2016-12-07 07:26:55 Valid Error = 0.64132826565313 
2016-12-07 07:26:55 Valid Loss = 0.032660690782579 
2016-12-07 07:27:03 Test Error = 0.6324 
2016-12-07 07:27:03 Test Loss = 0.032625482910156 
2016-12-07 07:27:03 -------------------LR------------------- 
2016-12-07 07:27:03 0.00390625 
2016-12-07 07:27:03 Epoch 43 
2016-12-07 07:30:14 Training Error = 0.60606666666667 
2016-12-07 07:30:14 Training Loss = 0.03290094281684 
2016-12-07 07:30:18 Valid Error = 0.63152630526105 
2016-12-07 07:30:18 Valid Loss = 0.032299392452022 
2016-12-07 07:30:26 Test Error = 0.6215 
2016-12-07 07:30:26 Test Loss = 0.032273190429688 
2016-12-07 07:30:26 -------------------LR------------------- 
2016-12-07 07:30:26 0.00390625 
2016-12-07 07:30:26 Epoch 44 
2016-12-07 07:33:36 Training Error = 0.60573333333333 
2016-12-07 07:33:36 Training Loss = 0.032880429958767 
2016-12-07 07:33:40 Valid Error = 0.62752550510102 
2016-12-07 07:33:40 Valid Loss = 0.032408202601527 
2016-12-07 07:33:48 Test Error = 0.6318 
2016-12-07 07:33:48 Test Loss = 0.032429604492187 
2016-12-07 07:33:48 -------------------LR------------------- 
2016-12-07 07:33:48 0.00390625 
2016-12-07 07:33:48 Epoch 45 
2016-12-07 07:36:59 Training Error = 0.60182222222222 
2016-12-07 07:36:59 Training Loss = 0.032861811631944 
2016-12-07 07:37:03 Valid Error = 0.63152630526105 
2016-12-07 07:37:03 Valid Loss = 0.032427873870452 
2016-12-07 07:37:11 Test Error = 0.6294 
2016-12-07 07:37:11 Test Loss = 0.032464857177734 
2016-12-07 07:37:11 -------------------LR------------------- 
2016-12-07 07:37:11 0.00390625 
2016-12-07 07:37:11 Epoch 46 
2016-12-07 07:40:22 Training Error = 0.60182222222222 
2016-12-07 07:40:22 Training Loss = 0.032817508029514 
2016-12-07 07:40:26 Valid Error = 0.63192638527706 
2016-12-07 07:40:26 Valid Loss = 0.032525723961266 
2016-12-07 07:40:34 Test Error = 0.6299 
2016-12-07 07:40:34 Test Loss = 0.032502690673828 
2016-12-07 07:40:34 -------------------LR------------------- 
2016-12-07 07:40:34 0.00390625 
2016-12-07 07:40:34 Epoch 47 
2016-12-07 07:43:47 Training Error = 0.59771111111111 
2016-12-07 07:43:47 Training Loss = 0.032759835123698 
2016-12-07 07:43:51 Valid Error = 0.62012402480496 
2016-12-07 07:43:51 Valid Loss = 0.032341354073312 
2016-12-07 07:44:00 Test Error = 0.6237 
2016-12-07 07:44:00 Test Loss = 0.032265415771484 
2016-12-07 07:44:00 -------------------LR------------------- 
2016-12-07 07:44:00 0.00390625 
2016-12-07 07:44:00 Epoch 48 
2016-12-07 07:47:08 Training Error = 0.59688888888889 
2016-12-07 07:47:08 Training Loss = 0.03272394656033 
2016-12-07 07:47:12 Valid Error = 0.62192438487698 
2016-12-07 07:47:12 Valid Loss = 0.032161938930141 
2016-12-07 07:47:20 Test Error = 0.6225 
2016-12-07 07:47:20 Test Loss = 0.032132872314453 
2016-12-07 07:47:20 -------------------LR------------------- 
2016-12-07 07:47:20 0.00390625 
2016-12-07 07:47:20 Epoch 49 
2016-12-07 07:50:30 Training Error = 0.59546666666667 
2016-12-07 07:50:30 Training Loss = 0.032714581759983 
2016-12-07 07:50:34 Valid Error = 0.62912582516503 
2016-12-07 07:50:34 Valid Loss = 0.032302052073558 
2016-12-07 07:50:42 Test Error = 0.6174 
2016-12-07 07:50:42 Test Loss = 0.032236345703125 
2016-12-07 07:50:42 -------------------LR------------------- 
2016-12-07 07:50:42 0.00390625 
2016-12-07 07:50:42 Epoch 50 
2016-12-07 07:53:55 Training Error = 0.59106666666667 
2016-12-07 07:53:55 Training Loss = 0.032654204101562 
2016-12-07 07:53:59 Valid Error = 0.62172434486897 
2016-12-07 07:53:59 Valid Loss = 0.032263203241327 
2016-12-07 07:54:07 Test Error = 0.62 
2016-12-07 07:54:07 Test Loss = 0.032173405273437 
2016-12-07 07:54:07 -------------------LR------------------- 
2016-12-07 07:54:07 0.00390625 
2016-12-07 07:54:07 Epoch 51 
2016-12-07 07:57:22 Training Error = 0.59346666666667 
2016-12-07 07:57:22 Training Loss = 0.032637327907986 
2016-12-07 07:57:26 Valid Error = 0.61712342468494 
2016-12-07 07:57:26 Valid Loss = 0.032074269192044 
2016-12-07 07:57:34 Test Error = 0.6137 
2016-12-07 07:57:34 Test Loss = 0.032013067626953 
2016-12-07 07:57:34 -------------------LR------------------- 
2016-12-07 07:57:34 0.00390625 
2016-12-07 07:57:34 Epoch 52 
2016-12-07 08:00:44 Training Error = 0.58888888888889 
2016-12-07 08:00:44 Training Loss = 0.032553214138455 
2016-12-07 08:00:48 Valid Error = 0.61452290458092 
2016-12-07 08:00:48 Valid Loss = 0.032100785495456 
2016-12-07 08:00:56 Test Error = 0.6163 
2016-12-07 08:00:56 Test Loss = 0.032143809326172 
2016-12-07 08:00:56 -------------------LR------------------- 
2016-12-07 08:00:56 0.00390625 
2016-12-07 08:00:56 Epoch 53 
2016-12-07 08:04:08 Training Error = 0.59022222222222 
2016-12-07 08:04:08 Training Loss = 0.032535209255642 
2016-12-07 08:04:12 Valid Error = 0.61512302460492 
2016-12-07 08:04:12 Valid Loss = 0.032143085343156 
2016-12-07 08:04:20 Test Error = 0.6157 
2016-12-07 08:04:20 Test Loss = 0.032162666992187 
2016-12-07 08:04:20 -------------------LR------------------- 
2016-12-07 08:04:20 0.00390625 
2016-12-07 08:04:20 Epoch 54 
2016-12-07 08:07:28 Training Error = 0.5856 
2016-12-07 08:07:28 Training Loss = 0.032489859266493 
2016-12-07 08:07:32 Valid Error = 0.61152230446089 
2016-12-07 08:07:32 Valid Loss = 0.03193729569462 
2016-12-07 08:07:40 Test Error = 0.6148 
2016-12-07 08:07:40 Test Loss = 0.031936900390625 
2016-12-07 08:07:40 -------------------LR------------------- 
2016-12-07 08:07:40 0.00390625 
2016-12-07 08:07:40 Epoch 55 
2016-12-07 08:10:52 Training Error = 0.586 
2016-12-07 08:10:52 Training Loss = 0.032483936035156 
2016-12-07 08:10:56 Valid Error = 0.61132226445289 
2016-12-07 08:10:56 Valid Loss = 0.032019234623295 
2016-12-07 08:11:04 Test Error = 0.6152 
2016-12-07 08:11:04 Test Loss = 0.031993242919922 
2016-12-07 08:11:04 -------------------LR------------------- 
2016-12-07 08:11:04 0.00390625 
2016-12-07 08:11:04 Epoch 56 
2016-12-07 08:14:15 Training Error = 0.58517777777778 
2016-12-07 08:14:15 Training Loss = 0.032436648166233 
2016-12-07 08:14:19 Valid Error = 0.60972194438888 
2016-12-07 08:14:19 Valid Loss = 0.032007528032427 
2016-12-07 08:14:27 Test Error = 0.6118 
2016-12-07 08:14:27 Test Loss = 0.031965328613281 
2016-12-07 08:14:27 -------------------LR------------------- 
2016-12-07 08:14:27 0.00390625 
2016-12-07 08:14:27 Epoch 57 
2016-12-07 08:17:38 Training Error = 0.58768888888889 
2016-12-07 08:17:38 Training Loss = 0.032438431966146 
2016-12-07 08:17:42 Valid Error = 0.60912182436487 
2016-12-07 08:17:42 Valid Loss = 0.031928155087705 
2016-12-07 08:17:50 Test Error = 0.6145 
2016-12-07 08:17:50 Test Loss = 0.031943411132813 
2016-12-07 08:17:50 -------------------LR------------------- 
2016-12-07 08:17:50 0.00390625 
2016-12-07 08:17:50 Epoch 58 
2016-12-07 08:21:01 Training Error = 0.5842 
2016-12-07 08:21:01 Training Loss = 0.03238508859592 
2016-12-07 08:21:05 Valid Error = 0.61652330466093 
2016-12-07 08:21:05 Valid Loss = 0.032055327352255 
2016-12-07 08:21:13 Test Error = 0.6118 
2016-12-07 08:21:13 Test Loss = 0.032018539550781 
2016-12-07 08:21:13 -------------------LR------------------- 
2016-12-07 08:21:13 0.00390625 
2016-12-07 08:21:13 Epoch 59 
2016-12-07 08:24:22 Training Error = 0.57986666666667 
2016-12-07 08:24:22 Training Loss = 0.032335159559462 
2016-12-07 08:24:26 Valid Error = 0.5999199839968 
2016-12-07 08:24:26 Valid Loss = 0.031709122953031 
2016-12-07 08:24:34 Test Error = 0.6031 
2016-12-07 08:24:34 Test Loss = 0.031668042236328 
2016-12-07 08:24:34 -------------------LR------------------- 
2016-12-07 08:24:34 0.00390625 
2016-12-07 08:24:34 Epoch 60 
2016-12-07 08:27:49 Training Error = 0.58024444444444 
2016-12-07 08:27:49 Training Loss = 0.032300306043837 
2016-12-07 08:27:53 Valid Error = 0.60612122424485 
2016-12-07 08:27:53 Valid Loss = 0.031774232198507 
2016-12-07 08:28:01 Test Error = 0.6055 
2016-12-07 08:28:01 Test Loss = 0.031732978027344 
2016-12-07 08:28:01 -------------------LR------------------- 
2016-12-07 08:28:01 0.001953125 
2016-12-07 08:28:01 Epoch 61 
2016-12-07 08:31:13 Training Error = 0.57473333333333 
2016-12-07 08:31:13 Training Loss = 0.032139185872396 
2016-12-07 08:31:17 Valid Error = 0.60872174434887 
2016-12-07 08:31:17 Valid Loss = 0.031853643781477 
2016-12-07 08:31:25 Test Error = 0.6042 
2016-12-07 08:31:25 Test Loss = 0.031701291748047 
2016-12-07 08:31:25 -------------------LR------------------- 
2016-12-07 08:31:25 0.001953125 
2016-12-07 08:31:25 Epoch 62 
2016-12-07 08:34:31 Training Error = 0.57415555555556 
2016-12-07 08:34:31 Training Loss = 0.032146027723524 
2016-12-07 08:34:35 Valid Error = 0.6005201040208 
2016-12-07 08:34:35 Valid Loss = 0.03156089602542 
2016-12-07 08:34:44 Test Error = 0.6035 
2016-12-07 08:34:44 Test Loss = 0.031524860107422 
2016-12-07 08:34:44 -------------------LR------------------- 
2016-12-07 08:34:44 0.001953125 
2016-12-07 08:34:44 Epoch 63 
2016-12-07 08:37:53 Training Error = 0.57077777777778 
2016-12-07 08:37:53 Training Loss = 0.032091686848958 
2016-12-07 08:37:57 Valid Error = 0.60092018403681 
2016-12-07 08:37:57 Valid Loss = 0.031526157995887 
2016-12-07 08:38:05 Test Error = 0.6029 
2016-12-07 08:38:05 Test Loss = 0.031546876708984 
2016-12-07 08:38:05 -------------------LR------------------- 
2016-12-07 08:38:05 0.001953125 
2016-12-07 08:38:05 Epoch 64 
2016-12-07 08:41:16 Training Error = 0.57246666666667 
2016-12-07 08:41:16 Training Loss = 0.032106435818142 
2016-12-07 08:41:20 Valid Error = 0.60272054410882 
2016-12-07 08:41:20 Valid Loss = 0.031673626747353 
2016-12-07 08:41:28 Test Error = 0.6037 
2016-12-07 08:41:28 Test Loss = 0.031617899169922 
2016-12-07 08:41:28 -------------------LR------------------- 
2016-12-07 08:41:28 0.001953125 
2016-12-07 08:41:28 Epoch 65 
2016-12-07 08:44:41 Training Error = 0.56984444444444 
2016-12-07 08:44:41 Training Loss = 0.032064296115451 
2016-12-07 08:44:45 Valid Error = 0.60452090418084 
2016-12-07 08:44:45 Valid Loss = 0.031843099732056 
2016-12-07 08:44:53 Test Error = 0.6053 
2016-12-07 08:44:53 Test Loss = 0.031780812988281 
2016-12-07 08:44:53 -------------------LR------------------- 
2016-12-07 08:44:53 0.001953125 
2016-12-07 08:44:53 Epoch 66 
2016-12-07 08:48:01 Training Error = 0.57113333333333 
2016-12-07 08:48:01 Training Loss = 0.032048295844184 
2016-12-07 08:48:05 Valid Error = 0.61072214442889 
2016-12-07 08:48:05 Valid Loss = 0.031829120675852 
2016-12-07 08:48:13 Test Error = 0.6071 
2016-12-07 08:48:13 Test Loss = 0.031825877929688 
2016-12-07 08:48:13 -------------------LR------------------- 
2016-12-07 08:48:13 0.001953125 
2016-12-07 08:48:13 Epoch 67 
2016-12-07 08:51:25 Training Error = 0.56753333333333 
2016-12-07 08:51:25 Training Loss = 0.032047011664497 
2016-12-07 08:51:29 Valid Error = 0.60072014402881 
2016-12-07 08:51:29 Valid Loss = 0.031531544389116 
2016-12-07 08:51:37 Test Error = 0.5999 
2016-12-07 08:51:37 Test Loss = 0.031514130859375 
2016-12-07 08:51:37 -------------------LR------------------- 
2016-12-07 08:51:37 0.001953125 
2016-12-07 08:51:37 Epoch 68 
2016-12-07 08:54:42 Training Error = 0.56871111111111 
2016-12-07 08:54:42 Training Loss = 0.031997443088108 
2016-12-07 08:54:46 Valid Error = 0.59791958391678 
2016-12-07 08:54:46 Valid Loss = 0.031513647073343 
2016-12-07 08:54:54 Test Error = 0.5986 
2016-12-07 08:54:54 Test Loss = 0.031455606445312 
2016-12-07 08:54:54 -------------------LR------------------- 
2016-12-07 08:54:54 0.001953125 
2016-12-07 08:54:54 Epoch 69 
2016-12-07 08:58:04 Training Error = 0.56693333333333 
2016-12-07 08:58:04 Training Loss = 0.032007921875 
2016-12-07 08:58:08 Valid Error = 0.59711942388478 
2016-12-07 08:58:08 Valid Loss = 0.031657014837103 
2016-12-07 08:58:16 Test Error = 0.5991 
2016-12-07 08:58:16 Test Loss = 0.031595260009766 
2016-12-07 08:58:16 -------------------LR------------------- 
2016-12-07 08:58:16 0.001953125 
2016-12-07 08:58:16 Epoch 70 
2016-12-07 09:01:36 Training Error = 0.56608888888889 
2016-12-07 09:01:36 Training Loss = 0.032006650227865 
2016-12-07 09:01:40 Valid Error = 0.60312062412483 
2016-12-07 09:01:40 Valid Loss = 0.031488718611678 
2016-12-07 09:01:48 Test Error = 0.5966 
2016-12-07 09:01:48 Test Loss = 0.031432352294922 
2016-12-07 09:01:48 -------------------LR------------------- 
2016-12-07 09:01:48 0.001953125 
2016-12-07 09:01:48 Epoch 71 
2016-12-07 09:04:58 Training Error = 0.5654 
2016-12-07 09:04:58 Training Loss = 0.03198174983724 
2016-12-07 09:05:02 Valid Error = 0.60592118423685 
2016-12-07 09:05:02 Valid Loss = 0.031692562132445 
2016-12-07 09:05:10 Test Error = 0.6007 
2016-12-07 09:05:10 Test Loss = 0.031767321044922 
2016-12-07 09:05:10 -------------------LR------------------- 
2016-12-07 09:05:10 0.001953125 
2016-12-07 09:05:10 Epoch 72 
2016-12-07 09:08:18 Training Error = 0.56377777777778 
2016-12-07 09:08:18 Training Loss = 0.031931457682292 
2016-12-07 09:08:22 Valid Error = 0.58851770354071 
2016-12-07 09:08:22 Valid Loss = 0.031237178601453 
2016-12-07 09:08:30 Test Error = 0.5947 
2016-12-07 09:08:30 Test Loss = 0.031285372314453 
2016-12-07 09:08:30 -------------------LR------------------- 
2016-12-07 09:08:30 0.001953125 
2016-12-07 09:08:30 Epoch 73 
2016-12-07 09:11:41 Training Error = 0.56571111111111 
2016-12-07 09:11:41 Training Loss = 0.031957907118056 
2016-12-07 09:11:45 Valid Error = 0.5997199439888 
2016-12-07 09:11:45 Valid Loss = 0.031420950586817 
2016-12-07 09:11:53 Test Error = 0.5942 
2016-12-07 09:11:53 Test Loss = 0.031419740478516 
2016-12-07 09:11:53 -------------------LR------------------- 
2016-12-07 09:11:53 0.001953125 
2016-12-07 09:11:53 Epoch 74 
2016-12-07 09:15:05 Training Error = 0.56166666666667 
2016-12-07 09:15:05 Training Loss = 0.031901507541233 
2016-12-07 09:15:09 Valid Error = 0.60112022404481 
2016-12-07 09:15:09 Valid Loss = 0.031672103190104 
2016-12-07 09:15:17 Test Error = 0.5981 
2016-12-07 09:15:17 Test Loss = 0.03156984375 
2016-12-07 09:15:17 -------------------LR------------------- 
2016-12-07 09:15:17 0.001953125 
2016-12-07 09:15:17 Epoch 75 
2016-12-07 09:18:28 Training Error = 0.56117777777778 
2016-12-07 09:18:28 Training Loss = 0.031877120117187 
2016-12-07 09:18:32 Valid Error = 0.5869173834767 
2016-12-07 09:18:32 Valid Loss = 0.031310320671257 
2016-12-07 09:18:40 Test Error = 0.5936 
2016-12-07 09:18:40 Test Loss = 0.031380697753906 
2016-12-07 09:18:40 -------------------LR------------------- 
2016-12-07 09:18:40 0.001953125 
2016-12-07 09:18:40 Epoch 76 
2016-12-07 09:21:49 Training Error = 0.56122222222222 
2016-12-07 09:21:49 Training Loss = 0.031877798665365 
2016-12-07 09:21:53 Valid Error = 0.58831766353271 
2016-12-07 09:21:53 Valid Loss = 0.03125957724277 
2016-12-07 09:22:01 Test Error = 0.5885 
2016-12-07 09:22:01 Test Loss = 0.031291105224609 
2016-12-07 09:22:01 -------------------LR------------------- 
2016-12-07 09:22:01 0.001953125 
2016-12-07 09:22:01 Epoch 77 
2016-12-07 09:25:12 Training Error = 0.56002222222222 
2016-12-07 09:25:12 Training Loss = 0.031855573025174 
2016-12-07 09:25:16 Valid Error = 0.59071814362873 
2016-12-07 09:25:16 Valid Loss = 0.031173654443995 
2016-12-07 09:25:24 Test Error = 0.5926 
2016-12-07 09:25:24 Test Loss = 0.031215282226563 
2016-12-07 09:25:24 -------------------LR------------------- 
2016-12-07 09:25:24 0.001953125 
2016-12-07 09:25:24 Epoch 78 
2016-12-07 09:28:31 Training Error = 0.55955555555556 
2016-12-07 09:28:31 Training Loss = 0.03184506656901 
2016-12-07 09:28:35 Valid Error = 0.58591718343669 
2016-12-07 09:28:35 Valid Loss = 0.031065729914974 
2016-12-07 09:28:43 Test Error = 0.5909 
2016-12-07 09:28:43 Test Loss = 0.031130204589844 
2016-12-07 09:28:43 -------------------LR------------------- 
2016-12-07 09:28:43 0.001953125 
2016-12-07 09:28:43 Epoch 79 
2016-12-07 09:31:54 Training Error = 0.55837777777778 
2016-12-07 09:31:54 Training Loss = 0.031815192599826 
2016-12-07 09:31:58 Valid Error = 0.59111822364473 
2016-12-07 09:31:58 Valid Loss = 0.031451329644586 
2016-12-07 09:32:06 Test Error = 0.5938 
2016-12-07 09:32:06 Test Loss = 0.031427384033203 
2016-12-07 09:32:06 -------------------LR------------------- 
2016-12-07 09:32:06 0.001953125 
2016-12-07 09:32:06 Epoch 80 
2016-12-07 09:35:22 Training Error = 0.56088888888889 
2016-12-07 09:35:22 Training Loss = 0.03182348187934 
2016-12-07 09:35:26 Valid Error = 0.59311862372474 
2016-12-07 09:35:26 Valid Loss = 0.031506161272601 
2016-12-07 09:35:34 Test Error = 0.5905 
2016-12-07 09:35:34 Test Loss = 0.031527695556641 
2016-12-07 09:35:34 -------------------LR------------------- 
2016-12-07 09:35:34 0.0009765625 
2016-12-07 09:35:34 Epoch 81 
2016-12-07 09:38:45 Training Error = 0.55766666666667 
2016-12-07 09:38:45 Training Loss = 0.031697132541233 
2016-12-07 09:38:49 Valid Error = 0.58931786357271 
2016-12-07 09:38:49 Valid Loss = 0.031159454914387 
2016-12-07 09:38:57 Test Error = 0.5886 
2016-12-07 09:38:57 Test Loss = 0.031166201904297 
2016-12-07 09:38:57 -------------------LR------------------- 
2016-12-07 09:38:57 0.0009765625 
2016-12-07 09:38:57 Epoch 82 
2016-12-07 09:42:09 Training Error = 0.554 
2016-12-07 09:42:09 Training Loss = 0.031666904296875 
2016-12-07 09:42:13 Valid Error = 0.58411682336467 
2016-12-07 09:42:13 Valid Loss = 0.031012145912025 
2016-12-07 09:42:21 Test Error = 0.5859 
2016-12-07 09:42:21 Test Loss = 0.031056119140625 
2016-12-07 09:42:21 -------------------LR------------------- 
2016-12-07 09:42:21 0.0009765625 
2016-12-07 09:42:21 Epoch 83 
2016-12-07 09:45:30 Training Error = 0.55262222222222 
2016-12-07 09:45:30 Training Loss = 0.031696590332031 
2016-12-07 09:45:34 Valid Error = 0.58431686337267 
2016-12-07 09:45:34 Valid Loss = 0.031111987153658 
2016-12-07 09:45:42 Test Error = 0.5848 
2016-12-07 09:45:42 Test Loss = 0.031189437988281 
2016-12-07 09:45:42 -------------------LR------------------- 
2016-12-07 09:45:42 0.0009765625 
2016-12-07 09:45:42 Epoch 84 
2016-12-07 09:48:48 Training Error = 0.55568888888889 
2016-12-07 09:48:48 Training Loss = 0.031676418023003 
2016-12-07 09:48:52 Valid Error = 0.58851770354071 
2016-12-07 09:48:52 Valid Loss = 0.031246900330995 
2016-12-07 09:49:00 Test Error = 0.5859 
2016-12-07 09:49:00 Test Loss = 0.031175152587891 
2016-12-07 09:49:00 -------------------LR------------------- 
2016-12-07 09:49:00 0.0009765625 
2016-12-07 09:49:00 Epoch 85 
2016-12-07 09:52:12 Training Error = 0.55313333333333 
2016-12-07 09:52:12 Training Loss = 0.031666182834201 
2016-12-07 09:52:16 Valid Error = 0.58891778355671 
2016-12-07 09:52:16 Valid Loss = 0.031364675675187 
2016-12-07 09:52:24 Test Error = 0.5874 
2016-12-07 09:52:24 Test Loss = 0.031344568847656 
2016-12-07 09:52:24 -------------------LR------------------- 
2016-12-07 09:52:24 0.0009765625 
2016-12-07 09:52:24 Epoch 86 
2016-12-07 09:55:36 Training Error = 0.55435555555556 
2016-12-07 09:55:36 Training Loss = 0.031654321994358 
2016-12-07 09:55:40 Valid Error = 0.58931786357271 
2016-12-07 09:55:40 Valid Loss = 0.031233237707923 
2016-12-07 09:55:48 Test Error = 0.5904 
2016-12-07 09:55:48 Test Loss = 0.031247409912109 
2016-12-07 09:55:48 -------------------LR------------------- 
2016-12-07 09:55:48 0.0009765625 
2016-12-07 09:55:48 Epoch 87 
2016-12-07 09:58:58 Training Error = 0.55182222222222 
2016-12-07 09:58:58 Training Loss = 0.031675018391927 
2016-12-07 09:59:02 Valid Error = 0.5875175035007 
2016-12-07 09:59:02 Valid Loss = 0.031267150274787 
2016-12-07 09:59:10 Test Error = 0.5903 
2016-12-07 09:59:10 Test Loss = 0.031273306884766 
2016-12-07 09:59:10 -------------------LR------------------- 
2016-12-07 09:59:10 0.0009765625 
2016-12-07 09:59:10 Epoch 88 
2016-12-07 10:02:20 Training Error = 0.55113333333333 
2016-12-07 10:02:20 Training Loss = 0.031623565755208 
2016-12-07 10:02:24 Valid Error = 0.58371674334867 
2016-12-07 10:02:24 Valid Loss = 0.03100729932276 
2016-12-07 10:02:32 Test Error = 0.5818 
2016-12-07 10:02:32 Test Loss = 0.031029412841797 
2016-12-07 10:02:32 -------------------LR------------------- 
2016-12-07 10:02:32 0.0009765625 
2016-12-07 10:02:32 Epoch 89 
2016-12-07 10:05:43 Training Error = 0.55091111111111 
2016-12-07 10:05:43 Training Loss = 0.031621092881944 
2016-12-07 10:05:47 Valid Error = 0.58131626325265 
2016-12-07 10:05:47 Valid Loss = 0.031012787864525 
2016-12-07 10:05:56 Test Error = 0.5834 
2016-12-07 10:05:56 Test Loss = 0.031049041259766 
2016-12-07 10:05:56 -------------------LR------------------- 
2016-12-07 10:05:56 0.0009765625 
2016-12-07 10:05:56 Epoch 90 
2016-12-07 10:09:15 Training Error = 0.55171111111111 
2016-12-07 10:09:15 Training Loss = 0.031636685058594 
2016-12-07 10:09:19 Valid Error = 0.59511902380476 
2016-12-07 10:09:19 Valid Loss = 0.031357752371512 
2016-12-07 10:09:27 Test Error = 0.5908 
2016-12-07 10:09:27 Test Loss = 0.031271296142578 
2016-12-07 10:09:27 -------------------LR------------------- 
2016-12-07 10:09:27 0.0009765625 
2016-12-07 10:09:27 Epoch 91 
2016-12-07 10:12:49 Training Error = 0.553 
2016-12-07 10:12:49 Training Loss = 0.031623687065972 
2016-12-07 10:12:53 Valid Error = 0.59191838367674 
2016-12-07 10:12:53 Valid Loss = 0.031193407332137 
2016-12-07 10:13:01 Test Error = 0.5878 
2016-12-07 10:13:01 Test Loss = 0.031208860595703 
2016-12-07 10:13:01 -------------------LR------------------- 
2016-12-07 10:13:01 0.0009765625 
2016-12-07 10:13:01 Epoch 92 
2016-12-07 10:16:35 Training Error = 0.54966666666667 
2016-12-07 10:16:35 Training Loss = 0.031633383897569 
2016-12-07 10:16:39 Valid Error = 0.58931786357271 
2016-12-07 10:16:39 Valid Loss = 0.031310950877635 
2016-12-07 10:16:47 Test Error = 0.5882 
2016-12-07 10:16:47 Test Loss = 0.031280590332031 
2016-12-07 10:16:47 -------------------LR------------------- 
2016-12-07 10:16:47 0.0009765625 
2016-12-07 10:16:47 Epoch 93 
2016-12-07 10:20:24 Training Error = 0.55064444444444 
2016-12-07 10:20:24 Training Loss = 0.031601563693576 
2016-12-07 10:20:28 Valid Error = 0.58971794358872 
2016-12-07 10:20:28 Valid Loss = 0.031271870778493 
2016-12-07 10:20:36 Test Error = 0.5894 
2016-12-07 10:20:36 Test Loss = 0.031275545166016 
2016-12-07 10:20:36 -------------------LR------------------- 
2016-12-07 10:20:36 0.0009765625 
2016-12-07 10:20:36 Epoch 94 
2016-12-07 10:24:09 Training Error = 0.55006666666667 
2016-12-07 10:24:09 Training Loss = 0.031581375759549 
2016-12-07 10:24:13 Valid Error = 0.59111822364473 
2016-12-07 10:24:13 Valid Loss = 0.031152250692098 
2016-12-07 10:24:21 Test Error = 0.5839 
2016-12-07 10:24:21 Test Loss = 0.031147970458984 
2016-12-07 10:24:21 -------------------LR------------------- 
2016-12-07 10:24:21 0.0009765625 
2016-12-07 10:24:21 Epoch 95 
2016-12-07 10:27:50 Training Error = 0.54993333333333 
2016-12-07 10:27:50 Training Loss = 0.031619799858941 
2016-12-07 10:27:54 Valid Error = 0.58011602320464 
2016-12-07 10:27:54 Valid Loss = 0.031111349796574 
2016-12-07 10:28:02 Test Error = 0.5842 
2016-12-07 10:28:02 Test Loss = 0.031062149169922 
2016-12-07 10:28:02 -------------------LR------------------- 
2016-12-07 10:28:02 0.0009765625 
2016-12-07 10:28:02 Epoch 96 
2016-12-07 10:31:32 Training Error = 0.55024444444444 
2016-12-07 10:31:32 Training Loss = 0.031583892469618 
2016-12-07 10:31:36 Valid Error = 0.58091618323665 
2016-12-07 10:31:36 Valid Loss = 0.031168475861604 
2016-12-07 10:31:44 Test Error = 0.5828 
2016-12-07 10:31:44 Test Loss = 0.031182341796875 
2016-12-07 10:31:44 -------------------LR------------------- 
2016-12-07 10:31:44 0.0009765625 
2016-12-07 10:31:44 Epoch 97 
2016-12-07 10:35:13 Training Error = 0.55002222222222 
2016-12-07 10:35:13 Training Loss = 0.031557878851997 
2016-12-07 10:35:17 Valid Error = 0.57951590318064 
2016-12-07 10:35:17 Valid Loss = 0.030911112808121 
2016-12-07 10:35:25 Test Error = 0.5856 
2016-12-07 10:35:25 Test Loss = 0.030994504150391 
2016-12-07 10:35:25 -------------------LR------------------- 
2016-12-07 10:35:25 0.0009765625 
2016-12-07 10:35:25 Epoch 98 
2016-12-07 10:39:02 Training Error = 0.548 
2016-12-07 10:39:02 Training Loss = 0.031567586534288 
2016-12-07 10:39:06 Valid Error = 0.58271654330866 
2016-12-07 10:39:06 Valid Loss = 0.031074761167906 
2016-12-07 10:39:14 Test Error = 0.5846 
2016-12-07 10:39:14 Test Loss = 0.031019955566406 
2016-12-07 10:39:14 -------------------LR------------------- 
2016-12-07 10:39:14 0.0009765625 
2016-12-07 10:39:14 Epoch 99 
2016-12-07 10:42:51 Training Error = 0.54893333333333 
2016-12-07 10:42:51 Training Loss = 0.03156057796224 
2016-12-07 10:42:55 Valid Error = 0.58051610322064 
2016-12-07 10:42:55 Valid Loss = 0.031143452919717 
2016-12-07 10:43:04 Test Error = 0.5818 
2016-12-07 10:43:04 Test Loss = 0.03105993359375 
2016-12-07 10:43:04 -------------------LR------------------- 
2016-12-07 10:43:04 0.0009765625 
2016-12-07 10:43:04 Epoch 100 
2016-12-07 10:46:41 Training Error = 0.5476 
2016-12-07 10:46:41 Training Loss = 0.031546614420573 
2016-12-07 10:46:45 Valid Error = 0.58211642328466 
2016-12-07 10:46:45 Valid Loss = 0.031008549874582 
2016-12-07 10:46:53 Test Error = 0.5756 
2016-12-07 10:46:53 Test Loss = 0.030930798095703 
2016-12-07 10:46:53 -------------------LR------------------- 
2016-12-07 10:46:53 0.00048828125 
2016-12-07 10:46:53 Epoch 101 
2016-12-07 10:50:25 Training Error = 0.5458 
2016-12-07 10:50:25 Training Loss = 0.031458458821615 
2016-12-07 10:50:29 Valid Error = 0.58631726345269 
2016-12-07 10:50:29 Valid Loss = 0.031196419458521 
2016-12-07 10:50:37 Test Error = 0.5882 
2016-12-07 10:50:37 Test Loss = 0.031138302246094 
2016-12-07 10:50:37 -------------------LR------------------- 
2016-12-07 10:50:37 0.00048828125 
2016-12-07 10:50:37 Epoch 102 
2016-12-07 10:54:09 Training Error = 0.54864444444444 
2016-12-07 10:54:09 Training Loss = 0.031453541775174 
2016-12-07 10:54:13 Valid Error = 0.57831566313263 
2016-12-07 10:54:13 Valid Loss = 0.03085604735595 
2016-12-07 10:54:21 Test Error = 0.5774 
2016-12-07 10:54:21 Test Loss = 0.030899086669922 
2016-12-07 10:54:21 -------------------LR------------------- 
2016-12-07 10:54:21 0.00048828125 
2016-12-07 10:54:21 Epoch 103 
2016-12-07 10:57:56 Training Error = 0.5444 
2016-12-07 10:57:56 Training Loss = 0.031435464626736 
2016-12-07 10:58:00 Valid Error = 0.58331666333267 
2016-12-07 10:58:00 Valid Loss = 0.031077488825251 
2016-12-07 10:58:08 Test Error = 0.5816 
2016-12-07 10:58:08 Test Loss = 0.031026740966797 
2016-12-07 10:58:08 -------------------LR------------------- 
2016-12-07 10:58:08 0.00048828125 
2016-12-07 10:58:08 Epoch 104 
2016-12-07 11:01:44 Training Error = 0.54593333333333 
2016-12-07 11:01:44 Training Loss = 0.031461157552083 
2016-12-07 11:01:48 Valid Error = 0.57831566313263 
2016-12-07 11:01:48 Valid Loss = 0.030890032337025 
2016-12-07 11:01:56 Test Error = 0.575 
2016-12-07 11:01:56 Test Loss = 0.030880415039063 
2016-12-07 11:01:56 -------------------LR------------------- 
2016-12-07 11:01:56 0.00048828125 
2016-12-07 11:01:56 Epoch 105 
2016-12-07 11:05:29 Training Error = 0.54604444444444 
2016-12-07 11:05:29 Training Loss = 0.031473197862413 
2016-12-07 11:05:33 Valid Error = 0.58311662332466 
2016-12-07 11:05:33 Valid Loss = 0.031011015368885 
2016-12-07 11:05:41 Test Error = 0.5775 
2016-12-07 11:05:41 Test Loss = 0.030934153564453 
2016-12-07 11:05:41 -------------------LR------------------- 
2016-12-07 11:05:41 0.00048828125 
2016-12-07 11:05:41 Epoch 106 
2016-12-07 11:09:10 Training Error = 0.54624444444444 
2016-12-07 11:09:10 Training Loss = 0.031449450412326 
2016-12-07 11:09:14 Valid Error = 0.5871174234847 
2016-12-07 11:09:14 Valid Loss = 0.031096771700411 
2016-12-07 11:09:22 Test Error = 0.5841 
2016-12-07 11:09:22 Test Loss = 0.031177621337891 
2016-12-07 11:09:22 -------------------LR------------------- 
2016-12-07 11:09:22 0.00048828125 
2016-12-07 11:09:22 Epoch 107 
2016-12-07 11:12:59 Training Error = 0.54566666666667 
2016-12-07 11:12:59 Training Loss = 0.031479066731771 
2016-12-07 11:13:03 Valid Error = 0.58531706341268 
2016-12-07 11:13:03 Valid Loss = 0.031021487452296 
2016-12-07 11:13:12 Test Error = 0.5823 
2016-12-07 11:13:12 Test Loss = 0.031005065917969 
2016-12-07 11:13:12 -------------------LR------------------- 
2016-12-07 11:13:12 0.00048828125 
2016-12-07 11:13:12 Epoch 108 
2016-12-07 11:16:49 Training Error = 0.54615555555556 
2016-12-07 11:16:49 Training Loss = 0.031469770182292 
2016-12-07 11:16:53 Valid Error = 0.58011602320464 
2016-12-07 11:16:53 Valid Loss = 0.031000525667758 
2016-12-07 11:17:01 Test Error = 0.5782 
2016-12-07 11:17:01 Test Loss = 0.030993711914063 
2016-12-07 11:17:01 -------------------LR------------------- 
2016-12-07 11:17:01 0.00048828125 
2016-12-07 11:17:01 Epoch 109 
2016-12-07 11:20:35 Training Error = 0.54453333333333 
2016-12-07 11:20:35 Training Loss = 0.031445652289497 
2016-12-07 11:20:39 Valid Error = 0.58151630326065 
2016-12-07 11:20:39 Valid Loss = 0.031084921412624 
2016-12-07 11:20:47 Test Error = 0.5816 
2016-12-07 11:20:47 Test Loss = 0.030989488525391 
2016-12-07 11:20:47 -------------------LR------------------- 
2016-12-07 11:20:47 0.00048828125 
2016-12-07 11:20:47 Epoch 110 
2016-12-07 11:24:20 Training Error = 0.54353333333333 
2016-12-07 11:24:20 Training Loss = 0.031431327690972 
2016-12-07 11:24:24 Valid Error = 0.57611522304461 
2016-12-07 11:24:24 Valid Loss = 0.030902041519058 
2016-12-07 11:24:32 Test Error = 0.577 
2016-12-07 11:24:32 Test Loss = 0.030871146728516 
2016-12-07 11:24:32 -------------------LR------------------- 
2016-12-07 11:24:32 0.00048828125 
2016-12-07 11:24:32 Epoch 111 
2016-12-07 11:27:57 Training Error = 0.54444444444444 
2016-12-07 11:27:57 Training Loss = 0.031477541775174 
2016-12-07 11:28:01 Valid Error = 0.57851570314063 
2016-12-07 11:28:01 Valid Loss = 0.030999780115076 
2016-12-07 11:28:09 Test Error = 0.5802 
2016-12-07 11:28:09 Test Loss = 0.031012232421875 
2016-12-07 11:28:09 -------------------LR------------------- 
2016-12-07 11:28:09 0.00048828125 
2016-12-07 11:28:09 Epoch 112 
2016-12-07 11:31:28 Training Error = 0.54342222222222 
2016-12-07 11:31:28 Training Loss = 0.031427918782552 
2016-12-07 11:31:32 Valid Error = 0.57771554310862 
2016-12-07 11:31:32 Valid Loss = 0.030966422886754 
2016-12-07 11:31:40 Test Error = 0.5773 
2016-12-07 11:31:40 Test Loss = 0.030985486572266 
2016-12-07 11:31:40 -------------------LR------------------- 
2016-12-07 11:31:40 0.00048828125 
2016-12-07 11:31:40 Epoch 113 
2016-12-07 11:35:06 Training Error = 0.54466666666667 
2016-12-07 11:35:06 Training Loss = 0.031423364040799 
2016-12-07 11:35:10 Valid Error = 0.57771554310862 
2016-12-07 11:35:10 Valid Loss = 0.030990637815061 
2016-12-07 11:35:18 Test Error = 0.5766 
2016-12-07 11:35:18 Test Loss = 0.030954188232422 
2016-12-07 11:35:18 -------------------LR------------------- 
2016-12-07 11:35:18 0.00048828125 
2016-12-07 11:35:18 Epoch 114 
2016-12-07 11:38:43 Training Error = 0.54488888888889 
2016-12-07 11:38:43 Training Loss = 0.031432415744358 
2016-12-07 11:38:47 Valid Error = 0.57191438287658 
2016-12-07 11:38:47 Valid Loss = 0.030810229656414 
2016-12-07 11:38:55 Test Error = 0.5728 
2016-12-07 11:38:55 Test Loss = 0.030843385742187 
2016-12-07 11:38:55 -------------------LR------------------- 
2016-12-07 11:38:55 0.00048828125 
2016-12-07 11:38:55 Epoch 115 
2016-12-07 11:42:14 Training Error = 0.54295555555556 
2016-12-07 11:42:14 Training Loss = 0.031437407280816 
2016-12-07 11:42:18 Valid Error = 0.5751150230046 
2016-12-07 11:42:18 Valid Loss = 0.030885208136848 
2016-12-07 11:42:26 Test Error = 0.5753 
2016-12-07 11:42:26 Test Loss = 0.03081231640625 
2016-12-07 11:42:26 -------------------LR------------------- 
2016-12-07 11:42:26 0.00048828125 
2016-12-07 11:42:26 Epoch 116 
2016-12-07 11:45:50 Training Error = 0.54293333333333 
2016-12-07 11:45:50 Training Loss = 0.031409746961806 
2016-12-07 11:45:54 Valid Error = 0.57811562312462 
2016-12-07 11:45:54 Valid Loss = 0.030814519171026 
2016-12-07 11:46:03 Test Error = 0.5716 
2016-12-07 11:46:03 Test Loss = 0.030699822753906 
2016-12-07 11:46:03 -------------------LR------------------- 
2016-12-07 11:46:03 0.00048828125 
2016-12-07 11:46:03 Epoch 117 
2016-12-07 11:49:30 Training Error = 0.54164444444444 
2016-12-07 11:49:30 Training Loss = 0.031389761773003 
2016-12-07 11:49:34 Valid Error = 0.5753150630126 
2016-12-07 11:49:34 Valid Loss = 0.03081197302967 
2016-12-07 11:49:42 Test Error = 0.5728 
2016-12-07 11:49:42 Test Loss = 0.030787599609375 
2016-12-07 11:49:42 -------------------LR------------------- 
2016-12-07 11:49:42 0.00048828125 
2016-12-07 11:49:42 Epoch 118 
2016-12-07 11:53:10 Training Error = 0.54395555555556 
2016-12-07 11:53:10 Training Loss = 0.031407125271267 
2016-12-07 11:53:14 Valid Error = 0.57951590318064 
2016-12-07 11:53:14 Valid Loss = 0.031036663003824 
2016-12-07 11:53:22 Test Error = 0.5815 
2016-12-07 11:53:22 Test Loss = 0.031048432861328 
2016-12-07 11:53:22 -------------------LR------------------- 
2016-12-07 11:53:22 0.00048828125 
2016-12-07 11:53:22 Epoch 119 
2016-12-07 11:56:35 Training Error = 0.54331111111111 
2016-12-07 11:56:35 Training Loss = 0.031419723741319 
2016-12-07 11:56:39 Valid Error = 0.58491698339668 
2016-12-07 11:56:39 Valid Loss = 0.031008929628359 
2016-12-07 11:56:47 Test Error = 0.5788 
2016-12-07 11:56:47 Test Loss = 0.030923201416016 
2016-12-07 11:56:47 -------------------LR------------------- 
2016-12-07 11:56:47 0.00048828125 
2016-12-07 11:56:48 Epoch 120 
2016-12-07 12:00:06 Training Error = 0.54253333333333 
2016-12-07 12:00:06 Training Loss = 0.031410314561632 
2016-12-07 12:00:10 Valid Error = 0.58271654330866 
2016-12-07 12:00:10 Valid Loss = 0.030877582075728 
2016-12-07 12:00:18 Test Error = 0.5789 
2016-12-07 12:00:18 Test Loss = 0.030850094970703 
2016-12-07 12:00:18 -------------------LR------------------- 
2016-12-07 12:00:18 0.000244140625 
2016-12-07 12:00:18 Epoch 121 
2016-12-07 12:03:34 Training Error = 0.53928888888889 
2016-12-07 12:03:34 Training Loss = 0.031329070095486 
2016-12-07 12:03:38 Valid Error = 0.58031606321264 
2016-12-07 12:03:38 Valid Loss = 0.030799744653345 
2016-12-07 12:03:46 Test Error = 0.5708 
2016-12-07 12:03:46 Test Loss = 0.030762409179688 
2016-12-07 12:03:46 -------------------LR------------------- 
2016-12-07 12:03:46 0.000244140625 
2016-12-07 12:03:46 Epoch 122 
2016-12-07 12:06:58 Training Error = 0.5416 
2016-12-07 12:06:58 Training Loss = 0.031308975477431 
2016-12-07 12:07:02 Valid Error = 0.58051610322064 
2016-12-07 12:07:02 Valid Loss = 0.030810119558035 
2016-12-07 12:07:10 Test Error = 0.57 
2016-12-07 12:07:10 Test Loss = 0.030717015380859 
2016-12-07 12:07:10 -------------------LR------------------- 
2016-12-07 12:07:10 0.000244140625 
2016-12-07 12:07:10 Epoch 123 
2016-12-07 12:10:35 Training Error = 0.5392 
2016-12-07 12:10:35 Training Loss = 0.031319888563368 
2016-12-07 12:10:39 Valid Error = 0.58451690338068 
2016-12-07 12:10:39 Valid Loss = 0.031076202819519 
2016-12-07 12:10:47 Test Error = 0.5862 
2016-12-07 12:10:47 Test Loss = 0.031106047607422 
2016-12-07 12:10:47 -------------------LR------------------- 
2016-12-07 12:10:47 0.000244140625 
2016-12-07 12:10:47 Epoch 124 
2016-12-07 12:14:23 Training Error = 0.5412 
2016-12-07 12:14:23 Training Loss = 0.031313391655816 
2016-12-07 12:14:27 Valid Error = 0.56951390278056 
2016-12-07 12:14:27 Valid Loss = 0.030668619568299 
2016-12-07 12:14:35 Test Error = 0.5697 
2016-12-07 12:14:35 Test Loss = 0.030675420654297 
2016-12-07 12:14:35 -------------------LR------------------- 
2016-12-07 12:14:35 0.000244140625 
2016-12-07 12:14:35 Epoch 125 
2016-12-07 12:18:03 Training Error = 0.5374 
2016-12-07 12:18:03 Training Loss = 0.031310677842882 
2016-12-07 12:18:07 Valid Error = 0.57671534306861 
2016-12-07 12:18:07 Valid Loss = 0.030735959364149 
2016-12-07 12:18:15 Test Error = 0.5737 
2016-12-07 12:18:15 Test Loss = 0.030665779052734 
2016-12-07 12:18:15 -------------------LR------------------- 
2016-12-07 12:18:15 0.000244140625 
2016-12-07 12:18:15 Epoch 126 
2016-12-07 12:21:52 Training Error = 0.54104444444444 
2016-12-07 12:21:52 Training Loss = 0.031304441080729 
2016-12-07 12:21:56 Valid Error = 0.57911582316463 
2016-12-07 12:21:56 Valid Loss = 0.030937024154037 
2016-12-07 12:22:04 Test Error = 0.5743 
2016-12-07 12:22:04 Test Loss = 0.030912591308594 
2016-12-07 12:22:04 -------------------LR------------------- 
2016-12-07 12:22:04 0.000244140625 
2016-12-07 12:22:04 Epoch 127 
2016-12-07 12:25:34 Training Error = 0.53824444444444 
2016-12-07 12:25:34 Training Loss = 0.031309781575521 
2016-12-07 12:25:38 Valid Error = 0.57131426285257 
2016-12-07 12:25:38 Valid Loss = 0.03081063365514 
2016-12-07 12:25:46 Test Error = 0.5728 
2016-12-07 12:25:46 Test Loss = 0.030720742675781 
2016-12-07 12:25:46 -------------------LR------------------- 
2016-12-07 12:25:46 0.000244140625 
2016-12-07 12:25:46 Epoch 128 
2016-12-07 12:29:21 Training Error = 0.53957777777778 
2016-12-07 12:29:21 Training Loss = 0.031347501898872 
2016-12-07 12:29:25 Valid Error = 0.57871574314863 
2016-12-07 12:29:25 Valid Loss = 0.030753448093113 
2016-12-07 12:29:33 Test Error = 0.5752 
2016-12-07 12:29:33 Test Loss = 0.030696780273438 
2016-12-07 12:29:33 -------------------LR------------------- 
2016-12-07 12:29:33 0.000244140625 
2016-12-07 12:29:33 Epoch 129 
2016-12-07 12:33:08 Training Error = 0.5416 
2016-12-07 12:33:08 Training Loss = 0.031347847330729 
2016-12-07 12:33:12 Valid Error = 0.58211642328466 
2016-12-07 12:33:12 Valid Loss = 0.030808484958591 
2016-12-07 12:33:20 Test Error = 0.5754 
2016-12-07 12:33:20 Test Loss = 0.030756022216797 
2016-12-07 12:33:20 -------------------LR------------------- 
2016-12-07 12:33:20 0.000244140625 
2016-12-07 12:33:20 Epoch 130 
2016-12-07 12:37:03 Training Error = 0.53817777777778 
2016-12-07 12:37:03 Training Loss = 0.031327873372396 
2016-12-07 12:37:07 Valid Error = 0.5755151030206 
2016-12-07 12:37:07 Valid Loss = 0.030925314722437 
2016-12-07 12:37:15 Test Error = 0.5801 
2016-12-07 12:37:15 Test Loss = 0.030939615234375 
2016-12-07 12:37:15 -------------------LR------------------- 
2016-12-07 12:37:15 0.000244140625 
2016-12-07 12:37:15 Epoch 131 
2016-12-07 12:40:49 Training Error = 0.53975555555556 
2016-12-07 12:40:49 Training Loss = 0.03133125531684 
2016-12-07 12:40:54 Valid Error = 0.5753150630126 
2016-12-07 12:40:54 Valid Loss = 0.030680844923537 
2016-12-07 12:41:02 Test Error = 0.5718 
2016-12-07 12:41:02 Test Loss = 0.030649572509766 
2016-12-07 12:41:02 -------------------LR------------------- 
2016-12-07 12:41:02 0.000244140625 
2016-12-07 12:41:02 Epoch 132 
2016-12-07 12:44:35 Training Error = 0.53826666666667 
2016-12-07 12:44:35 Training Loss = 0.031327728407118 
2016-12-07 12:44:40 Valid Error = 0.5751150230046 
2016-12-07 12:44:40 Valid Loss = 0.030700771384177 
2016-12-07 12:44:48 Test Error = 0.5733 
2016-12-07 12:44:48 Test Loss = 0.030662947998047 
2016-12-07 12:44:48 -------------------LR------------------- 
2016-12-07 12:44:48 0.000244140625 
2016-12-07 12:44:48 Epoch 133 
2016-12-07 12:48:26 Training Error = 0.53886666666667 
2016-12-07 12:48:26 Training Loss = 0.031322091308594 
2016-12-07 12:48:30 Valid Error = 0.57331466293259 
2016-12-07 12:48:30 Valid Loss = 0.030703078690018 
2016-12-07 12:48:38 Test Error = 0.5753 
2016-12-07 12:48:38 Test Loss = 0.030763682617188 
2016-12-07 12:48:38 -------------------LR------------------- 
2016-12-07 12:48:38 0.000244140625 
2016-12-07 12:48:38 Epoch 134 
2016-12-07 12:52:09 Training Error = 0.53811111111111 
2016-12-07 12:52:09 Training Loss = 0.031340069552951 
2016-12-07 12:52:13 Valid Error = 0.57891578315663 
2016-12-07 12:52:13 Valid Loss = 0.030877121781449 
2016-12-07 12:52:21 Test Error = 0.5816 
2016-12-07 12:52:21 Test Loss = 0.030825924560547 
2016-12-07 12:52:21 -------------------LR------------------- 
2016-12-07 12:52:21 0.000244140625 
2016-12-07 12:52:21 Epoch 135 
2016-12-07 12:55:55 Training Error = 0.53873333333333 
2016-12-07 12:55:55 Training Loss = 0.031325823187934 
2016-12-07 12:55:59 Valid Error = 0.57811562312462 
2016-12-07 12:55:59 Valid Loss = 0.030941688857314 
2016-12-07 12:56:07 Test Error = 0.5783 
2016-12-07 12:56:07 Test Loss = 0.030902469726562 
2016-12-07 12:56:07 -------------------LR------------------- 
2016-12-07 12:56:07 0.000244140625 
2016-12-07 12:56:07 Epoch 136 
2016-12-07 12:59:38 Training Error = 0.53815555555556 
2016-12-07 12:59:38 Training Loss = 0.031301366916233 
2016-12-07 12:59:42 Valid Error = 0.57571514302861 
2016-12-07 12:59:42 Valid Loss = 0.030844946983605 
2016-12-07 12:59:50 Test Error = 0.5732 
2016-12-07 12:59:50 Test Loss = 0.030853228759766 
2016-12-07 12:59:50 -------------------LR------------------- 
2016-12-07 12:59:50 0.000244140625 
2016-12-07 12:59:50 Epoch 137 
2016-12-07 13:03:26 Training Error = 0.53846666666667 
2016-12-07 13:03:26 Training Loss = 0.031307593478733 
2016-12-07 13:03:31 Valid Error = 0.57371474294859 
2016-12-07 13:03:31 Valid Loss = 0.030888045168704 
2016-12-07 13:03:39 Test Error = 0.5793 
2016-12-07 13:03:39 Test Loss = 0.031004384033203 
2016-12-07 13:03:39 -------------------LR------------------- 
2016-12-07 13:03:39 0.000244140625 
2016-12-07 13:03:39 Epoch 138 
2016-12-07 13:07:05 Training Error = 0.53937777777778 
2016-12-07 13:07:05 Training Loss = 0.031282634548611 
2016-12-07 13:07:09 Valid Error = 0.57291458291658 
2016-12-07 13:07:09 Valid Loss = 0.030740971467073 
2016-12-07 13:07:17 Test Error = 0.5726 
2016-12-07 13:07:17 Test Loss = 0.030677239013672 
2016-12-07 13:07:17 -------------------LR------------------- 
2016-12-07 13:07:17 0.000244140625 
2016-12-07 13:07:17 Epoch 139 
2016-12-07 13:10:48 Training Error = 0.53988888888889 
2016-12-07 13:10:48 Training Loss = 0.031306803331163 
2016-12-07 13:10:52 Valid Error = 0.57771554310862 
2016-12-07 13:10:52 Valid Loss = 0.030915280160532 
2016-12-07 13:11:00 Test Error = 0.5771 
2016-12-07 13:11:00 Test Loss = 0.030941275146484 
2016-12-07 13:11:00 -------------------LR------------------- 
2016-12-07 13:11:00 0.000244140625 
2016-12-07 13:11:00 Epoch 140 
2016-12-07 13:14:38 Training Error = 0.54142222222222 
2016-12-07 13:14:38 Training Loss = 0.031318566297743 
2016-12-07 13:14:42 Valid Error = 0.5747149429886 
2016-12-07 13:14:42 Valid Loss = 0.030806253230281 
2016-12-07 13:14:50 Test Error = 0.5748 
2016-12-07 13:14:50 Test Loss = 0.030853952392578 
2016-12-07 13:14:50 -------------------LR------------------- 
2016-12-07 13:14:50 0.0001220703125 
2016-12-07 13:14:50 Epoch 141 
2016-12-07 13:18:28 Training Error = 0.53553333333333 
2016-12-07 13:18:28 Training Loss = 0.031218995659722 
2016-12-07 13:18:32 Valid Error = 0.58091618323665 
2016-12-07 13:18:32 Valid Loss = 0.030832248441801 
2016-12-07 13:18:40 Test Error = 0.5766 
2016-12-07 13:18:40 Test Loss = 0.030791095458984 
2016-12-07 13:18:40 -------------------LR------------------- 
2016-12-07 13:18:40 0.0001220703125 
2016-12-07 13:18:40 Epoch 142 
2016-12-07 13:22:06 Training Error = 0.53875555555556 
2016-12-07 13:22:06 Training Loss = 0.03123972531467 
2016-12-07 13:22:10 Valid Error = 0.57991598319664 
2016-12-07 13:22:10 Valid Loss = 0.030900092219172 
2016-12-07 13:22:18 Test Error = 0.571 
2016-12-07 13:22:18 Test Loss = 0.030753389160156 
2016-12-07 13:22:18 -------------------LR------------------- 
2016-12-07 13:22:18 0.0001220703125 
2016-12-07 13:22:18 Epoch 143 
2016-12-07 13:25:50 Training Error = 0.53651111111111 
2016-12-07 13:25:50 Training Loss = 0.031253389485677 
2016-12-07 13:25:54 Valid Error = 0.5745149029806 
2016-12-07 13:25:54 Valid Loss = 0.030639465902915 
2016-12-07 13:26:02 Test Error = 0.5691 
2016-12-07 13:26:02 Test Loss = 0.030647518310547 
2016-12-07 13:26:02 -------------------LR------------------- 
2016-12-07 13:26:02 0.0001220703125 
2016-12-07 13:26:02 Epoch 144 
2016-12-07 13:29:24 Training Error = 0.53744444444444 
2016-12-07 13:29:24 Training Loss = 0.031275728298611 
2016-12-07 13:29:28 Valid Error = 0.57791558311662 
2016-12-07 13:29:28 Valid Loss = 0.030736411106908 
2016-12-07 13:29:36 Test Error = 0.5696 
2016-12-07 13:29:36 Test Loss = 0.03073094921875 
2016-12-07 13:29:36 -------------------LR------------------- 
2016-12-07 13:29:36 0.0001220703125 
2016-12-07 13:29:36 Epoch 145 
2016-12-07 13:33:15 Training Error = 0.53742222222222 
2016-12-07 13:33:15 Training Loss = 0.031260446180556 
2016-12-07 13:33:19 Valid Error = 0.58031606321264 
2016-12-07 13:33:19 Valid Loss = 0.030977422676583 
2016-12-07 13:33:27 Test Error = 0.5758 
2016-12-07 13:33:27 Test Loss = 0.030970993652344 
2016-12-07 13:33:27 -------------------LR------------------- 
2016-12-07 13:33:27 0.0001220703125 
2016-12-07 13:33:27 Epoch 146 
2016-12-07 13:36:58 Training Error = 0.53737777777778 
2016-12-07 13:36:58 Training Loss = 0.031300727647569 
2016-12-07 13:37:02 Valid Error = 0.5745149029806 
2016-12-07 13:37:02 Valid Loss = 0.030778106159382 
2016-12-07 13:37:10 Test Error = 0.5738 
2016-12-07 13:37:10 Test Loss = 0.030772861816406 
2016-12-07 13:37:10 -------------------LR------------------- 
2016-12-07 13:37:10 0.0001220703125 
2016-12-07 13:37:10 Epoch 147 
2016-12-07 13:40:38 Training Error = 0.53624444444444 
2016-12-07 13:40:38 Training Loss = 0.031257195855035 
2016-12-07 13:40:42 Valid Error = 0.57411482296459 
2016-12-07 13:40:42 Valid Loss = 0.030687381797325 
2016-12-07 13:40:50 Test Error = 0.5675 
2016-12-07 13:40:50 Test Loss = 0.030667028320313 
2016-12-07 13:40:50 -------------------LR------------------- 
2016-12-07 13:40:50 0.0001220703125 
2016-12-07 13:40:50 Epoch 148 
2016-12-07 13:44:16 Training Error = 0.53537777777778 
2016-12-07 13:44:16 Training Loss = 0.031236625868056 
2016-12-07 13:44:20 Valid Error = 0.57251450290058 
2016-12-07 13:44:20 Valid Loss = 0.03075588828428 
2016-12-07 13:44:28 Test Error = 0.5725 
2016-12-07 13:44:28 Test Loss = 0.030787302734375 
2016-12-07 13:44:28 -------------------LR------------------- 
2016-12-07 13:44:28 0.0001220703125 
2016-12-07 13:44:28 Epoch 149 
2016-12-07 13:48:06 Training Error = 0.53975555555556 
2016-12-07 13:48:06 Training Loss = 0.031281895453559 
2016-12-07 13:48:10 Valid Error = 0.57331466293259 
2016-12-07 13:48:10 Valid Loss = 0.030847213195129 
2016-12-07 13:48:18 Test Error = 0.5744 
2016-12-07 13:48:18 Test Loss = 0.030868863525391 
2016-12-07 13:48:18 -------------------LR------------------- 
2016-12-07 13:48:18 0.0001220703125 
2016-12-07 13:48:19 Epoch 150 
2016-12-07 13:51:55 Training Error = 0.53971111111111 
2016-12-07 13:51:55 Training Loss = 0.031272464463976 
2016-12-07 13:51:59 Valid Error = 0.56971394278856 
2016-12-07 13:51:59 Valid Loss = 0.030780519051767 
2016-12-07 13:52:07 Test Error = 0.5744 
2016-12-07 13:52:07 Test Loss = 0.030785680908203 
2016-12-07 13:52:07 -------------------LR------------------- 
2016-12-07 13:52:07 0.0001220703125 
2016-12-07 13:52:07 Epoch 151 
2016-12-07 13:55:45 Training Error = 0.53566666666667 
2016-12-07 13:55:45 Training Loss = 0.031278321072049 
2016-12-07 13:55:49 Valid Error = 0.58171634326865 
2016-12-07 13:55:49 Valid Loss = 0.031045245814662 
2016-12-07 13:55:57 Test Error = 0.5814 
2016-12-07 13:55:57 Test Loss = 0.031052194091797 
2016-12-07 13:55:57 -------------------LR------------------- 
2016-12-07 13:55:57 0.0001220703125 
2016-12-07 13:55:57 Epoch 152 
2016-12-07 13:59:26 Training Error = 0.53828888888889 
2016-12-07 13:59:26 Training Loss = 0.031294949598524 
2016-12-07 13:59:30 Valid Error = 0.57391478295659 
2016-12-07 13:59:30 Valid Loss = 0.030799136678182 
2016-12-07 13:59:38 Test Error = 0.5718 
2016-12-07 13:59:38 Test Loss = 0.030694062988281 
2016-12-07 13:59:38 -------------------LR------------------- 
2016-12-07 13:59:38 0.0001220703125 
2016-12-07 13:59:38 Epoch 153 
2016-12-07 14:03:16 Training Error = 0.53868888888889 
2016-12-07 14:03:16 Training Loss = 0.031289349175347 
2016-12-07 14:03:20 Valid Error = 0.57631526305261 
2016-12-07 14:03:20 Valid Loss = 0.030807897348032 
2016-12-07 14:03:28 Test Error = 0.5768 
2016-12-07 14:03:28 Test Loss = 0.030811631347656 
2016-12-07 14:03:28 -------------------LR------------------- 
2016-12-07 14:03:28 0.0001220703125 
2016-12-07 14:03:28 Epoch 154 
2016-12-07 14:06:57 Training Error = 0.53875555555556 
2016-12-07 14:06:57 Training Loss = 0.031268104980469 
2016-12-07 14:07:01 Valid Error = 0.57631526305261 
2016-12-07 14:07:01 Valid Loss = 0.030865679895716 
2016-12-07 14:07:09 Test Error = 0.5799 
2016-12-07 14:07:09 Test Loss = 0.030823021240234 
2016-12-07 14:07:09 -------------------LR------------------- 
2016-12-07 14:07:09 0.0001220703125 
2016-12-07 14:07:09 Epoch 155 
2016-12-07 14:10:42 Training Error = 0.5348 
2016-12-07 14:10:42 Training Loss = 0.031251519965278 
2016-12-07 14:10:46 Valid Error = 0.57591518303661 
2016-12-07 14:10:46 Valid Loss = 0.030642911023817 
2016-12-07 14:10:54 Test Error = 0.5697 
2016-12-07 14:10:54 Test Loss = 0.030581554199219 
2016-12-07 14:10:54 -------------------LR------------------- 
2016-12-07 14:10:54 0.0001220703125 
2016-12-07 14:10:54 Epoch 156 
2016-12-07 14:14:32 Training Error = 0.53631111111111 
2016-12-07 14:14:32 Training Loss = 0.031280705674913 
2016-12-07 14:14:36 Valid Error = 0.57351470294059 
2016-12-07 14:14:36 Valid Loss = 0.030804448706519 
2016-12-07 14:14:44 Test Error = 0.5702 
2016-12-07 14:14:44 Test Loss = 0.030780392822266 
2016-12-07 14:14:44 -------------------LR------------------- 
2016-12-07 14:14:44 0.0001220703125 
2016-12-07 14:14:44 Epoch 157 
2016-12-07 14:18:18 Training Error = 0.53584444444444 
2016-12-07 14:18:18 Training Loss = 0.031259597005208 
2016-12-07 14:18:22 Valid Error = 0.57811562312462 
2016-12-07 14:18:22 Valid Loss = 0.030755183140171 
2016-12-07 14:18:30 Test Error = 0.5694 
2016-12-07 14:18:30 Test Loss = 0.030732154785156 
2016-12-07 14:18:30 -------------------LR------------------- 
2016-12-07 14:18:30 0.0001220703125 
2016-12-07 14:18:30 Epoch 158 
2016-12-07 14:22:00 Training Error = 0.53584444444444 
2016-12-07 14:22:00 Training Loss = 0.031254386827257 
2016-12-07 14:22:04 Valid Error = 0.57291458291658 
2016-12-07 14:22:04 Valid Loss = 0.030853294028892 
2016-12-07 14:22:12 Test Error = 0.5747 
2016-12-07 14:22:12 Test Loss = 0.030781573242187 
2016-12-07 14:22:12 -------------------LR------------------- 
2016-12-07 14:22:12 0.0001220703125 
2016-12-07 14:22:12 Epoch 159 
2016-12-07 14:25:49 Training Error = 0.53793333333333 
2016-12-07 14:25:49 Training Loss = 0.031243251898872 
2016-12-07 14:25:53 Valid Error = 0.57251450290058 
2016-12-07 14:25:53 Valid Loss = 0.030731508172724 
2016-12-07 14:26:01 Test Error = 0.5732 
2016-12-07 14:26:01 Test Loss = 0.030743000244141 
2016-12-07 14:26:01 -------------------LR------------------- 
2016-12-07 14:26:01 0.0001220703125 
2016-12-07 14:26:01 Epoch 160 
2016-12-07 14:29:42 Training Error = 0.53857777777778 
2016-12-07 14:29:42 Training Loss = 0.031264535915799 
2016-12-07 14:29:46 Valid Error = 0.57111422284457 
2016-12-07 14:29:46 Valid Loss = 0.030666002470732 
2016-12-07 14:29:54 Test Error = 0.5748 
2016-12-07 14:29:54 Test Loss = 0.030742375732422 
2016-12-07 14:29:54 -------------------LR------------------- 
2016-12-07 14:29:54 6.103515625e-05 
2016-12-07 14:29:54 Epoch 161 
2016-12-07 14:33:32 Training Error = 0.5348 
2016-12-07 14:33:32 Training Loss = 0.031169658311632 
2016-12-07 14:33:36 Valid Error = 0.57711542308462 
2016-12-07 14:33:36 Valid Loss = 0.030772896925246 
2016-12-07 14:33:45 Test Error = 0.5761 
2016-12-07 14:33:45 Test Loss = 0.030811535644531 
2016-12-07 14:33:45 -------------------LR------------------- 
2016-12-07 14:33:45 6.103515625e-05 
2016-12-07 14:33:45 Epoch 162 
2016-12-07 14:37:22 Training Error = 0.53444444444444 
2016-12-07 14:37:22 Training Loss = 0.03119750640191 
2016-12-07 14:37:26 Valid Error = 0.57231446289258 
2016-12-07 14:37:26 Valid Loss = 0.030858922323202 
2016-12-07 14:37:34 Test Error = 0.5692 
2016-12-07 14:37:34 Test Loss = 0.030702190673828 
2016-12-07 14:37:34 -------------------LR------------------- 
2016-12-07 14:37:34 6.103515625e-05 
2016-12-07 14:37:34 Epoch 163 
2016-12-07 14:41:01 Training Error = 0.53353333333333 
2016-12-07 14:41:01 Training Loss = 0.031218416937934 
2016-12-07 14:41:05 Valid Error = 0.57331466293259 
2016-12-07 14:41:05 Valid Loss = 0.030770211836348 
2016-12-07 14:41:13 Test Error = 0.5705 
2016-12-07 14:41:13 Test Loss = 0.030751232910156 
2016-12-07 14:41:13 -------------------LR------------------- 
2016-12-07 14:41:13 6.103515625e-05 
2016-12-07 14:41:14 Epoch 164 
2016-12-07 14:44:49 Training Error = 0.53528888888889 
2016-12-07 14:44:49 Training Loss = 0.031215498914931 
2016-12-07 14:44:53 Valid Error = 0.57831566313263 
2016-12-07 14:44:53 Valid Loss = 0.030963119270638 
2016-12-07 14:45:01 Test Error = 0.577 
2016-12-07 14:45:01 Test Loss = 0.030930044433594 
2016-12-07 14:45:01 -------------------LR------------------- 
2016-12-07 14:45:01 6.103515625e-05 
2016-12-07 14:45:01 Epoch 165 
2016-12-07 14:48:31 Training Error = 0.53702222222222 
2016-12-07 14:48:31 Training Loss = 0.031214260199653 
2016-12-07 14:48:36 Valid Error = 0.57031406281256 
2016-12-07 14:48:36 Valid Loss = 0.030707596636187 
2016-12-07 14:48:44 Test Error = 0.5692 
2016-12-07 14:48:44 Test Loss = 0.030709794433594 
2016-12-07 14:48:44 -------------------LR------------------- 
2016-12-07 14:48:44 6.103515625e-05 
2016-12-07 14:48:44 Epoch 166 
2016-12-07 14:52:19 Training Error = 0.53584444444444 
2016-12-07 14:52:19 Training Loss = 0.03120771750217 
2016-12-07 14:52:23 Valid Error = 0.57171434286857 
2016-12-07 14:52:23 Valid Loss = 0.030739300142916 
2016-12-07 14:52:31 Test Error = 0.5706 
2016-12-07 14:52:31 Test Loss = 0.030711875976563 
2016-12-07 14:52:31 -------------------LR------------------- 
2016-12-07 14:52:31 6.103515625e-05 
2016-12-07 14:52:31 Epoch 167 
2016-12-07 14:55:51 Training Error = 0.53677777777778 
2016-12-07 14:55:51 Training Loss = 0.03121649593099 
2016-12-07 14:55:55 Valid Error = 0.57251450290058 
2016-12-07 14:55:55 Valid Loss = 0.030720740326753 
2016-12-07 14:56:03 Test Error = 0.5738 
2016-12-07 14:56:03 Test Loss = 0.030711951416016 
2016-12-07 14:56:03 -------------------LR------------------- 
2016-12-07 14:56:03 6.103515625e-05 
2016-12-07 14:56:03 Epoch 168 
2016-12-07 14:59:37 Training Error = 0.53844444444444 
2016-12-07 14:59:37 Training Loss = 0.031225827256944 
2016-12-07 14:59:41 Valid Error = 0.5751150230046 
2016-12-07 14:59:41 Valid Loss = 0.030767297196611 
2016-12-07 14:59:49 Test Error = 0.5731 
2016-12-07 14:59:49 Test Loss = 0.030756983886719 
2016-12-07 14:59:49 -------------------LR------------------- 
2016-12-07 14:59:49 6.103515625e-05 
2016-12-07 14:59:49 Epoch 169 
2016-12-07 15:03:20 Training Error = 0.53455555555556 
2016-12-07 15:03:20 Training Loss = 0.031224175130208 
2016-12-07 15:03:24 Valid Error = 0.57431486297259 
2016-12-07 15:03:24 Valid Loss = 0.030767319867719 
2016-12-07 15:03:32 Test Error = 0.5685 
2016-12-07 15:03:32 Test Loss = 0.030706498291016 
2016-12-07 15:03:32 -------------------LR------------------- 
2016-12-07 15:03:32 6.103515625e-05 
2016-12-07 15:03:32 Epoch 170 
2016-12-07 15:07:14 Training Error = 0.535 
2016-12-07 15:07:14 Training Loss = 0.031239815429687 
2016-12-07 15:07:18 Valid Error = 0.57371474294859 
2016-12-07 15:07:18 Valid Loss = 0.030550129797278 
2016-12-07 15:07:26 Test Error = 0.5722 
2016-12-07 15:07:26 Test Loss = 0.030551459716797 
2016-12-07 15:07:26 -------------------LR------------------- 
2016-12-07 15:07:26 6.103515625e-05 
2016-12-07 15:07:26 Epoch 171 
2016-12-07 15:11:03 Training Error = 0.53395555555556 
2016-12-07 15:11:03 Training Loss = 0.031236533799913 
2016-12-07 15:11:07 Valid Error = 0.57431486297259 
2016-12-07 15:11:07 Valid Loss = 0.030856153370167 
2016-12-07 15:11:15 Test Error = 0.5759 
2016-12-07 15:11:15 Test Loss = 0.030787951416016 
2016-12-07 15:11:15 -------------------LR------------------- 
2016-12-07 15:11:15 6.103515625e-05 
2016-12-07 15:11:15 Epoch 172 
2016-12-07 15:14:52 Training Error = 0.53615555555556 
2016-12-07 15:14:52 Training Loss = 0.031222986599392 
2016-12-07 15:14:56 Valid Error = 0.57111422284457 
2016-12-07 15:14:56 Valid Loss = 0.030737766175355 
2016-12-07 15:15:04 Test Error = 0.5705 
2016-12-07 15:15:04 Test Loss = 0.03075378515625 
2016-12-07 15:15:04 -------------------LR------------------- 
2016-12-07 15:15:04 6.103515625e-05 
2016-12-07 15:15:04 Epoch 173 
2016-12-07 15:18:32 Training Error = 0.53397777777778 
2016-12-07 15:18:32 Training Loss = 0.03121381515842 
2016-12-07 15:18:36 Valid Error = 0.56371274254851 
2016-12-07 15:18:36 Valid Loss = 0.030558953086387 
2016-12-07 15:18:44 Test Error = 0.5687 
2016-12-07 15:18:44 Test Loss = 0.030555526855469 
2016-12-07 15:18:44 -------------------LR------------------- 
2016-12-07 15:18:44 6.103515625e-05 
2016-12-07 15:18:45 Epoch 174 
2016-12-07 15:22:23 Training Error = 0.53366666666667 
2016-12-07 15:22:23 Training Loss = 0.031249165418837 
2016-12-07 15:22:27 Valid Error = 0.57591518303661 
2016-12-07 15:22:27 Valid Loss = 0.030736122338647 
2016-12-07 15:22:35 Test Error = 0.5749 
2016-12-07 15:22:35 Test Loss = 0.030812502929688 
2016-12-07 15:22:35 -------------------LR------------------- 
2016-12-07 15:22:35 6.103515625e-05 
2016-12-07 15:22:35 Epoch 175 
2016-12-07 15:26:05 Training Error = 0.53533333333333 
2016-12-07 15:26:05 Training Loss = 0.031219729709201 
2016-12-07 15:26:09 Valid Error = 0.5753150630126 
2016-12-07 15:26:09 Valid Loss = 0.030754162820535 
2016-12-07 15:26:17 Test Error = 0.5712 
2016-12-07 15:26:17 Test Loss = 0.030705783447266 
2016-12-07 15:26:17 -------------------LR------------------- 
2016-12-07 15:26:17 6.103515625e-05 
2016-12-07 15:26:17 Epoch 176 
2016-12-07 15:29:47 Training Error = 0.53455555555556 
2016-12-07 15:29:47 Training Loss = 0.031220768174913 
2016-12-07 15:29:51 Valid Error = 0.57251450290058 
2016-12-07 15:29:51 Valid Loss = 0.030730045402825 
2016-12-07 15:29:59 Test Error = 0.5715 
2016-12-07 15:29:59 Test Loss = 0.030718228759766 
2016-12-07 15:29:59 -------------------LR------------------- 
2016-12-07 15:29:59 6.103515625e-05 
2016-12-07 15:29:59 Epoch 177 
2016-12-07 15:33:27 Training Error = 0.53513333333333 
2016-12-07 15:33:27 Training Loss = 0.031230344184028 
2016-12-07 15:33:31 Valid Error = 0.56871374274855 
2016-12-07 15:33:31 Valid Loss = 0.030726985272871 
2016-12-07 15:33:39 Test Error = 0.5705 
2016-12-07 15:33:39 Test Loss = 0.03070463671875 
2016-12-07 15:33:39 -------------------LR------------------- 
2016-12-07 15:33:39 6.103515625e-05 
2016-12-07 15:33:39 Epoch 178 
2016-12-07 15:37:12 Training Error = 0.53486666666667 
2016-12-07 15:37:12 Training Loss = 0.031223119900174 
2016-12-07 15:37:16 Valid Error = 0.57331466293259 
2016-12-07 15:37:16 Valid Loss = 0.030718382642897 
2016-12-07 15:37:24 Test Error = 0.5709 
2016-12-07 15:37:24 Test Loss = 0.030688689941406 
2016-12-07 15:37:24 -------------------LR------------------- 
2016-12-07 15:37:24 6.103515625e-05 
2016-12-07 15:37:24 Epoch 179 
2016-12-07 15:40:56 Training Error = 0.53528888888889 
2016-12-07 15:40:56 Training Loss = 0.031228969346788 
2016-12-07 15:41:00 Valid Error = 0.58131626325265 
2016-12-07 15:41:00 Valid Loss = 0.030969304620539 
2016-12-07 15:41:08 Test Error = 0.5797 
2016-12-07 15:41:08 Test Loss = 0.030957872558594 
2016-12-07 15:41:08 -------------------LR------------------- 
2016-12-07 15:41:08 6.103515625e-05 
2016-12-07 15:41:08 Epoch 180 
2016-12-07 15:44:48 Training Error = 0.53266666666667 
2016-12-07 15:44:48 Training Loss = 0.031227550998264 
2016-12-07 15:44:52 Valid Error = 0.57951590318064 
2016-12-07 15:44:52 Valid Loss = 0.031030577089296 
2016-12-07 15:45:00 Test Error = 0.5771 
2016-12-07 15:45:00 Test Loss = 0.030883938964844 
2016-12-07 15:45:00 -------------------LR------------------- 
2016-12-07 15:45:00 3.0517578125e-05 
2016-12-07 15:45:00 Epoch 181 
2016-12-07 15:48:26 Training Error = 0.5336 
2016-12-07 15:48:26 Training Loss = 0.031156674913194 
2016-12-07 15:48:30 Valid Error = 0.5751150230046 
2016-12-07 15:48:30 Valid Loss = 0.030703748520982 
2016-12-07 15:48:38 Test Error = 0.5703 
2016-12-07 15:48:38 Test Loss = 0.030664607910156 
2016-12-07 15:48:38 -------------------LR------------------- 
2016-12-07 15:48:38 3.0517578125e-05 
2016-12-07 15:48:38 Epoch 182 
2016-12-07 15:52:04 Training Error = 0.53395555555556 
2016-12-07 15:52:04 Training Loss = 0.031171142632378 
2016-12-07 15:52:08 Valid Error = 0.57251450290058 
2016-12-07 15:52:08 Valid Loss = 0.03074140920657 
2016-12-07 15:52:16 Test Error = 0.5726 
2016-12-07 15:52:16 Test Loss = 0.030759491699219 
2016-12-07 15:52:16 -------------------LR------------------- 
2016-12-07 15:52:16 3.0517578125e-05 
2016-12-07 15:52:17 Epoch 183 
2016-12-07 15:55:47 Training Error = 0.5328 
2016-12-07 15:55:47 Training Loss = 0.031165854871962 
2016-12-07 15:55:51 Valid Error = 0.57371474294859 
2016-12-07 15:55:51 Valid Loss = 0.030737470971949 
2016-12-07 15:55:59 Test Error = 0.5742 
2016-12-07 15:55:59 Test Loss = 0.030675784179687 
2016-12-07 15:55:59 -------------------LR------------------- 
2016-12-07 15:55:59 3.0517578125e-05 
2016-12-07 15:55:59 Epoch 184 
2016-12-07 15:59:34 Training Error = 0.53446666666667 
2016-12-07 15:59:34 Training Loss = 0.031176487684462 
2016-12-07 15:59:38 Valid Error = 0.57071414282857 
2016-12-07 15:59:38 Valid Loss = 0.03062150459786 
2016-12-07 15:59:46 Test Error = 0.5686 
2016-12-07 15:59:46 Test Loss = 0.030607384521484 
2016-12-07 15:59:46 -------------------LR------------------- 
2016-12-07 15:59:46 3.0517578125e-05 
2016-12-07 15:59:46 Epoch 185 
2016-12-07 16:03:15 Training Error = 0.53393333333333 
2016-12-07 16:03:15 Training Loss = 0.031174856770833 
2016-12-07 16:03:19 Valid Error = 0.57131426285257 
2016-12-07 16:03:19 Valid Loss = 0.030607862695215 
2016-12-07 16:03:27 Test Error = 0.573 
2016-12-07 16:03:27 Test Loss = 0.030615405273438 
2016-12-07 16:03:27 -------------------LR------------------- 
2016-12-07 16:03:27 3.0517578125e-05 
2016-12-07 16:03:28 Epoch 186 
2016-12-07 16:07:07 Training Error = 0.535 
2016-12-07 16:07:07 Training Loss = 0.031217499511719 
2016-12-07 16:07:11 Valid Error = 0.57591518303661 
2016-12-07 16:07:11 Valid Loss = 0.030911717308617 
2016-12-07 16:07:19 Test Error = 0.5777 
2016-12-07 16:07:19 Test Loss = 0.030877331542969 
2016-12-07 16:07:19 -------------------LR------------------- 
2016-12-07 16:07:19 3.0517578125e-05 
2016-12-07 16:07:19 Epoch 187 
2016-12-07 16:10:48 Training Error = 0.53504444444444 
2016-12-07 16:10:48 Training Loss = 0.031198129937066 
2016-12-07 16:10:53 Valid Error = 0.57151430286057 
2016-12-07 16:10:53 Valid Loss = 0.030680647051348 
2016-12-07 16:11:00 Test Error = 0.574 
2016-12-07 16:11:00 Test Loss = 0.030714080078125 
2016-12-07 16:11:00 -------------------LR------------------- 
2016-12-07 16:11:00 3.0517578125e-05 
2016-12-07 16:11:01 Epoch 188 
2016-12-07 16:14:39 Training Error = 0.53508888888889 
2016-12-07 16:14:39 Training Loss = 0.031174327256944 
2016-12-07 16:14:43 Valid Error = 0.57651530306061 
2016-12-07 16:14:43 Valid Loss = 0.030867266667058 
2016-12-07 16:14:51 Test Error = 0.5792 
2016-12-07 16:14:51 Test Loss = 0.030922126464844 
2016-12-07 16:14:51 -------------------LR------------------- 
2016-12-07 16:14:51 3.0517578125e-05 
2016-12-07 16:14:51 Epoch 189 
2016-12-07 16:18:22 Training Error = 0.53233333333333 
2016-12-07 16:18:22 Training Loss = 0.031191173882378 
2016-12-07 16:18:26 Valid Error = 0.57251450290058 
2016-12-07 16:18:26 Valid Loss = 0.030609309994565 
2016-12-07 16:18:34 Test Error = 0.5709 
2016-12-07 16:18:34 Test Loss = 0.030624934814453 
2016-12-07 16:18:34 -------------------LR------------------- 
2016-12-07 16:18:34 3.0517578125e-05 
2016-12-07 16:18:34 Epoch 190 
2016-12-07 16:22:04 Training Error = 0.53426666666667 
2016-12-07 16:22:04 Training Loss = 0.031189298882378 
2016-12-07 16:22:08 Valid Error = 0.57691538307662 
2016-12-07 16:22:08 Valid Loss = 0.030895333904217 
2016-12-07 16:22:16 Test Error = 0.5794 
2016-12-07 16:22:16 Test Loss = 0.030917287841797 
2016-12-07 16:22:16 -------------------LR------------------- 
2016-12-07 16:22:16 3.0517578125e-05 
2016-12-07 16:22:16 Epoch 191 
2016-12-07 16:25:52 Training Error = 0.53562222222222 
2016-12-07 16:25:52 Training Loss = 0.031218202202691 
2016-12-07 16:25:56 Valid Error = 0.57611522304461 
2016-12-07 16:25:56 Valid Loss = 0.030902110820293 
2016-12-07 16:26:05 Test Error = 0.5768 
2016-12-07 16:26:05 Test Loss = 0.030877301757813 
2016-12-07 16:26:05 -------------------LR------------------- 
2016-12-07 16:26:05 3.0517578125e-05 
2016-12-07 16:26:05 Epoch 192 
2016-12-07 16:29:33 Training Error = 0.53562222222222 
2016-12-07 16:29:33 Training Loss = 0.031216939670139 
2016-12-07 16:29:37 Valid Error = 0.57751550310062 
2016-12-07 16:29:37 Valid Loss = 0.03072764572727 
2016-12-07 16:29:45 Test Error = 0.5689 
2016-12-07 16:29:45 Test Loss = 0.030769115478516 
2016-12-07 16:29:45 -------------------LR------------------- 
2016-12-07 16:29:45 3.0517578125e-05 
2016-12-07 16:29:45 Epoch 193 
2016-12-07 16:33:20 Training Error = 0.5352 
2016-12-07 16:33:20 Training Loss = 0.031209080674913 
2016-12-07 16:33:24 Valid Error = 0.57751550310062 
2016-12-07 16:33:24 Valid Loss = 0.030869086517181 
2016-12-07 16:33:32 Test Error = 0.5723 
2016-12-07 16:33:32 Test Loss = 0.030825982910156 
2016-12-07 16:33:32 -------------------LR------------------- 
2016-12-07 16:33:32 3.0517578125e-05 
2016-12-07 16:33:32 Epoch 194 
2016-12-07 16:37:03 Training Error = 0.53595555555556 
2016-12-07 16:37:03 Training Loss = 0.031180767361111 
2016-12-07 16:37:07 Valid Error = 0.57391478295659 
2016-12-07 16:37:07 Valid Loss = 0.030651067469325 
2016-12-07 16:37:15 Test Error = 0.5672 
2016-12-07 16:37:15 Test Loss = 0.030600344482422 
2016-12-07 16:37:15 -------------------LR------------------- 
2016-12-07 16:37:15 3.0517578125e-05 
2016-12-07 16:37:15 Epoch 195 
2016-12-07 16:40:54 Training Error = 0.53662222222222 
2016-12-07 16:40:54 Training Loss = 0.031195646864149 
2016-12-07 16:40:58 Valid Error = 0.57751550310062 
2016-12-07 16:40:58 Valid Loss = 0.030689624748283 
2016-12-07 16:41:06 Test Error = 0.571 
2016-12-07 16:41:06 Test Loss = 0.030702520996094 
2016-12-07 16:41:06 -------------------LR------------------- 
2016-12-07 16:41:06 3.0517578125e-05 
2016-12-07 16:41:06 Epoch 196 
2016-12-07 16:44:35 Training Error = 0.53302222222222 
2016-12-07 16:44:35 Training Loss = 0.031171225260417 
2016-12-07 16:44:39 Valid Error = 0.57591518303661 
2016-12-07 16:44:39 Valid Loss = 0.030707350673916 
2016-12-07 16:44:47 Test Error = 0.5713 
2016-12-07 16:44:47 Test Loss = 0.03069334765625 
2016-12-07 16:44:47 -------------------LR------------------- 
2016-12-07 16:44:47 3.0517578125e-05 
2016-12-07 16:44:47 Epoch 197 
2016-12-07 16:48:17 Training Error = 0.53433333333333 
2016-12-07 16:48:17 Training Loss = 0.031204988064236 
2016-12-07 16:48:21 Valid Error = 0.56891378275655 
2016-12-07 16:48:21 Valid Loss = 0.030577299268507 
2016-12-07 16:48:29 Test Error = 0.5666 
2016-12-07 16:48:29 Test Loss = 0.030519976318359 
2016-12-07 16:48:29 -------------------LR------------------- 
2016-12-07 16:48:29 3.0517578125e-05 
2016-12-07 16:48:29 Epoch 198 
2016-12-07 16:51:59 Training Error = 0.53262222222222 
2016-12-07 16:51:59 Training Loss = 0.031185958007813 
2016-12-07 16:52:03 Valid Error = 0.57011402280456 
2016-12-07 16:52:03 Valid Loss = 0.030705158643018 
2016-12-07 16:52:11 Test Error = 0.5722 
2016-12-07 16:52:11 Test Loss = 0.030691973388672 
2016-12-07 16:52:11 -------------------LR------------------- 
2016-12-07 16:52:11 3.0517578125e-05 
2016-12-07 16:52:11 Epoch 199 
2016-12-07 16:55:45 Training Error = 0.53735555555556 
2016-12-07 16:55:45 Training Loss = 0.031209650770399 
2016-12-07 16:55:49 Valid Error = 0.56911382276455 
2016-12-07 16:55:49 Valid Loss = 0.030582846571669 
2016-12-07 16:55:57 Test Error = 0.5707 
2016-12-07 16:55:57 Test Loss = 0.030608020263672 
2016-12-07 16:55:57 -------------------LR------------------- 
2016-12-07 16:55:57 3.0517578125e-05 
2016-12-07 16:55:57 Epoch 200 
2016-12-07 16:59:30 Training Error = 0.53444444444444 
2016-12-07 16:59:30 Training Loss = 0.031198024305556 
2016-12-07 16:59:34 Valid Error = 0.57111422284457 
2016-12-07 16:59:34 Valid Loss = 0.030581962328539 
2016-12-07 16:59:42 Test Error = 0.5721 
2016-12-07 16:59:42 Test Loss = 0.030617226318359 
2016-12-07 16:59:42 -------------------LR------------------- 
2016-12-07 16:59:42 1.52587890625e-05 
2016-12-07 16:59:42 Epoch 201 
2016-12-07 17:03:13 Training Error = 0.53297777777778 
2016-12-07 17:03:13 Training Loss = 0.031143291612413 
2016-12-07 17:03:17 Valid Error = 0.57911582316463 
2016-12-07 17:03:17 Valid Loss = 0.030926582081105 
2016-12-07 17:03:25 Test Error = 0.5783 
2016-12-07 17:03:25 Test Loss = 0.030885789550781 
2016-12-07 17:03:25 -------------------LR------------------- 
2016-12-07 17:03:25 1.52587890625e-05 
2016-12-07 17:03:25 Epoch 202 
2016-12-07 17:06:57 Training Error = 0.53084444444444 
2016-12-07 17:06:57 Training Loss = 0.031126629720052 
2016-12-07 17:07:01 Valid Error = 0.57231446289258 
2016-12-07 17:07:01 Valid Loss = 0.030586788453493 
2016-12-07 17:07:09 Test Error = 0.5689 
2016-12-07 17:07:09 Test Loss = 0.030556973876953 
2016-12-07 17:07:09 -------------------LR------------------- 
2016-12-07 17:07:09 1.52587890625e-05 
2016-12-07 17:07:10 Epoch 203 
2016-12-07 17:10:48 Training Error = 0.53184444444444 
2016-12-07 17:10:48 Training Loss = 0.031166731770833 
2016-12-07 17:10:52 Valid Error = 0.57071414282857 
2016-12-07 17:10:52 Valid Loss = 0.030727281502694 
2016-12-07 17:11:00 Test Error = 0.5751 
2016-12-07 17:11:00 Test Loss = 0.03075532421875 
2016-12-07 17:11:00 -------------------LR------------------- 
2016-12-07 17:11:00 1.52587890625e-05 
2016-12-07 17:11:00 Epoch 204 
2016-12-07 17:14:31 Training Error = 0.53375555555556 
2016-12-07 17:14:31 Training Loss = 0.031152716471354 
2016-12-07 17:14:35 Valid Error = 0.57671534306861 
2016-12-07 17:14:35 Valid Loss = 0.030853624520517 
2016-12-07 17:14:44 Test Error = 0.5762 
2016-12-07 17:14:44 Test Loss = 0.030864968994141 
2016-12-07 17:14:44 -------------------LR------------------- 
2016-12-07 17:14:44 1.52587890625e-05 
2016-12-07 17:14:44 Epoch 205 
2016-12-07 17:18:12 Training Error = 0.53237777777778 
2016-12-07 17:18:12 Training Loss = 0.031173872884115 
2016-12-07 17:18:16 Valid Error = 0.57391478295659 
2016-12-07 17:18:16 Valid Loss = 0.030715691781625 
2016-12-07 17:18:24 Test Error = 0.5726 
2016-12-07 17:18:24 Test Loss = 0.030647481445313 
2016-12-07 17:18:24 -------------------LR------------------- 
2016-12-07 17:18:24 1.52587890625e-05 
2016-12-07 17:18:24 Epoch 206 
2016-12-07 17:21:54 Training Error = 0.5332 
2016-12-07 17:21:54 Training Loss = 0.031150858940972 
2016-12-07 17:21:58 Valid Error = 0.57291458291658 
2016-12-07 17:21:58 Valid Loss = 0.030859006264565 
2016-12-07 17:22:06 Test Error = 0.5731 
2016-12-07 17:22:06 Test Loss = 0.030802634277344 
2016-12-07 17:22:06 -------------------LR------------------- 
2016-12-07 17:22:06 1.52587890625e-05 
2016-12-07 17:22:06 Epoch 207 
2016-12-07 17:25:42 Training Error = 0.53475555555556 
2016-12-07 17:25:42 Training Loss = 0.031188259982639 
2016-12-07 17:25:46 Valid Error = 0.56671334266853 
2016-12-07 17:25:46 Valid Loss = 0.030579867226113 
2016-12-07 17:25:54 Test Error = 0.5697 
2016-12-07 17:25:54 Test Loss = 0.0305603984375 
2016-12-07 17:25:54 -------------------LR------------------- 
2016-12-07 17:25:54 1.52587890625e-05 
2016-12-07 17:25:54 Epoch 208 
2016-12-07 17:29:24 Training Error = 0.53126666666667 
2016-12-07 17:29:24 Training Loss = 0.031159885579427 
2016-12-07 17:29:28 Valid Error = 0.56571314262853 
2016-12-07 17:29:28 Valid Loss = 0.030499698661552 
2016-12-07 17:29:36 Test Error = 0.5643 
2016-12-07 17:29:36 Test Loss = 0.030484987304687 
2016-12-07 17:29:36 -------------------LR------------------- 
2016-12-07 17:29:36 1.52587890625e-05 
2016-12-07 17:29:36 Epoch 209 
2016-12-07 17:33:11 Training Error = 0.53213333333333 
2016-12-07 17:33:11 Training Loss = 0.031156092556424 
2016-12-07 17:33:15 Valid Error = 0.57331466293259 
2016-12-07 17:33:15 Valid Loss = 0.03074564153509 
2016-12-07 17:33:23 Test Error = 0.5746 
2016-12-07 17:33:23 Test Loss = 0.030723832763672 
2016-12-07 17:33:23 -------------------LR------------------- 
2016-12-07 17:33:23 1.52587890625e-05 
2016-12-07 17:33:23 Epoch 210 
2016-12-07 17:37:03 Training Error = 0.53562222222222 
2016-12-07 17:37:03 Training Loss = 0.031197137641059 
2016-12-07 17:37:07 Valid Error = 0.57191438287658 
2016-12-07 17:37:07 Valid Loss = 0.030740653333998 
2016-12-07 17:37:15 Test Error = 0.5682 
2016-12-07 17:37:15 Test Loss = 0.030671573974609 
2016-12-07 17:37:15 -------------------LR------------------- 
2016-12-07 17:37:15 1.52587890625e-05 
2016-12-07 17:37:15 Epoch 211 
2016-12-07 17:40:52 Training Error = 0.537 
2016-12-07 17:40:52 Training Loss = 0.031227274902344 
2016-12-07 17:40:56 Valid Error = 0.57151430286057 
2016-12-07 17:40:56 Valid Loss = 0.030646972210981 
2016-12-07 17:41:04 Test Error = 0.571 
2016-12-07 17:41:04 Test Loss = 0.030609998291016 
2016-12-07 17:41:04 -------------------LR------------------- 
2016-12-07 17:41:04 1.52587890625e-05 
2016-12-07 17:41:04 Epoch 212 
2016-12-07 17:44:37 Training Error = 0.53482222222222 
2016-12-07 17:44:37 Training Loss = 0.03117128108724 
2016-12-07 17:44:41 Valid Error = 0.5749149829966 
2016-12-07 17:44:41 Valid Loss = 0.030766713165803 
2016-12-07 17:44:49 Test Error = 0.5716 
2016-12-07 17:44:49 Test Loss = 0.030791011474609 
2016-12-07 17:44:49 -------------------LR------------------- 
2016-12-07 17:44:49 1.52587890625e-05 
2016-12-07 17:44:49 Epoch 213 
2016-12-07 17:48:26 Training Error = 0.53577777777778 
2016-12-07 17:48:26 Training Loss = 0.031210294596354 
2016-12-07 17:48:30 Valid Error = 0.57031406281256 
2016-12-07 17:48:30 Valid Loss = 0.030523680358581 
2016-12-07 17:48:38 Test Error = 0.5709 
2016-12-07 17:48:38 Test Loss = 0.030608820068359 
2016-12-07 17:48:38 -------------------LR------------------- 
2016-12-07 17:48:38 1.52587890625e-05 
2016-12-07 17:48:38 Epoch 214 
2016-12-07 17:52:08 Training Error = 0.53426666666667 
2016-12-07 17:52:08 Training Loss = 0.031182309136285 
2016-12-07 17:52:12 Valid Error = 0.5749149829966 
2016-12-07 17:52:12 Valid Loss = 0.030771383922008 
2016-12-07 17:52:20 Test Error = 0.5746 
2016-12-07 17:52:20 Test Loss = 0.030743614746094 
2016-12-07 17:52:20 -------------------LR------------------- 
2016-12-07 17:52:20 1.52587890625e-05 
2016-12-07 17:52:20 Epoch 215 
2016-12-07 17:55:58 Training Error = 0.53262222222222 
2016-12-07 17:55:58 Training Loss = 0.031159223578559 
2016-12-07 17:56:02 Valid Error = 0.57131426285257 
2016-12-07 17:56:02 Valid Loss = 0.030645695356978 
2016-12-07 17:56:10 Test Error = 0.571 
2016-12-07 17:56:10 Test Loss = 0.030677852294922 
2016-12-07 17:56:10 -------------------LR------------------- 
2016-12-07 17:56:10 1.52587890625e-05 
2016-12-07 17:56:10 Epoch 216 
2016-12-07 17:59:43 Training Error = 0.53546666666667 
2016-12-07 17:59:43 Training Loss = 0.031205656629774 
2016-12-07 17:59:47 Valid Error = 0.57631526305261 
2016-12-07 17:59:47 Valid Loss = 0.030721901977172 
2016-12-07 17:59:55 Test Error = 0.571 
2016-12-07 17:59:55 Test Loss = 0.030667405029297 
2016-12-07 17:59:55 -------------------LR------------------- 
2016-12-07 17:59:55 1.52587890625e-05 
2016-12-07 17:59:55 Epoch 217 
2016-12-07 18:03:29 Training Error = 0.53413333333333 
2016-12-07 18:03:29 Training Loss = 0.031191197862413 
2016-12-07 18:03:33 Valid Error = 0.57331466293259 
2016-12-07 18:03:33 Valid Loss = 0.030795854760033 
2016-12-07 18:03:41 Test Error = 0.572 
2016-12-07 18:03:41 Test Loss = 0.030753625488281 
2016-12-07 18:03:41 -------------------LR------------------- 
2016-12-07 18:03:41 1.52587890625e-05 
2016-12-07 18:03:41 Epoch 218 
2016-12-07 18:07:16 Training Error = 0.53128888888889 
2016-12-07 18:07:16 Training Loss = 0.031168987087674 
2016-12-07 18:07:20 Valid Error = 0.57311462292458 
2016-12-07 18:07:20 Valid Loss = 0.030702597528192 
2016-12-07 18:07:28 Test Error = 0.5716 
2016-12-07 18:07:28 Test Loss = 0.030719150634766 
2016-12-07 18:07:28 -------------------LR------------------- 
2016-12-07 18:07:28 1.52587890625e-05 
2016-12-07 18:07:28 Epoch 219 
2016-12-07 18:10:55 Training Error = 0.53195555555556 
2016-12-07 18:10:55 Training Loss = 0.031202584147135 
2016-12-07 18:10:59 Valid Error = 0.57651530306061 
2016-12-07 18:10:59 Valid Loss = 0.030865334297677 
2016-12-07 18:11:07 Test Error = 0.5753 
2016-12-07 18:11:07 Test Loss = 0.030815450439453 
2016-12-07 18:11:07 -------------------LR------------------- 
2016-12-07 18:11:07 1.52587890625e-05 
2016-12-07 18:11:07 Epoch 220 
2016-12-07 18:14:51 Training Error = 0.53522222222222 
2016-12-07 18:14:51 Training Loss = 0.031189281575521 
2016-12-07 18:14:55 Valid Error = 0.5751150230046 
2016-12-07 18:14:55 Valid Loss = 0.030784281264663 
2016-12-07 18:15:03 Test Error = 0.5694 
2016-12-07 18:15:03 Test Loss = 0.030764900146484 
2016-12-07 18:15:03 -------------------LR------------------- 
2016-12-07 18:15:03 7.62939453125e-06 
2016-12-07 18:15:03 Epoch 221 
2016-12-07 18:18:39 Training Error = 0.53355555555556 
2016-12-07 18:18:39 Training Loss = 0.031134636447483 
2016-12-07 18:18:43 Valid Error = 0.57211442288458 
2016-12-07 18:18:43 Valid Loss = 0.030694043327507 
2016-12-07 18:18:51 Test Error = 0.5698 
2016-12-07 18:18:51 Test Loss = 0.030665629882812 
2016-12-07 18:18:51 -------------------LR------------------- 
2016-12-07 18:18:51 7.62939453125e-06 
2016-12-07 18:18:51 Epoch 222 
2016-12-07 18:22:27 Training Error = 0.53122222222222 
2016-12-07 18:22:27 Training Loss = 0.03112532671441 
2016-12-07 18:22:31 Valid Error = 0.57691538307662 
2016-12-07 18:22:31 Valid Loss = 0.030674017267267 
2016-12-07 18:22:39 Test Error = 0.569 
2016-12-07 18:22:39 Test Loss = 0.030693807128906 
2016-12-07 18:22:39 -------------------LR------------------- 
2016-12-07 18:22:39 7.62939453125e-06 
2016-12-07 18:22:39 Epoch 223 
2016-12-07 18:26:08 Training Error = 0.53237777777778 
2016-12-07 18:26:08 Training Loss = 0.031117985134549 
2016-12-07 18:26:12 Valid Error = 0.57151430286057 
2016-12-07 18:26:12 Valid Loss = 0.030603530527109 
2016-12-07 18:26:20 Test Error = 0.5697 
2016-12-07 18:26:20 Test Loss = 0.030681095703125 
2016-12-07 18:26:20 -------------------LR------------------- 
2016-12-07 18:26:20 7.62939453125e-06 
2016-12-07 18:26:20 Epoch 224 
2016-12-07 18:29:59 Training Error = 0.5298 
2016-12-07 18:29:59 Training Loss = 0.031152145019531 
2016-12-07 18:30:03 Valid Error = 0.57051410282056 
2016-12-07 18:30:03 Valid Loss = 0.030663419058707 
2016-12-07 18:30:11 Test Error = 0.5717 
2016-12-07 18:30:11 Test Loss = 0.030583661865234 
2016-12-07 18:30:11 -------------------LR------------------- 
2016-12-07 18:30:11 7.62939453125e-06 
2016-12-07 18:30:11 Epoch 225 
2016-12-07 18:33:37 Training Error = 0.53275555555556 
2016-12-07 18:33:37 Training Loss = 0.031167888671875 
2016-12-07 18:33:41 Valid Error = 0.57211442288458 
2016-12-07 18:33:41 Valid Loss = 0.030732323054989 
2016-12-07 18:33:49 Test Error = 0.5684 
2016-12-07 18:33:49 Test Loss = 0.030618615966797 
2016-12-07 18:33:49 -------------------LR------------------- 
2016-12-07 18:33:49 7.62939453125e-06 
2016-12-07 18:33:49 Epoch 226 
2016-12-07 18:37:26 Training Error = 0.53513333333333 
2016-12-07 18:37:26 Training Loss = 0.031178109483507 
2016-12-07 18:37:30 Valid Error = 0.57251450290058 
2016-12-07 18:37:30 Valid Loss = 0.030765406358018 
2016-12-07 18:37:38 Test Error = 0.5726 
2016-12-07 18:37:38 Test Loss = 0.030693434082031 
2016-12-07 18:37:38 -------------------LR------------------- 
2016-12-07 18:37:38 7.62939453125e-06 
2016-12-07 18:37:38 Epoch 227 
2016-12-07 18:41:09 Training Error = 0.53333333333333 
2016-12-07 18:41:09 Training Loss = 0.031170454915365 
2016-12-07 18:41:13 Valid Error = 0.57051410282056 
2016-12-07 18:41:13 Valid Loss = 0.030568393943748 
2016-12-07 18:41:21 Test Error = 0.5669 
2016-12-07 18:41:21 Test Loss = 0.030586923095703 
2016-12-07 18:41:21 -------------------LR------------------- 
2016-12-07 18:41:21 7.62939453125e-06 
2016-12-07 18:41:21 Epoch 228 
2016-12-07 18:44:51 Training Error = 0.53213333333333 
2016-12-07 18:44:51 Training Loss = 0.031181053168403 
2016-12-07 18:44:55 Valid Error = 0.57371474294859 
2016-12-07 18:44:55 Valid Loss = 0.030652920214648 
2016-12-07 18:45:03 Test Error = 0.5687 
2016-12-07 18:45:03 Test Loss = 0.030626551513672 
2016-12-07 18:45:03 -------------------LR------------------- 
2016-12-07 18:45:03 7.62939453125e-06 
2016-12-07 18:45:03 Epoch 229 
2016-12-07 18:48:29 Training Error = 0.53137777777778 
2016-12-07 18:48:29 Training Loss = 0.031174753689236 
2016-12-07 18:48:33 Valid Error = 0.57171434286857 
2016-12-07 18:48:33 Valid Loss = 0.030727017750661 
2016-12-07 18:48:41 Test Error = 0.5696 
2016-12-07 18:48:41 Test Loss = 0.030810338867187 
2016-12-07 18:48:41 -------------------LR------------------- 
2016-12-07 18:48:41 7.62939453125e-06 
2016-12-07 18:48:41 Epoch 230 
2016-12-07 18:52:26 Training Error = 0.53184444444444 
2016-12-07 18:52:26 Training Loss = 0.031160488606771 
2016-12-07 18:52:30 Valid Error = 0.5753150630126 
2016-12-07 18:52:30 Valid Loss = 0.03061026250958 
2016-12-07 18:52:38 Test Error = 0.5724 
2016-12-07 18:52:38 Test Loss = 0.030568711425781 
2016-12-07 18:52:38 -------------------LR------------------- 
2016-12-07 18:52:38 7.62939453125e-06 
2016-12-07 18:52:38 Epoch 231 
2016-12-07 18:56:12 Training Error = 0.53593333333333 
2016-12-07 18:56:12 Training Loss = 0.031209324761285 
2016-12-07 18:56:16 Valid Error = 0.57131426285257 
2016-12-07 18:56:16 Valid Loss = 0.030744300365795 
2016-12-07 18:56:24 Test Error = 0.5745 
2016-12-07 18:56:24 Test Loss = 0.030804743408203 
2016-12-07 18:56:24 -------------------LR------------------- 
2016-12-07 18:56:24 7.62939453125e-06 
2016-12-07 18:56:24 Epoch 232 
2016-12-07 19:00:01 Training Error = 0.53531111111111 
2016-12-07 19:00:01 Training Loss = 0.031171107042101 
2016-12-07 19:00:05 Valid Error = 0.56991398279656 
2016-12-07 19:00:05 Valid Loss = 0.030630497515093 
2016-12-07 19:00:13 Test Error = 0.5701 
2016-12-07 19:00:13 Test Loss = 0.030638073242187 
2016-12-07 19:00:13 -------------------LR------------------- 
2016-12-07 19:00:13 7.62939453125e-06 
2016-12-07 19:00:13 Epoch 233 
2016-12-07 19:03:37 Training Error = 0.53188888888889 
2016-12-07 19:03:37 Training Loss = 0.031162184190538 
2016-12-07 19:03:41 Valid Error = 0.56791358271654 
2016-12-07 19:03:41 Valid Loss = 0.030656333013678 
2016-12-07 19:03:50 Test Error = 0.5686 
2016-12-07 19:03:50 Test Loss = 0.030625301025391 
2016-12-07 19:03:50 -------------------LR------------------- 
2016-12-07 19:03:50 7.62939453125e-06 
2016-12-07 19:03:50 Epoch 234 
2016-12-07 19:07:23 Training Error = 0.53553333333333 
2016-12-07 19:07:23 Training Loss = 0.031169571289063 
2016-12-07 19:07:27 Valid Error = 0.57991598319664 
2016-12-07 19:07:27 Valid Loss = 0.030932495385522 
2016-12-07 19:07:35 Test Error = 0.576 
2016-12-07 19:07:35 Test Loss = 0.030801816650391 
2016-12-07 19:07:35 -------------------LR------------------- 
2016-12-07 19:07:35 7.62939453125e-06 
2016-12-07 19:07:35 Epoch 235 
2016-12-07 19:11:05 Training Error = 0.53197777777778 
2016-12-07 19:11:05 Training Loss = 0.03115463921441 
2016-12-07 19:11:09 Valid Error = 0.57251450290058 
2016-12-07 19:11:09 Valid Loss = 0.030592573319413 
2016-12-07 19:11:17 Test Error = 0.572 
2016-12-07 19:11:17 Test Loss = 0.030543491210938 
2016-12-07 19:11:17 -------------------LR------------------- 
2016-12-07 19:11:17 7.62939453125e-06 
2016-12-07 19:11:17 Epoch 236 
2016-12-07 19:14:51 Training Error = 0.53277777777778 
2016-12-07 19:14:51 Training Loss = 0.031155517957899 
2016-12-07 19:14:55 Valid Error = 0.5753150630126 
2016-12-07 19:14:55 Valid Loss = 0.030829697397593 
2016-12-07 19:15:03 Test Error = 0.5719 
2016-12-07 19:15:03 Test Loss = 0.030869906005859 
2016-12-07 19:15:03 -------------------LR------------------- 
2016-12-07 19:15:03 7.62939453125e-06 
2016-12-07 19:15:03 Epoch 237 
2016-12-07 19:18:39 Training Error = 0.53408888888889 
2016-12-07 19:18:39 Training Loss = 0.031191521918403 
2016-12-07 19:18:43 Valid Error = 0.5751150230046 
2016-12-07 19:18:43 Valid Loss = 0.03075658138754 
2016-12-07 19:18:51 Test Error = 0.5702 
2016-12-07 19:18:51 Test Loss = 0.030678140380859 
2016-12-07 19:18:51 -------------------LR------------------- 
2016-12-07 19:18:51 7.62939453125e-06 
2016-12-07 19:18:51 Epoch 238 
2016-12-07 19:22:26 Training Error = 0.53466666666667 
2016-12-07 19:22:26 Training Loss = 0.031162966362847 
2016-12-07 19:22:30 Valid Error = 0.5755151030206 
2016-12-07 19:22:30 Valid Loss = 0.030797663572264 
2016-12-07 19:22:38 Test Error = 0.571 
2016-12-07 19:22:38 Test Loss = 0.030770797119141 
2016-12-07 19:22:38 -------------------LR------------------- 
2016-12-07 19:22:38 7.62939453125e-06 
2016-12-07 19:22:38 Epoch 239 
2016-12-07 19:26:03 Training Error = 0.53044444444444 
2016-12-07 19:26:03 Training Loss = 0.031183942599826 
2016-12-07 19:26:08 Valid Error = 0.56951390278056 
2016-12-07 19:26:08 Valid Loss = 0.030742170737632 
2016-12-07 19:26:16 Test Error = 0.5696 
2016-12-07 19:26:16 Test Loss = 0.030660227294922 
2016-12-07 19:26:16 -------------------LR------------------- 
2016-12-07 19:26:16 7.62939453125e-06 
2016-12-07 19:26:16 Epoch 240 
2016-12-07 19:29:58 Training Error = 0.53097777777778 
2016-12-07 19:29:58 Training Loss = 0.031176639756944 
2016-12-07 19:30:02 Valid Error = 0.57591518303661 
2016-12-07 19:30:02 Valid Loss = 0.030796242297962 
2016-12-07 19:30:10 Test Error = 0.5739 
2016-12-07 19:30:10 Test Loss = 0.030737454589844 
2016-12-07 19:30:10 -------------------LR------------------- 
2016-12-07 19:30:10 3.814697265625e-06 
2016-12-07 19:30:11 Epoch 241 
2016-12-07 19:33:44 Training Error = 0.53073333333333 
2016-12-07 19:33:44 Training Loss = 0.03110520187717 
2016-12-07 19:33:48 Valid Error = 0.56991398279656 
2016-12-07 19:33:48 Valid Loss = 0.030535882738696 
2016-12-07 19:33:56 Test Error = 0.5667 
2016-12-07 19:33:56 Test Loss = 0.030528233154297 
2016-12-07 19:33:56 -------------------LR------------------- 
2016-12-07 19:33:56 3.814697265625e-06 
2016-12-07 19:33:56 Epoch 242 
2016-12-07 19:37:29 Training Error = 0.53495555555556 
2016-12-07 19:37:29 Training Loss = 0.031169632215712 
2016-12-07 19:37:33 Valid Error = 0.57591518303661 
2016-12-07 19:37:33 Valid Loss = 0.030979100169017 
2016-12-07 19:37:41 Test Error = 0.5816 
2016-12-07 19:37:41 Test Loss = 0.031003592529297 
2016-12-07 19:37:41 -------------------LR------------------- 
2016-12-07 19:37:41 3.814697265625e-06 
2016-12-07 19:37:41 Epoch 243 
2016-12-07 19:41:14 Training Error = 0.53235555555556 
2016-12-07 19:41:14 Training Loss = 0.031127052463108 
2016-12-07 19:41:18 Valid Error = 0.56831366273255 
2016-12-07 19:41:18 Valid Loss = 0.030646816746434 
2016-12-07 19:41:26 Test Error = 0.5713 
2016-12-07 19:41:26 Test Loss = 0.030585287353516 
2016-12-07 19:41:26 -------------------LR------------------- 
2016-12-07 19:41:26 3.814697265625e-06 
2016-12-07 19:41:26 Epoch 244 
2016-12-07 19:45:00 Training Error = 0.53384444444444 
2016-12-07 19:45:00 Training Loss = 0.031165458170573 
2016-12-07 19:45:04 Valid Error = 0.57311462292458 
2016-12-07 19:45:04 Valid Loss = 0.03059938662735 
2016-12-07 19:45:12 Test Error = 0.5658 
2016-12-07 19:45:12 Test Loss = 0.030529610839844 
2016-12-07 19:45:12 -------------------LR------------------- 
2016-12-07 19:45:12 3.814697265625e-06 
2016-12-07 19:45:12 Epoch 245 
2016-12-07 19:48:45 Training Error = 0.53162222222222 
2016-12-07 19:48:45 Training Loss = 0.031177285427517 
2016-12-07 19:48:49 Valid Error = 0.57151430286057 
2016-12-07 19:48:49 Valid Loss = 0.030645556052146 
2016-12-07 19:48:58 Test Error = 0.5685 
2016-12-07 19:48:58 Test Loss = 0.030633748046875 
2016-12-07 19:48:58 -------------------LR------------------- 
2016-12-07 19:48:58 3.814697265625e-06 
2016-12-07 19:48:58 Epoch 246 
2016-12-07 19:52:33 Training Error = 0.53497777777778 
2016-12-07 19:52:33 Training Loss = 0.031172852593316 
2016-12-07 19:52:37 Valid Error = 0.57911582316463 
2016-12-07 19:52:37 Valid Loss = 0.030952903333998 
2016-12-07 19:52:45 Test Error = 0.5726 
2016-12-07 19:52:45 Test Loss = 0.030863244384766 
2016-12-07 19:52:45 -------------------LR------------------- 
2016-12-07 19:52:45 3.814697265625e-06 
2016-12-07 19:52:45 Epoch 247 
2016-12-07 19:56:20 Training Error = 0.53402222222222 
2016-12-07 19:56:20 Training Loss = 0.031149282226563 
2016-12-07 19:56:24 Valid Error = 0.57631526305261 
2016-12-07 19:56:24 Valid Loss = 0.030704134662983 
2016-12-07 19:56:32 Test Error = 0.5699 
2016-12-07 19:56:32 Test Loss = 0.030641038085937 
2016-12-07 19:56:32 -------------------LR------------------- 
2016-12-07 19:56:32 3.814697265625e-06 
2016-12-07 19:56:32 Epoch 248 
2016-12-07 20:00:04 Training Error = 0.53431111111111 
2016-12-07 20:00:04 Training Loss = 0.031167757324219 
2016-12-07 20:00:08 Valid Error = 0.57991598319664 
2016-12-07 20:00:08 Valid Loss = 0.030819492578516 
2016-12-07 20:00:16 Test Error = 0.5758 
2016-12-07 20:00:16 Test Loss = 0.030747977783203 
2016-12-07 20:00:16 -------------------LR------------------- 
2016-12-07 20:00:16 3.814697265625e-06 
2016-12-07 20:00:16 Epoch 249 
2016-12-07 20:03:54 Training Error = 0.53393333333333 
2016-12-07 20:03:54 Training Loss = 0.031168931749132 
2016-12-07 20:03:58 Valid Error = 0.57651530306061 
2016-12-07 20:03:58 Valid Loss = 0.030844800158557 
2016-12-07 20:04:06 Test Error = 0.5772 
2016-12-07 20:04:06 Test Loss = 0.030888018310547 
2016-12-07 20:04:06 -------------------LR------------------- 
2016-12-07 20:04:06 3.814697265625e-06 
2016-12-07 20:04:06 Epoch 250 
2016-12-07 20:07:47 Training Error = 0.5348 
2016-12-07 20:07:47 Training Loss = 0.03118725265842 
2016-12-07 20:07:51 Valid Error = 0.57231446289258 
2016-12-07 20:07:51 Valid Loss = 0.030642909376662 
2016-12-07 20:07:59 Test Error = 0.5668 
2016-12-07 20:07:59 Test Loss = 0.030629219970703 
2016-12-07 20:07:59 -------------------LR------------------- 
2016-12-07 20:07:59 3.814697265625e-06 
2016-12-07 20:07:59 Epoch 251 
2016-12-07 20:11:39 Training Error = 0.53344444444444 
2016-12-07 20:11:39 Training Loss = 0.031170340711806 
2016-12-07 20:11:43 Valid Error = 0.57191438287658 
2016-12-07 20:11:43 Valid Loss = 0.030733931156743 
2016-12-07 20:11:51 Test Error = 0.5726 
2016-12-07 20:11:51 Test Loss = 0.030753991210937 
2016-12-07 20:11:51 -------------------LR------------------- 
2016-12-07 20:11:51 3.814697265625e-06 
2016-12-07 20:11:51 Epoch 252 
2016-12-07 20:15:21 Training Error = 0.53168888888889 
2016-12-07 20:15:21 Training Loss = 0.031148142632378 
2016-12-07 20:15:25 Valid Error = 0.5747149429886 
2016-12-07 20:15:25 Valid Loss = 0.030852316541639 
2016-12-07 20:15:33 Test Error = 0.5732 
2016-12-07 20:15:33 Test Loss = 0.030761959716797 
2016-12-07 20:15:33 -------------------LR------------------- 
2016-12-07 20:15:33 3.814697265625e-06 
2016-12-07 20:15:33 Epoch 253 
2016-12-07 20:19:04 Training Error = 0.53202222222222 
2016-12-07 20:19:04 Training Loss = 0.031142955132378 
2016-12-07 20:19:08 Valid Error = 0.57231446289258 
2016-12-07 20:19:08 Valid Loss = 0.030631433015535 
2016-12-07 20:19:17 Test Error = 0.5647 
2016-12-07 20:19:17 Test Loss = 0.030544607177734 
2016-12-07 20:19:17 -------------------LR------------------- 
2016-12-07 20:19:17 3.814697265625e-06 
2016-12-07 20:19:17 Epoch 254 
2016-12-07 20:22:49 Training Error = 0.53213333333333 
2016-12-07 20:22:49 Training Loss = 0.031175873535156 
2016-12-07 20:22:53 Valid Error = 0.57731546309262 
2016-12-07 20:22:53 Valid Loss = 0.030803373224787 
2016-12-07 20:23:01 Test Error = 0.5759 
2016-12-07 20:23:01 Test Loss = 0.030773973876953 
2016-12-07 20:23:01 -------------------LR------------------- 
2016-12-07 20:23:01 3.814697265625e-06 
2016-12-07 20:23:01 Epoch 255 
2016-12-07 20:26:38 Training Error = 0.53482222222222 
2016-12-07 20:26:38 Training Loss = 0.031174618977865 
2016-12-07 20:26:42 Valid Error = 0.5753150630126 
2016-12-07 20:26:42 Valid Loss = 0.030649280262196 
2016-12-07 20:26:50 Test Error = 0.5714 
2016-12-07 20:26:50 Test Loss = 0.030592111816406 
2016-12-07 20:26:50 -------------------LR------------------- 
2016-12-07 20:26:50 3.814697265625e-06 
2016-12-07 20:26:50 Epoch 256 
2016-12-07 20:30:22 Training Error = 0.53293333333333 
2016-12-07 20:30:22 Training Loss = 0.031141307562934 
2016-12-07 20:30:26 Valid Error = 0.58171634326865 
2016-12-07 20:30:26 Valid Loss = 0.030993323584327 
2016-12-07 20:30:34 Test Error = 0.577 
2016-12-07 20:30:34 Test Loss = 0.030961440917969 
2016-12-07 20:30:34 -------------------LR------------------- 
2016-12-07 20:30:34 3.814697265625e-06 
2016-12-07 20:30:34 Epoch 257 
2016-12-07 20:34:04 Training Error = 0.53135555555556 
2016-12-07 20:34:04 Training Loss = 0.031152540581597 
2016-12-07 20:34:08 Valid Error = 0.57231446289258 
2016-12-07 20:34:08 Valid Loss = 0.030624875257582 
2016-12-07 20:34:16 Test Error = 0.5715 
2016-12-07 20:34:16 Test Loss = 0.030634195556641 
2016-12-07 20:34:16 -------------------LR------------------- 
2016-12-07 20:34:16 3.814697265625e-06 
2016-12-07 20:34:16 Epoch 258 
2016-12-07 20:37:45 Training Error = 0.52955555555556 
2016-12-07 20:37:45 Training Loss = 0.03116714860026 
2016-12-07 20:37:49 Valid Error = 0.57591518303661 
2016-12-07 20:37:49 Valid Loss = 0.030671616682112 
2016-12-07 20:37:57 Test Error = 0.5691 
2016-12-07 20:37:57 Test Loss = 0.030650526611328 
2016-12-07 20:37:57 -------------------LR------------------- 
2016-12-07 20:37:57 3.814697265625e-06 
2016-12-07 20:37:57 Epoch 259 
2016-12-07 20:41:32 Training Error = 0.53484444444444 
2016-12-07 20:41:32 Training Loss = 0.031203205512153 
2016-12-07 20:41:36 Valid Error = 0.57071414282857 
2016-12-07 20:41:36 Valid Loss = 0.030706492964644 
2016-12-07 20:41:44 Test Error = 0.5699 
2016-12-07 20:41:44 Test Loss = 0.030658764404297 
2016-12-07 20:41:44 -------------------LR------------------- 
2016-12-07 20:41:44 3.814697265625e-06 
2016-12-07 20:41:44 Epoch 260 
2016-12-07 20:45:22 Training Error = 0.53477777777778 
2016-12-07 20:45:22 Training Loss = 0.031150834960937 
2016-12-07 20:45:26 Valid Error = 0.57571514302861 
2016-12-07 20:45:26 Valid Loss = 0.03067494349232 
2016-12-07 20:45:34 Test Error = 0.5681 
2016-12-07 20:45:34 Test Loss = 0.030581006103516 
2016-12-07 20:45:34 -------------------LR------------------- 
2016-12-07 20:45:34 1.9073486328125e-06 
2016-12-07 20:45:34 Epoch 261 
2016-12-07 20:49:11 Training Error = 0.53346666666667 
2016-12-07 20:49:11 Training Loss = 0.031133579589844 
2016-12-07 20:49:15 Valid Error = 0.57651530306061 
2016-12-07 20:49:15 Valid Loss = 0.030706930560932 
2016-12-07 20:49:23 Test Error = 0.5683 
2016-12-07 20:49:23 Test Loss = 0.030650466552734 
2016-12-07 20:49:23 -------------------LR------------------- 
2016-12-07 20:49:23 1.9073486328125e-06 
2016-12-07 20:49:23 Epoch 262 
2016-12-07 20:52:53 Training Error = 0.53133333333333 
2016-12-07 20:52:53 Training Loss = 0.031122664605035 
2016-12-07 20:52:57 Valid Error = 0.5745149029806 
2016-12-07 20:52:57 Valid Loss = 0.030679740266145 
2016-12-07 20:53:05 Test Error = 0.5679 
2016-12-07 20:53:05 Test Loss = 0.030543180664062 
2016-12-07 20:53:05 -------------------LR------------------- 
2016-12-07 20:53:05 1.9073486328125e-06 
2016-12-07 20:53:05 Epoch 263 
2016-12-07 20:56:39 Training Error = 0.5314 
2016-12-07 20:56:39 Training Loss = 0.031147611436632 
2016-12-07 20:56:43 Valid Error = 0.57111422284457 
2016-12-07 20:56:43 Valid Loss = 0.030610517564928 
2016-12-07 20:56:51 Test Error = 0.568 
2016-12-07 20:56:51 Test Loss = 0.030557816650391 
2016-12-07 20:56:51 -------------------LR------------------- 
2016-12-07 20:56:51 1.9073486328125e-06 
2016-12-07 20:56:51 Epoch 264 
2016-12-07 21:00:25 Training Error = 0.53311111111111 
2016-12-07 21:00:25 Training Loss = 0.031141803656684 
2016-12-07 21:00:29 Valid Error = 0.57771554310862 
2016-12-07 21:00:29 Valid Loss = 0.03073218241337 
2016-12-07 21:00:37 Test Error = 0.5719 
2016-12-07 21:00:37 Test Loss = 0.030707076660156 
2016-12-07 21:00:37 -------------------LR------------------- 
2016-12-07 21:00:37 1.9073486328125e-06 
2016-12-07 21:00:37 Epoch 265 
2016-12-07 21:04:16 Training Error = 0.53297777777778 
2016-12-07 21:04:16 Training Loss = 0.03113490500217 
2016-12-07 21:04:20 Valid Error = 0.57071414282857 
2016-12-07 21:04:20 Valid Loss = 0.030512686531747 
2016-12-07 21:04:28 Test Error = 0.5682 
2016-12-07 21:04:28 Test Loss = 0.030481480957031 
2016-12-07 21:04:28 -------------------LR------------------- 
2016-12-07 21:04:28 1.9073486328125e-06 
2016-12-07 21:04:28 Epoch 266 
2016-12-07 21:07:52 Training Error = 0.5314 
2016-12-07 21:07:52 Training Loss = 0.031140653157552 
2016-12-07 21:07:56 Valid Error = 0.57091418283657 
2016-12-07 21:07:56 Valid Loss = 0.030693154868247 
2016-12-07 21:08:04 Test Error = 0.5711 
2016-12-07 21:08:04 Test Loss = 0.0306320234375 
2016-12-07 21:08:04 -------------------LR------------------- 
2016-12-07 21:08:04 1.9073486328125e-06 
2016-12-07 21:08:05 Epoch 267 
2016-12-07 21:11:39 Training Error = 0.53135555555556 
2016-12-07 21:11:39 Training Loss = 0.031154377441406 
2016-12-07 21:11:43 Valid Error = 0.58091618323665 
2016-12-07 21:11:43 Valid Loss = 0.030897229439889 
2016-12-07 21:11:51 Test Error = 0.577 
2016-12-07 21:11:51 Test Loss = 0.0309379921875 
2016-12-07 21:11:51 -------------------LR------------------- 
2016-12-07 21:11:51 1.9073486328125e-06 
2016-12-07 21:11:51 Epoch 268 
2016-12-07 21:15:22 Training Error = 0.53282222222222 
2016-12-07 21:15:22 Training Loss = 0.031140884711372 
2016-12-07 21:15:26 Valid Error = 0.57571514302861 
2016-12-07 21:15:26 Valid Loss = 0.030735958181815 
2016-12-07 21:15:34 Test Error = 0.5684 
2016-12-07 21:15:34 Test Loss = 0.030678056640625 
2016-12-07 21:15:34 -------------------LR------------------- 
2016-12-07 21:15:34 1.9073486328125e-06 
2016-12-07 21:15:34 Epoch 269 
2016-12-07 21:19:12 Training Error = 0.53186666666667 
2016-12-07 21:19:12 Training Loss = 0.031184488172743 
2016-12-07 21:19:16 Valid Error = 0.58111622324465 
2016-12-07 21:19:16 Valid Loss = 0.030650553134678 
2016-12-07 21:19:24 Test Error = 0.5714 
2016-12-07 21:19:24 Test Loss = 0.030663716308594 
2016-12-07 21:19:24 -------------------LR------------------- 
2016-12-07 21:19:24 1.9073486328125e-06 
2016-12-07 21:19:24 Epoch 270 
2016-12-07 21:23:03 Training Error = 0.53155555555556 
2016-12-07 21:23:03 Training Loss = 0.031143973795573 
2016-12-07 21:23:07 Valid Error = 0.57811562312462 
2016-12-07 21:23:07 Valid Loss = 0.030828726253597 
2016-12-07 21:23:15 Test Error = 0.5771 
2016-12-07 21:23:15 Test Loss = 0.030782841064453 
2016-12-07 21:23:15 -------------------LR------------------- 
2016-12-07 21:23:15 1.9073486328125e-06 
2016-12-07 21:23:15 Epoch 271 
2016-12-07 21:26:52 Training Error = 0.53246666666667 
2016-12-07 21:26:52 Training Loss = 0.031148606499566 
2016-12-07 21:26:56 Valid Error = 0.57571514302861 
2016-12-07 21:26:56 Valid Loss = 0.030879380848133 
2016-12-07 21:27:04 Test Error = 0.5756 
2016-12-07 21:27:04 Test Loss = 0.030798338378906 
2016-12-07 21:27:04 -------------------LR------------------- 
2016-12-07 21:27:04 1.9073486328125e-06 
2016-12-07 21:27:04 Epoch 272 
2016-12-07 21:30:33 Training Error = 0.53262222222222 
2016-12-07 21:30:33 Training Loss = 0.031152061794705 
2016-12-07 21:30:37 Valid Error = 0.57231446289258 
2016-12-07 21:30:37 Valid Loss = 0.030666321077425 
2016-12-07 21:30:45 Test Error = 0.5698 
2016-12-07 21:30:45 Test Loss = 0.030745510742187 
2016-12-07 21:30:45 -------------------LR------------------- 
2016-12-07 21:30:45 1.9073486328125e-06 
2016-12-07 21:30:45 Epoch 273 
2016-12-07 21:34:19 Training Error = 0.53104444444444 
2016-12-07 21:34:19 Training Loss = 0.031163131293403 
2016-12-07 21:34:23 Valid Error = 0.57151430286057 
2016-12-07 21:34:23 Valid Loss = 0.030635834075286 
2016-12-07 21:34:31 Test Error = 0.5685 
2016-12-07 21:34:31 Test Loss = 0.030684938720703 
2016-12-07 21:34:31 -------------------LR------------------- 
2016-12-07 21:34:31 1.9073486328125e-06 
2016-12-07 21:34:31 Epoch 274 
2016-12-07 21:38:01 Training Error = 0.53428888888889 
2016-12-07 21:38:01 Training Loss = 0.03118589469401 
2016-12-07 21:38:05 Valid Error = 0.57071414282857 
2016-12-07 21:38:05 Valid Loss = 0.030628614438169 
2016-12-07 21:38:13 Test Error = 0.5716 
2016-12-07 21:38:13 Test Loss = 0.030679909179687 
2016-12-07 21:38:13 -------------------LR------------------- 
2016-12-07 21:38:13 1.9073486328125e-06 
2016-12-07 21:38:13 Epoch 275 
2016-12-07 21:41:48 Training Error = 0.53351111111111 
2016-12-07 21:41:48 Training Loss = 0.03119201936849 
2016-12-07 21:41:52 Valid Error = 0.56911382276455 
2016-12-07 21:41:52 Valid Loss = 0.030546936207692 
2016-12-07 21:42:00 Test Error = 0.5682 
2016-12-07 21:42:00 Test Loss = 0.030601205322266 
2016-12-07 21:42:00 -------------------LR------------------- 
2016-12-07 21:42:00 1.9073486328125e-06 
2016-12-07 21:42:00 Epoch 276 
2016-12-07 21:45:31 Training Error = 0.53342222222222 
2016-12-07 21:45:31 Training Loss = 0.031162151258681 
2016-12-07 21:45:35 Valid Error = 0.57251450290058 
2016-12-07 21:45:35 Valid Loss = 0.030747076182628 
2016-12-07 21:45:43 Test Error = 0.5697 
2016-12-07 21:45:43 Test Loss = 0.030691676025391 
2016-12-07 21:45:43 -------------------LR------------------- 
2016-12-07 21:45:43 1.9073486328125e-06 
2016-12-07 21:45:43 Epoch 277 
2016-12-07 21:49:13 Training Error = 0.53333333333333 
2016-12-07 21:49:13 Training Loss = 0.03113918359375 
2016-12-07 21:49:17 Valid Error = 0.57071414282857 
2016-12-07 21:49:17 Valid Loss = 0.030663452145994 
2016-12-07 21:49:25 Test Error = 0.5708 
2016-12-07 21:49:25 Test Loss = 0.030605518310547 
2016-12-07 21:49:25 -------------------LR------------------- 
2016-12-07 21:49:25 1.9073486328125e-06 
2016-12-07 21:49:25 Epoch 278 
2016-12-07 21:52:56 Training Error = 0.52982222222222 
2016-12-07 21:52:56 Training Loss = 0.031132556803385 
2016-12-07 21:53:00 Valid Error = 0.5749149829966 
2016-12-07 21:53:00 Valid Loss = 0.030786970854644 
2016-12-07 21:53:08 Test Error = 0.5769 
2016-12-07 21:53:08 Test Loss = 0.030768098388672 
2016-12-07 21:53:08 -------------------LR------------------- 
2016-12-07 21:53:08 1.9073486328125e-06 
2016-12-07 21:53:08 Epoch 279 
2016-12-07 21:56:42 Training Error = 0.53302222222222 
2016-12-07 21:56:42 Training Loss = 0.031142488606771 
2016-12-07 21:56:46 Valid Error = 0.57331466293259 
2016-12-07 21:56:46 Valid Loss = 0.030593545846139 
2016-12-07 21:56:55 Test Error = 0.569 
2016-12-07 21:56:55 Test Loss = 0.030657519287109 
2016-12-07 21:56:55 -------------------LR------------------- 
2016-12-07 21:56:55 1.9073486328125e-06 
2016-12-07 21:56:55 Epoch 280 
2016-12-07 22:00:42 Training Error = 0.53217777777778 
2016-12-07 22:00:42 Training Loss = 0.03115840218099 
2016-12-07 22:00:46 Valid Error = 0.56891378275655 
2016-12-07 22:00:46 Valid Loss = 0.030597064210695 
2016-12-07 22:00:54 Test Error = 0.5704 
2016-12-07 22:00:54 Test Loss = 0.030580984863281 
2016-12-07 22:00:54 -------------------LR------------------- 
2016-12-07 22:00:54 9.5367431640625e-07 
2016-12-07 22:00:54 Epoch 281 
2016-12-07 22:04:30 Training Error = 0.53215555555556 
2016-12-07 22:04:30 Training Loss = 0.031130884819878 
2016-12-07 22:04:34 Valid Error = 0.57411482296459 
2016-12-07 22:04:34 Valid Loss = 0.030684590294885 
2016-12-07 22:04:42 Test Error = 0.5702 
2016-12-07 22:04:42 Test Loss = 0.030646809814453 
2016-12-07 22:04:42 -------------------LR------------------- 
2016-12-07 22:04:42 9.5367431640625e-07 
2016-12-07 22:04:42 Epoch 282 
2016-12-07 22:08:17 Training Error = 0.53028888888889 
2016-12-07 22:08:17 Training Loss = 0.031147699327257 
2016-12-07 22:08:21 Valid Error = 0.56891378275655 
2016-12-07 22:08:21 Valid Loss = 0.030590286538492 
2016-12-07 22:08:29 Test Error = 0.566 
2016-12-07 22:08:29 Test Loss = 0.030549685058594 
2016-12-07 22:08:29 -------------------LR------------------- 
2016-12-07 22:08:29 9.5367431640625e-07 
2016-12-07 22:08:29 Epoch 283 
2016-12-07 22:12:05 Training Error = 0.5316 
2016-12-07 22:12:05 Training Loss = 0.031118712673611 
2016-12-07 22:12:09 Valid Error = 0.57251450290058 
2016-12-07 22:12:09 Valid Loss = 0.030689318455663 
2016-12-07 22:12:17 Test Error = 0.5686 
2016-12-07 22:12:17 Test Loss = 0.030629682373047 
2016-12-07 22:12:17 -------------------LR------------------- 
2016-12-07 22:12:17 9.5367431640625e-07 
2016-12-07 22:12:17 Epoch 284 
2016-12-07 22:15:53 Training Error = 0.532 
2016-12-07 22:15:53 Training Loss = 0.031151484809028 
2016-12-07 22:15:57 Valid Error = 0.57251450290058 
2016-12-07 22:15:57 Valid Loss = 0.030487933231083 
2016-12-07 22:16:05 Test Error = 0.5666 
2016-12-07 22:16:05 Test Loss = 0.030502931884766 
2016-12-07 22:16:05 -------------------LR------------------- 
2016-12-07 22:16:05 9.5367431640625e-07 
2016-12-07 22:16:05 Epoch 285 
2016-12-07 22:19:38 Training Error = 0.53135555555556 
2016-12-07 22:19:38 Training Loss = 0.031117962619358 
2016-12-07 22:19:42 Valid Error = 0.57251450290058 
2016-12-07 22:19:42 Valid Loss = 0.030567038100112 
2016-12-07 22:19:50 Test Error = 0.5689 
2016-12-07 22:19:50 Test Loss = 0.030562068603516 
2016-12-07 22:19:50 -------------------LR------------------- 
2016-12-07 22:19:50 9.5367431640625e-07 
2016-12-07 22:19:50 Epoch 286 
2016-12-07 22:23:22 Training Error = 0.53171111111111 
2016-12-07 22:23:22 Training Loss = 0.031157606825087 
2016-12-07 22:23:26 Valid Error = 0.57851570314063 
2016-12-07 22:23:26 Valid Loss = 0.03081076337568 
2016-12-07 22:23:34 Test Error = 0.5752 
2016-12-07 22:23:34 Test Loss = 0.030834752685547 
2016-12-07 22:23:34 -------------------LR------------------- 
2016-12-07 22:23:34 9.5367431640625e-07 
2016-12-07 22:23:34 Epoch 287 
2016-12-07 22:27:00 Training Error = 0.53162222222222 
2016-12-07 22:27:00 Training Loss = 0.031141285427517 
2016-12-07 22:27:04 Valid Error = 0.57391478295659 
2016-12-07 22:27:04 Valid Loss = 0.030882875698452 
2016-12-07 22:27:12 Test Error = 0.5746 
2016-12-07 22:27:12 Test Loss = 0.030855521972656 
2016-12-07 22:27:12 -------------------LR------------------- 
2016-12-07 22:27:12 9.5367431640625e-07 
2016-12-07 22:27:12 Epoch 288 
2016-12-07 22:30:48 Training Error = 0.53088888888889 
2016-12-07 22:30:48 Training Loss = 0.031136094075521 
2016-12-07 22:30:52 Valid Error = 0.57391478295659 
2016-12-07 22:30:52 Valid Loss = 0.030714775619858 
2016-12-07 22:31:00 Test Error = 0.5719 
2016-12-07 22:31:00 Test Loss = 0.030650184326172 
2016-12-07 22:31:00 -------------------LR------------------- 
2016-12-07 22:31:00 9.5367431640625e-07 
2016-12-07 22:31:00 Epoch 289 
2016-12-07 22:34:30 Training Error = 0.53071111111111 
2016-12-07 22:34:30 Training Loss = 0.031127117567274 
2016-12-07 22:34:35 Valid Error = 0.56891378275655 
2016-12-07 22:34:35 Valid Loss = 0.030659472171879 
2016-12-07 22:34:43 Test Error = 0.5701 
2016-12-07 22:34:43 Test Loss = 0.03060815625 
2016-12-07 22:34:43 -------------------LR------------------- 
2016-12-07 22:34:43 9.5367431640625e-07 
2016-12-07 22:34:43 Epoch 290 
2016-12-07 22:38:27 Training Error = 0.53108888888889 
2016-12-07 22:38:27 Training Loss = 0.031129658040365 
2016-12-07 22:38:31 Valid Error = 0.5747149429886 
2016-12-07 22:38:31 Valid Loss = 0.03080623935801 
2016-12-07 22:38:39 Test Error = 0.5783 
2016-12-07 22:38:39 Test Loss = 0.030736258300781 
2016-12-07 22:38:39 -------------------LR------------------- 
2016-12-07 22:38:39 9.5367431640625e-07 
2016-12-07 22:38:39 Epoch 291 
2016-12-07 22:42:12 Training Error = 0.53264444444444 
2016-12-07 22:42:12 Training Loss = 0.031167843153212 
2016-12-07 22:42:16 Valid Error = 0.57171434286857 
2016-12-07 22:42:16 Valid Loss = 0.030707459012235 
2016-12-07 22:42:24 Test Error = 0.5705 
2016-12-07 22:42:24 Test Loss = 0.030732687988281 
2016-12-07 22:42:24 -------------------LR------------------- 
2016-12-07 22:42:24 9.5367431640625e-07 
2016-12-07 22:42:24 Epoch 292 
2016-12-07 22:45:59 Training Error = 0.53446666666667 
2016-12-07 22:45:59 Training Loss = 0.031173000054253 
2016-12-07 22:46:03 Valid Error = 0.57011402280456 
2016-12-07 22:46:03 Valid Loss = 0.030524997950587 
2016-12-07 22:46:11 Test Error = 0.5675 
2016-12-07 22:46:11 Test Loss = 0.030528491943359 
2016-12-07 22:46:11 -------------------LR------------------- 
2016-12-07 22:46:11 9.5367431640625e-07 
2016-12-07 22:46:11 Epoch 293 
2016-12-07 22:49:40 Training Error = 0.53044444444444 
2016-12-07 22:49:40 Training Loss = 0.031146460394965 
2016-12-07 22:49:44 Valid Error = 0.57431486297259 
2016-12-07 22:49:44 Valid Loss = 0.030924325293067 
2016-12-07 22:49:52 Test Error = 0.5707 
2016-12-07 22:49:52 Test Loss = 0.030760016113281 
2016-12-07 22:49:52 -------------------LR------------------- 
2016-12-07 22:49:52 9.5367431640625e-07 
2016-12-07 22:49:52 Epoch 294 
2016-12-07 22:53:25 Training Error = 0.53226666666667 
2016-12-07 22:53:25 Training Loss = 0.031177155978733 
2016-12-07 22:53:29 Valid Error = 0.57391478295659 
2016-12-07 22:53:29 Valid Loss = 0.030705357383262 
2016-12-07 22:53:37 Test Error = 0.5719 
2016-12-07 22:53:37 Test Loss = 0.030643942382813 
2016-12-07 22:53:37 -------------------LR------------------- 
2016-12-07 22:53:37 9.5367431640625e-07 
2016-12-07 22:53:37 Epoch 295 
2016-12-07 22:57:04 Training Error = 0.53435555555556 
2016-12-07 22:57:04 Training Loss = 0.031207395996094 
2016-12-07 22:57:08 Valid Error = 0.57431486297259 
2016-12-07 22:57:08 Valid Loss = 0.030552311010718 
2016-12-07 22:57:16 Test Error = 0.5699 
2016-12-07 22:57:16 Test Loss = 0.030685658691406 
2016-12-07 22:57:16 -------------------LR------------------- 
2016-12-07 22:57:16 9.5367431640625e-07 
2016-12-07 22:57:16 Epoch 296 
2016-12-07 23:00:45 Training Error = 0.53102222222222 
2016-12-07 23:00:45 Training Loss = 0.031150078504774 
2016-12-07 23:00:49 Valid Error = 0.5749149829966 
2016-12-07 23:00:49 Valid Loss = 0.03080739294959 
2016-12-07 23:00:57 Test Error = 0.5739 
2016-12-07 23:00:57 Test Loss = 0.030811538330078 
2016-12-07 23:00:57 -------------------LR------------------- 
2016-12-07 23:00:57 9.5367431640625e-07 
2016-12-07 23:00:57 Epoch 297 
2016-12-07 23:04:25 Training Error = 0.53293333333333 
2016-12-07 23:04:25 Training Loss = 0.031146447265625 
2016-12-07 23:04:29 Valid Error = 0.57131426285257 
2016-12-07 23:04:29 Valid Loss = 0.03059353319726 
2016-12-07 23:04:37 Test Error = 0.5691 
2016-12-07 23:04:37 Test Loss = 0.030593051513672 
2016-12-07 23:04:37 -------------------LR------------------- 
2016-12-07 23:04:37 9.5367431640625e-07 
2016-12-07 23:04:37 Epoch 298 
2016-12-07 23:08:13 Training Error = 0.53077777777778 
2016-12-07 23:08:13 Training Loss = 0.031123095323351 
2016-12-07 23:08:18 Valid Error = 0.57151430286057 
2016-12-07 23:08:18 Valid Loss = 0.030647457956492 
2016-12-07 23:08:26 Test Error = 0.5742 
2016-12-07 23:08:26 Test Loss = 0.03075778515625 
2016-12-07 23:08:26 -------------------LR------------------- 
2016-12-07 23:08:26 9.5367431640625e-07 
2016-12-07 23:08:26 Epoch 299 
2016-12-07 23:11:55 Training Error = 0.53064444444444 
2016-12-07 23:11:55 Training Loss = 0.031132174207899 
2016-12-07 23:11:59 Valid Error = 0.56991398279656 
2016-12-07 23:11:59 Valid Loss = 0.030614299169286 
2016-12-07 23:12:07 Test Error = 0.5751 
2016-12-07 23:12:07 Test Loss = 0.030614178466797 
2016-12-07 23:12:07 -------------------LR------------------- 
2016-12-07 23:12:07 9.5367431640625e-07 
2016-12-07 23:12:07 Epoch 300 
2016-12-07 23:15:53 Training Error = 0.53195555555556 
2016-12-07 23:15:53 Training Loss = 0.03113656640625 
2016-12-07 23:15:57 Valid Error = 0.57191438287658 
2016-12-07 23:15:57 Valid Loss = 0.030612353654436 
2016-12-07 23:16:05 Test Error = 0.5712 
2016-12-07 23:16:05 Test Loss = 0.030653056640625 
2016-12-07 23:16:05 -------------------LR------------------- 
2016-12-07 23:16:05 4.7683715820312e-07 
2016-12-07 23:16:05 Epoch 301 
2016-12-07 23:19:33 Training Error = 0.53104444444444 
2016-12-07 23:19:33 Training Loss = 0.031086391655816 
2016-12-07 23:19:37 Valid Error = 0.57111422284457 
2016-12-07 23:19:37 Valid Loss = 0.030608157743681 
2016-12-07 23:19:45 Test Error = 0.565 
2016-12-07 23:19:45 Test Loss = 0.030564049560547 
2016-12-07 23:19:45 -------------------LR------------------- 
2016-12-07 23:19:45 4.7683715820312e-07 
2016-12-07 23:19:45 Epoch 302 
2016-12-07 23:23:20 Training Error = 0.53184444444444 
2016-12-07 23:23:20 Training Loss = 0.031116786783854 
2016-12-07 23:23:24 Valid Error = 0.57171434286857 
2016-12-07 23:23:24 Valid Loss = 0.030779328121579 
2016-12-07 23:23:32 Test Error = 0.5701 
2016-12-07 23:23:32 Test Loss = 0.030764705078125 
2016-12-07 23:23:32 -------------------LR------------------- 
2016-12-07 23:23:32 4.7683715820312e-07 
2016-12-07 23:23:32 Epoch 303 
2016-12-07 23:27:02 Training Error = 0.53166666666667 
2016-12-07 23:27:02 Training Loss = 0.031124307562934 
2016-12-07 23:27:06 Valid Error = 0.56971394278856 
2016-12-07 23:27:06 Valid Loss = 0.030653826205111 
2016-12-07 23:27:14 Test Error = 0.5689 
2016-12-07 23:27:14 Test Loss = 0.030581860595703 
2016-12-07 23:27:14 -------------------LR------------------- 
2016-12-07 23:27:14 4.7683715820312e-07 
2016-12-07 23:27:14 Epoch 304 
2016-12-07 23:30:47 Training Error = 0.532 
2016-12-07 23:30:47 Training Loss = 0.031115474555122 
2016-12-07 23:30:51 Valid Error = 0.56991398279656 
2016-12-07 23:30:51 Valid Loss = 0.030739953036533 
2016-12-07 23:30:59 Test Error = 0.5736 
2016-12-07 23:30:59 Test Loss = 0.030779790283203 
2016-12-07 23:30:59 -------------------LR------------------- 
2016-12-07 23:30:59 4.7683715820312e-07 
2016-12-07 23:30:59 Epoch 305 
2016-12-07 23:34:27 Training Error = 0.53153333333333 
2016-12-07 23:34:27 Training Loss = 0.031135580132378 
2016-12-07 23:34:31 Valid Error = 0.5747149429886 
2016-12-07 23:34:31 Valid Loss = 0.030815941877913 
2016-12-07 23:34:39 Test Error = 0.577 
2016-12-07 23:34:39 Test Loss = 0.030725908691406 
2016-12-07 23:34:39 -------------------LR------------------- 
2016-12-07 23:34:39 4.7683715820312e-07 
2016-12-07 23:34:39 Epoch 306 
2016-12-07 23:38:13 Training Error = 0.53555555555556 
2016-12-07 23:38:13 Training Loss = 0.031173078938802 
2016-12-07 23:38:17 Valid Error = 0.57071414282857 
2016-12-07 23:38:17 Valid Loss = 0.030803136542304 
2016-12-07 23:38:25 Test Error = 0.568 
2016-12-07 23:38:25 Test Loss = 0.030684393066406 
2016-12-07 23:38:25 -------------------LR------------------- 
2016-12-07 23:38:25 4.7683715820312e-07 
2016-12-07 23:38:25 Epoch 307 
2016-12-07 23:41:59 Training Error = 0.53448888888889 
2016-12-07 23:41:59 Training Loss = 0.031147378038194 
2016-12-07 23:42:03 Valid Error = 0.5755151030206 
2016-12-07 23:42:03 Valid Loss = 0.030798002021553 
2016-12-07 23:42:11 Test Error = 0.5711 
2016-12-07 23:42:11 Test Loss = 0.030752705810547 
2016-12-07 23:42:11 -------------------LR------------------- 
2016-12-07 23:42:11 4.7683715820312e-07 
2016-12-07 23:42:11 Epoch 308 
2016-12-07 23:45:48 Training Error = 0.53162222222222 
2016-12-07 23:45:48 Training Loss = 0.031128462022569 
2016-12-07 23:45:52 Valid Error = 0.5745149029806 
2016-12-07 23:45:52 Valid Loss = 0.030677501121727 
2016-12-07 23:46:00 Test Error = 0.5684 
2016-12-07 23:46:00 Test Loss = 0.030624349121094 
2016-12-07 23:46:00 -------------------LR------------------- 
2016-12-07 23:46:00 4.7683715820312e-07 
2016-12-07 23:46:00 Epoch 309 
2016-12-07 23:49:35 Training Error = 0.53211111111111 
2016-12-07 23:49:35 Training Loss = 0.031137269748264 
2016-12-07 23:49:39 Valid Error = 0.57411482296459 
2016-12-07 23:49:39 Valid Loss = 0.03079908667652 
2016-12-07 23:49:47 Test Error = 0.5718 
2016-12-07 23:49:47 Test Loss = 0.030805614746094 
2016-12-07 23:49:47 -------------------LR------------------- 
2016-12-07 23:49:47 4.7683715820312e-07 
2016-12-07 23:49:47 Epoch 310 
2016-12-07 23:53:28 Training Error = 0.53315555555556 
2016-12-07 23:53:28 Training Loss = 0.031152085828993 
2016-12-07 23:53:33 Valid Error = 0.57191438287658 
2016-12-07 23:53:33 Valid Loss = 0.030723129090516 
2016-12-07 23:53:41 Test Error = 0.57 
2016-12-07 23:53:41 Test Loss = 0.030646088867188 
2016-12-07 23:53:41 -------------------LR------------------- 
2016-12-07 23:53:41 4.7683715820312e-07 
2016-12-07 23:53:41 Epoch 311 
2016-12-07 23:57:16 Training Error = 0.53131111111111 
2016-12-07 23:57:16 Training Loss = 0.031112590874566 
2016-12-07 23:57:20 Valid Error = 0.57091418283657 
2016-12-07 23:57:20 Valid Loss = 0.030563738440589 
2016-12-07 23:57:28 Test Error = 0.5651 
2016-12-07 23:57:28 Test Loss = 0.030567766845703 
2016-12-07 23:57:28 -------------------LR------------------- 
2016-12-07 23:57:28 4.7683715820312e-07 
2016-12-07 23:57:28 Epoch 312 
2016-12-08 00:01:00 Training Error = 0.53111111111111 
2016-12-08 00:01:00 Training Loss = 0.031149714518229 
2016-12-08 00:01:04 Valid Error = 0.5751150230046 
2016-12-08 00:01:04 Valid Loss = 0.030778176500231 
2016-12-08 00:01:13 Test Error = 0.5749 
2016-12-08 00:01:13 Test Loss = 0.030743870117187 
2016-12-08 00:01:13 -------------------LR------------------- 
2016-12-08 00:01:13 4.7683715820312e-07 
2016-12-08 00:01:13 Epoch 313 
2016-12-08 00:04:52 Training Error = 0.53515555555556 
2016-12-08 00:04:52 Training Loss = 0.031168045355903 
2016-12-08 00:04:56 Valid Error = 0.57611522304461 
2016-12-08 00:04:56 Valid Loss = 0.030779765043364 
2016-12-08 00:05:04 Test Error = 0.5709 
2016-12-08 00:05:04 Test Loss = 0.030685596679688 
2016-12-08 00:05:04 -------------------LR------------------- 
2016-12-08 00:05:04 4.7683715820312e-07 
2016-12-08 00:05:04 Epoch 314 
2016-12-08 00:08:28 Training Error = 0.53222222222222 
2016-12-08 00:08:28 Training Loss = 0.031157919813368 
2016-12-08 00:08:32 Valid Error = 0.57711542308462 
2016-12-08 00:08:32 Valid Loss = 0.030740691090993 
2016-12-08 00:08:40 Test Error = 0.5734 
2016-12-08 00:08:40 Test Loss = 0.030717942382812 
2016-12-08 00:08:40 -------------------LR------------------- 
2016-12-08 00:08:40 4.7683715820312e-07 
2016-12-08 00:08:40 Epoch 315 
2016-12-08 00:12:17 Training Error = 0.52944444444444 
2016-12-08 00:12:17 Training Loss = 0.031138280761719 
2016-12-08 00:12:21 Valid Error = 0.57571514302861 
2016-12-08 00:12:21 Valid Loss = 0.030628959770806 
2016-12-08 00:12:29 Test Error = 0.5639 
2016-12-08 00:12:29 Test Loss = 0.030496671875 
2016-12-08 00:12:29 -------------------LR------------------- 
2016-12-08 00:12:29 4.7683715820312e-07 
2016-12-08 00:12:29 Epoch 316 
2016-12-08 00:16:00 Training Error = 0.53213333333333 
2016-12-08 00:16:00 Training Loss = 0.031167543945312 
2016-12-08 00:16:04 Valid Error = 0.57371474294859 
2016-12-08 00:16:04 Valid Loss = 0.030661195428338 
2016-12-08 00:16:12 Test Error = 0.5734 
2016-12-08 00:16:12 Test Loss = 0.030701473876953 
2016-12-08 00:16:12 -------------------LR------------------- 
2016-12-08 00:16:12 4.7683715820312e-07 
2016-12-08 00:16:12 Epoch 317 
2016-12-08 00:19:50 Training Error = 0.53215555555556 
2016-12-08 00:19:50 Training Loss = 0.031139607204861 
2016-12-08 00:19:54 Valid Error = 0.58111622324465 
2016-12-08 00:19:54 Valid Loss = 0.030698700631784 
2016-12-08 00:20:03 Test Error = 0.5725 
2016-12-08 00:20:03 Test Loss = 0.030675403564453 
2016-12-08 00:20:03 -------------------LR------------------- 
2016-12-08 00:20:03 4.7683715820312e-07 
2016-12-08 00:20:03 Epoch 318 
2016-12-08 00:23:37 Training Error = 0.53231111111111 
2016-12-08 00:23:37 Training Loss = 0.031152610080295 
2016-12-08 00:23:41 Valid Error = 0.57031406281256 
2016-12-08 00:23:41 Valid Loss = 0.030671950107823 
2016-12-08 00:23:49 Test Error = 0.5698 
2016-12-08 00:23:49 Test Loss = 0.030651431152344 
2016-12-08 00:23:49 -------------------LR------------------- 
2016-12-08 00:23:49 4.7683715820312e-07 
2016-12-08 00:23:49 Epoch 319 
2016-12-08 00:27:31 Training Error = 0.53086666666667 
2016-12-08 00:27:31 Training Loss = 0.031129154079861 
2016-12-08 00:27:35 Valid Error = 0.57311462292458 
2016-12-08 00:27:35 Valid Loss = 0.030639475833744 
2016-12-08 00:27:43 Test Error = 0.5734 
2016-12-08 00:27:43 Test Loss = 0.030655804443359 
2016-12-08 00:27:43 -------------------LR------------------- 
2016-12-08 00:27:43 4.7683715820312e-07 
2016-12-08 00:27:43 Epoch 320 
2016-12-08 00:31:19 Training Error = 0.53173333333333 
2016-12-08 00:31:19 Training Loss = 0.031149385959201 
2016-12-08 00:31:23 Valid Error = 0.57091418283657 
2016-12-08 00:31:23 Valid Loss = 0.030751137429422 
2016-12-08 00:31:31 Test Error = 0.572 
2016-12-08 00:31:31 Test Loss = 0.030663173339844 
2016-12-08 00:31:31 -------------------LR------------------- 
2016-12-08 00:31:31 2.3841857910156e-07 
2016-12-08 00:31:31 Epoch 321 
2016-12-08 00:35:10 Training Error = 0.53008888888889 
2016-12-08 00:35:10 Training Loss = 0.031091905707465 
2016-12-08 00:35:14 Valid Error = 0.56751350270054 
2016-12-08 00:35:14 Valid Loss = 0.03049655125829 
2016-12-08 00:35:22 Test Error = 0.5654 
2016-12-08 00:35:22 Test Loss = 0.030530444580078 
2016-12-08 00:35:22 -------------------LR------------------- 
2016-12-08 00:35:22 2.3841857910156e-07 
2016-12-08 00:35:22 Epoch 322 
2016-12-08 00:38:52 Training Error = 0.52746666666667 
2016-12-08 00:38:52 Training Loss = 0.031105943467882 
2016-12-08 00:38:56 Valid Error = 0.56951390278056 
2016-12-08 00:38:56 Valid Loss = 0.030604530961626 
2016-12-08 00:39:04 Test Error = 0.5708 
2016-12-08 00:39:04 Test Loss = 0.030593343505859 
2016-12-08 00:39:04 -------------------LR------------------- 
2016-12-08 00:39:04 2.3841857910156e-07 
2016-12-08 00:39:04 Epoch 323 
2016-12-08 00:42:43 Training Error = 0.53188888888889 
2016-12-08 00:42:43 Training Loss = 0.031133766276042 
2016-12-08 00:42:47 Valid Error = 0.57211442288458 
2016-12-08 00:42:47 Valid Loss = 0.030815506586176 
2016-12-08 00:42:55 Test Error = 0.5746 
2016-12-08 00:42:55 Test Loss = 0.030779652832031 
2016-12-08 00:42:55 -------------------LR------------------- 
2016-12-08 00:42:55 2.3841857910156e-07 
2016-12-08 00:42:55 Epoch 324 
2016-12-08 00:46:17 Training Error = 0.53106666666667 
2016-12-08 00:46:17 Training Loss = 0.031119050184462 
2016-12-08 00:46:21 Valid Error = 0.57211442288458 
2016-12-08 00:46:21 Valid Loss = 0.030750836432135 
2016-12-08 00:46:29 Test Error = 0.5703 
2016-12-08 00:46:29 Test Loss = 0.030643132080078 
2016-12-08 00:46:29 -------------------LR------------------- 
2016-12-08 00:46:29 2.3841857910156e-07 
2016-12-08 00:46:29 Epoch 325 
2016-12-08 00:50:08 Training Error = 0.53162222222222 
2016-12-08 00:50:08 Training Loss = 0.031150309244792 
2016-12-08 00:50:12 Valid Error = 0.57851570314063 
2016-12-08 00:50:12 Valid Loss = 0.030852652386273 
2016-12-08 00:50:20 Test Error = 0.5735 
2016-12-08 00:50:20 Test Loss = 0.030802368652344 
2016-12-08 00:50:20 -------------------LR------------------- 
2016-12-08 00:50:20 2.3841857910156e-07 
2016-12-08 00:50:20 Epoch 326 
2016-12-08 00:53:51 Training Error = 0.53344444444444 
2016-12-08 00:53:51 Training Loss = 0.031146994357639 
2016-12-08 00:53:55 Valid Error = 0.57251450290058 
2016-12-08 00:53:55 Valid Loss = 0.030767307128906 
2016-12-08 00:54:03 Test Error = 0.5716 
2016-12-08 00:54:03 Test Loss = 0.030698256591797 
2016-12-08 00:54:03 -------------------LR------------------- 
2016-12-08 00:54:03 2.3841857910156e-07 
2016-12-08 00:54:03 Epoch 327 
2016-12-08 00:57:42 Training Error = 0.53148888888889 
2016-12-08 00:57:42 Training Loss = 0.031115525716146 
2016-12-08 00:57:46 Valid Error = 0.57151430286057 
2016-12-08 00:57:46 Valid Loss = 0.030707107913578 
2016-12-08 00:57:54 Test Error = 0.5707 
2016-12-08 00:57:54 Test Loss = 0.030725726074219 
2016-12-08 00:57:54 -------------------LR------------------- 
2016-12-08 00:57:54 2.3841857910156e-07 
2016-12-08 00:57:55 Epoch 328 
2016-12-08 01:01:28 Training Error = 0.53393333333333 
2016-12-08 01:01:28 Training Loss = 0.031166219238281 
2016-12-08 01:01:32 Valid Error = 0.57571514302861 
2016-12-08 01:01:32 Valid Loss = 0.030957802367797 
2016-12-08 01:01:40 Test Error = 0.5781 
2016-12-08 01:01:40 Test Loss = 0.030889535888672 
2016-12-08 01:01:40 -------------------LR------------------- 
2016-12-08 01:01:40 2.3841857910156e-07 
2016-12-08 01:01:40 Epoch 329 
2016-12-08 01:05:11 Training Error = 0.53066666666667 
2016-12-08 01:05:11 Training Loss = 0.031140711805556 
2016-12-08 01:05:15 Valid Error = 0.56931386277255 
2016-12-08 01:05:15 Valid Loss = 0.030648680990561 
2016-12-08 01:05:23 Test Error = 0.5708 
2016-12-08 01:05:23 Test Loss = 0.030619391601562 
2016-12-08 01:05:23 -------------------LR------------------- 
2016-12-08 01:05:23 2.3841857910156e-07 
2016-12-08 01:05:23 Epoch 330 
2016-12-08 01:09:00 Training Error = 0.53264444444444 
2016-12-08 01:09:00 Training Loss = 0.031125263183594 
2016-12-08 01:09:04 Valid Error = 0.56391278255651 
2016-12-08 01:09:04 Valid Loss = 0.030570337889159 
2016-12-08 01:09:12 Test Error = 0.5673 
2016-12-08 01:09:12 Test Loss = 0.030613056396484 
2016-12-08 01:09:12 -------------------LR------------------- 
2016-12-08 01:09:12 2.3841857910156e-07 
2016-12-08 01:09:12 Epoch 331 
2016-12-08 01:12:51 Training Error = 0.53077777777778 
2016-12-08 01:12:51 Training Loss = 0.031134286675347 
2016-12-08 01:12:56 Valid Error = 0.56511302260452 
2016-12-08 01:12:56 Valid Loss = 0.030674004005959 
2016-12-08 01:13:04 Test Error = 0.5681 
2016-12-08 01:13:04 Test Loss = 0.030632132568359 
2016-12-08 01:13:04 -------------------LR------------------- 
2016-12-08 01:13:04 2.3841857910156e-07 
2016-12-08 01:13:04 Epoch 332 
2016-12-08 01:16:38 Training Error = 0.53293333333333 
2016-12-08 01:16:38 Training Loss = 0.031161383246528 
2016-12-08 01:16:42 Valid Error = 0.57291458291658 
2016-12-08 01:16:42 Valid Loss = 0.030755919691176 
2016-12-08 01:16:50 Test Error = 0.5799 
2016-12-08 01:16:50 Test Loss = 0.030804947509766 
2016-12-08 01:16:50 -------------------LR------------------- 
2016-12-08 01:16:50 2.3841857910156e-07 
2016-12-08 01:16:50 Epoch 333 
2016-12-08 01:20:20 Training Error = 0.53217777777778 
2016-12-08 01:20:20 Training Loss = 0.031153508843316 
2016-12-08 01:20:24 Valid Error = 0.57771554310862 
2016-12-08 01:20:24 Valid Loss = 0.03089081120867 
2016-12-08 01:20:32 Test Error = 0.5772 
2016-12-08 01:20:32 Test Loss = 0.030815145263672 
2016-12-08 01:20:32 -------------------LR------------------- 
2016-12-08 01:20:32 2.3841857910156e-07 
2016-12-08 01:20:32 Epoch 334 
2016-12-08 01:24:04 Training Error = 0.53364444444444 
2016-12-08 01:24:04 Training Loss = 0.031150751139323 
2016-12-08 01:24:08 Valid Error = 0.5745149029806 
2016-12-08 01:24:08 Valid Loss = 0.030727719631741 
2016-12-08 01:24:16 Test Error = 0.577 
2016-12-08 01:24:16 Test Loss = 0.030721151123047 
2016-12-08 01:24:16 -------------------LR------------------- 
2016-12-08 01:24:16 2.3841857910156e-07 
2016-12-08 01:24:16 Epoch 335 
2016-12-08 01:27:52 Training Error = 0.53284444444444 
2016-12-08 01:27:52 Training Loss = 0.03116983203125 
2016-12-08 01:27:56 Valid Error = 0.57911582316463 
2016-12-08 01:27:56 Valid Loss = 0.030856111209354 
2016-12-08 01:28:04 Test Error = 0.5693 
2016-12-08 01:28:04 Test Loss = 0.030714728759766 
2016-12-08 01:28:04 -------------------LR------------------- 
2016-12-08 01:28:04 2.3841857910156e-07 
2016-12-08 01:28:04 Epoch 336 
2016-12-08 01:31:33 Training Error = 0.5328 
2016-12-08 01:31:33 Training Loss = 0.031157441189236 
2016-12-08 01:31:37 Valid Error = 0.57211442288458 
2016-12-08 01:31:37 Valid Loss = 0.03064433585783 
2016-12-08 01:31:45 Test Error = 0.5657 
2016-12-08 01:31:45 Test Loss = 0.030595179199219 
2016-12-08 01:31:45 -------------------LR------------------- 
2016-12-08 01:31:45 2.3841857910156e-07 
2016-12-08 01:31:45 Epoch 337 
