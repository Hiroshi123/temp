2016-12-11 13:53:49 [program started on Sun Dec 11 13:53:49 2016] 
2016-12-11 13:53:49 [command line arguments] 
2016-12-11 13:53:49 stcWeights false 
2016-12-11 13:53:49 LR 0.015625 
2016-12-11 13:53:49 batchSize 64 
2016-12-11 13:53:49 network ./Models/Cifar10_Custom 
2016-12-11 13:53:49 stcNeurons true 
2016-12-11 13:53:49 constBatchSize false 
2016-12-11 13:53:49 chartFileName chart1 
2016-12-11 13:53:49 dp_prepro false 
2016-12-11 13:53:49 nGPU 1 
2016-12-11 13:53:49 dataset Cifar100 
2016-12-11 13:53:49 type cuda 
2016-12-11 13:53:49 momentum 0 
2016-12-11 13:53:49 threads 8 
2016-12-11 13:53:49 weightDecay 0 
2016-12-11 13:53:49 runningVal false 
2016-12-11 13:53:49 convLayerN 6 
2016-12-11 13:53:49 LRDecay 0 
2016-12-11 13:53:49 numHid 2048 
2016-12-11 13:53:49 save /dev/shm/clone/temp/th/Results/Cifar100/model6-10-2048 
2016-12-11 13:53:49 augment false 
2016-12-11 13:53:49 epoch -1 
2016-12-11 13:53:49 modelsFolder ./Models/ 
2016-12-11 13:53:49 format rgb 
2016-12-11 13:53:49 preProcDir /dev/shm/clone/temp/th/PreProcData/Cifar100 
2016-12-11 13:53:49 imageFileExtension svg 
2016-12-11 13:53:49 channel 1 
2016-12-11 13:53:49 devid 6 
2016-12-11 13:53:49 visualize 1 
2016-12-11 13:53:49 LRDecayPerEpoch 0.0001 
2016-12-11 13:53:49 optimization adam 
2016-12-11 13:53:49 SBN true 
2016-12-11 13:53:49 normalization simple 
2016-12-11 13:53:49 title model1 
2016-12-11 13:53:49 load  
2016-12-11 13:53:49 whiten true 
2016-12-11 13:53:49 [----------------------] 
2016-12-11 13:53:51 ==> Network 
2016-12-11 13:53:51 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 2048)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(2048 -> 2048)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(2048 -> 100)
  (38): nn.BatchNormalization
} 
2016-12-11 13:53:51 ==>25768876 Parameters 
2016-12-11 13:53:51 ==> Loss 
2016-12-11 13:53:51 SqrtHingeEmbeddingCriterion 
2016-12-11 13:53:51 
==> Starting Training
 
2016-12-11 13:53:51 Epoch 1 
2016-12-11 14:02:44 Training Error = 0.92966666666667 
2016-12-11 14:02:44 Training Loss = 0.080974110520699 
2016-12-11 14:02:56 Valid Error = 0.90698139627926 
2016-12-11 14:02:56 Valid Loss = 0.03857257532168 
2016-12-11 14:03:19 Test Error = 0.9069 
2016-12-11 14:03:19 Test Loss = 0.03859399503963 
2016-12-11 14:03:19 -------------------LR------------------- 
2016-12-11 14:03:19 0.015625 
2016-12-11 14:03:19 Epoch 2 
2016-12-11 14:11:32 Training Error = 0.89666666666667 
2016-12-11 14:11:32 Training Loss = 0.038528363267806 
2016-12-11 14:11:44 Valid Error = 0.85957191438288 
2016-12-11 14:11:44 Valid Loss = 0.038102304215457 
2016-12-11 14:12:07 Test Error = 0.8639 
2016-12-11 14:12:07 Test Loss = 0.038160572583508 
2016-12-11 14:12:07 -------------------LR------------------- 
2016-12-11 14:12:07 0.015625 
2016-12-11 14:12:07 Epoch 3 
2016-12-11 14:20:18 Training Error = 0.85528888888889 
2016-12-11 14:20:18 Training Loss = 0.037999064685269 
2016-12-11 14:20:30 Valid Error = 0.83296659331866 
2016-12-11 14:20:30 Valid Loss = 0.037692917910881 
2016-12-11 14:20:53 Test Error = 0.8319 
2016-12-11 14:20:53 Test Loss = 0.037759096910999 
2016-12-11 14:20:53 -------------------LR------------------- 
2016-12-11 14:20:53 0.015625 
2016-12-11 14:20:53 Epoch 4 
2016-12-11 14:29:02 Training Error = 0.81848888888889 
2016-12-11 14:29:02 Training Loss = 0.037497796707533 
2016-12-11 14:29:13 Valid Error = 0.78495699139828 
2016-12-11 14:29:13 Valid Loss = 0.036958891284832 
2016-12-11 14:29:37 Test Error = 0.7887 
2016-12-11 14:29:37 Test Loss = 0.037062097506918 
2016-12-11 14:29:37 -------------------LR------------------- 
2016-12-11 14:29:37 0.015625 
2016-12-11 14:29:37 Epoch 5 
2016-12-11 14:37:48 Training Error = 0.78655555555556 
2016-12-11 14:37:48 Training Loss = 0.036984686113217 
2016-12-11 14:38:00 Valid Error = 0.76835367073415 
2016-12-11 14:38:00 Valid Loss = 0.036378837976921 
2016-12-11 14:38:23 Test Error = 0.7654 
2016-12-11 14:38:23 Test Loss = 0.036427754976188 
2016-12-11 14:38:23 -------------------LR------------------- 
2016-12-11 14:38:23 0.015625 
2016-12-11 14:38:23 Epoch 6 
2016-12-11 14:46:34 Training Error = 0.75971111111111 
2016-12-11 14:46:34 Training Loss = 0.036478961242193 
2016-12-11 14:46:46 Valid Error = 0.73194638927786 
2016-12-11 14:46:46 Valid Loss = 0.035420635858884 
2016-12-11 14:47:09 Test Error = 0.7386 
2016-12-11 14:47:09 Test Loss = 0.035507810753622 
2016-12-11 14:47:09 -------------------LR------------------- 
2016-12-11 14:47:09 0.015625 
2016-12-11 14:47:09 Epoch 7 
2016-12-11 14:55:20 Training Error = 0.73622222222222 
2016-12-11 14:55:20 Training Loss = 0.036105842634358 
2016-12-11 14:55:32 Valid Error = 0.70174034806961 
2016-12-11 14:55:32 Valid Loss = 0.034740157291212 
2016-12-11 14:55:55 Test Error = 0.707 
2016-12-11 14:55:55 Test Loss = 0.034832665601354 
2016-12-11 14:55:55 -------------------LR------------------- 
2016-12-11 14:55:55 0.015625 
2016-12-11 14:55:55 Epoch 8 
2016-12-11 15:04:05 Training Error = 0.71764444444444 
2016-12-11 15:04:05 Training Loss = 0.035768579823727 
2016-12-11 15:04:17 Valid Error = 0.68473694738948 
2016-12-11 15:04:17 Valid Loss = 0.034259903543034 
2016-12-11 15:04:41 Test Error = 0.6881 
2016-12-11 15:04:41 Test Loss = 0.03439652754243 
2016-12-11 15:04:41 -------------------LR------------------- 
2016-12-11 15:04:41 0.015625 
2016-12-11 15:04:41 Epoch 9 
2016-12-11 15:12:52 Training Error = 0.70202222222222 
2016-12-11 15:12:52 Training Loss = 0.035492008931258 
2016-12-11 15:13:03 Valid Error = 0.69333866773355 
2016-12-11 15:13:03 Valid Loss = 0.034075725880497 
2016-12-11 15:13:27 Test Error = 0.6909 
2016-12-11 15:13:27 Test Loss = 0.03417949419872 
2016-12-11 15:13:27 -------------------LR------------------- 
2016-12-11 15:13:27 0.015625 
2016-12-11 15:13:27 Epoch 10 
2016-12-11 15:21:41 Training Error = 0.69073333333333 
2016-12-11 15:21:41 Training Loss = 0.035280479321426 
2016-12-11 15:21:53 Valid Error = 0.6879375875175 
2016-12-11 15:21:53 Valid Loss = 0.034058988577203 
2016-12-11 15:22:17 Test Error = 0.6926 
2016-12-11 15:22:17 Test Loss = 0.034165912904557 
2016-12-11 15:22:17 -------------------LR------------------- 
2016-12-11 15:22:17 0.015625 
2016-12-11 15:22:17 Epoch 11 
2016-12-11 15:30:25 Training Error = 0.67951111111111 
2016-12-11 15:30:25 Training Loss = 0.034956455823373 
2016-12-11 15:30:36 Valid Error = 0.68393678735747 
2016-12-11 15:30:36 Valid Loss = 0.033886629646984 
2016-12-11 15:31:00 Test Error = 0.6879 
2016-12-11 15:31:00 Test Loss = 0.033950988001125 
2016-12-11 15:31:00 -------------------LR------------------- 
2016-12-11 15:31:00 0.015625 
2016-12-11 15:31:00 Epoch 12 
2016-12-11 15:39:07 Training Error = 0.67802222222222 
2016-12-11 15:39:07 Training Loss = 0.034939873523333 
2016-12-11 15:39:18 Valid Error = 0.68153630726145 
2016-12-11 15:39:18 Valid Loss = 0.033795238330179 
2016-12-11 15:39:42 Test Error = 0.6824 
2016-12-11 15:39:42 Test Loss = 0.03389026596288 
2016-12-11 15:39:42 -------------------LR------------------- 
2016-12-11 15:39:42 0.015625 
2016-12-11 15:39:42 Epoch 13 
2016-12-11 15:47:47 Training Error = 0.67964444444444 
2016-12-11 15:47:47 Training Loss = 0.034952185963365 
2016-12-11 15:47:59 Valid Error = 0.67653530706141 
2016-12-11 15:47:59 Valid Loss = 0.03369946642767 
2016-12-11 15:48:22 Test Error = 0.6786 
2016-12-11 15:48:22 Test Loss = 0.033787227785511 
2016-12-11 15:48:22 -------------------LR------------------- 
2016-12-11 15:48:22 0.015625 
2016-12-11 15:48:22 Epoch 14 
2016-12-11 15:56:29 Training Error = 0.67808888888889 
2016-12-11 15:56:29 Training Loss = 0.034937235719778 
2016-12-11 15:56:41 Valid Error = 0.68833766753351 
2016-12-11 15:56:41 Valid Loss = 0.034142249846329 
2016-12-11 15:57:04 Test Error = 0.6944 
2016-12-11 15:57:04 Test Loss = 0.034239440252826 
2016-12-11 15:57:04 -------------------LR------------------- 
2016-12-11 15:57:04 0.015625 
2016-12-11 15:57:04 Epoch 15 
2016-12-11 16:05:11 Training Error = 0.67886666666667 
2016-12-11 16:05:11 Training Loss = 0.034936908473345 
2016-12-11 16:05:23 Valid Error = 0.68513702740548 
2016-12-11 16:05:23 Valid Loss = 0.034019785819821 
2016-12-11 16:05:46 Test Error = 0.6901 
2016-12-11 16:05:46 Test Loss = 0.03414767294173 
2016-12-11 16:05:46 -------------------LR------------------- 
2016-12-11 16:05:46 0.015625 
2016-12-11 16:05:46 Epoch 16 
2016-12-11 16:13:54 Training Error = 0.67846666666667 
2016-12-11 16:13:54 Training Loss = 0.034947560707276 
2016-12-11 16:14:06 Valid Error = 0.67093418683737 
2016-12-11 16:14:06 Valid Loss = 0.033441974745952 
2016-12-11 16:14:29 Test Error = 0.6753 
2016-12-11 16:14:29 Test Loss = 0.033522047449829 
2016-12-11 16:14:29 -------------------LR------------------- 
2016-12-11 16:14:29 0.015625 
2016-12-11 16:14:29 Epoch 17 
2016-12-11 16:22:32 Training Error = 0.67675555555556 
2016-12-11 16:22:32 Training Loss = 0.034908606200056 
2016-12-11 16:22:43 Valid Error = 0.67813562712543 
2016-12-11 16:22:43 Valid Loss = 0.033786256434042 
2016-12-11 16:23:07 Test Error = 0.6818 
2016-12-11 16:23:07 Test Loss = 0.033878945575398 
2016-12-11 16:23:07 -------------------LR------------------- 
2016-12-11 16:23:07 0.015625 
2016-12-11 16:23:07 Epoch 18 
2016-12-11 16:31:10 Training Error = 0.67811111111111 
2016-12-11 16:31:10 Training Loss = 0.034951619986783 
2016-12-11 16:31:22 Valid Error = 0.67053410682136 
2016-12-11 16:31:22 Valid Loss = 0.033594690455666 
2016-12-11 16:31:45 Test Error = 0.6722 
2016-12-11 16:31:45 Test Loss = 0.033689062124605 
2016-12-11 16:31:45 -------------------LR------------------- 
2016-12-11 16:31:45 0.015625 
2016-12-11 16:31:45 Epoch 19 
2016-12-11 16:39:50 Training Error = 0.678 
2016-12-11 16:39:50 Training Loss = 0.034957081065936 
2016-12-11 16:40:02 Valid Error = 0.68393678735747 
2016-12-11 16:40:02 Valid Loss = 0.03387246381094 
2016-12-11 16:40:25 Test Error = 0.6868 
2016-12-11 16:40:25 Test Loss = 0.0339957420993 
2016-12-11 16:40:25 -------------------LR------------------- 
2016-12-11 16:40:25 0.015625 
2016-12-11 16:40:25 Epoch 20 
2016-12-11 16:48:28 Training Error = 0.67897777777778 
2016-12-11 16:48:28 Training Loss = 0.034945368360389 
2016-12-11 16:48:40 Valid Error = 0.67573514702941 
2016-12-11 16:48:40 Valid Loss = 0.033665295875956 
2016-12-11 16:49:03 Test Error = 0.6749 
2016-12-11 16:49:03 Test Loss = 0.033783855802694 
2016-12-11 16:49:03 -------------------LR------------------- 
2016-12-11 16:49:03 0.015625 
2016-12-11 16:49:03 Epoch 21 
2016-12-11 16:57:05 Training Error = 0.68051111111111 
2016-12-11 16:57:05 Training Loss = 0.034972107281739 
2016-12-11 16:57:16 Valid Error = 0.67413482696539 
2016-12-11 16:57:16 Valid Loss = 0.033658616969641 
2016-12-11 16:57:39 Test Error = 0.6808 
2016-12-11 16:57:39 Test Loss = 0.033791389465332 
2016-12-11 16:57:39 -------------------LR------------------- 
2016-12-11 16:57:39 0.015625 
2016-12-11 16:57:40 Epoch 22 
2016-12-11 17:05:39 Training Error = 0.67824444444444 
2016-12-11 17:05:39 Training Loss = 0.034926120306958 
2016-12-11 17:05:50 Valid Error = 0.67993598719744 
2016-12-11 17:05:50 Valid Loss = 0.033729304801706 
2016-12-11 17:06:14 Test Error = 0.6793 
2016-12-11 17:06:14 Test Loss = 0.033836636497716 
2016-12-11 17:06:14 -------------------LR------------------- 
2016-12-11 17:06:14 0.015625 
2016-12-11 17:06:14 Epoch 23 
2016-12-11 17:14:12 Training Error = 0.67948888888889 
2016-12-11 17:14:12 Training Loss = 0.034948424029757 
2016-12-11 17:14:23 Valid Error = 0.6745349069814 
2016-12-11 17:14:23 Valid Loss = 0.033711352947608 
2016-12-11 17:14:47 Test Error = 0.6753 
2016-12-11 17:14:47 Test Loss = 0.033792257263402 
2016-12-11 17:14:47 -------------------LR------------------- 
2016-12-11 17:14:47 0.015625 
2016-12-11 17:14:47 Epoch 24 
2016-12-11 17:22:47 Training Error = 0.67715555555556 
2016-12-11 17:22:47 Training Loss = 0.034937407499687 
2016-12-11 17:22:58 Valid Error = 0.68853770754151 
2016-12-11 17:22:58 Valid Loss = 0.033952070243967 
2016-12-11 17:23:22 Test Error = 0.6852 
2016-12-11 17:23:22 Test Loss = 0.034053347384094 
2016-12-11 17:23:22 -------------------LR------------------- 
2016-12-11 17:23:22 0.015625 
2016-12-11 17:23:22 Epoch 25 
2016-12-11 17:31:20 Training Error = 0.67797777777778 
2016-12-11 17:31:20 Training Loss = 0.034948856681585 
2016-12-11 17:31:31 Valid Error = 0.68293658731746 
2016-12-11 17:31:31 Valid Loss = 0.033940308477736 
2016-12-11 17:31:55 Test Error = 0.684 
2016-12-11 17:31:55 Test Loss = 0.034078637870254 
2016-12-11 17:31:55 -------------------LR------------------- 
2016-12-11 17:31:55 0.015625 
2016-12-11 17:31:55 Epoch 26 
2016-12-11 17:39:57 Training Error = 0.6808 
2016-12-11 17:39:57 Training Loss = 0.034960646554828 
2016-12-11 17:40:09 Valid Error = 0.67973594718944 
2016-12-11 17:40:09 Valid Loss = 0.033720189171286 
2016-12-11 17:40:32 Test Error = 0.6771 
2016-12-11 17:40:32 Test Loss = 0.033832808345746 
2016-12-11 17:40:32 -------------------LR------------------- 
2016-12-11 17:40:32 0.015625 
2016-12-11 17:40:32 Epoch 27 
2016-12-11 17:48:30 Training Error = 0.68002222222222 
2016-12-11 17:48:30 Training Loss = 0.034958134019239 
2016-12-11 17:48:42 Valid Error = 0.67133426685337 
2016-12-11 17:48:42 Valid Loss = 0.033625339629637 
2016-12-11 17:49:05 Test Error = 0.6768 
2016-12-11 17:49:05 Test Loss = 0.033718543690481 
2016-12-11 17:49:05 -------------------LR------------------- 
2016-12-11 17:49:05 0.015625 
2016-12-11 17:49:05 Epoch 28 
2016-12-11 17:57:08 Training Error = 0.679 
2016-12-11 17:57:08 Training Loss = 0.034942619936033 
2016-12-11 17:57:20 Valid Error = 0.67253450690138 
2016-12-11 17:57:20 Valid Loss = 0.033556120115422 
2016-12-11 17:57:43 Test Error = 0.6715 
2016-12-11 17:57:43 Test Loss = 0.033659874238786 
2016-12-11 17:57:43 -------------------LR------------------- 
2016-12-11 17:57:43 0.015625 
2016-12-11 17:57:43 Epoch 29 
2016-12-11 18:05:45 Training Error = 0.67791111111111 
2016-12-11 18:05:45 Training Loss = 0.03494539632716 
2016-12-11 18:05:57 Valid Error = 0.6745349069814 
2016-12-11 18:05:57 Valid Loss = 0.033525127200494 
2016-12-11 18:06:21 Test Error = 0.6718 
2016-12-11 18:06:21 Test Loss = 0.033618357242293 
2016-12-11 18:06:21 -------------------LR------------------- 
2016-12-11 18:06:21 0.015625 
2016-12-11 18:06:21 Epoch 30 
2016-12-11 18:14:23 Training Error = 0.67822222222222 
2016-12-11 18:14:23 Training Loss = 0.034934391836551 
2016-12-11 18:14:34 Valid Error = 0.67893578715743 
2016-12-11 18:14:34 Valid Loss = 0.033854556105236 
2016-12-11 18:14:57 Test Error = 0.6865 
2016-12-11 18:14:57 Test Loss = 0.033976691589234 
2016-12-11 18:14:57 -------------------LR------------------- 
2016-12-11 18:14:57 0.015625 
2016-12-11 18:14:58 Epoch 31 
2016-12-11 18:23:01 Training Error = 0.67653333333333 
2016-12-11 18:23:01 Training Loss = 0.034935741373761 
2016-12-11 18:23:13 Valid Error = 0.69053810762152 
2016-12-11 18:23:13 Valid Loss = 0.033879856908084 
2016-12-11 18:23:36 Test Error = 0.6931 
2016-12-11 18:23:36 Test Loss = 0.033991729803146 
2016-12-11 18:23:36 -------------------LR------------------- 
2016-12-11 18:23:36 0.015625 
2016-12-11 18:23:36 Epoch 32 
2016-12-11 18:31:38 Training Error = 0.67833333333333 
2016-12-11 18:31:38 Training Loss = 0.034942815632305 
2016-12-11 18:31:49 Valid Error = 0.68153630726145 
2016-12-11 18:31:49 Valid Loss = 0.03384133890352 
2016-12-11 18:32:13 Test Error = 0.6817 
2016-12-11 18:32:13 Test Loss = 0.0339315640243 
2016-12-11 18:32:13 -------------------LR------------------- 
2016-12-11 18:32:13 0.015625 
2016-12-11 18:32:13 Epoch 33 
2016-12-11 18:40:23 Training Error = 0.67711111111111 
2016-12-11 18:40:23 Training Loss = 0.034944887239147 
2016-12-11 18:40:35 Valid Error = 0.68273654730946 
2016-12-11 18:40:35 Valid Loss = 0.03391475790448 
2016-12-11 18:40:58 Test Error = 0.6807 
2016-12-11 18:40:58 Test Loss = 0.033999765238185 
2016-12-11 18:40:58 -------------------LR------------------- 
2016-12-11 18:40:58 0.015625 
2016-12-11 18:40:58 Epoch 34 
2016-12-11 18:49:05 Training Error = 0.67924444444444 
2016-12-11 18:49:05 Training Loss = 0.034941885437478 
2016-12-11 18:49:17 Valid Error = 0.67393478695739 
2016-12-11 18:49:17 Valid Loss = 0.033681045113162 
2016-12-11 18:49:40 Test Error = 0.6792 
2016-12-11 18:49:40 Test Loss = 0.033799434482672 
2016-12-11 18:49:40 -------------------LR------------------- 
2016-12-11 18:49:40 0.015625 
2016-12-11 18:49:40 Epoch 35 
2016-12-11 18:57:47 Training Error = 0.68035555555556 
2016-12-11 18:57:47 Training Loss = 0.034952164556492 
2016-12-11 18:57:59 Valid Error = 0.69053810762152 
2016-12-11 18:57:59 Valid Loss = 0.034028695241883 
2016-12-11 18:58:22 Test Error = 0.6894 
2016-12-11 18:58:22 Test Loss = 0.034096302196478 
2016-12-11 18:58:22 -------------------LR------------------- 
2016-12-11 18:58:22 0.015625 
2016-12-11 18:58:22 Epoch 36 
2016-12-11 19:06:27 Training Error = 0.67891111111111 
2016-12-11 19:06:27 Training Loss = 0.034958605776456 
2016-12-11 19:06:38 Valid Error = 0.67673534706941 
2016-12-11 19:06:38 Valid Loss = 0.033684629924043 
2016-12-11 19:07:02 Test Error = 0.6796 
2016-12-11 19:07:02 Test Loss = 0.033802387851059 
2016-12-11 19:07:02 -------------------LR------------------- 
2016-12-11 19:07:02 0.015625 
2016-12-11 19:07:02 Epoch 37 
2016-12-11 19:15:06 Training Error = 0.67828888888889 
2016-12-11 19:15:06 Training Loss = 0.034937473024157 
2016-12-11 19:15:18 Valid Error = 0.68493698739748 
2016-12-11 19:15:18 Valid Loss = 0.033778191828598 
2016-12-11 19:15:41 Test Error = 0.6856 
2016-12-11 19:15:41 Test Loss = 0.033891777961877 
2016-12-11 19:15:41 -------------------LR------------------- 
2016-12-11 19:15:41 0.015625 
2016-12-11 19:15:41 Epoch 38 
2016-12-11 19:23:46 Training Error = 0.67775555555556 
2016-12-11 19:23:46 Training Loss = 0.034954012581571 
2016-12-11 19:23:57 Valid Error = 0.67353470694139 
2016-12-11 19:23:57 Valid Loss = 0.033512137694988 
2016-12-11 19:24:21 Test Error = 0.6745 
2016-12-11 19:24:21 Test Loss = 0.033608287565268 
2016-12-11 19:24:21 -------------------LR------------------- 
2016-12-11 19:24:21 0.015625 
2016-12-11 19:24:21 Epoch 39 
2016-12-11 19:32:23 Training Error = 0.67877777777778 
2016-12-11 19:32:23 Training Loss = 0.034947033324702 
2016-12-11 19:32:34 Valid Error = 0.66633326665333 
2016-12-11 19:32:34 Valid Loss = 0.033526894606475 
2016-12-11 19:32:58 Test Error = 0.6715 
2016-12-11 19:32:58 Test Loss = 0.033615953618554 
2016-12-11 19:32:58 -------------------LR------------------- 
2016-12-11 19:32:58 0.015625 
2016-12-11 19:32:58 Epoch 40 
2016-12-11 19:41:02 Training Error = 0.67784444444444 
2016-12-11 19:41:02 Training Loss = 0.034938448064707 
2016-12-11 19:41:13 Valid Error = 0.6877375475095 
2016-12-11 19:41:13 Valid Loss = 0.034020731957868 
2016-12-11 19:41:37 Test Error = 0.6874 
2016-12-11 19:41:37 Test Loss = 0.034089356167301 
2016-12-11 19:41:37 -------------------LR------------------- 
2016-12-11 19:41:37 0.015625 
2016-12-11 19:41:37 Epoch 41 
2016-12-11 19:49:41 Training Error = 0.67595555555556 
2016-12-11 19:49:41 Training Loss = 0.034932532252913 
2016-12-11 19:49:52 Valid Error = 0.6751350270054 
2016-12-11 19:49:52 Valid Loss = 0.033670935346248 
2016-12-11 19:50:16 Test Error = 0.6782 
2016-12-11 19:50:16 Test Loss = 0.033797401136653 
2016-12-11 19:50:16 -------------------LR------------------- 
2016-12-11 19:50:16 0.015625 
2016-12-11 19:50:16 Epoch 42 
2016-12-11 19:58:12 Training Error = 0.67817777777778 
2016-12-11 19:58:12 Training Loss = 0.034952149892395 
2016-12-11 19:58:24 Valid Error = 0.68213642728546 
2016-12-11 19:58:24 Valid Loss = 0.033906147743004 
2016-12-11 19:58:47 Test Error = 0.6846 
2016-12-11 19:58:47 Test Loss = 0.033985106747621 
2016-12-11 19:58:47 -------------------LR------------------- 
2016-12-11 19:58:47 0.015625 
2016-12-11 19:58:47 Epoch 43 
2016-12-11 20:06:44 Training Error = 0.67766666666667 
2016-12-11 20:06:44 Training Loss = 0.034941926686601 
2016-12-11 20:06:56 Valid Error = 0.66913382676535 
2016-12-11 20:06:56 Valid Loss = 0.033559424079564 
2016-12-11 20:07:19 Test Error = 0.6737 
2016-12-11 20:07:19 Test Loss = 0.033675765049685 
2016-12-11 20:07:19 -------------------LR------------------- 
2016-12-11 20:07:19 0.015625 
2016-12-11 20:07:19 Epoch 44 
2016-12-11 20:15:20 Training Error = 0.67864444444444 
2016-12-11 20:15:20 Training Loss = 0.034950627582994 
2016-12-11 20:15:31 Valid Error = 0.68613722744549 
2016-12-11 20:15:31 Valid Loss = 0.033889721836794 
2016-12-11 20:15:55 Test Error = 0.6822 
2016-12-11 20:15:55 Test Loss = 0.033992588580794 
2016-12-11 20:15:55 -------------------LR------------------- 
2016-12-11 20:15:55 0.015625 
2016-12-11 20:15:55 Epoch 45 
2016-12-11 20:23:54 Training Error = 0.67993333333333 
2016-12-11 20:23:54 Training Loss = 0.034941996894777 
2016-12-11 20:24:06 Valid Error = 0.68133626725345 
2016-12-11 20:24:06 Valid Loss = 0.033862801645807 
2016-12-11 20:24:29 Test Error = 0.6857 
2016-12-11 20:24:29 Test Loss = 0.033968121063937 
2016-12-11 20:24:29 -------------------LR------------------- 
2016-12-11 20:24:29 0.015625 
2016-12-11 20:24:29 Epoch 46 
2016-12-11 20:32:34 Training Error = 0.67724444444444 
2016-12-11 20:32:34 Training Loss = 0.034941954412921 
2016-12-11 20:32:45 Valid Error = 0.6747349469894 
2016-12-11 20:32:45 Valid Loss = 0.033654939404017 
2016-12-11 20:33:09 Test Error = 0.676 
2016-12-11 20:33:09 Test Loss = 0.033741469292124 
2016-12-11 20:33:09 -------------------LR------------------- 
2016-12-11 20:33:09 0.015625 
2016-12-11 20:33:09 Epoch 47 
2016-12-11 20:41:10 Training Error = 0.67657777777778 
2016-12-11 20:41:10 Training Loss = 0.034951246160675 
2016-12-11 20:41:21 Valid Error = 0.66953390678136 
2016-12-11 20:41:21 Valid Loss = 0.033647677846671 
2016-12-11 20:41:45 Test Error = 0.6697 
2016-12-11 20:41:45 Test Loss = 0.033749216012894 
2016-12-11 20:41:45 -------------------LR------------------- 
2016-12-11 20:41:45 0.015625 
2016-12-11 20:41:45 Epoch 48 
2016-12-11 20:49:47 Training Error = 0.67964444444444 
2016-12-11 20:49:47 Training Loss = 0.03493967526677 
2016-12-11 20:49:58 Valid Error = 0.68953790758152 
2016-12-11 20:49:58 Valid Loss = 0.033993393542754 
2016-12-11 20:50:22 Test Error = 0.6893 
2016-12-11 20:50:22 Test Loss = 0.034087854008766 
2016-12-11 20:50:22 -------------------LR------------------- 
2016-12-11 20:50:22 0.015625 
2016-12-11 20:50:22 Epoch 49 
2016-12-11 20:58:23 Training Error = 0.67631111111111 
2016-12-11 20:58:23 Training Loss = 0.034949774715033 
2016-12-11 20:58:35 Valid Error = 0.68033606721344 
2016-12-11 20:58:35 Valid Loss = 0.033818172300487 
2016-12-11 20:58:58 Test Error = 0.6821 
2016-12-11 20:58:58 Test Loss = 0.033920941762863 
2016-12-11 20:58:58 -------------------LR------------------- 
2016-12-11 20:58:58 0.015625 
2016-12-11 20:58:58 Epoch 50 
2016-12-11 21:07:00 Training Error = 0.67924444444444 
2016-12-11 21:07:00 Training Loss = 0.03494864682921 
2016-12-11 21:07:11 Valid Error = 0.68553710742148 
2016-12-11 21:07:11 Valid Loss = 0.033757448778446 
2016-12-11 21:07:35 Test Error = 0.6846 
2016-12-11 21:07:35 Test Loss = 0.033885284517981 
2016-12-11 21:07:35 -------------------LR------------------- 
2016-12-11 21:07:35 0.0078125 
2016-12-11 21:07:35 Epoch 51 
2016-12-11 21:15:38 Training Error = 0.67951111111111 
2016-12-11 21:15:38 Training Loss = 0.034962108975107 
2016-12-11 21:15:50 Valid Error = 0.68313662732547 
2016-12-11 21:15:50 Valid Loss = 0.033843300825433 
2016-12-11 21:16:13 Test Error = 0.6834 
2016-12-11 21:16:13 Test Loss = 0.033958997650511 
2016-12-11 21:16:13 -------------------LR------------------- 
2016-12-11 21:16:13 0.0078125 
2016-12-11 21:16:13 Epoch 52 
2016-12-11 21:24:10 Training Error = 0.67964444444444 
2016-12-11 21:24:10 Training Loss = 0.034961340691556 
2016-12-11 21:24:22 Valid Error = 0.68853770754151 
2016-12-11 21:24:22 Valid Loss = 0.03383082567891 
2016-12-11 21:24:45 Test Error = 0.6863 
2016-12-11 21:24:45 Test Loss = 0.033917981317848 
2016-12-11 21:24:45 -------------------LR------------------- 
2016-12-11 21:24:45 0.0078125 
2016-12-11 21:24:45 Epoch 53 
2016-12-11 21:32:47 Training Error = 0.68073333333333 
2016-12-11 21:32:47 Training Loss = 0.034963149042292 
2016-12-11 21:32:58 Valid Error = 0.67693538707742 
2016-12-11 21:32:58 Valid Loss = 0.033612689178632 
2016-12-11 21:33:22 Test Error = 0.673 
2016-12-11 21:33:22 Test Loss = 0.033688212109219 
2016-12-11 21:33:22 -------------------LR------------------- 
2016-12-11 21:33:22 0.0078125 
2016-12-11 21:33:22 Epoch 54 
2016-12-11 21:41:23 Training Error = 0.67795555555556 
2016-12-11 21:41:23 Training Loss = 0.034950204430656 
2016-12-11 21:41:34 Valid Error = 0.68253650730146 
2016-12-11 21:41:34 Valid Loss = 0.033768318315958 
2016-12-11 21:41:58 Test Error = 0.6805 
2016-12-11 21:41:58 Test Loss = 0.033895581239348 
2016-12-11 21:41:58 -------------------LR------------------- 
2016-12-11 21:41:58 0.0078125 
2016-12-11 21:41:58 Epoch 55 
2016-12-11 21:49:58 Training Error = 0.67842222222222 
2016-12-11 21:49:58 Training Loss = 0.034943186166612 
2016-12-11 21:50:10 Valid Error = 0.68053610722144 
2016-12-11 21:50:10 Valid Loss = 0.033849521989633 
2016-12-11 21:50:33 Test Error = 0.6843 
2016-12-11 21:50:33 Test Loss = 0.033969735172903 
2016-12-11 21:50:33 -------------------LR------------------- 
2016-12-11 21:50:33 0.0078125 
2016-12-11 21:50:33 Epoch 56 
2016-12-11 21:58:36 Training Error = 0.67815555555556 
2016-12-11 21:58:36 Training Loss = 0.034961828992448 
2016-12-11 21:58:48 Valid Error = 0.6753350670134 
2016-12-11 21:58:48 Valid Loss = 0.033538827792645 
2016-12-11 21:59:11 Test Error = 0.6717 
2016-12-11 21:59:11 Test Loss = 0.033661313831427 
2016-12-11 21:59:11 -------------------LR------------------- 
2016-12-11 21:59:11 0.0078125 
2016-12-11 21:59:11 Epoch 57 
2016-12-11 22:07:14 Training Error = 0.67873333333333 
2016-12-11 22:07:14 Training Loss = 0.034952115907588 
2016-12-11 22:07:26 Valid Error = 0.67433486697339 
2016-12-11 22:07:26 Valid Loss = 0.033654670517009 
2016-12-11 22:07:49 Test Error = 0.6736 
2016-12-11 22:07:49 Test Loss = 0.033756458258173 
2016-12-11 22:07:49 -------------------LR------------------- 
2016-12-11 22:07:49 0.0078125 
2016-12-11 22:07:49 Epoch 58 
2016-12-11 22:15:53 Training Error = 0.68053333333333 
2016-12-11 22:15:53 Training Loss = 0.034944611814889 
2016-12-11 22:16:04 Valid Error = 0.67993598719744 
2016-12-11 22:16:04 Valid Loss = 0.033733790170866 
2016-12-11 22:16:28 Test Error = 0.6798 
2016-12-11 22:16:28 Test Loss = 0.033837809972702 
2016-12-11 22:16:28 -------------------LR------------------- 
2016-12-11 22:16:28 0.0078125 
2016-12-11 22:16:28 Epoch 59 
2016-12-11 22:24:25 Training Error = 0.6782 
2016-12-11 22:24:25 Training Loss = 0.034939274676144 
2016-12-11 22:24:37 Valid Error = 0.68013602720544 
2016-12-11 22:24:37 Valid Loss = 0.033651236819531 
2016-12-11 22:25:00 Test Error = 0.6778 
2016-12-11 22:25:00 Test Loss = 0.033759233222646 
2016-12-11 22:25:00 -------------------LR------------------- 
2016-12-11 22:25:00 0.0078125 
2016-12-11 22:25:00 Epoch 60 
2016-12-11 22:33:01 Training Error = 0.6776 
2016-12-11 22:33:01 Training Loss = 0.034947275014764 
2016-12-11 22:33:13 Valid Error = 0.68573714742949 
2016-12-11 22:33:13 Valid Loss = 0.033968367464504 
2016-12-11 22:33:36 Test Error = 0.6873 
2016-12-11 22:33:36 Test Loss = 0.034115276032952 
2016-12-11 22:33:36 -------------------LR------------------- 
2016-12-11 22:33:36 0.0078125 
2016-12-11 22:33:36 Epoch 61 
2016-12-11 22:41:41 Training Error = 0.67906666666667 
2016-12-11 22:41:41 Training Loss = 0.034956562972882 
2016-12-11 22:41:52 Valid Error = 0.66853370674135 
2016-12-11 22:41:52 Valid Loss = 0.033577730349563 
2016-12-11 22:42:16 Test Error = 0.6689 
2016-12-11 22:42:16 Test Loss = 0.033638905157709 
2016-12-11 22:42:16 -------------------LR------------------- 
2016-12-11 22:42:16 0.0078125 
2016-12-11 22:42:16 Epoch 62 
2016-12-11 22:50:19 Training Error = 0.67871111111111 
2016-12-11 22:50:19 Training Loss = 0.034962347075343 
2016-12-11 22:50:31 Valid Error = 0.67913582716543 
2016-12-11 22:50:31 Valid Loss = 0.033689836451201 
2016-12-11 22:50:54 Test Error = 0.6824 
2016-12-11 22:50:54 Test Loss = 0.033790739706367 
2016-12-11 22:50:54 -------------------LR------------------- 
2016-12-11 22:50:54 0.0078125 
2016-12-11 22:50:54 Epoch 63 
2016-12-11 22:58:58 Training Error = 0.67742222222222 
2016-12-11 22:58:58 Training Loss = 0.034933506280861 
2016-12-11 22:59:09 Valid Error = 0.67893578715743 
2016-12-11 22:59:09 Valid Loss = 0.033759143201611 
2016-12-11 22:59:33 Test Error = 0.6752 
2016-12-11 22:59:33 Test Loss = 0.033861535020695 
2016-12-11 22:59:33 -------------------LR------------------- 
2016-12-11 22:59:33 0.0078125 
2016-12-11 22:59:33 Epoch 64 
2016-12-11 23:07:36 Training Error = 0.67713333333333 
2016-12-11 23:07:36 Training Loss = 0.034941807365553 
2016-12-11 23:07:47 Valid Error = 0.68253650730146 
2016-12-11 23:07:47 Valid Loss = 0.033759493107822 
2016-12-11 23:08:11 Test Error = 0.6842 
2016-12-11 23:08:11 Test Loss = 0.033858948057624 
2016-12-11 23:08:11 -------------------LR------------------- 
2016-12-11 23:08:11 0.0078125 
2016-12-11 23:08:11 Epoch 65 
2016-12-11 23:16:15 Training Error = 0.67884444444444 
2016-12-11 23:16:15 Training Loss = 0.03495247467675 
2016-12-11 23:16:26 Valid Error = 0.67633526705341 
2016-12-11 23:16:26 Valid Loss = 0.033683426030937 
2016-12-11 23:16:50 Test Error = 0.678 
2016-12-11 23:16:50 Test Loss = 0.033778676607047 
2016-12-11 23:16:50 -------------------LR------------------- 
2016-12-11 23:16:50 0.0078125 
2016-12-11 23:16:50 Epoch 66 
2016-12-11 23:24:54 Training Error = 0.67862222222222 
2016-12-11 23:24:54 Training Loss = 0.034951718900014 
2016-12-11 23:25:06 Valid Error = 0.68853770754151 
2016-12-11 23:25:06 Valid Loss = 0.03405035795398 
2016-12-11 23:25:29 Test Error = 0.6914 
2016-12-11 23:25:29 Test Loss = 0.034155835953488 
2016-12-11 23:25:29 -------------------LR------------------- 
2016-12-11 23:25:29 0.0078125 
2016-12-11 23:25:30 Epoch 67 
2016-12-11 23:35:07 Training Error = 0.67864444444444 
2016-12-11 23:35:07 Training Loss = 0.034940371526913 
2016-12-11 23:35:19 Valid Error = 0.67133426685337 
2016-12-11 23:35:19 Valid Loss = 0.033507364494676 
2016-12-11 23:35:43 Test Error = 0.6721 
2016-12-11 23:35:43 Test Loss = 0.033577690321928 
2016-12-11 23:35:43 -------------------LR------------------- 
2016-12-11 23:35:43 0.0078125 
2016-12-11 23:35:43 Epoch 68 
2016-12-11 23:46:38 Training Error = 0.6802 
2016-12-11 23:46:38 Training Loss = 0.034948435246267 
2016-12-11 23:46:49 Valid Error = 0.6747349469894 
2016-12-11 23:46:49 Valid Loss = 0.033661945913843 
2016-12-11 23:47:13 Test Error = 0.6747 
2016-12-11 23:47:13 Test Loss = 0.033741014899722 
2016-12-11 23:47:13 -------------------LR------------------- 
2016-12-11 23:47:13 0.0078125 
2016-12-11 23:47:13 Epoch 69 
2016-12-11 23:57:21 Training Error = 0.6806 
2016-12-11 23:57:21 Training Loss = 0.034969243634154 
2016-12-11 23:57:33 Valid Error = 0.67653530706141 
2016-12-11 23:57:33 Valid Loss = 0.03375973098748 
2016-12-11 23:57:57 Test Error = 0.6836 
2016-12-11 23:57:57 Test Loss = 0.033865773252621 
2016-12-11 23:57:57 -------------------LR------------------- 
2016-12-11 23:57:57 0.0078125 
2016-12-11 23:57:57 Epoch 70 
2016-12-12 00:08:00 Training Error = 0.67995555555556 
2016-12-12 00:08:00 Training Loss = 0.034958602484654 
2016-12-12 00:08:12 Valid Error = 0.67853570714143 
2016-12-12 00:08:12 Valid Loss = 0.033669790471441 
2016-12-12 00:08:35 Test Error = 0.6772 
2016-12-12 00:08:35 Test Loss = 0.033713815014833 
2016-12-12 00:08:35 -------------------LR------------------- 
2016-12-12 00:08:35 0.0078125 
2016-12-12 00:08:36 Epoch 71 
2016-12-12 00:18:41 Training Error = 0.67768888888889 
2016-12-12 00:18:41 Training Loss = 0.034952912858941 
2016-12-12 00:18:53 Valid Error = 0.67673534706941 
2016-12-12 00:18:53 Valid Loss = 0.033547052785242 
2016-12-12 00:19:16 Test Error = 0.6749 
2016-12-12 00:19:16 Test Loss = 0.033645333773012 
2016-12-12 00:19:16 -------------------LR------------------- 
2016-12-12 00:19:16 0.0078125 
2016-12-12 00:19:16 Epoch 72 
2016-12-12 00:29:14 Training Error = 0.6798 
2016-12-12 00:29:14 Training Loss = 0.034950428689745 
2016-12-12 00:29:26 Valid Error = 0.68033606721344 
2016-12-12 00:29:26 Valid Loss = 0.03390103491909 
2016-12-12 00:29:49 Test Error = 0.6818 
2016-12-12 00:29:49 Test Loss = 0.034014949783398 
2016-12-12 00:29:49 -------------------LR------------------- 
2016-12-12 00:29:49 0.0078125 
2016-12-12 00:29:49 Epoch 73 
2016-12-12 00:39:58 Training Error = 0.67955555555556 
2016-12-12 00:39:58 Training Loss = 0.034947642192922 
2016-12-12 00:40:09 Valid Error = 0.67913582716543 
2016-12-12 00:40:09 Valid Loss = 0.033809180018268 
2016-12-12 00:40:33 Test Error = 0.6876 
2016-12-12 00:40:33 Test Loss = 0.033936500245598 
2016-12-12 00:40:33 -------------------LR------------------- 
2016-12-12 00:40:33 0.0078125 
2016-12-12 00:40:33 Epoch 74 
2016-12-12 00:50:24 Training Error = 0.6786 
2016-12-12 00:50:24 Training Loss = 0.034952868511054 
2016-12-12 00:50:36 Valid Error = 0.68273654730946 
2016-12-12 00:50:36 Valid Loss = 0.033663746974352 
2016-12-12 00:50:59 Test Error = 0.6788 
2016-12-12 00:50:59 Test Loss = 0.033759972715074 
2016-12-12 00:50:59 -------------------LR------------------- 
2016-12-12 00:50:59 0.0078125 
2016-12-12 00:50:59 Epoch 75 
2016-12-12 01:01:01 Training Error = 0.67931111111111 
2016-12-12 01:01:01 Training Loss = 0.034935331104154 
2016-12-12 01:01:13 Valid Error = 0.68173634726945 
2016-12-12 01:01:13 Valid Loss = 0.033762997731593 
2016-12-12 01:01:36 Test Error = 0.6826 
2016-12-12 01:01:36 Test Loss = 0.033826646683322 
2016-12-12 01:01:36 -------------------LR------------------- 
2016-12-12 01:01:36 0.0078125 
2016-12-12 01:01:36 Epoch 76 
2016-12-12 01:11:43 Training Error = 0.67906666666667 
2016-12-12 01:11:43 Training Loss = 0.034951060570099 
2016-12-12 01:11:54 Valid Error = 0.68453690738148 
2016-12-12 01:11:54 Valid Loss = 0.033803006339461 
2016-12-12 01:12:18 Test Error = 0.684 
2016-12-12 01:12:18 Test Loss = 0.033915154493538 
2016-12-12 01:12:18 -------------------LR------------------- 
2016-12-12 01:12:18 0.0078125 
2016-12-12 01:12:18 Epoch 77 
2016-12-12 01:22:20 Training Error = 0.67797777777778 
2016-12-12 01:22:20 Training Loss = 0.034934652610259 
2016-12-12 01:22:31 Valid Error = 0.67873574714943 
2016-12-12 01:22:31 Valid Loss = 0.033758463100758 
2016-12-12 01:22:55 Test Error = 0.6802 
2016-12-12 01:22:55 Test Loss = 0.03383055574575 
2016-12-12 01:22:55 -------------------LR------------------- 
2016-12-12 01:22:55 0.0078125 
2016-12-12 01:22:55 Epoch 78 
2016-12-12 01:33:03 Training Error = 0.67835555555556 
2016-12-12 01:33:03 Training Loss = 0.034970339770344 
2016-12-12 01:33:15 Valid Error = 0.67933586717343 
2016-12-12 01:33:15 Valid Loss = 0.033673523808905 
2016-12-12 01:33:38 Test Error = 0.6798 
2016-12-12 01:33:38 Test Loss = 0.033754603224955 
2016-12-12 01:33:38 -------------------LR------------------- 
2016-12-12 01:33:38 0.0078125 
2016-12-12 01:33:38 Epoch 79 
2016-12-12 01:43:28 Training Error = 0.67791111111111 
2016-12-12 01:43:28 Training Loss = 0.034949714195999 
2016-12-12 01:43:40 Valid Error = 0.6877375475095 
2016-12-12 01:43:40 Valid Loss = 0.033918863761274 
2016-12-12 01:44:03 Test Error = 0.688 
2016-12-12 01:44:03 Test Loss = 0.034015751826535 
2016-12-12 01:44:03 -------------------LR------------------- 
2016-12-12 01:44:03 0.0078125 
2016-12-12 01:44:03 Epoch 80 
2016-12-12 01:54:20 Training Error = 0.67915555555556 
2016-12-12 01:54:20 Training Loss = 0.03495734885335 
2016-12-12 01:54:32 Valid Error = 0.67813562712543 
2016-12-12 01:54:32 Valid Loss = 0.033706688225593 
2016-12-12 01:54:55 Test Error = 0.6792 
2016-12-12 01:54:55 Test Loss = 0.033800828122789 
2016-12-12 01:54:55 -------------------LR------------------- 
2016-12-12 01:54:55 0.0078125 
2016-12-12 01:54:55 Epoch 81 
2016-12-12 02:04:55 Training Error = 0.67797777777778 
2016-12-12 02:04:55 Training Loss = 0.034945707896894 
2016-12-12 02:05:06 Valid Error = 0.67913582716543 
2016-12-12 02:05:06 Valid Loss = 0.033757979537867 
2016-12-12 02:05:30 Test Error = 0.6804 
2016-12-12 02:05:30 Test Loss = 0.033883628207407 
2016-12-12 02:05:30 -------------------LR------------------- 
2016-12-12 02:05:30 0.0078125 
2016-12-12 02:05:30 Epoch 82 
2016-12-12 02:15:25 Training Error = 0.67868888888889 
2016-12-12 02:15:25 Training Loss = 0.034933918704363 
2016-12-12 02:15:37 Valid Error = 0.67813562712543 
2016-12-12 02:15:37 Valid Loss = 0.033620452911039 
2016-12-12 02:16:01 Test Error = 0.6773 
2016-12-12 02:16:01 Test Loss = 0.033727583004411 
2016-12-12 02:16:01 -------------------LR------------------- 
2016-12-12 02:16:01 0.0078125 
2016-12-12 02:16:01 Epoch 83 
2016-12-12 02:26:05 Training Error = 0.67864444444444 
2016-12-12 02:26:05 Training Loss = 0.034955469691618 
2016-12-12 02:26:17 Valid Error = 0.68533706741348 
2016-12-12 02:26:17 Valid Loss = 0.033883096525078 
2016-12-12 02:26:41 Test Error = 0.6878 
2016-12-12 02:26:41 Test Loss = 0.033956655909301 
2016-12-12 02:26:41 -------------------LR------------------- 
2016-12-12 02:26:41 0.0078125 
2016-12-12 02:26:41 Epoch 84 
2016-12-12 02:36:35 Training Error = 0.67553333333333 
2016-12-12 02:36:35 Training Loss = 0.034940218576653 
2016-12-12 02:36:47 Valid Error = 0.67733546709342 
2016-12-12 02:36:47 Valid Loss = 0.033646694247158 
2016-12-12 02:37:11 Test Error = 0.6789 
2016-12-12 02:37:11 Test Loss = 0.033775897496825 
2016-12-12 02:37:11 -------------------LR------------------- 
2016-12-12 02:37:11 0.0078125 
2016-12-12 02:37:11 Epoch 85 
2016-12-12 02:47:24 Training Error = 0.67775555555556 
2016-12-12 02:47:24 Training Loss = 0.034958335442299 
2016-12-12 02:47:36 Valid Error = 0.68633726745349 
2016-12-12 02:47:36 Valid Loss = 0.0338267028612 
2016-12-12 02:48:00 Test Error = 0.6852 
2016-12-12 02:48:00 Test Loss = 0.033932972880685 
2016-12-12 02:48:00 -------------------LR------------------- 
2016-12-12 02:48:00 0.0078125 
2016-12-12 02:48:00 Epoch 86 
2016-12-12 02:57:49 Training Error = 0.67982222222222 
2016-12-12 02:57:49 Training Loss = 0.034964454698969 
2016-12-12 02:58:01 Valid Error = 0.68033606721344 
2016-12-12 02:58:01 Valid Loss = 0.033647627446794 
2016-12-12 02:58:25 Test Error = 0.6817 
2016-12-12 02:58:25 Test Loss = 0.033745977893756 
2016-12-12 02:58:25 -------------------LR------------------- 
2016-12-12 02:58:25 0.0078125 
2016-12-12 02:58:25 Epoch 87 
2016-12-12 03:08:25 Training Error = 0.67804444444444 
2016-12-12 03:08:25 Training Loss = 0.034956306398592 
2016-12-12 03:08:36 Valid Error = 0.68453690738148 
2016-12-12 03:08:36 Valid Loss = 0.033833777568224 
2016-12-12 03:09:00 Test Error = 0.6821 
2016-12-12 03:09:00 Test Loss = 0.033988700702692 
2016-12-12 03:09:00 -------------------LR------------------- 
2016-12-12 03:09:00 0.0078125 
2016-12-12 03:09:00 Epoch 88 
2016-12-12 03:19:02 Training Error = 0.67666666666667 
2016-12-12 03:19:02 Training Loss = 0.034937435852533 
2016-12-12 03:19:13 Valid Error = 0.67293458691738 
2016-12-12 03:19:13 Valid Loss = 0.033670058190068 
2016-12-12 03:19:37 Test Error = 0.6747 
2016-12-12 03:19:37 Test Loss = 0.033739121066537 
2016-12-12 03:19:37 -------------------LR------------------- 
2016-12-12 03:19:37 0.0078125 
2016-12-12 03:19:37 Epoch 89 
2016-12-12 03:29:34 Training Error = 0.67775555555556 
2016-12-12 03:29:34 Training Loss = 0.034937123009427 
2016-12-12 03:29:46 Valid Error = 0.67053410682136 
2016-12-12 03:29:46 Valid Loss = 0.033513771629678 
2016-12-12 03:30:10 Test Error = 0.6702 
2016-12-12 03:30:10 Test Loss = 0.033588109578297 
2016-12-12 03:30:10 -------------------LR------------------- 
2016-12-12 03:30:10 0.0078125 
2016-12-12 03:30:10 Epoch 90 
2016-12-12 03:40:17 Training Error = 0.67795555555556 
2016-12-12 03:40:17 Training Loss = 0.034941905906255 
2016-12-12 03:40:29 Valid Error = 0.66913382676535 
2016-12-12 03:40:29 Valid Loss = 0.033483881622715 
2016-12-12 03:40:53 Test Error = 0.6702 
2016-12-12 03:40:53 Test Loss = 0.033579047090688 
2016-12-12 03:40:53 -------------------LR------------------- 
2016-12-12 03:40:53 0.0078125 
2016-12-12 03:40:53 Epoch 91 
2016-12-12 03:50:43 Training Error = 0.67991111111111 
2016-12-12 03:50:43 Training Loss = 0.034968907778913 
2016-12-12 03:50:55 Valid Error = 0.6747349469894 
2016-12-12 03:50:55 Valid Loss = 0.033617865461553 
2016-12-12 03:51:19 Test Error = 0.675 
2016-12-12 03:51:19 Test Loss = 0.033736846796267 
2016-12-12 03:51:19 -------------------LR------------------- 
2016-12-12 03:51:19 0.0078125 
2016-12-12 03:51:19 Epoch 92 
2016-12-12 04:01:18 Training Error = 0.67777777777778 
2016-12-12 04:01:18 Training Loss = 0.034946101934395 
2016-12-12 04:01:29 Valid Error = 0.67753550710142 
2016-12-12 04:01:29 Valid Loss = 0.033703806521017 
2016-12-12 04:01:53 Test Error = 0.6801 
2016-12-12 04:01:53 Test Loss = 0.033835670219106 
2016-12-12 04:01:53 -------------------LR------------------- 
2016-12-12 04:01:53 0.0078125 
2016-12-12 04:01:53 Epoch 93 
2016-12-12 04:11:56 Training Error = 0.6784 
2016-12-12 04:11:56 Training Loss = 0.034957575777715 
2016-12-12 04:12:08 Valid Error = 0.67413482696539 
2016-12-12 04:12:08 Valid Loss = 0.033614445431107 
2016-12-12 04:12:31 Test Error = 0.6743 
2016-12-12 04:12:31 Test Loss = 0.033706884125995 
2016-12-12 04:12:31 -------------------LR------------------- 
2016-12-12 04:12:31 0.0078125 
2016-12-12 04:12:31 Epoch 94 
2016-12-12 04:22:30 Training Error = 0.67824444444444 
2016-12-12 04:22:30 Training Loss = 0.034943448474461 
2016-12-12 04:22:42 Valid Error = 0.67173434686937 
2016-12-12 04:22:42 Valid Loss = 0.033495044268493 
2016-12-12 04:23:06 Test Error = 0.6764 
2016-12-12 04:23:06 Test Loss = 0.033591114032041 
2016-12-12 04:23:06 -------------------LR------------------- 
2016-12-12 04:23:06 0.0078125 
2016-12-12 04:23:06 Epoch 95 
2016-12-12 04:33:15 Training Error = 0.6792 
2016-12-12 04:33:15 Training Loss = 0.034950062337924 
2016-12-12 04:33:27 Valid Error = 0.67353470694139 
2016-12-12 04:33:27 Valid Loss = 0.033606106040706 
2016-12-12 04:33:51 Test Error = 0.677 
2016-12-12 04:33:51 Test Loss = 0.033730487595698 
2016-12-12 04:33:51 -------------------LR------------------- 
2016-12-12 04:33:51 0.0078125 
2016-12-12 04:33:51 Epoch 96 
2016-12-12 04:43:43 Training Error = 0.67644444444444 
2016-12-12 04:43:43 Training Loss = 0.034941407398067 
2016-12-12 04:43:55 Valid Error = 0.68053610722144 
2016-12-12 04:43:55 Valid Loss = 0.033694819114954 
2016-12-12 04:44:18 Test Error = 0.68 
2016-12-12 04:44:18 Test Loss = 0.033782649921004 
2016-12-12 04:44:18 -------------------LR------------------- 
2016-12-12 04:44:18 0.0078125 
2016-12-12 04:44:18 Epoch 97 
2016-12-12 04:54:19 Training Error = 0.67824444444444 
2016-12-12 04:54:19 Training Loss = 0.034954898916185 
2016-12-12 04:54:30 Valid Error = 0.68393678735747 
2016-12-12 04:54:30 Valid Loss = 0.033880319435816 
2016-12-12 04:54:54 Test Error = 0.6837 
2016-12-12 04:54:54 Test Loss = 0.033983018428657 
2016-12-12 04:54:54 -------------------LR------------------- 
2016-12-12 04:54:54 0.0078125 
2016-12-12 04:54:54 Epoch 98 
2016-12-12 05:04:58 Training Error = 0.67757777777778 
2016-12-12 05:04:58 Training Loss = 0.034949731562625 
2016-12-12 05:05:09 Valid Error = 0.67253450690138 
2016-12-12 05:05:09 Valid Loss = 0.033500934483561 
2016-12-12 05:05:33 Test Error = 0.6728 
2016-12-12 05:05:33 Test Loss = 0.033581732185024 
2016-12-12 05:05:33 -------------------LR------------------- 
2016-12-12 05:05:33 0.0078125 
2016-12-12 05:05:33 Epoch 99 
2016-12-12 05:14:53 Training Error = 0.67866666666667 
2016-12-12 05:14:53 Training Loss = 0.034931599118493 
2016-12-12 05:15:05 Valid Error = 0.68073614722945 
2016-12-12 05:15:05 Valid Loss = 0.033649609364825 
2016-12-12 05:15:28 Test Error = 0.6819 
2016-12-12 05:15:28 Test Loss = 0.033798776477765 
2016-12-12 05:15:28 -------------------LR------------------- 
2016-12-12 05:15:28 0.0078125 
2016-12-12 05:15:28 Epoch 100 
2016-12-12 05:24:30 Training Error = 0.68155555555556 
2016-12-12 05:24:30 Training Loss = 0.034979385442354 
2016-12-12 05:24:42 Valid Error = 0.67953590718144 
2016-12-12 05:24:42 Valid Loss = 0.033743510690348 
2016-12-12 05:25:05 Test Error = 0.6822 
2016-12-12 05:25:05 Test Loss = 0.03384667076123 
2016-12-12 05:25:05 -------------------LR------------------- 
2016-12-12 05:25:05 0.00390625 
2016-12-12 05:25:05 Epoch 101 
2016-12-12 05:33:53 Training Error = 0.67875555555556 
2016-12-12 05:33:53 Training Loss = 0.034935631921345 
2016-12-12 05:34:04 Valid Error = 0.68053610722144 
2016-12-12 05:34:04 Valid Loss = 0.033745792205252 
2016-12-12 05:34:28 Test Error = 0.6854 
2016-12-12 05:34:28 Test Loss = 0.03385305793422 
2016-12-12 05:34:28 -------------------LR------------------- 
2016-12-12 05:34:28 0.00390625 
2016-12-12 05:34:28 Epoch 102 
2016-12-12 05:43:22 Training Error = 0.67757777777778 
2016-12-12 05:43:22 Training Loss = 0.034956458254971 
2016-12-12 05:43:33 Valid Error = 0.67313462692539 
2016-12-12 05:43:33 Valid Loss = 0.033542860412253 
2016-12-12 05:43:57 Test Error = 0.675 
2016-12-12 05:43:57 Test Loss = 0.033679643573275 
2016-12-12 05:43:57 -------------------LR------------------- 
2016-12-12 05:43:57 0.00390625 
2016-12-12 05:43:57 Epoch 103 
2016-12-12 05:52:54 Training Error = 0.67868888888889 
2016-12-12 05:52:54 Training Loss = 0.034947818121449 
2016-12-12 05:53:06 Valid Error = 0.6753350670134 
2016-12-12 05:53:06 Valid Loss = 0.033723931204777 
2016-12-12 05:53:29 Test Error = 0.6794 
2016-12-12 05:53:29 Test Loss = 0.033852640868752 
2016-12-12 05:53:29 -------------------LR------------------- 
2016-12-12 05:53:29 0.00390625 
2016-12-12 05:53:29 Epoch 104 
2016-12-12 06:02:20 Training Error = 0.67862222222222 
2016-12-12 06:02:20 Training Loss = 0.034960140463981 
2016-12-12 06:02:31 Valid Error = 0.6871374274855 
2016-12-12 06:02:31 Valid Loss = 0.033958060107654 
2016-12-12 06:02:55 Test Error = 0.6894 
2016-12-12 06:02:55 Test Loss = 0.034089607068687 
2016-12-12 06:02:55 -------------------LR------------------- 
2016-12-12 06:02:55 0.00390625 
2016-12-12 06:02:55 Epoch 105 
2016-12-12 06:11:44 Training Error = 0.67637777777778 
2016-12-12 06:11:44 Training Loss = 0.03493760982359 
2016-12-12 06:11:56 Valid Error = 0.68253650730146 
2016-12-12 06:11:56 Valid Loss = 0.033866996359868 
2016-12-12 06:12:19 Test Error = 0.6852 
2016-12-12 06:12:19 Test Loss = 0.03397272214768 
2016-12-12 06:12:19 -------------------LR------------------- 
2016-12-12 06:12:19 0.00390625 
2016-12-12 06:12:19 Epoch 106 
2016-12-12 06:21:13 Training Error = 0.67686666666667 
2016-12-12 06:21:13 Training Loss = 0.034937975457446 
2016-12-12 06:21:24 Valid Error = 0.67753550710142 
2016-12-12 06:21:24 Valid Loss = 0.03384994658596 
2016-12-12 06:21:48 Test Error = 0.6796 
2016-12-12 06:21:48 Test Loss = 0.03394448474714 
2016-12-12 06:21:48 -------------------LR------------------- 
2016-12-12 06:21:48 0.00390625 
2016-12-12 06:21:48 Epoch 107 
2016-12-12 06:30:42 Training Error = 0.67795555555556 
2016-12-12 06:30:42 Training Loss = 0.034947752739218 
2016-12-12 06:30:54 Valid Error = 0.68133626725345 
2016-12-12 06:30:54 Valid Loss = 0.03386140346096 
2016-12-12 06:31:17 Test Error = 0.6826 
2016-12-12 06:31:17 Test Loss = 0.033968161564724 
2016-12-12 06:31:17 -------------------LR------------------- 
2016-12-12 06:31:17 0.00390625 
2016-12-12 06:31:17 Epoch 108 
2016-12-12 06:40:13 Training Error = 0.679 
2016-12-12 06:40:13 Training Loss = 0.034957809990103 
2016-12-12 06:40:24 Valid Error = 0.6745349069814 
2016-12-12 06:40:24 Valid Loss = 0.033511375428108 
2016-12-12 06:40:48 Test Error = 0.6796 
2016-12-12 06:40:48 Test Loss = 0.033631985688665 
2016-12-12 06:40:48 -------------------LR------------------- 
2016-12-12 06:40:48 0.00390625 
2016-12-12 06:40:48 Epoch 109 
2016-12-12 06:49:40 Training Error = 0.6772 
2016-12-12 06:49:40 Training Loss = 0.034931880340657 
2016-12-12 06:49:52 Valid Error = 0.67733546709342 
2016-12-12 06:49:52 Valid Loss = 0.033667045299227 
2016-12-12 06:50:16 Test Error = 0.6776 
2016-12-12 06:50:16 Test Loss = 0.033782042120672 
2016-12-12 06:50:16 -------------------LR------------------- 
2016-12-12 06:50:16 0.00390625 
2016-12-12 06:50:16 Epoch 110 
2016-12-12 06:59:12 Training Error = 0.67951111111111 
2016-12-12 06:59:12 Training Loss = 0.034945729242807 
2016-12-12 06:59:23 Valid Error = 0.68073614722945 
2016-12-12 06:59:23 Valid Loss = 0.033766277849566 
2016-12-12 06:59:46 Test Error = 0.6863 
2016-12-12 06:59:46 Test Loss = 0.033863244512279 
2016-12-12 06:59:46 -------------------LR------------------- 
2016-12-12 06:59:46 0.00390625 
2016-12-12 06:59:47 Epoch 111 
2016-12-12 07:08:48 Training Error = 0.67611111111111 
2016-12-12 07:08:48 Training Loss = 0.034949577098543 
2016-12-12 07:09:00 Valid Error = 0.68193638727746 
2016-12-12 07:09:00 Valid Loss = 0.033656392886453 
2016-12-12 07:09:23 Test Error = 0.6824 
2016-12-12 07:09:23 Test Loss = 0.03378262791664 
2016-12-12 07:09:23 -------------------LR------------------- 
2016-12-12 07:09:23 0.00390625 
2016-12-12 07:09:23 Epoch 112 
2016-12-12 07:18:18 Training Error = 0.67848888888889 
2016-12-12 07:18:18 Training Loss = 0.034957514083521 
2016-12-12 07:18:29 Valid Error = 0.6875375075015 
2016-12-12 07:18:29 Valid Loss = 0.033900174723827 
2016-12-12 07:18:53 Test Error = 0.689 
2016-12-12 07:18:53 Test Loss = 0.034007021985996 
2016-12-12 07:18:53 -------------------LR------------------- 
2016-12-12 07:18:53 0.00390625 
2016-12-12 07:18:53 Epoch 113 
2016-12-12 07:27:46 Training Error = 0.67591111111111 
2016-12-12 07:27:46 Training Loss = 0.034934421262958 
2016-12-12 07:27:58 Valid Error = 0.67933586717343 
2016-12-12 07:27:58 Valid Loss = 0.033765668446505 
2016-12-12 07:28:22 Test Error = 0.6791 
2016-12-12 07:28:22 Test Loss = 0.033873145959939 
2016-12-12 07:28:22 -------------------LR------------------- 
2016-12-12 07:28:22 0.00390625 
2016-12-12 07:28:22 Epoch 114 
2016-12-12 07:37:17 Training Error = 0.67628888888889 
2016-12-12 07:37:17 Training Loss = 0.034938044846058 
2016-12-12 07:37:29 Valid Error = 0.68453690738148 
2016-12-12 07:37:29 Valid Loss = 0.033817660273954 
2016-12-12 07:37:53 Test Error = 0.6829 
2016-12-12 07:37:53 Test Loss = 0.03391900780854 
2016-12-12 07:37:53 -------------------LR------------------- 
2016-12-12 07:37:53 0.00390625 
2016-12-12 07:37:53 Epoch 115 
2016-12-12 07:46:46 Training Error = 0.6796 
2016-12-12 07:46:46 Training Loss = 0.034941639205949 
2016-12-12 07:46:58 Valid Error = 0.67273454690938 
2016-12-12 07:46:58 Valid Loss = 0.033620840347697 
2016-12-12 07:47:22 Test Error = 0.6755 
2016-12-12 07:47:22 Test Loss = 0.033723861351135 
2016-12-12 07:47:22 -------------------LR------------------- 
2016-12-12 07:47:22 0.00390625 
2016-12-12 07:47:22 Epoch 116 
2016-12-12 07:56:09 Training Error = 0.67766666666667 
2016-12-12 07:56:09 Training Loss = 0.034959373653612 
2016-12-12 07:56:21 Valid Error = 0.67973594718944 
2016-12-12 07:56:21 Valid Loss = 0.033725876433078 
2016-12-12 07:56:45 Test Error = 0.6813 
2016-12-12 07:56:45 Test Loss = 0.033844174822425 
2016-12-12 07:56:45 -------------------LR------------------- 
2016-12-12 07:56:45 0.00390625 
2016-12-12 07:56:45 Epoch 117 
2016-12-12 08:05:45 Training Error = 0.678 
2016-12-12 08:05:45 Training Loss = 0.034929036548869 
2016-12-12 08:05:57 Valid Error = 0.67993598719744 
2016-12-12 08:05:57 Valid Loss = 0.033777095060021 
2016-12-12 08:06:20 Test Error = 0.6818 
2016-12-12 08:06:20 Test Loss = 0.033918105037349 
2016-12-12 08:06:20 -------------------LR------------------- 
2016-12-12 08:06:20 0.00390625 
2016-12-12 08:06:20 Epoch 118 
2016-12-12 08:15:12 Training Error = 0.67826666666667 
2016-12-12 08:15:12 Training Loss = 0.034939376999709 
2016-12-12 08:15:23 Valid Error = 0.67433486697339 
2016-12-12 08:15:23 Valid Loss = 0.033603197661705 
2016-12-12 08:15:47 Test Error = 0.6785 
2016-12-12 08:15:47 Test Loss = 0.033700230668305 
2016-12-12 08:15:47 -------------------LR------------------- 
2016-12-12 08:15:47 0.00390625 
2016-12-12 08:15:47 Epoch 119 
2016-12-12 08:24:37 Training Error = 0.67791111111111 
2016-12-12 08:24:37 Training Loss = 0.034946169338443 
2016-12-12 08:24:49 Valid Error = 0.67093418683737 
2016-12-12 08:24:49 Valid Loss = 0.03352569529204 
2016-12-12 08:25:13 Test Error = 0.6723 
2016-12-12 08:25:13 Test Loss = 0.033643735715538 
2016-12-12 08:25:13 -------------------LR------------------- 
2016-12-12 08:25:13 0.00390625 
2016-12-12 08:25:13 Epoch 120 
2016-12-12 08:34:17 Training Error = 0.67844444444444 
2016-12-12 08:34:17 Training Loss = 0.034949528165162 
2016-12-12 08:34:29 Valid Error = 0.68253650730146 
2016-12-12 08:34:29 Valid Loss = 0.033825114506278 
2016-12-12 08:34:52 Test Error = 0.6851 
2016-12-12 08:34:52 Test Loss = 0.033908154129223 
2016-12-12 08:34:52 -------------------LR------------------- 
2016-12-12 08:34:52 0.00390625 
2016-12-12 08:34:52 Epoch 121 
2016-12-12 08:43:47 Training Error = 0.67584444444444 
2016-12-12 08:43:47 Training Loss = 0.034945839778944 
2016-12-12 08:43:59 Valid Error = 0.67393478695739 
2016-12-12 08:43:59 Valid Loss = 0.033566394710196 
2016-12-12 08:44:22 Test Error = 0.6744 
2016-12-12 08:44:22 Test Loss = 0.033641790705881 
2016-12-12 08:44:22 -------------------LR------------------- 
2016-12-12 08:44:22 0.00390625 
2016-12-12 08:44:23 Epoch 122 
2016-12-12 08:53:23 Training Error = 0.67722222222222 
2016-12-12 08:53:23 Training Loss = 0.034921805919571 
2016-12-12 08:53:34 Valid Error = 0.67893578715743 
2016-12-12 08:53:34 Valid Loss = 0.033857178528529 
2016-12-12 08:53:58 Test Error = 0.6847 
2016-12-12 08:53:58 Test Loss = 0.03398520926761 
2016-12-12 08:53:58 -------------------LR------------------- 
2016-12-12 08:53:58 0.00390625 
2016-12-12 08:53:58 Epoch 123 
2016-12-12 09:02:57 Training Error = 0.67655555555556 
2016-12-12 09:02:57 Training Loss = 0.034947768212719 
2016-12-12 09:03:08 Valid Error = 0.67433486697339 
2016-12-12 09:03:08 Valid Loss = 0.033630161298334 
2016-12-12 09:03:32 Test Error = 0.6756 
2016-12-12 09:03:32 Test Loss = 0.033699050390037 
2016-12-12 09:03:32 -------------------LR------------------- 
2016-12-12 09:03:32 0.00390625 
2016-12-12 09:03:32 Epoch 124 
2016-12-12 09:12:24 Training Error = 0.6772 
2016-12-12 09:12:24 Training Loss = 0.034947440288961 
2016-12-12 09:12:36 Valid Error = 0.67733546709342 
2016-12-12 09:12:36 Valid Loss = 0.033747013192927 
2016-12-12 09:12:59 Test Error = 0.6785 
2016-12-12 09:12:59 Test Loss = 0.033833502523459 
2016-12-12 09:12:59 -------------------LR------------------- 
2016-12-12 09:12:59 0.00390625 
2016-12-12 09:12:59 Epoch 125 
2016-12-12 09:22:03 Training Error = 0.68084444444444 
2016-12-12 09:22:03 Training Loss = 0.034958160919222 
2016-12-12 09:22:14 Valid Error = 0.67833566713343 
2016-12-12 09:22:14 Valid Loss = 0.033753763232481 
2016-12-12 09:22:38 Test Error = 0.6793 
2016-12-12 09:22:38 Test Loss = 0.033838245033459 
2016-12-12 09:22:38 -------------------LR------------------- 
2016-12-12 09:22:38 0.00390625 
2016-12-12 09:22:38 Epoch 126 
2016-12-12 09:31:28 Training Error = 0.67902222222222 
2016-12-12 09:31:28 Training Loss = 0.034951834008098 
2016-12-12 09:31:40 Valid Error = 0.67973594718944 
2016-12-12 09:31:40 Valid Loss = 0.033649970454721 
2016-12-12 09:32:03 Test Error = 0.6751 
2016-12-12 09:32:03 Test Loss = 0.033749257485578 
2016-12-12 09:32:03 -------------------LR------------------- 
2016-12-12 09:32:03 0.00390625 
2016-12-12 09:32:04 Epoch 127 
2016-12-12 09:40:54 Training Error = 0.67975555555556 
2016-12-12 09:40:54 Training Loss = 0.03495189380578 
2016-12-12 09:41:05 Valid Error = 0.66953390678136 
2016-12-12 09:41:05 Valid Loss = 0.033535625447416 
2016-12-12 09:41:29 Test Error = 0.6755 
2016-12-12 09:41:29 Test Loss = 0.033625575235695 
2016-12-12 09:41:29 -------------------LR------------------- 
2016-12-12 09:41:29 0.00390625 
2016-12-12 09:41:29 Epoch 128 
2016-12-12 09:50:28 Training Error = 0.6802 
2016-12-12 09:50:28 Training Loss = 0.034948765930127 
2016-12-12 09:50:40 Valid Error = 0.68133626725345 
2016-12-12 09:50:40 Valid Loss = 0.033778938048571 
2016-12-12 09:51:03 Test Error = 0.6831 
2016-12-12 09:51:03 Test Loss = 0.033876030414727 
2016-12-12 09:51:03 -------------------LR------------------- 
2016-12-12 09:51:03 0.00390625 
2016-12-12 09:51:04 Epoch 129 
2016-12-12 09:59:56 Training Error = 0.67986666666667 
2016-12-12 09:59:56 Training Loss = 0.034951806732199 
2016-12-12 10:00:08 Valid Error = 0.66753350670134 
2016-12-12 10:00:08 Valid Loss = 0.033556030727856 
2016-12-12 10:00:31 Test Error = 0.6731 
2016-12-12 10:00:31 Test Loss = 0.0336700131635 
2016-12-12 10:00:31 -------------------LR------------------- 
2016-12-12 10:00:31 0.00390625 
2016-12-12 10:00:31 Epoch 130 
2016-12-12 10:09:22 Training Error = 0.67697777777778 
2016-12-12 10:09:22 Training Loss = 0.034958884079348 
2016-12-12 10:09:34 Valid Error = 0.67573514702941 
2016-12-12 10:09:34 Valid Loss = 0.03347036694963 
2016-12-12 10:09:57 Test Error = 0.6774 
2016-12-12 10:09:57 Test Loss = 0.0335891917253 
2016-12-12 10:09:57 -------------------LR------------------- 
2016-12-12 10:09:57 0.00390625 
2016-12-12 10:09:57 Epoch 131 
2016-12-12 10:19:01 Training Error = 0.67764444444444 
2016-12-12 10:19:01 Training Loss = 0.034930473288352 
2016-12-12 10:19:13 Valid Error = 0.67673534706941 
2016-12-12 10:19:13 Valid Loss = 0.033584090680369 
2016-12-12 10:19:36 Test Error = 0.673 
2016-12-12 10:19:36 Test Loss = 0.033658726989843 
2016-12-12 10:19:36 -------------------LR------------------- 
2016-12-12 10:19:36 0.00390625 
2016-12-12 10:19:36 Epoch 132 
2016-12-12 10:28:23 Training Error = 0.67984444444444 
2016-12-12 10:28:23 Training Loss = 0.034944984743541 
2016-12-12 10:28:34 Valid Error = 0.67693538707742 
2016-12-12 10:28:34 Valid Loss = 0.033635983540395 
2016-12-12 10:28:58 Test Error = 0.6764 
2016-12-12 10:28:58 Test Loss = 0.033740965667044 
2016-12-12 10:28:58 -------------------LR------------------- 
2016-12-12 10:28:58 0.00390625 
2016-12-12 10:28:58 Epoch 133 
2016-12-12 10:37:55 Training Error = 0.67906666666667 
2016-12-12 10:37:55 Training Loss = 0.034955430914733 
2016-12-12 10:38:07 Valid Error = 0.68353670734147 
2016-12-12 10:38:07 Valid Loss = 0.033835736088468 
2016-12-12 10:38:30 Test Error = 0.6821 
2016-12-12 10:38:30 Test Loss = 0.033923273359894 
2016-12-12 10:38:30 -------------------LR------------------- 
2016-12-12 10:38:30 0.00390625 
2016-12-12 10:38:30 Epoch 134 
2016-12-12 10:47:28 Training Error = 0.67568888888889 
2016-12-12 10:47:28 Training Loss = 0.034939842237668 
2016-12-12 10:47:40 Valid Error = 0.67013402680536 
2016-12-12 10:47:40 Valid Loss = 0.033542286879762 
2016-12-12 10:48:03 Test Error = 0.6708 
2016-12-12 10:48:03 Test Loss = 0.033668843530546 
2016-12-12 10:48:03 -------------------LR------------------- 
2016-12-12 10:48:03 0.00390625 
2016-12-12 10:48:03 Epoch 135 
2016-12-12 10:56:39 Training Error = 0.67988888888889 
2016-12-12 10:56:39 Training Loss = 0.034948247809979 
2016-12-12 10:56:50 Valid Error = 0.68213642728546 
2016-12-12 10:56:50 Valid Loss = 0.033660633111302 
2016-12-12 10:57:14 Test Error = 0.6776 
2016-12-12 10:57:14 Test Loss = 0.033756737526815 
2016-12-12 10:57:14 -------------------LR------------------- 
2016-12-12 10:57:14 0.00390625 
2016-12-12 10:57:14 Epoch 136 
2016-12-12 11:04:52 Training Error = 0.67791111111111 
2016-12-12 11:04:52 Training Loss = 0.034921121773395 
2016-12-12 11:05:04 Valid Error = 0.67973594718944 
2016-12-12 11:05:04 Valid Loss = 0.033765549422604 
2016-12-12 11:05:27 Test Error = 0.679 
2016-12-12 11:05:27 Test Loss = 0.033858873160781 
2016-12-12 11:05:27 -------------------LR------------------- 
2016-12-12 11:05:27 0.00390625 
2016-12-12 11:05:27 Epoch 137 
2016-12-12 11:12:58 Training Error = 0.67717777777778 
2016-12-12 11:12:58 Training Loss = 0.034953777715564 
2016-12-12 11:13:09 Valid Error = 0.67413482696539 
2016-12-12 11:13:09 Valid Loss = 0.033652132436983 
2016-12-12 11:13:33 Test Error = 0.6783 
2016-12-12 11:13:33 Test Loss = 0.033768551000364 
2016-12-12 11:13:33 -------------------LR------------------- 
2016-12-12 11:13:33 0.00390625 
2016-12-12 11:13:33 Epoch 138 
2016-12-12 11:21:10 Training Error = 0.67728888888889 
2016-12-12 11:21:10 Training Loss = 0.034946183555506 
2016-12-12 11:21:22 Valid Error = 0.67873574714943 
2016-12-12 11:21:22 Valid Loss = 0.033691173962184 
2016-12-12 11:21:45 Test Error = 0.675 
2016-12-12 11:21:45 Test Loss = 0.033788946130473 
2016-12-12 11:21:45 -------------------LR------------------- 
2016-12-12 11:21:45 0.00390625 
2016-12-12 11:21:45 Epoch 139 
2016-12-12 11:29:20 Training Error = 0.67935555555556 
2016-12-12 11:29:20 Training Loss = 0.034950956580314 
2016-12-12 11:29:31 Valid Error = 0.68193638727746 
2016-12-12 11:29:31 Valid Loss = 0.033772911413238 
2016-12-12 11:29:55 Test Error = 0.6841 
2016-12-12 11:29:55 Test Loss = 0.033912290023391 
2016-12-12 11:29:55 -------------------LR------------------- 
2016-12-12 11:29:55 0.00390625 
2016-12-12 11:29:55 Epoch 140 
2016-12-12 11:37:29 Training Error = 0.68 
2016-12-12 11:37:29 Training Loss = 0.034966550079936 
2016-12-12 11:37:41 Valid Error = 0.67233446689338 
2016-12-12 11:37:41 Valid Loss = 0.033645804445739 
2016-12-12 11:38:04 Test Error = 0.6723 
2016-12-12 11:38:04 Test Loss = 0.033752946079157 
2016-12-12 11:38:04 -------------------LR------------------- 
2016-12-12 11:38:04 0.00390625 
2016-12-12 11:38:04 Epoch 141 
2016-12-12 11:45:37 Training Error = 0.67904444444444 
2016-12-12 11:45:37 Training Loss = 0.034948302940889 
2016-12-12 11:45:48 Valid Error = 0.68213642728546 
2016-12-12 11:45:48 Valid Loss = 0.033867942170252 
2016-12-12 11:46:12 Test Error = 0.6778 
2016-12-12 11:46:12 Test Loss = 0.033989521090392 
2016-12-12 11:46:12 -------------------LR------------------- 
2016-12-12 11:46:12 0.00390625 
2016-12-12 11:46:12 Epoch 142 
2016-12-12 11:53:48 Training Error = 0.67868888888889 
2016-12-12 11:53:48 Training Loss = 0.034942054494538 
2016-12-12 11:54:00 Valid Error = 0.68213642728546 
2016-12-12 11:54:00 Valid Loss = 0.033793460042309 
2016-12-12 11:54:23 Test Error = 0.6826 
2016-12-12 11:54:23 Test Loss = 0.033886199863094 
2016-12-12 11:54:23 -------------------LR------------------- 
2016-12-12 11:54:23 0.00390625 
2016-12-12 11:54:23 Epoch 143 
2016-12-12 12:01:57 Training Error = 0.67922222222222 
2016-12-12 12:01:57 Training Loss = 0.03494679573246 
2016-12-12 12:02:09 Valid Error = 0.68113622724545 
2016-12-12 12:02:09 Valid Loss = 0.033762340907809 
2016-12-12 12:02:32 Test Error = 0.6802 
2016-12-12 12:02:32 Test Loss = 0.033843123396491 
2016-12-12 12:02:32 -------------------LR------------------- 
2016-12-12 12:02:32 0.00390625 
2016-12-12 12:02:32 Epoch 144 
2016-12-12 12:10:30 Training Error = 0.67875555555556 
2016-12-12 12:10:30 Training Loss = 0.034963052645326 
2016-12-12 12:10:42 Valid Error = 0.67353470694139 
2016-12-12 12:10:42 Valid Loss = 0.033631287125524 
2016-12-12 12:11:05 Test Error = 0.6758 
2016-12-12 12:11:05 Test Loss = 0.033807724023321 
2016-12-12 12:11:05 -------------------LR------------------- 
2016-12-12 12:11:05 0.00390625 
2016-12-12 12:11:05 Epoch 145 
2016-12-12 12:19:22 Training Error = 0.67848888888889 
2016-12-12 12:19:22 Training Loss = 0.03495376156135 
2016-12-12 12:19:34 Valid Error = 0.66693338667734 
2016-12-12 12:19:34 Valid Loss = 0.033587582236388 
2016-12-12 12:19:57 Test Error = 0.6741 
2016-12-12 12:19:57 Test Loss = 0.033711626894155 
2016-12-12 12:19:57 -------------------LR------------------- 
2016-12-12 12:19:57 0.00390625 
2016-12-12 12:19:57 Epoch 146 
2016-12-12 12:27:31 Training Error = 0.67857777777778 
2016-12-12 12:27:31 Training Loss = 0.034931727038188 
2016-12-12 12:27:43 Valid Error = 0.67433486697339 
2016-12-12 12:27:43 Valid Loss = 0.033588815175172 
2016-12-12 12:28:06 Test Error = 0.6705 
2016-12-12 12:28:06 Test Loss = 0.033690464101779 
2016-12-12 12:28:06 -------------------LR------------------- 
2016-12-12 12:28:06 0.00390625 
2016-12-12 12:28:06 Epoch 147 
2016-12-12 12:35:43 Training Error = 0.67911111111111 
2016-12-12 12:35:43 Training Loss = 0.034949390729043 
2016-12-12 12:35:55 Valid Error = 0.68633726745349 
2016-12-12 12:35:55 Valid Loss = 0.033823031551368 
2016-12-12 12:36:18 Test Error = 0.6846 
2016-12-12 12:36:18 Test Loss = 0.033887942338445 
2016-12-12 12:36:18 -------------------LR------------------- 
2016-12-12 12:36:18 0.00390625 
2016-12-12 12:36:18 Epoch 148 
2016-12-12 12:43:53 Training Error = 0.67677777777778 
2016-12-12 12:43:53 Training Loss = 0.034949211173437 
2016-12-12 12:44:04 Valid Error = 0.67793558711742 
2016-12-12 12:44:04 Valid Loss = 0.033758129176783 
2016-12-12 12:44:27 Test Error = 0.6798 
2016-12-12 12:44:27 Test Loss = 0.033864424426085 
2016-12-12 12:44:27 -------------------LR------------------- 
2016-12-12 12:44:27 0.00390625 
2016-12-12 12:44:28 Epoch 149 
2016-12-12 12:52:13 Training Error = 0.67804444444444 
2016-12-12 12:52:13 Training Loss = 0.034937208914621 
2016-12-12 12:52:24 Valid Error = 0.66893378675735 
2016-12-12 12:52:24 Valid Loss = 0.033463460812732 
2016-12-12 12:52:48 Test Error = 0.6728 
2016-12-12 12:52:48 Test Loss = 0.033597421463887 
2016-12-12 12:52:48 -------------------LR------------------- 
2016-12-12 12:52:48 0.00390625 
2016-12-12 12:52:48 Epoch 150 
2016-12-12 13:01:45 Training Error = 0.67906666666667 
2016-12-12 13:01:45 Training Loss = 0.034943317652426 
2016-12-12 13:01:57 Valid Error = 0.68373674734947 
2016-12-12 13:01:57 Valid Loss = 0.033793314270689 
2016-12-12 13:02:20 Test Error = 0.6858 
2016-12-12 13:02:20 Test Loss = 0.033922550738997 
2016-12-12 13:02:20 -------------------LR------------------- 
2016-12-12 13:02:20 0.001953125 
2016-12-12 13:02:20 Epoch 151 
2016-12-12 13:11:12 Training Error = 0.67646666666667 
2016-12-12 13:11:12 Training Loss = 0.034950976805253 
2016-12-12 13:11:23 Valid Error = 0.67793558711742 
2016-12-12 13:11:23 Valid Loss = 0.033693191548153 
2016-12-12 13:11:47 Test Error = 0.6807 
2016-12-12 13:11:47 Test Loss = 0.033820468301226 
2016-12-12 13:11:47 -------------------LR------------------- 
2016-12-12 13:11:47 0.001953125 
2016-12-12 13:11:47 Epoch 152 
2016-12-12 13:20:39 Training Error = 0.67831111111111 
2016-12-12 13:20:39 Training Loss = 0.03495998300612 
2016-12-12 13:20:51 Valid Error = 0.6751350270054 
2016-12-12 13:20:51 Valid Loss = 0.033540204847484 
2016-12-12 13:21:15 Test Error = 0.6756 
2016-12-12 13:21:15 Test Loss = 0.033686742008112 
2016-12-12 13:21:15 -------------------LR------------------- 
2016-12-12 13:21:15 0.001953125 
2016-12-12 13:21:15 Epoch 153 
2016-12-12 13:30:09 Training Error = 0.67986666666667 
2016-12-12 13:30:09 Training Loss = 0.034960098175163 
2016-12-12 13:30:20 Valid Error = 0.68653730746149 
2016-12-12 13:30:20 Valid Loss = 0.033853678017801 
2016-12-12 13:30:44 Test Error = 0.6818 
2016-12-12 13:30:44 Test Loss = 0.033949635362929 
2016-12-12 13:30:44 -------------------LR------------------- 
2016-12-12 13:30:44 0.001953125 
2016-12-12 13:30:44 Epoch 154 
2016-12-12 13:39:34 Training Error = 0.678 
2016-12-12 13:39:34 Training Loss = 0.034953125573017 
2016-12-12 13:39:45 Valid Error = 0.67653530706141 
2016-12-12 13:39:45 Valid Loss = 0.033675533513695 
2016-12-12 13:40:09 Test Error = 0.679 
2016-12-12 13:40:09 Test Loss = 0.033742418547345 
2016-12-12 13:40:09 -------------------LR------------------- 
2016-12-12 13:40:09 0.001953125 
2016-12-12 13:40:09 Epoch 155 
2016-12-12 13:50:17 Training Error = 0.67735555555556 
2016-12-12 13:50:17 Training Loss = 0.034934767613357 
2016-12-12 13:50:28 Valid Error = 0.67793558711742 
2016-12-12 13:50:28 Valid Loss = 0.03386700491362 
2016-12-12 13:50:52 Test Error = 0.6854 
2016-12-12 13:50:52 Test Loss = 0.033996831064771 
2016-12-12 13:50:52 -------------------LR------------------- 
2016-12-12 13:50:52 0.001953125 
2016-12-12 13:50:52 Epoch 156 
2016-12-12 14:01:33 Training Error = 0.67908888888889 
2016-12-12 14:01:33 Training Loss = 0.034971101829274 
2016-12-12 14:01:44 Valid Error = 0.68973794758952 
2016-12-12 14:01:44 Valid Loss = 0.033862249290749 
2016-12-12 14:02:08 Test Error = 0.6854 
2016-12-12 14:02:08 Test Loss = 0.033966338680049 
2016-12-12 14:02:08 -------------------LR------------------- 
2016-12-12 14:02:08 0.001953125 
2016-12-12 14:02:08 Epoch 157 
2016-12-12 14:12:45 Training Error = 0.67846666666667 
2016-12-12 14:12:45 Training Loss = 0.034941154427149 
2016-12-12 14:12:57 Valid Error = 0.66933386677335 
2016-12-12 14:12:57 Valid Loss = 0.033483301562815 
2016-12-12 14:13:20 Test Error = 0.6711 
2016-12-12 14:13:20 Test Loss = 0.033624501881326 
2016-12-12 14:13:20 -------------------LR------------------- 
2016-12-12 14:13:20 0.001953125 
2016-12-12 14:13:20 Epoch 158 
2016-12-12 14:24:00 Training Error = 0.67782222222222 
2016-12-12 14:24:00 Training Loss = 0.034961086548865 
2016-12-12 14:24:12 Valid Error = 0.68093618723745 
2016-12-12 14:24:12 Valid Loss = 0.033716615255228 
2016-12-12 14:24:36 Test Error = 0.6788 
2016-12-12 14:24:36 Test Loss = 0.033846513936474 
2016-12-12 14:24:36 -------------------LR------------------- 
2016-12-12 14:24:36 0.001953125 
2016-12-12 14:24:36 Epoch 159 
2016-12-12 14:35:13 Training Error = 0.67944444444444 
2016-12-12 14:35:13 Training Loss = 0.034959396777505 
2016-12-12 14:35:24 Valid Error = 0.6749349869974 
2016-12-12 14:35:24 Valid Loss = 0.033495206427617 
2016-12-12 14:35:48 Test Error = 0.6762 
2016-12-12 14:35:48 Test Loss = 0.033564760852012 
2016-12-12 14:35:48 -------------------LR------------------- 
2016-12-12 14:35:48 0.001953125 
2016-12-12 14:35:48 Epoch 160 
2016-12-12 14:46:25 Training Error = 0.67937777777778 
2016-12-12 14:46:25 Training Loss = 0.034944370964711 
2016-12-12 14:46:37 Valid Error = 0.67113422684537 
2016-12-12 14:46:37 Valid Loss = 0.03347702028954 
2016-12-12 14:47:00 Test Error = 0.6721 
2016-12-12 14:47:00 Test Loss = 0.033617063874652 
2016-12-12 14:47:00 -------------------LR------------------- 
2016-12-12 14:47:00 0.001953125 
2016-12-12 14:47:00 Epoch 161 
2016-12-12 14:57:31 Training Error = 0.67942222222222 
2016-12-12 14:57:31 Training Loss = 0.034945615665479 
2016-12-12 14:57:43 Valid Error = 0.68273654730946 
2016-12-12 14:57:43 Valid Loss = 0.033799369460204 
2016-12-12 14:58:07 Test Error = 0.683 
2016-12-12 14:58:07 Test Loss = 0.033889001615488 
2016-12-12 14:58:07 -------------------LR------------------- 
2016-12-12 14:58:07 0.001953125 
2016-12-12 14:58:07 Epoch 162 
2016-12-12 15:08:46 Training Error = 0.67817777777778 
2016-12-12 15:08:46 Training Loss = 0.03495455772362 
2016-12-12 15:08:58 Valid Error = 0.67993598719744 
2016-12-12 15:08:58 Valid Loss = 0.033715466452766 
2016-12-12 15:09:22 Test Error = 0.6786 
2016-12-12 15:09:22 Test Loss = 0.033796068376796 
2016-12-12 15:09:22 -------------------LR------------------- 
2016-12-12 15:09:22 0.001953125 
2016-12-12 15:09:22 Epoch 163 
2016-12-12 15:19:45 Training Error = 0.67788888888889 
2016-12-12 15:19:45 Training Loss = 0.034950231706554 
2016-12-12 15:19:56 Valid Error = 0.67733546709342 
2016-12-12 15:19:56 Valid Loss = 0.033697275779131 
2016-12-12 15:20:20 Test Error = 0.6803 
2016-12-12 15:20:20 Test Loss = 0.033790598644572 
2016-12-12 15:20:20 -------------------LR------------------- 
2016-12-12 15:20:20 0.001953125 
2016-12-12 15:20:20 Epoch 164 
2016-12-12 15:30:54 Training Error = 0.67973333333333 
2016-12-12 15:30:54 Training Loss = 0.034950577369468 
2016-12-12 15:31:06 Valid Error = 0.67073414682937 
2016-12-12 15:31:06 Valid Loss = 0.033540534184164 
2016-12-12 15:31:30 Test Error = 0.6725 
2016-12-12 15:31:30 Test Loss = 0.033609843588179 
2016-12-12 15:31:30 -------------------LR------------------- 
2016-12-12 15:31:30 0.001953125 
2016-12-12 15:31:30 Epoch 165 
2016-12-12 15:42:03 Training Error = 0.67775555555556 
2016-12-12 15:42:03 Training Loss = 0.034934832914309 
2016-12-12 15:42:15 Valid Error = 0.68853770754151 
2016-12-12 15:42:15 Valid Loss = 0.033974108583888 
2016-12-12 15:42:38 Test Error = 0.6887 
2016-12-12 15:42:38 Test Loss = 0.034101897136421 
2016-12-12 15:42:38 -------------------LR------------------- 
2016-12-12 15:42:38 0.001953125 
2016-12-12 15:42:38 Epoch 166 
2016-12-12 15:53:06 Training Error = 0.67815555555556 
2016-12-12 15:53:06 Training Loss = 0.034936661503532 
2016-12-12 15:53:17 Valid Error = 0.67313462692539 
2016-12-12 15:53:17 Valid Loss = 0.033616209879491 
2016-12-12 15:53:41 Test Error = 0.674 
2016-12-12 15:53:41 Test Loss = 0.033699701409431 
2016-12-12 15:53:41 -------------------LR------------------- 
2016-12-12 15:53:41 0.001953125 
2016-12-12 15:53:41 Epoch 167 
2016-12-12 16:04:23 Training Error = 0.67757777777778 
2016-12-12 16:04:23 Training Loss = 0.034955060285601 
2016-12-12 16:04:34 Valid Error = 0.68213642728546 
2016-12-12 16:04:34 Valid Loss = 0.033779019761905 
2016-12-12 16:04:58 Test Error = 0.6824 
2016-12-12 16:04:58 Test Loss = 0.033843533992767 
2016-12-12 16:04:58 -------------------LR------------------- 
2016-12-12 16:04:58 0.001953125 
2016-12-12 16:04:58 Epoch 168 
2016-12-12 16:15:32 Training Error = 0.67722222222222 
2016-12-12 16:15:32 Training Loss = 0.034929923025722 
2016-12-12 16:15:43 Valid Error = 0.67653530706141 
2016-12-12 16:15:43 Valid Loss = 0.033693399869081 
2016-12-12 16:16:07 Test Error = 0.6738 
2016-12-12 16:16:07 Test Loss = 0.033801017065716 
2016-12-12 16:16:07 -------------------LR------------------- 
2016-12-12 16:16:07 0.001953125 
2016-12-12 16:16:07 Epoch 169 
2016-12-12 16:26:48 Training Error = 0.67746666666667 
2016-12-12 16:26:48 Training Loss = 0.034935166236352 
2016-12-12 16:26:59 Valid Error = 0.6755351070214 
2016-12-12 16:26:59 Valid Loss = 0.033877536905609 
2016-12-12 16:27:23 Test Error = 0.6812 
2016-12-12 16:27:23 Test Loss = 0.033969722401564 
2016-12-12 16:27:23 -------------------LR------------------- 
2016-12-12 16:27:23 0.001953125 
2016-12-12 16:27:23 Epoch 170 
2016-12-12 16:37:49 Training Error = 0.67786666666667 
2016-12-12 16:37:49 Training Loss = 0.034936283379793 
2016-12-12 16:38:01 Valid Error = 0.67253450690138 
2016-12-12 16:38:01 Valid Loss = 0.033605216045276 
2016-12-12 16:38:24 Test Error = 0.6726 
2016-12-12 16:38:24 Test Loss = 0.033704630766705 
2016-12-12 16:38:24 -------------------LR------------------- 
2016-12-12 16:38:24 0.001953125 
2016-12-12 16:38:24 Epoch 171 
2016-12-12 16:48:59 Training Error = 0.68006666666667 
2016-12-12 16:48:59 Training Loss = 0.034931822358207 
2016-12-12 16:49:11 Valid Error = 0.68113622724545 
2016-12-12 16:49:11 Valid Loss = 0.033727436074297 
2016-12-12 16:49:34 Test Error = 0.6845 
2016-12-12 16:49:34 Test Loss = 0.033862112874438 
2016-12-12 16:49:34 -------------------LR------------------- 
2016-12-12 16:49:34 0.001953125 
2016-12-12 16:49:34 Epoch 172 
2016-12-12 17:00:11 Training Error = 0.67837777777778 
2016-12-12 17:00:11 Training Loss = 0.034952833022584 
2016-12-12 17:00:23 Valid Error = 0.66353270654131 
2016-12-12 17:00:23 Valid Loss = 0.033374531204403 
2016-12-12 17:00:46 Test Error = 0.6683 
2016-12-12 17:00:46 Test Loss = 0.033494347295943 
2016-12-12 17:00:46 -------------------LR------------------- 
2016-12-12 17:00:46 0.001953125 
2016-12-12 17:00:46 Epoch 173 
2016-12-12 17:11:16 Training Error = 0.67913333333333 
2016-12-12 17:11:16 Training Loss = 0.03496327621693 
2016-12-12 17:11:28 Valid Error = 0.66773354670934 
2016-12-12 17:11:28 Valid Loss = 0.033446693722206 
2016-12-12 17:11:51 Test Error = 0.6684 
2016-12-12 17:11:51 Test Loss = 0.033586393587149 
2016-12-12 17:11:51 -------------------LR------------------- 
2016-12-12 17:11:51 0.001953125 
2016-12-12 17:11:51 Epoch 174 
2016-12-12 17:22:36 Training Error = 0.67908888888889 
2016-12-12 17:22:36 Training Loss = 0.034942362315275 
2016-12-12 17:22:48 Valid Error = 0.67913582716543 
2016-12-12 17:22:48 Valid Loss = 0.033676061375878 
2016-12-12 17:23:12 Test Error = 0.6798 
2016-12-12 17:23:12 Test Loss = 0.03382786371146 
2016-12-12 17:23:12 -------------------LR------------------- 
2016-12-12 17:23:12 0.001953125 
2016-12-12 17:23:12 Epoch 175 
2016-12-12 17:33:51 Training Error = 0.67728888888889 
2016-12-12 17:33:51 Training Loss = 0.034920870197768 
2016-12-12 17:34:03 Valid Error = 0.68133626725345 
2016-12-12 17:34:03 Valid Loss = 0.033824077044861 
2016-12-12 17:34:27 Test Error = 0.6806 
2016-12-12 17:34:27 Test Loss = 0.033951019618162 
2016-12-12 17:34:27 -------------------LR------------------- 
2016-12-12 17:34:27 0.001953125 
2016-12-12 17:34:27 Epoch 176 
2016-12-12 17:45:13 Training Error = 0.6792 
2016-12-12 17:45:13 Training Loss = 0.034969227012586 
2016-12-12 17:45:24 Valid Error = 0.68393678735747 
2016-12-12 17:45:24 Valid Loss = 0.033856074029671 
2016-12-12 17:45:48 Test Error = 0.6821 
2016-12-12 17:45:48 Test Loss = 0.033957723629702 
2016-12-12 17:45:48 -------------------LR------------------- 
2016-12-12 17:45:48 0.001953125 
2016-12-12 17:45:48 Epoch 177 
2016-12-12 17:56:24 Training Error = 0.67777777777778 
2016-12-12 17:56:24 Training Loss = 0.034956851706586 
2016-12-12 17:56:36 Valid Error = 0.68453690738148 
2016-12-12 17:56:36 Valid Loss = 0.033898744712471 
2016-12-12 17:56:59 Test Error = 0.6879 
2016-12-12 17:56:59 Test Loss = 0.03403724456289 
2016-12-12 17:56:59 -------------------LR------------------- 
2016-12-12 17:56:59 0.001953125 
2016-12-12 17:56:59 Epoch 178 
2016-12-12 18:07:42 Training Error = 0.67791111111111 
2016-12-12 18:07:42 Training Loss = 0.034935281865976 
2016-12-12 18:07:54 Valid Error = 0.68053610722144 
2016-12-12 18:07:54 Valid Loss = 0.033752380305561 
2016-12-12 18:08:18 Test Error = 0.6811 
2016-12-12 18:08:18 Test Loss = 0.033863660119901 
2016-12-12 18:08:18 -------------------LR------------------- 
2016-12-12 18:08:18 0.001953125 
2016-12-12 18:08:18 Epoch 179 
2016-12-12 18:18:59 Training Error = 0.68088888888889 
2016-12-12 18:18:59 Training Loss = 0.034944682144983 
2016-12-12 18:19:11 Valid Error = 0.67353470694139 
2016-12-12 18:19:11 Valid Loss = 0.033691015209039 
2016-12-12 18:19:35 Test Error = 0.6767 
2016-12-12 18:19:35 Test Loss = 0.033781078833683 
2016-12-12 18:19:35 -------------------LR------------------- 
2016-12-12 18:19:35 0.001953125 
2016-12-12 18:19:35 Epoch 180 
2016-12-12 18:30:07 Training Error = 0.67786666666667 
2016-12-12 18:30:07 Training Loss = 0.034940315122631 
2016-12-12 18:30:18 Valid Error = 0.6747349469894 
2016-12-12 18:30:18 Valid Loss = 0.033675080798634 
2016-12-12 18:30:42 Test Error = 0.6768 
2016-12-12 18:30:42 Test Loss = 0.033809909228307 
2016-12-12 18:30:42 -------------------LR------------------- 
2016-12-12 18:30:42 0.001953125 
2016-12-12 18:30:42 Epoch 181 
2016-12-12 18:41:26 Training Error = 0.67617777777778 
2016-12-12 18:41:26 Training Loss = 0.034935236464847 
2016-12-12 18:41:38 Valid Error = 0.6875375075015 
2016-12-12 18:41:38 Valid Loss = 0.03386361644669 
2016-12-12 18:42:01 Test Error = 0.6869 
2016-12-12 18:42:01 Test Loss = 0.033971265182374 
2016-12-12 18:42:01 -------------------LR------------------- 
2016-12-12 18:42:01 0.001953125 
2016-12-12 18:42:01 Epoch 182 
2016-12-12 18:52:29 Training Error = 0.67682222222222 
2016-12-12 18:52:29 Training Loss = 0.034936152462932 
2016-12-12 18:52:41 Valid Error = 0.67153430686137 
2016-12-12 18:52:41 Valid Loss = 0.033679433972667 
2016-12-12 18:53:05 Test Error = 0.6737 
2016-12-12 18:53:05 Test Loss = 0.033745848965493 
2016-12-12 18:53:05 -------------------LR------------------- 
2016-12-12 18:53:05 0.001953125 
2016-12-12 18:53:05 Epoch 183 
2016-12-12 19:03:47 Training Error = 0.67784444444444 
2016-12-12 19:03:47 Training Loss = 0.034945244948295 
2016-12-12 19:03:58 Valid Error = 0.67573514702941 
2016-12-12 19:03:58 Valid Loss = 0.033697424275534 
2016-12-12 19:04:22 Test Error = 0.6769 
2016-12-12 19:04:22 Test Loss = 0.033809141869758 
2016-12-12 19:04:22 -------------------LR------------------- 
2016-12-12 19:04:22 0.001953125 
2016-12-12 19:04:22 Epoch 184 
2016-12-12 19:14:56 Training Error = 0.67824444444444 
2016-12-12 19:14:56 Training Loss = 0.03494698677212 
2016-12-12 19:15:07 Valid Error = 0.68173634726945 
2016-12-12 19:15:07 Valid Loss = 0.033824439410922 
2016-12-12 19:15:31 Test Error = 0.681 
2016-12-12 19:15:31 Test Loss = 0.033921577505245 
2016-12-12 19:15:31 -------------------LR------------------- 
2016-12-12 19:15:31 0.001953125 
2016-12-12 19:15:31 Epoch 185 
2016-12-12 19:26:08 Training Error = 0.67871111111111 
2016-12-12 19:26:08 Training Loss = 0.034939554557204 
2016-12-12 19:26:20 Valid Error = 0.67313462692539 
2016-12-12 19:26:20 Valid Loss = 0.033679609320263 
2016-12-12 19:26:44 Test Error = 0.6776 
2016-12-12 19:26:44 Test Loss = 0.033775195513561 
2016-12-12 19:26:44 -------------------LR------------------- 
2016-12-12 19:26:44 0.001953125 
2016-12-12 19:26:44 Epoch 186 
2016-12-12 19:37:26 Training Error = 0.6778 
2016-12-12 19:37:26 Training Loss = 0.034932736564766 
2016-12-12 19:37:37 Valid Error = 0.67953590718144 
2016-12-12 19:37:37 Valid Loss = 0.033763524507312 
2016-12-12 19:38:01 Test Error = 0.68 
2016-12-12 19:38:01 Test Loss = 0.033856499772163 
2016-12-12 19:38:01 -------------------LR------------------- 
2016-12-12 19:38:01 0.001953125 
2016-12-12 19:38:01 Epoch 187 
2016-12-12 19:48:32 Training Error = 0.67706666666667 
2016-12-12 19:48:32 Training Loss = 0.034942536635155 
2016-12-12 19:48:43 Valid Error = 0.6751350270054 
2016-12-12 19:48:43 Valid Loss = 0.033717514796024 
2016-12-12 19:49:07 Test Error = 0.6776 
2016-12-12 19:49:07 Test Loss = 0.033792261181364 
2016-12-12 19:49:07 -------------------LR------------------- 
2016-12-12 19:49:07 0.001953125 
2016-12-12 19:49:07 Epoch 188 
2016-12-12 19:59:44 Training Error = 0.67846666666667 
2016-12-12 19:59:44 Training Loss = 0.034956551692025 
2016-12-12 19:59:56 Valid Error = 0.67733546709342 
2016-12-12 19:59:56 Valid Loss = 0.033709115697505 
2016-12-12 20:00:19 Test Error = 0.6754 
2016-12-12 20:00:19 Test Loss = 0.033831993834988 
2016-12-12 20:00:19 -------------------LR------------------- 
2016-12-12 20:00:19 0.001953125 
2016-12-12 20:00:20 Epoch 189 
2016-12-12 20:10:52 Training Error = 0.67682222222222 
2016-12-12 20:10:52 Training Loss = 0.034944692636755 
2016-12-12 20:11:03 Valid Error = 0.68193638727746 
2016-12-12 20:11:03 Valid Loss = 0.033867215704961 
2016-12-12 20:11:27 Test Error = 0.684 
2016-12-12 20:11:27 Test Loss = 0.034024014989282 
2016-12-12 20:11:27 -------------------LR------------------- 
2016-12-12 20:11:27 0.001953125 
2016-12-12 20:11:27 Epoch 190 
2016-12-12 20:22:07 Training Error = 0.67933333333333 
2016-12-12 20:22:07 Training Loss = 0.034949948824942 
2016-12-12 20:22:19 Valid Error = 0.67953590718144 
2016-12-12 20:22:19 Valid Loss = 0.033802907087488 
2016-12-12 20:22:42 Test Error = 0.6761 
2016-12-12 20:22:42 Test Loss = 0.033880772028759 
2016-12-12 20:22:42 -------------------LR------------------- 
2016-12-12 20:22:42 0.001953125 
2016-12-12 20:22:42 Epoch 191 
2016-12-12 20:33:12 Training Error = 0.67826666666667 
2016-12-12 20:33:12 Training Loss = 0.034940859570422 
2016-12-12 20:33:24 Valid Error = 0.67673534706941 
2016-12-12 20:33:24 Valid Loss = 0.033654952010453 
2016-12-12 20:33:47 Test Error = 0.6782 
2016-12-12 20:33:47 Test Loss = 0.033772472970805 
2016-12-12 20:33:47 -------------------LR------------------- 
2016-12-12 20:33:47 0.001953125 
2016-12-12 20:33:47 Epoch 192 
2016-12-12 20:44:24 Training Error = 0.67946666666667 
2016-12-12 20:44:24 Training Loss = 0.034957189736041 
2016-12-12 20:44:36 Valid Error = 0.67893578715743 
2016-12-12 20:44:36 Valid Loss = 0.033768320406971 
2016-12-12 20:45:00 Test Error = 0.6811 
2016-12-12 20:45:00 Test Loss = 0.033931215507969 
2016-12-12 20:45:00 -------------------LR------------------- 
2016-12-12 20:45:00 0.001953125 
2016-12-12 20:45:00 Epoch 193 
2016-12-12 20:55:43 Training Error = 0.67857777777778 
2016-12-12 20:55:43 Training Loss = 0.034936544160274 
2016-12-12 20:55:55 Valid Error = 0.68213642728546 
2016-12-12 20:55:55 Valid Loss = 0.033863260000136 
2016-12-12 20:56:19 Test Error = 0.6844 
2016-12-12 20:56:19 Test Loss = 0.033938770582722 
2016-12-12 20:56:19 -------------------LR------------------- 
2016-12-12 20:56:19 0.001953125 
2016-12-12 20:56:19 Epoch 194 
2016-12-12 21:06:50 Training Error = 0.67784444444444 
2016-12-12 21:06:50 Training Loss = 0.034939332871952 
2016-12-12 21:07:01 Valid Error = 0.6751350270054 
2016-12-12 21:07:01 Valid Loss = 0.033702612556989 
2016-12-12 21:07:25 Test Error = 0.679 
2016-12-12 21:07:25 Test Loss = 0.033799701010346 
2016-12-12 21:07:25 -------------------LR------------------- 
2016-12-12 21:07:25 0.001953125 
2016-12-12 21:07:25 Epoch 195 
2016-12-12 21:18:06 Training Error = 0.67768888888889 
2016-12-12 21:18:06 Training Loss = 0.034961474930698 
2016-12-12 21:18:18 Valid Error = 0.67633526705341 
2016-12-12 21:18:18 Valid Loss = 0.033756368125757 
2016-12-12 21:18:41 Test Error = 0.6823 
2016-12-12 21:18:41 Test Loss = 0.03389561565059 
2016-12-12 21:18:41 -------------------LR------------------- 
2016-12-12 21:18:41 0.001953125 
2016-12-12 21:18:41 Epoch 196 
2016-12-12 21:29:12 Training Error = 0.68082222222222 
2016-12-12 21:29:12 Training Loss = 0.034953935518861 
2016-12-12 21:29:24 Valid Error = 0.6753350670134 
2016-12-12 21:29:24 Valid Loss = 0.033664277962276 
2016-12-12 21:29:48 Test Error = 0.6749 
2016-12-12 21:29:48 Test Loss = 0.033752284657424 
2016-12-12 21:29:48 -------------------LR------------------- 
2016-12-12 21:29:48 0.001953125 
2016-12-12 21:29:48 Epoch 197 
2016-12-12 21:40:30 Training Error = 0.67837777777778 
2016-12-12 21:40:30 Training Loss = 0.034937304722315 
2016-12-12 21:40:41 Valid Error = 0.68593718743749 
2016-12-12 21:40:41 Valid Loss = 0.033867879883937 
2016-12-12 21:41:05 Test Error = 0.6835 
2016-12-12 21:41:05 Test Loss = 0.033953284290945 
2016-12-12 21:41:05 -------------------LR------------------- 
2016-12-12 21:41:05 0.001953125 
2016-12-12 21:41:05 Epoch 198 
2016-12-12 21:51:37 Training Error = 0.67853333333333 
2016-12-12 21:51:37 Training Loss = 0.034935371530327 
2016-12-12 21:51:49 Valid Error = 0.67893578715743 
2016-12-12 21:51:49 Valid Loss = 0.03383677031636 
2016-12-12 21:52:13 Test Error = 0.684 
2016-12-12 21:52:13 Test Loss = 0.033915121236425 
2016-12-12 21:52:13 -------------------LR------------------- 
2016-12-12 21:52:13 0.001953125 
2016-12-12 21:52:13 Epoch 199 
2016-12-12 22:03:03 Training Error = 0.67746666666667 
2016-12-12 22:03:03 Training Loss = 0.034952725795182 
2016-12-12 22:03:15 Valid Error = 0.68133626725345 
2016-12-12 22:03:15 Valid Loss = 0.033853122485266 
2016-12-12 22:03:38 Test Error = 0.6835 
2016-12-12 22:03:38 Test Loss = 0.033957132624972 
2016-12-12 22:03:38 -------------------LR------------------- 
2016-12-12 22:03:38 0.001953125 
2016-12-12 22:03:38 Epoch 200 
2016-12-12 22:14:16 Training Error = 0.67722222222222 
2016-12-12 22:14:16 Training Loss = 0.034948294945061 
2016-12-12 22:14:27 Valid Error = 0.67933586717343 
2016-12-12 22:14:27 Valid Loss = 0.033673830092708 
2016-12-12 22:14:51 Test Error = 0.68 
2016-12-12 22:14:51 Test Loss = 0.033806692764258 
2016-12-12 22:14:51 -------------------LR------------------- 
2016-12-12 22:14:51 0.0009765625 
2016-12-12 22:14:51 Epoch 201 
2016-12-12 22:25:18 Training Error = 0.67837777777778 
2016-12-12 22:25:18 Training Loss = 0.034934250729328 
2016-12-12 22:25:29 Valid Error = 0.67913582716543 
2016-12-12 22:25:29 Valid Loss = 0.033663209907401 
2016-12-12 22:25:53 Test Error = 0.6732 
2016-12-12 22:25:53 Test Loss = 0.033763245032851 
2016-12-12 22:25:53 -------------------LR------------------- 
2016-12-12 22:25:53 0.0009765625 
2016-12-12 22:25:53 Epoch 202 
2016-12-12 22:36:33 Training Error = 0.67735555555556 
2016-12-12 22:36:33 Training Loss = 0.034953099997206 
2016-12-12 22:36:44 Valid Error = 0.67833566713343 
2016-12-12 22:36:44 Valid Loss = 0.033585845363507 
2016-12-12 22:37:08 Test Error = 0.6783 
2016-12-12 22:37:08 Test Loss = 0.033692553498942 
2016-12-12 22:37:08 -------------------LR------------------- 
2016-12-12 22:37:08 0.0009765625 
2016-12-12 22:37:08 Epoch 203 
2016-12-12 22:47:45 Training Error = 0.67811111111111 
2016-12-12 22:47:45 Training Loss = 0.03494372298433 
2016-12-12 22:47:56 Valid Error = 0.6871374274855 
2016-12-12 22:47:56 Valid Loss = 0.033891930618941 
2016-12-12 22:48:20 Test Error = 0.685 
2016-12-12 22:48:20 Test Loss = 0.034017391174462 
2016-12-12 22:48:20 -------------------LR------------------- 
2016-12-12 22:48:20 0.0009765625 
2016-12-12 22:48:20 Epoch 204 
2016-12-12 22:58:59 Training Error = 0.67977777777778 
2016-12-12 22:58:59 Training Loss = 0.034953846853565 
2016-12-12 22:59:10 Valid Error = 0.68573714742949 
2016-12-12 22:59:10 Valid Loss = 0.033726769411973 
2016-12-12 22:59:34 Test Error = 0.6838 
2016-12-12 22:59:34 Test Loss = 0.033819425181978 
2016-12-12 22:59:34 -------------------LR------------------- 
2016-12-12 22:59:34 0.0009765625 
2016-12-12 22:59:34 Epoch 205 
2016-12-12 23:10:04 Training Error = 0.67704444444444 
2016-12-12 23:10:04 Training Loss = 0.034940990013155 
2016-12-12 23:10:15 Valid Error = 0.68153630726145 
2016-12-12 23:10:15 Valid Loss = 0.033837185246604 
2016-12-12 23:10:39 Test Error = 0.6826 
2016-12-12 23:10:39 Test Loss = 0.03391474623589 
2016-12-12 23:10:39 -------------------LR------------------- 
2016-12-12 23:10:39 0.0009765625 
2016-12-12 23:10:39 Epoch 206 
2016-12-12 23:21:16 Training Error = 0.67822222222222 
2016-12-12 23:21:16 Training Loss = 0.034963829270141 
2016-12-12 23:21:28 Valid Error = 0.6753350670134 
2016-12-12 23:21:28 Valid Loss = 0.033508799149374 
2016-12-12 23:21:51 Test Error = 0.6727 
2016-12-12 23:21:51 Test Loss = 0.033584767845786 
2016-12-12 23:21:51 -------------------LR------------------- 
2016-12-12 23:21:51 0.0009765625 
2016-12-12 23:21:52 Epoch 207 
2016-12-12 23:32:28 Training Error = 0.67853333333333 
2016-12-12 23:32:28 Training Loss = 0.034944852218032 
2016-12-12 23:32:40 Valid Error = 0.68353670734147 
2016-12-12 23:32:40 Valid Loss = 0.033884064030259 
2016-12-12 23:33:04 Test Error = 0.6837 
2016-12-12 23:33:04 Test Loss = 0.034009780261167 
2016-12-12 23:33:04 -------------------LR------------------- 
2016-12-12 23:33:04 0.0009765625 
2016-12-12 23:33:04 Epoch 208 
2016-12-12 23:43:33 Training Error = 0.67806666666667 
2016-12-12 23:43:33 Training Loss = 0.034947840598496 
2016-12-12 23:43:44 Valid Error = 0.6877375475095 
2016-12-12 23:43:44 Valid Loss = 0.033769192462804 
2016-12-12 23:44:08 Test Error = 0.6825 
2016-12-12 23:44:08 Test Loss = 0.033860622545716 
2016-12-12 23:44:08 -------------------LR------------------- 
2016-12-12 23:44:08 0.0009765625 
2016-12-12 23:44:08 Epoch 209 
2016-12-12 23:54:49 Training Error = 0.67846666666667 
2016-12-12 23:54:49 Training Loss = 0.03494098904458 
2016-12-12 23:55:00 Valid Error = 0.68453690738148 
2016-12-12 23:55:00 Valid Loss = 0.033804919461014 
2016-12-12 23:55:24 Test Error = 0.6819 
2016-12-12 23:55:24 Test Loss = 0.033917337830659 
2016-12-12 23:55:24 -------------------LR------------------- 
2016-12-12 23:55:24 0.0009765625 
2016-12-12 23:55:24 Epoch 210 
2016-12-13 00:06:00 Training Error = 0.67833333333333 
2016-12-13 00:06:00 Training Loss = 0.03494229614396 
2016-12-13 00:06:12 Valid Error = 0.67273454690938 
2016-12-13 00:06:12 Valid Loss = 0.033613278335516 
2016-12-13 00:06:35 Test Error = 0.6756 
2016-12-13 00:06:35 Test Loss = 0.033707330166155 
2016-12-13 00:06:35 -------------------LR------------------- 
2016-12-13 00:06:35 0.0009765625 
2016-12-13 00:06:35 Epoch 211 
2016-12-13 00:17:17 Training Error = 0.67688888888889 
2016-12-13 00:17:17 Training Loss = 0.034944438653236 
2016-12-13 00:17:28 Valid Error = 0.68033606721344 
2016-12-13 00:17:28 Valid Loss = 0.033796025736638 
2016-12-13 00:17:52 Test Error = 0.677 
2016-12-13 00:17:52 Test Loss = 0.033924326759994 
2016-12-13 00:17:52 -------------------LR------------------- 
2016-12-13 00:17:52 0.0009765625 
2016-12-13 00:17:52 Epoch 212 
2016-12-13 00:28:23 Training Error = 0.678 
2016-12-13 00:28:23 Training Loss = 0.034940556047315 
2016-12-13 00:28:35 Valid Error = 0.67333466693339 
2016-12-13 00:28:35 Valid Loss = 0.033720268763427 
2016-12-13 00:28:59 Test Error = 0.6809 
2016-12-13 00:28:59 Test Loss = 0.033831549571578 
2016-12-13 00:28:59 -------------------LR------------------- 
2016-12-13 00:28:59 0.0009765625 
2016-12-13 00:28:59 Epoch 213 
2016-12-13 00:39:41 Training Error = 0.67768888888889 
2016-12-13 00:39:41 Training Loss = 0.034966186772693 
2016-12-13 00:39:53 Valid Error = 0.68353670734147 
2016-12-13 00:39:53 Valid Loss = 0.033877680987174 
2016-12-13 00:40:16 Test Error = 0.6853 
2016-12-13 00:40:16 Test Loss = 0.033993081013868 
2016-12-13 00:40:16 -------------------LR------------------- 
2016-12-13 00:40:16 0.0009765625 
2016-12-13 00:40:16 Epoch 214 
2016-12-13 00:50:52 Training Error = 0.67944444444444 
2016-12-13 00:50:52 Training Loss = 0.034948831454597 
2016-12-13 00:51:04 Valid Error = 0.68053610722144 
2016-12-13 00:51:04 Valid Loss = 0.033669277565389 
2016-12-13 00:51:27 Test Error = 0.68 
2016-12-13 00:51:27 Test Loss = 0.033782274996399 
2016-12-13 00:51:27 -------------------LR------------------- 
2016-12-13 00:51:27 0.0009765625 
2016-12-13 00:51:27 Epoch 215 
2016-12-13 01:01:58 Training Error = 0.67797777777778 
2016-12-13 01:01:58 Training Loss = 0.034940341175957 
2016-12-13 01:02:10 Valid Error = 0.66793358671734 
2016-12-13 01:02:10 Valid Loss = 0.033419043496116 
2016-12-13 01:02:34 Test Error = 0.6726 
2016-12-13 01:02:34 Test Loss = 0.033543999392516 
2016-12-13 01:02:34 -------------------LR------------------- 
2016-12-13 01:02:34 0.0009765625 
2016-12-13 01:02:34 Epoch 216 
2016-12-13 01:13:10 Training Error = 0.67793333333333 
2016-12-13 01:13:10 Training Loss = 0.034939445914193 
2016-12-13 01:13:21 Valid Error = 0.68233646729346 
2016-12-13 01:13:21 Valid Loss = 0.033900921336134 
2016-12-13 01:13:45 Test Error = 0.6873 
2016-12-13 01:13:45 Test Loss = 0.034014851895108 
2016-12-13 01:13:45 -------------------LR------------------- 
2016-12-13 01:13:45 0.0009765625 
2016-12-13 01:13:45 Epoch 217 
2016-12-13 01:24:13 Training Error = 0.67868888888889 
2016-12-13 01:24:13 Training Loss = 0.03494062804363 
2016-12-13 01:24:25 Valid Error = 0.68353670734147 
2016-12-13 01:24:25 Valid Loss = 0.033786859257958 
2016-12-13 01:24:49 Test Error = 0.6852 
2016-12-13 01:24:49 Test Loss = 0.033927268890818 
2016-12-13 01:24:49 -------------------LR------------------- 
2016-12-13 01:24:49 0.0009765625 
2016-12-13 01:24:49 Epoch 218 
2016-12-13 01:35:26 Training Error = 0.6766 
2016-12-13 01:35:26 Training Loss = 0.034937489855696 
2016-12-13 01:35:38 Valid Error = 0.67173434686937 
2016-12-13 01:35:38 Valid Loss = 0.033598456193051 
2016-12-13 01:36:01 Test Error = 0.6771 
2016-12-13 01:36:01 Test Loss = 0.033694715909897 
2016-12-13 01:36:01 -------------------LR------------------- 
2016-12-13 01:36:01 0.0009765625 
2016-12-13 01:36:01 Epoch 219 
2016-12-13 01:46:31 Training Error = 0.67813333333333 
2016-12-13 01:46:31 Training Loss = 0.034928222285076 
2016-12-13 01:46:43 Valid Error = 0.67113422684537 
2016-12-13 01:46:43 Valid Loss = 0.033469328729412 
2016-12-13 01:47:07 Test Error = 0.6717 
2016-12-13 01:47:07 Test Loss = 0.03353694170144 
2016-12-13 01:47:07 -------------------LR------------------- 
2016-12-13 01:47:07 0.0009765625 
2016-12-13 01:47:07 Epoch 220 
2016-12-13 01:57:47 Training Error = 0.68062222222222 
2016-12-13 01:57:47 Training Loss = 0.034965336620808 
2016-12-13 01:57:58 Valid Error = 0.6873374674935 
2016-12-13 01:57:58 Valid Loss = 0.033953741683236 
2016-12-13 01:58:22 Test Error = 0.6899 
2016-12-13 01:58:22 Test Loss = 0.034087121091831 
2016-12-13 01:58:22 -------------------LR------------------- 
2016-12-13 01:58:22 0.0009765625 
2016-12-13 01:58:22 Epoch 221 
2016-12-13 02:09:01 Training Error = 0.67971111111111 
2016-12-13 02:09:01 Training Loss = 0.034950071617284 
2016-12-13 02:09:13 Valid Error = 0.69193838767754 
2016-12-13 02:09:13 Valid Loss = 0.034067566213729 
2016-12-13 02:09:36 Test Error = 0.6904 
2016-12-13 02:09:36 Test Loss = 0.034165839252958 
2016-12-13 02:09:36 -------------------LR------------------- 
2016-12-13 02:09:36 0.0009765625 
2016-12-13 02:09:36 Epoch 222 
2016-12-13 02:20:10 Training Error = 0.67762222222222 
2016-12-13 02:20:10 Training Loss = 0.034948389628394 
2016-12-13 02:20:21 Valid Error = 0.67773554710942 
2016-12-13 02:20:21 Valid Loss = 0.033716893756584 
2016-12-13 02:20:45 Test Error = 0.6797 
2016-12-13 02:20:45 Test Loss = 0.033838776387986 
2016-12-13 02:20:45 -------------------LR------------------- 
2016-12-13 02:20:45 0.0009765625 
2016-12-13 02:20:45 Epoch 223 
2016-12-13 02:31:26 Training Error = 0.67757777777778 
2016-12-13 02:31:26 Training Loss = 0.034957832111554 
2016-12-13 02:31:37 Valid Error = 0.67393478695739 
2016-12-13 02:31:37 Valid Loss = 0.033613695688748 
2016-12-13 02:32:01 Test Error = 0.6761 
2016-12-13 02:32:01 Test Loss = 0.033690133519993 
2016-12-13 02:32:01 -------------------LR------------------- 
2016-12-13 02:32:01 0.0009765625 
2016-12-13 02:32:01 Epoch 224 
2016-12-13 02:42:37 Training Error = 0.67708888888889 
2016-12-13 02:42:37 Training Loss = 0.034952908310701 
2016-12-13 02:42:49 Valid Error = 0.68633726745349 
2016-12-13 02:42:49 Valid Loss = 0.033937019698228 
2016-12-13 02:43:13 Test Error = 0.6833 
2016-12-13 02:43:13 Test Loss = 0.034034925220878 
2016-12-13 02:43:13 -------------------LR------------------- 
2016-12-13 02:43:13 0.0009765625 
2016-12-13 02:43:13 Epoch 225 
2016-12-13 02:53:48 Training Error = 0.67711111111111 
2016-12-13 02:53:48 Training Loss = 0.034945878074928 
2016-12-13 02:54:00 Valid Error = 0.6875375075015 
2016-12-13 02:54:00 Valid Loss = 0.033840283687895 
2016-12-13 02:54:23 Test Error = 0.6849 
2016-12-13 02:54:23 Test Loss = 0.033926445055919 
2016-12-13 02:54:23 -------------------LR------------------- 
2016-12-13 02:54:23 0.0009765625 
2016-12-13 02:54:23 Epoch 226 
2016-12-13 03:05:01 Training Error = 0.67893333333333 
2016-12-13 03:05:01 Training Loss = 0.034951481676914 
2016-12-13 03:05:12 Valid Error = 0.66593318663733 
2016-12-13 03:05:12 Valid Loss = 0.033406358114418 
2016-12-13 03:05:36 Test Error = 0.6684 
2016-12-13 03:05:36 Test Loss = 0.033461681110844 
2016-12-13 03:05:36 -------------------LR------------------- 
2016-12-13 03:05:36 0.0009765625 
2016-12-13 03:05:36 Epoch 227 
2016-12-13 03:16:15 Training Error = 0.67911111111111 
2016-12-13 03:16:15 Training Loss = 0.034960970004851 
2016-12-13 03:16:26 Valid Error = 0.67753550710142 
2016-12-13 03:16:26 Valid Loss = 0.033684778144519 
2016-12-13 03:16:50 Test Error = 0.679 
2016-12-13 03:16:50 Test Loss = 0.033799697942794 
2016-12-13 03:16:50 -------------------LR------------------- 
2016-12-13 03:16:50 0.0009765625 
2016-12-13 03:16:50 Epoch 228 
2016-12-13 03:27:29 Training Error = 0.67884444444444 
2016-12-13 03:27:29 Training Loss = 0.034955077811398 
2016-12-13 03:27:40 Valid Error = 0.68173634726945 
2016-12-13 03:27:40 Valid Loss = 0.03380032912732 
2016-12-13 03:28:04 Test Error = 0.6801 
2016-12-13 03:28:04 Test Loss = 0.033870171817245 
2016-12-13 03:28:04 -------------------LR------------------- 
2016-12-13 03:28:04 0.0009765625 
2016-12-13 03:28:04 Epoch 229 
2016-12-13 03:38:37 Training Error = 0.67771111111111 
2016-12-13 03:38:37 Training Loss = 0.034960465322841 
2016-12-13 03:38:49 Valid Error = 0.68433686737347 
2016-12-13 03:38:49 Valid Loss = 0.033886044098714 
2016-12-13 03:39:13 Test Error = 0.6849 
2016-12-13 03:39:13 Test Loss = 0.034016989082288 
2016-12-13 03:39:13 -------------------LR------------------- 
2016-12-13 03:39:13 0.0009765625 
2016-12-13 03:39:13 Epoch 230 
2016-12-13 03:49:52 Training Error = 0.67768888888889 
2016-12-13 03:49:52 Training Loss = 0.034953899688341 
2016-12-13 03:50:04 Valid Error = 0.68473694738948 
2016-12-13 03:50:04 Valid Loss = 0.033837924107074 
2016-12-13 03:50:27 Test Error = 0.6842 
2016-12-13 03:50:27 Test Loss = 0.03395025745319 
2016-12-13 03:50:27 -------------------LR------------------- 
2016-12-13 03:50:27 0.0009765625 
2016-12-13 03:50:27 Epoch 231 
2016-12-13 04:00:57 Training Error = 0.67886666666667 
2016-12-13 04:00:57 Training Loss = 0.03495124400678 
2016-12-13 04:01:08 Valid Error = 0.68233646729346 
2016-12-13 04:01:08 Valid Loss = 0.033806293739333 
2016-12-13 04:01:32 Test Error = 0.6796 
2016-12-13 04:01:32 Test Loss = 0.033887231228458 
2016-12-13 04:01:32 -------------------LR------------------- 
2016-12-13 04:01:32 0.0009765625 
2016-12-13 04:01:32 Epoch 232 
2016-12-13 04:12:08 Training Error = 0.67848888888889 
2016-12-13 04:12:08 Training Loss = 0.034940342740579 
2016-12-13 04:12:19 Valid Error = 0.66573314662933 
2016-12-13 04:12:19 Valid Loss = 0.03358075464397 
2016-12-13 04:12:43 Test Error = 0.6716 
2016-12-13 04:12:43 Test Loss = 0.033712893261272 
2016-12-13 04:12:43 -------------------LR------------------- 
2016-12-13 04:12:43 0.0009765625 
2016-12-13 04:12:43 Epoch 233 
2016-12-13 04:23:16 Training Error = 0.67817777777778 
2016-12-13 04:23:16 Training Loss = 0.034961678182537 
2016-12-13 04:23:28 Valid Error = 0.68193638727746 
2016-12-13 04:23:28 Valid Loss = 0.033748024298959 
2016-12-13 04:23:52 Test Error = 0.6836 
2016-12-13 04:23:52 Test Loss = 0.033825100956449 
2016-12-13 04:23:52 -------------------LR------------------- 
2016-12-13 04:23:52 0.0009765625 
2016-12-13 04:23:52 Epoch 234 
2016-12-13 04:34:31 Training Error = 0.67926666666667 
2016-12-13 04:34:31 Training Loss = 0.034957855120301 
2016-12-13 04:34:43 Valid Error = 0.69073814762953 
2016-12-13 04:34:43 Valid Loss = 0.033958631023145 
2016-12-13 04:35:06 Test Error = 0.6879 
2016-12-13 04:35:06 Test Loss = 0.034039151835593 
2016-12-13 04:35:06 -------------------LR------------------- 
2016-12-13 04:35:06 0.0009765625 
2016-12-13 04:35:06 Epoch 235 
2016-12-13 04:45:44 Training Error = 0.67553333333333 
2016-12-13 04:45:44 Training Loss = 0.034932094331492 
2016-12-13 04:45:56 Valid Error = 0.67013402680536 
2016-12-13 04:45:56 Valid Loss = 0.033541280434317 
2016-12-13 04:46:19 Test Error = 0.6684 
2016-12-13 04:46:19 Test Loss = 0.033632311395779 
2016-12-13 04:46:19 -------------------LR------------------- 
2016-12-13 04:46:19 0.0009765625 
2016-12-13 04:46:19 Epoch 236 
2016-12-13 04:56:55 Training Error = 0.67771111111111 
2016-12-13 04:56:55 Training Loss = 0.034954475279559 
2016-12-13 04:57:06 Valid Error = 0.67693538707742 
2016-12-13 04:57:06 Valid Loss = 0.033758035878807 
2016-12-13 04:57:30 Test Error = 0.6787 
2016-12-13 04:57:30 Test Loss = 0.033892467128243 
2016-12-13 04:57:30 -------------------LR------------------- 
2016-12-13 04:57:30 0.0009765625 
2016-12-13 04:57:30 Epoch 237 
2016-12-13 05:08:03 Training Error = 0.68044444444444 
2016-12-13 05:08:03 Training Loss = 0.034985921450637 
2016-12-13 05:08:15 Valid Error = 0.67753550710142 
2016-12-13 05:08:15 Valid Loss = 0.033774437706035 
2016-12-13 05:08:38 Test Error = 0.6802 
2016-12-13 05:08:38 Test Loss = 0.033868105715247 
2016-12-13 05:08:38 -------------------LR------------------- 
2016-12-13 05:08:38 0.0009765625 
2016-12-13 05:08:38 Epoch 238 
2016-12-13 05:19:10 Training Error = 0.67686666666667 
2016-12-13 05:19:10 Training Loss = 0.034936972257089 
2016-12-13 05:19:22 Valid Error = 0.67993598719744 
2016-12-13 05:19:22 Valid Loss = 0.033675858513141 
2016-12-13 05:19:45 Test Error = 0.6787 
2016-12-13 05:19:45 Test Loss = 0.033783310750488 
2016-12-13 05:19:45 -------------------LR------------------- 
2016-12-13 05:19:45 0.0009765625 
2016-12-13 05:19:45 Epoch 239 
2016-12-13 05:30:22 Training Error = 0.67817777777778 
2016-12-13 05:30:22 Training Loss = 0.034951550506733 
2016-12-13 05:30:33 Valid Error = 0.68133626725345 
2016-12-13 05:30:33 Valid Loss = 0.033759472766793 
2016-12-13 05:30:57 Test Error = 0.6822 
2016-12-13 05:30:57 Test Loss = 0.033855401512924 
2016-12-13 05:30:57 -------------------LR------------------- 
2016-12-13 05:30:57 0.0009765625 
2016-12-13 05:30:57 Epoch 240 
2016-12-13 05:41:32 Training Error = 0.67588888888889 
2016-12-13 05:41:32 Training Loss = 0.034939198578623 
2016-12-13 05:41:43 Valid Error = 0.68033606721344 
2016-12-13 05:41:43 Valid Loss = 0.033726197323791 
2016-12-13 05:42:07 Test Error = 0.682 
2016-12-13 05:42:07 Test Loss = 0.033867393511875 
2016-12-13 05:42:07 -------------------LR------------------- 
2016-12-13 05:42:07 0.0009765625 
2016-12-13 05:42:07 Epoch 241 
2016-12-13 05:52:43 Training Error = 0.67933333333333 
2016-12-13 05:52:43 Training Loss = 0.034944492873143 
2016-12-13 05:52:54 Valid Error = 0.67033406681336 
2016-12-13 05:52:54 Valid Loss = 0.03349319755061 
2016-12-13 05:53:18 Test Error = 0.6708 
2016-12-13 05:53:18 Test Loss = 0.033595602922379 
2016-12-13 05:53:18 -------------------LR------------------- 
2016-12-13 05:53:18 0.0009765625 
2016-12-13 05:53:18 Epoch 242 
2016-12-13 06:03:52 Training Error = 0.67928888888889 
2016-12-13 06:03:52 Training Loss = 0.0349431225522 
2016-12-13 06:04:04 Valid Error = 0.67573514702941 
2016-12-13 06:04:04 Valid Loss = 0.033503865307537 
2016-12-13 06:04:28 Test Error = 0.6757 
2016-12-13 06:04:28 Test Loss = 0.033589972811899 
2016-12-13 06:04:28 -------------------LR------------------- 
2016-12-13 06:04:28 0.0009765625 
2016-12-13 06:04:28 Epoch 243 
2016-12-13 06:14:59 Training Error = 0.67968888888889 
2016-12-13 06:14:59 Training Loss = 0.034947203919291 
2016-12-13 06:15:10 Valid Error = 0.68173634726945 
2016-12-13 06:15:10 Valid Loss = 0.033762114276507 
2016-12-13 06:15:34 Test Error = 0.6825 
2016-12-13 06:15:34 Test Loss = 0.033898573058426 
2016-12-13 06:15:34 -------------------LR------------------- 
2016-12-13 06:15:34 0.0009765625 
2016-12-13 06:15:34 Epoch 244 
2016-12-13 06:24:28 Training Error = 0.67835555555556 
2016-12-13 06:24:28 Training Loss = 0.034941865432669 
2016-12-13 06:24:40 Valid Error = 0.67373474694939 
2016-12-13 06:24:40 Valid Loss = 0.033539363484271 
2016-12-13 06:25:03 Test Error = 0.6749 
2016-12-13 06:25:03 Test Loss = 0.033628476744245 
2016-12-13 06:25:03 -------------------LR------------------- 
2016-12-13 06:25:03 0.0009765625 
2016-12-13 06:25:03 Epoch 245 
2016-12-13 06:34:04 Training Error = 0.67982222222222 
2016-12-13 06:34:04 Training Loss = 0.034966401749037 
2016-12-13 06:34:15 Valid Error = 0.67633526705341 
2016-12-13 06:34:15 Valid Loss = 0.033737506293043 
2016-12-13 06:34:39 Test Error = 0.6814 
2016-12-13 06:34:39 Test Loss = 0.033865658583914 
2016-12-13 06:34:39 -------------------LR------------------- 
2016-12-13 06:34:39 0.0009765625 
2016-12-13 06:34:39 Epoch 246 
2016-12-13 06:43:29 Training Error = 0.67988888888889 
2016-12-13 06:43:29 Training Loss = 0.03493978892199 
2016-12-13 06:43:41 Valid Error = 0.67593518703741 
2016-12-13 06:43:41 Valid Loss = 0.033620248034893 
2016-12-13 06:44:04 Test Error = 0.6768 
2016-12-13 06:44:04 Test Loss = 0.033706643626948 
2016-12-13 06:44:04 -------------------LR------------------- 
2016-12-13 06:44:04 0.0009765625 
2016-12-13 06:44:04 Epoch 247 
2016-12-13 06:52:54 Training Error = 0.67717777777778 
2016-12-13 06:52:54 Training Loss = 0.03494866759601 
2016-12-13 06:53:05 Valid Error = 0.67093418683737 
2016-12-13 06:53:05 Valid Loss = 0.033551267935182 
2016-12-13 06:53:29 Test Error = 0.671 
2016-12-13 06:53:29 Test Loss = 0.033655002086785 
2016-12-13 06:53:29 -------------------LR------------------- 
2016-12-13 06:53:29 0.0009765625 
2016-12-13 06:53:29 Epoch 248 
2016-12-13 07:02:21 Training Error = 0.6786 
2016-12-13 07:02:21 Training Loss = 0.034963249912993 
2016-12-13 07:02:32 Valid Error = 0.6879375875175 
2016-12-13 07:02:32 Valid Loss = 0.033999153455386 
2016-12-13 07:02:56 Test Error = 0.6902 
2016-12-13 07:02:56 Test Loss = 0.034113516351979 
2016-12-13 07:02:56 -------------------LR------------------- 
2016-12-13 07:02:56 0.0009765625 
2016-12-13 07:02:56 Epoch 249 
2016-12-13 07:11:49 Training Error = 0.67951111111111 
2016-12-13 07:11:49 Training Loss = 0.034952990405939 
2016-12-13 07:12:01 Valid Error = 0.67733546709342 
2016-12-13 07:12:01 Valid Loss = 0.033719652876069 
2016-12-13 07:12:24 Test Error = 0.6729 
2016-12-13 07:12:24 Test Loss = 0.033780659945907 
2016-12-13 07:12:24 -------------------LR------------------- 
2016-12-13 07:12:24 0.0009765625 
2016-12-13 07:12:24 Epoch 250 
2016-12-13 07:21:18 Training Error = 0.68062222222222 
2016-12-13 07:21:18 Training Loss = 0.034978980516846 
2016-12-13 07:21:30 Valid Error = 0.67393478695739 
2016-12-13 07:21:30 Valid Loss = 0.033522198467531 
2016-12-13 07:21:54 Test Error = 0.6748 
2016-12-13 07:21:54 Test Loss = 0.033649655162908 
2016-12-13 07:21:54 -------------------LR------------------- 
2016-12-13 07:21:54 0.00048828125 
2016-12-13 07:21:54 Epoch 251 
2016-12-13 07:30:46 Training Error = 0.67704444444444 
2016-12-13 07:30:46 Training Loss = 0.034944330894134 
2016-12-13 07:30:58 Valid Error = 0.67413482696539 
2016-12-13 07:30:58 Valid Loss = 0.033610506842408 
2016-12-13 07:31:21 Test Error = 0.6746 
2016-12-13 07:31:21 Test Loss = 0.033729767328615 
2016-12-13 07:31:21 -------------------LR------------------- 
2016-12-13 07:31:21 0.00048828125 
2016-12-13 07:31:21 Epoch 252 
2016-12-13 07:40:20 Training Error = 0.67786666666667 
2016-12-13 07:40:20 Training Loss = 0.034929145571183 
2016-12-13 07:40:31 Valid Error = 0.6747349469894 
2016-12-13 07:40:31 Valid Loss = 0.03354194040971 
2016-12-13 07:40:55 Test Error = 0.6731 
2016-12-13 07:40:55 Test Loss = 0.033670809466368 
2016-12-13 07:40:55 -------------------LR------------------- 
2016-12-13 07:40:55 0.00048828125 
2016-12-13 07:40:55 Epoch 253 
2016-12-13 07:49:46 Training Error = 0.67986666666667 
2016-12-13 07:49:46 Training Loss = 0.034962554712864 
2016-12-13 07:49:57 Valid Error = 0.68293658731746 
2016-12-13 07:49:57 Valid Loss = 0.03386712226471 
2016-12-13 07:50:21 Test Error = 0.6828 
2016-12-13 07:50:21 Test Loss = 0.033983884131073 
2016-12-13 07:50:21 -------------------LR------------------- 
2016-12-13 07:50:21 0.00048828125 
2016-12-13 07:50:21 Epoch 254 
2016-12-13 07:59:16 Training Error = 0.67771111111111 
2016-12-13 07:59:16 Training Loss = 0.034955368939448 
2016-12-13 07:59:27 Valid Error = 0.68033606721344 
2016-12-13 07:59:27 Valid Loss = 0.033773540398527 
2016-12-13 07:59:51 Test Error = 0.683 
2016-12-13 07:59:51 Test Loss = 0.033885413248828 
2016-12-13 07:59:51 -------------------LR------------------- 
2016-12-13 07:59:51 0.00048828125 
2016-12-13 07:59:51 Epoch 255 
2016-12-13 08:08:47 Training Error = 0.67711111111111 
2016-12-13 08:08:47 Training Loss = 0.034937547631562 
2016-12-13 08:08:58 Valid Error = 0.68073614722945 
2016-12-13 08:08:58 Valid Loss = 0.033854117557326 
2016-12-13 08:09:22 Test Error = 0.6851 
2016-12-13 08:09:22 Test Loss = 0.033948488858095 
2016-12-13 08:09:22 -------------------LR------------------- 
2016-12-13 08:09:22 0.00048828125 
2016-12-13 08:09:22 Epoch 256 
2016-12-13 08:18:14 Training Error = 0.67811111111111 
2016-12-13 08:18:14 Training Loss = 0.034950900846584 
2016-12-13 08:18:26 Valid Error = 0.67953590718144 
2016-12-13 08:18:26 Valid Loss = 0.033700701970519 
2016-12-13 08:18:49 Test Error = 0.6804 
2016-12-13 08:18:49 Test Loss = 0.033825026196279 
2016-12-13 08:18:49 -------------------LR------------------- 
2016-12-13 08:18:49 0.00048828125 
2016-12-13 08:18:49 Epoch 257 
2016-12-13 08:27:43 Training Error = 0.67857777777778 
2016-12-13 08:27:43 Training Loss = 0.0349575072256 
2016-12-13 08:27:55 Valid Error = 0.67573514702941 
2016-12-13 08:27:55 Valid Loss = 0.033601776523142 
2016-12-13 08:28:18 Test Error = 0.675 
2016-12-13 08:28:18 Test Loss = 0.033701553830675 
2016-12-13 08:28:18 -------------------LR------------------- 
2016-12-13 08:28:18 0.00048828125 
2016-12-13 08:28:18 Epoch 258 
2016-12-13 08:37:13 Training Error = 0.678 
2016-12-13 08:37:13 Training Loss = 0.034948742755435 
2016-12-13 08:37:25 Valid Error = 0.67093418683737 
2016-12-13 08:37:25 Valid Loss = 0.033658497872447 
2016-12-13 08:37:49 Test Error = 0.6744 
2016-12-13 08:37:49 Test Loss = 0.033768229363071 
2016-12-13 08:37:49 -------------------LR------------------- 
2016-12-13 08:37:49 0.00048828125 
2016-12-13 08:37:49 Epoch 259 
2016-12-13 08:46:51 Training Error = 0.67735555555556 
2016-12-13 08:46:51 Training Loss = 0.034948182888329 
2016-12-13 08:47:03 Valid Error = 0.67813562712543 
2016-12-13 08:47:03 Valid Loss = 0.033802851798521 
2016-12-13 08:47:26 Test Error = 0.6778 
2016-12-13 08:47:26 Test Loss = 0.03395943606735 
2016-12-13 08:47:26 -------------------LR------------------- 
2016-12-13 08:47:26 0.00048828125 
2016-12-13 08:47:26 Epoch 260 
2016-12-13 08:56:28 Training Error = 0.67844444444444 
2016-12-13 08:56:28 Training Loss = 0.03495674314824 
2016-12-13 08:56:39 Valid Error = 0.68493698739748 
2016-12-13 08:56:39 Valid Loss = 0.033759801077368 
2016-12-13 08:57:03 Test Error = 0.6828 
2016-12-13 08:57:03 Test Loss = 0.033885178231889 
2016-12-13 08:57:03 -------------------LR------------------- 
2016-12-13 08:57:03 0.00048828125 
2016-12-13 08:57:03 Epoch 261 
2016-12-13 09:05:58 Training Error = 0.67808888888889 
2016-12-13 09:05:58 Training Loss = 0.034932114299048 
2016-12-13 09:06:10 Valid Error = 0.6755351070214 
2016-12-13 09:06:10 Valid Loss = 0.033620888251293 
2016-12-13 09:06:33 Test Error = 0.6752 
2016-12-13 09:06:33 Test Loss = 0.033735796812993 
2016-12-13 09:06:33 -------------------LR------------------- 
2016-12-13 09:06:33 0.00048828125 
2016-12-13 09:06:33 Epoch 262 
2016-12-13 09:15:31 Training Error = 0.67926666666667 
2016-12-13 09:15:31 Training Loss = 0.034953561411662 
2016-12-13 09:15:43 Valid Error = 0.68153630726145 
2016-12-13 09:15:43 Valid Loss = 0.033825508297891 
2016-12-13 09:16:07 Test Error = 0.6833 
2016-12-13 09:16:07 Test Loss = 0.033936204029496 
2016-12-13 09:16:07 -------------------LR------------------- 
2016-12-13 09:16:07 0.00048828125 
2016-12-13 09:16:07 Epoch 263 
