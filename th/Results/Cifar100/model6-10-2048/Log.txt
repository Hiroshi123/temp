2016-12-11 13:53:49 [program started on Sun Dec 11 13:53:49 2016] 
2016-12-11 13:53:49 [command line arguments] 
2016-12-11 13:53:49 stcWeights false 
2016-12-11 13:53:49 LR 0.015625 
2016-12-11 13:53:49 batchSize 64 
2016-12-11 13:53:49 network ./Models/Cifar10_Custom 
2016-12-11 13:53:49 stcNeurons true 
2016-12-11 13:53:49 constBatchSize false 
2016-12-11 13:53:49 chartFileName chart1 
2016-12-11 13:53:49 dp_prepro false 
2016-12-11 13:53:49 nGPU 1 
2016-12-11 13:53:49 dataset Cifar100 
2016-12-11 13:53:49 type cuda 
2016-12-11 13:53:49 momentum 0 
2016-12-11 13:53:49 threads 8 
2016-12-11 13:53:49 weightDecay 0 
2016-12-11 13:53:49 runningVal false 
2016-12-11 13:53:49 convLayerN 6 
2016-12-11 13:53:49 LRDecay 0 
2016-12-11 13:53:49 numHid 2048 
2016-12-11 13:53:49 save /dev/shm/clone/temp/th/Results/Cifar100/model6-10-2048 
2016-12-11 13:53:49 augment false 
2016-12-11 13:53:49 epoch -1 
2016-12-11 13:53:49 modelsFolder ./Models/ 
2016-12-11 13:53:49 format rgb 
2016-12-11 13:53:49 preProcDir /dev/shm/clone/temp/th/PreProcData/Cifar100 
2016-12-11 13:53:49 imageFileExtension svg 
2016-12-11 13:53:49 channel 1 
2016-12-11 13:53:49 devid 6 
2016-12-11 13:53:49 visualize 1 
2016-12-11 13:53:49 LRDecayPerEpoch 0.0001 
2016-12-11 13:53:49 optimization adam 
2016-12-11 13:53:49 SBN true 
2016-12-11 13:53:49 normalization simple 
2016-12-11 13:53:49 title model1 
2016-12-11 13:53:49 load  
2016-12-11 13:53:49 whiten true 
2016-12-11 13:53:49 [----------------------] 
2016-12-11 13:53:51 ==> Network 
2016-12-11 13:53:51 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 2048)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(2048 -> 2048)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(2048 -> 100)
  (38): nn.BatchNormalization
} 
2016-12-11 13:53:51 ==>25768876 Parameters 
2016-12-11 13:53:51 ==> Loss 
2016-12-11 13:53:51 SqrtHingeEmbeddingCriterion 
2016-12-11 13:53:51 
==> Starting Training
 
2016-12-11 13:53:51 Epoch 1 
2016-12-11 14:02:44 Training Error = 0.92966666666667 
2016-12-11 14:02:44 Training Loss = 0.080974110520699 
2016-12-11 14:02:56 Valid Error = 0.90698139627926 
2016-12-11 14:02:56 Valid Loss = 0.03857257532168 
2016-12-11 14:03:19 Test Error = 0.9069 
2016-12-11 14:03:19 Test Loss = 0.03859399503963 
2016-12-11 14:03:19 -------------------LR------------------- 
2016-12-11 14:03:19 0.015625 
2016-12-11 14:03:19 Epoch 2 
2016-12-11 14:11:32 Training Error = 0.89666666666667 
2016-12-11 14:11:32 Training Loss = 0.038528363267806 
2016-12-11 14:11:44 Valid Error = 0.85957191438288 
2016-12-11 14:11:44 Valid Loss = 0.038102304215457 
2016-12-11 14:12:07 Test Error = 0.8639 
2016-12-11 14:12:07 Test Loss = 0.038160572583508 
2016-12-11 14:12:07 -------------------LR------------------- 
2016-12-11 14:12:07 0.015625 
2016-12-11 14:12:07 Epoch 3 
2016-12-11 14:20:18 Training Error = 0.85528888888889 
2016-12-11 14:20:18 Training Loss = 0.037999064685269 
2016-12-11 14:20:30 Valid Error = 0.83296659331866 
2016-12-11 14:20:30 Valid Loss = 0.037692917910881 
2016-12-11 14:20:53 Test Error = 0.8319 
2016-12-11 14:20:53 Test Loss = 0.037759096910999 
2016-12-11 14:20:53 -------------------LR------------------- 
2016-12-11 14:20:53 0.015625 
2016-12-11 14:20:53 Epoch 4 
2016-12-11 14:29:02 Training Error = 0.81848888888889 
2016-12-11 14:29:02 Training Loss = 0.037497796707533 
2016-12-11 14:29:13 Valid Error = 0.78495699139828 
2016-12-11 14:29:13 Valid Loss = 0.036958891284832 
2016-12-11 14:29:37 Test Error = 0.7887 
2016-12-11 14:29:37 Test Loss = 0.037062097506918 
2016-12-11 14:29:37 -------------------LR------------------- 
2016-12-11 14:29:37 0.015625 
2016-12-11 14:29:37 Epoch 5 
2016-12-11 14:37:48 Training Error = 0.78655555555556 
2016-12-11 14:37:48 Training Loss = 0.036984686113217 
2016-12-11 14:38:00 Valid Error = 0.76835367073415 
2016-12-11 14:38:00 Valid Loss = 0.036378837976921 
2016-12-11 14:38:23 Test Error = 0.7654 
2016-12-11 14:38:23 Test Loss = 0.036427754976188 
2016-12-11 14:38:23 -------------------LR------------------- 
2016-12-11 14:38:23 0.015625 
2016-12-11 14:38:23 Epoch 6 
2016-12-11 14:46:34 Training Error = 0.75971111111111 
2016-12-11 14:46:34 Training Loss = 0.036478961242193 
2016-12-11 14:46:46 Valid Error = 0.73194638927786 
2016-12-11 14:46:46 Valid Loss = 0.035420635858884 
2016-12-11 14:47:09 Test Error = 0.7386 
2016-12-11 14:47:09 Test Loss = 0.035507810753622 
2016-12-11 14:47:09 -------------------LR------------------- 
2016-12-11 14:47:09 0.015625 
2016-12-11 14:47:09 Epoch 7 
2016-12-11 14:55:20 Training Error = 0.73622222222222 
2016-12-11 14:55:20 Training Loss = 0.036105842634358 
2016-12-11 14:55:32 Valid Error = 0.70174034806961 
2016-12-11 14:55:32 Valid Loss = 0.034740157291212 
2016-12-11 14:55:55 Test Error = 0.707 
2016-12-11 14:55:55 Test Loss = 0.034832665601354 
2016-12-11 14:55:55 -------------------LR------------------- 
2016-12-11 14:55:55 0.015625 
2016-12-11 14:55:55 Epoch 8 
2016-12-11 15:04:05 Training Error = 0.71764444444444 
2016-12-11 15:04:05 Training Loss = 0.035768579823727 
2016-12-11 15:04:17 Valid Error = 0.68473694738948 
2016-12-11 15:04:17 Valid Loss = 0.034259903543034 
2016-12-11 15:04:41 Test Error = 0.6881 
2016-12-11 15:04:41 Test Loss = 0.03439652754243 
2016-12-11 15:04:41 -------------------LR------------------- 
2016-12-11 15:04:41 0.015625 
2016-12-11 15:04:41 Epoch 9 
2016-12-11 15:12:52 Training Error = 0.70202222222222 
2016-12-11 15:12:52 Training Loss = 0.035492008931258 
2016-12-11 15:13:03 Valid Error = 0.69333866773355 
2016-12-11 15:13:03 Valid Loss = 0.034075725880497 
2016-12-11 15:13:27 Test Error = 0.6909 
2016-12-11 15:13:27 Test Loss = 0.03417949419872 
2016-12-11 15:13:27 -------------------LR------------------- 
2016-12-11 15:13:27 0.015625 
2016-12-11 15:13:27 Epoch 10 
2016-12-11 15:21:41 Training Error = 0.69073333333333 
2016-12-11 15:21:41 Training Loss = 0.035280479321426 
2016-12-11 15:21:53 Valid Error = 0.6879375875175 
2016-12-11 15:21:53 Valid Loss = 0.034058988577203 
2016-12-11 15:22:17 Test Error = 0.6926 
2016-12-11 15:22:17 Test Loss = 0.034165912904557 
2016-12-11 15:22:17 -------------------LR------------------- 
2016-12-11 15:22:17 0.015625 
2016-12-11 15:22:17 Epoch 11 
2016-12-11 15:30:25 Training Error = 0.67951111111111 
2016-12-11 15:30:25 Training Loss = 0.034956455823373 
2016-12-11 15:30:36 Valid Error = 0.68393678735747 
2016-12-11 15:30:36 Valid Loss = 0.033886629646984 
2016-12-11 15:31:00 Test Error = 0.6879 
2016-12-11 15:31:00 Test Loss = 0.033950988001125 
2016-12-11 15:31:00 -------------------LR------------------- 
2016-12-11 15:31:00 0.015625 
2016-12-11 15:31:00 Epoch 12 
2016-12-11 15:39:07 Training Error = 0.67802222222222 
2016-12-11 15:39:07 Training Loss = 0.034939873523333 
2016-12-11 15:39:18 Valid Error = 0.68153630726145 
2016-12-11 15:39:18 Valid Loss = 0.033795238330179 
2016-12-11 15:39:42 Test Error = 0.6824 
2016-12-11 15:39:42 Test Loss = 0.03389026596288 
2016-12-11 15:39:42 -------------------LR------------------- 
2016-12-11 15:39:42 0.015625 
2016-12-11 15:39:42 Epoch 13 
2016-12-11 15:47:47 Training Error = 0.67964444444444 
2016-12-11 15:47:47 Training Loss = 0.034952185963365 
2016-12-11 15:47:59 Valid Error = 0.67653530706141 
2016-12-11 15:47:59 Valid Loss = 0.03369946642767 
2016-12-11 15:48:22 Test Error = 0.6786 
2016-12-11 15:48:22 Test Loss = 0.033787227785511 
2016-12-11 15:48:22 -------------------LR------------------- 
2016-12-11 15:48:22 0.015625 
2016-12-11 15:48:22 Epoch 14 
2016-12-11 15:56:29 Training Error = 0.67808888888889 
2016-12-11 15:56:29 Training Loss = 0.034937235719778 
2016-12-11 15:56:41 Valid Error = 0.68833766753351 
2016-12-11 15:56:41 Valid Loss = 0.034142249846329 
2016-12-11 15:57:04 Test Error = 0.6944 
2016-12-11 15:57:04 Test Loss = 0.034239440252826 
2016-12-11 15:57:04 -------------------LR------------------- 
2016-12-11 15:57:04 0.015625 
2016-12-11 15:57:04 Epoch 15 
2016-12-11 16:05:11 Training Error = 0.67886666666667 
2016-12-11 16:05:11 Training Loss = 0.034936908473345 
2016-12-11 16:05:23 Valid Error = 0.68513702740548 
2016-12-11 16:05:23 Valid Loss = 0.034019785819821 
2016-12-11 16:05:46 Test Error = 0.6901 
2016-12-11 16:05:46 Test Loss = 0.03414767294173 
2016-12-11 16:05:46 -------------------LR------------------- 
2016-12-11 16:05:46 0.015625 
2016-12-11 16:05:46 Epoch 16 
2016-12-11 16:13:54 Training Error = 0.67846666666667 
2016-12-11 16:13:54 Training Loss = 0.034947560707276 
2016-12-11 16:14:06 Valid Error = 0.67093418683737 
2016-12-11 16:14:06 Valid Loss = 0.033441974745952 
2016-12-11 16:14:29 Test Error = 0.6753 
2016-12-11 16:14:29 Test Loss = 0.033522047449829 
2016-12-11 16:14:29 -------------------LR------------------- 
2016-12-11 16:14:29 0.015625 
2016-12-11 16:14:29 Epoch 17 
2016-12-11 16:22:32 Training Error = 0.67675555555556 
2016-12-11 16:22:32 Training Loss = 0.034908606200056 
2016-12-11 16:22:43 Valid Error = 0.67813562712543 
2016-12-11 16:22:43 Valid Loss = 0.033786256434042 
2016-12-11 16:23:07 Test Error = 0.6818 
2016-12-11 16:23:07 Test Loss = 0.033878945575398 
2016-12-11 16:23:07 -------------------LR------------------- 
2016-12-11 16:23:07 0.015625 
2016-12-11 16:23:07 Epoch 18 
2016-12-11 16:31:10 Training Error = 0.67811111111111 
2016-12-11 16:31:10 Training Loss = 0.034951619986783 
2016-12-11 16:31:22 Valid Error = 0.67053410682136 
2016-12-11 16:31:22 Valid Loss = 0.033594690455666 
2016-12-11 16:31:45 Test Error = 0.6722 
2016-12-11 16:31:45 Test Loss = 0.033689062124605 
2016-12-11 16:31:45 -------------------LR------------------- 
2016-12-11 16:31:45 0.015625 
2016-12-11 16:31:45 Epoch 19 
2016-12-11 16:39:50 Training Error = 0.678 
2016-12-11 16:39:50 Training Loss = 0.034957081065936 
2016-12-11 16:40:02 Valid Error = 0.68393678735747 
2016-12-11 16:40:02 Valid Loss = 0.03387246381094 
2016-12-11 16:40:25 Test Error = 0.6868 
2016-12-11 16:40:25 Test Loss = 0.0339957420993 
2016-12-11 16:40:25 -------------------LR------------------- 
2016-12-11 16:40:25 0.015625 
2016-12-11 16:40:25 Epoch 20 
2016-12-11 16:48:28 Training Error = 0.67897777777778 
2016-12-11 16:48:28 Training Loss = 0.034945368360389 
2016-12-11 16:48:40 Valid Error = 0.67573514702941 
2016-12-11 16:48:40 Valid Loss = 0.033665295875956 
2016-12-11 16:49:03 Test Error = 0.6749 
2016-12-11 16:49:03 Test Loss = 0.033783855802694 
2016-12-11 16:49:03 -------------------LR------------------- 
2016-12-11 16:49:03 0.015625 
2016-12-11 16:49:03 Epoch 21 
2016-12-11 16:57:05 Training Error = 0.68051111111111 
2016-12-11 16:57:05 Training Loss = 0.034972107281739 
2016-12-11 16:57:16 Valid Error = 0.67413482696539 
2016-12-11 16:57:16 Valid Loss = 0.033658616969641 
2016-12-11 16:57:39 Test Error = 0.6808 
2016-12-11 16:57:39 Test Loss = 0.033791389465332 
2016-12-11 16:57:39 -------------------LR------------------- 
2016-12-11 16:57:39 0.015625 
2016-12-11 16:57:40 Epoch 22 
2016-12-11 17:05:39 Training Error = 0.67824444444444 
2016-12-11 17:05:39 Training Loss = 0.034926120306958 
2016-12-11 17:05:50 Valid Error = 0.67993598719744 
2016-12-11 17:05:50 Valid Loss = 0.033729304801706 
2016-12-11 17:06:14 Test Error = 0.6793 
2016-12-11 17:06:14 Test Loss = 0.033836636497716 
2016-12-11 17:06:14 -------------------LR------------------- 
2016-12-11 17:06:14 0.015625 
2016-12-11 17:06:14 Epoch 23 
2016-12-11 17:14:12 Training Error = 0.67948888888889 
2016-12-11 17:14:12 Training Loss = 0.034948424029757 
2016-12-11 17:14:23 Valid Error = 0.6745349069814 
2016-12-11 17:14:23 Valid Loss = 0.033711352947608 
2016-12-11 17:14:47 Test Error = 0.6753 
2016-12-11 17:14:47 Test Loss = 0.033792257263402 
2016-12-11 17:14:47 -------------------LR------------------- 
2016-12-11 17:14:47 0.015625 
2016-12-11 17:14:47 Epoch 24 
2016-12-11 17:22:47 Training Error = 0.67715555555556 
2016-12-11 17:22:47 Training Loss = 0.034937407499687 
2016-12-11 17:22:58 Valid Error = 0.68853770754151 
2016-12-11 17:22:58 Valid Loss = 0.033952070243967 
2016-12-11 17:23:22 Test Error = 0.6852 
2016-12-11 17:23:22 Test Loss = 0.034053347384094 
2016-12-11 17:23:22 -------------------LR------------------- 
2016-12-11 17:23:22 0.015625 
2016-12-11 17:23:22 Epoch 25 
2016-12-11 17:31:20 Training Error = 0.67797777777778 
2016-12-11 17:31:20 Training Loss = 0.034948856681585 
2016-12-11 17:31:31 Valid Error = 0.68293658731746 
2016-12-11 17:31:31 Valid Loss = 0.033940308477736 
2016-12-11 17:31:55 Test Error = 0.684 
2016-12-11 17:31:55 Test Loss = 0.034078637870254 
2016-12-11 17:31:55 -------------------LR------------------- 
2016-12-11 17:31:55 0.015625 
2016-12-11 17:31:55 Epoch 26 
2016-12-11 17:39:57 Training Error = 0.6808 
2016-12-11 17:39:57 Training Loss = 0.034960646554828 
2016-12-11 17:40:09 Valid Error = 0.67973594718944 
2016-12-11 17:40:09 Valid Loss = 0.033720189171286 
2016-12-11 17:40:32 Test Error = 0.6771 
2016-12-11 17:40:32 Test Loss = 0.033832808345746 
2016-12-11 17:40:32 -------------------LR------------------- 
2016-12-11 17:40:32 0.015625 
2016-12-11 17:40:32 Epoch 27 
2016-12-11 17:48:30 Training Error = 0.68002222222222 
2016-12-11 17:48:30 Training Loss = 0.034958134019239 
2016-12-11 17:48:42 Valid Error = 0.67133426685337 
2016-12-11 17:48:42 Valid Loss = 0.033625339629637 
2016-12-11 17:49:05 Test Error = 0.6768 
2016-12-11 17:49:05 Test Loss = 0.033718543690481 
2016-12-11 17:49:05 -------------------LR------------------- 
2016-12-11 17:49:05 0.015625 
2016-12-11 17:49:05 Epoch 28 
2016-12-11 17:57:08 Training Error = 0.679 
2016-12-11 17:57:08 Training Loss = 0.034942619936033 
2016-12-11 17:57:20 Valid Error = 0.67253450690138 
2016-12-11 17:57:20 Valid Loss = 0.033556120115422 
2016-12-11 17:57:43 Test Error = 0.6715 
2016-12-11 17:57:43 Test Loss = 0.033659874238786 
2016-12-11 17:57:43 -------------------LR------------------- 
2016-12-11 17:57:43 0.015625 
2016-12-11 17:57:43 Epoch 29 
2016-12-11 18:05:45 Training Error = 0.67791111111111 
2016-12-11 18:05:45 Training Loss = 0.03494539632716 
2016-12-11 18:05:57 Valid Error = 0.6745349069814 
2016-12-11 18:05:57 Valid Loss = 0.033525127200494 
2016-12-11 18:06:21 Test Error = 0.6718 
2016-12-11 18:06:21 Test Loss = 0.033618357242293 
2016-12-11 18:06:21 -------------------LR------------------- 
2016-12-11 18:06:21 0.015625 
2016-12-11 18:06:21 Epoch 30 
2016-12-11 18:14:23 Training Error = 0.67822222222222 
2016-12-11 18:14:23 Training Loss = 0.034934391836551 
2016-12-11 18:14:34 Valid Error = 0.67893578715743 
2016-12-11 18:14:34 Valid Loss = 0.033854556105236 
2016-12-11 18:14:57 Test Error = 0.6865 
2016-12-11 18:14:57 Test Loss = 0.033976691589234 
2016-12-11 18:14:57 -------------------LR------------------- 
2016-12-11 18:14:57 0.015625 
2016-12-11 18:14:58 Epoch 31 
2016-12-11 18:23:01 Training Error = 0.67653333333333 
2016-12-11 18:23:01 Training Loss = 0.034935741373761 
2016-12-11 18:23:13 Valid Error = 0.69053810762152 
2016-12-11 18:23:13 Valid Loss = 0.033879856908084 
2016-12-11 18:23:36 Test Error = 0.6931 
2016-12-11 18:23:36 Test Loss = 0.033991729803146 
2016-12-11 18:23:36 -------------------LR------------------- 
2016-12-11 18:23:36 0.015625 
2016-12-11 18:23:36 Epoch 32 
2016-12-11 18:31:38 Training Error = 0.67833333333333 
2016-12-11 18:31:38 Training Loss = 0.034942815632305 
2016-12-11 18:31:49 Valid Error = 0.68153630726145 
2016-12-11 18:31:49 Valid Loss = 0.03384133890352 
2016-12-11 18:32:13 Test Error = 0.6817 
2016-12-11 18:32:13 Test Loss = 0.0339315640243 
2016-12-11 18:32:13 -------------------LR------------------- 
2016-12-11 18:32:13 0.015625 
2016-12-11 18:32:13 Epoch 33 
2016-12-11 18:40:23 Training Error = 0.67711111111111 
2016-12-11 18:40:23 Training Loss = 0.034944887239147 
2016-12-11 18:40:35 Valid Error = 0.68273654730946 
2016-12-11 18:40:35 Valid Loss = 0.03391475790448 
2016-12-11 18:40:58 Test Error = 0.6807 
2016-12-11 18:40:58 Test Loss = 0.033999765238185 
2016-12-11 18:40:58 -------------------LR------------------- 
2016-12-11 18:40:58 0.015625 
2016-12-11 18:40:58 Epoch 34 
2016-12-11 18:49:05 Training Error = 0.67924444444444 
2016-12-11 18:49:05 Training Loss = 0.034941885437478 
2016-12-11 18:49:17 Valid Error = 0.67393478695739 
2016-12-11 18:49:17 Valid Loss = 0.033681045113162 
2016-12-11 18:49:40 Test Error = 0.6792 
2016-12-11 18:49:40 Test Loss = 0.033799434482672 
2016-12-11 18:49:40 -------------------LR------------------- 
2016-12-11 18:49:40 0.015625 
2016-12-11 18:49:40 Epoch 35 
2016-12-11 18:57:47 Training Error = 0.68035555555556 
2016-12-11 18:57:47 Training Loss = 0.034952164556492 
2016-12-11 18:57:59 Valid Error = 0.69053810762152 
2016-12-11 18:57:59 Valid Loss = 0.034028695241883 
2016-12-11 18:58:22 Test Error = 0.6894 
2016-12-11 18:58:22 Test Loss = 0.034096302196478 
2016-12-11 18:58:22 -------------------LR------------------- 
2016-12-11 18:58:22 0.015625 
2016-12-11 18:58:22 Epoch 36 
2016-12-11 19:06:27 Training Error = 0.67891111111111 
2016-12-11 19:06:27 Training Loss = 0.034958605776456 
2016-12-11 19:06:38 Valid Error = 0.67673534706941 
2016-12-11 19:06:38 Valid Loss = 0.033684629924043 
2016-12-11 19:07:02 Test Error = 0.6796 
2016-12-11 19:07:02 Test Loss = 0.033802387851059 
2016-12-11 19:07:02 -------------------LR------------------- 
2016-12-11 19:07:02 0.015625 
2016-12-11 19:07:02 Epoch 37 
2016-12-11 19:15:06 Training Error = 0.67828888888889 
2016-12-11 19:15:06 Training Loss = 0.034937473024157 
2016-12-11 19:15:18 Valid Error = 0.68493698739748 
2016-12-11 19:15:18 Valid Loss = 0.033778191828598 
2016-12-11 19:15:41 Test Error = 0.6856 
2016-12-11 19:15:41 Test Loss = 0.033891777961877 
2016-12-11 19:15:41 -------------------LR------------------- 
2016-12-11 19:15:41 0.015625 
2016-12-11 19:15:41 Epoch 38 
2016-12-11 19:23:46 Training Error = 0.67775555555556 
2016-12-11 19:23:46 Training Loss = 0.034954012581571 
2016-12-11 19:23:57 Valid Error = 0.67353470694139 
2016-12-11 19:23:57 Valid Loss = 0.033512137694988 
2016-12-11 19:24:21 Test Error = 0.6745 
2016-12-11 19:24:21 Test Loss = 0.033608287565268 
2016-12-11 19:24:21 -------------------LR------------------- 
2016-12-11 19:24:21 0.015625 
2016-12-11 19:24:21 Epoch 39 
2016-12-11 19:32:23 Training Error = 0.67877777777778 
2016-12-11 19:32:23 Training Loss = 0.034947033324702 
2016-12-11 19:32:34 Valid Error = 0.66633326665333 
2016-12-11 19:32:34 Valid Loss = 0.033526894606475 
2016-12-11 19:32:58 Test Error = 0.6715 
2016-12-11 19:32:58 Test Loss = 0.033615953618554 
2016-12-11 19:32:58 -------------------LR------------------- 
2016-12-11 19:32:58 0.015625 
2016-12-11 19:32:58 Epoch 40 
2016-12-11 19:41:02 Training Error = 0.67784444444444 
2016-12-11 19:41:02 Training Loss = 0.034938448064707 
2016-12-11 19:41:13 Valid Error = 0.6877375475095 
2016-12-11 19:41:13 Valid Loss = 0.034020731957868 
2016-12-11 19:41:37 Test Error = 0.6874 
2016-12-11 19:41:37 Test Loss = 0.034089356167301 
2016-12-11 19:41:37 -------------------LR------------------- 
2016-12-11 19:41:37 0.015625 
2016-12-11 19:41:37 Epoch 41 
2016-12-11 19:49:41 Training Error = 0.67595555555556 
2016-12-11 19:49:41 Training Loss = 0.034932532252913 
2016-12-11 19:49:52 Valid Error = 0.6751350270054 
2016-12-11 19:49:52 Valid Loss = 0.033670935346248 
2016-12-11 19:50:16 Test Error = 0.6782 
2016-12-11 19:50:16 Test Loss = 0.033797401136653 
2016-12-11 19:50:16 -------------------LR------------------- 
2016-12-11 19:50:16 0.015625 
2016-12-11 19:50:16 Epoch 42 
2016-12-11 19:58:12 Training Error = 0.67817777777778 
2016-12-11 19:58:12 Training Loss = 0.034952149892395 
2016-12-11 19:58:24 Valid Error = 0.68213642728546 
2016-12-11 19:58:24 Valid Loss = 0.033906147743004 
2016-12-11 19:58:47 Test Error = 0.6846 
2016-12-11 19:58:47 Test Loss = 0.033985106747621 
2016-12-11 19:58:47 -------------------LR------------------- 
2016-12-11 19:58:47 0.015625 
2016-12-11 19:58:47 Epoch 43 
2016-12-11 20:06:44 Training Error = 0.67766666666667 
2016-12-11 20:06:44 Training Loss = 0.034941926686601 
2016-12-11 20:06:56 Valid Error = 0.66913382676535 
2016-12-11 20:06:56 Valid Loss = 0.033559424079564 
2016-12-11 20:07:19 Test Error = 0.6737 
2016-12-11 20:07:19 Test Loss = 0.033675765049685 
2016-12-11 20:07:19 -------------------LR------------------- 
2016-12-11 20:07:19 0.015625 
2016-12-11 20:07:19 Epoch 44 
2016-12-11 20:15:20 Training Error = 0.67864444444444 
2016-12-11 20:15:20 Training Loss = 0.034950627582994 
2016-12-11 20:15:31 Valid Error = 0.68613722744549 
2016-12-11 20:15:31 Valid Loss = 0.033889721836794 
2016-12-11 20:15:55 Test Error = 0.6822 
2016-12-11 20:15:55 Test Loss = 0.033992588580794 
2016-12-11 20:15:55 -------------------LR------------------- 
2016-12-11 20:15:55 0.015625 
2016-12-11 20:15:55 Epoch 45 
2016-12-11 20:23:54 Training Error = 0.67993333333333 
2016-12-11 20:23:54 Training Loss = 0.034941996894777 
2016-12-11 20:24:06 Valid Error = 0.68133626725345 
2016-12-11 20:24:06 Valid Loss = 0.033862801645807 
2016-12-11 20:24:29 Test Error = 0.6857 
2016-12-11 20:24:29 Test Loss = 0.033968121063937 
2016-12-11 20:24:29 -------------------LR------------------- 
2016-12-11 20:24:29 0.015625 
2016-12-11 20:24:29 Epoch 46 
2016-12-11 20:32:34 Training Error = 0.67724444444444 
2016-12-11 20:32:34 Training Loss = 0.034941954412921 
2016-12-11 20:32:45 Valid Error = 0.6747349469894 
2016-12-11 20:32:45 Valid Loss = 0.033654939404017 
2016-12-11 20:33:09 Test Error = 0.676 
2016-12-11 20:33:09 Test Loss = 0.033741469292124 
2016-12-11 20:33:09 -------------------LR------------------- 
2016-12-11 20:33:09 0.015625 
2016-12-11 20:33:09 Epoch 47 
2016-12-11 20:41:10 Training Error = 0.67657777777778 
2016-12-11 20:41:10 Training Loss = 0.034951246160675 
2016-12-11 20:41:21 Valid Error = 0.66953390678136 
2016-12-11 20:41:21 Valid Loss = 0.033647677846671 
2016-12-11 20:41:45 Test Error = 0.6697 
2016-12-11 20:41:45 Test Loss = 0.033749216012894 
2016-12-11 20:41:45 -------------------LR------------------- 
2016-12-11 20:41:45 0.015625 
2016-12-11 20:41:45 Epoch 48 
2016-12-11 20:49:47 Training Error = 0.67964444444444 
2016-12-11 20:49:47 Training Loss = 0.03493967526677 
2016-12-11 20:49:58 Valid Error = 0.68953790758152 
2016-12-11 20:49:58 Valid Loss = 0.033993393542754 
2016-12-11 20:50:22 Test Error = 0.6893 
2016-12-11 20:50:22 Test Loss = 0.034087854008766 
2016-12-11 20:50:22 -------------------LR------------------- 
2016-12-11 20:50:22 0.015625 
2016-12-11 20:50:22 Epoch 49 
2016-12-11 20:58:23 Training Error = 0.67631111111111 
2016-12-11 20:58:23 Training Loss = 0.034949774715033 
2016-12-11 20:58:35 Valid Error = 0.68033606721344 
2016-12-11 20:58:35 Valid Loss = 0.033818172300487 
2016-12-11 20:58:58 Test Error = 0.6821 
2016-12-11 20:58:58 Test Loss = 0.033920941762863 
2016-12-11 20:58:58 -------------------LR------------------- 
2016-12-11 20:58:58 0.015625 
2016-12-11 20:58:58 Epoch 50 
2016-12-11 21:07:00 Training Error = 0.67924444444444 
2016-12-11 21:07:00 Training Loss = 0.03494864682921 
2016-12-11 21:07:11 Valid Error = 0.68553710742148 
2016-12-11 21:07:11 Valid Loss = 0.033757448778446 
2016-12-11 21:07:35 Test Error = 0.6846 
2016-12-11 21:07:35 Test Loss = 0.033885284517981 
2016-12-11 21:07:35 -------------------LR------------------- 
2016-12-11 21:07:35 0.0078125 
2016-12-11 21:07:35 Epoch 51 
2016-12-11 21:15:38 Training Error = 0.67951111111111 
2016-12-11 21:15:38 Training Loss = 0.034962108975107 
2016-12-11 21:15:50 Valid Error = 0.68313662732547 
2016-12-11 21:15:50 Valid Loss = 0.033843300825433 
2016-12-11 21:16:13 Test Error = 0.6834 
2016-12-11 21:16:13 Test Loss = 0.033958997650511 
2016-12-11 21:16:13 -------------------LR------------------- 
2016-12-11 21:16:13 0.0078125 
2016-12-11 21:16:13 Epoch 52 
2016-12-11 21:24:10 Training Error = 0.67964444444444 
2016-12-11 21:24:10 Training Loss = 0.034961340691556 
2016-12-11 21:24:22 Valid Error = 0.68853770754151 
2016-12-11 21:24:22 Valid Loss = 0.03383082567891 
2016-12-11 21:24:45 Test Error = 0.6863 
2016-12-11 21:24:45 Test Loss = 0.033917981317848 
2016-12-11 21:24:45 -------------------LR------------------- 
2016-12-11 21:24:45 0.0078125 
2016-12-11 21:24:45 Epoch 53 
2016-12-11 21:32:47 Training Error = 0.68073333333333 
2016-12-11 21:32:47 Training Loss = 0.034963149042292 
2016-12-11 21:32:58 Valid Error = 0.67693538707742 
2016-12-11 21:32:58 Valid Loss = 0.033612689178632 
2016-12-11 21:33:22 Test Error = 0.673 
2016-12-11 21:33:22 Test Loss = 0.033688212109219 
2016-12-11 21:33:22 -------------------LR------------------- 
2016-12-11 21:33:22 0.0078125 
2016-12-11 21:33:22 Epoch 54 
2016-12-11 21:41:23 Training Error = 0.67795555555556 
2016-12-11 21:41:23 Training Loss = 0.034950204430656 
2016-12-11 21:41:34 Valid Error = 0.68253650730146 
2016-12-11 21:41:34 Valid Loss = 0.033768318315958 
2016-12-11 21:41:58 Test Error = 0.6805 
2016-12-11 21:41:58 Test Loss = 0.033895581239348 
2016-12-11 21:41:58 -------------------LR------------------- 
2016-12-11 21:41:58 0.0078125 
2016-12-11 21:41:58 Epoch 55 
2016-12-11 21:49:58 Training Error = 0.67842222222222 
2016-12-11 21:49:58 Training Loss = 0.034943186166612 
2016-12-11 21:50:10 Valid Error = 0.68053610722144 
2016-12-11 21:50:10 Valid Loss = 0.033849521989633 
2016-12-11 21:50:33 Test Error = 0.6843 
2016-12-11 21:50:33 Test Loss = 0.033969735172903 
2016-12-11 21:50:33 -------------------LR------------------- 
2016-12-11 21:50:33 0.0078125 
2016-12-11 21:50:33 Epoch 56 
2016-12-11 21:58:36 Training Error = 0.67815555555556 
2016-12-11 21:58:36 Training Loss = 0.034961828992448 
2016-12-11 21:58:48 Valid Error = 0.6753350670134 
2016-12-11 21:58:48 Valid Loss = 0.033538827792645 
2016-12-11 21:59:11 Test Error = 0.6717 
2016-12-11 21:59:11 Test Loss = 0.033661313831427 
2016-12-11 21:59:11 -------------------LR------------------- 
2016-12-11 21:59:11 0.0078125 
2016-12-11 21:59:11 Epoch 57 
2016-12-11 22:07:14 Training Error = 0.67873333333333 
2016-12-11 22:07:14 Training Loss = 0.034952115907588 
2016-12-11 22:07:26 Valid Error = 0.67433486697339 
2016-12-11 22:07:26 Valid Loss = 0.033654670517009 
2016-12-11 22:07:49 Test Error = 0.6736 
2016-12-11 22:07:49 Test Loss = 0.033756458258173 
2016-12-11 22:07:49 -------------------LR------------------- 
2016-12-11 22:07:49 0.0078125 
2016-12-11 22:07:49 Epoch 58 
2016-12-11 22:15:53 Training Error = 0.68053333333333 
2016-12-11 22:15:53 Training Loss = 0.034944611814889 
2016-12-11 22:16:04 Valid Error = 0.67993598719744 
2016-12-11 22:16:04 Valid Loss = 0.033733790170866 
2016-12-11 22:16:28 Test Error = 0.6798 
2016-12-11 22:16:28 Test Loss = 0.033837809972702 
2016-12-11 22:16:28 -------------------LR------------------- 
2016-12-11 22:16:28 0.0078125 
2016-12-11 22:16:28 Epoch 59 
2016-12-11 22:24:25 Training Error = 0.6782 
2016-12-11 22:24:25 Training Loss = 0.034939274676144 
2016-12-11 22:24:37 Valid Error = 0.68013602720544 
2016-12-11 22:24:37 Valid Loss = 0.033651236819531 
2016-12-11 22:25:00 Test Error = 0.6778 
2016-12-11 22:25:00 Test Loss = 0.033759233222646 
2016-12-11 22:25:00 -------------------LR------------------- 
2016-12-11 22:25:00 0.0078125 
2016-12-11 22:25:00 Epoch 60 
2016-12-11 22:33:01 Training Error = 0.6776 
2016-12-11 22:33:01 Training Loss = 0.034947275014764 
2016-12-11 22:33:13 Valid Error = 0.68573714742949 
2016-12-11 22:33:13 Valid Loss = 0.033968367464504 
2016-12-11 22:33:36 Test Error = 0.6873 
2016-12-11 22:33:36 Test Loss = 0.034115276032952 
2016-12-11 22:33:36 -------------------LR------------------- 
2016-12-11 22:33:36 0.0078125 
2016-12-11 22:33:36 Epoch 61 
2016-12-11 22:41:41 Training Error = 0.67906666666667 
2016-12-11 22:41:41 Training Loss = 0.034956562972882 
2016-12-11 22:41:52 Valid Error = 0.66853370674135 
2016-12-11 22:41:52 Valid Loss = 0.033577730349563 
2016-12-11 22:42:16 Test Error = 0.6689 
2016-12-11 22:42:16 Test Loss = 0.033638905157709 
2016-12-11 22:42:16 -------------------LR------------------- 
2016-12-11 22:42:16 0.0078125 
2016-12-11 22:42:16 Epoch 62 
2016-12-11 22:50:19 Training Error = 0.67871111111111 
2016-12-11 22:50:19 Training Loss = 0.034962347075343 
2016-12-11 22:50:31 Valid Error = 0.67913582716543 
2016-12-11 22:50:31 Valid Loss = 0.033689836451201 
2016-12-11 22:50:54 Test Error = 0.6824 
2016-12-11 22:50:54 Test Loss = 0.033790739706367 
2016-12-11 22:50:54 -------------------LR------------------- 
2016-12-11 22:50:54 0.0078125 
2016-12-11 22:50:54 Epoch 63 
2016-12-11 22:58:58 Training Error = 0.67742222222222 
2016-12-11 22:58:58 Training Loss = 0.034933506280861 
2016-12-11 22:59:09 Valid Error = 0.67893578715743 
2016-12-11 22:59:09 Valid Loss = 0.033759143201611 
2016-12-11 22:59:33 Test Error = 0.6752 
2016-12-11 22:59:33 Test Loss = 0.033861535020695 
2016-12-11 22:59:33 -------------------LR------------------- 
2016-12-11 22:59:33 0.0078125 
2016-12-11 22:59:33 Epoch 64 
2016-12-11 23:07:36 Training Error = 0.67713333333333 
2016-12-11 23:07:36 Training Loss = 0.034941807365553 
2016-12-11 23:07:47 Valid Error = 0.68253650730146 
2016-12-11 23:07:47 Valid Loss = 0.033759493107822 
2016-12-11 23:08:11 Test Error = 0.6842 
2016-12-11 23:08:11 Test Loss = 0.033858948057624 
2016-12-11 23:08:11 -------------------LR------------------- 
2016-12-11 23:08:11 0.0078125 
2016-12-11 23:08:11 Epoch 65 
2016-12-11 23:16:15 Training Error = 0.67884444444444 
2016-12-11 23:16:15 Training Loss = 0.03495247467675 
2016-12-11 23:16:26 Valid Error = 0.67633526705341 
2016-12-11 23:16:26 Valid Loss = 0.033683426030937 
2016-12-11 23:16:50 Test Error = 0.678 
2016-12-11 23:16:50 Test Loss = 0.033778676607047 
2016-12-11 23:16:50 -------------------LR------------------- 
2016-12-11 23:16:50 0.0078125 
2016-12-11 23:16:50 Epoch 66 
2016-12-11 23:24:54 Training Error = 0.67862222222222 
2016-12-11 23:24:54 Training Loss = 0.034951718900014 
2016-12-11 23:25:06 Valid Error = 0.68853770754151 
2016-12-11 23:25:06 Valid Loss = 0.03405035795398 
2016-12-11 23:25:29 Test Error = 0.6914 
2016-12-11 23:25:29 Test Loss = 0.034155835953488 
2016-12-11 23:25:29 -------------------LR------------------- 
2016-12-11 23:25:29 0.0078125 
2016-12-11 23:25:30 Epoch 67 
2016-12-11 23:35:07 Training Error = 0.67864444444444 
2016-12-11 23:35:07 Training Loss = 0.034940371526913 
2016-12-11 23:35:19 Valid Error = 0.67133426685337 
2016-12-11 23:35:19 Valid Loss = 0.033507364494676 
2016-12-11 23:35:43 Test Error = 0.6721 
2016-12-11 23:35:43 Test Loss = 0.033577690321928 
2016-12-11 23:35:43 -------------------LR------------------- 
2016-12-11 23:35:43 0.0078125 
2016-12-11 23:35:43 Epoch 68 
2016-12-11 23:46:38 Training Error = 0.6802 
2016-12-11 23:46:38 Training Loss = 0.034948435246267 
2016-12-11 23:46:49 Valid Error = 0.6747349469894 
2016-12-11 23:46:49 Valid Loss = 0.033661945913843 
2016-12-11 23:47:13 Test Error = 0.6747 
2016-12-11 23:47:13 Test Loss = 0.033741014899722 
2016-12-11 23:47:13 -------------------LR------------------- 
2016-12-11 23:47:13 0.0078125 
2016-12-11 23:47:13 Epoch 69 
2016-12-11 23:57:21 Training Error = 0.6806 
2016-12-11 23:57:21 Training Loss = 0.034969243634154 
2016-12-11 23:57:33 Valid Error = 0.67653530706141 
2016-12-11 23:57:33 Valid Loss = 0.03375973098748 
2016-12-11 23:57:57 Test Error = 0.6836 
2016-12-11 23:57:57 Test Loss = 0.033865773252621 
2016-12-11 23:57:57 -------------------LR------------------- 
2016-12-11 23:57:57 0.0078125 
2016-12-11 23:57:57 Epoch 70 
2016-12-12 00:08:00 Training Error = 0.67995555555556 
2016-12-12 00:08:00 Training Loss = 0.034958602484654 
2016-12-12 00:08:12 Valid Error = 0.67853570714143 
2016-12-12 00:08:12 Valid Loss = 0.033669790471441 
2016-12-12 00:08:35 Test Error = 0.6772 
2016-12-12 00:08:35 Test Loss = 0.033713815014833 
2016-12-12 00:08:35 -------------------LR------------------- 
2016-12-12 00:08:35 0.0078125 
2016-12-12 00:08:36 Epoch 71 
2016-12-12 00:18:41 Training Error = 0.67768888888889 
2016-12-12 00:18:41 Training Loss = 0.034952912858941 
2016-12-12 00:18:53 Valid Error = 0.67673534706941 
2016-12-12 00:18:53 Valid Loss = 0.033547052785242 
2016-12-12 00:19:16 Test Error = 0.6749 
2016-12-12 00:19:16 Test Loss = 0.033645333773012 
2016-12-12 00:19:16 -------------------LR------------------- 
2016-12-12 00:19:16 0.0078125 
2016-12-12 00:19:16 Epoch 72 
2016-12-12 00:29:14 Training Error = 0.6798 
2016-12-12 00:29:14 Training Loss = 0.034950428689745 
2016-12-12 00:29:26 Valid Error = 0.68033606721344 
2016-12-12 00:29:26 Valid Loss = 0.03390103491909 
2016-12-12 00:29:49 Test Error = 0.6818 
2016-12-12 00:29:49 Test Loss = 0.034014949783398 
2016-12-12 00:29:49 -------------------LR------------------- 
2016-12-12 00:29:49 0.0078125 
2016-12-12 00:29:49 Epoch 73 
2016-12-12 00:39:58 Training Error = 0.67955555555556 
2016-12-12 00:39:58 Training Loss = 0.034947642192922 
2016-12-12 00:40:09 Valid Error = 0.67913582716543 
2016-12-12 00:40:09 Valid Loss = 0.033809180018268 
2016-12-12 00:40:33 Test Error = 0.6876 
2016-12-12 00:40:33 Test Loss = 0.033936500245598 
2016-12-12 00:40:33 -------------------LR------------------- 
2016-12-12 00:40:33 0.0078125 
2016-12-12 00:40:33 Epoch 74 
2016-12-12 00:50:24 Training Error = 0.6786 
2016-12-12 00:50:24 Training Loss = 0.034952868511054 
2016-12-12 00:50:36 Valid Error = 0.68273654730946 
2016-12-12 00:50:36 Valid Loss = 0.033663746974352 
2016-12-12 00:50:59 Test Error = 0.6788 
2016-12-12 00:50:59 Test Loss = 0.033759972715074 
2016-12-12 00:50:59 -------------------LR------------------- 
2016-12-12 00:50:59 0.0078125 
2016-12-12 00:50:59 Epoch 75 
2016-12-12 01:01:01 Training Error = 0.67931111111111 
2016-12-12 01:01:01 Training Loss = 0.034935331104154 
2016-12-12 01:01:13 Valid Error = 0.68173634726945 
2016-12-12 01:01:13 Valid Loss = 0.033762997731593 
2016-12-12 01:01:36 Test Error = 0.6826 
2016-12-12 01:01:36 Test Loss = 0.033826646683322 
2016-12-12 01:01:36 -------------------LR------------------- 
2016-12-12 01:01:36 0.0078125 
2016-12-12 01:01:36 Epoch 76 
2016-12-12 01:11:43 Training Error = 0.67906666666667 
2016-12-12 01:11:43 Training Loss = 0.034951060570099 
2016-12-12 01:11:54 Valid Error = 0.68453690738148 
2016-12-12 01:11:54 Valid Loss = 0.033803006339461 
2016-12-12 01:12:18 Test Error = 0.684 
2016-12-12 01:12:18 Test Loss = 0.033915154493538 
2016-12-12 01:12:18 -------------------LR------------------- 
2016-12-12 01:12:18 0.0078125 
2016-12-12 01:12:18 Epoch 77 
2016-12-12 01:22:20 Training Error = 0.67797777777778 
2016-12-12 01:22:20 Training Loss = 0.034934652610259 
2016-12-12 01:22:31 Valid Error = 0.67873574714943 
2016-12-12 01:22:31 Valid Loss = 0.033758463100758 
2016-12-12 01:22:55 Test Error = 0.6802 
2016-12-12 01:22:55 Test Loss = 0.03383055574575 
2016-12-12 01:22:55 -------------------LR------------------- 
2016-12-12 01:22:55 0.0078125 
2016-12-12 01:22:55 Epoch 78 
2016-12-12 01:33:03 Training Error = 0.67835555555556 
2016-12-12 01:33:03 Training Loss = 0.034970339770344 
2016-12-12 01:33:15 Valid Error = 0.67933586717343 
2016-12-12 01:33:15 Valid Loss = 0.033673523808905 
2016-12-12 01:33:38 Test Error = 0.6798 
2016-12-12 01:33:38 Test Loss = 0.033754603224955 
2016-12-12 01:33:38 -------------------LR------------------- 
2016-12-12 01:33:38 0.0078125 
2016-12-12 01:33:38 Epoch 79 
2016-12-12 01:43:28 Training Error = 0.67791111111111 
2016-12-12 01:43:28 Training Loss = 0.034949714195999 
2016-12-12 01:43:40 Valid Error = 0.6877375475095 
2016-12-12 01:43:40 Valid Loss = 0.033918863761274 
2016-12-12 01:44:03 Test Error = 0.688 
2016-12-12 01:44:03 Test Loss = 0.034015751826535 
2016-12-12 01:44:03 -------------------LR------------------- 
2016-12-12 01:44:03 0.0078125 
2016-12-12 01:44:03 Epoch 80 
2016-12-12 01:54:20 Training Error = 0.67915555555556 
2016-12-12 01:54:20 Training Loss = 0.03495734885335 
2016-12-12 01:54:32 Valid Error = 0.67813562712543 
2016-12-12 01:54:32 Valid Loss = 0.033706688225593 
2016-12-12 01:54:55 Test Error = 0.6792 
2016-12-12 01:54:55 Test Loss = 0.033800828122789 
2016-12-12 01:54:55 -------------------LR------------------- 
2016-12-12 01:54:55 0.0078125 
2016-12-12 01:54:55 Epoch 81 
2016-12-12 02:04:55 Training Error = 0.67797777777778 
2016-12-12 02:04:55 Training Loss = 0.034945707896894 
2016-12-12 02:05:06 Valid Error = 0.67913582716543 
2016-12-12 02:05:06 Valid Loss = 0.033757979537867 
2016-12-12 02:05:30 Test Error = 0.6804 
2016-12-12 02:05:30 Test Loss = 0.033883628207407 
2016-12-12 02:05:30 -------------------LR------------------- 
2016-12-12 02:05:30 0.0078125 
2016-12-12 02:05:30 Epoch 82 
2016-12-12 02:15:25 Training Error = 0.67868888888889 
2016-12-12 02:15:25 Training Loss = 0.034933918704363 
2016-12-12 02:15:37 Valid Error = 0.67813562712543 
2016-12-12 02:15:37 Valid Loss = 0.033620452911039 
2016-12-12 02:16:01 Test Error = 0.6773 
2016-12-12 02:16:01 Test Loss = 0.033727583004411 
2016-12-12 02:16:01 -------------------LR------------------- 
2016-12-12 02:16:01 0.0078125 
2016-12-12 02:16:01 Epoch 83 
2016-12-12 02:26:05 Training Error = 0.67864444444444 
2016-12-12 02:26:05 Training Loss = 0.034955469691618 
2016-12-12 02:26:17 Valid Error = 0.68533706741348 
2016-12-12 02:26:17 Valid Loss = 0.033883096525078 
2016-12-12 02:26:41 Test Error = 0.6878 
2016-12-12 02:26:41 Test Loss = 0.033956655909301 
2016-12-12 02:26:41 -------------------LR------------------- 
2016-12-12 02:26:41 0.0078125 
2016-12-12 02:26:41 Epoch 84 
2016-12-12 02:36:35 Training Error = 0.67553333333333 
2016-12-12 02:36:35 Training Loss = 0.034940218576653 
2016-12-12 02:36:47 Valid Error = 0.67733546709342 
2016-12-12 02:36:47 Valid Loss = 0.033646694247158 
2016-12-12 02:37:11 Test Error = 0.6789 
2016-12-12 02:37:11 Test Loss = 0.033775897496825 
2016-12-12 02:37:11 -------------------LR------------------- 
2016-12-12 02:37:11 0.0078125 
2016-12-12 02:37:11 Epoch 85 
2016-12-12 02:47:24 Training Error = 0.67775555555556 
2016-12-12 02:47:24 Training Loss = 0.034958335442299 
2016-12-12 02:47:36 Valid Error = 0.68633726745349 
2016-12-12 02:47:36 Valid Loss = 0.0338267028612 
2016-12-12 02:48:00 Test Error = 0.6852 
2016-12-12 02:48:00 Test Loss = 0.033932972880685 
2016-12-12 02:48:00 -------------------LR------------------- 
2016-12-12 02:48:00 0.0078125 
2016-12-12 02:48:00 Epoch 86 
2016-12-12 02:57:49 Training Error = 0.67982222222222 
2016-12-12 02:57:49 Training Loss = 0.034964454698969 
2016-12-12 02:58:01 Valid Error = 0.68033606721344 
2016-12-12 02:58:01 Valid Loss = 0.033647627446794 
2016-12-12 02:58:25 Test Error = 0.6817 
2016-12-12 02:58:25 Test Loss = 0.033745977893756 
2016-12-12 02:58:25 -------------------LR------------------- 
2016-12-12 02:58:25 0.0078125 
2016-12-12 02:58:25 Epoch 87 
2016-12-12 03:08:25 Training Error = 0.67804444444444 
2016-12-12 03:08:25 Training Loss = 0.034956306398592 
2016-12-12 03:08:36 Valid Error = 0.68453690738148 
2016-12-12 03:08:36 Valid Loss = 0.033833777568224 
2016-12-12 03:09:00 Test Error = 0.6821 
2016-12-12 03:09:00 Test Loss = 0.033988700702692 
2016-12-12 03:09:00 -------------------LR------------------- 
2016-12-12 03:09:00 0.0078125 
2016-12-12 03:09:00 Epoch 88 
2016-12-12 03:19:02 Training Error = 0.67666666666667 
2016-12-12 03:19:02 Training Loss = 0.034937435852533 
2016-12-12 03:19:13 Valid Error = 0.67293458691738 
2016-12-12 03:19:13 Valid Loss = 0.033670058190068 
2016-12-12 03:19:37 Test Error = 0.6747 
2016-12-12 03:19:37 Test Loss = 0.033739121066537 
2016-12-12 03:19:37 -------------------LR------------------- 
2016-12-12 03:19:37 0.0078125 
2016-12-12 03:19:37 Epoch 89 
2016-12-12 03:29:34 Training Error = 0.67775555555556 
2016-12-12 03:29:34 Training Loss = 0.034937123009427 
2016-12-12 03:29:46 Valid Error = 0.67053410682136 
2016-12-12 03:29:46 Valid Loss = 0.033513771629678 
2016-12-12 03:30:10 Test Error = 0.6702 
2016-12-12 03:30:10 Test Loss = 0.033588109578297 
2016-12-12 03:30:10 -------------------LR------------------- 
2016-12-12 03:30:10 0.0078125 
2016-12-12 03:30:10 Epoch 90 
2016-12-12 03:40:17 Training Error = 0.67795555555556 
2016-12-12 03:40:17 Training Loss = 0.034941905906255 
2016-12-12 03:40:29 Valid Error = 0.66913382676535 
2016-12-12 03:40:29 Valid Loss = 0.033483881622715 
2016-12-12 03:40:53 Test Error = 0.6702 
2016-12-12 03:40:53 Test Loss = 0.033579047090688 
2016-12-12 03:40:53 -------------------LR------------------- 
2016-12-12 03:40:53 0.0078125 
2016-12-12 03:40:53 Epoch 91 
2016-12-12 03:50:43 Training Error = 0.67991111111111 
2016-12-12 03:50:43 Training Loss = 0.034968907778913 
2016-12-12 03:50:55 Valid Error = 0.6747349469894 
2016-12-12 03:50:55 Valid Loss = 0.033617865461553 
2016-12-12 03:51:19 Test Error = 0.675 
2016-12-12 03:51:19 Test Loss = 0.033736846796267 
2016-12-12 03:51:19 -------------------LR------------------- 
2016-12-12 03:51:19 0.0078125 
2016-12-12 03:51:19 Epoch 92 
2016-12-12 04:01:18 Training Error = 0.67777777777778 
2016-12-12 04:01:18 Training Loss = 0.034946101934395 
2016-12-12 04:01:29 Valid Error = 0.67753550710142 
2016-12-12 04:01:29 Valid Loss = 0.033703806521017 
2016-12-12 04:01:53 Test Error = 0.6801 
2016-12-12 04:01:53 Test Loss = 0.033835670219106 
2016-12-12 04:01:53 -------------------LR------------------- 
2016-12-12 04:01:53 0.0078125 
2016-12-12 04:01:53 Epoch 93 
2016-12-12 04:11:56 Training Error = 0.6784 
2016-12-12 04:11:56 Training Loss = 0.034957575777715 
2016-12-12 04:12:08 Valid Error = 0.67413482696539 
2016-12-12 04:12:08 Valid Loss = 0.033614445431107 
2016-12-12 04:12:31 Test Error = 0.6743 
2016-12-12 04:12:31 Test Loss = 0.033706884125995 
2016-12-12 04:12:31 -------------------LR------------------- 
2016-12-12 04:12:31 0.0078125 
2016-12-12 04:12:31 Epoch 94 
2016-12-12 04:22:30 Training Error = 0.67824444444444 
2016-12-12 04:22:30 Training Loss = 0.034943448474461 
2016-12-12 04:22:42 Valid Error = 0.67173434686937 
2016-12-12 04:22:42 Valid Loss = 0.033495044268493 
2016-12-12 04:23:06 Test Error = 0.6764 
2016-12-12 04:23:06 Test Loss = 0.033591114032041 
2016-12-12 04:23:06 -------------------LR------------------- 
2016-12-12 04:23:06 0.0078125 
2016-12-12 04:23:06 Epoch 95 
2016-12-12 04:33:15 Training Error = 0.6792 
2016-12-12 04:33:15 Training Loss = 0.034950062337924 
2016-12-12 04:33:27 Valid Error = 0.67353470694139 
2016-12-12 04:33:27 Valid Loss = 0.033606106040706 
2016-12-12 04:33:51 Test Error = 0.677 
2016-12-12 04:33:51 Test Loss = 0.033730487595698 
2016-12-12 04:33:51 -------------------LR------------------- 
2016-12-12 04:33:51 0.0078125 
2016-12-12 04:33:51 Epoch 96 
2016-12-12 04:43:43 Training Error = 0.67644444444444 
2016-12-12 04:43:43 Training Loss = 0.034941407398067 
2016-12-12 04:43:55 Valid Error = 0.68053610722144 
2016-12-12 04:43:55 Valid Loss = 0.033694819114954 
2016-12-12 04:44:18 Test Error = 0.68 
2016-12-12 04:44:18 Test Loss = 0.033782649921004 
2016-12-12 04:44:18 -------------------LR------------------- 
2016-12-12 04:44:18 0.0078125 
2016-12-12 04:44:18 Epoch 97 
2016-12-12 04:54:19 Training Error = 0.67824444444444 
2016-12-12 04:54:19 Training Loss = 0.034954898916185 
2016-12-12 04:54:30 Valid Error = 0.68393678735747 
2016-12-12 04:54:30 Valid Loss = 0.033880319435816 
2016-12-12 04:54:54 Test Error = 0.6837 
2016-12-12 04:54:54 Test Loss = 0.033983018428657 
2016-12-12 04:54:54 -------------------LR------------------- 
2016-12-12 04:54:54 0.0078125 
2016-12-12 04:54:54 Epoch 98 
2016-12-12 05:04:58 Training Error = 0.67757777777778 
2016-12-12 05:04:58 Training Loss = 0.034949731562625 
2016-12-12 05:05:09 Valid Error = 0.67253450690138 
2016-12-12 05:05:09 Valid Loss = 0.033500934483561 
2016-12-12 05:05:33 Test Error = 0.6728 
2016-12-12 05:05:33 Test Loss = 0.033581732185024 
2016-12-12 05:05:33 -------------------LR------------------- 
2016-12-12 05:05:33 0.0078125 
2016-12-12 05:05:33 Epoch 99 
2016-12-12 05:14:53 Training Error = 0.67866666666667 
2016-12-12 05:14:53 Training Loss = 0.034931599118493 
2016-12-12 05:15:05 Valid Error = 0.68073614722945 
2016-12-12 05:15:05 Valid Loss = 0.033649609364825 
2016-12-12 05:15:28 Test Error = 0.6819 
2016-12-12 05:15:28 Test Loss = 0.033798776477765 
2016-12-12 05:15:28 -------------------LR------------------- 
2016-12-12 05:15:28 0.0078125 
2016-12-12 05:15:28 Epoch 100 
2016-12-12 05:24:30 Training Error = 0.68155555555556 
2016-12-12 05:24:30 Training Loss = 0.034979385442354 
2016-12-12 05:24:42 Valid Error = 0.67953590718144 
2016-12-12 05:24:42 Valid Loss = 0.033743510690348 
2016-12-12 05:25:05 Test Error = 0.6822 
2016-12-12 05:25:05 Test Loss = 0.03384667076123 
2016-12-12 05:25:05 -------------------LR------------------- 
2016-12-12 05:25:05 0.00390625 
2016-12-12 05:25:05 Epoch 101 
2016-12-12 05:33:53 Training Error = 0.67875555555556 
2016-12-12 05:33:53 Training Loss = 0.034935631921345 
2016-12-12 05:34:04 Valid Error = 0.68053610722144 
2016-12-12 05:34:04 Valid Loss = 0.033745792205252 
2016-12-12 05:34:28 Test Error = 0.6854 
2016-12-12 05:34:28 Test Loss = 0.03385305793422 
2016-12-12 05:34:28 -------------------LR------------------- 
2016-12-12 05:34:28 0.00390625 
2016-12-12 05:34:28 Epoch 102 
2016-12-12 05:43:22 Training Error = 0.67757777777778 
2016-12-12 05:43:22 Training Loss = 0.034956458254971 
2016-12-12 05:43:33 Valid Error = 0.67313462692539 
2016-12-12 05:43:33 Valid Loss = 0.033542860412253 
2016-12-12 05:43:57 Test Error = 0.675 
2016-12-12 05:43:57 Test Loss = 0.033679643573275 
2016-12-12 05:43:57 -------------------LR------------------- 
2016-12-12 05:43:57 0.00390625 
2016-12-12 05:43:57 Epoch 103 
2016-12-12 05:52:54 Training Error = 0.67868888888889 
2016-12-12 05:52:54 Training Loss = 0.034947818121449 
2016-12-12 05:53:06 Valid Error = 0.6753350670134 
2016-12-12 05:53:06 Valid Loss = 0.033723931204777 
2016-12-12 05:53:29 Test Error = 0.6794 
2016-12-12 05:53:29 Test Loss = 0.033852640868752 
2016-12-12 05:53:29 -------------------LR------------------- 
2016-12-12 05:53:29 0.00390625 
2016-12-12 05:53:29 Epoch 104 
2016-12-12 06:02:20 Training Error = 0.67862222222222 
2016-12-12 06:02:20 Training Loss = 0.034960140463981 
2016-12-12 06:02:31 Valid Error = 0.6871374274855 
2016-12-12 06:02:31 Valid Loss = 0.033958060107654 
2016-12-12 06:02:55 Test Error = 0.6894 
2016-12-12 06:02:55 Test Loss = 0.034089607068687 
2016-12-12 06:02:55 -------------------LR------------------- 
2016-12-12 06:02:55 0.00390625 
2016-12-12 06:02:55 Epoch 105 
2016-12-12 06:11:44 Training Error = 0.67637777777778 
2016-12-12 06:11:44 Training Loss = 0.03493760982359 
2016-12-12 06:11:56 Valid Error = 0.68253650730146 
2016-12-12 06:11:56 Valid Loss = 0.033866996359868 
2016-12-12 06:12:19 Test Error = 0.6852 
2016-12-12 06:12:19 Test Loss = 0.03397272214768 
2016-12-12 06:12:19 -------------------LR------------------- 
2016-12-12 06:12:19 0.00390625 
2016-12-12 06:12:19 Epoch 106 
2016-12-12 06:21:13 Training Error = 0.67686666666667 
2016-12-12 06:21:13 Training Loss = 0.034937975457446 
2016-12-12 06:21:24 Valid Error = 0.67753550710142 
2016-12-12 06:21:24 Valid Loss = 0.03384994658596 
2016-12-12 06:21:48 Test Error = 0.6796 
2016-12-12 06:21:48 Test Loss = 0.03394448474714 
2016-12-12 06:21:48 -------------------LR------------------- 
2016-12-12 06:21:48 0.00390625 
2016-12-12 06:21:48 Epoch 107 
2016-12-12 06:30:42 Training Error = 0.67795555555556 
2016-12-12 06:30:42 Training Loss = 0.034947752739218 
2016-12-12 06:30:54 Valid Error = 0.68133626725345 
2016-12-12 06:30:54 Valid Loss = 0.03386140346096 
2016-12-12 06:31:17 Test Error = 0.6826 
2016-12-12 06:31:17 Test Loss = 0.033968161564724 
2016-12-12 06:31:17 -------------------LR------------------- 
2016-12-12 06:31:17 0.00390625 
2016-12-12 06:31:17 Epoch 108 
2016-12-12 06:40:13 Training Error = 0.679 
2016-12-12 06:40:13 Training Loss = 0.034957809990103 
2016-12-12 06:40:24 Valid Error = 0.6745349069814 
2016-12-12 06:40:24 Valid Loss = 0.033511375428108 
2016-12-12 06:40:48 Test Error = 0.6796 
2016-12-12 06:40:48 Test Loss = 0.033631985688665 
2016-12-12 06:40:48 -------------------LR------------------- 
2016-12-12 06:40:48 0.00390625 
2016-12-12 06:40:48 Epoch 109 
2016-12-12 06:49:40 Training Error = 0.6772 
2016-12-12 06:49:40 Training Loss = 0.034931880340657 
2016-12-12 06:49:52 Valid Error = 0.67733546709342 
2016-12-12 06:49:52 Valid Loss = 0.033667045299227 
2016-12-12 06:50:16 Test Error = 0.6776 
2016-12-12 06:50:16 Test Loss = 0.033782042120672 
2016-12-12 06:50:16 -------------------LR------------------- 
2016-12-12 06:50:16 0.00390625 
2016-12-12 06:50:16 Epoch 110 
2016-12-12 06:59:12 Training Error = 0.67951111111111 
2016-12-12 06:59:12 Training Loss = 0.034945729242807 
2016-12-12 06:59:23 Valid Error = 0.68073614722945 
2016-12-12 06:59:23 Valid Loss = 0.033766277849566 
2016-12-12 06:59:46 Test Error = 0.6863 
2016-12-12 06:59:46 Test Loss = 0.033863244512279 
2016-12-12 06:59:46 -------------------LR------------------- 
2016-12-12 06:59:46 0.00390625 
2016-12-12 06:59:47 Epoch 111 
2016-12-12 07:08:48 Training Error = 0.67611111111111 
2016-12-12 07:08:48 Training Loss = 0.034949577098543 
2016-12-12 07:09:00 Valid Error = 0.68193638727746 
2016-12-12 07:09:00 Valid Loss = 0.033656392886453 
2016-12-12 07:09:23 Test Error = 0.6824 
2016-12-12 07:09:23 Test Loss = 0.03378262791664 
2016-12-12 07:09:23 -------------------LR------------------- 
2016-12-12 07:09:23 0.00390625 
2016-12-12 07:09:23 Epoch 112 
2016-12-12 07:18:18 Training Error = 0.67848888888889 
2016-12-12 07:18:18 Training Loss = 0.034957514083521 
2016-12-12 07:18:29 Valid Error = 0.6875375075015 
2016-12-12 07:18:29 Valid Loss = 0.033900174723827 
2016-12-12 07:18:53 Test Error = 0.689 
2016-12-12 07:18:53 Test Loss = 0.034007021985996 
2016-12-12 07:18:53 -------------------LR------------------- 
2016-12-12 07:18:53 0.00390625 
2016-12-12 07:18:53 Epoch 113 
2016-12-12 07:27:46 Training Error = 0.67591111111111 
2016-12-12 07:27:46 Training Loss = 0.034934421262958 
2016-12-12 07:27:58 Valid Error = 0.67933586717343 
2016-12-12 07:27:58 Valid Loss = 0.033765668446505 
2016-12-12 07:28:22 Test Error = 0.6791 
2016-12-12 07:28:22 Test Loss = 0.033873145959939 
2016-12-12 07:28:22 -------------------LR------------------- 
2016-12-12 07:28:22 0.00390625 
2016-12-12 07:28:22 Epoch 114 
2016-12-12 07:37:17 Training Error = 0.67628888888889 
2016-12-12 07:37:17 Training Loss = 0.034938044846058 
2016-12-12 07:37:29 Valid Error = 0.68453690738148 
2016-12-12 07:37:29 Valid Loss = 0.033817660273954 
2016-12-12 07:37:53 Test Error = 0.6829 
2016-12-12 07:37:53 Test Loss = 0.03391900780854 
2016-12-12 07:37:53 -------------------LR------------------- 
2016-12-12 07:37:53 0.00390625 
2016-12-12 07:37:53 Epoch 115 
2016-12-12 07:46:46 Training Error = 0.6796 
2016-12-12 07:46:46 Training Loss = 0.034941639205949 
2016-12-12 07:46:58 Valid Error = 0.67273454690938 
2016-12-12 07:46:58 Valid Loss = 0.033620840347697 
2016-12-12 07:47:22 Test Error = 0.6755 
2016-12-12 07:47:22 Test Loss = 0.033723861351135 
2016-12-12 07:47:22 -------------------LR------------------- 
2016-12-12 07:47:22 0.00390625 
2016-12-12 07:47:22 Epoch 116 
2016-12-12 07:56:09 Training Error = 0.67766666666667 
2016-12-12 07:56:09 Training Loss = 0.034959373653612 
2016-12-12 07:56:21 Valid Error = 0.67973594718944 
2016-12-12 07:56:21 Valid Loss = 0.033725876433078 
2016-12-12 07:56:45 Test Error = 0.6813 
2016-12-12 07:56:45 Test Loss = 0.033844174822425 
2016-12-12 07:56:45 -------------------LR------------------- 
2016-12-12 07:56:45 0.00390625 
2016-12-12 07:56:45 Epoch 117 
2016-12-12 08:05:45 Training Error = 0.678 
2016-12-12 08:05:45 Training Loss = 0.034929036548869 
2016-12-12 08:05:57 Valid Error = 0.67993598719744 
2016-12-12 08:05:57 Valid Loss = 0.033777095060021 
2016-12-12 08:06:20 Test Error = 0.6818 
2016-12-12 08:06:20 Test Loss = 0.033918105037349 
2016-12-12 08:06:20 -------------------LR------------------- 
2016-12-12 08:06:20 0.00390625 
2016-12-12 08:06:20 Epoch 118 
2016-12-12 08:15:12 Training Error = 0.67826666666667 
2016-12-12 08:15:12 Training Loss = 0.034939376999709 
2016-12-12 08:15:23 Valid Error = 0.67433486697339 
2016-12-12 08:15:23 Valid Loss = 0.033603197661705 
2016-12-12 08:15:47 Test Error = 0.6785 
2016-12-12 08:15:47 Test Loss = 0.033700230668305 
2016-12-12 08:15:47 -------------------LR------------------- 
2016-12-12 08:15:47 0.00390625 
2016-12-12 08:15:47 Epoch 119 
2016-12-12 08:24:37 Training Error = 0.67791111111111 
2016-12-12 08:24:37 Training Loss = 0.034946169338443 
2016-12-12 08:24:49 Valid Error = 0.67093418683737 
2016-12-12 08:24:49 Valid Loss = 0.03352569529204 
2016-12-12 08:25:13 Test Error = 0.6723 
2016-12-12 08:25:13 Test Loss = 0.033643735715538 
2016-12-12 08:25:13 -------------------LR------------------- 
2016-12-12 08:25:13 0.00390625 
2016-12-12 08:25:13 Epoch 120 
2016-12-12 08:34:17 Training Error = 0.67844444444444 
2016-12-12 08:34:17 Training Loss = 0.034949528165162 
2016-12-12 08:34:29 Valid Error = 0.68253650730146 
2016-12-12 08:34:29 Valid Loss = 0.033825114506278 
2016-12-12 08:34:52 Test Error = 0.6851 
2016-12-12 08:34:52 Test Loss = 0.033908154129223 
2016-12-12 08:34:52 -------------------LR------------------- 
2016-12-12 08:34:52 0.00390625 
2016-12-12 08:34:52 Epoch 121 
2016-12-12 08:43:47 Training Error = 0.67584444444444 
2016-12-12 08:43:47 Training Loss = 0.034945839778944 
2016-12-12 08:43:59 Valid Error = 0.67393478695739 
2016-12-12 08:43:59 Valid Loss = 0.033566394710196 
2016-12-12 08:44:22 Test Error = 0.6744 
2016-12-12 08:44:22 Test Loss = 0.033641790705881 
2016-12-12 08:44:22 -------------------LR------------------- 
2016-12-12 08:44:22 0.00390625 
2016-12-12 08:44:23 Epoch 122 
2016-12-12 08:53:23 Training Error = 0.67722222222222 
2016-12-12 08:53:23 Training Loss = 0.034921805919571 
2016-12-12 08:53:34 Valid Error = 0.67893578715743 
2016-12-12 08:53:34 Valid Loss = 0.033857178528529 
2016-12-12 08:53:58 Test Error = 0.6847 
2016-12-12 08:53:58 Test Loss = 0.03398520926761 
2016-12-12 08:53:58 -------------------LR------------------- 
2016-12-12 08:53:58 0.00390625 
2016-12-12 08:53:58 Epoch 123 
2016-12-12 09:02:57 Training Error = 0.67655555555556 
2016-12-12 09:02:57 Training Loss = 0.034947768212719 
2016-12-12 09:03:08 Valid Error = 0.67433486697339 
2016-12-12 09:03:08 Valid Loss = 0.033630161298334 
2016-12-12 09:03:32 Test Error = 0.6756 
2016-12-12 09:03:32 Test Loss = 0.033699050390037 
2016-12-12 09:03:32 -------------------LR------------------- 
2016-12-12 09:03:32 0.00390625 
2016-12-12 09:03:32 Epoch 124 
2016-12-12 09:12:24 Training Error = 0.6772 
2016-12-12 09:12:24 Training Loss = 0.034947440288961 
2016-12-12 09:12:36 Valid Error = 0.67733546709342 
2016-12-12 09:12:36 Valid Loss = 0.033747013192927 
2016-12-12 09:12:59 Test Error = 0.6785 
2016-12-12 09:12:59 Test Loss = 0.033833502523459 
2016-12-12 09:12:59 -------------------LR------------------- 
2016-12-12 09:12:59 0.00390625 
2016-12-12 09:12:59 Epoch 125 
2016-12-12 09:22:03 Training Error = 0.68084444444444 
2016-12-12 09:22:03 Training Loss = 0.034958160919222 
2016-12-12 09:22:14 Valid Error = 0.67833566713343 
2016-12-12 09:22:14 Valid Loss = 0.033753763232481 
2016-12-12 09:22:38 Test Error = 0.6793 
2016-12-12 09:22:38 Test Loss = 0.033838245033459 
2016-12-12 09:22:38 -------------------LR------------------- 
2016-12-12 09:22:38 0.00390625 
2016-12-12 09:22:38 Epoch 126 
2016-12-12 09:31:28 Training Error = 0.67902222222222 
2016-12-12 09:31:28 Training Loss = 0.034951834008098 
2016-12-12 09:31:40 Valid Error = 0.67973594718944 
2016-12-12 09:31:40 Valid Loss = 0.033649970454721 
2016-12-12 09:32:03 Test Error = 0.6751 
2016-12-12 09:32:03 Test Loss = 0.033749257485578 
2016-12-12 09:32:03 -------------------LR------------------- 
2016-12-12 09:32:03 0.00390625 
2016-12-12 09:32:04 Epoch 127 
2016-12-12 09:40:54 Training Error = 0.67975555555556 
2016-12-12 09:40:54 Training Loss = 0.03495189380578 
2016-12-12 09:41:05 Valid Error = 0.66953390678136 
2016-12-12 09:41:05 Valid Loss = 0.033535625447416 
2016-12-12 09:41:29 Test Error = 0.6755 
2016-12-12 09:41:29 Test Loss = 0.033625575235695 
2016-12-12 09:41:29 -------------------LR------------------- 
2016-12-12 09:41:29 0.00390625 
2016-12-12 09:41:29 Epoch 128 
2016-12-12 09:50:28 Training Error = 0.6802 
2016-12-12 09:50:28 Training Loss = 0.034948765930127 
2016-12-12 09:50:40 Valid Error = 0.68133626725345 
2016-12-12 09:50:40 Valid Loss = 0.033778938048571 
2016-12-12 09:51:03 Test Error = 0.6831 
2016-12-12 09:51:03 Test Loss = 0.033876030414727 
2016-12-12 09:51:03 -------------------LR------------------- 
2016-12-12 09:51:03 0.00390625 
2016-12-12 09:51:04 Epoch 129 
