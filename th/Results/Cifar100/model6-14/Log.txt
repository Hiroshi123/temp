2016-12-10 16:44:33 [program started on Sat Dec 10 16:44:33 2016] 
2016-12-10 16:44:33 [command line arguments] 
2016-12-10 16:44:33 stcWeights false 
2016-12-10 16:44:33 LR 0.015625 
2016-12-10 16:44:33 batchSize 600 
2016-12-10 16:44:33 network ./Models/Cifar10_Custom 
2016-12-10 16:44:33 stcNeurons true 
2016-12-10 16:44:33 constBatchSize false 
2016-12-10 16:44:33 chartFileName chart1 
2016-12-10 16:44:33 dp_prepro false 
2016-12-10 16:44:33 nGPU 4 
2016-12-10 16:44:33 dataset Cifar100 
2016-12-10 16:44:33 type cuda 
2016-12-10 16:44:33 momentum 0 
2016-12-10 16:44:33 threads 8 
2016-12-10 16:44:33 weightDecay 0 
2016-12-10 16:44:33 runningVal false 
2016-12-10 16:44:33 convLayerN 6 
2016-12-10 16:44:33 LRDecay 0 
2016-12-10 16:44:33 numHid 1024 
2016-12-10 16:44:33 save /dev/shm/clone/temp/th/Results/Cifar100/model6-14 
2016-12-10 16:44:33 augment false 
2016-12-10 16:44:33 epoch -1 
2016-12-10 16:44:33 modelsFolder ./Models/ 
2016-12-10 16:44:33 format rgb 
2016-12-10 16:44:33 preProcDir /dev/shm/clone/temp/th/PreProcData/Cifar100 
2016-12-10 16:44:33 imageFileExtension svg 
2016-12-10 16:44:33 channel 1.4 
2016-12-10 16:44:33 devid 7 
2016-12-10 16:44:33 visualize 1 
2016-12-10 16:44:33 LRDecayPerEpoch 0.0001 
2016-12-10 16:44:33 optimization adam 
2016-12-10 16:44:33 SBN true 
2016-12-10 16:44:33 normalization simple 
2016-12-10 16:44:33 title model1 
2016-12-10 16:44:33 load  
2016-12-10 16:44:33 whiten true 
2016-12-10 16:44:33 [----------------------] 
2016-12-10 16:44:41 ==> Network 
2016-12-10 16:44:41 DataParallelTable: 4 x nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 179, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(179 -> 179, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(179 -> 358, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(358 -> 358, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(358 -> 716, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(716 -> 716, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(11456)
  (29): BinaryLinear(11456 -> 1024)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(1024 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 100)
  (38): nn.BatchNormalization
} 
2016-12-10 16:44:41 ==>21840154 Parameters 
2016-12-10 16:44:41 ==> Loss 
2016-12-10 16:44:41 SqrtHingeEmbeddingCriterion 
2016-12-10 16:44:41 
==> Starting Training
 
2016-12-10 16:44:41 Epoch 1 
2016-12-10 16:48:48 Training Error = 0.93537777777778 
2016-12-10 16:48:48 Training Loss = 0.40707866493056 
2016-12-10 16:48:53 Valid Error = 0.92898579715943 
2016-12-10 16:48:53 Valid Loss = 0.078036950540463 
2016-12-10 16:49:19 Test Error = 0.9307 
2016-12-10 16:49:19 Test Loss = 0.078234836234298 
2016-12-10 16:49:19 -------------------LR------------------- 
2016-12-10 16:49:19 0.015625 
2016-12-10 16:49:19 Epoch 2 
2016-12-10 16:54:17 Training Error = 0.91711111111111 
2016-12-10 16:54:17 Training Loss = 0.047579485568576 
2016-12-10 16:54:22 Valid Error = 0.91078215643129 
2016-12-10 16:54:22 Valid Loss = 0.041742894630851 
2016-12-10 16:54:39 Test Error = 0.9168 
2016-12-10 16:54:39 Test Loss = 0.041663108137542 
2016-12-10 16:54:39 -------------------LR------------------- 
2016-12-10 16:54:39 0.015625 
2016-12-10 16:54:39 Epoch 3 
2016-12-10 16:59:48 Training Error = 0.89444444444444 
2016-12-10 16:59:48 Training Loss = 0.039021418185764 
2016-12-10 16:59:53 Valid Error = 0.89817963592719 
2016-12-10 16:59:53 Valid Loss = 0.040365088449518 
2016-12-10 17:00:18 Test Error = 0.8989 
2016-12-10 17:00:18 Test Loss = 0.040322567749023 
2016-12-10 17:00:18 -------------------LR------------------- 
2016-12-10 17:00:18 0.015625 
2016-12-10 17:00:18 Epoch 4 
2016-12-10 17:05:27 Training Error = 0.85968888888889 
2016-12-10 17:05:27 Training Loss = 0.03823940234375 
2016-12-10 17:05:32 Valid Error = 0.87697539507902 
2016-12-10 17:05:32 Valid Loss = 0.039128514888898 
2016-12-10 17:05:59 Test Error = 0.871 
2016-12-10 17:05:59 Test Loss = 0.039108781822055 
2016-12-10 17:05:59 -------------------LR------------------- 
2016-12-10 17:05:59 0.015625 
2016-12-10 17:05:59 Epoch 5 
2016-12-10 17:10:58 Training Error = 0.82713333333333 
2016-12-10 17:10:58 Training Loss = 0.037646855848524 
2016-12-10 17:11:03 Valid Error = 0.85137027405481 
2016-12-10 17:11:03 Valid Loss = 0.038664492565548 
2016-12-10 17:11:21 Test Error = 0.841 
2016-12-10 17:11:21 Test Loss = 0.038624532183479 
2016-12-10 17:11:21 -------------------LR------------------- 
2016-12-10 17:11:21 0.015625 
2016-12-10 17:11:21 Epoch 6 
2016-12-10 17:16:35 Training Error = 0.79597777777778 
2016-12-10 17:16:35 Training Loss = 0.037115352050781 
2016-12-10 17:16:39 Valid Error = 0.82176435287057 
2016-12-10 17:16:39 Valid Loss = 0.037663339745149 
2016-12-10 17:17:05 Test Error = 0.8132 
2016-12-10 17:17:05 Test Loss = 0.037646484554515 
2016-12-10 17:17:05 -------------------LR------------------- 
2016-12-10 17:17:05 0.015625 
2016-12-10 17:17:05 Epoch 7 
2016-12-10 17:22:19 Training Error = 0.76771111111111 
2016-12-10 17:22:19 Training Loss = 0.036638951009115 
2016-12-10 17:22:24 Valid Error = 0.78455691138228 
2016-12-10 17:22:24 Valid Loss = 0.03693216121751 
2016-12-10 17:22:50 Test Error = 0.7784 
2016-12-10 17:22:50 Test Loss = 0.036832647166533 
2016-12-10 17:22:50 -------------------LR------------------- 
2016-12-10 17:22:50 0.015625 
2016-12-10 17:22:50 Epoch 8 
2016-12-10 17:27:48 Training Error = 0.74624444444444 
2016-12-10 17:27:48 Training Loss = 0.03620183610026 
2016-12-10 17:27:53 Valid Error = 0.75375075015003 
2016-12-10 17:27:53 Valid Loss = 0.036315947610503 
2016-12-10 17:28:10 Test Error = 0.7518 
2016-12-10 17:28:10 Test Loss = 0.036330137305166 
2016-12-10 17:28:10 -------------------LR------------------- 
2016-12-10 17:28:10 0.015625 
2016-12-10 17:28:10 Epoch 9 
2016-12-10 17:33:21 Training Error = 0.72071111111111 
2016-12-10 17:33:21 Training Loss = 0.035783622775608 
2016-12-10 17:33:26 Valid Error = 0.73974794958992 
2016-12-10 17:33:26 Valid Loss = 0.036014210940499 
2016-12-10 17:33:52 Test Error = 0.739 
2016-12-10 17:33:52 Test Loss = 0.035997122910443 
2016-12-10 17:33:52 -------------------LR------------------- 
2016-12-10 17:33:52 0.015625 
2016-12-10 17:33:52 Epoch 10 
2016-12-10 17:38:45 Training Error = 0.70275555555556 
2016-12-10 17:38:45 Training Loss = 0.035434643825955 
2016-12-10 17:38:50 Valid Error = 0.72254450890178 
2016-12-10 17:38:50 Valid Loss = 0.035506284955776 
2016-12-10 17:39:10 Test Error = 0.7146 
2016-12-10 17:39:10 Test Loss = 0.035382634779986 
2016-12-10 17:39:10 -------------------LR------------------- 
2016-12-10 17:39:10 0.015625 
2016-12-10 17:39:10 Epoch 11 
2016-12-10 17:44:18 Training Error = 0.68428888888889 
2016-12-10 17:44:18 Training Loss = 0.035115397894965 
2016-12-10 17:44:23 Valid Error = 0.72034406881376 
2016-12-10 17:44:23 Valid Loss = 0.035408494360274 
2016-12-10 17:44:44 Test Error = 0.7123 
2016-12-10 17:44:44 Test Loss = 0.03532875402114 
2016-12-10 17:44:44 -------------------LR------------------- 
2016-12-10 17:44:44 0.015625 
2016-12-10 17:44:45 Epoch 12 
2016-12-10 17:49:58 Training Error = 0.67444444444444 
2016-12-10 17:49:58 Training Loss = 0.034827973225911 
2016-12-10 17:50:03 Valid Error = 0.69253850770154 
2016-12-10 17:50:03 Valid Loss = 0.034562598237862 
2016-12-10 17:50:27 Test Error = 0.6869 
2016-12-10 17:50:27 Test Loss = 0.034504357969995 
2016-12-10 17:50:27 -------------------LR------------------- 
2016-12-10 17:50:27 0.015625 
2016-12-10 17:50:27 Epoch 13 
2016-12-10 17:55:34 Training Error = 0.66033333333333 
2016-12-10 17:55:34 Training Loss = 0.034559762586806 
2016-12-10 17:55:39 Valid Error = 0.70174034806961 
2016-12-10 17:55:39 Valid Loss = 0.034862928772825 
2016-12-10 17:56:04 Test Error = 0.6941 
2016-12-10 17:56:04 Test Loss = 0.034735358862783 
2016-12-10 17:56:04 -------------------LR------------------- 
2016-12-10 17:56:04 0.015625 
2016-12-10 17:56:04 Epoch 14 
2016-12-10 18:01:10 Training Error = 0.64591111111111 
2016-12-10 18:01:10 Training Loss = 0.034290603325738 
2016-12-10 18:01:15 Valid Error = 0.68233646729346 
2016-12-10 18:01:15 Valid Loss = 0.034212880611508 
2016-12-10 18:01:41 Test Error = 0.6776 
2016-12-10 18:01:41 Test Loss = 0.034117656812481 
2016-12-10 18:01:41 -------------------LR------------------- 
2016-12-10 18:01:41 0.015625 
2016-12-10 18:01:41 Epoch 15 
2016-12-10 18:06:35 Training Error = 0.63715555555556 
2016-12-10 18:06:35 Training Loss = 0.034046668104384 
2016-12-10 18:06:40 Valid Error = 0.66113222644529 
2016-12-10 18:06:40 Valid Loss = 0.033606342709142 
2016-12-10 18:07:01 Test Error = 0.6569 
2016-12-10 18:07:01 Test Loss = 0.033549370021446 
2016-12-10 18:07:01 -------------------LR------------------- 
2016-12-10 18:07:01 0.015625 
2016-12-10 18:07:01 Epoch 16 
2016-12-10 18:12:11 Training Error = 0.6274 
2016-12-10 18:12:11 Training Loss = 0.033869251030816 
2016-12-10 18:12:16 Valid Error = 0.66033206641328 
2016-12-10 18:12:16 Valid Loss = 0.033682616359385 
2016-12-10 18:12:39 Test Error = 0.6571 
2016-12-10 18:12:39 Test Loss = 0.033533042399089 
2016-12-10 18:12:39 -------------------LR------------------- 
2016-12-10 18:12:39 0.015625 
2016-12-10 18:12:39 Epoch 17 
2016-12-10 18:17:49 Training Error = 0.61988888888889 
2016-12-10 18:17:49 Training Loss = 0.033641973470052 
2016-12-10 18:17:54 Valid Error = 0.64092818563713 
2016-12-10 18:17:54 Valid Loss = 0.032920441800701 
2016-12-10 18:18:19 Test Error = 0.646 
2016-12-10 18:18:19 Test Loss = 0.032874463309494 
2016-12-10 18:18:19 -------------------LR------------------- 
2016-12-10 18:18:19 0.015625 
2016-12-10 18:18:19 Epoch 18 
2016-12-10 18:23:13 Training Error = 0.61251111111111 
2016-12-10 18:23:13 Training Loss = 0.033463245903863 
2016-12-10 18:23:18 Valid Error = 0.63032606521304 
2016-12-10 18:23:18 Valid Loss = 0.032655184254379 
2016-12-10 18:23:38 Test Error = 0.6284 
2016-12-10 18:23:38 Test Loss = 0.032611611699123 
2016-12-10 18:23:38 -------------------LR------------------- 
2016-12-10 18:23:38 0.015625 
2016-12-10 18:23:38 Epoch 19 
2016-12-10 18:28:46 Training Error = 0.60197777777778 
2016-12-10 18:28:46 Training Loss = 0.033281254123264 
2016-12-10 18:28:51 Valid Error = 0.61732346469294 
2016-12-10 18:28:51 Valid Loss = 0.032436315322725 
2016-12-10 18:29:12 Test Error = 0.6176 
2016-12-10 18:29:12 Test Loss = 0.032389551319795 
2016-12-10 18:29:12 -------------------LR------------------- 
2016-12-10 18:29:12 0.015625 
2016-12-10 18:29:13 Epoch 20 
2016-12-10 18:34:10 Training Error = 0.59235555555556 
2016-12-10 18:34:10 Training Loss = 0.033099085910373 
2016-12-10 18:34:14 Valid Error = 0.62212442488498 
2016-12-10 18:34:14 Valid Loss = 0.032567295612766 
2016-12-10 18:34:38 Test Error = 0.6295 
2016-12-10 18:34:38 Test Loss = 0.032478214458391 
2016-12-10 18:34:38 -------------------LR------------------- 
2016-12-10 18:34:38 0.015625 
2016-12-10 18:34:38 Epoch 21 
2016-12-10 18:39:44 Training Error = 0.58768888888889 
2016-12-10 18:39:44 Training Loss = 0.032943180067274 
2016-12-10 18:39:49 Valid Error = 0.61412282456491 
2016-12-10 18:39:49 Valid Loss = 0.032325010288394 
2016-12-10 18:40:14 Test Error = 0.6151 
2016-12-10 18:40:14 Test Loss = 0.032385473094267 
2016-12-10 18:40:14 -------------------LR------------------- 
2016-12-10 18:40:14 0.015625 
2016-12-10 18:40:14 Epoch 22 
2016-12-10 18:45:23 Training Error = 0.58244444444444 
2016-12-10 18:45:23 Training Loss = 0.032809459147135 
2016-12-10 18:45:28 Valid Error = 0.5997199439888 
2016-12-10 18:45:28 Valid Loss = 0.031734171014442 
2016-12-10 18:45:47 Test Error = 0.6001 
2016-12-10 18:45:47 Test Loss = 0.031636514820772 
2016-12-10 18:45:47 -------------------LR------------------- 
2016-12-10 18:45:47 0.015625 
2016-12-10 18:45:47 Epoch 23 
2016-12-10 18:50:39 Training Error = 0.57573333333333 
2016-12-10 18:50:39 Training Loss = 0.032631889322917 
2016-12-10 18:50:44 Valid Error = 0.58671734346869 
2016-12-10 18:50:44 Valid Loss = 0.031267970298314 
2016-12-10 18:51:04 Test Error = 0.5862 
2016-12-10 18:51:04 Test Loss = 0.031141042612113 
2016-12-10 18:51:04 -------------------LR------------------- 
2016-12-10 18:51:04 0.015625 
2016-12-10 18:51:05 Epoch 24 
2016-12-10 18:56:15 Training Error = 0.57097777777778 
2016-12-10 18:56:15 Training Loss = 0.032520509087457 
2016-12-10 18:56:20 Valid Error = 0.60432086417283 
2016-12-10 18:56:20 Valid Loss = 0.032070606464987 
2016-12-10 18:56:43 Test Error = 0.6099 
2016-12-10 18:56:43 Test Loss = 0.03195906048943 
2016-12-10 18:56:43 -------------------LR------------------- 
2016-12-10 18:56:43 0.015625 
2016-12-10 18:56:43 Epoch 25 
2016-12-10 19:01:50 Training Error = 0.56602222222222 
2016-12-10 19:01:50 Training Loss = 0.032379227511936 
2016-12-10 19:01:55 Valid Error = 0.60152030406081 
2016-12-10 19:01:55 Valid Loss = 0.031784899182145 
2016-12-10 19:02:19 Test Error = 0.6042 
2016-12-10 19:02:19 Test Loss = 0.031704038612515 
2016-12-10 19:02:19 -------------------LR------------------- 
2016-12-10 19:02:19 0.015625 
2016-12-10 19:02:19 Epoch 26 
2016-12-10 19:07:38 Training Error = 0.55711111111111 
2016-12-10 19:07:38 Training Loss = 0.032237193847656 
2016-12-10 19:07:43 Valid Error = 0.5997199439888 
2016-12-10 19:07:43 Valid Loss = 0.031968672897819 
2016-12-10 19:08:08 Test Error = 0.6082 
2016-12-10 19:08:08 Test Loss = 0.031875864545037 
2016-12-10 19:08:08 -------------------LR------------------- 
2016-12-10 19:08:08 0.015625 
2016-12-10 19:08:08 Epoch 27 
2016-12-10 19:13:12 Training Error = 0.55335555555556 
2016-12-10 19:13:12 Training Loss = 0.032162364040799 
2016-12-10 19:13:17 Valid Error = 0.60172034406881 
2016-12-10 19:13:17 Valid Loss = 0.031727809573311 
2016-12-10 19:13:43 Test Error = 0.592 
2016-12-10 19:13:43 Test Loss = 0.031627350870768 
2016-12-10 19:13:43 -------------------LR------------------- 
2016-12-10 19:13:43 0.015625 
2016-12-10 19:13:43 Epoch 28 
2016-12-10 19:18:45 Training Error = 0.55335555555556 
2016-12-10 19:18:45 Training Loss = 0.032067880995009 
2016-12-10 19:18:50 Valid Error = 0.56711342268454 
2016-12-10 19:18:50 Valid Loss = 0.030852624727551 
2016-12-10 19:19:10 Test Error = 0.5713 
2016-12-10 19:19:10 Test Loss = 0.030811117374196 
2016-12-10 19:19:10 -------------------LR------------------- 
2016-12-10 19:19:10 0.015625 
2016-12-10 19:19:10 Epoch 29 
2016-12-10 19:24:19 Training Error = 0.54826666666667 
2016-12-10 19:24:19 Training Loss = 0.031917892496745 
2016-12-10 19:24:24 Valid Error = 0.55951190238048 
2016-12-10 19:24:24 Valid Loss = 0.030495958930803 
2016-12-10 19:24:47 Test Error = 0.5629 
2016-12-10 19:24:47 Test Loss = 0.030458752979952 
2016-12-10 19:24:47 -------------------LR------------------- 
2016-12-10 19:24:47 0.015625 
2016-12-10 19:24:47 Epoch 30 
2016-12-10 19:29:56 Training Error = 0.54753333333333 
2016-12-10 19:29:56 Training Loss = 0.031874991129557 
2016-12-10 19:30:01 Valid Error = 0.56151230246049 
2016-12-10 19:30:01 Valid Loss = 0.030345051142758 
2016-12-10 19:30:25 Test Error = 0.5588 
2016-12-10 19:30:25 Test Loss = 0.030223809455423 
2016-12-10 19:30:25 -------------------LR------------------- 
2016-12-10 19:30:25 0.015625 
2016-12-10 19:30:25 Epoch 31 
2016-12-10 19:35:34 Training Error = 0.53988888888889 
2016-12-10 19:35:34 Training Loss = 0.031784605333116 
2016-12-10 19:35:39 Valid Error = 0.56331266253251 
2016-12-10 19:35:39 Valid Loss = 0.030776225868337 
2016-12-10 19:36:04 Test Error = 0.5718 
2016-12-10 19:36:04 Test Loss = 0.030802262908337 
2016-12-10 19:36:04 -------------------LR------------------- 
2016-12-10 19:36:04 0.015625 
2016-12-10 19:36:04 Epoch 32 
2016-12-10 19:41:20 Training Error = 0.53366666666667 
2016-12-10 19:41:20 Training Loss = 0.031642949571398 
2016-12-10 19:41:25 Valid Error = 0.57031406281256 
2016-12-10 19:41:25 Valid Loss = 0.030853322844556 
2016-12-10 19:41:52 Test Error = 0.5753 
2016-12-10 19:41:52 Test Loss = 0.030948118740905 
2016-12-10 19:41:52 -------------------LR------------------- 
2016-12-10 19:41:52 0.015625 
2016-12-10 19:41:52 Epoch 33 
2016-12-10 19:46:50 Training Error = 0.5348 
2016-12-10 19:46:50 Training Loss = 0.031590581000434 
2016-12-10 19:46:55 Valid Error = 0.56471294258852 
2016-12-10 19:46:55 Valid Loss = 0.03085608923433 
2016-12-10 19:47:16 Test Error = 0.5693 
2016-12-10 19:47:16 Test Loss = 0.030746592263614 
2016-12-10 19:47:16 -------------------LR------------------- 
2016-12-10 19:47:16 0.015625 
2016-12-10 19:47:16 Epoch 34 
2016-12-10 19:52:32 Training Error = 0.5262 
2016-12-10 19:52:32 Training Loss = 0.031492495605469 
2016-12-10 19:52:37 Valid Error = 0.55931186237247 
2016-12-10 19:52:37 Valid Loss = 0.030761290111219 
2016-12-10 19:53:01 Test Error = 0.5678 
2016-12-10 19:53:01 Test Loss = 0.030839666029986 
2016-12-10 19:53:01 -------------------LR------------------- 
2016-12-10 19:53:01 0.015625 
2016-12-10 19:53:01 Epoch 35 
2016-12-10 19:58:09 Training Error = 0.52651111111111 
2016-12-10 19:58:09 Training Loss = 0.031415397515191 
2016-12-10 19:58:14 Valid Error = 0.56491298259652 
2016-12-10 19:58:14 Valid Loss = 0.030198412801947 
2016-12-10 19:58:38 Test Error = 0.5568 
2016-12-10 19:58:38 Test Loss = 0.030090340827493 
2016-12-10 19:58:38 -------------------LR------------------- 
2016-12-10 19:58:38 0.015625 
2016-12-10 19:58:38 Epoch 36 
2016-12-10 20:03:48 Training Error = 0.52433333333333 
2016-12-10 20:03:48 Training Loss = 0.031355757052951 
2016-12-10 20:03:53 Valid Error = 0.56031206241248 
2016-12-10 20:03:53 Valid Loss = 0.030383659759527 
2016-12-10 20:04:19 Test Error = 0.5577 
2016-12-10 20:04:19 Test Loss = 0.030198030598958 
2016-12-10 20:04:19 -------------------LR------------------- 
2016-12-10 20:04:19 0.015625 
2016-12-10 20:04:19 Epoch 37 
2016-12-10 20:09:24 Training Error = 0.52115555555556 
2016-12-10 20:09:24 Training Loss = 0.031266158881293 
2016-12-10 20:09:29 Valid Error = 0.55091018203641 
2016-12-10 20:09:29 Valid Loss = 0.029997838069561 
2016-12-10 20:09:56 Test Error = 0.5475 
2016-12-10 20:09:56 Test Loss = 0.029980249980852 
2016-12-10 20:09:56 -------------------LR------------------- 
2016-12-10 20:09:56 0.015625 
2016-12-10 20:09:56 Epoch 38 
2016-12-10 20:14:47 Training Error = 0.51631111111111 
2016-12-10 20:14:47 Training Loss = 0.031200394015842 
2016-12-10 20:14:52 Valid Error = 0.55991198239648 
2016-12-10 20:14:52 Valid Loss = 0.030855540123533 
2016-12-10 20:15:12 Test Error = 0.5674 
2016-12-10 20:15:12 Test Loss = 0.030909588204178 
2016-12-10 20:15:12 -------------------LR------------------- 
2016-12-10 20:15:12 0.015625 
2016-12-10 20:15:12 Epoch 39 
2016-12-10 20:20:21 Training Error = 0.51517777777778 
2016-12-10 20:20:21 Training Loss = 0.031101960801866 
2016-12-10 20:20:26 Valid Error = 0.55271054210842 
2016-12-10 20:20:26 Valid Loss = 0.030103616018915 
2016-12-10 20:20:50 Test Error = 0.549 
2016-12-10 20:20:50 Test Loss = 0.029987558222752 
2016-12-10 20:20:50 -------------------LR------------------- 
2016-12-10 20:20:50 0.015625 
2016-12-10 20:20:50 Epoch 40 
2016-12-10 20:26:04 Training Error = 0.51384444444444 
2016-12-10 20:26:04 Training Loss = 0.031045129774306 
2016-12-10 20:26:09 Valid Error = 0.52750550110022 
2016-12-10 20:26:09 Valid Loss = 0.029339176598142 
2016-12-10 20:26:34 Test Error = 0.534 
2016-12-10 20:26:34 Test Loss = 0.029397172277114 
2016-12-10 20:26:34 -------------------LR------------------- 
2016-12-10 20:26:34 0.015625 
2016-12-10 20:26:34 Epoch 41 
2016-12-10 20:31:29 Training Error = 0.50942222222222 
2016-12-10 20:31:29 Training Loss = 0.030992446885851 
2016-12-10 20:31:34 Valid Error = 0.55311062212442 
2016-12-10 20:31:34 Valid Loss = 0.030556695891749 
2016-12-10 20:31:59 Test Error = 0.5564 
2016-12-10 20:31:59 Test Loss = 0.030491320082721 
2016-12-10 20:31:59 -------------------LR------------------- 
2016-12-10 20:31:59 0.015625 
2016-12-10 20:31:59 Epoch 42 
2016-12-10 20:37:08 Training Error = 0.50857777777778 
2016-12-10 20:37:08 Training Loss = 0.030923557915582 
2016-12-10 20:37:13 Valid Error = 0.54090818163633 
2016-12-10 20:37:13 Valid Loss = 0.029716880901996 
2016-12-10 20:37:40 Test Error = 0.5416 
2016-12-10 20:37:40 Test Loss = 0.02977025421741 
2016-12-10 20:37:40 -------------------LR------------------- 
2016-12-10 20:37:40 0.015625 
2016-12-10 20:37:40 Epoch 43 
2016-12-10 20:42:35 Training Error = 0.50722222222222 
2016-12-10 20:42:35 Training Loss = 0.030888767740885 
2016-12-10 20:42:40 Valid Error = 0.5245049009802 
2016-12-10 20:42:40 Valid Loss = 0.029263419291917 
2016-12-10 20:43:00 Test Error = 0.5277 
2016-12-10 20:43:00 Test Loss = 0.029345642748066 
2016-12-10 20:43:00 -------------------LR------------------- 
2016-12-10 20:43:00 0.015625 
2016-12-10 20:43:00 Epoch 44 
2016-12-10 20:48:13 Training Error = 0.50326666666667 
2016-12-10 20:48:13 Training Loss = 0.030826307617187 
2016-12-10 20:48:18 Valid Error = 0.53210642128426 
2016-12-10 20:48:18 Valid Loss = 0.029555706696233 
2016-12-10 20:48:42 Test Error = 0.526 
2016-12-10 20:48:42 Test Loss = 0.029379917578604 
2016-12-10 20:48:42 -------------------LR------------------- 
2016-12-10 20:48:42 0.015625 
2016-12-10 20:48:42 Epoch 45 
2016-12-10 20:53:50 Training Error = 0.4996 
2016-12-10 20:53:50 Training Loss = 0.030760633436415 
2016-12-10 20:53:55 Valid Error = 0.52750550110022 
2016-12-10 20:53:55 Valid Loss = 0.029428217324052 
2016-12-10 20:54:20 Test Error = 0.5362 
2016-12-10 20:54:20 Test Loss = 0.029485934208889 
2016-12-10 20:54:20 -------------------LR------------------- 
2016-12-10 20:54:20 0.015625 
2016-12-10 20:54:20 Epoch 46 
2016-12-10 20:59:23 Training Error = 0.49833333333333 
2016-12-10 20:59:23 Training Loss = 0.030654522298177 
2016-12-10 20:59:28 Valid Error = 0.53950790158032 
2016-12-10 20:59:28 Valid Loss = 0.029714245816757 
2016-12-10 20:59:54 Test Error = 0.5381 
2016-12-10 20:59:54 Test Loss = 0.02964625268076 
2016-12-10 20:59:54 -------------------LR------------------- 
2016-12-10 20:59:54 0.015625 
2016-12-10 20:59:54 Epoch 47 
2016-12-10 21:04:57 Training Error = 0.49946666666667 
2016-12-10 21:04:57 Training Loss = 0.030632076280382 
2016-12-10 21:05:02 Valid Error = 0.53530706141228 
2016-12-10 21:05:02 Valid Loss = 0.029970699324076 
2016-12-10 21:05:29 Test Error = 0.5416 
2016-12-10 21:05:29 Test Loss = 0.029896323050705 
2016-12-10 21:05:29 -------------------LR------------------- 
2016-12-10 21:05:29 0.015625 
2016-12-10 21:05:29 Epoch 48 
2016-12-10 21:10:29 Training Error = 0.49737777777778 
2016-12-10 21:10:29 Training Loss = 0.030593632405599 
2016-12-10 21:10:34 Valid Error = 0.52210442088418 
2016-12-10 21:10:34 Valid Loss = 0.029208630054161 
2016-12-10 21:10:54 Test Error = 0.5302 
2016-12-10 21:10:54 Test Loss = 0.029242738252528 
2016-12-10 21:10:54 -------------------LR------------------- 
2016-12-10 21:10:54 0.015625 
2016-12-10 21:10:55 Epoch 49 
2016-12-10 21:16:02 Training Error = 0.49524444444444 
2016-12-10 21:16:02 Training Loss = 0.030511461642795 
2016-12-10 21:16:07 Valid Error = 0.50850170034007 
2016-12-10 21:16:07 Valid Loss = 0.028499888506615 
2016-12-10 21:16:31 Test Error = 0.5089 
2016-12-10 21:16:31 Test Loss = 0.028475178198721 
2016-12-10 21:16:31 -------------------LR------------------- 
2016-12-10 21:16:31 0.015625 
2016-12-10 21:16:31 Epoch 50 
2016-12-10 21:21:46 Training Error = 0.49051111111111 
2016-12-10 21:21:46 Training Loss = 0.030476881103516 
2016-12-10 21:21:51 Valid Error = 0.54890978195639 
2016-12-10 21:21:51 Valid Loss = 0.029907931419158 
2016-12-10 21:22:15 Test Error = 0.5523 
2016-12-10 21:22:15 Test Loss = 0.030013296987496 
2016-12-10 21:22:15 -------------------LR------------------- 
2016-12-10 21:22:15 0.0078125 
2016-12-10 21:22:15 Epoch 51 
2016-12-10 21:27:12 Training Error = 0.47315555555556 
2016-12-10 21:27:12 Training Loss = 0.029818762803819 
2016-12-10 21:27:17 Valid Error = 0.50390078015603 
2016-12-10 21:27:17 Valid Loss = 0.028428926642762 
2016-12-10 21:27:43 Test Error = 0.5123 
2016-12-10 21:27:43 Test Loss = 0.028545336136163 
2016-12-10 21:27:43 -------------------LR------------------- 
2016-12-10 21:27:43 0.0078125 
2016-12-10 21:27:43 Epoch 52 
2016-12-10 21:32:57 Training Error = 0.46348888888889 
2016-12-10 21:32:57 Training Loss = 0.029601162868924 
2016-12-10 21:33:02 Valid Error = 0.51170234046809 
2016-12-10 21:33:02 Valid Loss = 0.028939883948233 
2016-12-10 21:33:29 Test Error = 0.511 
2016-12-10 21:33:29 Test Loss = 0.028865515675264 
2016-12-10 21:33:29 -------------------LR------------------- 
2016-12-10 21:33:29 0.0078125 
2016-12-10 21:33:29 Epoch 53 
2016-12-10 21:38:24 Training Error = 0.45591111111111 
2016-12-10 21:38:24 Training Loss = 0.029502744384766 
2016-12-10 21:38:29 Valid Error = 0.49409881976395 
2016-12-10 21:38:29 Valid Loss = 0.028312963730872 
2016-12-10 21:38:49 Test Error = 0.4981 
2016-12-10 21:38:49 Test Loss = 0.028439543002259 
2016-12-10 21:38:49 -------------------LR------------------- 
2016-12-10 21:38:49 0.0078125 
2016-12-10 21:38:49 Epoch 54 
2016-12-10 21:44:01 Training Error = 0.45248888888889 
2016-12-10 21:44:01 Training Loss = 0.029410557156033 
2016-12-10 21:44:06 Valid Error = 0.49189837967594 
2016-12-10 21:44:06 Valid Loss = 0.028165985397092 
2016-12-10 21:44:30 Test Error = 0.4946 
2016-12-10 21:44:30 Test Loss = 0.028181654028799 
2016-12-10 21:44:30 -------------------LR------------------- 
2016-12-10 21:44:30 0.0078125 
2016-12-10 21:44:30 Epoch 55 
2016-12-10 21:49:44 Training Error = 0.45295555555556 
2016-12-10 21:49:44 Training Loss = 0.029366423800998 
2016-12-10 21:49:49 Valid Error = 0.49009801960392 
2016-12-10 21:49:49 Valid Loss = 0.028240001431537 
2016-12-10 21:50:13 Test Error = 0.5002 
2016-12-10 21:50:13 Test Loss = 0.028306785613415 
2016-12-10 21:50:13 -------------------LR------------------- 
2016-12-10 21:50:13 0.0078125 
2016-12-10 21:50:13 Epoch 56 
2016-12-10 21:55:07 Training Error = 0.44668888888889 
2016-12-10 21:55:07 Training Loss = 0.029248782470703 
2016-12-10 21:55:12 Valid Error = 0.49429885977195 
2016-12-10 21:55:12 Valid Loss = 0.028452233197191 
2016-12-10 21:55:37 Test Error = 0.4985 
2016-12-10 21:55:37 Test Loss = 0.028536728144627 
2016-12-10 21:55:37 -------------------LR------------------- 
2016-12-10 21:55:37 0.0078125 
2016-12-10 21:55:37 Epoch 57 
2016-12-10 22:00:41 Training Error = 0.44524444444444 
2016-12-10 22:00:41 Training Loss = 0.029283392740885 
2016-12-10 22:00:46 Valid Error = 0.49189837967594 
2016-12-10 22:00:46 Valid Loss = 0.028695522215343 
2016-12-10 22:01:13 Test Error = 0.5041 
2016-12-10 22:01:13 Test Loss = 0.028834183457318 
2016-12-10 22:01:13 -------------------LR------------------- 
2016-12-10 22:01:13 0.0078125 
2016-12-10 22:01:13 Epoch 58 
2016-12-10 22:06:10 Training Error = 0.44402222222222 
2016-12-10 22:06:10 Training Loss = 0.029196530300564 
2016-12-10 22:06:15 Valid Error = 0.48949789957992 
2016-12-10 22:06:15 Valid Loss = 0.028132724726606 
2016-12-10 22:06:35 Test Error = 0.4928 
2016-12-10 22:06:35 Test Loss = 0.028158184515261 
2016-12-10 22:06:35 -------------------LR------------------- 
2016-12-10 22:06:35 0.0078125 
2016-12-10 22:06:35 Epoch 59 
2016-12-10 22:11:48 Training Error = 0.44253333333333 
2016-12-10 22:11:48 Training Loss = 0.029182701524523 
2016-12-10 22:11:53 Valid Error = 0.49629925985197 
2016-12-10 22:11:53 Valid Loss = 0.02831313433396 
2016-12-10 22:12:17 Test Error = 0.4987 
2016-12-10 22:12:17 Test Loss = 0.02829928594851 
2016-12-10 22:12:17 -------------------LR------------------- 
2016-12-10 22:12:17 0.0078125 
2016-12-10 22:12:17 Epoch 60 
2016-12-10 22:17:19 Training Error = 0.43782222222222 
2016-12-10 22:17:19 Training Loss = 0.029113098931207 
2016-12-10 22:17:24 Valid Error = 0.49569913982797 
2016-12-10 22:17:24 Valid Loss = 0.028499605344612 
2016-12-10 22:17:49 Test Error = 0.4952 
2016-12-10 22:17:49 Test Loss = 0.028488664036171 
2016-12-10 22:17:49 -------------------LR------------------- 
2016-12-10 22:17:49 0.0078125 
2016-12-10 22:17:49 Epoch 61 
2016-12-10 22:22:52 Training Error = 0.4378 
2016-12-10 22:22:52 Training Loss = 0.029104128092448 
2016-12-10 22:22:57 Valid Error = 0.4870974194839 
2016-12-10 22:22:57 Valid Loss = 0.02824399342497 
2016-12-10 22:23:23 Test Error = 0.4894 
2016-12-10 22:23:23 Test Loss = 0.028299184701957 
2016-12-10 22:23:23 -------------------LR------------------- 
2016-12-10 22:23:23 0.0078125 
2016-12-10 22:23:23 Epoch 62 
2016-12-10 22:28:27 Training Error = 0.43857777777778 
2016-12-10 22:28:27 Training Loss = 0.029067356662326 
2016-12-10 22:28:32 Valid Error = 0.49409881976395 
2016-12-10 22:28:32 Valid Loss = 0.028603293770784 
2016-12-10 22:28:59 Test Error = 0.4966 
2016-12-10 22:28:59 Test Loss = 0.028672235107422 
2016-12-10 22:28:59 -------------------LR------------------- 
2016-12-10 22:28:59 0.0078125 
2016-12-10 22:28:59 Epoch 63 
2016-12-10 22:33:55 Training Error = 0.43477777777778 
2016-12-10 22:33:55 Training Loss = 0.029032664469401 
2016-12-10 22:34:00 Valid Error = 0.48049609921984 
2016-12-10 22:34:00 Valid Loss = 0.02794752116726 
2016-12-10 22:34:21 Test Error = 0.4879 
2016-12-10 22:34:21 Test Loss = 0.027976104796167 
2016-12-10 22:34:21 -------------------LR------------------- 
2016-12-10 22:34:21 0.0078125 
2016-12-10 22:34:21 Epoch 64 
2016-12-10 22:39:32 Training Error = 0.43246666666667 
2016-12-10 22:39:32 Training Loss = 0.028981666069878 
2016-12-10 22:39:37 Valid Error = 0.48869773954791 
2016-12-10 22:39:37 Valid Loss = 0.028290831091629 
2016-12-10 22:40:01 Test Error = 0.4909 
2016-12-10 22:40:01 Test Loss = 0.028270272587795 
2016-12-10 22:40:01 -------------------LR------------------- 
2016-12-10 22:40:01 0.0078125 
2016-12-10 22:40:01 Epoch 65 
2016-12-10 22:45:12 Training Error = 0.43362222222222 
2016-12-10 22:45:12 Training Loss = 0.028958752468533 
2016-12-10 22:45:17 Valid Error = 0.48949789957992 
2016-12-10 22:45:17 Valid Loss = 0.028211202459373 
2016-12-10 22:45:42 Test Error = 0.4936 
2016-12-10 22:45:42 Test Loss = 0.028210336662741 
2016-12-10 22:45:42 -------------------LR------------------- 
2016-12-10 22:45:42 0.0078125 
2016-12-10 22:45:42 Epoch 66 
2016-12-10 22:50:35 Training Error = 0.43175555555556 
2016-12-10 22:50:35 Training Loss = 0.028941243570964 
2016-12-10 22:50:40 Valid Error = 0.48149629925985 
2016-12-10 22:50:40 Valid Loss = 0.027919077401984 
2016-12-10 22:51:06 Test Error = 0.4828 
2016-12-10 22:51:06 Test Loss = 0.027972802973729 
2016-12-10 22:51:06 -------------------LR------------------- 
2016-12-10 22:51:06 0.0078125 
2016-12-10 22:51:06 Epoch 67 
2016-12-10 22:56:16 Training Error = 0.42993333333333 
2016-12-10 22:56:16 Training Loss = 0.028908769992405 
2016-12-10 22:56:21 Valid Error = 0.48309661932386 
2016-12-10 22:56:21 Valid Loss = 0.028050578145947 
2016-12-10 22:56:48 Test Error = 0.4838 
2016-12-10 22:56:48 Test Loss = 0.028158141072591 
2016-12-10 22:56:48 -------------------LR------------------- 
2016-12-10 22:56:48 0.0078125 
2016-12-10 22:56:48 Epoch 68 
2016-12-10 23:01:40 Training Error = 0.42702222222222 
2016-12-10 23:01:40 Training Loss = 0.028874236979167 
2016-12-10 23:01:45 Valid Error = 0.47989597919584 
2016-12-10 23:01:45 Valid Loss = 0.028075067671437 
2016-12-10 23:02:06 Test Error = 0.4885 
2016-12-10 23:02:06 Test Loss = 0.028072600121592 
2016-12-10 23:02:06 -------------------LR------------------- 
2016-12-10 23:02:06 0.0078125 
2016-12-10 23:02:06 Epoch 69 
2016-12-10 23:07:17 Training Error = 0.42873333333333 
2016-12-10 23:07:17 Training Loss = 0.028869260904948 
2016-12-10 23:07:21 Valid Error = 0.49649929985997 
2016-12-10 23:07:21 Valid Loss = 0.028484480945354 
2016-12-10 23:07:46 Test Error = 0.4998 
2016-12-10 23:07:46 Test Loss = 0.028619487986845 
2016-12-10 23:07:46 -------------------LR------------------- 
2016-12-10 23:07:46 0.0078125 
2016-12-10 23:07:46 Epoch 70 
2016-12-10 23:12:56 Training Error = 0.42657777777778 
2016-12-10 23:12:56 Training Loss = 0.028825374023437 
2016-12-10 23:13:01 Valid Error = 0.46689337867574 
2016-12-10 23:13:01 Valid Loss = 0.027310995068205 
2016-12-10 23:13:26 Test Error = 0.4765 
2016-12-10 23:13:26 Test Loss = 0.02753215266209 
2016-12-10 23:13:26 -------------------LR------------------- 
2016-12-10 23:13:26 0.0078125 
2016-12-10 23:13:26 Epoch 71 
2016-12-10 23:18:27 Training Error = 0.42504444444444 
2016-12-10 23:18:27 Training Loss = 0.028779516140408 
2016-12-10 23:18:32 Valid Error = 0.47769553910782 
2016-12-10 23:18:32 Valid Loss = 0.027877087036564 
2016-12-10 23:18:57 Test Error = 0.4854 
2016-12-10 23:18:57 Test Loss = 0.028032971490598 
2016-12-10 23:18:57 -------------------LR------------------- 
2016-12-10 23:18:57 0.0078125 
2016-12-10 23:18:57 Epoch 72 
2016-12-10 23:23:55 Training Error = 0.42462222222222 
2016-12-10 23:23:55 Training Loss = 0.02881265749783 
2016-12-10 23:24:00 Valid Error = 0.47429485897179 
2016-12-10 23:24:00 Valid Loss = 0.027915049280464 
2016-12-10 23:24:27 Test Error = 0.48 
2016-12-10 23:24:27 Test Loss = 0.027901495840035 
2016-12-10 23:24:27 -------------------LR------------------- 
2016-12-10 23:24:27 0.0078125 
2016-12-10 23:24:27 Epoch 73 
2016-12-10 23:29:35 Training Error = 0.42411111111111 
2016-12-10 23:29:35 Training Loss = 0.028754625406901 
2016-12-10 23:29:40 Valid Error = 0.47109421884377 
2016-12-10 23:29:40 Valid Loss = 0.027870200179636 
2016-12-10 23:30:01 Test Error = 0.4784 
2016-12-10 23:30:01 Test Loss = 0.027998434089212 
2016-12-10 23:30:01 -------------------LR------------------- 
2016-12-10 23:30:01 0.0078125 
2016-12-10 23:30:01 Epoch 74 
2016-12-10 23:35:05 Training Error = 0.424 
2016-12-10 23:35:05 Training Loss = 0.028693300808377 
2016-12-10 23:35:09 Valid Error = 0.46529305861172 
2016-12-10 23:35:09 Valid Loss = 0.027515731222528 
2016-12-10 23:35:34 Test Error = 0.472 
2016-12-10 23:35:34 Test Loss = 0.027576265761432 
2016-12-10 23:35:34 -------------------LR------------------- 
2016-12-10 23:35:34 0.0078125 
2016-12-10 23:35:34 Epoch 75 
2016-12-10 23:40:42 Training Error = 0.42344444444444 
2016-12-10 23:40:42 Training Loss = 0.028721563259549 
2016-12-10 23:40:47 Valid Error = 0.48189637927586 
2016-12-10 23:40:47 Valid Loss = 0.028071512637697 
2016-12-10 23:41:12 Test Error = 0.4887 
2016-12-10 23:41:12 Test Loss = 0.028071356799556 
2016-12-10 23:41:12 -------------------LR------------------- 
2016-12-10 23:41:12 0.0078125 
2016-12-10 23:41:12 Epoch 76 
2016-12-10 23:46:10 Training Error = 0.42297777777778 
2016-12-10 23:46:10 Training Loss = 0.028658152967665 
2016-12-10 23:46:15 Valid Error = 0.48389677935587 
2016-12-10 23:46:15 Valid Loss = 0.028087639647029 
2016-12-10 23:46:40 Test Error = 0.4813 
2016-12-10 23:46:40 Test Loss = 0.028101901185279 
2016-12-10 23:46:40 -------------------LR------------------- 
2016-12-10 23:46:40 0.0078125 
2016-12-10 23:46:40 Epoch 77 
2016-12-10 23:51:50 Training Error = 0.41957777777778 
2016-12-10 23:51:50 Training Loss = 0.028676277235243 
2016-12-10 23:51:55 Valid Error = 0.47349469893979 
2016-12-10 23:51:55 Valid Loss = 0.027910582321511 
2016-12-10 23:52:22 Test Error = 0.4775 
2016-12-10 23:52:22 Test Loss = 0.027983679259057 
2016-12-10 23:52:22 -------------------LR------------------- 
2016-12-10 23:52:22 0.0078125 
2016-12-10 23:52:22 Epoch 78 
2016-12-10 23:57:34 Training Error = 0.41922222222222 
2016-12-10 23:57:34 Training Loss = 0.028673072835286 
2016-12-10 23:57:39 Valid Error = 0.47229445889178 
2016-12-10 23:57:39 Valid Loss = 0.027913936880947 
2016-12-10 23:57:59 Test Error = 0.4769 
2016-12-10 23:57:59 Test Loss = 0.027847986019359 
2016-12-10 23:57:59 -------------------LR------------------- 
2016-12-10 23:57:59 0.0078125 
2016-12-10 23:57:59 Epoch 79 
2016-12-11 00:03:11 Training Error = 0.41755555555556 
2016-12-11 00:03:11 Training Loss = 0.028610857476128 
2016-12-11 00:03:16 Valid Error = 0.4870974194839 
2016-12-11 00:03:16 Valid Loss = 0.028098933735245 
2016-12-11 00:03:41 Test Error = 0.4862 
2016-12-11 00:03:41 Test Loss = 0.028190166877298 
2016-12-11 00:03:41 -------------------LR------------------- 
2016-12-11 00:03:41 0.0078125 
2016-12-11 00:03:41 Epoch 80 
2016-12-11 00:08:57 Training Error = 0.41593333333333 
2016-12-11 00:08:57 Training Loss = 0.028599463053385 
2016-12-11 00:09:02 Valid Error = 0.46889377875575 
2016-12-11 00:09:02 Valid Loss = 0.027443481136331 
2016-12-11 00:09:27 Test Error = 0.4703 
2016-12-11 00:09:27 Test Loss = 0.027471664787741 
2016-12-11 00:09:27 -------------------LR------------------- 
2016-12-11 00:09:27 0.0078125 
2016-12-11 00:09:27 Epoch 81 
2016-12-11 00:14:50 Training Error = 0.41628888888889 
2016-12-11 00:14:50 Training Loss = 0.028580997314453 
2016-12-11 00:14:55 Valid Error = 0.47709541908382 
2016-12-11 00:14:55 Valid Loss = 0.027931389806063 
2016-12-11 00:15:20 Test Error = 0.4828 
2016-12-11 00:15:20 Test Loss = 0.027969901589786 
2016-12-11 00:15:20 -------------------LR------------------- 
2016-12-11 00:15:20 0.0078125 
2016-12-11 00:15:20 Epoch 82 
2016-12-11 00:20:54 Training Error = 0.41817777777778 
2016-12-11 00:20:54 Training Loss = 0.028577437771267 
2016-12-11 00:20:59 Valid Error = 0.47649529905981 
2016-12-11 00:20:59 Valid Loss = 0.027982925615536 
2016-12-11 00:21:27 Test Error = 0.4824 
2016-12-11 00:21:27 Test Loss = 0.028030332497989 
2016-12-11 00:21:27 -------------------LR------------------- 
2016-12-11 00:21:27 0.0078125 
2016-12-11 00:21:27 Epoch 83 
2016-12-11 00:26:51 Training Error = 0.4136 
2016-12-11 00:26:51 Training Loss = 0.028498102105035 
2016-12-11 00:26:56 Valid Error = 0.47849569913983 
2016-12-11 00:26:56 Valid Loss = 0.028036159835864 
2016-12-11 00:27:23 Test Error = 0.4781 
2016-12-11 00:27:23 Test Loss = 0.028009706025965 
2016-12-11 00:27:23 -------------------LR------------------- 
2016-12-11 00:27:23 0.0078125 
2016-12-11 00:27:23 Epoch 84 
2016-12-11 00:32:38 Training Error = 0.41288888888889 
2016-12-11 00:32:38 Training Loss = 0.028484811225043 
2016-12-11 00:32:43 Valid Error = 0.47349469893979 
2016-12-11 00:32:43 Valid Loss = 0.027727325381519 
2016-12-11 00:33:04 Test Error = 0.4748 
2016-12-11 00:33:04 Test Loss = 0.027744212790097 
2016-12-11 00:33:04 -------------------LR------------------- 
2016-12-11 00:33:04 0.0078125 
2016-12-11 00:33:04 Epoch 85 
2016-12-11 00:38:42 Training Error = 0.4134 
2016-12-11 00:38:42 Training Loss = 0.028497009385851 
2016-12-11 00:38:47 Valid Error = 0.47729545909182 
2016-12-11 00:38:47 Valid Loss = 0.027777983910301 
2016-12-11 00:39:11 Test Error = 0.4803 
2016-12-11 00:39:11 Test Loss = 0.02789300106273 
2016-12-11 00:39:11 -------------------LR------------------- 
2016-12-11 00:39:11 0.0078125 
2016-12-11 00:39:11 Epoch 86 
2016-12-11 00:44:18 Training Error = 0.41206666666667 
2016-12-11 00:44:18 Training Loss = 0.028451679796007 
2016-12-11 00:44:23 Valid Error = 0.49449889977996 
2016-12-11 00:44:23 Valid Loss = 0.028874439814724 
2016-12-11 00:44:47 Test Error = 0.4999 
2016-12-11 00:44:47 Test Loss = 0.028930679141774 
2016-12-11 00:44:47 -------------------LR------------------- 
2016-12-11 00:44:47 0.0078125 
2016-12-11 00:44:47 Epoch 87 
2016-12-11 00:50:11 Training Error = 0.4128 
2016-12-11 00:50:11 Training Loss = 0.028481619656033 
2016-12-11 00:50:16 Valid Error = 0.46609321864373 
2016-12-11 00:50:16 Valid Loss = 0.027440399116532 
2016-12-11 00:50:41 Test Error = 0.475 
2016-12-11 00:50:41 Test Loss = 0.027575186935126 
2016-12-11 00:50:41 -------------------LR------------------- 
2016-12-11 00:50:41 0.0078125 
2016-12-11 00:50:41 Epoch 88 
2016-12-11 00:56:08 Training Error = 0.4102 
2016-12-11 00:56:08 Training Loss = 0.028413648980035 
2016-12-11 00:56:13 Valid Error = 0.45949189837968 
2016-12-11 00:56:13 Valid Loss = 0.02716372796532 
2016-12-11 00:56:40 Test Error = 0.469 
2016-12-11 00:56:40 Test Loss = 0.027381777415556 
2016-12-11 00:56:40 -------------------LR------------------- 
2016-12-11 00:56:40 0.0078125 
2016-12-11 00:56:40 Epoch 89 
2016-12-11 01:01:49 Training Error = 0.40853333333333 
2016-12-11 01:01:49 Training Loss = 0.028365905571832 
2016-12-11 01:01:54 Valid Error = 0.47169433886777 
2016-12-11 01:01:54 Valid Loss = 0.027530973140305 
2016-12-11 01:02:22 Test Error = 0.4718 
2016-12-11 01:02:22 Test Loss = 0.027544817995558 
2016-12-11 01:02:22 -------------------LR------------------- 
2016-12-11 01:02:22 0.0078125 
2016-12-11 01:02:22 Epoch 90 
2016-12-11 01:07:40 Training Error = 0.40993333333333 
2016-12-11 01:07:40 Training Loss = 0.02838935007053 
2016-12-11 01:07:45 Valid Error = 0.46729345869174 
2016-12-11 01:07:45 Valid Loss = 0.027701679390333 
2016-12-11 01:08:06 Test Error = 0.4742 
2016-12-11 01:08:06 Test Loss = 0.027813322777842 
2016-12-11 01:08:06 -------------------LR------------------- 
2016-12-11 01:08:06 0.0078125 
2016-12-11 01:08:06 Epoch 91 
2016-12-11 01:13:29 Training Error = 0.41017777777778 
2016-12-11 01:13:29 Training Loss = 0.02836168766276 
2016-12-11 01:13:34 Valid Error = 0.49289857971594 
2016-12-11 01:13:34 Valid Loss = 0.028693647791956 
2016-12-11 01:13:58 Test Error = 0.4899 
2016-12-11 01:13:58 Test Loss = 0.028679287839403 
2016-12-11 01:13:58 -------------------LR------------------- 
2016-12-11 01:13:58 0.0078125 
2016-12-11 01:13:58 Epoch 92 
2016-12-11 01:19:19 Training Error = 0.40708888888889 
2016-12-11 01:19:19 Training Loss = 0.02834868608941 
2016-12-11 01:19:24 Valid Error = 0.46629325865173 
2016-12-11 01:19:24 Valid Loss = 0.027412571704097 
2016-12-11 01:19:48 Test Error = 0.4706 
2016-12-11 01:19:48 Test Loss = 0.027553501981847 
2016-12-11 01:19:48 -------------------LR------------------- 
2016-12-11 01:19:48 0.0078125 
2016-12-11 01:19:48 Epoch 93 
2016-12-11 01:25:06 Training Error = 0.40937777777778 
2016-12-11 01:25:06 Training Loss = 0.028325450873481 
2016-12-11 01:25:11 Valid Error = 0.46529305861172 
2016-12-11 01:25:11 Valid Loss = 0.027396297004 
2016-12-11 01:25:35 Test Error = 0.4698 
2016-12-11 01:25:35 Test Loss = 0.027466090183632 
2016-12-11 01:25:35 -------------------LR------------------- 
2016-12-11 01:25:35 0.0078125 
2016-12-11 01:25:35 Epoch 94 
2016-12-11 01:31:00 Training Error = 0.40631111111111 
2016-12-11 01:31:00 Training Loss = 0.02830476421441 
2016-12-11 01:31:05 Valid Error = 0.46709341868374 
2016-12-11 01:31:05 Valid Loss = 0.027556959099471 
2016-12-11 01:31:32 Test Error = 0.4717 
2016-12-11 01:31:32 Test Loss = 0.027516320082721 
2016-12-11 01:31:32 -------------------LR------------------- 
2016-12-11 01:31:32 0.0078125 
2016-12-11 01:31:32 Epoch 95 
2016-12-11 01:36:59 Training Error = 0.40415555555556 
2016-12-11 01:36:59 Training Loss = 0.028284014431424 
2016-12-11 01:37:04 Valid Error = 0.47889577915583 
2016-12-11 01:37:04 Valid Loss = 0.02821131138435 
2016-12-11 01:37:25 Test Error = 0.4798 
2016-12-11 01:37:25 Test Loss = 0.028256838570389 
2016-12-11 01:37:25 -------------------LR------------------- 
2016-12-11 01:37:25 0.0078125 
2016-12-11 01:37:25 Epoch 96 
2016-12-11 01:42:56 Training Error = 0.40817777777778 
2016-12-11 01:42:56 Training Loss = 0.028289272488064 
2016-12-11 01:43:01 Valid Error = 0.4744948989798 
2016-12-11 01:43:01 Valid Loss = 0.028250715096206 
2016-12-11 01:43:25 Test Error = 0.4868 
2016-12-11 01:43:25 Test Loss = 0.028288559678022 
2016-12-11 01:43:25 -------------------LR------------------- 
2016-12-11 01:43:25 0.0078125 
2016-12-11 01:43:25 Epoch 97 
2016-12-11 01:48:38 Training Error = 0.40402222222222 
2016-12-11 01:48:38 Training Loss = 0.028258354600694 
2016-12-11 01:48:43 Valid Error = 0.46369273854771 
2016-12-11 01:48:43 Valid Loss = 0.027789736885654 
2016-12-11 01:49:08 Test Error = 0.4692 
2016-12-11 01:49:08 Test Loss = 0.027773287305645 
2016-12-11 01:49:08 -------------------LR------------------- 
2016-12-11 01:49:08 0.0078125 
2016-12-11 01:49:08 Epoch 98 
2016-12-11 01:54:33 Training Error = 0.40473333333333 
2016-12-11 01:54:33 Training Loss = 0.028228270562066 
2016-12-11 01:54:38 Valid Error = 0.46969393878776 
2016-12-11 01:54:38 Valid Loss = 0.028134664975494 
2016-12-11 01:55:03 Test Error = 0.4777 
2016-12-11 01:55:03 Test Loss = 0.028117668540805 
2016-12-11 01:55:03 -------------------LR------------------- 
2016-12-11 01:55:03 0.0078125 
2016-12-11 01:55:03 Epoch 99 
2016-12-11 02:00:15 Training Error = 0.4058 
2016-12-11 02:00:15 Training Loss = 0.028195171061198 
2016-12-11 02:00:20 Valid Error = 0.46969393878776 
2016-12-11 02:00:20 Valid Loss = 0.027563138970951 
2016-12-11 02:00:47 Test Error = 0.4714 
2016-12-11 02:00:47 Test Loss = 0.027561504708084 
2016-12-11 02:00:47 -------------------LR------------------- 
2016-12-11 02:00:47 0.0078125 
2016-12-11 02:00:47 Epoch 100 
2016-12-11 02:06:23 Training Error = 0.40271111111111 
2016-12-11 02:06:23 Training Loss = 0.028191778266059 
2016-12-11 02:06:28 Valid Error = 0.48349669933987 
2016-12-11 02:06:28 Valid Loss = 0.028013245233237 
2016-12-11 02:06:49 Test Error = 0.475 
2016-12-11 02:06:49 Test Loss = 0.02799509750067 
2016-12-11 02:06:49 -------------------LR------------------- 
2016-12-11 02:06:49 0.00390625 
2016-12-11 02:06:49 Epoch 101 
2016-12-11 02:12:07 Training Error = 0.38433333333333 
2016-12-11 02:12:07 Training Loss = 0.027552230278863 
2016-12-11 02:12:12 Valid Error = 0.46989397879576 
2016-12-11 02:12:12 Valid Loss = 0.027542582368948 
2016-12-11 02:12:36 Test Error = 0.4666 
2016-12-11 02:12:36 Test Loss = 0.027526988070619 
2016-12-11 02:12:36 -------------------LR------------------- 
2016-12-11 02:12:36 0.00390625 
2016-12-11 02:12:36 Epoch 102 
2016-12-11 02:17:56 Training Error = 0.37642222222222 
2016-12-11 02:17:56 Training Loss = 0.027331815972222 
2016-12-11 02:18:01 Valid Error = 0.44748949789958 
2016-12-11 02:18:01 Valid Loss = 0.026605494193243 
2016-12-11 02:18:25 Test Error = 0.45 
2016-12-11 02:18:25 Test Loss = 0.026571742996515 
2016-12-11 02:18:25 -------------------LR------------------- 
2016-12-11 02:18:25 0.00390625 
2016-12-11 02:18:25 Epoch 103 
2016-12-11 02:23:46 Training Error = 0.37135555555556 
2016-12-11 02:23:46 Training Loss = 0.02723733843316 
2016-12-11 02:23:51 Valid Error = 0.4626925385077 
2016-12-11 02:23:51 Valid Loss = 0.027416302387998 
2016-12-11 02:24:16 Test Error = 0.4668 
2016-12-11 02:24:16 Test Loss = 0.027421643963982 
2016-12-11 02:24:16 -------------------LR------------------- 
2016-12-11 02:24:16 0.00390625 
2016-12-11 02:24:16 Epoch 104 
2016-12-11 02:29:36 Training Error = 0.36848888888889 
2016-12-11 02:29:36 Training Loss = 0.027162953830295 
2016-12-11 02:29:41 Valid Error = 0.44548909781956 
2016-12-11 02:29:41 Valid Loss = 0.02667585005967 
2016-12-11 02:30:08 Test Error = 0.4431 
2016-12-11 02:30:08 Test Loss = 0.026632992673388 
2016-12-11 02:30:08 -------------------LR------------------- 
2016-12-11 02:30:08 0.00390625 
2016-12-11 02:30:08 Epoch 105 
2016-12-11 02:35:31 Training Error = 0.36591111111111 
2016-12-11 02:35:31 Training Loss = 0.027157192274306 
2016-12-11 02:35:36 Valid Error = 0.45389077815563 
2016-12-11 02:35:36 Valid Loss = 0.027351803747334 
2016-12-11 02:35:56 Test Error = 0.4601 
2016-12-11 02:35:56 Test Loss = 0.027446915989296 
2016-12-11 02:35:56 -------------------LR------------------- 
2016-12-11 02:35:56 0.00390625 
2016-12-11 02:35:56 Epoch 106 
2016-12-11 02:41:23 Training Error = 0.36397777777778 
2016-12-11 02:41:23 Training Loss = 0.027116742485894 
2016-12-11 02:41:28 Valid Error = 0.4500900180036 
2016-12-11 02:41:28 Valid Loss = 0.026890965713169 
2016-12-11 02:41:52 Test Error = 0.4534 
2016-12-11 02:41:52 Test Loss = 0.027025358192593 
2016-12-11 02:41:52 -------------------LR------------------- 
2016-12-11 02:41:52 0.00390625 
2016-12-11 02:41:52 Epoch 107 
2016-12-11 02:47:05 Training Error = 0.3628 
2016-12-11 02:47:05 Training Loss = 0.027104863471137 
2016-12-11 02:47:09 Valid Error = 0.44908981796359 
2016-12-11 02:47:09 Valid Loss = 0.027179859434433 
2016-12-11 02:47:34 Test Error = 0.453 
2016-12-11 02:47:34 Test Loss = 0.027033703373928 
2016-12-11 02:47:34 -------------------LR------------------- 
2016-12-11 02:47:34 0.00390625 
2016-12-11 02:47:34 Epoch 108 
2016-12-11 02:53:01 Training Error = 0.36273333333333 
2016-12-11 02:53:01 Training Loss = 0.027089305989583 
2016-12-11 02:53:06 Valid Error = 0.45849169833967 
2016-12-11 02:53:06 Valid Loss = 0.027158938618512 
2016-12-11 02:53:30 Test Error = 0.4551 
2016-12-11 02:53:30 Test Loss = 0.02718823409735 
2016-12-11 02:53:30 -------------------LR------------------- 
2016-12-11 02:53:30 0.00390625 
2016-12-11 02:53:31 Epoch 109 
2016-12-11 02:58:47 Training Error = 0.35904444444444 
2016-12-11 02:58:47 Training Loss = 0.026996114501953 
2016-12-11 02:58:52 Valid Error = 0.4496899379876 
2016-12-11 02:58:52 Valid Loss = 0.027085806008031 
2016-12-11 02:59:19 Test Error = 0.4536 
2016-12-11 02:59:19 Test Loss = 0.027126727294922 
2016-12-11 02:59:19 -------------------LR------------------- 
2016-12-11 02:59:19 0.00390625 
2016-12-11 02:59:19 Epoch 110 
2016-12-11 03:04:31 Training Error = 0.35848888888889 
2016-12-11 03:04:31 Training Loss = 0.026986240885417 
2016-12-11 03:04:36 Valid Error = 0.45349069813963 
2016-12-11 03:04:36 Valid Loss = 0.02744354261224 
2016-12-11 03:04:56 Test Error = 0.4555 
2016-12-11 03:04:56 Test Loss = 0.027480952782724 
2016-12-11 03:04:56 -------------------LR------------------- 
2016-12-11 03:04:56 0.00390625 
2016-12-11 03:04:56 Epoch 111 
2016-12-11 03:10:30 Training Error = 0.35711111111111 
2016-12-11 03:10:30 Training Loss = 0.026969960232205 
2016-12-11 03:10:35 Valid Error = 0.44348869773955 
2016-12-11 03:10:35 Valid Loss = 0.026502188307441 
2016-12-11 03:10:59 Test Error = 0.4432 
2016-12-11 03:10:59 Test Loss = 0.026539295391008 
2016-12-11 03:10:59 -------------------LR------------------- 
2016-12-11 03:10:59 0.00390625 
2016-12-11 03:10:59 Epoch 112 
2016-12-11 03:16:13 Training Error = 0.3572 
2016-12-11 03:16:13 Training Loss = 0.02696421999783 
2016-12-11 03:16:18 Valid Error = 0.45369073814763 
2016-12-11 03:16:18 Valid Loss = 0.027292146215789 
2016-12-11 03:16:42 Test Error = 0.4544 
2016-12-11 03:16:42 Test Loss = 0.027275722069834 
2016-12-11 03:16:42 -------------------LR------------------- 
2016-12-11 03:16:42 0.00390625 
2016-12-11 03:16:42 Epoch 113 
2016-12-11 03:22:11 Training Error = 0.35684444444444 
2016-12-11 03:22:11 Training Loss = 0.027012371744792 
2016-12-11 03:22:16 Valid Error = 0.4626925385077 
2016-12-11 03:22:16 Valid Loss = 0.027736484898905 
2016-12-11 03:22:40 Test Error = 0.4607 
2016-12-11 03:22:40 Test Loss = 0.027760604858398 
2016-12-11 03:22:40 -------------------LR------------------- 
2016-12-11 03:22:40 0.00390625 
2016-12-11 03:22:40 Epoch 114 
2016-12-11 03:28:04 Training Error = 0.3562 
2016-12-11 03:28:04 Training Loss = 0.026933020996094 
2016-12-11 03:28:09 Valid Error = 0.46389277855571 
2016-12-11 03:28:09 Valid Loss = 0.027999321531704 
2016-12-11 03:28:36 Test Error = 0.4644 
2016-12-11 03:28:36 Test Loss = 0.027965748087565 
2016-12-11 03:28:36 -------------------LR------------------- 
2016-12-11 03:28:36 0.00390625 
2016-12-11 03:28:37 Epoch 115 
2016-12-11 03:33:52 Training Error = 0.35502222222222 
2016-12-11 03:33:52 Training Loss = 0.026988833875868 
2016-12-11 03:33:57 Valid Error = 0.45429085817163 
2016-12-11 03:33:57 Valid Loss = 0.027621593577152 
2016-12-11 03:34:17 Test Error = 0.4551 
2016-12-11 03:34:17 Test Loss = 0.027668672269933 
2016-12-11 03:34:17 -------------------LR------------------- 
2016-12-11 03:34:17 0.00390625 
2016-12-11 03:34:17 Epoch 116 
2016-12-11 03:39:41 Training Error = 0.35355555555556 
2016-12-11 03:39:41 Training Loss = 0.026894605007595 
2016-12-11 03:39:46 Valid Error = 0.46149229845969 
2016-12-11 03:39:46 Valid Loss = 0.02762654146542 
2016-12-11 03:40:10 Test Error = 0.4612 
2016-12-11 03:40:10 Test Loss = 0.02762300492829 
2016-12-11 03:40:10 -------------------LR------------------- 
2016-12-11 03:40:10 0.00390625 
2016-12-11 03:40:10 Epoch 117 
2016-12-11 03:45:44 Training Error = 0.35331111111111 
2016-12-11 03:45:44 Training Loss = 0.026877147379557 
2016-12-11 03:45:49 Valid Error = 0.46149229845969 
2016-12-11 03:45:49 Valid Loss = 0.027973519884397 
2016-12-11 03:46:12 Test Error = 0.465 
2016-12-11 03:46:12 Test Loss = 0.027863264495251 
2016-12-11 03:46:12 -------------------LR------------------- 
2016-12-11 03:46:12 0.00390625 
2016-12-11 03:46:12 Epoch 118 
2016-12-11 03:51:22 Training Error = 0.35542222222222 
2016-12-11 03:51:22 Training Loss = 0.026926892903646 
2016-12-11 03:51:26 Valid Error = 0.45449089817964 
2016-12-11 03:51:26 Valid Loss = 0.027530760004586 
2016-12-11 03:51:51 Test Error = 0.4551 
2016-12-11 03:51:51 Test Loss = 0.02733867558498 
2016-12-11 03:51:51 -------------------LR------------------- 
2016-12-11 03:51:51 0.00390625 
2016-12-11 03:51:51 Epoch 119 
2016-12-11 03:57:14 Training Error = 0.3524 
2016-12-11 03:57:14 Training Loss = 0.026862722005208 
2016-12-11 03:57:19 Valid Error = 0.45229045809162 
2016-12-11 03:57:19 Valid Loss = 0.027490980762373 
2016-12-11 03:57:46 Test Error = 0.4566 
2016-12-11 03:57:46 Test Loss = 0.027522942097982 
2016-12-11 03:57:46 -------------------LR------------------- 
2016-12-11 03:57:46 0.00390625 
2016-12-11 03:57:46 Epoch 120 
2016-12-11 04:02:54 Training Error = 0.35253333333333 
2016-12-11 04:02:54 Training Loss = 0.026844391248915 
2016-12-11 04:02:59 Valid Error = 0.44708941788358 
2016-12-11 04:02:59 Valid Loss = 0.027349995455022 
2016-12-11 04:03:19 Test Error = 0.456 
2016-12-11 04:03:19 Test Loss = 0.027345543715533 
2016-12-11 04:03:19 -------------------LR------------------- 
2016-12-11 04:03:19 0.00390625 
2016-12-11 04:03:20 Epoch 121 
2016-12-11 04:08:47 Training Error = 0.34937777777778 
2016-12-11 04:08:47 Training Loss = 0.026868032226563 
2016-12-11 04:08:52 Valid Error = 0.44788957791558 
2016-12-11 04:08:52 Valid Loss = 0.02717410397369 
2016-12-11 04:09:16 Test Error = 0.4534 
2016-12-11 04:09:16 Test Loss = 0.027249966251149 
2016-12-11 04:09:16 -------------------LR------------------- 
2016-12-11 04:09:16 0.00390625 
2016-12-11 04:09:16 Epoch 122 
2016-12-11 04:14:39 Training Error = 0.3474 
2016-12-11 04:14:39 Training Loss = 0.026779927842882 
2016-12-11 04:14:44 Valid Error = 0.45689137827566 
2016-12-11 04:14:44 Valid Loss = 0.027878988835462 
2016-12-11 04:15:08 Test Error = 0.4674 
2016-12-11 04:15:08 Test Loss = 0.027732371969784 
2016-12-11 04:15:08 -------------------LR------------------- 
2016-12-11 04:15:08 0.00390625 
2016-12-11 04:15:08 Epoch 123 
2016-12-11 04:20:29 Training Error = 0.35004444444444 
2016-12-11 04:20:29 Training Loss = 0.026808014675564 
2016-12-11 04:20:34 Valid Error = 0.47349469893979 
2016-12-11 04:20:34 Valid Loss = 0.028073830480982 
2016-12-11 04:20:58 Test Error = 0.4675 
2016-12-11 04:20:58 Test Loss = 0.028035848340801 
2016-12-11 04:20:58 -------------------LR------------------- 
2016-12-11 04:20:58 0.00390625 
2016-12-11 04:20:58 Epoch 124 
2016-12-11 04:26:30 Training Error = 0.34995555555556 
2016-12-11 04:26:30 Training Loss = 0.026805034966363 
2016-12-11 04:26:35 Valid Error = 0.44768953790758 
2016-12-11 04:26:35 Valid Loss = 0.027480360196481 
2016-12-11 04:27:00 Test Error = 0.4487 
2016-12-11 04:27:00 Test Loss = 0.027295470054477 
2016-12-11 04:27:00 -------------------LR------------------- 
2016-12-11 04:27:00 0.00390625 
2016-12-11 04:27:00 Epoch 125 
2016-12-11 04:32:14 Training Error = 0.34662222222222 
2016-12-11 04:32:14 Training Loss = 0.026734148220486 
2016-12-11 04:32:19 Valid Error = 0.45309061812362 
2016-12-11 04:32:19 Valid Loss = 0.027531533305134 
2016-12-11 04:32:46 Test Error = 0.4527 
2016-12-11 04:32:46 Test Loss = 0.027389984729243 
2016-12-11 04:32:46 -------------------LR------------------- 
2016-12-11 04:32:46 0.00390625 
2016-12-11 04:32:46 Epoch 126 
2016-12-11 04:38:16 Training Error = 0.34722222222222 
2016-12-11 04:38:16 Training Loss = 0.02679438655599 
2016-12-11 04:38:21 Valid Error = 0.44308861772354 
2016-12-11 04:38:21 Valid Loss = 0.027113291002221 
2016-12-11 04:38:41 Test Error = 0.4492 
2016-12-11 04:38:41 Test Loss = 0.027144725006702 
2016-12-11 04:38:41 -------------------LR------------------- 
2016-12-11 04:38:41 0.00390625 
2016-12-11 04:38:41 Epoch 127 
2016-12-11 04:44:00 Training Error = 0.34671111111111 
2016-12-11 04:44:00 Training Loss = 0.026749973687066 
2016-12-11 04:44:05 Valid Error = 0.44888977795559 
2016-12-11 04:44:05 Valid Loss = 0.027306168010917 
2016-12-11 04:44:29 Test Error = 0.4475 
2016-12-11 04:44:29 Test Loss = 0.027378542971144 
2016-12-11 04:44:29 -------------------LR------------------- 
2016-12-11 04:44:29 0.00390625 
2016-12-11 04:44:29 Epoch 128 
2016-12-11 04:49:45 Training Error = 0.34524444444444 
2016-12-11 04:49:45 Training Loss = 0.026728062093099 
2016-12-11 04:49:50 Valid Error = 0.43668733746749 
2016-12-11 04:49:50 Valid Loss = 0.027438083386133 
2016-12-11 04:50:15 Test Error = 0.4489 
2016-12-11 04:50:15 Test Loss = 0.027573237579944 
2016-12-11 04:50:15 -------------------LR------------------- 
2016-12-11 04:50:15 0.00390625 
2016-12-11 04:50:15 Epoch 129 
2016-12-11 04:55:44 Training Error = 0.34468888888889 
2016-12-11 04:55:44 Training Loss = 0.026727307481554 
2016-12-11 04:55:49 Valid Error = 0.45889177835567 
2016-12-11 04:55:49 Valid Loss = 0.02779991889015 
2016-12-11 04:56:14 Test Error = 0.4599 
2016-12-11 04:56:14 Test Loss = 0.027631654327991 
2016-12-11 04:56:14 -------------------LR------------------- 
2016-12-11 04:56:14 0.00390625 
2016-12-11 04:56:14 Epoch 130 
2016-12-11 05:01:27 Training Error = 0.34815555555556 
2016-12-11 05:01:27 Training Loss = 0.026804194797092 
2016-12-11 05:01:32 Valid Error = 0.45309061812362 
2016-12-11 05:01:32 Valid Loss = 0.027711723109816 
2016-12-11 05:01:59 Test Error = 0.4609 
2016-12-11 05:01:59 Test Loss = 0.027758625584023 
2016-12-11 05:01:59 -------------------LR------------------- 
2016-12-11 05:01:59 0.00390625 
2016-12-11 05:01:59 Epoch 131 
2016-12-11 05:07:03 Training Error = 0.34448888888889 
2016-12-11 05:07:03 Training Loss = 0.026735155192057 
2016-12-11 05:07:08 Valid Error = 0.4622924584917 
2016-12-11 05:07:08 Valid Loss = 0.028097826001117 
2016-12-11 05:07:35 Test Error = 0.4613 
2016-12-11 05:07:35 Test Loss = 0.02799268170525 
2016-12-11 05:07:35 -------------------LR------------------- 
2016-12-11 05:07:35 0.00390625 
2016-12-11 05:07:35 Epoch 132 
2016-12-11 05:13:08 Training Error = 0.3448 
2016-12-11 05:13:08 Training Loss = 0.026728333875868 
2016-12-11 05:13:13 Valid Error = 0.44608921784357 
2016-12-11 05:13:13 Valid Loss = 0.02726845467186 
2016-12-11 05:13:34 Test Error = 0.453 
2016-12-11 05:13:34 Test Loss = 0.027338659967161 
2016-12-11 05:13:34 -------------------LR------------------- 
2016-12-11 05:13:34 0.00390625 
2016-12-11 05:13:34 Epoch 133 
2016-12-11 05:18:46 Training Error = 0.33928888888889 
2016-12-11 05:18:46 Training Loss = 0.026648820638021 
2016-12-11 05:18:50 Valid Error = 0.45469093818764 
2016-12-11 05:18:50 Valid Loss = 0.027768046908624 
2016-12-11 05:19:15 Test Error = 0.4587 
2016-12-11 05:19:15 Test Loss = 0.027706495098039 
2016-12-11 05:19:15 -------------------LR------------------- 
2016-12-11 05:19:15 0.00390625 
2016-12-11 05:19:15 Epoch 134 
2016-12-11 05:24:45 Training Error = 0.34202222222222 
2016-12-11 05:24:45 Training Loss = 0.026701432318793 
2016-12-11 05:24:50 Valid Error = 0.4500900180036 
2016-12-11 05:24:50 Valid Loss = 0.027447085542322 
2016-12-11 05:25:14 Test Error = 0.4479 
2016-12-11 05:25:14 Test Loss = 0.027442912382238 
2016-12-11 05:25:14 -------------------LR------------------- 
2016-12-11 05:25:14 0.00390625 
2016-12-11 05:25:14 Epoch 135 
2016-12-11 05:30:41 Training Error = 0.34335555555556 
2016-12-11 05:30:41 Training Loss = 0.026660890001085 
2016-12-11 05:30:46 Valid Error = 0.45229045809162 
2016-12-11 05:30:46 Valid Loss = 0.027624125675079 
2016-12-11 05:31:10 Test Error = 0.4548 
2016-12-11 05:31:10 Test Loss = 0.027584848979875 
2016-12-11 05:31:10 -------------------LR------------------- 
2016-12-11 05:31:10 0.00390625 
2016-12-11 05:31:10 Epoch 136 
2016-12-11 05:36:27 Training Error = 0.34246666666667 
2016-12-11 05:36:27 Training Loss = 0.026689294976128 
2016-12-11 05:36:32 Valid Error = 0.4498899779956 
2016-12-11 05:36:32 Valid Loss = 0.027175444027638 
2016-12-11 05:36:57 Test Error = 0.4559 
2016-12-11 05:36:57 Test Loss = 0.027212119846718 
2016-12-11 05:36:57 -------------------LR------------------- 
2016-12-11 05:36:57 0.00390625 
2016-12-11 05:36:57 Epoch 137 
2016-12-11 05:42:15 Training Error = 0.34093333333333 
2016-12-11 05:42:15 Training Loss = 0.026664251302083 
2016-12-11 05:42:20 Valid Error = 0.4496899379876 
2016-12-11 05:42:20 Valid Loss = 0.027516603113086 
2016-12-11 05:42:47 Test Error = 0.4522 
2016-12-11 05:42:47 Test Loss = 0.027441265569949 
2016-12-11 05:42:47 -------------------LR------------------- 
2016-12-11 05:42:47 0.00390625 
2016-12-11 05:42:47 Epoch 138 
2016-12-11 05:48:11 Training Error = 0.33953333333333 
2016-12-11 05:48:11 Training Loss = 0.026619441351997 
2016-12-11 05:48:16 Valid Error = 0.45069013802761 
2016-12-11 05:48:16 Valid Loss = 0.027615365222879 
2016-12-11 05:48:42 Test Error = 0.4551 
2016-12-11 05:48:42 Test Loss = 0.027602988688151 
2016-12-11 05:48:42 -------------------LR------------------- 
2016-12-11 05:48:42 0.00390625 
2016-12-11 05:48:42 Epoch 139 
2016-12-11 05:54:12 Training Error = 0.34146666666667 
2016-12-11 05:54:12 Training Loss = 0.026673050998264 
2016-12-11 05:54:17 Valid Error = 0.45249049809962 
2016-12-11 05:54:17 Valid Loss = 0.027694902936267 
2016-12-11 05:54:37 Test Error = 0.4541 
2016-12-11 05:54:37 Test Loss = 0.027644548483456 
2016-12-11 05:54:37 -------------------LR------------------- 
2016-12-11 05:54:37 0.00390625 
2016-12-11 05:54:37 Epoch 140 
2016-12-11 06:00:06 Training Error = 0.34024444444444 
2016-12-11 06:00:06 Training Loss = 0.026614124511719 
2016-12-11 06:00:11 Valid Error = 0.4626925385077 
2016-12-11 06:00:11 Valid Loss = 0.028218873422105 
2016-12-11 06:00:35 Test Error = 0.4651 
2016-12-11 06:00:35 Test Loss = 0.02828689994064 
2016-12-11 06:00:35 -------------------LR------------------- 
2016-12-11 06:00:35 0.00390625 
2016-12-11 06:00:35 Epoch 141 
2016-12-11 06:05:48 Training Error = 0.34011111111111 
2016-12-11 06:05:48 Training Loss = 0.026640659261068 
2016-12-11 06:05:53 Valid Error = 0.44028805761152 
2016-12-11 06:05:53 Valid Loss = 0.026966487438231 
2016-12-11 06:06:16 Test Error = 0.4464 
2016-12-11 06:06:16 Test Loss = 0.027060390337776 
2016-12-11 06:06:16 -------------------LR------------------- 
2016-12-11 06:06:16 0.00390625 
2016-12-11 06:06:16 Epoch 142 
2016-12-11 06:11:40 Training Error = 0.33986666666667 
2016-12-11 06:11:40 Training Loss = 0.026638158013238 
2016-12-11 06:11:45 Valid Error = 0.4370874174835 
2016-12-11 06:11:45 Valid Loss = 0.027051635120817 
2016-12-11 06:12:10 Test Error = 0.4395 
2016-12-11 06:12:10 Test Loss = 0.026982910275927 
2016-12-11 06:12:10 -------------------LR------------------- 
2016-12-11 06:12:10 0.00390625 
2016-12-11 06:12:10 Epoch 143 
2016-12-11 06:17:29 Training Error = 0.34055555555556 
2016-12-11 06:17:29 Training Loss = 0.026594941460503 
2016-12-11 06:17:34 Valid Error = 0.44168833766753 
2016-12-11 06:17:34 Valid Loss = 0.026915954409226 
2016-12-11 06:17:59 Test Error = 0.4445 
2016-12-11 06:17:59 Test Loss = 0.026898494825176 
2016-12-11 06:17:59 -------------------LR------------------- 
2016-12-11 06:17:59 0.00390625 
2016-12-11 06:17:59 Epoch 144 
2016-12-11 06:23:11 Training Error = 0.34242222222222 
2016-12-11 06:23:11 Training Loss = 0.026616501112196 
2016-12-11 06:23:16 Valid Error = 0.43988797759552 
2016-12-11 06:23:16 Valid Loss = 0.027298630288396 
2016-12-11 06:23:43 Test Error = 0.446 
2016-12-11 06:23:43 Test Loss = 0.027462260825961 
2016-12-11 06:23:43 -------------------LR------------------- 
2016-12-11 06:23:43 0.00390625 
2016-12-11 06:23:43 Epoch 145 
2016-12-11 06:29:08 Training Error = 0.34111111111111 
2016-12-11 06:29:08 Training Loss = 0.026609223768446 
2016-12-11 06:29:13 Valid Error = 0.44028805761152 
2016-12-11 06:29:13 Valid Loss = 0.027026524653205 
2016-12-11 06:29:40 Test Error = 0.4451 
2016-12-11 06:29:40 Test Loss = 0.026995892992207 
2016-12-11 06:29:40 -------------------LR------------------- 
2016-12-11 06:29:40 0.00390625 
2016-12-11 06:29:40 Epoch 146 
2016-12-11 06:34:50 Training Error = 0.33648888888889 
2016-12-11 06:34:50 Training Loss = 0.026564423719618 
2016-12-11 06:34:55 Valid Error = 0.45469093818764 
2016-12-11 06:34:55 Valid Loss = 0.027782022494017 
2016-12-11 06:35:16 Test Error = 0.4598 
2016-12-11 06:35:16 Test Loss = 0.027772558653588 
2016-12-11 06:35:16 -------------------LR------------------- 
2016-12-11 06:35:16 0.00390625 
2016-12-11 06:35:16 Epoch 147 
2016-12-11 06:40:48 Training Error = 0.33957777777778 
2016-12-11 06:40:48 Training Loss = 0.026593317545573 
2016-12-11 06:40:53 Valid Error = 0.45709141828366 
2016-12-11 06:40:53 Valid Loss = 0.027896330789736 
2016-12-11 06:41:18 Test Error = 0.4545 
2016-12-11 06:41:18 Test Loss = 0.027688921281403 
2016-12-11 06:41:18 -------------------LR------------------- 
2016-12-11 06:41:18 0.00390625 
2016-12-11 06:41:18 Epoch 148 
2016-12-11 06:46:44 Training Error = 0.33764444444444 
2016-12-11 06:46:44 Training Loss = 0.026569629828559 
2016-12-11 06:46:49 Valid Error = 0.43988797759552 
2016-12-11 06:46:49 Valid Loss = 0.027176159679328 
2016-12-11 06:47:14 Test Error = 0.4529 
2016-12-11 06:47:14 Test Loss = 0.027114937456916 
2016-12-11 06:47:14 -------------------LR------------------- 
2016-12-11 06:47:14 0.00390625 
2016-12-11 06:47:14 Epoch 149 
2016-12-11 06:52:24 Training Error = 0.34075555555556 
2016-12-11 06:52:24 Training Loss = 0.026630106363932 
2016-12-11 06:52:29 Valid Error = 0.44788957791558 
2016-12-11 06:52:29 Valid Loss = 0.027707270795665 
2016-12-11 06:52:53 Test Error = 0.4555 
2016-12-11 06:52:53 Test Loss = 0.027741532568838 
2016-12-11 06:52:53 -------------------LR------------------- 
2016-12-11 06:52:53 0.00390625 
2016-12-11 06:52:53 Epoch 150 
2016-12-11 06:58:25 Training Error = 0.33977777777778 
2016-12-11 06:58:25 Training Loss = 0.026629102647569 
2016-12-11 06:58:30 Valid Error = 0.44608921784357 
2016-12-11 06:58:30 Valid Loss = 0.027614112405016 
2016-12-11 06:58:54 Test Error = 0.4479 
2016-12-11 06:58:54 Test Loss = 0.027512247661516 
2016-12-11 06:58:54 -------------------LR------------------- 
2016-12-11 06:58:54 0.001953125 
2016-12-11 06:58:54 Epoch 151 
2016-12-11 07:04:17 Training Error = 0.32282222222222 
2016-12-11 07:04:17 Training Loss = 0.026035532850477 
2016-12-11 07:04:22 Valid Error = 0.42868573714743 
2016-12-11 07:04:22 Valid Loss = 0.026983896507321 
2016-12-11 07:04:46 Test Error = 0.4359 
2016-12-11 07:04:46 Test Loss = 0.026993755445293 
2016-12-11 07:04:46 -------------------LR------------------- 
2016-12-11 07:04:46 0.001953125 
2016-12-11 07:04:46 Epoch 152 
2016-12-11 07:10:11 Training Error = 0.318 
2016-12-11 07:10:11 Training Loss = 0.02594552883572 
2016-12-11 07:10:16 Valid Error = 0.44428885777155 
2016-12-11 07:10:16 Valid Loss = 0.027129576313325 
2016-12-11 07:10:41 Test Error = 0.4471 
2016-12-11 07:10:41 Test Loss = 0.027206461768057 
2016-12-11 07:10:41 -------------------LR------------------- 
2016-12-11 07:10:41 0.001953125 
2016-12-11 07:10:41 Epoch 153 
2016-12-11 07:16:08 Training Error = 0.31473333333333 
2016-12-11 07:16:08 Training Loss = 0.025839894476997 
2016-12-11 07:16:13 Valid Error = 0.44648929785957 
2016-12-11 07:16:13 Valid Loss = 0.027395388813825 
2016-12-11 07:16:37 Test Error = 0.4439 
2016-12-11 07:16:37 Test Loss = 0.027291172042547 
2016-12-11 07:16:37 -------------------LR------------------- 
2016-12-11 07:16:37 0.001953125 
2016-12-11 07:16:37 Epoch 154 
2016-12-11 07:21:46 Training Error = 0.31673333333333 
2016-12-11 07:21:46 Training Loss = 0.025887557074653 
2016-12-11 07:21:51 Valid Error = 0.43628725745149 
2016-12-11 07:21:51 Valid Loss = 0.026808709474837 
2016-12-11 07:22:15 Test Error = 0.4366 
2016-12-11 07:22:15 Test Loss = 0.026846581373028 
2016-12-11 07:22:15 -------------------LR------------------- 
2016-12-11 07:22:15 0.001953125 
2016-12-11 07:22:15 Epoch 155 
2016-12-11 07:27:39 Training Error = 0.3136 
2016-12-11 07:27:39 Training Loss = 0.025897095594618 
2016-12-11 07:27:44 Valid Error = 0.43968793758752 
2016-12-11 07:27:44 Valid Loss = 0.027155004085368 
2016-12-11 07:28:09 Test Error = 0.4446 
2016-12-11 07:28:09 Test Loss = 0.02722047549977 
2016-12-11 07:28:09 -------------------LR------------------- 
2016-12-11 07:28:09 0.001953125 
2016-12-11 07:28:09 Epoch 156 
2016-12-11 07:33:37 Training Error = 0.311 
2016-12-11 07:33:37 Training Loss = 0.025778606363932 
2016-12-11 07:33:42 Valid Error = 0.43428685737147 
2016-12-11 07:33:42 Valid Loss = 0.027074719660859 
2016-12-11 07:34:08 Test Error = 0.4397 
2016-12-11 07:34:08 Test Loss = 0.027064284320906 
2016-12-11 07:34:08 -------------------LR------------------- 
2016-12-11 07:34:08 0.001953125 
2016-12-11 07:34:09 Epoch 157 
2016-12-11 07:39:26 Training Error = 0.30882222222222 
2016-12-11 07:39:26 Training Loss = 0.025755644070095 
2016-12-11 07:39:31 Valid Error = 0.43168633726745 
2016-12-11 07:39:31 Valid Loss = 0.026958129734002 
2016-12-11 07:39:57 Test Error = 0.4383 
2016-12-11 07:39:57 Test Loss = 0.026994759712967 
2016-12-11 07:39:57 -------------------LR------------------- 
2016-12-11 07:39:57 0.001953125 
2016-12-11 07:39:57 Epoch 158 
2016-12-11 07:45:28 Training Error = 0.308 
2016-12-11 07:45:28 Training Loss = 0.0257635234375 
2016-12-11 07:45:33 Valid Error = 0.44528905781156 
2016-12-11 07:45:33 Valid Loss = 0.027393796758405 
2016-12-11 07:45:53 Test Error = 0.4487 
2016-12-11 07:45:53 Test Loss = 0.027565750241747 
2016-12-11 07:45:53 -------------------LR------------------- 
2016-12-11 07:45:53 0.001953125 
2016-12-11 07:45:53 Epoch 159 
2016-12-11 07:51:08 Training Error = 0.31244444444444 
2016-12-11 07:51:08 Training Loss = 0.025746611056858 
2016-12-11 07:51:13 Valid Error = 0.44308861772354 
2016-12-11 07:51:13 Valid Loss = 0.027455105432354 
2016-12-11 07:51:37 Test Error = 0.4453 
2016-12-11 07:51:37 Test Loss = 0.02747422987994 
2016-12-11 07:51:37 -------------------LR------------------- 
2016-12-11 07:51:37 0.001953125 
2016-12-11 07:51:37 Epoch 160 
2016-12-11 07:57:02 Training Error = 0.30457777777778 
2016-12-11 07:57:02 Training Loss = 0.025687820041233 
2016-12-11 07:57:07 Valid Error = 0.43028605721144 
2016-12-11 07:57:07 Valid Loss = 0.026847325295868 
2016-12-11 07:57:32 Test Error = 0.4444 
2016-12-11 07:57:32 Test Loss = 0.026996655333276 
2016-12-11 07:57:32 -------------------LR------------------- 
2016-12-11 07:57:32 0.001953125 
2016-12-11 07:57:32 Epoch 161 
2016-12-11 08:02:58 Training Error = 0.30951111111111 
2016-12-11 08:02:58 Training Loss = 0.025757158338759 
2016-12-11 08:03:03 Valid Error = 0.43208641728346 
2016-12-11 08:03:03 Valid Loss = 0.026858727294649 
2016-12-11 08:03:27 Test Error = 0.4352 
2016-12-11 08:03:27 Test Loss = 0.026825353644876 
2016-12-11 08:03:27 -------------------LR------------------- 
2016-12-11 08:03:27 0.001953125 
2016-12-11 08:03:27 Epoch 162 
2016-12-11 08:08:53 Training Error = 0.30724444444444 
2016-12-11 08:08:53 Training Loss = 0.025759777994792 
2016-12-11 08:08:58 Valid Error = 0.42788557711542 
2016-12-11 08:08:58 Valid Loss = 0.027004309144509 
2016-12-11 08:09:22 Test Error = 0.4345 
2016-12-11 08:09:22 Test Loss = 0.026976990883023 
2016-12-11 08:09:22 -------------------LR------------------- 
2016-12-11 08:09:22 0.001953125 
2016-12-11 08:09:22 Epoch 163 
2016-12-11 08:14:43 Training Error = 0.30646666666667 
2016-12-11 08:14:43 Training Loss = 0.025681521294488 
2016-12-11 08:14:48 Valid Error = 0.43368673734747 
2016-12-11 08:14:48 Valid Loss = 0.027047314496292 
2016-12-11 08:15:12 Test Error = 0.4303 
2016-12-11 08:15:12 Test Loss = 0.026980811564128 
2016-12-11 08:15:12 -------------------LR------------------- 
2016-12-11 08:15:12 0.001953125 
2016-12-11 08:15:12 Epoch 164 
2016-12-11 08:20:33 Training Error = 0.30508888888889 
2016-12-11 08:20:33 Training Loss = 0.02565841921658 
2016-12-11 08:20:38 Valid Error = 0.43608721744349 
2016-12-11 08:20:38 Valid Loss = 0.027371219621236 
2016-12-11 08:21:03 Test Error = 0.4398 
2016-12-11 08:21:03 Test Loss = 0.027295714853324 
2016-12-11 08:21:03 -------------------LR------------------- 
2016-12-11 08:21:03 0.001953125 
2016-12-11 08:21:03 Epoch 165 
2016-12-11 08:26:28 Training Error = 0.30422222222222 
2016-12-11 08:26:28 Training Loss = 0.025667666937934 
2016-12-11 08:26:33 Valid Error = 0.43308661732346 
2016-12-11 08:26:33 Valid Loss = 0.027422747450587 
2016-12-11 08:26:58 Test Error = 0.4422 
2016-12-11 08:26:58 Test Loss = 0.027452805403167 
2016-12-11 08:26:58 -------------------LR------------------- 
2016-12-11 08:26:58 0.001953125 
2016-12-11 08:26:58 Epoch 166 
2016-12-11 08:32:27 Training Error = 0.30504444444444 
2016-12-11 08:32:27 Training Loss = 0.025700791259766 
2016-12-11 08:32:32 Valid Error = 0.43368673734747 
2016-12-11 08:32:32 Valid Loss = 0.027146655534708 
2016-12-11 08:32:56 Test Error = 0.4401 
2016-12-11 08:32:56 Test Loss = 0.027152981507544 
2016-12-11 08:32:56 -------------------LR------------------- 
2016-12-11 08:32:56 0.001953125 
2016-12-11 08:32:56 Epoch 167 
2016-12-11 08:38:08 Training Error = 0.30384444444444 
2016-12-11 08:38:08 Training Loss = 0.025692213568793 
2016-12-11 08:38:13 Valid Error = 0.44088817763553 
2016-12-11 08:38:13 Valid Loss = 0.027394043030092 
2016-12-11 08:38:38 Test Error = 0.4424 
2016-12-11 08:38:38 Test Loss = 0.02738804584578 
2016-12-11 08:38:38 -------------------LR------------------- 
2016-12-11 08:38:38 0.001953125 
2016-12-11 08:38:38 Epoch 168 
2016-12-11 08:44:14 Training Error = 0.30466666666667 
2016-12-11 08:44:14 Training Loss = 0.025658413655599 
2016-12-11 08:44:19 Valid Error = 0.42608521704341 
2016-12-11 08:44:19 Valid Loss = 0.026997295490537 
2016-12-11 08:44:43 Test Error = 0.4371 
2016-12-11 08:44:43 Test Loss = 0.027157562196021 
2016-12-11 08:44:43 -------------------LR------------------- 
2016-12-11 08:44:43 0.001953125 
2016-12-11 08:44:43 Epoch 169 
2016-12-11 08:50:04 Training Error = 0.30546666666667 
2016-12-11 08:50:04 Training Loss = 0.025678781629774 
2016-12-11 08:50:09 Valid Error = 0.4378875775155 
2016-12-11 08:50:09 Valid Loss = 0.027268894575961 
2016-12-11 08:50:33 Test Error = 0.4407 
2016-12-11 08:50:33 Test Loss = 0.027116281187768 
2016-12-11 08:50:33 -------------------LR------------------- 
2016-12-11 08:50:33 0.001953125 
2016-12-11 08:50:33 Epoch 170 
2016-12-11 08:56:03 Training Error = 0.30068888888889 
2016-12-11 08:56:03 Training Loss = 0.02560869930013 
2016-12-11 08:56:08 Valid Error = 0.44128825765153 
2016-12-11 08:56:08 Valid Loss = 0.027480770108954 
2016-12-11 08:56:32 Test Error = 0.4477 
2016-12-11 08:56:32 Test Loss = 0.027510287116556 
2016-12-11 08:56:32 -------------------LR------------------- 
2016-12-11 08:56:32 0.001953125 
2016-12-11 08:56:32 Epoch 171 
2016-12-11 09:01:51 Training Error = 0.30264444444444 
2016-12-11 09:01:51 Training Loss = 0.025627915690104 
2016-12-11 09:01:55 Valid Error = 0.44528905781156 
2016-12-11 09:01:55 Valid Loss = 0.027777522128737 
2016-12-11 09:02:20 Test Error = 0.444 
2016-12-11 09:02:20 Test Loss = 0.027506927191042 
2016-12-11 09:02:20 -------------------LR------------------- 
2016-12-11 09:02:20 0.001953125 
2016-12-11 09:02:20 Epoch 172 
2016-12-11 09:07:32 Training Error = 0.30144444444444 
2016-12-11 09:07:32 Training Loss = 0.025608795491536 
2016-12-11 09:07:37 Valid Error = 0.43508701740348 
2016-12-11 09:07:37 Valid Loss = 0.027464225353565 
2016-12-11 09:08:01 Test Error = 0.4445 
2016-12-11 09:08:01 Test Loss = 0.027544360231886 
2016-12-11 09:08:01 -------------------LR------------------- 
2016-12-11 09:08:01 0.001953125 
2016-12-11 09:08:01 Epoch 173 
2016-12-11 09:13:28 Training Error = 0.30135555555556 
2016-12-11 09:13:28 Training Loss = 0.025634429117839 
2016-12-11 09:13:33 Valid Error = 0.44508901780356 
2016-12-11 09:13:33 Valid Loss = 0.027642799912195 
2016-12-11 09:13:58 Test Error = 0.4547 
2016-12-11 09:13:58 Test Loss = 0.027684689809762 
2016-12-11 09:13:58 -------------------LR------------------- 
2016-12-11 09:13:58 0.001953125 
2016-12-11 09:13:58 Epoch 174 
2016-12-11 09:19:27 Training Error = 0.30164444444444 
2016-12-11 09:19:27 Training Loss = 0.025622667941623 
2016-12-11 09:19:31 Valid Error = 0.42608521704341 
2016-12-11 09:19:31 Valid Loss = 0.026819008102715 
2016-12-11 09:19:56 Test Error = 0.4368 
2016-12-11 09:19:56 Test Loss = 0.02685037949506 
2016-12-11 09:19:56 -------------------LR------------------- 
2016-12-11 09:19:56 0.001953125 
2016-12-11 09:19:56 Epoch 175 
2016-12-11 09:25:12 Training Error = 0.30071111111111 
2016-12-11 09:25:12 Training Loss = 0.025612812798394 
2016-12-11 09:25:17 Valid Error = 0.43868773754751 
2016-12-11 09:25:17 Valid Loss = 0.027238154316641 
2016-12-11 09:25:41 Test Error = 0.4463 
2016-12-11 09:25:41 Test Loss = 0.027303061571308 
2016-12-11 09:25:41 -------------------LR------------------- 
2016-12-11 09:25:41 0.001953125 
2016-12-11 09:25:41 Epoch 176 
2016-12-11 09:31:09 Training Error = 0.30451111111111 
2016-12-11 09:31:09 Training Loss = 0.025662150878906 
2016-12-11 09:31:14 Valid Error = 0.42568513702741 
2016-12-11 09:31:14 Valid Loss = 0.027043860560761 
2016-12-11 09:31:38 Test Error = 0.4292 
2016-12-11 09:31:38 Test Loss = 0.027039118329216 
2016-12-11 09:31:38 -------------------LR------------------- 
2016-12-11 09:31:38 0.001953125 
2016-12-11 09:31:38 Epoch 177 
2016-12-11 09:36:55 Training Error = 0.3012 
2016-12-11 09:36:55 Training Loss = 0.025645803493924 
2016-12-11 09:37:00 Valid Error = 0.43308661732346 
2016-12-11 09:37:00 Valid Loss = 0.027173747165097 
2016-12-11 09:37:25 Test Error = 0.4388 
2016-12-11 09:37:25 Test Loss = 0.027140433936026 
2016-12-11 09:37:25 -------------------LR------------------- 
2016-12-11 09:37:25 0.001953125 
2016-12-11 09:37:25 Epoch 178 
2016-12-11 09:42:39 Training Error = 0.30111111111111 
2016-12-11 09:42:39 Training Loss = 0.025635007622613 
2016-12-11 09:42:44 Valid Error = 0.44208841768354 
2016-12-11 09:42:44 Valid Loss = 0.02724144269502 
2016-12-11 09:43:08 Test Error = 0.4414 
2016-12-11 09:43:08 Test Loss = 0.027117099298215 
2016-12-11 09:43:08 -------------------LR------------------- 
2016-12-11 09:43:08 0.001953125 
2016-12-11 09:43:08 Epoch 179 
2016-12-11 09:48:40 Training Error = 0.29811111111111 
2016-12-11 09:48:40 Training Loss = 0.025577030815972 
2016-12-11 09:48:45 Valid Error = 0.43048609721944 
2016-12-11 09:48:45 Valid Loss = 0.027266087953875 
2016-12-11 09:49:09 Test Error = 0.4391 
2016-12-11 09:49:09 Test Loss = 0.027227855128868 
2016-12-11 09:49:09 -------------------LR------------------- 
2016-12-11 09:49:09 0.001953125 
2016-12-11 09:49:09 Epoch 180 
2016-12-11 09:54:29 Training Error = 0.298 
2016-12-11 09:54:29 Training Loss = 0.025602784613715 
2016-12-11 09:54:34 Valid Error = 0.4376875375075 
2016-12-11 09:54:34 Valid Loss = 0.027607175443143 
2016-12-11 09:54:59 Test Error = 0.445 
2016-12-11 09:54:59 Test Loss = 0.027747616397633 
2016-12-11 09:54:59 -------------------LR------------------- 
2016-12-11 09:54:59 0.001953125 
2016-12-11 09:54:59 Epoch 181 
2016-12-11 10:00:27 Training Error = 0.2968 
2016-12-11 10:00:27 Training Loss = 0.025534942545573 
2016-12-11 10:00:32 Valid Error = 0.44028805761152 
2016-12-11 10:00:32 Valid Loss = 0.027107680016338 
2016-12-11 10:00:57 Test Error = 0.4375 
2016-12-11 10:00:57 Test Loss = 0.027208906046549 
2016-12-11 10:00:57 -------------------LR------------------- 
2016-12-11 10:00:57 0.001953125 
2016-12-11 10:00:57 Epoch 182 
2016-12-11 10:06:16 Training Error = 0.29684444444444 
2016-12-11 10:06:16 Training Loss = 0.025507038438585 
2016-12-11 10:06:21 Valid Error = 0.42348469693939 
2016-12-11 10:06:21 Valid Loss = 0.026837536867597 
2016-12-11 10:06:45 Test Error = 0.4297 
2016-12-11 10:06:45 Test Loss = 0.026698299512676 
2016-12-11 10:06:45 -------------------LR------------------- 
2016-12-11 10:06:45 0.001953125 
2016-12-11 10:06:46 Epoch 183 
2016-12-11 10:12:14 Training Error = 0.29673333333333 
2016-12-11 10:12:14 Training Loss = 0.025543690185547 
2016-12-11 10:12:19 Valid Error = 0.41408281656331 
2016-12-11 10:12:19 Valid Loss = 0.026474158942817 
2016-12-11 10:12:44 Test Error = 0.421 
2016-12-11 10:12:44 Test Loss = 0.02642363652248 
2016-12-11 10:12:44 -------------------LR------------------- 
2016-12-11 10:12:44 0.001953125 
2016-12-11 10:12:44 Epoch 184 
2016-12-11 10:18:12 Training Error = 0.29651111111111 
2016-12-11 10:18:12 Training Loss = 0.025519119384766 
2016-12-11 10:18:17 Valid Error = 0.42108421684337 
2016-12-11 10:18:17 Valid Loss = 0.026979946187735 
2016-12-11 10:18:41 Test Error = 0.4289 
2016-12-11 10:18:41 Test Loss = 0.027044819312002 
2016-12-11 10:18:41 -------------------LR------------------- 
2016-12-11 10:18:41 0.001953125 
2016-12-11 10:18:41 Epoch 185 
2016-12-11 10:24:02 Training Error = 0.29655555555556 
2016-12-11 10:24:02 Training Loss = 0.02551810804579 
2016-12-11 10:24:07 Valid Error = 0.4378875775155 
2016-12-11 10:24:07 Valid Loss = 0.027940961987218 
2016-12-11 10:24:32 Test Error = 0.445 
2016-12-11 10:24:32 Test Loss = 0.027842119762944 
2016-12-11 10:24:32 -------------------LR------------------- 
2016-12-11 10:24:32 0.001953125 
2016-12-11 10:24:32 Epoch 186 
2016-12-11 10:30:01 Training Error = 0.29653333333333 
2016-12-11 10:30:01 Training Loss = 0.025558988416884 
2016-12-11 10:30:06 Valid Error = 0.43268653730746 
2016-12-11 10:30:06 Valid Loss = 0.027325480697578 
2016-12-11 10:30:31 Test Error = 0.4334 
2016-12-11 10:30:31 Test Loss = 0.027167347268497 
2016-12-11 10:30:31 -------------------LR------------------- 
2016-12-11 10:30:31 0.001953125 
2016-12-11 10:30:31 Epoch 187 
2016-12-11 10:35:53 Training Error = 0.29862222222222 
2016-12-11 10:35:53 Training Loss = 0.025584295735677 
2016-12-11 10:35:58 Valid Error = 0.42828565713143 
2016-12-11 10:35:58 Valid Loss = 0.026977525170839 
2016-12-11 10:36:22 Test Error = 0.435 
2016-12-11 10:36:22 Test Loss = 0.026994913138595 
2016-12-11 10:36:22 -------------------LR------------------- 
2016-12-11 10:36:22 0.001953125 
2016-12-11 10:36:22 Epoch 188 
2016-12-11 10:41:42 Training Error = 0.29546666666667 
2016-12-11 10:41:42 Training Loss = 0.025525445638021 
2016-12-11 10:41:47 Valid Error = 0.43488697739548 
2016-12-11 10:41:47 Valid Loss = 0.027374900610274 
2016-12-11 10:42:11 Test Error = 0.4338 
2016-12-11 10:42:11 Test Loss = 0.027248224954044 
2016-12-11 10:42:11 -------------------LR------------------- 
2016-12-11 10:42:11 0.001953125 
2016-12-11 10:42:11 Epoch 189 
2016-12-11 10:47:41 Training Error = 0.29622222222222 
2016-12-11 10:47:41 Training Loss = 0.02557731499566 
2016-12-11 10:47:46 Valid Error = 0.43408681736347 
2016-12-11 10:47:46 Valid Loss = 0.027097041192153 
2016-12-11 10:48:11 Test Error = 0.429 
2016-12-11 10:48:11 Test Loss = 0.026923274260876 
2016-12-11 10:48:11 -------------------LR------------------- 
2016-12-11 10:48:11 0.001953125 
2016-12-11 10:48:11 Epoch 190 
2016-12-11 10:53:25 Training Error = 0.29375555555556 
2016-12-11 10:53:25 Training Loss = 0.025506066297743 
2016-12-11 10:53:30 Valid Error = 0.43368673734747 
2016-12-11 10:53:30 Valid Loss = 0.027017133962183 
2016-12-11 10:53:55 Test Error = 0.4333 
2016-12-11 10:53:55 Test Loss = 0.026838115737017 
2016-12-11 10:53:55 -------------------LR------------------- 
2016-12-11 10:53:55 0.001953125 
2016-12-11 10:53:55 Epoch 191 
2016-12-11 10:59:23 Training Error = 0.29351111111111 
2016-12-11 10:59:23 Training Loss = 0.025458805230035 
2016-12-11 10:59:28 Valid Error = 0.43468693738748 
2016-12-11 10:59:28 Valid Loss = 0.027515543132465 
2016-12-11 10:59:53 Test Error = 0.4434 
2016-12-11 10:59:53 Test Loss = 0.027481539916992 
2016-12-11 10:59:53 -------------------LR------------------- 
2016-12-11 10:59:53 0.001953125 
2016-12-11 10:59:53 Epoch 192 
2016-12-11 11:05:24 Training Error = 0.29844444444444 
2016-12-11 11:05:24 Training Loss = 0.025557416503906 
2016-12-11 11:05:28 Valid Error = 0.44128825765153 
2016-12-11 11:05:28 Valid Loss = 0.027549761281314 
2016-12-11 11:05:53 Test Error = 0.4447 
2016-12-11 11:05:53 Test Loss = 0.027401326317881 
2016-12-11 11:05:53 -------------------LR------------------- 
2016-12-11 11:05:53 0.001953125 
2016-12-11 11:05:53 Epoch 193 
2016-12-11 11:11:02 Training Error = 0.29797777777778 
2016-12-11 11:11:02 Training Loss = 0.025541419840495 
2016-12-11 11:11:07 Valid Error = 0.43008601720344 
2016-12-11 11:11:07 Valid Loss = 0.02724614968583 
2016-12-11 11:11:31 Test Error = 0.4342 
2016-12-11 11:11:31 Test Loss = 0.027209061686198 
2016-12-11 11:11:31 -------------------LR------------------- 
2016-12-11 11:11:31 0.001953125 
2016-12-11 11:11:31 Epoch 194 
2016-12-11 11:16:57 Training Error = 0.29313333333333 
2016-12-11 11:16:57 Training Loss = 0.025491293348524 
2016-12-11 11:17:02 Valid Error = 0.43328665733147 
2016-12-11 11:17:02 Valid Loss = 0.027288375845972 
2016-12-11 11:17:26 Test Error = 0.4379 
2016-12-11 11:17:26 Test Loss = 0.027187101476333 
2016-12-11 11:17:26 -------------------LR------------------- 
2016-12-11 11:17:26 0.001953125 
2016-12-11 11:17:27 Epoch 195 
2016-12-11 11:22:35 Training Error = 0.29386666666667 
2016-12-11 11:22:35 Training Loss = 0.025464838623047 
2016-12-11 11:22:40 Valid Error = 0.43028605721144 
2016-12-11 11:22:40 Valid Loss = 0.027233538037955 
2016-12-11 11:23:05 Test Error = 0.4331 
2016-12-11 11:23:05 Test Loss = 0.027105677705653 
2016-12-11 11:23:05 -------------------LR------------------- 
2016-12-11 11:23:05 0.001953125 
2016-12-11 11:23:05 Epoch 196 
2016-12-11 11:28:30 Training Error = 0.29344444444444 
2016-12-11 11:28:30 Training Loss = 0.025432503363715 
2016-12-11 11:28:35 Valid Error = 0.44568913782757 
2016-12-11 11:28:35 Valid Loss = 0.027994964203159 
2016-12-11 11:28:59 Test Error = 0.4455 
2016-12-11 11:28:59 Test Loss = 0.027888960116517 
2016-12-11 11:28:59 -------------------LR------------------- 
2016-12-11 11:28:59 0.001953125 
2016-12-11 11:28:59 Epoch 197 
2016-12-11 11:34:35 Training Error = 0.29442222222222 
2016-12-11 11:34:35 Training Loss = 0.025475747748481 
2016-12-11 11:34:40 Valid Error = 0.42868573714743 
2016-12-11 11:34:40 Valid Loss = 0.026955816786706 
2016-12-11 11:35:04 Test Error = 0.4287 
2016-12-11 11:35:04 Test Loss = 0.026878492766736 
2016-12-11 11:35:04 -------------------LR------------------- 
2016-12-11 11:35:04 0.001953125 
2016-12-11 11:35:04 Epoch 198 
2016-12-11 11:40:30 Training Error = 0.29426666666667 
2016-12-11 11:40:30 Training Loss = 0.025528012152778 
2016-12-11 11:40:35 Valid Error = 0.4246849369874 
2016-12-11 11:40:35 Valid Loss = 0.027330115967251 
2016-12-11 11:40:59 Test Error = 0.4271 
2016-12-11 11:40:59 Test Loss = 0.027183340573778 
2016-12-11 11:40:59 -------------------LR------------------- 
2016-12-11 11:40:59 0.001953125 
2016-12-11 11:40:59 Epoch 199 
2016-12-11 11:46:24 Training Error = 0.29571111111111 
2016-12-11 11:46:24 Training Loss = 0.02553796077474 
2016-12-11 11:46:29 Valid Error = 0.44588917783557 
2016-12-11 11:46:29 Valid Loss = 0.028106758514978 
2016-12-11 11:46:53 Test Error = 0.447 
2016-12-11 11:46:53 Test Loss = 0.027909185372147 
2016-12-11 11:46:53 -------------------LR------------------- 
2016-12-11 11:46:53 0.001953125 
2016-12-11 11:46:53 Epoch 200 
2016-12-11 11:52:18 Training Error = 0.29475555555556 
2016-12-11 11:52:18 Training Loss = 0.025481209364149 
2016-12-11 11:52:23 Valid Error = 0.42648529705941 
2016-12-11 11:52:23 Valid Loss = 0.026885453408172 
2016-12-11 11:52:47 Test Error = 0.4303 
2016-12-11 11:52:47 Test Loss = 0.026914515955308 
2016-12-11 11:52:47 -------------------LR------------------- 
2016-12-11 11:52:47 0.0009765625 
2016-12-11 11:52:47 Epoch 201 
2016-12-11 11:58:12 Training Error = 0.28302222222222 
2016-12-11 11:58:12 Training Loss = 0.025032311387804 
2016-12-11 11:58:17 Valid Error = 0.43048609721944 
2016-12-11 11:58:17 Valid Loss = 0.027236025892492 
2016-12-11 11:58:41 Test Error = 0.4317 
2016-12-11 11:58:41 Test Loss = 0.027207065657073 
2016-12-11 11:58:41 -------------------LR------------------- 
2016-12-11 11:58:41 0.0009765625 
2016-12-11 11:58:41 Epoch 202 
2016-12-11 12:04:03 Training Error = 0.28024444444444 
2016-12-11 12:04:03 Training Loss = 0.025013841227214 
2016-12-11 12:04:08 Valid Error = 0.42808561712342 
2016-12-11 12:04:08 Valid Loss = 0.0273745942122 
2016-12-11 12:04:32 Test Error = 0.4297 
2016-12-11 12:04:32 Test Loss = 0.02727995743097 
2016-12-11 12:04:32 -------------------LR------------------- 
2016-12-11 12:04:32 0.0009765625 
2016-12-11 12:04:32 Epoch 203 
2016-12-11 12:09:47 Training Error = 0.27966666666667 
2016-12-11 12:09:47 Training Loss = 0.024979859266493 
2016-12-11 12:09:51 Valid Error = 0.41928385677135 
2016-12-11 12:09:51 Valid Loss = 0.026653714529407 
2016-12-11 12:10:16 Test Error = 0.4244 
2016-12-11 12:10:16 Test Loss = 0.02665991599887 
2016-12-11 12:10:16 -------------------LR------------------- 
2016-12-11 12:10:16 0.0009765625 
2016-12-11 12:10:16 Epoch 204 
2016-12-11 12:15:46 Training Error = 0.27768888888889 
2016-12-11 12:15:46 Training Loss = 0.024942888346354 
2016-12-11 12:15:51 Valid Error = 0.43448689737948 
2016-12-11 12:15:51 Valid Loss = 0.027372149546879 
2016-12-11 12:16:15 Test Error = 0.4365 
2016-12-11 12:16:15 Test Loss = 0.027216645962584 
2016-12-11 12:16:15 -------------------LR------------------- 
2016-12-11 12:16:15 0.0009765625 
2016-12-11 12:16:15 Epoch 205 
2016-12-11 12:21:41 Training Error = 0.2774 
2016-12-11 12:21:41 Training Loss = 0.024974918891059 
2016-12-11 12:21:46 Valid Error = 0.41908381676335 
2016-12-11 12:21:46 Valid Loss = 0.026742606427455 
2016-12-11 12:22:10 Test Error = 0.4212 
2016-12-11 12:22:10 Test Loss = 0.026518779141295 
2016-12-11 12:22:10 -------------------LR------------------- 
2016-12-11 12:22:10 0.0009765625 
2016-12-11 12:22:10 Epoch 206 
2016-12-11 12:27:29 Training Error = 0.27895555555556 
2016-12-11 12:27:29 Training Loss = 0.02495096359592 
2016-12-11 12:27:34 Valid Error = 0.43168633726745 
2016-12-11 12:27:34 Valid Loss = 0.027100255948934 
2016-12-11 12:27:58 Test Error = 0.4323 
2016-12-11 12:27:58 Test Loss = 0.026992085056679 
2016-12-11 12:27:58 -------------------LR------------------- 
2016-12-11 12:27:58 0.0009765625 
2016-12-11 12:27:58 Epoch 207 
2016-12-11 12:33:29 Training Error = 0.2756 
2016-12-11 12:33:29 Training Loss = 0.024948743869358 
2016-12-11 12:33:34 Valid Error = 0.42628525705141 
2016-12-11 12:33:34 Valid Loss = 0.027350028151372 
2016-12-11 12:33:59 Test Error = 0.4294 
2016-12-11 12:33:59 Test Loss = 0.02711544602338 
2016-12-11 12:33:59 -------------------LR------------------- 
2016-12-11 12:33:59 0.0009765625 
2016-12-11 12:33:59 Epoch 208 
2016-12-11 12:39:07 Training Error = 0.27513333333333 
2016-12-11 12:39:07 Training Loss = 0.024927549886068 
2016-12-11 12:39:12 Valid Error = 0.44488897779556 
2016-12-11 12:39:12 Valid Loss = 0.028009388219172 
2016-12-11 12:39:36 Test Error = 0.4509 
2016-12-11 12:39:36 Test Loss = 0.027900944967831 
2016-12-11 12:39:36 -------------------LR------------------- 
2016-12-11 12:39:36 0.0009765625 
2016-12-11 12:39:36 Epoch 209 
2016-12-11 12:45:12 Training Error = 0.27553333333333 
2016-12-11 12:45:12 Training Loss = 0.02490540375434 
2016-12-11 12:45:17 Valid Error = 0.41428285657131 
2016-12-11 12:45:17 Valid Loss = 0.026904102099809 
2016-12-11 12:45:41 Test Error = 0.425 
2016-12-11 12:45:41 Test Loss = 0.026936407530542 
2016-12-11 12:45:41 -------------------LR------------------- 
2016-12-11 12:45:41 0.0009765625 
2016-12-11 12:45:41 Epoch 210 
2016-12-11 12:51:07 Training Error = 0.27593333333333 
2016-12-11 12:51:07 Training Loss = 0.024949127956814 
2016-12-11 12:51:12 Valid Error = 0.40648129625925 
2016-12-11 12:51:12 Valid Loss = 0.026213238200506 
2016-12-11 12:51:37 Test Error = 0.4126 
2016-12-11 12:51:37 Test Loss = 0.026216812073951 
2016-12-11 12:51:37 -------------------LR------------------- 
2016-12-11 12:51:37 0.0009765625 
2016-12-11 12:51:37 Epoch 211 
2016-12-11 12:56:51 Training Error = 0.27522222222222 
2016-12-11 12:56:51 Training Loss = 0.024944097764757 
2016-12-11 12:56:56 Valid Error = 0.42148429685937 
2016-12-11 12:56:56 Valid Loss = 0.026543667830299 
2016-12-11 12:57:20 Test Error = 0.4221 
2016-12-11 12:57:20 Test Loss = 0.026581746538948 
2016-12-11 12:57:20 -------------------LR------------------- 
2016-12-11 12:57:20 0.0009765625 
2016-12-11 12:57:20 Epoch 212 
2016-12-11 13:02:48 Training Error = 0.2776 
2016-12-11 13:02:48 Training Loss = 0.024947570855035 
2016-12-11 13:02:53 Valid Error = 0.42008401680336 
2016-12-11 13:02:53 Valid Loss = 0.026739856648831 
2016-12-11 13:03:17 Test Error = 0.4187 
2016-12-11 13:03:17 Test Loss = 0.026708846567191 
2016-12-11 13:03:17 -------------------LR------------------- 
2016-12-11 13:03:17 0.0009765625 
2016-12-11 13:03:17 Epoch 213 
2016-12-11 13:08:36 Training Error = 0.27551111111111 
2016-12-11 13:08:36 Training Loss = 0.024961436035156 
2016-12-11 13:08:41 Valid Error = 0.44088817763553 
2016-12-11 13:08:41 Valid Loss = 0.027954328267268 
2016-12-11 13:09:05 Test Error = 0.4414 
2016-12-11 13:09:05 Test Loss = 0.027908162075866 
2016-12-11 13:09:05 -------------------LR------------------- 
2016-12-11 13:09:05 0.0009765625 
2016-12-11 13:09:05 Epoch 214 
2016-12-11 13:14:20 Training Error = 0.27415555555556 
2016-12-11 13:14:20 Training Loss = 0.024914151448568 
2016-12-11 13:14:25 Valid Error = 0.43508701740348 
2016-12-11 13:14:25 Valid Loss = 0.027710446592409 
2016-12-11 13:14:49 Test Error = 0.4377 
2016-12-11 13:14:49 Test Loss = 0.027629948874081 
2016-12-11 13:14:49 -------------------LR------------------- 
2016-12-11 13:14:49 0.0009765625 
2016-12-11 13:14:50 Epoch 215 
2016-12-11 13:19:56 Training Error = 0.27386666666667 
2016-12-11 13:19:56 Training Loss = 0.024966728407118 
2016-12-11 13:20:01 Valid Error = 0.42828565713143 
2016-12-11 13:20:01 Valid Loss = 0.027139178746243 
2016-12-11 13:20:25 Test Error = 0.4282 
2016-12-11 13:20:25 Test Loss = 0.027135996380974 
2016-12-11 13:20:25 -------------------LR------------------- 
2016-12-11 13:20:25 0.0009765625 
2016-12-11 13:20:25 Epoch 216 
2016-12-11 13:25:58 Training Error = 0.27495555555556 
2016-12-11 13:25:58 Training Loss = 0.024861387478299 
2016-12-11 13:26:03 Valid Error = 0.41368273654731 
2016-12-11 13:26:03 Valid Loss = 0.026350437635588 
2016-12-11 13:26:27 Test Error = 0.4152 
2016-12-11 13:26:27 Test Loss = 0.026404125797047 
2016-12-11 13:26:27 -------------------LR------------------- 
2016-12-11 13:26:27 0.0009765625 
2016-12-11 13:26:27 Epoch 217 
2016-12-11 13:32:18 Training Error = 0.27097777777778 
2016-12-11 13:32:18 Training Loss = 0.024924401909722 
2016-12-11 13:32:23 Valid Error = 0.42068413682737 
2016-12-11 13:32:23 Valid Loss = 0.026766389973958 
2016-12-11 13:32:47 Test Error = 0.4232 
2016-12-11 13:32:47 Test Loss = 0.026687605794271 
2016-12-11 13:32:47 -------------------LR------------------- 
2016-12-11 13:32:47 0.0009765625 
2016-12-11 13:32:47 Epoch 218 
2016-12-11 13:38:28 Training Error = 0.273 
2016-12-11 13:38:28 Training Loss = 0.024906274169922 
2016-12-11 13:38:33 Valid Error = 0.42608521704341 
2016-12-11 13:38:33 Valid Loss = 0.027017881107242 
2016-12-11 13:38:57 Test Error = 0.4316 
2016-12-11 13:38:57 Test Loss = 0.027151279703776 
2016-12-11 13:38:57 -------------------LR------------------- 
2016-12-11 13:38:57 0.0009765625 
2016-12-11 13:38:57 Epoch 219 
2016-12-11 13:44:57 Training Error = 0.27186666666667 
2016-12-11 13:44:57 Training Loss = 0.024881654242622 
2016-12-11 13:45:02 Valid Error = 0.41848369673935 
2016-12-11 13:45:02 Valid Loss = 0.026746151103508 
2016-12-11 13:45:27 Test Error = 0.4138 
2016-12-11 13:45:27 Test Loss = 0.026691474046894 
2016-12-11 13:45:27 -------------------LR------------------- 
2016-12-11 13:45:27 0.0009765625 
2016-12-11 13:45:27 Epoch 220 
2016-12-11 13:51:47 Training Error = 0.27464444444444 
2016-12-11 13:51:47 Training Loss = 0.024955240749783 
2016-12-11 13:51:51 Valid Error = 0.41728345669134 
2016-12-11 13:51:51 Valid Loss = 0.026848990508278 
2016-12-11 13:52:16 Test Error = 0.4286 
2016-12-11 13:52:16 Test Loss = 0.026802189426796 
2016-12-11 13:52:16 -------------------LR------------------- 
2016-12-11 13:52:16 0.0009765625 
2016-12-11 13:52:16 Epoch 221 
2016-12-11 23:35:01 Training Error = 0.26942222222222 
2016-12-11 23:35:01 Training Loss = 0.024893187228733 
2016-12-11 23:35:06 Valid Error = 0.4372874574915 
2016-12-11 23:35:06 Valid Loss = 0.027668978507537 
2016-12-11 23:35:30 Test Error = 0.4339 
2016-12-11 23:35:30 Test Loss = 0.027639867745194 
2016-12-11 23:35:30 -------------------LR------------------- 
2016-12-11 23:35:30 0.0009765625 
2016-12-11 23:35:30 Epoch 222 
2016-12-11 23:42:12 Training Error = 0.2726 
2016-12-11 23:42:12 Training Loss = 0.024883091471354 
2016-12-11 23:42:17 Valid Error = 0.42648529705941 
2016-12-11 23:42:17 Valid Loss = 0.026787239127813 
2016-12-11 23:42:41 Test Error = 0.4256 
2016-12-11 23:42:41 Test Loss = 0.026684821753408 
2016-12-11 23:42:41 -------------------LR------------------- 
2016-12-11 23:42:41 0.0009765625 
2016-12-11 23:42:41 Epoch 223 
2016-12-11 23:49:08 Training Error = 0.27071111111111 
2016-12-11 23:49:08 Training Loss = 0.024937557915582 
2016-12-11 23:49:13 Valid Error = 0.42368473694739 
2016-12-11 23:49:13 Valid Loss = 0.026506192841877 
2016-12-11 23:49:36 Test Error = 0.4235 
2016-12-11 23:49:36 Test Loss = 0.026427080939798 
2016-12-11 23:49:36 -------------------LR------------------- 
2016-12-11 23:49:36 0.0009765625 
2016-12-11 23:49:36 Epoch 224 
2016-12-11 23:55:59 Training Error = 0.27264444444444 
2016-12-11 23:55:59 Training Loss = 0.024903322943793 
2016-12-11 23:56:04 Valid Error = 0.43308661732346 
2016-12-11 23:56:04 Valid Loss = 0.027440758943371 
2016-12-11 23:56:28 Test Error = 0.4338 
2016-12-11 23:56:28 Test Loss = 0.027326912255381 
2016-12-11 23:56:28 -------------------LR------------------- 
2016-12-11 23:56:28 0.0009765625 
2016-12-11 23:56:28 Epoch 225 
2016-12-12 00:02:40 Training Error = 0.27322222222222 
2016-12-12 00:02:40 Training Loss = 0.024906575792101 
2016-12-12 00:02:45 Valid Error = 0.43148629725945 
2016-12-12 00:02:45 Valid Loss = 0.027665050494806 
2016-12-12 00:03:09 Test Error = 0.4359 
2016-12-12 00:03:09 Test Loss = 0.027508727249445 
2016-12-12 00:03:09 -------------------LR------------------- 
2016-12-12 00:03:09 0.0009765625 
2016-12-12 00:03:09 Epoch 226 
2016-12-12 00:09:06 Training Error = 0.27115555555556 
2016-12-12 00:09:06 Training Loss = 0.024872817789714 
2016-12-12 00:09:11 Valid Error = 0.41828365673135 
2016-12-12 00:09:11 Valid Loss = 0.027017193508095 
2016-12-12 00:09:35 Test Error = 0.4265 
2016-12-12 00:09:35 Test Loss = 0.027014241715974 
2016-12-12 00:09:35 -------------------LR------------------- 
2016-12-12 00:09:35 0.0009765625 
2016-12-12 00:09:35 Epoch 227 
2016-12-12 00:15:59 Training Error = 0.27097777777778 
2016-12-12 00:15:59 Training Loss = 0.024882646674262 
2016-12-12 00:16:04 Valid Error = 0.43088617723545 
2016-12-12 00:16:04 Valid Loss = 0.027990926503221 
2016-12-12 00:16:27 Test Error = 0.44 
2016-12-12 00:16:27 Test Loss = 0.027798698933919 
2016-12-12 00:16:27 -------------------LR------------------- 
2016-12-12 00:16:27 0.0009765625 
2016-12-12 00:16:27 Epoch 228 
2016-12-12 00:22:46 Training Error = 0.26888888888889 
2016-12-12 00:22:46 Training Loss = 0.024802838324653 
2016-12-12 00:22:51 Valid Error = 0.42008401680336 
2016-12-12 00:22:51 Valid Loss = 0.026712628515752 
2016-12-12 00:23:15 Test Error = 0.4229 
2016-12-12 00:23:15 Test Loss = 0.026699034627279 
2016-12-12 00:23:15 -------------------LR------------------- 
2016-12-12 00:23:15 0.0009765625 
2016-12-12 00:23:15 Epoch 229 
2016-12-12 00:29:18 Training Error = 0.26717777777778 
2016-12-12 00:29:18 Training Loss = 0.024813203911675 
2016-12-12 00:29:23 Valid Error = 0.42808561712342 
2016-12-12 00:29:23 Valid Loss = 0.027416383579637 
2016-12-12 00:29:46 Test Error = 0.4277 
2016-12-12 00:29:46 Test Loss = 0.027303238812615 
2016-12-12 00:29:46 -------------------LR------------------- 
2016-12-12 00:29:46 0.0009765625 
2016-12-12 00:29:46 Epoch 230 
2016-12-12 00:36:02 Training Error = 0.27033333333333 
2016-12-12 00:36:02 Training Loss = 0.024836207139757 
2016-12-12 00:36:07 Valid Error = 0.4250850170034 
2016-12-12 00:36:07 Valid Loss = 0.027208238685107 
2016-12-12 00:36:31 Test Error = 0.4249 
2016-12-12 00:36:31 Test Loss = 0.027162338974897 
2016-12-12 00:36:31 -------------------LR------------------- 
2016-12-12 00:36:31 0.0009765625 
2016-12-12 00:36:31 Epoch 231 
2016-12-12 00:42:36 Training Error = 0.26866666666667 
2016-12-12 00:42:36 Training Loss = 0.024826500325521 
2016-12-12 00:42:41 Valid Error = 0.42648529705941 
2016-12-12 00:42:41 Valid Loss = 0.026960613128759 
2016-12-12 00:43:05 Test Error = 0.4207 
2016-12-12 00:43:05 Test Loss = 0.026938844688266 
2016-12-12 00:43:05 -------------------LR------------------- 
2016-12-12 00:43:05 0.0009765625 
2016-12-12 00:43:05 Epoch 232 
2016-12-12 00:49:21 Training Error = 0.26888888888889 
2016-12-12 00:49:21 Training Loss = 0.024860797200521 
2016-12-12 00:49:26 Valid Error = 0.43408681736347 
2016-12-12 00:49:26 Valid Loss = 0.027644097931062 
2016-12-12 00:49:50 Test Error = 0.4353 
2016-12-12 00:49:50 Test Loss = 0.027699957574583 
2016-12-12 00:49:50 -------------------LR------------------- 
2016-12-12 00:49:50 0.0009765625 
2016-12-12 00:49:50 Epoch 233 
2016-12-12 00:56:05 Training Error = 0.26815555555556 
2016-12-12 00:56:05 Training Loss = 0.024850562771267 
2016-12-12 00:56:10 Valid Error = 0.43008601720344 
2016-12-12 00:56:10 Valid Loss = 0.027040013418192 
2016-12-12 00:56:34 Test Error = 0.432 
2016-12-12 00:56:34 Test Loss = 0.026933642518287 
2016-12-12 00:56:34 -------------------LR------------------- 
2016-12-12 00:56:34 0.0009765625 
2016-12-12 00:56:34 Epoch 234 
2016-12-12 01:02:34 Training Error = 0.2696 
2016-12-12 01:02:34 Training Loss = 0.024885944173177 
2016-12-12 01:02:39 Valid Error = 0.4252850570114 
2016-12-12 01:02:39 Valid Loss = 0.026852368520754 
2016-12-12 01:03:03 Test Error = 0.4251 
2016-12-12 01:03:03 Test Loss = 0.026801398123947 
2016-12-12 01:03:03 -------------------LR------------------- 
2016-12-12 01:03:03 0.0009765625 
2016-12-12 01:03:03 Epoch 235 
2016-12-12 01:09:19 Training Error = 0.27164444444444 
2016-12-12 01:09:19 Training Loss = 0.02490573187934 
2016-12-12 01:09:24 Valid Error = 0.43128625725145 
2016-12-12 01:09:24 Valid Loss = 0.027235320820002 
2016-12-12 01:09:48 Test Error = 0.4306 
2016-12-12 01:09:48 Test Loss = 0.027071052581189 
2016-12-12 01:09:48 -------------------LR------------------- 
2016-12-12 01:09:48 0.0009765625 
2016-12-12 01:09:48 Epoch 236 
2016-12-12 01:15:58 Training Error = 0.26833333333333 
2016-12-12 01:15:58 Training Loss = 0.024832921169705 
2016-12-12 01:16:03 Valid Error = 0.4246849369874 
2016-12-12 01:16:03 Valid Loss = 0.026906672938532 
2016-12-12 01:16:27 Test Error = 0.4243 
2016-12-12 01:16:27 Test Loss = 0.026732625146006 
2016-12-12 01:16:27 -------------------LR------------------- 
2016-12-12 01:16:27 0.0009765625 
2016-12-12 01:16:27 Epoch 237 
2016-12-12 01:22:37 Training Error = 0.26857777777778 
2016-12-12 01:22:37 Training Loss = 0.024822800374349 
2016-12-12 01:22:42 Valid Error = 0.42988597719544 
2016-12-12 01:22:42 Valid Loss = 0.027046649267614 
2016-12-12 01:23:05 Test Error = 0.4242 
2016-12-12 01:23:05 Test Loss = 0.026875891352635 
2016-12-12 01:23:05 -------------------LR------------------- 
2016-12-12 01:23:05 0.0009765625 
2016-12-12 01:23:05 Epoch 238 
2016-12-12 01:29:22 Training Error = 0.2662 
2016-12-12 01:29:22 Training Loss = 0.024845366482205 
2016-12-12 01:29:27 Valid Error = 0.43388677735547 
2016-12-12 01:29:27 Valid Loss = 0.027345268047595 
2016-12-12 01:29:51 Test Error = 0.4297 
2016-12-12 01:29:51 Test Loss = 0.0273104904474 
2016-12-12 01:29:51 -------------------LR------------------- 
2016-12-12 01:29:51 0.0009765625 
2016-12-12 01:29:51 Epoch 239 
2016-12-12 01:36:04 Training Error = 0.26828888888889 
2016-12-12 01:36:04 Training Loss = 0.024818855088976 
2016-12-12 01:36:09 Valid Error = 0.42388477695539 
2016-12-12 01:36:09 Valid Loss = 0.027224760865553 
2016-12-12 01:36:33 Test Error = 0.4337 
2016-12-12 01:36:33 Test Loss = 0.027364487113205 
2016-12-12 01:36:33 -------------------LR------------------- 
2016-12-12 01:36:33 0.0009765625 
2016-12-12 01:36:33 Epoch 240 
2016-12-12 01:42:45 Training Error = 0.27022222222222 
2016-12-12 01:42:45 Training Loss = 0.02489229288737 
2016-12-12 01:42:50 Valid Error = 0.42728545709142 
2016-12-12 01:42:50 Valid Loss = 0.027025593320107 
2016-12-12 01:43:14 Test Error = 0.4261 
2016-12-12 01:43:14 Test Loss = 0.027135222850126 
2016-12-12 01:43:14 -------------------LR------------------- 
2016-12-12 01:43:14 0.0009765625 
2016-12-12 01:43:14 Epoch 241 
2016-12-12 01:49:34 Training Error = 0.2672 
2016-12-12 01:49:34 Training Loss = 0.024802704806858 
2016-12-12 01:49:39 Valid Error = 0.4250850170034 
2016-12-12 01:49:39 Valid Loss = 0.027501848913122 
2016-12-12 01:50:02 Test Error = 0.4285 
2016-12-12 01:50:02 Test Loss = 0.027513783294079 
2016-12-12 01:50:02 -------------------LR------------------- 
2016-12-12 01:50:02 0.0009765625 
2016-12-12 01:50:03 Epoch 242 
2016-12-12 01:56:01 Training Error = 0.26902222222222 
2016-12-12 01:56:01 Training Loss = 0.02482169647895 
2016-12-12 01:56:06 Valid Error = 0.4244848969794 
2016-12-12 01:56:06 Valid Loss = 0.027054647200666 
2016-12-12 01:56:30 Test Error = 0.4277 
2016-12-12 01:56:30 Test Loss = 0.027010095394359 
2016-12-12 01:56:30 -------------------LR------------------- 
2016-12-12 01:56:30 0.0009765625 
2016-12-12 01:56:30 Epoch 243 
2016-12-12 02:02:47 Training Error = 0.26673333333333 
2016-12-12 02:02:47 Training Loss = 0.024868552463108 
2016-12-12 02:02:52 Valid Error = 0.42928585717143 
2016-12-12 02:02:52 Valid Loss = 0.027374698508139 
2016-12-12 02:03:16 Test Error = 0.4333 
2016-12-12 02:03:16 Test Loss = 0.027353152226467 
2016-12-12 02:03:16 -------------------LR------------------- 
2016-12-12 02:03:16 0.0009765625 
2016-12-12 02:03:16 Epoch 244 
2016-12-12 02:09:35 Training Error = 0.26844444444444 
2016-12-12 02:09:35 Training Loss = 0.024833914116753 
2016-12-12 02:09:40 Valid Error = 0.42568513702741 
2016-12-12 02:09:40 Valid Loss = 0.027182568524089 
2016-12-12 02:10:04 Test Error = 0.4303 
2016-12-12 02:10:04 Test Loss = 0.027116522336474 
2016-12-12 02:10:04 -------------------LR------------------- 
2016-12-12 02:10:04 0.0009765625 
2016-12-12 02:10:04 Epoch 245 
2016-12-12 02:16:03 Training Error = 0.26671111111111 
2016-12-12 02:16:03 Training Loss = 0.02483061070421 
2016-12-12 02:16:08 Valid Error = 0.4368873774755 
2016-12-12 02:16:08 Valid Loss = 0.028076121938178 
2016-12-12 02:16:32 Test Error = 0.4403 
2016-12-12 02:16:32 Test Loss = 0.027953518557081 
2016-12-12 02:16:32 -------------------LR------------------- 
2016-12-12 02:16:32 0.0009765625 
2016-12-12 02:16:32 Epoch 246 
2016-12-12 02:22:53 Training Error = 0.26768888888889 
2016-12-12 02:22:53 Training Loss = 0.024798950113932 
2016-12-12 02:22:58 Valid Error = 0.42928585717143 
2016-12-12 02:22:58 Valid Loss = 0.027079725230927 
2016-12-12 02:23:21 Test Error = 0.431 
2016-12-12 02:23:21 Test Loss = 0.027007532755534 
2016-12-12 02:23:21 -------------------LR------------------- 
2016-12-12 02:23:21 0.0009765625 
2016-12-12 02:23:21 Epoch 247 
2016-12-12 02:29:34 Training Error = 0.26653333333333 
2016-12-12 02:29:34 Training Loss = 0.02480463945855 
2016-12-12 02:29:39 Valid Error = 0.4248849769954 
2016-12-12 02:29:39 Valid Loss = 0.027561715370518 
2016-12-12 02:30:03 Test Error = 0.4326 
2016-12-12 02:30:03 Test Loss = 0.027442955047009 
2016-12-12 02:30:03 -------------------LR------------------- 
2016-12-12 02:30:03 0.0009765625 
2016-12-12 02:30:03 Epoch 248 
2016-12-12 02:36:11 Training Error = 0.26691111111111 
2016-12-12 02:36:11 Training Loss = 0.024791832817925 
2016-12-12 02:36:16 Valid Error = 0.42668533706741 
2016-12-12 02:36:16 Valid Loss = 0.026906819614884 
2016-12-12 02:36:40 Test Error = 0.4327 
2016-12-12 02:36:40 Test Loss = 0.026886376953125 
2016-12-12 02:36:40 -------------------LR------------------- 
2016-12-12 02:36:40 0.0009765625 
2016-12-12 02:36:40 Epoch 249 
2016-12-12 02:42:56 Training Error = 0.26955555555556 
2016-12-12 02:42:56 Training Loss = 0.024847754041884 
2016-12-12 02:43:01 Valid Error = 0.42588517703541 
2016-12-12 02:43:01 Valid Loss = 0.027164097203592 
2016-12-12 02:43:24 Test Error = 0.4319 
2016-12-12 02:43:24 Test Loss = 0.027195365337297 
2016-12-12 02:43:24 -------------------LR------------------- 
2016-12-12 02:43:24 0.0009765625 
2016-12-12 02:43:24 Epoch 250 
2016-12-12 02:49:29 Training Error = 0.26762222222222 
2016-12-12 02:49:29 Training Loss = 0.024831600802951 
2016-12-12 02:49:34 Valid Error = 0.42648529705941 
2016-12-12 02:49:34 Valid Loss = 0.027051998028382 
2016-12-12 02:49:58 Test Error = 0.421 
2016-12-12 02:49:58 Test Loss = 0.027090280689913 
2016-12-12 02:49:58 -------------------LR------------------- 
2016-12-12 02:49:58 0.00048828125 
2016-12-12 02:49:58 Epoch 251 
2016-12-12 02:56:12 Training Error = 0.25846666666667 
2016-12-12 02:56:12 Training Loss = 0.02440609117296 
2016-12-12 02:56:17 Valid Error = 0.43448689737948 
2016-12-12 02:56:17 Valid Loss = 0.02734930946326 
2016-12-12 02:56:40 Test Error = 0.4346 
2016-12-12 02:56:40 Test Loss = 0.0273966544357 
2016-12-12 02:56:40 -------------------LR------------------- 
2016-12-12 02:56:40 0.00048828125 
2016-12-12 02:56:41 Epoch 252 
2016-12-12 03:02:48 Training Error = 0.25873333333333 
2016-12-12 03:02:48 Training Loss = 0.024446879964193 
2016-12-12 03:02:53 Valid Error = 0.42148429685937 
2016-12-12 03:02:53 Valid Loss = 0.02690272030613 
2016-12-12 03:03:17 Test Error = 0.4291 
2016-12-12 03:03:17 Test Loss = 0.026723615220014 
2016-12-12 03:03:17 -------------------LR------------------- 
2016-12-12 03:03:17 0.00048828125 
2016-12-12 03:03:17 Epoch 253 
2016-12-12 03:09:19 Training Error = 0.25677777777778 
2016-12-12 03:09:19 Training Loss = 0.024421059082031 
2016-12-12 03:09:24 Valid Error = 0.4248849769954 
2016-12-12 03:09:24 Valid Loss = 0.027052005527993 
2016-12-12 03:09:48 Test Error = 0.4285 
2016-12-12 03:09:48 Test Loss = 0.027021077473958 
2016-12-12 03:09:48 -------------------LR------------------- 
2016-12-12 03:09:48 0.00048828125 
2016-12-12 03:09:48 Epoch 254 
2016-12-12 03:16:05 Training Error = 0.25457777777778 
2016-12-12 03:16:05 Training Loss = 0.024368825602214 
2016-12-12 03:16:10 Valid Error = 0.42368473694739 
2016-12-12 03:16:10 Valid Loss = 0.027397082371856 
2016-12-12 03:16:34 Test Error = 0.4248 
2016-12-12 03:16:34 Test Loss = 0.027312507001091 
2016-12-12 03:16:34 -------------------LR------------------- 
2016-12-12 03:16:34 0.00048828125 
2016-12-12 03:16:34 Epoch 255 
2016-12-12 03:22:49 Training Error = 0.25406666666667 
2016-12-12 03:22:49 Training Loss = 0.024369433539497 
2016-12-12 03:22:54 Valid Error = 0.41828365673135 
2016-12-12 03:22:54 Valid Loss = 0.026951828596469 
2016-12-12 03:23:18 Test Error = 0.4189 
2016-12-12 03:23:18 Test Loss = 0.026947082998238 
2016-12-12 03:23:18 -------------------LR------------------- 
2016-12-12 03:23:18 0.00048828125 
2016-12-12 03:23:18 Epoch 256 
2016-12-12 03:29:24 Training Error = 0.25797777777778 
2016-12-12 03:29:24 Training Loss = 0.024472187771267 
2016-12-12 03:29:30 Valid Error = 0.41968393678736 
2016-12-12 03:29:30 Valid Loss = 0.027242526538763 
2016-12-12 03:29:53 Test Error = 0.4269 
2016-12-12 03:29:53 Test Loss = 0.027167747587316 
2016-12-12 03:29:53 -------------------LR------------------- 
2016-12-12 03:29:53 0.00048828125 
2016-12-12 03:29:53 Epoch 257 
2016-12-12 03:36:10 Training Error = 0.25508888888889 
2016-12-12 03:36:10 Training Loss = 0.024427289333767 
2016-12-12 03:36:15 Valid Error = 0.42568513702741 
2016-12-12 03:36:15 Valid Loss = 0.026995169488256 
2016-12-12 03:36:38 Test Error = 0.4268 
2016-12-12 03:36:38 Test Loss = 0.027003443400065 
2016-12-12 03:36:38 -------------------LR------------------- 
2016-12-12 03:36:38 0.00048828125 
2016-12-12 03:36:38 Epoch 258 
2016-12-12 03:42:39 Training Error = 0.25771111111111 
2016-12-12 03:42:39 Training Loss = 0.024487423258464 
2016-12-12 03:42:44 Valid Error = 0.43168633726745 
2016-12-12 03:42:44 Valid Loss = 0.027201414821731 
2016-12-12 03:43:08 Test Error = 0.4192 
2016-12-12 03:43:08 Test Loss = 0.026987239104626 
2016-12-12 03:43:08 -------------------LR------------------- 
2016-12-12 03:43:08 0.00048828125 
2016-12-12 03:43:08 Epoch 259 
2016-12-12 03:49:23 Training Error = 0.25382222222222 
2016-12-12 03:49:23 Training Loss = 0.024399858072917 
2016-12-12 03:49:28 Valid Error = 0.42348469693939 
2016-12-12 03:49:28 Valid Loss = 0.027135169500979 
2016-12-12 03:49:51 Test Error = 0.419 
2016-12-12 03:49:51 Test Loss = 0.026953746900371 
2016-12-12 03:49:51 -------------------LR------------------- 
2016-12-12 03:49:51 0.00048828125 
2016-12-12 03:49:51 Epoch 260 
2016-12-12 03:56:07 Training Error = 0.25282222222222 
2016-12-12 03:56:07 Training Loss = 0.024394400417752 
2016-12-12 03:56:12 Valid Error = 0.41368273654731 
2016-12-12 03:56:12 Valid Loss = 0.026540418626653 
2016-12-12 03:56:35 Test Error = 0.4137 
2016-12-12 03:56:35 Test Loss = 0.026547976624732 
2016-12-12 03:56:35 -------------------LR------------------- 
2016-12-12 03:56:35 0.00048828125 
2016-12-12 03:56:35 Epoch 261 
2016-12-12 04:02:33 Training Error = 0.25262222222222 
2016-12-12 04:02:33 Training Loss = 0.0244293410102 
2016-12-12 04:02:38 Valid Error = 0.41128225645129 
2016-12-12 04:02:38 Valid Loss = 0.026950026465607 
2016-12-12 04:03:01 Test Error = 0.4187 
2016-12-12 04:03:01 Test Loss = 0.0268035341749 
2016-12-12 04:03:01 -------------------LR------------------- 
2016-12-12 04:03:01 0.00048828125 
2016-12-12 04:03:01 Epoch 262 
2016-12-12 04:09:19 Training Error = 0.25282222222222 
2016-12-12 04:09:19 Training Loss = 0.024425460666233 
2016-12-12 04:09:24 Valid Error = 0.41728345669134 
2016-12-12 04:09:24 Valid Loss = 0.026855535293429 
2016-12-12 04:09:47 Test Error = 0.4231 
2016-12-12 04:09:47 Test Loss = 0.026665798112458 
2016-12-12 04:09:47 -------------------LR------------------- 
2016-12-12 04:09:47 0.00048828125 
2016-12-12 04:09:47 Epoch 263 
2016-12-12 04:16:01 Training Error = 0.25566666666667 
2016-12-12 04:16:01 Training Loss = 0.024403701524523 
2016-12-12 04:16:06 Valid Error = 0.4248849769954 
2016-12-12 04:16:06 Valid Loss = 0.027167266767322 
2016-12-12 04:16:30 Test Error = 0.4241 
2016-12-12 04:16:30 Test Loss = 0.027050803031173 
2016-12-12 04:16:30 -------------------LR------------------- 
2016-12-12 04:16:30 0.00048828125 
2016-12-12 04:16:30 Epoch 264 
2016-12-12 04:22:28 Training Error = 0.25091111111111 
2016-12-12 04:22:28 Training Loss = 0.024384619411892 
2016-12-12 04:22:33 Valid Error = 0.42248449689938 
2016-12-12 04:22:33 Valid Loss = 0.027414790442783 
2016-12-12 04:22:57 Test Error = 0.4266 
2016-12-12 04:22:57 Test Loss = 0.027481821396772 
2016-12-12 04:22:57 -------------------LR------------------- 
2016-12-12 04:22:57 0.00048828125 
2016-12-12 04:22:57 Epoch 265 
2016-12-12 04:29:13 Training Error = 0.25268888888889 
2016-12-12 04:29:13 Training Loss = 0.024397536105686 
2016-12-12 04:29:18 Valid Error = 0.42348469693939 
2016-12-12 04:29:18 Valid Loss = 0.027048203542125 
2016-12-12 04:29:42 Test Error = 0.4251 
2016-12-12 04:29:42 Test Loss = 0.027032955573587 
2016-12-12 04:29:42 -------------------LR------------------- 
2016-12-12 04:29:42 0.00048828125 
2016-12-12 04:29:42 Epoch 266 
2016-12-12 04:35:55 Training Error = 0.25148888888889 
2016-12-12 04:35:55 Training Loss = 0.024402811740451 
2016-12-12 04:36:00 Valid Error = 0.4128825765153 
2016-12-12 04:36:00 Valid Loss = 0.026101805732993 
2016-12-12 04:36:24 Test Error = 0.4142 
2016-12-12 04:36:24 Test Loss = 0.026121898217295 
2016-12-12 04:36:24 -------------------LR------------------- 
2016-12-12 04:36:24 0.00048828125 
2016-12-12 04:36:24 Epoch 267 
2016-12-12 04:42:41 Training Error = 0.25815555555556 
2016-12-12 04:42:41 Training Loss = 0.024485993950738 
2016-12-12 04:42:46 Valid Error = 0.42368473694739 
2016-12-12 04:42:46 Valid Loss = 0.026950754927524 
2016-12-12 04:43:09 Test Error = 0.4241 
2016-12-12 04:43:09 Test Loss = 0.026957543107575 
2016-12-12 04:43:09 -------------------LR------------------- 
2016-12-12 04:43:09 0.00048828125 
2016-12-12 04:43:09 Epoch 268 
2016-12-12 04:49:18 Training Error = 0.25126666666667 
2016-12-12 04:49:18 Training Loss = 0.024426164035373 
2016-12-12 04:49:23 Valid Error = 0.41108221644329 
2016-12-12 04:49:23 Valid Loss = 0.026314214656226 
2016-12-12 04:49:47 Test Error = 0.4196 
2016-12-12 04:49:47 Test Loss = 0.026442292516372 
2016-12-12 04:49:47 -------------------LR------------------- 
2016-12-12 04:49:47 0.00048828125 
2016-12-12 04:49:47 Epoch 269 
2016-12-12 04:55:49 Training Error = 0.25064444444444 
2016-12-12 04:55:49 Training Loss = 0.024419469563802 
2016-12-12 04:55:54 Valid Error = 0.41548309661932 
2016-12-12 04:55:54 Valid Loss = 0.026622892557042 
2016-12-12 04:56:17 Test Error = 0.4195 
2016-12-12 04:56:17 Test Loss = 0.026711518889782 
2016-12-12 04:56:17 -------------------LR------------------- 
2016-12-12 04:56:17 0.00048828125 
2016-12-12 04:56:17 Epoch 270 
2016-12-12 05:02:37 Training Error = 0.25337777777778 
2016-12-12 05:02:37 Training Loss = 0.024396031467014 
2016-12-12 05:02:42 Valid Error = 0.43048609721944 
2016-12-12 05:02:42 Valid Loss = 0.027581293097204 
2016-12-12 05:03:05 Test Error = 0.4312 
2016-12-12 05:03:05 Test Loss = 0.027416836368336 
2016-12-12 05:03:05 -------------------LR------------------- 
2016-12-12 05:03:05 0.00048828125 
2016-12-12 05:03:05 Epoch 271 
2016-12-12 05:09:17 Training Error = 0.25433333333333 
2016-12-12 05:09:17 Training Loss = 0.024436259765625 
2016-12-12 05:09:22 Valid Error = 0.41708341668334 
2016-12-12 05:09:22 Valid Loss = 0.027004779306054 
2016-12-12 05:09:46 Test Error = 0.4212 
2016-12-12 05:09:46 Test Loss = 0.027116846959731 
2016-12-12 05:09:46 -------------------LR------------------- 
2016-12-12 05:09:46 0.00048828125 
2016-12-12 05:09:46 Epoch 272 
2016-12-12 05:15:06 Training Error = 0.25253333333333 
2016-12-12 05:15:06 Training Loss = 0.024460522732205 
2016-12-12 05:15:11 Valid Error = 0.42768553710742 
2016-12-12 05:15:11 Valid Loss = 0.027193251470115 
2016-12-12 05:15:34 Test Error = 0.4275 
2016-12-12 05:15:34 Test Loss = 0.027179648485371 
2016-12-12 05:15:34 -------------------LR------------------- 
2016-12-12 05:15:34 0.00048828125 
2016-12-12 05:15:34 Epoch 273 
2016-12-12 05:21:10 Training Error = 0.25444444444444 
2016-12-12 05:21:10 Training Loss = 0.024445358696832 
2016-12-12 05:21:15 Valid Error = 0.42148429685937 
2016-12-12 05:21:15 Valid Loss = 0.026990798625879 
2016-12-12 05:21:38 Test Error = 0.4229 
2016-12-12 05:21:38 Test Loss = 0.026873533241422 
2016-12-12 05:21:38 -------------------LR------------------- 
2016-12-12 05:21:38 0.00048828125 
2016-12-12 05:21:38 Epoch 274 
2016-12-12 05:26:50 Training Error = 0.25035555555556 
2016-12-12 05:26:50 Training Loss = 0.024354364393446 
2016-12-12 05:26:55 Valid Error = 0.41448289657932 
2016-12-12 05:26:55 Valid Loss = 0.026576170826508 
2016-12-12 05:27:19 Test Error = 0.4172 
2016-12-12 05:27:19 Test Loss = 0.026588897764917 
2016-12-12 05:27:19 -------------------LR------------------- 
2016-12-12 05:27:19 0.00048828125 
2016-12-12 05:27:19 Epoch 275 
2016-12-12 05:32:49 Training Error = 0.25282222222222 
2016-12-12 05:32:49 Training Loss = 0.024396032009549 
2016-12-12 05:32:54 Valid Error = 0.42008401680336 
2016-12-12 05:32:54 Valid Loss = 0.027290995970612 
2016-12-12 05:33:17 Test Error = 0.4233 
2016-12-12 05:33:17 Test Loss = 0.027093982711493 
2016-12-12 05:33:17 -------------------LR------------------- 
2016-12-12 05:33:17 0.00048828125 
2016-12-12 05:33:17 Epoch 276 
2016-12-12 05:38:45 Training Error = 0.25222222222222 
2016-12-12 05:38:45 Training Loss = 0.024431139350043 
2016-12-12 05:38:49 Valid Error = 0.41128225645129 
2016-12-12 05:38:49 Valid Loss = 0.026500386287903 
2016-12-12 05:39:13 Test Error = 0.4137 
2016-12-12 05:39:13 Test Loss = 0.026452409811581 
2016-12-12 05:39:13 -------------------LR------------------- 
2016-12-12 05:39:13 0.00048828125 
2016-12-12 05:39:13 Epoch 277 
2016-12-12 05:44:23 Training Error = 0.25242222222222 
2016-12-12 05:44:23 Training Loss = 0.024398405381944 
2016-12-12 05:44:28 Valid Error = 0.42628525705141 
2016-12-12 05:44:28 Valid Loss = 0.027562668900283 
2016-12-12 05:44:51 Test Error = 0.4234 
2016-12-12 05:44:51 Test Loss = 0.027510092043409 
2016-12-12 05:44:51 -------------------LR------------------- 
2016-12-12 05:44:51 0.00048828125 
2016-12-12 05:44:51 Epoch 278 
2016-12-12 05:50:18 Training Error = 0.25255555555556 
2016-12-12 05:50:18 Training Loss = 0.02440041805013 
2016-12-12 05:50:22 Valid Error = 0.42068413682737 
2016-12-12 05:50:22 Valid Loss = 0.027060849517589 
2016-12-12 05:50:46 Test Error = 0.4178 
2016-12-12 05:50:46 Test Loss = 0.02705339678596 
2016-12-12 05:50:46 -------------------LR------------------- 
2016-12-12 05:50:46 0.00048828125 
2016-12-12 05:50:46 Epoch 279 
2016-12-12 05:56:15 Training Error = 0.25344444444444 
2016-12-12 05:56:15 Training Loss = 0.024411691867405 
2016-12-12 05:56:20 Valid Error = 0.42088417683537 
2016-12-12 05:56:20 Valid Loss = 0.02693249684044 
2016-12-12 05:56:43 Test Error = 0.4121 
2016-12-12 05:56:43 Test Loss = 0.026590563067268 
2016-12-12 05:56:43 -------------------LR------------------- 
2016-12-12 05:56:43 0.00048828125 
2016-12-12 05:56:43 Epoch 280 
2016-12-12 06:02:12 Training Error = 0.25424444444444 
2016-12-12 06:02:12 Training Loss = 0.024445077528212 
2016-12-12 06:02:17 Valid Error = 0.41328265653131 
2016-12-12 06:02:17 Valid Loss = 0.026814044239435 
2016-12-12 06:02:40 Test Error = 0.419 
2016-12-12 06:02:40 Test Loss = 0.026873859959023 
2016-12-12 06:02:40 -------------------LR------------------- 
2016-12-12 06:02:40 0.00048828125 
2016-12-12 06:02:40 Epoch 281 
2016-12-12 06:08:08 Training Error = 0.24871111111111 
2016-12-12 06:08:08 Training Loss = 0.024361252360026 
2016-12-12 06:08:13 Valid Error = 0.42068413682737 
2016-12-12 06:08:13 Valid Loss = 0.026756426650941 
2016-12-12 06:08:36 Test Error = 0.426 
2016-12-12 06:08:36 Test Loss = 0.026687339154412 
2016-12-12 06:08:36 -------------------LR------------------- 
2016-12-12 06:08:36 0.00048828125 
2016-12-12 06:08:36 Epoch 282 
