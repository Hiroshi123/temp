2016-12-12 12:52:03 [program started on Mon Dec 12 12:52:03 2016] 
2016-12-12 12:52:03 [command line arguments] 
2016-12-12 12:52:03 stcWeights false 
2016-12-12 12:52:03 LR 0.015625 
2016-12-12 12:52:03 batchSize 500 
2016-12-12 12:52:03 network ./Models/Cifar10_Custom 
2016-12-12 12:52:03 stcNeurons true 
2016-12-12 12:52:03 constBatchSize false 
2016-12-12 12:52:03 chartFileName chart1 
2016-12-12 12:52:03 dp_prepro false 
2016-12-12 12:52:03 nGPU 3 
2016-12-12 12:52:03 dataset Cifar100 
2016-12-12 12:52:03 type cuda 
2016-12-12 12:52:03 momentum 0 
2016-12-12 12:52:03 threads 8 
2016-12-12 12:52:03 weightDecay 0 
2016-12-12 12:52:03 runningVal false 
2016-12-12 12:52:03 convLayerN 6 
2016-12-12 12:52:03 LRDecay 0 
2016-12-12 12:52:03 numHid 216 
2016-12-12 12:52:03 save /dev/shm/clone/temp/th/Results/Cifar100/model6-10-216-v2 
2016-12-12 12:52:03 augment false 
2016-12-12 12:52:03 epoch -1 
2016-12-12 12:52:03 modelsFolder ./Models/ 
2016-12-12 12:52:03 format rgb 
2016-12-12 12:52:03 preProcDir /dev/shm/clone/temp/th/PreProcData/Cifar100 
2016-12-12 12:52:03 imageFileExtension svg 
2016-12-12 12:52:03 channel 1 
2016-12-12 12:52:03 devid 11 
2016-12-12 12:52:03 visualize 1 
2016-12-12 12:52:03 LRDecayPerEpoch 0.0001 
2016-12-12 12:52:03 optimization adam 
2016-12-12 12:52:03 SBN true 
2016-12-12 12:52:03 normalization simple 
2016-12-12 12:52:03 title model1 
2016-12-12 12:52:03 load  
2016-12-12 12:52:03 whiten true 
2016-12-12 12:52:03 [----------------------] 
2016-12-12 12:52:05 ==> Network 
2016-12-12 12:52:05 DataParallelTable: 3 x nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 216)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(216 -> 216)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(216 -> 100)
  (38): nn.BatchNormalization
} 
2016-12-12 12:52:05 ==>6419292 Parameters 
2016-12-12 12:52:05 ==> Loss 
2016-12-12 12:52:05 SqrtHingeEmbeddingCriterion 
2016-12-12 12:52:05 
==> Starting Training
 
2016-12-12 12:52:05 Epoch 1 
2016-12-12 12:55:40 Training Error = 0.94186666666667 
2016-12-12 12:55:40 Training Loss = 0.35473061013455 
2016-12-12 12:55:44 Valid Error = 0.92158431686337 
2016-12-12 12:55:44 Valid Loss = 0.058699396618432 
2016-12-12 12:55:53 Test Error = 0.9226 
2016-12-12 12:55:53 Test Loss = 0.058810382324219 
2016-12-12 12:55:53 -------------------LR------------------- 
2016-12-12 12:55:53 0.015625 
2016-12-12 12:55:53 Epoch 2 
2016-12-12 12:59:37 Training Error = 0.9164 
2016-12-12 12:59:37 Training Loss = 0.042328170735677 
2016-12-12 12:59:41 Valid Error = 0.91858371674335 
2016-12-12 12:59:41 Valid Loss = 0.039301411269316 
2016-12-12 12:59:49 Test Error = 0.9169 
2016-12-12 12:59:49 Test Loss = 0.039342787597656 
2016-12-12 12:59:49 -------------------LR------------------- 
2016-12-12 12:59:49 0.015625 
2016-12-12 12:59:49 Epoch 3 
2016-12-12 13:03:25 Training Error = 0.90722222222222 
2016-12-12 13:03:25 Training Loss = 0.038756456244575 
2016-12-12 13:03:29 Valid Error = 0.90278055611122 
2016-12-12 13:03:29 Valid Loss = 0.038718707336548 
2016-12-12 13:03:37 Test Error = 0.9085 
2016-12-12 13:03:37 Test Loss = 0.038789818847656 
2016-12-12 13:03:37 -------------------LR------------------- 
2016-12-12 13:03:37 0.015625 
2016-12-12 13:03:37 Epoch 4 
2016-12-12 13:07:23 Training Error = 0.89384444444444 
2016-12-12 13:07:23 Training Loss = 0.038536207058377 
2016-12-12 13:07:27 Valid Error = 0.8879775955191 
2016-12-12 13:07:27 Valid Loss = 0.038465388637138 
2016-12-12 13:07:36 Test Error = 0.8884 
2016-12-12 13:07:36 Test Loss = 0.038523901489258 
2016-12-12 13:07:36 -------------------LR------------------- 
2016-12-12 13:07:36 0.015625 
2016-12-12 13:07:36 Epoch 5 
2016-12-12 13:11:13 Training Error = 0.88137777777778 
2016-12-12 13:11:13 Training Loss = 0.038400189100477 
2016-12-12 13:11:17 Valid Error = 0.874974994999 
2016-12-12 13:11:17 Valid Loss = 0.038305842558163 
2016-12-12 13:11:26 Test Error = 0.8777 
2016-12-12 13:11:26 Test Loss = 0.038390758911133 
2016-12-12 13:11:26 -------------------LR------------------- 
2016-12-12 13:11:26 0.015625 
2016-12-12 13:11:26 Epoch 6 
2016-12-12 13:15:02 Training Error = 0.87062222222222 
2016-12-12 13:15:02 Training Loss = 0.038260522433811 
2016-12-12 13:15:06 Valid Error = 0.86657331466293 
2016-12-12 13:15:06 Valid Loss = 0.038170251835213 
2016-12-12 13:15:14 Test Error = 0.8671 
2016-12-12 13:15:14 Test Loss = 0.03822625402832 
2016-12-12 13:15:14 -------------------LR------------------- 
2016-12-12 13:15:14 0.015625 
2016-12-12 13:15:14 Epoch 7 
2016-12-12 13:19:10 Training Error = 0.86235555555556 
2016-12-12 13:19:10 Training Loss = 0.038147136474609 
2016-12-12 13:19:13 Valid Error = 0.85837167433487 
2016-12-12 13:19:13 Valid Loss = 0.038109463939598 
2016-12-12 13:19:21 Test Error = 0.8634 
2016-12-12 13:19:21 Test Loss = 0.038194410888672 
2016-12-12 13:19:21 -------------------LR------------------- 
2016-12-12 13:19:21 0.015625 
2016-12-12 13:19:21 Epoch 8 
2016-12-12 13:22:52 Training Error = 0.85404444444444 
2016-12-12 13:22:52 Training Loss = 0.038033963541667 
2016-12-12 13:22:56 Valid Error = 0.84076815363073 
2016-12-12 13:22:56 Valid Loss = 0.037866282273531 
2016-12-12 13:23:04 Test Error = 0.8391 
2016-12-12 13:23:04 Test Loss = 0.037936802490234 
2016-12-12 13:23:04 -------------------LR------------------- 
2016-12-12 13:23:04 0.015625 
2016-12-12 13:23:04 Epoch 9 
2016-12-12 13:26:51 Training Error = 0.84273333333333 
2016-12-12 13:26:51 Training Loss = 0.037918870958116 
2016-12-12 13:26:55 Valid Error = 0.82836567313463 
2016-12-12 13:26:55 Valid Loss = 0.037706015790859 
2016-12-12 13:27:04 Test Error = 0.8293 
2016-12-12 13:27:04 Test Loss = 0.037799137939453 
2016-12-12 13:27:04 -------------------LR------------------- 
2016-12-12 13:27:04 0.015625 
2016-12-12 13:27:04 Epoch 10 
2016-12-12 13:30:42 Training Error = 0.83486666666667 
2016-12-12 13:30:42 Training Loss = 0.037790332221137 
2016-12-12 13:30:46 Valid Error = 0.81776355271054 
2016-12-12 13:30:46 Valid Loss = 0.037492103904587 
2016-12-12 13:30:56 Test Error = 0.8217 
2016-12-12 13:30:56 Test Loss = 0.037590231201172 
2016-12-12 13:30:56 -------------------LR------------------- 
2016-12-12 13:30:56 0.015625 
2016-12-12 13:30:56 Epoch 11 
2016-12-12 13:34:39 Training Error = 0.82491111111111 
2016-12-12 13:34:39 Training Loss = 0.037654986626519 
2016-12-12 13:34:43 Valid Error = 0.81376275255051 
2016-12-12 13:34:43 Valid Loss = 0.03745857332634 
2016-12-12 13:34:51 Test Error = 0.8185 
2016-12-12 13:34:51 Test Loss = 0.037560813598633 
2016-12-12 13:34:51 -------------------LR------------------- 
2016-12-12 13:34:51 0.015625 
2016-12-12 13:34:51 Epoch 12 
2016-12-12 13:38:31 Training Error = 0.81557777777778 
2016-12-12 13:38:31 Training Loss = 0.037511870741102 
2016-12-12 13:38:35 Valid Error = 0.81316263252651 
2016-12-12 13:38:35 Valid Loss = 0.03741582705401 
2016-12-12 13:38:43 Test Error = 0.8151 
2016-12-12 13:38:43 Test Loss = 0.037519451782227 
2016-12-12 13:38:43 -------------------LR------------------- 
2016-12-12 13:38:43 0.015625 
2016-12-12 13:38:43 Epoch 13 
2016-12-12 13:42:29 Training Error = 0.80637777777778 
2016-12-12 13:42:29 Training Loss = 0.037381661783854 
2016-12-12 13:42:33 Valid Error = 0.80356071214243 
2016-12-12 13:42:33 Valid Loss = 0.037247344659045 
2016-12-12 13:42:41 Test Error = 0.8029 
2016-12-12 13:42:41 Test Loss = 0.037314580322266 
2016-12-12 13:42:41 -------------------LR------------------- 
2016-12-12 13:42:41 0.015625 
2016-12-12 13:42:41 Epoch 14 
2016-12-12 13:46:52 Training Error = 0.79853333333333 
2016-12-12 13:46:52 Training Loss = 0.037275578369141 
2016-12-12 13:46:56 Valid Error = 0.79315863172635 
2016-12-12 13:46:56 Valid Loss = 0.037171353404563 
2016-12-12 13:47:05 Test Error = 0.8002 
2016-12-12 13:47:05 Test Loss = 0.037267849975586 
2016-12-12 13:47:05 -------------------LR------------------- 
2016-12-12 13:47:05 0.015625 
2016-12-12 13:47:05 Epoch 15 
2016-12-12 13:51:30 Training Error = 0.79542222222222 
2016-12-12 13:51:30 Training Loss = 0.037159361300998 
2016-12-12 13:51:34 Valid Error = 0.77955591118224 
2016-12-12 13:51:34 Valid Loss = 0.036778446025351 
2016-12-12 13:51:43 Test Error = 0.7884 
2016-12-12 13:51:43 Test Loss = 0.036877032836914 
2016-12-12 13:51:43 -------------------LR------------------- 
2016-12-12 13:51:43 0.015625 
2016-12-12 13:51:43 Epoch 16 
2016-12-12 13:56:16 Training Error = 0.79071111111111 
2016-12-12 13:56:16 Training Loss = 0.037055527479384 
2016-12-12 13:56:20 Valid Error = 0.77055411082216 
2016-12-12 13:56:20 Valid Loss = 0.036489239040092 
2016-12-12 13:56:28 Test Error = 0.7752 
2016-12-12 13:56:28 Test Loss = 0.036611695678711 
2016-12-12 13:56:28 -------------------LR------------------- 
2016-12-12 13:56:28 0.015625 
2016-12-12 13:56:28 Epoch 17 
2016-12-12 14:00:58 Training Error = 0.77995555555556 
2016-12-12 14:00:58 Training Loss = 0.036946649061415 
2016-12-12 14:01:02 Valid Error = 0.76815363072615 
2016-12-12 14:01:02 Valid Loss = 0.036502182956734 
2016-12-12 14:01:09 Test Error = 0.7705 
2016-12-12 14:01:09 Test Loss = 0.036639492675781 
2016-12-12 14:01:09 -------------------LR------------------- 
2016-12-12 14:01:09 0.015625 
2016-12-12 14:01:09 Epoch 18 
2016-12-12 14:05:33 Training Error = 0.77795555555556 
2016-12-12 14:05:33 Training Loss = 0.036851630126953 
2016-12-12 14:05:37 Valid Error = 0.75375075015003 
2016-12-12 14:05:37 Valid Loss = 0.03617399744851 
2016-12-12 14:05:45 Test Error = 0.7561 
2016-12-12 14:05:45 Test Loss = 0.036279757080078 
2016-12-12 14:05:45 -------------------LR------------------- 
2016-12-12 14:05:45 0.015625 
2016-12-12 14:05:45 Epoch 19 
2016-12-12 14:10:20 Training Error = 0.77533333333333 
2016-12-12 14:10:20 Training Loss = 0.036759781792535 
2016-12-12 14:10:24 Valid Error = 0.74874974994999 
2016-12-12 14:10:24 Valid Loss = 0.036097618526604 
2016-12-12 14:10:32 Test Error = 0.7548 
2016-12-12 14:10:32 Test Loss = 0.03621841027832 
2016-12-12 14:10:32 -------------------LR------------------- 
2016-12-12 14:10:32 0.015625 
2016-12-12 14:10:32 Epoch 20 
2016-12-12 14:14:57 Training Error = 0.77233333333333 
2016-12-12 14:14:57 Training Loss = 0.036663703531901 
2016-12-12 14:15:01 Valid Error = 0.75835167033407 
2016-12-12 14:15:01 Valid Loss = 0.036152345566622 
2016-12-12 14:15:10 Test Error = 0.7602 
2016-12-12 14:15:10 Test Loss = 0.03630383605957 
2016-12-12 14:15:10 -------------------LR------------------- 
2016-12-12 14:15:10 0.015625 
2016-12-12 14:15:10 Epoch 21 
2016-12-12 14:19:43 Training Error = 0.76584444444444 
2016-12-12 14:19:43 Training Loss = 0.036601350667318 
2016-12-12 14:19:47 Valid Error = 0.75195039007802 
2016-12-12 14:19:47 Valid Loss = 0.035913357356314 
2016-12-12 14:19:54 Test Error = 0.7511 
2016-12-12 14:19:54 Test Loss = 0.036053111328125 
2016-12-12 14:19:54 -------------------LR------------------- 
2016-12-12 14:19:54 0.015625 
2016-12-12 14:19:54 Epoch 22 
2016-12-12 14:24:23 Training Error = 0.76415555555556 
2016-12-12 14:24:23 Training Loss = 0.036505613172743 
2016-12-12 14:24:27 Valid Error = 0.73834766953391 
2016-12-12 14:24:27 Valid Loss = 0.035841464953833 
2016-12-12 14:24:35 Test Error = 0.7418 
2016-12-12 14:24:35 Test Loss = 0.035932220214844 
2016-12-12 14:24:35 -------------------LR------------------- 
2016-12-12 14:24:35 0.015625 
2016-12-12 14:24:35 Epoch 23 
2016-12-12 14:29:00 Training Error = 0.75984444444444 
2016-12-12 14:29:00 Training Loss = 0.036411039035373 
2016-12-12 14:29:04 Valid Error = 0.7369473894779 
2016-12-12 14:29:04 Valid Loss = 0.035710839859406 
2016-12-12 14:29:12 Test Error = 0.7383 
2016-12-12 14:29:12 Test Loss = 0.035835032470703 
2016-12-12 14:29:12 -------------------LR------------------- 
2016-12-12 14:29:12 0.015625 
2016-12-12 14:29:12 Epoch 24 
2016-12-12 14:33:48 Training Error = 0.75826666666667 
2016-12-12 14:33:48 Training Loss = 0.036362469455295 
2016-12-12 14:33:51 Valid Error = 0.72734546909382 
2016-12-12 14:33:51 Valid Loss = 0.035576667606698 
2016-12-12 14:34:00 Test Error = 0.7309 
2016-12-12 14:34:00 Test Loss = 0.035660263427734 
2016-12-12 14:34:00 -------------------LR------------------- 
2016-12-12 14:34:00 0.015625 
2016-12-12 14:34:00 Epoch 25 
2016-12-12 14:38:20 Training Error = 0.75297777777778 
2016-12-12 14:38:20 Training Loss = 0.036300211290148 
2016-12-12 14:38:24 Valid Error = 0.71994398879776 
2016-12-12 14:38:24 Valid Loss = 0.035329510141866 
2016-12-12 14:38:33 Test Error = 0.7187 
2016-12-12 14:38:33 Test Loss = 0.035427612182617 
2016-12-12 14:38:33 -------------------LR------------------- 
2016-12-12 14:38:33 0.015625 
2016-12-12 14:38:33 Epoch 26 
2016-12-12 14:42:59 Training Error = 0.74637777777778 
2016-12-12 14:42:59 Training Loss = 0.036202717936198 
2016-12-12 14:43:03 Valid Error = 0.72014402880576 
2016-12-12 14:43:03 Valid Loss = 0.035363128118542 
2016-12-12 14:43:11 Test Error = 0.724 
2016-12-12 14:43:11 Test Loss = 0.035427674560547 
2016-12-12 14:43:11 -------------------LR------------------- 
2016-12-12 14:43:11 0.015625 
2016-12-12 14:43:11 Epoch 27 
2016-12-12 14:47:32 Training Error = 0.74488888888889 
2016-12-12 14:47:32 Training Loss = 0.03616431781684 
2016-12-12 14:47:36 Valid Error = 0.71574314862973 
2016-12-12 14:47:36 Valid Loss = 0.035236209643897 
2016-12-12 14:47:44 Test Error = 0.7166 
2016-12-12 14:47:44 Test Loss = 0.035343718994141 
2016-12-12 14:47:44 -------------------LR------------------- 
2016-12-12 14:47:44 0.015625 
2016-12-12 14:47:44 Epoch 28 
2016-12-12 14:52:08 Training Error = 0.74137777777778 
2016-12-12 14:52:08 Training Loss = 0.036078680609809 
2016-12-12 14:52:12 Valid Error = 0.71794358871774 
2016-12-12 14:52:12 Valid Loss = 0.035186865232907 
2016-12-12 14:52:20 Test Error = 0.7133 
2016-12-12 14:52:20 Test Loss = 0.035249193969727 
2016-12-12 14:52:20 -------------------LR------------------- 
2016-12-12 14:52:20 0.015625 
2016-12-12 14:52:20 Epoch 29 
2016-12-12 14:56:42 Training Error = 0.73848888888889 
2016-12-12 14:56:42 Training Loss = 0.036029993652344 
2016-12-12 14:56:46 Valid Error = 0.70954190838168 
2016-12-12 14:56:46 Valid Loss = 0.034998529481326 
2016-12-12 14:56:55 Test Error = 0.7177 
2016-12-12 14:56:55 Test Loss = 0.035113093383789 
2016-12-12 14:56:55 -------------------LR------------------- 
2016-12-12 14:56:55 0.015625 
2016-12-12 14:56:55 Epoch 30 
2016-12-12 15:01:19 Training Error = 0.73622222222222 
2016-12-12 15:01:19 Training Loss = 0.035948955457899 
2016-12-12 15:01:23 Valid Error = 0.71154230846169 
2016-12-12 15:01:23 Valid Loss = 0.035043655926599 
2016-12-12 15:01:32 Test Error = 0.7133 
2016-12-12 15:01:32 Test Loss = 0.035088717651367 
2016-12-12 15:01:32 -------------------LR------------------- 
2016-12-12 15:01:32 0.015625 
2016-12-12 15:01:32 Epoch 31 
2016-12-12 15:05:56 Training Error = 0.73271111111111 
2016-12-12 15:05:56 Training Loss = 0.035887269911024 
2016-12-12 15:06:00 Valid Error = 0.70854170834167 
2016-12-12 15:06:00 Valid Loss = 0.034987192912681 
2016-12-12 15:06:08 Test Error = 0.7133 
2016-12-12 15:06:08 Test Loss = 0.035049377929688 
2016-12-12 15:06:08 -------------------LR------------------- 
2016-12-12 15:06:08 0.015625 
2016-12-12 15:06:08 Epoch 32 
2016-12-12 15:10:29 Training Error = 0.73073333333333 
2016-12-12 15:10:29 Training Loss = 0.035855043782552 
2016-12-12 15:10:33 Valid Error = 0.6997399479896 
2016-12-12 15:10:33 Valid Loss = 0.034746528380981 
2016-12-12 15:10:41 Test Error = 0.7017 
2016-12-12 15:10:41 Test Loss = 0.034897216308594 
2016-12-12 15:10:41 -------------------LR------------------- 
2016-12-12 15:10:41 0.015625 
2016-12-12 15:10:41 Epoch 33 
2016-12-12 15:15:13 Training Error = 0.72793333333333 
2016-12-12 15:15:13 Training Loss = 0.035809751600477 
2016-12-12 15:15:16 Valid Error = 0.69893978795759 
2016-12-12 15:15:16 Valid Loss = 0.034721934629513 
2016-12-12 15:15:24 Test Error = 0.702 
2016-12-12 15:15:24 Test Loss = 0.034813885986328 
2016-12-12 15:15:24 -------------------LR------------------- 
2016-12-12 15:15:24 0.015625 
2016-12-12 15:15:24 Epoch 34 
2016-12-12 15:19:44 Training Error = 0.72528888888889 
2016-12-12 15:19:44 Training Loss = 0.035783289957682 
2016-12-12 15:19:48 Valid Error = 0.69633926785357 
2016-12-12 15:19:48 Valid Loss = 0.034581282523543 
2016-12-12 15:19:56 Test Error = 0.694 
2016-12-12 15:19:56 Test Loss = 0.03462068371582 
2016-12-12 15:19:56 -------------------LR------------------- 
2016-12-12 15:19:56 0.015625 
2016-12-12 15:19:56 Epoch 35 
2016-12-12 15:24:19 Training Error = 0.72422222222222 
2016-12-12 15:24:19 Training Loss = 0.035728676350911 
2016-12-12 15:24:23 Valid Error = 0.70694138827766 
2016-12-12 15:24:23 Valid Loss = 0.034770610091766 
2016-12-12 15:24:32 Test Error = 0.7056 
2016-12-12 15:24:32 Test Loss = 0.034840965209961 
2016-12-12 15:24:32 -------------------LR------------------- 
2016-12-12 15:24:32 0.015625 
2016-12-12 15:24:32 Epoch 36 
2016-12-12 15:29:01 Training Error = 0.72293333333333 
2016-12-12 15:29:01 Training Loss = 0.035663489746094 
2016-12-12 15:29:05 Valid Error = 0.69873974794959 
2016-12-12 15:29:05 Valid Loss = 0.034574740498086 
2016-12-12 15:29:13 Test Error = 0.7017 
2016-12-12 15:29:13 Test Loss = 0.034591445678711 
2016-12-12 15:29:13 -------------------LR------------------- 
2016-12-12 15:29:13 0.015625 
2016-12-12 15:29:13 Epoch 37 
2016-12-12 15:33:32 Training Error = 0.71577777777778 
2016-12-12 15:33:32 Training Loss = 0.035591959418403 
2016-12-12 15:33:36 Valid Error = 0.69773954790958 
2016-12-12 15:33:36 Valid Loss = 0.034526897776021 
2016-12-12 15:33:44 Test Error = 0.6944 
2016-12-12 15:33:44 Test Loss = 0.034580093261719 
2016-12-12 15:33:44 -------------------LR------------------- 
2016-12-12 15:33:44 0.015625 
2016-12-12 15:33:44 Epoch 38 
2016-12-12 15:38:13 Training Error = 0.71526666666667 
2016-12-12 15:38:13 Training Loss = 0.035562825358073 
2016-12-12 15:38:17 Valid Error = 0.69353870774155 
2016-12-12 15:38:17 Valid Loss = 0.034350935510181 
2016-12-12 15:38:25 Test Error = 0.6894 
2016-12-12 15:38:25 Test Loss = 0.034388463989258 
2016-12-12 15:38:25 -------------------LR------------------- 
2016-12-12 15:38:25 0.015625 
2016-12-12 15:38:25 Epoch 39 
2016-12-12 15:42:52 Training Error = 0.71191111111111 
2016-12-12 15:42:52 Training Loss = 0.035499212076823 
2016-12-12 15:42:55 Valid Error = 0.69313862772555 
2016-12-12 15:42:55 Valid Loss = 0.034367317071643 
2016-12-12 15:43:04 Test Error = 0.6924 
2016-12-12 15:43:04 Test Loss = 0.034512892089844 
2016-12-12 15:43:04 -------------------LR------------------- 
2016-12-12 15:43:04 0.015625 
2016-12-12 15:43:04 Epoch 40 
2016-12-12 15:47:28 Training Error = 0.71211111111111 
2016-12-12 15:47:28 Training Loss = 0.035476861463759 
2016-12-12 15:47:32 Valid Error = 0.69373874774955 
2016-12-12 15:47:32 Valid Loss = 0.034186542289168 
2016-12-12 15:47:41 Test Error = 0.692 
2016-12-12 15:47:41 Test Loss = 0.034203584350586 
2016-12-12 15:47:41 -------------------LR------------------- 
2016-12-12 15:47:41 0.015625 
2016-12-12 15:47:41 Epoch 41 
2016-12-12 15:52:17 Training Error = 0.71193333333333 
2016-12-12 15:52:17 Training Loss = 0.035430913085938 
2016-12-12 15:52:21 Valid Error = 0.68273654730946 
2016-12-12 15:52:21 Valid Loss = 0.034094307103465 
2016-12-12 15:52:28 Test Error = 0.6841 
2016-12-12 15:52:28 Test Loss = 0.034192652709961 
2016-12-12 15:52:28 -------------------LR------------------- 
2016-12-12 15:52:28 0.015625 
2016-12-12 15:52:28 Epoch 42 
2016-12-12 15:56:56 Training Error = 0.70588888888889 
2016-12-12 15:56:56 Training Loss = 0.035379327718099 
2016-12-12 15:57:00 Valid Error = 0.68933786757351 
2016-12-12 15:57:00 Valid Loss = 0.034070665880589 
2016-12-12 15:57:08 Test Error = 0.6873 
2016-12-12 15:57:08 Test Loss = 0.034126154663086 
2016-12-12 15:57:08 -------------------LR------------------- 
2016-12-12 15:57:08 0.015625 
2016-12-12 15:57:08 Epoch 43 
2016-12-12 16:01:36 Training Error = 0.70595555555556 
2016-12-12 16:01:36 Training Loss = 0.035361158311632 
2016-12-12 16:01:40 Valid Error = 0.6869373874775 
2016-12-12 16:01:40 Valid Loss = 0.034193111065882 
2016-12-12 16:01:48 Test Error = 0.687 
2016-12-12 16:01:48 Test Loss = 0.034234573364258 
2016-12-12 16:01:48 -------------------LR------------------- 
2016-12-12 16:01:48 0.015625 
2016-12-12 16:01:48 Epoch 44 
2016-12-12 16:06:17 Training Error = 0.70233333333333 
2016-12-12 16:06:17 Training Loss = 0.035309798394097 
2016-12-12 16:06:20 Valid Error = 0.69173834766953 
2016-12-12 16:06:20 Valid Loss = 0.034173285809901 
2016-12-12 16:06:29 Test Error = 0.6867 
2016-12-12 16:06:29 Test Loss = 0.034278969604492 
2016-12-12 16:06:29 -------------------LR------------------- 
2016-12-12 16:06:29 0.015625 
2016-12-12 16:06:29 Epoch 45 
2016-12-12 16:10:50 Training Error = 0.70531111111111 
2016-12-12 16:10:50 Training Loss = 0.035283600043403 
2016-12-12 16:10:54 Valid Error = 0.68493698739748 
2016-12-12 16:10:54 Valid Loss = 0.034119747490587 
2016-12-12 16:11:02 Test Error = 0.6819 
2016-12-12 16:11:02 Test Loss = 0.034143197387695 
2016-12-12 16:11:02 -------------------LR------------------- 
2016-12-12 16:11:02 0.015625 
2016-12-12 16:11:02 Epoch 46 
2016-12-12 16:15:32 Training Error = 0.70277777777778 
2016-12-12 16:15:32 Training Loss = 0.035226004720052 
2016-12-12 16:15:36 Valid Error = 0.67933586717343 
2016-12-12 16:15:36 Valid Loss = 0.034008244667069 
2016-12-12 16:15:44 Test Error = 0.6833 
2016-12-12 16:15:44 Test Loss = 0.034072666870117 
2016-12-12 16:15:44 -------------------LR------------------- 
2016-12-12 16:15:44 0.015625 
2016-12-12 16:15:44 Epoch 47 
2016-12-12 16:20:09 Training Error = 0.69511111111111 
2016-12-12 16:20:09 Training Loss = 0.03516927992079 
2016-12-12 16:20:13 Valid Error = 0.67733546709342 
2016-12-12 16:20:13 Valid Loss = 0.033727010137462 
2016-12-12 16:20:21 Test Error = 0.6752 
2016-12-12 16:20:21 Test Loss = 0.033813899658203 
2016-12-12 16:20:21 -------------------LR------------------- 
2016-12-12 16:20:21 0.015625 
2016-12-12 16:20:21 Epoch 48 
2016-12-12 16:24:44 Training Error = 0.69424444444444 
2016-12-12 16:24:44 Training Loss = 0.03516304155816 
2016-12-12 16:24:48 Valid Error = 0.68133626725345 
2016-12-12 16:24:48 Valid Loss = 0.033967852455888 
2016-12-12 16:24:56 Test Error = 0.6796 
2016-12-12 16:24:56 Test Loss = 0.033991372314453 
2016-12-12 16:24:56 -------------------LR------------------- 
2016-12-12 16:24:56 0.015625 
2016-12-12 16:24:56 Epoch 49 
2016-12-12 16:29:16 Training Error = 0.69426666666667 
2016-12-12 16:29:16 Training Loss = 0.035118210666233 
2016-12-12 16:29:20 Valid Error = 0.68673734746949 
2016-12-12 16:29:20 Valid Loss = 0.033954541919288 
2016-12-12 16:29:29 Test Error = 0.6824 
2016-12-12 16:29:29 Test Loss = 0.033985592041016 
2016-12-12 16:29:29 -------------------LR------------------- 
2016-12-12 16:29:29 0.015625 
2016-12-12 16:29:29 Epoch 50 
2016-12-12 16:34:01 Training Error = 0.69182222222222 
2016-12-12 16:34:01 Training Loss = 0.035044651123047 
2016-12-12 16:34:05 Valid Error = 0.6751350270054 
2016-12-12 16:34:05 Valid Loss = 0.033707024683645 
2016-12-12 16:34:14 Test Error = 0.672 
2016-12-12 16:34:14 Test Loss = 0.033752937866211 
2016-12-12 16:34:14 -------------------LR------------------- 
2016-12-12 16:34:14 0.0078125 
2016-12-12 16:34:14 Epoch 51 
2016-12-12 16:38:31 Training Error = 0.6832 
2016-12-12 16:38:31 Training Loss = 0.034892774576823 
2016-12-12 16:38:35 Valid Error = 0.67013402680536 
2016-12-12 16:38:35 Valid Loss = 0.033568174529234 
2016-12-12 16:38:43 Test Error = 0.6705 
2016-12-12 16:38:43 Test Loss = 0.033696693725586 
2016-12-12 16:38:43 -------------------LR------------------- 
2016-12-12 16:38:43 0.0078125 
2016-12-12 16:38:43 Epoch 52 
2016-12-12 16:43:10 Training Error = 0.68346666666667 
2016-12-12 16:43:10 Training Loss = 0.034884614664714 
2016-12-12 16:43:14 Valid Error = 0.66093218643729 
2016-12-12 16:43:14 Valid Loss = 0.03354303217519 
2016-12-12 16:43:22 Test Error = 0.6695 
2016-12-12 16:43:22 Test Loss = 0.033629515258789 
2016-12-12 16:43:22 -------------------LR------------------- 
2016-12-12 16:43:22 0.0078125 
2016-12-12 16:43:22 Epoch 53 
2016-12-12 16:47:55 Training Error = 0.6788 
2016-12-12 16:47:55 Training Loss = 0.034828491292318 
2016-12-12 16:47:59 Valid Error = 0.66633326665333 
2016-12-12 16:47:59 Valid Loss = 0.033649296479678 
2016-12-12 16:48:07 Test Error = 0.6695 
2016-12-12 16:48:07 Test Loss = 0.033723253662109 
2016-12-12 16:48:07 -------------------LR------------------- 
2016-12-12 16:48:07 0.0078125 
2016-12-12 16:48:07 Epoch 54 
2016-12-12 16:52:20 Training Error = 0.68166666666667 
2016-12-12 16:52:20 Training Loss = 0.034852562825521 
2016-12-12 16:52:24 Valid Error = 0.67793558711742 
2016-12-12 16:52:24 Valid Loss = 0.033592817114698 
2016-12-12 16:52:32 Test Error = 0.6745 
2016-12-12 16:52:32 Test Loss = 0.033634229614258 
2016-12-12 16:52:32 -------------------LR------------------- 
2016-12-12 16:52:32 0.0078125 
2016-12-12 16:52:32 Epoch 55 
2016-12-12 16:56:57 Training Error = 0.67804444444444 
2016-12-12 16:56:57 Training Loss = 0.034810752360026 
2016-12-12 16:57:01 Valid Error = 0.67373474694939 
2016-12-12 16:57:01 Valid Loss = 0.033570270471118 
2016-12-12 16:57:10 Test Error = 0.6721 
2016-12-12 16:57:10 Test Loss = 0.033643516845703 
2016-12-12 16:57:10 -------------------LR------------------- 
2016-12-12 16:57:10 0.0078125 
2016-12-12 16:57:10 Epoch 56 
2016-12-12 17:01:40 Training Error = 0.67844444444444 
2016-12-12 17:01:40 Training Loss = 0.034785484564887 
2016-12-12 17:01:43 Valid Error = 0.67073414682937 
2016-12-12 17:01:43 Valid Loss = 0.033649493669468 
2016-12-12 17:01:51 Test Error = 0.6757 
2016-12-12 17:01:51 Test Loss = 0.033683903808594 
2016-12-12 17:01:51 -------------------LR------------------- 
2016-12-12 17:01:51 0.0078125 
2016-12-12 17:01:51 Epoch 57 
2016-12-12 17:06:21 Training Error = 0.67751111111111 
2016-12-12 17:06:21 Training Loss = 0.034761441677517 
2016-12-12 17:06:25 Valid Error = 0.6627325465093 
2016-12-12 17:06:25 Valid Loss = 0.03349457957272 
2016-12-12 17:06:32 Test Error = 0.6691 
2016-12-12 17:06:32 Test Loss = 0.033541158447266 
2016-12-12 17:06:32 -------------------LR------------------- 
2016-12-12 17:06:32 0.0078125 
2016-12-12 17:06:32 Epoch 58 
2016-12-12 17:10:58 Training Error = 0.67662222222222 
2016-12-12 17:10:58 Training Loss = 0.034745726888021 
2016-12-12 17:11:02 Valid Error = 0.66593318663733 
2016-12-12 17:11:02 Valid Loss = 0.033429171884785 
2016-12-12 17:11:10 Test Error = 0.6661 
2016-12-12 17:11:10 Test Loss = 0.03350499206543 
2016-12-12 17:11:10 -------------------LR------------------- 
2016-12-12 17:11:10 0.0078125 
2016-12-12 17:11:10 Epoch 59 
2016-12-12 17:15:36 Training Error = 0.67597777777778 
2016-12-12 17:15:36 Training Loss = 0.034735792534722 
2016-12-12 17:15:40 Valid Error = 0.65733146629326 
2016-12-12 17:15:40 Valid Loss = 0.033151558816363 
2016-12-12 17:15:48 Test Error = 0.6597 
2016-12-12 17:15:48 Test Loss = 0.033196218139648 
2016-12-12 17:15:48 -------------------LR------------------- 
2016-12-12 17:15:48 0.0078125 
2016-12-12 17:15:48 Epoch 60 
2016-12-12 17:20:12 Training Error = 0.6728 
2016-12-12 17:20:12 Training Loss = 0.034686049560547 
2016-12-12 17:20:16 Valid Error = 0.66473294658932 
2016-12-12 17:20:16 Valid Loss = 0.033419591495491 
2016-12-12 17:20:25 Test Error = 0.6661 
2016-12-12 17:20:25 Test Loss = 0.033466689819336 
2016-12-12 17:20:25 -------------------LR------------------- 
2016-12-12 17:20:25 0.0078125 
2016-12-12 17:20:25 Epoch 61 
2016-12-12 17:25:01 Training Error = 0.67377777777778 
2016-12-12 17:25:01 Training Loss = 0.034651239067925 
2016-12-12 17:25:05 Valid Error = 0.6629325865173 
2016-12-12 17:25:05 Valid Loss = 0.033337455954389 
2016-12-12 17:25:13 Test Error = 0.6648 
2016-12-12 17:25:13 Test Loss = 0.033395711791992 
2016-12-12 17:25:13 -------------------LR------------------- 
2016-12-12 17:25:13 0.0078125 
2016-12-12 17:25:13 Epoch 62 
2016-12-12 17:29:45 Training Error = 0.67306666666667 
2016-12-12 17:29:45 Training Loss = 0.034685024468316 
2016-12-12 17:29:49 Valid Error = 0.6621324264853 
2016-12-12 17:29:49 Valid Loss = 0.033305498204417 
2016-12-12 17:29:57 Test Error = 0.6701 
2016-12-12 17:29:57 Test Loss = 0.033417484008789 
2016-12-12 17:29:57 -------------------LR------------------- 
2016-12-12 17:29:57 0.0078125 
2016-12-12 17:29:57 Epoch 63 
2016-12-12 17:34:19 Training Error = 0.67222222222222 
2016-12-12 17:34:19 Training Loss = 0.034633879584418 
2016-12-12 17:34:23 Valid Error = 0.65373074614923 
2016-12-12 17:34:23 Valid Loss = 0.03319887300382 
2016-12-12 17:34:30 Test Error = 0.6586 
2016-12-12 17:34:30 Test Loss = 0.033326086669922 
2016-12-12 17:34:30 -------------------LR------------------- 
2016-12-12 17:34:30 0.0078125 
2016-12-12 17:34:30 Epoch 64 
2016-12-12 17:39:04 Training Error = 0.6686 
2016-12-12 17:39:04 Training Loss = 0.034591029432509 
2016-12-12 17:39:07 Valid Error = 0.64792958591718 
2016-12-12 17:39:07 Valid Loss = 0.033237890825597 
2016-12-12 17:39:16 Test Error = 0.6583 
2016-12-12 17:39:16 Test Loss = 0.033234764404297 
2016-12-12 17:39:16 -------------------LR------------------- 
2016-12-12 17:39:16 0.0078125 
2016-12-12 17:39:16 Epoch 65 
2016-12-12 17:43:38 Training Error = 0.66937777777778 
2016-12-12 17:43:38 Training Loss = 0.034612221598307 
2016-12-12 17:43:42 Valid Error = 0.65753150630126 
2016-12-12 17:43:42 Valid Loss = 0.033241198571949 
2016-12-12 17:43:51 Test Error = 0.6523 
2016-12-12 17:43:51 Test Loss = 0.033225523803711 
2016-12-12 17:43:51 -------------------LR------------------- 
2016-12-12 17:43:51 0.0078125 
2016-12-12 17:43:51 Epoch 66 
2016-12-12 17:48:13 Training Error = 0.66784444444444 
2016-12-12 17:48:13 Training Loss = 0.034609768256293 
2016-12-12 17:48:17 Valid Error = 0.65393078615723 
2016-12-12 17:48:17 Valid Loss = 0.033059546218413 
2016-12-12 17:48:24 Test Error = 0.6574 
2016-12-12 17:48:24 Test Loss = 0.033185510742188 
2016-12-12 17:48:24 -------------------LR------------------- 
2016-12-12 17:48:24 0.0078125 
2016-12-12 17:48:24 Epoch 67 
2016-12-12 17:52:57 Training Error = 0.6676 
2016-12-12 17:52:57 Training Loss = 0.034589249647352 
2016-12-12 17:53:01 Valid Error = 0.65833166633327 
2016-12-12 17:53:01 Valid Loss = 0.033326280175096 
2016-12-12 17:53:09 Test Error = 0.6659 
2016-12-12 17:53:09 Test Loss = 0.03343637890625 
2016-12-12 17:53:09 -------------------LR------------------- 
2016-12-12 17:53:09 0.0078125 
2016-12-12 17:53:09 Epoch 68 
2016-12-12 17:57:28 Training Error = 0.66757777777778 
2016-12-12 17:57:28 Training Loss = 0.034581131510417 
2016-12-12 17:57:32 Valid Error = 0.65213042608522 
2016-12-12 17:57:32 Valid Loss = 0.033154579865786 
2016-12-12 17:57:39 Test Error = 0.6585 
2016-12-12 17:57:39 Test Loss = 0.033278018676758 
2016-12-12 17:57:39 -------------------LR------------------- 
2016-12-12 17:57:39 0.0078125 
2016-12-12 17:57:39 Epoch 69 
2016-12-12 18:02:03 Training Error = 0.66577777777778 
2016-12-12 18:02:03 Training Loss = 0.034526475260417 
2016-12-12 18:02:07 Valid Error = 0.64672934586917 
2016-12-12 18:02:07 Valid Loss = 0.033081941345582 
2016-12-12 18:02:15 Test Error = 0.6563 
2016-12-12 18:02:15 Test Loss = 0.033162337890625 
2016-12-12 18:02:15 -------------------LR------------------- 
2016-12-12 18:02:15 0.0078125 
2016-12-12 18:02:15 Epoch 70 
2016-12-12 18:06:52 Training Error = 0.66886666666667 
2016-12-12 18:06:52 Training Loss = 0.034541477647569 
2016-12-12 18:06:56 Valid Error = 0.64332866573315 
2016-12-12 18:06:56 Valid Loss = 0.032990356381709 
2016-12-12 18:07:05 Test Error = 0.654 
2016-12-12 18:07:05 Test Loss = 0.033099896362305 
2016-12-12 18:07:05 -------------------LR------------------- 
2016-12-12 18:07:05 0.0078125 
2016-12-12 18:07:05 Epoch 71 
2016-12-12 18:11:22 Training Error = 0.66953333333333 
2016-12-12 18:11:22 Training Loss = 0.034503695203993 
2016-12-12 18:11:26 Valid Error = 0.64892978595719 
2016-12-12 18:11:26 Valid Loss = 0.033035283334247 
2016-12-12 18:11:34 Test Error = 0.658 
2016-12-12 18:11:34 Test Loss = 0.033093374023437 
2016-12-12 18:11:34 -------------------LR------------------- 
2016-12-12 18:11:34 0.0078125 
2016-12-12 18:11:34 Epoch 72 
2016-12-12 18:16:05 Training Error = 0.66315555555556 
2016-12-12 18:16:05 Training Loss = 0.034473026421441 
2016-12-12 18:16:09 Valid Error = 0.65073014602921 
2016-12-12 18:16:09 Valid Loss = 0.033059133458812 
2016-12-12 18:16:17 Test Error = 0.6578 
2016-12-12 18:16:17 Test Loss = 0.033151778686523 
2016-12-12 18:16:17 -------------------LR------------------- 
2016-12-12 18:16:17 0.0078125 
2016-12-12 18:16:17 Epoch 73 
2016-12-12 18:20:47 Training Error = 0.66242222222222 
2016-12-12 18:20:47 Training Loss = 0.034452561984592 
2016-12-12 18:20:51 Valid Error = 0.64272854570914 
2016-12-12 18:20:51 Valid Loss = 0.032822644608553 
2016-12-12 18:20:59 Test Error = 0.6489 
2016-12-12 18:20:59 Test Loss = 0.032933982177734 
2016-12-12 18:20:59 -------------------LR------------------- 
2016-12-12 18:20:59 0.0078125 
2016-12-12 18:20:59 Epoch 74 
2016-12-12 18:25:21 Training Error = 0.66182222222222 
2016-12-12 18:25:21 Training Loss = 0.03445775632053 
2016-12-12 18:25:25 Valid Error = 0.65353070614123 
2016-12-12 18:25:25 Valid Loss = 0.03319741334867 
2016-12-12 18:25:33 Test Error = 0.657 
2016-12-12 18:25:33 Test Loss = 0.033205313476563 
2016-12-12 18:25:33 -------------------LR------------------- 
2016-12-12 18:25:33 0.0078125 
2016-12-12 18:25:33 Epoch 75 
2016-12-12 18:29:59 Training Error = 0.66233333333333 
2016-12-12 18:29:59 Training Loss = 0.034423055718316 
2016-12-12 18:30:03 Valid Error = 0.64632926585317 
2016-12-12 18:30:03 Valid Loss = 0.032909550989675 
2016-12-12 18:30:12 Test Error = 0.6477 
2016-12-12 18:30:12 Test Loss = 0.032968576538086 
2016-12-12 18:30:12 -------------------LR------------------- 
2016-12-12 18:30:12 0.0078125 
2016-12-12 18:30:12 Epoch 76 
2016-12-12 18:34:41 Training Error = 0.65915555555556 
2016-12-12 18:34:41 Training Loss = 0.034386430718316 
2016-12-12 18:34:45 Valid Error = 0.64672934586917 
2016-12-12 18:34:45 Valid Loss = 0.033023103819945 
2016-12-12 18:34:53 Test Error = 0.6534 
2016-12-12 18:34:53 Test Loss = 0.03306041003418 
2016-12-12 18:34:53 -------------------LR------------------- 
2016-12-12 18:34:53 0.0078125 
2016-12-12 18:34:53 Epoch 77 
2016-12-12 18:39:18 Training Error = 0.66 
2016-12-12 18:39:18 Training Loss = 0.034388194797092 
2016-12-12 18:39:22 Valid Error = 0.65113022604521 
2016-12-12 18:39:22 Valid Loss = 0.033072018007695 
2016-12-12 18:39:30 Test Error = 0.6573 
2016-12-12 18:39:30 Test Loss = 0.033125855957031 
2016-12-12 18:39:30 -------------------LR------------------- 
2016-12-12 18:39:30 0.0078125 
2016-12-12 18:39:30 Epoch 78 
2016-12-12 18:43:50 Training Error = 0.65944444444444 
2016-12-12 18:43:50 Training Loss = 0.034371318142361 
2016-12-12 18:43:54 Valid Error = 0.65713142628526 
2016-12-12 18:43:54 Valid Loss = 0.033126345212397 
2016-12-12 18:44:02 Test Error = 0.6598 
2016-12-12 18:44:02 Test Loss = 0.033183735351563 
2016-12-12 18:44:02 -------------------LR------------------- 
2016-12-12 18:44:02 0.0078125 
2016-12-12 18:44:02 Epoch 79 
2016-12-12 18:48:31 Training Error = 0.6604 
2016-12-12 18:48:31 Training Loss = 0.034331202311198 
2016-12-12 18:48:35 Valid Error = 0.64352870574115 
2016-12-12 18:48:35 Valid Loss = 0.032782618680721 
2016-12-12 18:48:43 Test Error = 0.6438 
2016-12-12 18:48:43 Test Loss = 0.03287973059082 
2016-12-12 18:48:43 -------------------LR------------------- 
2016-12-12 18:48:43 0.0078125 
2016-12-12 18:48:43 Epoch 80 
2016-12-12 18:53:05 Training Error = 0.65844444444444 
2016-12-12 18:53:05 Training Loss = 0.034362431396484 
2016-12-12 18:53:09 Valid Error = 0.64512902580516 
2016-12-12 18:53:09 Valid Loss = 0.032741936584595 
2016-12-12 18:53:18 Test Error = 0.6485 
2016-12-12 18:53:18 Test Loss = 0.032825397094727 
2016-12-12 18:53:18 -------------------LR------------------- 
2016-12-12 18:53:18 0.0078125 
2016-12-12 18:53:18 Epoch 81 
2016-12-12 18:57:54 Training Error = 0.65864444444444 
2016-12-12 18:57:54 Training Loss = 0.034338283393012 
2016-12-12 18:57:58 Valid Error = 0.64412882576515 
2016-12-12 18:57:58 Valid Loss = 0.032799806700804 
2016-12-12 18:58:06 Test Error = 0.645 
2016-12-12 18:58:06 Test Loss = 0.032869776123047 
2016-12-12 18:58:06 -------------------LR------------------- 
2016-12-12 18:58:06 0.0078125 
2016-12-12 18:58:06 Epoch 82 
2016-12-12 19:02:36 Training Error = 0.65753333333333 
2016-12-12 19:02:36 Training Loss = 0.034337055772569 
2016-12-12 19:02:40 Valid Error = 0.64552910582116 
2016-12-12 19:02:40 Valid Loss = 0.032856310276804 
2016-12-12 19:02:47 Test Error = 0.6487 
2016-12-12 19:02:47 Test Loss = 0.032919115112305 
2016-12-12 19:02:47 -------------------LR------------------- 
2016-12-12 19:02:47 0.0078125 
2016-12-12 19:02:48 Epoch 83 
2016-12-12 19:07:01 Training Error = 0.65708888888889 
2016-12-12 19:07:01 Training Loss = 0.034294547607422 
2016-12-12 19:07:05 Valid Error = 0.64572914582917 
2016-12-12 19:07:05 Valid Loss = 0.032841946661389 
2016-12-12 19:07:13 Test Error = 0.649 
2016-12-12 19:07:13 Test Loss = 0.032951545654297 
2016-12-12 19:07:13 -------------------LR------------------- 
2016-12-12 19:07:13 0.0078125 
2016-12-12 19:07:13 Epoch 84 
2016-12-12 19:11:48 Training Error = 0.65473333333333 
2016-12-12 19:11:48 Training Loss = 0.034304566433377 
2016-12-12 19:11:52 Valid Error = 0.65153030606121 
2016-12-12 19:11:52 Valid Loss = 0.032920551986297 
2016-12-12 19:12:00 Test Error = 0.6517 
2016-12-12 19:12:00 Test Loss = 0.033029784790039 
2016-12-12 19:12:00 -------------------LR------------------- 
2016-12-12 19:12:00 0.0078125 
2016-12-12 19:12:00 Epoch 85 
2016-12-12 19:16:19 Training Error = 0.6558 
2016-12-12 19:16:19 Training Loss = 0.034261252007378 
2016-12-12 19:16:23 Valid Error = 0.65213042608522 
2016-12-12 19:16:23 Valid Loss = 0.033093908769199 
2016-12-12 19:16:32 Test Error = 0.6522 
2016-12-12 19:16:32 Test Loss = 0.033099968505859 
2016-12-12 19:16:32 -------------------LR------------------- 
2016-12-12 19:16:32 0.0078125 
2016-12-12 19:16:32 Epoch 86 
2016-12-12 19:20:58 Training Error = 0.65533333333333 
2016-12-12 19:20:58 Training Loss = 0.034246342013889 
2016-12-12 19:21:02 Valid Error = 0.65473094618924 
2016-12-12 19:21:02 Valid Loss = 0.033027623806695 
2016-12-12 19:21:10 Test Error = 0.6568 
2016-12-12 19:21:10 Test Loss = 0.033064716674805 
2016-12-12 19:21:10 -------------------LR------------------- 
2016-12-12 19:21:10 0.0078125 
2016-12-12 19:21:10 Epoch 87 
2016-12-12 19:25:42 Training Error = 0.65513333333333 
2016-12-12 19:25:42 Training Loss = 0.034235694525825 
2016-12-12 19:25:46 Valid Error = 0.64632926585317 
2016-12-12 19:25:46 Valid Loss = 0.032889827806003 
2016-12-12 19:25:53 Test Error = 0.6517 
2016-12-12 19:25:53 Test Loss = 0.032951364135742 
2016-12-12 19:25:53 -------------------LR------------------- 
2016-12-12 19:25:53 0.0078125 
2016-12-12 19:25:53 Epoch 88 
2016-12-12 19:30:12 Training Error = 0.65404444444444 
2016-12-12 19:30:12 Training Loss = 0.034219120307075 
2016-12-12 19:30:16 Valid Error = 0.64652930586117 
2016-12-12 19:30:16 Valid Loss = 0.032851993043215 
2016-12-12 19:30:23 Test Error = 0.6536 
2016-12-12 19:30:23 Test Loss = 0.033002920532227 
2016-12-12 19:30:23 -------------------LR------------------- 
2016-12-12 19:30:23 0.0078125 
2016-12-12 19:30:23 Epoch 89 
2016-12-12 19:34:46 Training Error = 0.6548 
2016-12-12 19:34:46 Training Loss = 0.034233835449219 
2016-12-12 19:34:49 Valid Error = 0.62652530506101 
2016-12-12 19:34:49 Valid Loss = 0.032437061742626 
2016-12-12 19:34:58 Test Error = 0.6347 
2016-12-12 19:34:58 Test Loss = 0.032525276367187 
2016-12-12 19:34:58 -------------------LR------------------- 
2016-12-12 19:34:58 0.0078125 
2016-12-12 19:34:58 Epoch 90 
2016-12-12 19:39:30 Training Error = 0.65248888888889 
2016-12-12 19:39:30 Training Loss = 0.034200065538194 
2016-12-12 19:39:34 Valid Error = 0.64612922584517 
2016-12-12 19:39:34 Valid Loss = 0.032818961371963 
2016-12-12 19:39:43 Test Error = 0.649 
2016-12-12 19:39:43 Test Loss = 0.032899402099609 
2016-12-12 19:39:43 -------------------LR------------------- 
2016-12-12 19:39:43 0.0078125 
2016-12-12 19:39:43 Epoch 91 
2016-12-12 19:44:05 Training Error = 0.65237777777778 
2016-12-12 19:44:05 Training Loss = 0.034189516357422 
2016-12-12 19:44:08 Valid Error = 0.64512902580516 
2016-12-12 19:44:08 Valid Loss = 0.032958863100713 
2016-12-12 19:44:16 Test Error = 0.6471 
2016-12-12 19:44:16 Test Loss = 0.033000893310547 
2016-12-12 19:44:16 -------------------LR------------------- 
2016-12-12 19:44:16 0.0078125 
2016-12-12 19:44:16 Epoch 92 
2016-12-12 19:48:39 Training Error = 0.64957777777778 
2016-12-12 19:48:39 Training Loss = 0.03417010413954 
2016-12-12 19:48:43 Valid Error = 0.63452690538108 
2016-12-12 19:48:43 Valid Loss = 0.032754279499429 
2016-12-12 19:48:51 Test Error = 0.6394 
2016-12-12 19:48:51 Test Loss = 0.032809924682617 
2016-12-12 19:48:51 -------------------LR------------------- 
2016-12-12 19:48:51 0.0078125 
2016-12-12 19:48:51 Epoch 93 
2016-12-12 19:53:18 Training Error = 0.64833333333333 
2016-12-12 19:53:18 Training Loss = 0.034151207221137 
2016-12-12 19:53:22 Valid Error = 0.64012802560512 
2016-12-12 19:53:22 Valid Loss = 0.032452182334395 
2016-12-12 19:53:29 Test Error = 0.6413 
2016-12-12 19:53:29 Test Loss = 0.03251215625 
2016-12-12 19:53:29 -------------------LR------------------- 
2016-12-12 19:53:29 0.0078125 
2016-12-12 19:53:30 Epoch 94 
2016-12-12 19:57:56 Training Error = 0.64875555555556 
2016-12-12 19:57:56 Training Loss = 0.034143858317057 
2016-12-12 19:58:00 Valid Error = 0.64192838567714 
2016-12-12 19:58:00 Valid Loss = 0.032638792401698 
2016-12-12 19:58:09 Test Error = 0.6444 
2016-12-12 19:58:09 Test Loss = 0.032721561401367 
2016-12-12 19:58:09 -------------------LR------------------- 
2016-12-12 19:58:09 0.0078125 
2016-12-12 19:58:09 Epoch 95 
2016-12-12 20:02:28 Training Error = 0.65155555555556 
2016-12-12 20:02:28 Training Loss = 0.034117068386502 
2016-12-12 20:02:32 Valid Error = 0.6503300660132 
2016-12-12 20:02:32 Valid Loss = 0.032603084203074 
2016-12-12 20:02:41 Test Error = 0.6451 
2016-12-12 20:02:41 Test Loss = 0.032649466186523 
2016-12-12 20:02:41 -------------------LR------------------- 
2016-12-12 20:02:41 0.0078125 
2016-12-12 20:02:41 Epoch 96 
2016-12-12 20:07:19 Training Error = 0.64895555555556 
2016-12-12 20:07:19 Training Loss = 0.034111698133681 
2016-12-12 20:07:23 Valid Error = 0.63672734546909 
2016-12-12 20:07:23 Valid Loss = 0.032516873732328 
2016-12-12 20:07:31 Test Error = 0.6399 
2016-12-12 20:07:31 Test Loss = 0.032632282470703 
2016-12-12 20:07:31 -------------------LR------------------- 
2016-12-12 20:07:31 0.0078125 
2016-12-12 20:07:31 Epoch 97 
2016-12-12 20:11:47 Training Error = 0.64764444444444 
2016-12-12 20:11:47 Training Loss = 0.034097390272352 
2016-12-12 20:11:51 Valid Error = 0.63452690538108 
2016-12-12 20:11:51 Valid Loss = 0.032566292854752 
2016-12-12 20:11:58 Test Error = 0.6344 
2016-12-12 20:11:58 Test Loss = 0.032603131103516 
2016-12-12 20:11:58 -------------------LR------------------- 
2016-12-12 20:11:58 0.0078125 
2016-12-12 20:11:58 Epoch 98 
2016-12-12 20:16:22 Training Error = 0.64771111111111 
2016-12-12 20:16:22 Training Loss = 0.034082761501736 
2016-12-12 20:16:26 Valid Error = 0.64472894578916 
2016-12-12 20:16:26 Valid Loss = 0.032804663544374 
2016-12-12 20:16:33 Test Error = 0.6513 
2016-12-12 20:16:33 Test Loss = 0.032840712036133 
2016-12-12 20:16:33 -------------------LR------------------- 
2016-12-12 20:16:33 0.0078125 
2016-12-12 20:16:33 Epoch 99 
2016-12-12 20:21:10 Training Error = 0.64462222222222 
2016-12-12 20:21:10 Training Loss = 0.034063699978299 
2016-12-12 20:21:13 Valid Error = 0.63832766553311 
2016-12-12 20:21:13 Valid Loss = 0.032638058572712 
2016-12-12 20:21:22 Test Error = 0.6383 
2016-12-12 20:21:22 Test Loss = 0.032624771484375 
2016-12-12 20:21:22 -------------------LR------------------- 
2016-12-12 20:21:22 0.0078125 
2016-12-12 20:21:22 Epoch 100 
2016-12-12 20:25:36 Training Error = 0.64615555555556 
2016-12-12 20:25:36 Training Loss = 0.03404616813151 
2016-12-12 20:25:40 Valid Error = 0.64692938587718 
2016-12-12 20:25:40 Valid Loss = 0.032749359748794 
2016-12-12 20:25:49 Test Error = 0.6464 
2016-12-12 20:25:49 Test Loss = 0.032862787719727 
2016-12-12 20:25:49 -------------------LR------------------- 
2016-12-12 20:25:49 0.00390625 
2016-12-12 20:25:49 Epoch 101 
2016-12-12 20:30:24 Training Error = 0.64037777777778 
2016-12-12 20:30:24 Training Loss = 0.033882097005208 
2016-12-12 20:30:27 Valid Error = 0.63552710542108 
2016-12-12 20:30:27 Valid Loss = 0.03240379324665 
2016-12-12 20:30:35 Test Error = 0.6444 
2016-12-12 20:30:35 Test Loss = 0.032467541625977 
2016-12-12 20:30:35 -------------------LR------------------- 
2016-12-12 20:30:35 0.00390625 
2016-12-12 20:30:35 Epoch 102 
2016-12-12 20:35:00 Training Error = 0.63891111111111 
2016-12-12 20:35:00 Training Loss = 0.033858584472656 
2016-12-12 20:35:03 Valid Error = 0.63392678535707 
2016-12-12 20:35:03 Valid Loss = 0.032491752509903 
2016-12-12 20:35:11 Test Error = 0.6387 
2016-12-12 20:35:11 Test Loss = 0.032541429321289 
2016-12-12 20:35:11 -------------------LR------------------- 
2016-12-12 20:35:11 0.00390625 
2016-12-12 20:35:11 Epoch 103 
2016-12-12 20:39:36 Training Error = 0.63693333333333 
2016-12-12 20:39:36 Training Loss = 0.033849638373481 
2016-12-12 20:39:40 Valid Error = 0.6377275455091 
2016-12-12 20:39:40 Valid Loss = 0.032448835655197 
2016-12-12 20:39:48 Test Error = 0.6399 
2016-12-12 20:39:48 Test Loss = 0.032497673217773 
2016-12-12 20:39:48 -------------------LR------------------- 
2016-12-12 20:39:48 0.00390625 
2016-12-12 20:39:48 Epoch 104 
2016-12-12 20:44:21 Training Error = 0.64037777777778 
2016-12-12 20:44:21 Training Loss = 0.033889051378038 
2016-12-12 20:44:25 Valid Error = 0.63012602520504 
2016-12-12 20:44:25 Valid Loss = 0.032510292822461 
2016-12-12 20:44:34 Test Error = 0.6369 
2016-12-12 20:44:34 Test Loss = 0.032564100585937 
2016-12-12 20:44:34 -------------------LR------------------- 
2016-12-12 20:44:34 0.00390625 
2016-12-12 20:44:34 Epoch 105 
2016-12-12 20:48:57 Training Error = 0.63682222222222 
2016-12-12 20:48:57 Training Loss = 0.033848774983724 
2016-12-12 20:49:01 Valid Error = 0.63532706541308 
2016-12-12 20:49:01 Valid Loss = 0.032475934747425 
2016-12-12 20:49:10 Test Error = 0.6402 
2016-12-12 20:49:10 Test Loss = 0.032546979003906 
2016-12-12 20:49:10 -------------------LR------------------- 
2016-12-12 20:49:10 0.00390625 
2016-12-12 20:49:10 Epoch 106 
2016-12-12 20:53:36 Training Error = 0.63971111111111 
2016-12-12 20:53:36 Training Loss = 0.033885786024306 
2016-12-12 20:53:40 Valid Error = 0.63212642528506 
2016-12-12 20:53:40 Valid Loss = 0.032556473276631 
2016-12-12 20:53:47 Test Error = 0.6402 
2016-12-12 20:53:47 Test Loss = 0.032607534179688 
2016-12-12 20:53:47 -------------------LR------------------- 
2016-12-12 20:53:47 0.00390625 
2016-12-12 20:53:48 Epoch 107 
2016-12-12 20:58:18 Training Error = 0.63624444444444 
2016-12-12 20:58:18 Training Loss = 0.033823208414714 
2016-12-12 20:58:22 Valid Error = 0.63952790558112 
2016-12-12 20:58:22 Valid Loss = 0.032465011310707 
2016-12-12 20:58:30 Test Error = 0.6372 
2016-12-12 20:58:30 Test Loss = 0.032540568847656 
2016-12-12 20:58:30 -------------------LR------------------- 
2016-12-12 20:58:30 0.00390625 
2016-12-12 20:58:30 Epoch 108 
2016-12-12 21:02:59 Training Error = 0.63891111111111 
2016-12-12 21:02:59 Training Loss = 0.033832629801432 
2016-12-12 21:03:03 Valid Error = 0.63412682536507 
2016-12-12 21:03:03 Valid Loss = 0.03232922871084 
2016-12-12 21:03:11 Test Error = 0.6359 
2016-12-12 21:03:11 Test Loss = 0.032448055297852 
2016-12-12 21:03:11 -------------------LR------------------- 
2016-12-12 21:03:11 0.00390625 
2016-12-12 21:03:11 Epoch 109 
2016-12-12 21:07:28 Training Error = 0.63833333333333 
2016-12-12 21:07:28 Training Loss = 0.033824430175781 
2016-12-12 21:07:32 Valid Error = 0.64372874574915 
2016-12-12 21:07:32 Valid Loss = 0.032623331858052 
2016-12-12 21:07:41 Test Error = 0.644 
2016-12-12 21:07:41 Test Loss = 0.032659670654297 
2016-12-12 21:07:41 -------------------LR------------------- 
2016-12-12 21:07:41 0.00390625 
2016-12-12 21:07:41 Epoch 110 
2016-12-12 21:12:18 Training Error = 0.63577777777778 
2016-12-12 21:12:18 Training Loss = 0.033787426459418 
2016-12-12 21:12:22 Valid Error = 0.63372674534907 
2016-12-12 21:12:22 Valid Loss = 0.032468685645705 
2016-12-12 21:12:31 Test Error = 0.6435 
2016-12-12 21:12:31 Test Loss = 0.032588698120117 
2016-12-12 21:12:31 -------------------LR------------------- 
2016-12-12 21:12:31 0.00390625 
2016-12-12 21:12:31 Epoch 111 
2016-12-12 21:17:01 Training Error = 0.63535555555556 
2016-12-12 21:17:01 Training Loss = 0.033848483615451 
2016-12-12 21:17:05 Valid Error = 0.64232846569314 
2016-12-12 21:17:05 Valid Loss = 0.032652291636496 
2016-12-12 21:17:12 Test Error = 0.6404 
2016-12-12 21:17:12 Test Loss = 0.032704102539063 
2016-12-12 21:17:12 -------------------LR------------------- 
2016-12-12 21:17:12 0.00390625 
2016-12-12 21:17:12 Epoch 112 
2016-12-12 21:21:29 Training Error = 0.63508888888889 
2016-12-12 21:21:29 Training Loss = 0.033799216959635 
2016-12-12 21:21:33 Valid Error = 0.62392478495699 
2016-12-12 21:21:33 Valid Loss = 0.032237973703266 
2016-12-12 21:21:40 Test Error = 0.6303 
2016-12-12 21:21:40 Test Loss = 0.032295801513672 
2016-12-12 21:21:40 -------------------LR------------------- 
2016-12-12 21:21:40 0.00390625 
2016-12-12 21:21:41 Epoch 113 
2016-12-12 21:26:14 Training Error = 0.63435555555556 
2016-12-12 21:26:14 Training Loss = 0.03380742835829 
2016-12-12 21:26:18 Valid Error = 0.6371274254851 
2016-12-12 21:26:18 Valid Loss = 0.032464199299967 
2016-12-12 21:26:26 Test Error = 0.6396 
2016-12-12 21:26:26 Test Loss = 0.032540522705078 
2016-12-12 21:26:26 -------------------LR------------------- 
2016-12-12 21:26:26 0.00390625 
2016-12-12 21:26:26 Epoch 114 
2016-12-12 21:30:42 Training Error = 0.63315555555556 
2016-12-12 21:30:42 Training Loss = 0.033766876356337 
2016-12-12 21:30:45 Valid Error = 0.625125025005 
2016-12-12 21:30:45 Valid Loss = 0.032058498449047 
2016-12-12 21:30:54 Test Error = 0.6225 
2016-12-12 21:30:54 Test Loss = 0.032204318725586 
2016-12-12 21:30:54 -------------------LR------------------- 
2016-12-12 21:30:54 0.00390625 
2016-12-12 21:30:54 Epoch 115 
2016-12-12 21:35:11 Training Error = 0.63473333333333 
2016-12-12 21:35:11 Training Loss = 0.033766946316189 
2016-12-12 21:35:15 Valid Error = 0.63532706541308 
2016-12-12 21:35:15 Valid Loss = 0.032377786638707 
2016-12-12 21:35:24 Test Error = 0.636 
2016-12-12 21:35:24 Test Loss = 0.032432442260742 
2016-12-12 21:35:24 -------------------LR------------------- 
2016-12-12 21:35:24 0.00390625 
2016-12-12 21:35:24 Epoch 116 
2016-12-12 21:40:05 Training Error = 0.63235555555556 
2016-12-12 21:40:05 Training Loss = 0.033760329915365 
2016-12-12 21:40:08 Valid Error = 0.64172834566913 
2016-12-12 21:40:08 Valid Loss = 0.032536823705517 
2016-12-12 21:40:16 Test Error = 0.6389 
2016-12-12 21:40:16 Test Loss = 0.032578509399414 
2016-12-12 21:40:16 -------------------LR------------------- 
2016-12-12 21:40:16 0.00390625 
2016-12-12 21:40:16 Epoch 117 
2016-12-12 21:44:34 Training Error = 0.63526666666667 
2016-12-12 21:44:34 Training Loss = 0.033754240261502 
2016-12-12 21:44:38 Valid Error = 0.62832566513303 
2016-12-12 21:44:38 Valid Loss = 0.032211957430486 
2016-12-12 21:44:46 Test Error = 0.6297 
2016-12-12 21:44:46 Test Loss = 0.032219938354492 
2016-12-12 21:44:46 -------------------LR------------------- 
2016-12-12 21:44:46 0.00390625 
2016-12-12 21:44:46 Epoch 118 
2016-12-12 21:49:11 Training Error = 0.63188888888889 
2016-12-12 21:49:11 Training Loss = 0.033728297634549 
2016-12-12 21:49:15 Valid Error = 0.64032806561312 
2016-12-12 21:49:15 Valid Loss = 0.03260538569424 
2016-12-12 21:49:22 Test Error = 0.6403 
2016-12-12 21:49:22 Test Loss = 0.032618252197266 
2016-12-12 21:49:22 -------------------LR------------------- 
2016-12-12 21:49:22 0.00390625 
2016-12-12 21:49:23 Epoch 119 
2016-12-12 21:53:47 Training Error = 0.63417777777778 
2016-12-12 21:53:47 Training Loss = 0.033757525770399 
2016-12-12 21:53:51 Valid Error = 0.63372674534907 
2016-12-12 21:53:51 Valid Loss = 0.032241988346322 
2016-12-12 21:54:00 Test Error = 0.6326 
2016-12-12 21:54:00 Test Loss = 0.032288923217773 
2016-12-12 21:54:00 -------------------LR------------------- 
2016-12-12 21:54:00 0.00390625 
2016-12-12 21:54:00 Epoch 120 
2016-12-12 21:58:24 Training Error = 0.63153333333333 
2016-12-12 21:58:24 Training Loss = 0.03371961054145 
2016-12-12 21:58:28 Valid Error = 0.62752550510102 
2016-12-12 21:58:28 Valid Loss = 0.032250927106655 
2016-12-12 21:58:37 Test Error = 0.6286 
2016-12-12 21:58:37 Test Loss = 0.032339415405273 
2016-12-12 21:58:37 -------------------LR------------------- 
2016-12-12 21:58:37 0.00390625 
2016-12-12 21:58:37 Epoch 121 
2016-12-12 22:03:14 Training Error = 0.63144444444444 
2016-12-12 22:03:14 Training Loss = 0.033708240722656 
2016-12-12 22:03:18 Valid Error = 0.63412682536507 
2016-12-12 22:03:18 Valid Loss = 0.032452822516615 
2016-12-12 22:03:26 Test Error = 0.6393 
2016-12-12 22:03:26 Test Loss = 0.032538307373047 
2016-12-12 22:03:26 -------------------LR------------------- 
2016-12-12 22:03:26 0.00390625 
2016-12-12 22:03:26 Epoch 122 
2016-12-12 22:07:47 Training Error = 0.63086666666667 
2016-12-12 22:07:47 Training Loss = 0.033716210557726 
2016-12-12 22:07:51 Valid Error = 0.63212642528506 
2016-12-12 22:07:51 Valid Loss = 0.032351405398688 
2016-12-12 22:07:59 Test Error = 0.6384 
2016-12-12 22:07:59 Test Loss = 0.03241444519043 
2016-12-12 22:07:59 -------------------LR------------------- 
2016-12-12 22:07:59 0.00390625 
2016-12-12 22:07:59 Epoch 123 
2016-12-12 22:12:21 Training Error = 0.63262222222222 
2016-12-12 22:12:21 Training Loss = 0.033724024007161 
2016-12-12 22:12:25 Valid Error = 0.62372474494899 
2016-12-12 22:12:25 Valid Loss = 0.031974596364604 
2016-12-12 22:12:32 Test Error = 0.6186 
2016-12-12 22:12:32 Test Loss = 0.032053602172852 
2016-12-12 22:12:32 -------------------LR------------------- 
2016-12-12 22:12:32 0.00390625 
2016-12-12 22:12:32 Epoch 124 
2016-12-12 22:16:54 Training Error = 0.63268888888889 
2016-12-12 22:16:54 Training Loss = 0.0337094609375 
2016-12-12 22:16:58 Valid Error = 0.63392678535707 
2016-12-12 22:16:58 Valid Loss = 0.032303848537407 
2016-12-12 22:17:07 Test Error = 0.6373 
2016-12-12 22:17:07 Test Loss = 0.032366124511719 
2016-12-12 22:17:07 -------------------LR------------------- 
2016-12-12 22:17:07 0.00390625 
2016-12-12 22:17:07 Epoch 125 
2016-12-12 22:21:32 Training Error = 0.63202222222222 
2016-12-12 22:21:32 Training Loss = 0.033692454779731 
2016-12-12 22:21:36 Valid Error = 0.62732546509302 
2016-12-12 22:21:36 Valid Loss = 0.032292805081843 
2016-12-12 22:21:45 Test Error = 0.6315 
2016-12-12 22:21:45 Test Loss = 0.032296985107422 
2016-12-12 22:21:45 -------------------LR------------------- 
2016-12-12 22:21:45 0.00390625 
2016-12-12 22:21:45 Epoch 126 
2016-12-12 22:26:03 Training Error = 0.6314 
2016-12-12 22:26:03 Training Loss = 0.033726461127387 
2016-12-12 22:26:07 Valid Error = 0.61592318463693 
2016-12-12 22:26:07 Valid Loss = 0.031884242411581 
2016-12-12 22:26:15 Test Error = 0.6209 
2016-12-12 22:26:15 Test Loss = 0.031930809448242 
2016-12-12 22:26:15 -------------------LR------------------- 
2016-12-12 22:26:15 0.00390625 
2016-12-12 22:26:15 Epoch 127 
2016-12-12 22:30:52 Training Error = 0.62997777777778 
2016-12-12 22:30:52 Training Loss = 0.033690538438585 
2016-12-12 22:30:56 Valid Error = 0.61472294458892 
2016-12-12 22:30:56 Valid Loss = 0.031922419478606 
2016-12-12 22:31:04 Test Error = 0.618 
2016-12-12 22:31:04 Test Loss = 0.03199422253418 
2016-12-12 22:31:04 -------------------LR------------------- 
2016-12-12 22:31:04 0.00390625 
2016-12-12 22:31:04 Epoch 128 
2016-12-12 22:35:24 Training Error = 0.63073333333333 
2016-12-12 22:35:24 Training Loss = 0.033696241265191 
2016-12-12 22:35:28 Valid Error = 0.61792358471694 
2016-12-12 22:35:28 Valid Loss = 0.031971590175468 
2016-12-12 22:35:36 Test Error = 0.6269 
2016-12-12 22:35:36 Test Loss = 0.032071100708008 
2016-12-12 22:35:36 -------------------LR------------------- 
2016-12-12 22:35:36 0.00390625 
2016-12-12 22:35:36 Epoch 129 
2016-12-12 22:39:54 Training Error = 0.63024444444444 
2016-12-12 22:39:54 Training Loss = 0.033678864501953 
2016-12-12 22:39:58 Valid Error = 0.61372274454891 
2016-12-12 22:39:58 Valid Loss = 0.031812040789098 
2016-12-12 22:40:06 Test Error = 0.6188 
2016-12-12 22:40:06 Test Loss = 0.031956585449219 
2016-12-12 22:40:06 -------------------LR------------------- 
2016-12-12 22:40:06 0.00390625 
2016-12-12 22:40:06 Epoch 130 
2016-12-12 22:44:42 Training Error = 0.63046666666667 
2016-12-12 22:44:42 Training Loss = 0.033669299831814 
2016-12-12 22:44:46 Valid Error = 0.63372674534907 
2016-12-12 22:44:46 Valid Loss = 0.032401696542499 
2016-12-12 22:44:55 Test Error = 0.6355 
2016-12-12 22:44:55 Test Loss = 0.032448470581055 
2016-12-12 22:44:55 -------------------LR------------------- 
2016-12-12 22:44:55 0.00390625 
2016-12-12 22:44:55 Epoch 131 
2016-12-12 22:49:14 Training Error = 0.62955555555556 
2016-12-12 22:49:14 Training Loss = 0.033671152370877 
2016-12-12 22:49:18 Valid Error = 0.625525105021 
2016-12-12 22:49:18 Valid Loss = 0.032117862471525 
2016-12-12 22:49:26 Test Error = 0.628 
2016-12-12 22:49:26 Test Loss = 0.032231264892578 
2016-12-12 22:49:26 -------------------LR------------------- 
2016-12-12 22:49:26 0.00390625 
2016-12-12 22:49:26 Epoch 132 
2016-12-12 22:53:52 Training Error = 0.62791111111111 
2016-12-12 22:53:52 Training Loss = 0.033668155653212 
2016-12-12 22:53:56 Valid Error = 0.61972394478896 
2016-12-12 22:53:56 Valid Loss = 0.031881705787552 
2016-12-12 22:54:03 Test Error = 0.6239 
2016-12-12 22:54:03 Test Loss = 0.032032496948242 
2016-12-12 22:54:03 -------------------LR------------------- 
2016-12-12 22:54:03 0.00390625 
2016-12-12 22:54:03 Epoch 133 
2016-12-12 22:58:36 Training Error = 0.62653333333333 
2016-12-12 22:58:36 Training Loss = 0.03362215234375 
2016-12-12 22:58:40 Valid Error = 0.62692538507702 
2016-12-12 22:58:40 Valid Loss = 0.032059229211842 
2016-12-12 22:58:47 Test Error = 0.626 
2016-12-12 22:58:47 Test Loss = 0.032099623291016 
2016-12-12 22:58:47 -------------------LR------------------- 
2016-12-12 22:58:47 0.00390625 
2016-12-12 22:58:47 Epoch 134 
2016-12-12 23:03:07 Training Error = 0.62777777777778 
2016-12-12 23:03:07 Training Loss = 0.033616951822917 
2016-12-12 23:03:11 Valid Error = 0.61892378475695 
2016-12-12 23:03:11 Valid Loss = 0.031749189042636 
2016-12-12 23:03:20 Test Error = 0.6205 
2016-12-12 23:03:20 Test Loss = 0.03186157800293 
2016-12-12 23:03:20 -------------------LR------------------- 
2016-12-12 23:03:20 0.00390625 
2016-12-12 23:03:20 Epoch 135 
2016-12-12 23:07:46 Training Error = 0.62946666666667 
2016-12-12 23:07:46 Training Loss = 0.033619925672743 
2016-12-12 23:07:50 Valid Error = 0.62012402480496 
2016-12-12 23:07:50 Valid Loss = 0.032003223184651 
2016-12-12 23:07:59 Test Error = 0.6263 
2016-12-12 23:07:59 Test Loss = 0.0321441875 
2016-12-12 23:07:59 -------------------LR------------------- 
2016-12-12 23:07:59 0.00390625 
2016-12-12 23:07:59 Epoch 136 
2016-12-12 23:12:29 Training Error = 0.62968888888889 
2016-12-12 23:12:29 Training Loss = 0.033632204155816 
2016-12-12 23:12:33 Valid Error = 0.625325065013 
2016-12-12 23:12:33 Valid Loss = 0.032138643702444 
2016-12-12 23:12:41 Test Error = 0.627 
2016-12-12 23:12:41 Test Loss = 0.032219777587891 
2016-12-12 23:12:41 -------------------LR------------------- 
2016-12-12 23:12:41 0.00390625 
2016-12-12 23:12:41 Epoch 137 
2016-12-12 23:17:03 Training Error = 0.62704444444444 
2016-12-12 23:17:03 Training Loss = 0.033610334798177 
2016-12-12 23:17:07 Valid Error = 0.62692538507702 
2016-12-12 23:17:07 Valid Loss = 0.032345260900708 
2016-12-12 23:17:14 Test Error = 0.6313 
2016-12-12 23:17:14 Test Loss = 0.032385146484375 
2016-12-12 23:17:14 -------------------LR------------------- 
2016-12-12 23:17:14 0.00390625 
2016-12-12 23:17:14 Epoch 138 
2016-12-12 23:21:41 Training Error = 0.62975555555556 
2016-12-12 23:21:41 Training Loss = 0.033626245469835 
2016-12-12 23:21:45 Valid Error = 0.63932786557311 
2016-12-12 23:21:45 Valid Loss = 0.032264715850647 
2016-12-12 23:21:52 Test Error = 0.6352 
2016-12-12 23:21:52 Test Loss = 0.032283905639648 
2016-12-12 23:21:52 -------------------LR------------------- 
2016-12-12 23:21:52 0.00390625 
2016-12-12 23:21:52 Epoch 139 
2016-12-12 23:26:20 Training Error = 0.6266 
2016-12-12 23:26:20 Training Loss = 0.033587608940972 
2016-12-12 23:26:24 Valid Error = 0.62292458491698 
2016-12-12 23:26:24 Valid Loss = 0.031951918942377 
2016-12-12 23:26:32 Test Error = 0.6234 
2016-12-12 23:26:32 Test Loss = 0.032064672241211 
2016-12-12 23:26:32 -------------------LR------------------- 
2016-12-12 23:26:32 0.00390625 
2016-12-12 23:26:32 Epoch 140 
2016-12-12 23:30:51 Training Error = 0.62753333333333 
2016-12-12 23:30:51 Training Loss = 0.033627990424262 
2016-12-12 23:30:55 Valid Error = 0.61932386477295 
2016-12-12 23:30:55 Valid Loss = 0.032012251958996 
2016-12-12 23:31:04 Test Error = 0.6236 
2016-12-12 23:31:04 Test Loss = 0.032146187255859 
2016-12-12 23:31:04 -------------------LR------------------- 
2016-12-12 23:31:04 0.00390625 
2016-12-12 23:31:04 Epoch 141 
2016-12-12 23:35:30 Training Error = 0.62773333333333 
2016-12-12 23:35:30 Training Loss = 0.033564064398872 
2016-12-12 23:35:33 Valid Error = 0.62592518503701 
2016-12-12 23:35:33 Valid Loss = 0.032205487616835 
2016-12-12 23:35:41 Test Error = 0.6308 
2016-12-12 23:35:41 Test Loss = 0.032243891357422 
2016-12-12 23:35:41 -------------------LR------------------- 
2016-12-12 23:35:41 0.00390625 
2016-12-12 23:35:41 Epoch 142 
2016-12-12 23:40:07 Training Error = 0.62502222222222 
2016-12-12 23:40:07 Training Loss = 0.033572106689453 
2016-12-12 23:40:11 Valid Error = 0.63932786557311 
2016-12-12 23:40:11 Valid Loss = 0.032373466449501 
2016-12-12 23:40:18 Test Error = 0.6378 
2016-12-12 23:40:18 Test Loss = 0.032407823364258 
2016-12-12 23:40:18 -------------------LR------------------- 
2016-12-12 23:40:18 0.00390625 
2016-12-12 23:40:19 Epoch 143 
2016-12-12 23:44:35 Training Error = 0.62757777777778 
2016-12-12 23:44:35 Training Loss = 0.033576231608073 
2016-12-12 23:44:39 Valid Error = 0.62832566513303 
2016-12-12 23:44:39 Valid Loss = 0.032185024738442 
2016-12-12 23:44:46 Test Error = 0.6312 
2016-12-12 23:44:46 Test Loss = 0.032285219848633 
2016-12-12 23:44:46 -------------------LR------------------- 
2016-12-12 23:44:46 0.00390625 
2016-12-12 23:44:46 Epoch 144 
2016-12-12 23:49:16 Training Error = 0.62415555555556 
2016-12-12 23:49:16 Training Loss = 0.033556899142795 
2016-12-12 23:49:20 Valid Error = 0.62092418483697 
2016-12-12 23:49:20 Valid Loss = 0.031998514493342 
2016-12-12 23:49:28 Test Error = 0.6273 
2016-12-12 23:49:28 Test Loss = 0.03210813293457 
2016-12-12 23:49:28 -------------------LR------------------- 
2016-12-12 23:49:28 0.00390625 
2016-12-12 23:49:28 Epoch 145 
2016-12-12 23:54:01 Training Error = 0.62626666666667 
2016-12-12 23:54:01 Training Loss = 0.033565018853082 
2016-12-12 23:54:05 Valid Error = 0.6127225445089 
2016-12-12 23:54:05 Valid Loss = 0.031889857027042 
2016-12-12 23:54:14 Test Error = 0.6245 
2016-12-12 23:54:14 Test Loss = 0.032034910522461 
2016-12-12 23:54:14 -------------------LR------------------- 
2016-12-12 23:54:14 0.00390625 
2016-12-12 23:54:14 Epoch 146 
2016-12-12 23:58:35 Training Error = 0.62575555555556 
2016-12-12 23:58:35 Training Loss = 0.033558875406901 
2016-12-12 23:58:39 Valid Error = 0.61932386477295 
2016-12-12 23:58:39 Valid Loss = 0.0318920341518 
2016-12-12 23:58:47 Test Error = 0.6243 
2016-12-12 23:58:47 Test Loss = 0.032033599365234 
2016-12-12 23:58:47 -------------------LR------------------- 
2016-12-12 23:58:47 0.00390625 
2016-12-12 23:58:47 Epoch 147 
2016-12-13 00:03:23 Training Error = 0.62386666666667 
2016-12-13 00:03:23 Training Loss = 0.033547173502604 
2016-12-13 00:03:27 Valid Error = 0.61872374474895 
2016-12-13 00:03:27 Valid Loss = 0.031968347412599 
2016-12-13 00:03:35 Test Error = 0.6255 
2016-12-13 00:03:35 Test Loss = 0.032014881958008 
2016-12-13 00:03:35 -------------------LR------------------- 
2016-12-13 00:03:35 0.00390625 
2016-12-13 00:03:35 Epoch 148 
2016-12-13 00:07:45 Training Error = 0.62617777777778 
2016-12-13 00:07:45 Training Loss = 0.03356169647895 
2016-12-13 00:07:49 Valid Error = 0.63272654530906 
2016-12-13 00:07:49 Valid Loss = 0.032156109590764 
2016-12-13 00:07:57 Test Error = 0.6343 
2016-12-13 00:07:57 Test Loss = 0.032183290039062 
2016-12-13 00:07:57 -------------------LR------------------- 
2016-12-13 00:07:57 0.00390625 
2016-12-13 00:07:57 Epoch 149 
2016-12-13 00:12:22 Training Error = 0.62611111111111 
2016-12-13 00:12:22 Training Loss = 0.033549617323134 
2016-12-13 00:12:26 Valid Error = 0.61372274454891 
2016-12-13 00:12:26 Valid Loss = 0.031798797831992 
2016-12-13 00:12:34 Test Error = 0.6212 
2016-12-13 00:12:34 Test Loss = 0.031927317260742 
2016-12-13 00:12:34 -------------------LR------------------- 
2016-12-13 00:12:34 0.00390625 
2016-12-13 00:12:34 Epoch 150 
2016-12-13 00:17:06 Training Error = 0.62348888888889 
2016-12-13 00:17:06 Training Loss = 0.033497597520616 
2016-12-13 00:17:10 Valid Error = 0.62872574514903 
2016-12-13 00:17:10 Valid Loss = 0.032194322174133 
2016-12-13 00:17:19 Test Error = 0.629 
2016-12-13 00:17:19 Test Loss = 0.032272379638672 
2016-12-13 00:17:19 -------------------LR------------------- 
2016-12-13 00:17:19 0.001953125 
2016-12-13 00:17:19 Epoch 151 
2016-12-13 00:21:36 Training Error = 0.61777777777778 
2016-12-13 00:21:36 Training Loss = 0.033380312228733 
2016-12-13 00:21:40 Valid Error = 0.62312462492498 
2016-12-13 00:21:40 Valid Loss = 0.03186428458773 
2016-12-13 00:21:48 Test Error = 0.6233 
2016-12-13 00:21:48 Test Loss = 0.031886140991211 
2016-12-13 00:21:48 -------------------LR------------------- 
2016-12-13 00:21:48 0.001953125 
2016-12-13 00:21:48 Epoch 152 
2016-12-13 00:26:08 Training Error = 0.61773333333333 
2016-12-13 00:26:08 Training Loss = 0.033369598524306 
2016-12-13 00:26:12 Valid Error = 0.61812362472494 
2016-12-13 00:26:12 Valid Loss = 0.03199692285303 
2016-12-13 00:26:20 Test Error = 0.6212 
2016-12-13 00:26:20 Test Loss = 0.031976535766602 
2016-12-13 00:26:20 -------------------LR------------------- 
2016-12-13 00:26:20 0.001953125 
2016-12-13 00:26:20 Epoch 153 
2016-12-13 00:30:49 Training Error = 0.61793333333333 
2016-12-13 00:30:49 Training Loss = 0.033406326090495 
2016-12-13 00:30:53 Valid Error = 0.61852370474095 
2016-12-13 00:30:53 Valid Loss = 0.031843487050762 
2016-12-13 00:31:01 Test Error = 0.622 
2016-12-13 00:31:01 Test Loss = 0.031920874633789 
2016-12-13 00:31:01 -------------------LR------------------- 
2016-12-13 00:31:01 0.001953125 
2016-12-13 00:31:01 Epoch 154 
2016-12-13 00:35:24 Training Error = 0.61664444444444 
2016-12-13 00:35:24 Training Loss = 0.033356115668403 
2016-12-13 00:35:28 Valid Error = 0.6119223844769 
2016-12-13 00:35:28 Valid Loss = 0.031592398896426 
2016-12-13 00:35:37 Test Error = 0.6156 
2016-12-13 00:35:37 Test Loss = 0.031741682495117 
2016-12-13 00:35:37 -------------------LR------------------- 
2016-12-13 00:35:37 0.001953125 
2016-12-13 00:35:37 Epoch 155 
2016-12-13 00:40:04 Training Error = 0.61662222222222 
2016-12-13 00:40:04 Training Loss = 0.033356938395182 
2016-12-13 00:40:08 Valid Error = 0.62072414482897 
2016-12-13 00:40:08 Valid Loss = 0.031752593935919 
2016-12-13 00:40:16 Test Error = 0.62 
2016-12-13 00:40:16 Test Loss = 0.031805446899414 
2016-12-13 00:40:16 -------------------LR------------------- 
2016-12-13 00:40:16 0.001953125 
2016-12-13 00:40:17 Epoch 156 
2016-12-13 00:44:45 Training Error = 0.61708888888889 
2016-12-13 00:44:45 Training Loss = 0.033396062065972 
2016-12-13 00:44:49 Valid Error = 0.61032206441288 
2016-12-13 00:44:49 Valid Loss = 0.031570027717055 
2016-12-13 00:44:56 Test Error = 0.6119 
2016-12-13 00:44:56 Test Loss = 0.031593997314453 
2016-12-13 00:44:56 -------------------LR------------------- 
2016-12-13 00:44:56 0.001953125 
2016-12-13 00:44:56 Epoch 157 
2016-12-13 00:49:20 Training Error = 0.6188 
2016-12-13 00:49:20 Training Loss = 0.033425842176649 
2016-12-13 00:49:24 Valid Error = 0.62712542508502 
2016-12-13 00:49:24 Valid Loss = 0.032039409672861 
2016-12-13 00:49:32 Test Error = 0.6234 
2016-12-13 00:49:32 Test Loss = 0.032125424682617 
2016-12-13 00:49:32 -------------------LR------------------- 
2016-12-13 00:49:32 0.001953125 
2016-12-13 00:49:32 Epoch 158 
2016-12-13 00:53:57 Training Error = 0.61757777777778 
2016-12-13 00:53:57 Training Loss = 0.033385583306207 
2016-12-13 00:54:01 Valid Error = 0.62412482496499 
2016-12-13 00:54:01 Valid Loss = 0.031946618993358 
2016-12-13 00:54:09 Test Error = 0.6242 
2016-12-13 00:54:09 Test Loss = 0.031956462524414 
2016-12-13 00:54:09 -------------------LR------------------- 
2016-12-13 00:54:09 0.001953125 
2016-12-13 00:54:09 Epoch 159 
2016-12-13 00:58:33 Training Error = 0.61802222222222 
2016-12-13 00:58:33 Training Loss = 0.033352367513021 
2016-12-13 00:58:37 Valid Error = 0.61812362472494 
2016-12-13 00:58:37 Valid Loss = 0.031781773902786 
2016-12-13 00:58:45 Test Error = 0.6179 
2016-12-13 00:58:45 Test Loss = 0.031825310302734 
2016-12-13 00:58:45 -------------------LR------------------- 
2016-12-13 00:58:45 0.001953125 
2016-12-13 00:58:45 Epoch 160 
2016-12-13 01:02:58 Training Error = 0.61631111111111 
2016-12-13 01:02:58 Training Loss = 0.033361666314019 
2016-12-13 01:03:02 Valid Error = 0.61392278455691 
2016-12-13 01:03:02 Valid Loss = 0.031777376988352 
2016-12-13 01:03:10 Test Error = 0.6145 
2016-12-13 01:03:10 Test Loss = 0.031827186279297 
2016-12-13 01:03:10 -------------------LR------------------- 
2016-12-13 01:03:10 0.001953125 
2016-12-13 01:03:10 Epoch 161 
2016-12-13 01:07:41 Training Error = 0.61864444444444 
2016-12-13 01:07:41 Training Loss = 0.033388158772786 
2016-12-13 01:07:45 Valid Error = 0.62232446489298 
2016-12-13 01:07:45 Valid Loss = 0.031869619594169 
2016-12-13 01:07:53 Test Error = 0.6188 
2016-12-13 01:07:53 Test Loss = 0.031944627929687 
2016-12-13 01:07:53 -------------------LR------------------- 
2016-12-13 01:07:53 0.001953125 
2016-12-13 01:07:53 Epoch 162 
2016-12-13 01:12:20 Training Error = 0.61844444444444 
2016-12-13 01:12:20 Training Loss = 0.033369949164497 
2016-12-13 01:12:24 Valid Error = 0.60852170434087 
2016-12-13 01:12:24 Valid Loss = 0.031735538404446 
2016-12-13 01:12:31 Test Error = 0.617 
2016-12-13 01:12:31 Test Loss = 0.03184224987793 
2016-12-13 01:12:31 -------------------LR------------------- 
2016-12-13 01:12:31 0.001953125 
2016-12-13 01:12:32 Epoch 163 
