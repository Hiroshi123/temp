2016-12-09 23:37:16 [program started on Fri Dec  9 23:37:16 2016] 
2016-12-09 23:37:16 [command line arguments] 
2016-12-09 23:37:16 stcWeights false 
2016-12-09 23:37:16 LR 0.015625 
2016-12-09 23:37:16 batchSize 300 
2016-12-09 23:37:16 network ./Models/Cifar10_Custom 
2016-12-09 23:37:16 stcNeurons true 
2016-12-09 23:37:16 constBatchSize false 
2016-12-09 23:37:16 chartFileName chart1 
2016-12-09 23:37:16 dp_prepro false 
2016-12-09 23:37:16 nGPU 1 
2016-12-09 23:37:16 dataset Cifar100 
2016-12-09 23:37:16 type cuda 
2016-12-09 23:37:16 momentum 0 
2016-12-09 23:37:16 threads 8 
2016-12-09 23:37:16 weightDecay 0 
2016-12-09 23:37:16 runningVal false 
2016-12-09 23:37:16 convLayerN 6 
2016-12-09 23:37:16 LRDecay 0 
2016-12-09 23:37:16 numHid 216 
2016-12-09 23:37:16 save /dev/shm/temp/th/Results/Cifar100/model6-10-216 
2016-12-09 23:37:16 augment false 
2016-12-09 23:37:16 epoch -1 
2016-12-09 23:37:16 modelsFolder ./Models/ 
2016-12-09 23:37:16 format rgb 
2016-12-09 23:37:16 preProcDir /dev/shm/temp/th/PreProcData/Cifar100 
2016-12-09 23:37:16 imageFileExtension svg 
2016-12-09 23:37:16 channel 1 
2016-12-09 23:37:16 devid 8 
2016-12-09 23:37:16 visualize 1 
2016-12-09 23:37:16 LRDecayPerEpoch 0.0001 
2016-12-09 23:37:16 optimization adam 
2016-12-09 23:37:16 SBN true 
2016-12-09 23:37:16 normalization simple 
2016-12-09 23:37:16 title model1 
2016-12-09 23:37:16 load  
2016-12-09 23:37:16 whiten true 
2016-12-09 23:37:16 [----------------------] 
2016-12-09 23:37:17 ==> Network 
2016-12-09 23:37:17 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 216)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(216 -> 216)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(216 -> 100)
  (38): nn.BatchNormalization
} 
2016-12-09 23:37:17 ==>6419292 Parameters 
2016-12-09 23:37:17 ==> Loss 
2016-12-09 23:37:17 SqrtHingeEmbeddingCriterion 
2016-12-09 23:37:17 
==> Starting Training
 
2016-12-09 23:37:17 Epoch 1 
2016-12-09 23:46:36 Training Error = 0.93708888888889 
2016-12-09 23:46:36 Training Loss = 0.23043812955729 
2016-12-09 23:46:47 Valid Error = 0.91558311662332 
2016-12-09 23:46:47 Valid Loss = 0.039897409898662 
2016-12-09 23:47:10 Test Error = 0.9192 
2016-12-09 23:47:10 Test Loss = 0.039937104019464 
2016-12-09 23:47:10 -------------------LR------------------- 
2016-12-09 23:47:10 0.015625 
2016-12-09 23:47:10 Epoch 2 
2016-12-09 23:56:47 Training Error = 0.90468888888889 
2016-12-09 23:56:47 Training Loss = 0.038832261094835 
2016-12-09 23:56:58 Valid Error = 0.88997799559912 
2016-12-09 23:56:58 Valid Loss = 0.038544488636648 
2016-12-09 23:57:20 Test Error = 0.8887 
2016-12-09 23:57:20 Test Loss = 0.038623264866249 
2016-12-09 23:57:20 -------------------LR------------------- 
2016-12-09 23:57:20 0.015625 
2016-12-09 23:57:20 Epoch 3 
2016-12-10 00:06:57 Training Error = 0.88088888888889 
2016-12-10 00:06:57 Training Loss = 0.038451571343316 
2016-12-10 00:07:08 Valid Error = 0.86557311462292 
2016-12-10 00:07:08 Valid Loss = 0.038237422455462 
2016-12-10 00:07:31 Test Error = 0.8636 
2016-12-10 00:07:31 Test Loss = 0.038300243063534 
2016-12-10 00:07:31 -------------------LR------------------- 
2016-12-10 00:07:31 0.015625 
2016-12-10 00:07:31 Epoch 4 
2016-12-10 00:17:05 Training Error = 0.86622222222222 
2016-12-10 00:17:05 Training Loss = 0.038242233588325 
2016-12-10 00:17:16 Valid Error = 0.8495699139828 
2016-12-10 00:17:16 Valid Loss = 0.037974293376589 
2016-12-10 00:17:39 Test Error = 0.8505 
2016-12-10 00:17:39 Test Loss = 0.038106945591347 
2016-12-10 00:17:39 -------------------LR------------------- 
2016-12-10 00:17:39 0.015625 
2016-12-10 00:17:39 Epoch 5 
2016-12-10 00:27:13 Training Error = 0.85246666666667 
2016-12-10 00:27:13 Training Loss = 0.03806912641059 
2016-12-10 00:27:24 Valid Error = 0.84216843368674 
2016-12-10 00:27:24 Valid Loss = 0.037862900125772 
2016-12-10 00:27:47 Test Error = 0.8398 
2016-12-10 00:27:47 Test Loss = 0.037980571283079 
2016-12-10 00:27:47 -------------------LR------------------- 
2016-12-10 00:27:47 0.015625 
2016-12-10 00:27:47 Epoch 6 
2016-12-10 00:37:29 Training Error = 0.84195555555556 
2016-12-10 00:37:29 Training Loss = 0.037927162082248 
2016-12-10 00:37:40 Valid Error = 0.83376675335067 
2016-12-10 00:37:40 Valid Loss = 0.037755633502223 
2016-12-10 00:38:03 Test Error = 0.83 
2016-12-10 00:38:03 Test Loss = 0.037864564723595 
2016-12-10 00:38:03 -------------------LR------------------- 
2016-12-10 00:38:03 0.015625 
2016-12-10 00:38:03 Epoch 7 
2016-12-10 00:47:38 Training Error = 0.82993333333333 
2016-12-10 00:47:38 Training Loss = 0.03778155211046 
2016-12-10 00:47:50 Valid Error = 0.82876575315063 
2016-12-10 00:47:50 Valid Loss = 0.03763769836516 
2016-12-10 00:48:12 Test Error = 0.8298 
2016-12-10 00:48:12 Test Loss = 0.037763506870644 
2016-12-10 00:48:12 -------------------LR------------------- 
2016-12-10 00:48:12 0.015625 
2016-12-10 00:48:12 Epoch 8 
2016-12-10 00:57:51 Training Error = 0.82768888888889 
2016-12-10 00:57:51 Training Loss = 0.037649289442274 
2016-12-10 00:58:02 Valid Error = 0.81956391278256 
2016-12-10 00:58:02 Valid Loss = 0.037419847592406 
2016-12-10 00:58:25 Test Error = 0.8139 
2016-12-10 00:58:25 Test Loss = 0.037524643303366 
2016-12-10 00:58:25 -------------------LR------------------- 
2016-12-10 00:58:25 0.015625 
2016-12-10 00:58:25 Epoch 9 
2016-12-10 01:07:59 Training Error = 0.81791111111111 
2016-12-10 01:07:59 Training Loss = 0.037503946940104 
2016-12-10 01:08:10 Valid Error = 0.79655931186237 
2016-12-10 01:08:10 Valid Loss = 0.037150577524042 
2016-12-10 01:08:33 Test Error = 0.8009 
2016-12-10 01:08:33 Test Loss = 0.037271435427198 
2016-12-10 01:08:33 -------------------LR------------------- 
2016-12-10 01:08:33 0.015625 
2016-12-10 01:08:33 Epoch 10 
2016-12-10 01:18:20 Training Error = 0.80782222222222 
2016-12-10 01:18:20 Training Loss = 0.03736091023763 
2016-12-10 01:18:31 Valid Error = 0.80796159231846 
2016-12-10 01:18:31 Valid Loss = 0.037240462388728 
2016-12-10 01:18:53 Test Error = 0.8085 
2016-12-10 01:18:53 Test Loss = 0.037345499943752 
2016-12-10 01:18:53 -------------------LR------------------- 
2016-12-10 01:18:53 0.015625 
2016-12-10 01:18:54 Epoch 11 
2016-12-10 01:28:27 Training Error = 0.80302222222222 
2016-12-10 01:28:27 Training Loss = 0.037242754150391 
2016-12-10 01:28:38 Valid Error = 0.78395679135827 
2016-12-10 01:28:38 Valid Loss = 0.036907717633001 
2016-12-10 01:29:01 Test Error = 0.7811 
2016-12-10 01:29:01 Test Loss = 0.036970304810767 
2016-12-10 01:29:01 -------------------LR------------------- 
2016-12-10 01:29:01 0.015625 
2016-12-10 01:29:01 Epoch 12 
2016-12-10 01:38:39 Training Error = 0.7954 
2016-12-10 01:38:39 Training Loss = 0.037104141330295 
2016-12-10 01:38:50 Valid Error = 0.78295659131826 
2016-12-10 01:38:50 Valid Loss = 0.036790750557177 
2016-12-10 01:39:12 Test Error = 0.7819 
2016-12-10 01:39:12 Test Loss = 0.036845662195542 
2016-12-10 01:39:12 -------------------LR------------------- 
2016-12-10 01:39:12 0.015625 
2016-12-10 01:39:12 Epoch 13 
2016-12-10 01:48:47 Training Error = 0.78826666666667 
2016-12-10 01:48:47 Training Loss = 0.036986458577474 
2016-12-10 01:48:58 Valid Error = 0.76395279055811 
2016-12-10 01:48:58 Valid Loss = 0.036509259803585 
2016-12-10 01:49:21 Test Error = 0.7716 
2016-12-10 01:49:21 Test Loss = 0.036600285189759 
2016-12-10 01:49:21 -------------------LR------------------- 
2016-12-10 01:49:21 0.015625 
2016-12-10 01:49:21 Epoch 14 
2016-12-10 01:58:55 Training Error = 0.78242222222222 
2016-12-10 01:58:55 Training Loss = 0.036874687717014 
2016-12-10 01:59:06 Valid Error = 0.76835367073415 
2016-12-10 01:59:06 Valid Loss = 0.036568558152714 
2016-12-10 01:59:29 Test Error = 0.7721 
2016-12-10 01:59:29 Test Loss = 0.036668678852156 
2016-12-10 01:59:29 -------------------LR------------------- 
2016-12-10 01:59:29 0.015625 
2016-12-10 01:59:29 Epoch 15 
2016-12-10 02:09:04 Training Error = 0.77448888888889 
2016-12-10 02:09:04 Training Loss = 0.036740946777344 
2016-12-10 02:09:15 Valid Error = 0.76495299059812 
2016-12-10 02:09:15 Valid Loss = 0.036391089917216 
2016-12-10 02:09:37 Test Error = 0.764 
2016-12-10 02:09:37 Test Loss = 0.036519225954542 
2016-12-10 02:09:37 -------------------LR------------------- 
2016-12-10 02:09:37 0.015625 
2016-12-10 02:09:37 Epoch 16 
2016-12-10 02:19:15 Training Error = 0.77062222222222 
2016-12-10 02:19:15 Training Loss = 0.03664274102105 
2016-12-10 02:19:26 Valid Error = 0.74934986997399 
2016-12-10 02:19:26 Valid Loss = 0.036071873670926 
2016-12-10 02:19:49 Test Error = 0.7555 
2016-12-10 02:19:49 Test Loss = 0.03620374917423 
2016-12-10 02:19:49 -------------------LR------------------- 
2016-12-10 02:19:49 0.015625 
2016-12-10 02:19:49 Epoch 17 
2016-12-10 02:29:36 Training Error = 0.76573333333333 
2016-12-10 02:29:36 Training Loss = 0.036543139838325 
2016-12-10 02:29:47 Valid Error = 0.75135027005401 
2016-12-10 02:29:47 Valid Loss = 0.036107493427279 
2016-12-10 02:30:09 Test Error = 0.7504 
2016-12-10 02:30:09 Test Loss = 0.036185844630821 
2016-12-10 02:30:09 -------------------LR------------------- 
2016-12-10 02:30:09 0.015625 
2016-12-10 02:30:10 Epoch 18 
2016-12-10 02:39:39 Training Error = 0.76353333333333 
2016-12-10 02:39:39 Training Loss = 0.036445256510417 
2016-12-10 02:39:50 Valid Error = 0.73034606921384 
2016-12-10 02:39:50 Valid Loss = 0.035728392242453 
2016-12-10 02:40:13 Test Error = 0.7373 
2016-12-10 02:40:13 Test Loss = 0.035860042407466 
2016-12-10 02:40:13 -------------------LR------------------- 
2016-12-10 02:40:13 0.015625 
2016-12-10 02:40:13 Epoch 19 
2016-12-10 02:49:54 Training Error = 0.75577777777778 
2016-12-10 02:49:54 Training Loss = 0.036333587320964 
2016-12-10 02:50:05 Valid Error = 0.74574914982997 
2016-12-10 02:50:05 Valid Loss = 0.035822656335398 
2016-12-10 02:50:27 Test Error = 0.7442 
2016-12-10 02:50:27 Test Loss = 0.035919771022423 
2016-12-10 02:50:27 -------------------LR------------------- 
2016-12-10 02:50:27 0.015625 
2016-12-10 02:50:28 Epoch 20 
2016-12-10 03:00:03 Training Error = 0.75571111111111 
2016-12-10 03:00:03 Training Loss = 0.036261030897352 
2016-12-10 03:00:14 Valid Error = 0.73514702940588 
2016-12-10 03:00:14 Valid Loss = 0.035745280289507 
2016-12-10 03:00:37 Test Error = 0.7365 
2016-12-10 03:00:37 Test Loss = 0.035826216215246 
2016-12-10 03:00:37 -------------------LR------------------- 
2016-12-10 03:00:37 0.015625 
2016-12-10 03:00:37 Epoch 21 
2016-12-10 03:10:16 Training Error = 0.74971111111111 
2016-12-10 03:10:16 Training Loss = 0.036183650037977 
2016-12-10 03:10:27 Valid Error = 0.72374474894979 
2016-12-10 03:10:27 Valid Loss = 0.035446526311186 
2016-12-10 03:10:50 Test Error = 0.7218 
2016-12-10 03:10:50 Test Loss = 0.035507998567469 
2016-12-10 03:10:50 -------------------LR------------------- 
2016-12-10 03:10:50 0.015625 
2016-12-10 03:10:50 Epoch 22 
2016-12-10 03:20:26 Training Error = 0.74766666666667 
2016-12-10 03:20:26 Training Loss = 0.036094927463108 
2016-12-10 03:20:38 Valid Error = 0.72614522904581 
2016-12-10 03:20:38 Valid Loss = 0.035280992783935 
2016-12-10 03:21:00 Test Error = 0.7251 
2016-12-10 03:21:00 Test Loss = 0.035331630691828 
2016-12-10 03:21:00 -------------------LR------------------- 
2016-12-10 03:21:00 0.015625 
2016-12-10 03:21:00 Epoch 23 
2016-12-10 03:30:35 Training Error = 0.74237777777778 
2016-12-10 03:30:35 Training Loss = 0.03600537483724 
2016-12-10 03:30:46 Valid Error = 0.71994398879776 
2016-12-10 03:30:46 Valid Loss = 0.035281554433665 
2016-12-10 03:31:09 Test Error = 0.7206 
2016-12-10 03:31:09 Test Loss = 0.035355802259258 
2016-12-10 03:31:09 -------------------LR------------------- 
2016-12-10 03:31:09 0.015625 
2016-12-10 03:31:09 Epoch 24 
2016-12-10 03:40:41 Training Error = 0.7384 
2016-12-10 03:40:41 Training Loss = 0.035950733642578 
2016-12-10 03:40:52 Valid Error = 0.71534306861372 
2016-12-10 03:40:52 Valid Loss = 0.035072708935446 
2016-12-10 03:41:15 Test Error = 0.7154 
2016-12-10 03:41:15 Test Loss = 0.035147341559915 
2016-12-10 03:41:15 -------------------LR------------------- 
2016-12-10 03:41:15 0.015625 
2016-12-10 03:41:15 Epoch 25 
2016-12-10 03:50:55 Training Error = 0.73584444444444 
2016-12-10 03:50:55 Training Loss = 0.035878311848958 
2016-12-10 03:51:06 Valid Error = 0.71174234846969 
2016-12-10 03:51:06 Valid Loss = 0.035015469700438 
2016-12-10 03:51:28 Test Error = 0.7123 
2016-12-10 03:51:28 Test Loss = 0.035047096731149 
2016-12-10 03:51:28 -------------------LR------------------- 
2016-12-10 03:51:28 0.015625 
2016-12-10 03:51:28 Epoch 26 
2016-12-10 04:01:08 Training Error = 0.73108888888889 
2016-12-10 04:01:08 Training Loss = 0.035790215223524 
2016-12-10 04:01:20 Valid Error = 0.70774154830966 
2016-12-10 04:01:20 Valid Loss = 0.034924157977652 
2016-12-10 04:01:42 Test Error = 0.7128 
2016-12-10 04:01:42 Test Loss = 0.034992870076497 
2016-12-10 04:01:42 -------------------LR------------------- 
2016-12-10 04:01:42 0.015625 
2016-12-10 04:01:42 Epoch 27 
2016-12-10 04:11:28 Training Error = 0.73073333333333 
2016-12-10 04:11:28 Training Loss = 0.035745687608507 
2016-12-10 04:11:39 Valid Error = 0.71134226845369 
2016-12-10 04:11:39 Valid Loss = 0.034800333578268 
2016-12-10 04:12:02 Test Error = 0.7101 
2016-12-10 04:12:02 Test Loss = 0.034824247921214 
2016-12-10 04:12:02 -------------------LR------------------- 
2016-12-10 04:12:02 0.015625 
2016-12-10 04:12:02 Epoch 28 
2016-12-10 04:21:28 Training Error = 0.7268 
2016-12-10 04:21:28 Training Loss = 0.035659524522569 
2016-12-10 04:21:39 Valid Error = 0.70594118823765 
2016-12-10 04:21:39 Valid Loss = 0.034758605828935 
2016-12-10 04:22:02 Test Error = 0.7036 
2016-12-10 04:22:02 Test Loss = 0.034758733801748 
2016-12-10 04:22:02 -------------------LR------------------- 
2016-12-10 04:22:02 0.015625 
2016-12-10 04:22:02 Epoch 29 
2016-12-10 04:31:38 Training Error = 0.72268888888889 
2016-12-10 04:31:38 Training Loss = 0.035608807725694 
2016-12-10 04:31:50 Valid Error = 0.70394078815763 
2016-12-10 04:31:50 Valid Loss = 0.034813986958695 
2016-12-10 04:32:12 Test Error = 0.7108 
2016-12-10 04:32:12 Test Loss = 0.03484944894828 
2016-12-10 04:32:12 -------------------LR------------------- 
2016-12-10 04:32:12 0.015625 
2016-12-10 04:32:12 Epoch 30 
2016-12-10 04:41:52 Training Error = 0.72213333333333 
2016-12-10 04:41:52 Training Loss = 0.035557607801649 
2016-12-10 04:42:04 Valid Error = 0.69673934786957 
2016-12-10 04:42:04 Valid Loss = 0.034612430861102 
2016-12-10 04:42:26 Test Error = 0.703 
2016-12-10 04:42:26 Test Loss = 0.034658718004414 
2016-12-10 04:42:26 -------------------LR------------------- 
2016-12-10 04:42:26 0.015625 
2016-12-10 04:42:26 Epoch 31 
2016-12-10 04:52:02 Training Error = 0.71906666666667 
2016-12-10 04:52:02 Training Loss = 0.035494640516493 
2016-12-10 04:52:13 Valid Error = 0.69513902780556 
2016-12-10 04:52:13 Valid Loss = 0.034563383342109 
2016-12-10 04:52:36 Test Error = 0.6927 
2016-12-10 04:52:36 Test Loss = 0.034605802468693 
2016-12-10 04:52:36 -------------------LR------------------- 
2016-12-10 04:52:36 0.015625 
2016-12-10 04:52:36 Epoch 32 
2016-12-10 05:02:13 Training Error = 0.71808888888889 
2016-12-10 05:02:13 Training Loss = 0.035460941731771 
2016-12-10 05:02:24 Valid Error = 0.69613922784557 
2016-12-10 05:02:24 Valid Loss = 0.034474334170133 
2016-12-10 05:02:47 Test Error = 0.6978 
2016-12-10 05:02:47 Test Loss = 0.034509621474322 
2016-12-10 05:02:47 -------------------LR------------------- 
2016-12-10 05:02:47 0.015625 
2016-12-10 05:02:47 Epoch 33 
2016-12-10 05:12:23 Training Error = 0.71353333333333 
2016-12-10 05:12:23 Training Loss = 0.03540070686849 
2016-12-10 05:12:34 Valid Error = 0.69233846769354 
2016-12-10 05:12:34 Valid Loss = 0.034387595467187 
2016-12-10 05:12:57 Test Error = 0.6905 
2016-12-10 05:12:57 Test Loss = 0.034386938715916 
2016-12-10 05:12:57 -------------------LR------------------- 
2016-12-10 05:12:57 0.015625 
2016-12-10 05:12:57 Epoch 34 
2016-12-10 05:22:36 Training Error = 0.7126 
2016-12-10 05:22:36 Training Loss = 0.035351504584418 
2016-12-10 05:22:47 Valid Error = 0.69013802760552 
2016-12-10 05:22:47 Valid Loss = 0.034238846636772 
2016-12-10 05:23:10 Test Error = 0.6861 
2016-12-10 05:23:10 Test Loss = 0.034264469580557 
2016-12-10 05:23:10 -------------------LR------------------- 
2016-12-10 05:23:10 0.015625 
2016-12-10 05:23:10 Epoch 35 
2016-12-10 05:32:46 Training Error = 0.71104444444444 
2016-12-10 05:32:46 Training Loss = 0.035313370388455 
2016-12-10 05:32:57 Valid Error = 0.67673534706941 
2016-12-10 05:32:57 Valid Loss = 0.033939151146212 
2016-12-10 05:33:20 Test Error = 0.6741 
2016-12-10 05:33:20 Test Loss = 0.033916635431028 
2016-12-10 05:33:20 -------------------LR------------------- 
2016-12-10 05:33:20 0.015625 
2016-12-10 05:33:20 Epoch 36 
2016-12-10 05:42:58 Training Error = 0.70668888888889 
2016-12-10 05:42:58 Training Loss = 0.035233306396484 
2016-12-10 05:43:09 Valid Error = 0.67393478695739 
2016-12-10 05:43:09 Valid Loss = 0.033954125541757 
2016-12-10 05:43:32 Test Error = 0.6748 
2016-12-10 05:43:32 Test Loss = 0.033984377812404 
2016-12-10 05:43:32 -------------------LR------------------- 
2016-12-10 05:43:32 0.015625 
2016-12-10 05:43:32 Epoch 37 
2016-12-10 05:53:13 Training Error = 0.70093333333333 
2016-12-10 05:53:13 Training Loss = 0.035161517985026 
2016-12-10 05:53:24 Valid Error = 0.68273654730946 
2016-12-10 05:53:24 Valid Loss = 0.034195635353665 
2016-12-10 05:53:47 Test Error = 0.6819 
2016-12-10 05:53:47 Test Loss = 0.034256061658672 
2016-12-10 05:53:47 -------------------LR------------------- 
2016-12-10 05:53:47 0.015625 
2016-12-10 05:53:47 Epoch 38 
2016-12-10 06:03:25 Training Error = 0.70024444444444 
2016-12-10 06:03:25 Training Loss = 0.035146615152995 
2016-12-10 06:03:36 Valid Error = 0.67013402680536 
2016-12-10 06:03:36 Valid Loss = 0.033760180294207 
2016-12-10 06:03:58 Test Error = 0.664 
2016-12-10 06:03:58 Test Loss = 0.033723750125661 
2016-12-10 06:03:58 -------------------LR------------------- 
2016-12-10 06:03:58 0.015625 
2016-12-10 06:03:58 Epoch 39 
2016-12-10 06:13:33 Training Error = 0.70028888888889 
2016-12-10 06:13:33 Training Loss = 0.035090665703668 
2016-12-10 06:13:44 Valid Error = 0.6749349869974 
2016-12-10 06:13:44 Valid Loss = 0.033749298020529 
2016-12-10 06:14:06 Test Error = 0.6649 
2016-12-10 06:14:06 Test Loss = 0.033729039091222 
2016-12-10 06:14:06 -------------------LR------------------- 
2016-12-10 06:14:06 0.015625 
2016-12-10 06:14:06 Epoch 40 
2016-12-10 06:23:55 Training Error = 0.69911111111111 
2016-12-10 06:23:55 Training Loss = 0.03504891788737 
2016-12-10 06:24:06 Valid Error = 0.66373274654931 
2016-12-10 06:24:06 Valid Loss = 0.033602254350245 
2016-12-10 06:24:28 Test Error = 0.6697 
2016-12-10 06:24:28 Test Loss = 0.033693715293735 
2016-12-10 06:24:28 -------------------LR------------------- 
2016-12-10 06:24:28 0.015625 
2016-12-10 06:24:28 Epoch 41 
2016-12-10 06:34:00 Training Error = 0.69826666666667 
2016-12-10 06:34:00 Training Loss = 0.034988617621528 
2016-12-10 06:34:11 Valid Error = 0.66433286657331 
2016-12-10 06:34:11 Valid Loss = 0.033637438854188 
2016-12-10 06:34:34 Test Error = 0.664 
2016-12-10 06:34:34 Test Loss = 0.033683896502327 
2016-12-10 06:34:34 -------------------LR------------------- 
2016-12-10 06:34:34 0.015625 
2016-12-10 06:34:34 Epoch 42 
2016-12-10 06:44:15 Training Error = 0.69193333333333 
2016-12-10 06:44:15 Training Loss = 0.034962897447374 
2016-12-10 06:44:27 Valid Error = 0.67133426685337 
2016-12-10 06:44:27 Valid Loss = 0.033650104850689 
2016-12-10 06:44:49 Test Error = 0.6667 
2016-12-10 06:44:49 Test Loss = 0.033650938595043 
2016-12-10 06:44:49 -------------------LR------------------- 
2016-12-10 06:44:49 0.015625 
2016-12-10 06:44:49 Epoch 43 
2016-12-10 06:54:32 Training Error = 0.69088888888889 
2016-12-10 06:54:32 Training Loss = 0.034913138617622 
2016-12-10 06:54:43 Valid Error = 0.67713542708542 
2016-12-10 06:54:43 Valid Loss = 0.03360981817814 
2016-12-10 06:55:06 Test Error = 0.6718 
2016-12-10 06:55:06 Test Loss = 0.033582867970186 
2016-12-10 06:55:06 -------------------LR------------------- 
2016-12-10 06:55:06 0.015625 
2016-12-10 06:55:06 Epoch 44 
