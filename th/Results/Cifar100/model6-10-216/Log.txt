2016-12-09 23:37:16 [program started on Fri Dec  9 23:37:16 2016] 
2016-12-09 23:37:16 [command line arguments] 
2016-12-09 23:37:16 stcWeights false 
2016-12-09 23:37:16 LR 0.015625 
2016-12-09 23:37:16 batchSize 300 
2016-12-09 23:37:16 network ./Models/Cifar10_Custom 
2016-12-09 23:37:16 stcNeurons true 
2016-12-09 23:37:16 constBatchSize false 
2016-12-09 23:37:16 chartFileName chart1 
2016-12-09 23:37:16 dp_prepro false 
2016-12-09 23:37:16 nGPU 1 
2016-12-09 23:37:16 dataset Cifar100 
2016-12-09 23:37:16 type cuda 
2016-12-09 23:37:16 momentum 0 
2016-12-09 23:37:16 threads 8 
2016-12-09 23:37:16 weightDecay 0 
2016-12-09 23:37:16 runningVal false 
2016-12-09 23:37:16 convLayerN 6 
2016-12-09 23:37:16 LRDecay 0 
2016-12-09 23:37:16 numHid 216 
2016-12-09 23:37:16 save /dev/shm/temp/th/Results/Cifar100/model6-10-216 
2016-12-09 23:37:16 augment false 
2016-12-09 23:37:16 epoch -1 
2016-12-09 23:37:16 modelsFolder ./Models/ 
2016-12-09 23:37:16 format rgb 
2016-12-09 23:37:16 preProcDir /dev/shm/temp/th/PreProcData/Cifar100 
2016-12-09 23:37:16 imageFileExtension svg 
2016-12-09 23:37:16 channel 1 
2016-12-09 23:37:16 devid 8 
2016-12-09 23:37:16 visualize 1 
2016-12-09 23:37:16 LRDecayPerEpoch 0.0001 
2016-12-09 23:37:16 optimization adam 
2016-12-09 23:37:16 SBN true 
2016-12-09 23:37:16 normalization simple 
2016-12-09 23:37:16 title model1 
2016-12-09 23:37:16 load  
2016-12-09 23:37:16 whiten true 
2016-12-09 23:37:16 [----------------------] 
2016-12-09 23:37:17 ==> Network 
2016-12-09 23:37:17 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): nn.View(8192)
  (29): BinaryLinear(8192 -> 216)
  (30): BatchNormalizationShiftPow2
  (31): nn.HardTanh
  (32): BinarizedNeurons
  (33): BinaryLinear(216 -> 216)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(216 -> 100)
  (38): nn.BatchNormalization
} 
2016-12-09 23:37:17 ==>6419292 Parameters 
2016-12-09 23:37:17 ==> Loss 
2016-12-09 23:37:17 SqrtHingeEmbeddingCriterion 
2016-12-09 23:37:17 
==> Starting Training
 
2016-12-09 23:37:17 Epoch 1 
2016-12-09 23:46:36 Training Error = 0.93708888888889 
2016-12-09 23:46:36 Training Loss = 0.23043812955729 
2016-12-09 23:46:47 Valid Error = 0.91558311662332 
2016-12-09 23:46:47 Valid Loss = 0.039897409898662 
2016-12-09 23:47:10 Test Error = 0.9192 
2016-12-09 23:47:10 Test Loss = 0.039937104019464 
2016-12-09 23:47:10 -------------------LR------------------- 
2016-12-09 23:47:10 0.015625 
2016-12-09 23:47:10 Epoch 2 
2016-12-09 23:56:47 Training Error = 0.90468888888889 
2016-12-09 23:56:47 Training Loss = 0.038832261094835 
2016-12-09 23:56:58 Valid Error = 0.88997799559912 
2016-12-09 23:56:58 Valid Loss = 0.038544488636648 
2016-12-09 23:57:20 Test Error = 0.8887 
2016-12-09 23:57:20 Test Loss = 0.038623264866249 
2016-12-09 23:57:20 -------------------LR------------------- 
2016-12-09 23:57:20 0.015625 
2016-12-09 23:57:20 Epoch 3 
2016-12-10 00:06:57 Training Error = 0.88088888888889 
2016-12-10 00:06:57 Training Loss = 0.038451571343316 
2016-12-10 00:07:08 Valid Error = 0.86557311462292 
2016-12-10 00:07:08 Valid Loss = 0.038237422455462 
2016-12-10 00:07:31 Test Error = 0.8636 
2016-12-10 00:07:31 Test Loss = 0.038300243063534 
2016-12-10 00:07:31 -------------------LR------------------- 
2016-12-10 00:07:31 0.015625 
2016-12-10 00:07:31 Epoch 4 
2016-12-10 00:17:05 Training Error = 0.86622222222222 
2016-12-10 00:17:05 Training Loss = 0.038242233588325 
2016-12-10 00:17:16 Valid Error = 0.8495699139828 
2016-12-10 00:17:16 Valid Loss = 0.037974293376589 
2016-12-10 00:17:39 Test Error = 0.8505 
2016-12-10 00:17:39 Test Loss = 0.038106945591347 
2016-12-10 00:17:39 -------------------LR------------------- 
2016-12-10 00:17:39 0.015625 
2016-12-10 00:17:39 Epoch 5 
2016-12-10 00:27:13 Training Error = 0.85246666666667 
2016-12-10 00:27:13 Training Loss = 0.03806912641059 
2016-12-10 00:27:24 Valid Error = 0.84216843368674 
2016-12-10 00:27:24 Valid Loss = 0.037862900125772 
2016-12-10 00:27:47 Test Error = 0.8398 
2016-12-10 00:27:47 Test Loss = 0.037980571283079 
2016-12-10 00:27:47 -------------------LR------------------- 
2016-12-10 00:27:47 0.015625 
2016-12-10 00:27:47 Epoch 6 
2016-12-10 00:37:29 Training Error = 0.84195555555556 
2016-12-10 00:37:29 Training Loss = 0.037927162082248 
2016-12-10 00:37:40 Valid Error = 0.83376675335067 
2016-12-10 00:37:40 Valid Loss = 0.037755633502223 
2016-12-10 00:38:03 Test Error = 0.83 
2016-12-10 00:38:03 Test Loss = 0.037864564723595 
2016-12-10 00:38:03 -------------------LR------------------- 
2016-12-10 00:38:03 0.015625 
2016-12-10 00:38:03 Epoch 7 
2016-12-10 00:47:38 Training Error = 0.82993333333333 
2016-12-10 00:47:38 Training Loss = 0.03778155211046 
2016-12-10 00:47:50 Valid Error = 0.82876575315063 
2016-12-10 00:47:50 Valid Loss = 0.03763769836516 
2016-12-10 00:48:12 Test Error = 0.8298 
2016-12-10 00:48:12 Test Loss = 0.037763506870644 
2016-12-10 00:48:12 -------------------LR------------------- 
2016-12-10 00:48:12 0.015625 
2016-12-10 00:48:12 Epoch 8 
2016-12-10 00:57:51 Training Error = 0.82768888888889 
2016-12-10 00:57:51 Training Loss = 0.037649289442274 
2016-12-10 00:58:02 Valid Error = 0.81956391278256 
2016-12-10 00:58:02 Valid Loss = 0.037419847592406 
2016-12-10 00:58:25 Test Error = 0.8139 
2016-12-10 00:58:25 Test Loss = 0.037524643303366 
2016-12-10 00:58:25 -------------------LR------------------- 
2016-12-10 00:58:25 0.015625 
2016-12-10 00:58:25 Epoch 9 
2016-12-10 01:07:59 Training Error = 0.81791111111111 
2016-12-10 01:07:59 Training Loss = 0.037503946940104 
2016-12-10 01:08:10 Valid Error = 0.79655931186237 
2016-12-10 01:08:10 Valid Loss = 0.037150577524042 
2016-12-10 01:08:33 Test Error = 0.8009 
2016-12-10 01:08:33 Test Loss = 0.037271435427198 
2016-12-10 01:08:33 -------------------LR------------------- 
2016-12-10 01:08:33 0.015625 
2016-12-10 01:08:33 Epoch 10 
2016-12-10 01:18:20 Training Error = 0.80782222222222 
2016-12-10 01:18:20 Training Loss = 0.03736091023763 
2016-12-10 01:18:31 Valid Error = 0.80796159231846 
2016-12-10 01:18:31 Valid Loss = 0.037240462388728 
2016-12-10 01:18:53 Test Error = 0.8085 
2016-12-10 01:18:53 Test Loss = 0.037345499943752 
2016-12-10 01:18:53 -------------------LR------------------- 
2016-12-10 01:18:53 0.015625 
2016-12-10 01:18:54 Epoch 11 
2016-12-10 01:28:27 Training Error = 0.80302222222222 
2016-12-10 01:28:27 Training Loss = 0.037242754150391 
2016-12-10 01:28:38 Valid Error = 0.78395679135827 
2016-12-10 01:28:38 Valid Loss = 0.036907717633001 
2016-12-10 01:29:01 Test Error = 0.7811 
2016-12-10 01:29:01 Test Loss = 0.036970304810767 
2016-12-10 01:29:01 -------------------LR------------------- 
2016-12-10 01:29:01 0.015625 
2016-12-10 01:29:01 Epoch 12 
2016-12-10 01:38:39 Training Error = 0.7954 
2016-12-10 01:38:39 Training Loss = 0.037104141330295 
2016-12-10 01:38:50 Valid Error = 0.78295659131826 
2016-12-10 01:38:50 Valid Loss = 0.036790750557177 
2016-12-10 01:39:12 Test Error = 0.7819 
2016-12-10 01:39:12 Test Loss = 0.036845662195542 
2016-12-10 01:39:12 -------------------LR------------------- 
2016-12-10 01:39:12 0.015625 
2016-12-10 01:39:12 Epoch 13 
2016-12-10 01:48:47 Training Error = 0.78826666666667 
2016-12-10 01:48:47 Training Loss = 0.036986458577474 
2016-12-10 01:48:58 Valid Error = 0.76395279055811 
2016-12-10 01:48:58 Valid Loss = 0.036509259803585 
2016-12-10 01:49:21 Test Error = 0.7716 
2016-12-10 01:49:21 Test Loss = 0.036600285189759 
2016-12-10 01:49:21 -------------------LR------------------- 
2016-12-10 01:49:21 0.015625 
2016-12-10 01:49:21 Epoch 14 
2016-12-10 01:58:55 Training Error = 0.78242222222222 
2016-12-10 01:58:55 Training Loss = 0.036874687717014 
2016-12-10 01:59:06 Valid Error = 0.76835367073415 
2016-12-10 01:59:06 Valid Loss = 0.036568558152714 
2016-12-10 01:59:29 Test Error = 0.7721 
2016-12-10 01:59:29 Test Loss = 0.036668678852156 
2016-12-10 01:59:29 -------------------LR------------------- 
2016-12-10 01:59:29 0.015625 
2016-12-10 01:59:29 Epoch 15 
2016-12-10 02:09:04 Training Error = 0.77448888888889 
2016-12-10 02:09:04 Training Loss = 0.036740946777344 
2016-12-10 02:09:15 Valid Error = 0.76495299059812 
2016-12-10 02:09:15 Valid Loss = 0.036391089917216 
2016-12-10 02:09:37 Test Error = 0.764 
2016-12-10 02:09:37 Test Loss = 0.036519225954542 
2016-12-10 02:09:37 -------------------LR------------------- 
2016-12-10 02:09:37 0.015625 
2016-12-10 02:09:37 Epoch 16 
2016-12-10 02:19:15 Training Error = 0.77062222222222 
2016-12-10 02:19:15 Training Loss = 0.03664274102105 
2016-12-10 02:19:26 Valid Error = 0.74934986997399 
2016-12-10 02:19:26 Valid Loss = 0.036071873670926 
2016-12-10 02:19:49 Test Error = 0.7555 
2016-12-10 02:19:49 Test Loss = 0.03620374917423 
2016-12-10 02:19:49 -------------------LR------------------- 
2016-12-10 02:19:49 0.015625 
2016-12-10 02:19:49 Epoch 17 
2016-12-10 02:29:36 Training Error = 0.76573333333333 
2016-12-10 02:29:36 Training Loss = 0.036543139838325 
2016-12-10 02:29:47 Valid Error = 0.75135027005401 
2016-12-10 02:29:47 Valid Loss = 0.036107493427279 
2016-12-10 02:30:09 Test Error = 0.7504 
2016-12-10 02:30:09 Test Loss = 0.036185844630821 
2016-12-10 02:30:09 -------------------LR------------------- 
2016-12-10 02:30:09 0.015625 
2016-12-10 02:30:10 Epoch 18 
2016-12-10 02:39:39 Training Error = 0.76353333333333 
2016-12-10 02:39:39 Training Loss = 0.036445256510417 
2016-12-10 02:39:50 Valid Error = 0.73034606921384 
2016-12-10 02:39:50 Valid Loss = 0.035728392242453 
2016-12-10 02:40:13 Test Error = 0.7373 
2016-12-10 02:40:13 Test Loss = 0.035860042407466 
2016-12-10 02:40:13 -------------------LR------------------- 
2016-12-10 02:40:13 0.015625 
2016-12-10 02:40:13 Epoch 19 
2016-12-10 02:49:54 Training Error = 0.75577777777778 
2016-12-10 02:49:54 Training Loss = 0.036333587320964 
2016-12-10 02:50:05 Valid Error = 0.74574914982997 
2016-12-10 02:50:05 Valid Loss = 0.035822656335398 
2016-12-10 02:50:27 Test Error = 0.7442 
2016-12-10 02:50:27 Test Loss = 0.035919771022423 
2016-12-10 02:50:27 -------------------LR------------------- 
2016-12-10 02:50:27 0.015625 
2016-12-10 02:50:28 Epoch 20 
2016-12-10 03:00:03 Training Error = 0.75571111111111 
2016-12-10 03:00:03 Training Loss = 0.036261030897352 
2016-12-10 03:00:14 Valid Error = 0.73514702940588 
2016-12-10 03:00:14 Valid Loss = 0.035745280289507 
2016-12-10 03:00:37 Test Error = 0.7365 
2016-12-10 03:00:37 Test Loss = 0.035826216215246 
2016-12-10 03:00:37 -------------------LR------------------- 
2016-12-10 03:00:37 0.015625 
2016-12-10 03:00:37 Epoch 21 
2016-12-10 03:10:16 Training Error = 0.74971111111111 
2016-12-10 03:10:16 Training Loss = 0.036183650037977 
2016-12-10 03:10:27 Valid Error = 0.72374474894979 
2016-12-10 03:10:27 Valid Loss = 0.035446526311186 
2016-12-10 03:10:50 Test Error = 0.7218 
2016-12-10 03:10:50 Test Loss = 0.035507998567469 
2016-12-10 03:10:50 -------------------LR------------------- 
2016-12-10 03:10:50 0.015625 
2016-12-10 03:10:50 Epoch 22 
2016-12-10 03:20:26 Training Error = 0.74766666666667 
2016-12-10 03:20:26 Training Loss = 0.036094927463108 
2016-12-10 03:20:38 Valid Error = 0.72614522904581 
2016-12-10 03:20:38 Valid Loss = 0.035280992783935 
2016-12-10 03:21:00 Test Error = 0.7251 
2016-12-10 03:21:00 Test Loss = 0.035331630691828 
2016-12-10 03:21:00 -------------------LR------------------- 
2016-12-10 03:21:00 0.015625 
2016-12-10 03:21:00 Epoch 23 
2016-12-10 03:30:35 Training Error = 0.74237777777778 
2016-12-10 03:30:35 Training Loss = 0.03600537483724 
2016-12-10 03:30:46 Valid Error = 0.71994398879776 
2016-12-10 03:30:46 Valid Loss = 0.035281554433665 
2016-12-10 03:31:09 Test Error = 0.7206 
2016-12-10 03:31:09 Test Loss = 0.035355802259258 
2016-12-10 03:31:09 -------------------LR------------------- 
2016-12-10 03:31:09 0.015625 
2016-12-10 03:31:09 Epoch 24 
2016-12-10 03:40:41 Training Error = 0.7384 
2016-12-10 03:40:41 Training Loss = 0.035950733642578 
2016-12-10 03:40:52 Valid Error = 0.71534306861372 
2016-12-10 03:40:52 Valid Loss = 0.035072708935446 
2016-12-10 03:41:15 Test Error = 0.7154 
2016-12-10 03:41:15 Test Loss = 0.035147341559915 
2016-12-10 03:41:15 -------------------LR------------------- 
2016-12-10 03:41:15 0.015625 
2016-12-10 03:41:15 Epoch 25 
2016-12-10 03:50:55 Training Error = 0.73584444444444 
2016-12-10 03:50:55 Training Loss = 0.035878311848958 
2016-12-10 03:51:06 Valid Error = 0.71174234846969 
2016-12-10 03:51:06 Valid Loss = 0.035015469700438 
2016-12-10 03:51:28 Test Error = 0.7123 
2016-12-10 03:51:28 Test Loss = 0.035047096731149 
2016-12-10 03:51:28 -------------------LR------------------- 
2016-12-10 03:51:28 0.015625 
2016-12-10 03:51:28 Epoch 26 
2016-12-10 04:01:08 Training Error = 0.73108888888889 
2016-12-10 04:01:08 Training Loss = 0.035790215223524 
2016-12-10 04:01:20 Valid Error = 0.70774154830966 
2016-12-10 04:01:20 Valid Loss = 0.034924157977652 
2016-12-10 04:01:42 Test Error = 0.7128 
2016-12-10 04:01:42 Test Loss = 0.034992870076497 
2016-12-10 04:01:42 -------------------LR------------------- 
2016-12-10 04:01:42 0.015625 
2016-12-10 04:01:42 Epoch 27 
2016-12-10 04:11:28 Training Error = 0.73073333333333 
2016-12-10 04:11:28 Training Loss = 0.035745687608507 
2016-12-10 04:11:39 Valid Error = 0.71134226845369 
2016-12-10 04:11:39 Valid Loss = 0.034800333578268 
2016-12-10 04:12:02 Test Error = 0.7101 
2016-12-10 04:12:02 Test Loss = 0.034824247921214 
2016-12-10 04:12:02 -------------------LR------------------- 
2016-12-10 04:12:02 0.015625 
2016-12-10 04:12:02 Epoch 28 
2016-12-10 04:21:28 Training Error = 0.7268 
2016-12-10 04:21:28 Training Loss = 0.035659524522569 
2016-12-10 04:21:39 Valid Error = 0.70594118823765 
2016-12-10 04:21:39 Valid Loss = 0.034758605828935 
2016-12-10 04:22:02 Test Error = 0.7036 
2016-12-10 04:22:02 Test Loss = 0.034758733801748 
2016-12-10 04:22:02 -------------------LR------------------- 
2016-12-10 04:22:02 0.015625 
2016-12-10 04:22:02 Epoch 29 
2016-12-10 04:31:38 Training Error = 0.72268888888889 
2016-12-10 04:31:38 Training Loss = 0.035608807725694 
2016-12-10 04:31:50 Valid Error = 0.70394078815763 
2016-12-10 04:31:50 Valid Loss = 0.034813986958695 
2016-12-10 04:32:12 Test Error = 0.7108 
2016-12-10 04:32:12 Test Loss = 0.03484944894828 
2016-12-10 04:32:12 -------------------LR------------------- 
2016-12-10 04:32:12 0.015625 
2016-12-10 04:32:12 Epoch 30 
2016-12-10 04:41:52 Training Error = 0.72213333333333 
2016-12-10 04:41:52 Training Loss = 0.035557607801649 
2016-12-10 04:42:04 Valid Error = 0.69673934786957 
2016-12-10 04:42:04 Valid Loss = 0.034612430861102 
2016-12-10 04:42:26 Test Error = 0.703 
2016-12-10 04:42:26 Test Loss = 0.034658718004414 
2016-12-10 04:42:26 -------------------LR------------------- 
2016-12-10 04:42:26 0.015625 
2016-12-10 04:42:26 Epoch 31 
2016-12-10 04:52:02 Training Error = 0.71906666666667 
2016-12-10 04:52:02 Training Loss = 0.035494640516493 
2016-12-10 04:52:13 Valid Error = 0.69513902780556 
2016-12-10 04:52:13 Valid Loss = 0.034563383342109 
2016-12-10 04:52:36 Test Error = 0.6927 
2016-12-10 04:52:36 Test Loss = 0.034605802468693 
2016-12-10 04:52:36 -------------------LR------------------- 
2016-12-10 04:52:36 0.015625 
2016-12-10 04:52:36 Epoch 32 
2016-12-10 05:02:13 Training Error = 0.71808888888889 
2016-12-10 05:02:13 Training Loss = 0.035460941731771 
2016-12-10 05:02:24 Valid Error = 0.69613922784557 
2016-12-10 05:02:24 Valid Loss = 0.034474334170133 
2016-12-10 05:02:47 Test Error = 0.6978 
2016-12-10 05:02:47 Test Loss = 0.034509621474322 
2016-12-10 05:02:47 -------------------LR------------------- 
2016-12-10 05:02:47 0.015625 
2016-12-10 05:02:47 Epoch 33 
2016-12-10 05:12:23 Training Error = 0.71353333333333 
2016-12-10 05:12:23 Training Loss = 0.03540070686849 
2016-12-10 05:12:34 Valid Error = 0.69233846769354 
2016-12-10 05:12:34 Valid Loss = 0.034387595467187 
2016-12-10 05:12:57 Test Error = 0.6905 
2016-12-10 05:12:57 Test Loss = 0.034386938715916 
2016-12-10 05:12:57 -------------------LR------------------- 
2016-12-10 05:12:57 0.015625 
2016-12-10 05:12:57 Epoch 34 
2016-12-10 05:22:36 Training Error = 0.7126 
2016-12-10 05:22:36 Training Loss = 0.035351504584418 
2016-12-10 05:22:47 Valid Error = 0.69013802760552 
2016-12-10 05:22:47 Valid Loss = 0.034238846636772 
2016-12-10 05:23:10 Test Error = 0.6861 
2016-12-10 05:23:10 Test Loss = 0.034264469580557 
2016-12-10 05:23:10 -------------------LR------------------- 
2016-12-10 05:23:10 0.015625 
2016-12-10 05:23:10 Epoch 35 
2016-12-10 05:32:46 Training Error = 0.71104444444444 
2016-12-10 05:32:46 Training Loss = 0.035313370388455 
2016-12-10 05:32:57 Valid Error = 0.67673534706941 
2016-12-10 05:32:57 Valid Loss = 0.033939151146212 
2016-12-10 05:33:20 Test Error = 0.6741 
2016-12-10 05:33:20 Test Loss = 0.033916635431028 
2016-12-10 05:33:20 -------------------LR------------------- 
2016-12-10 05:33:20 0.015625 
2016-12-10 05:33:20 Epoch 36 
2016-12-10 05:42:58 Training Error = 0.70668888888889 
2016-12-10 05:42:58 Training Loss = 0.035233306396484 
2016-12-10 05:43:09 Valid Error = 0.67393478695739 
2016-12-10 05:43:09 Valid Loss = 0.033954125541757 
2016-12-10 05:43:32 Test Error = 0.6748 
2016-12-10 05:43:32 Test Loss = 0.033984377812404 
2016-12-10 05:43:32 -------------------LR------------------- 
2016-12-10 05:43:32 0.015625 
2016-12-10 05:43:32 Epoch 37 
2016-12-10 05:53:13 Training Error = 0.70093333333333 
2016-12-10 05:53:13 Training Loss = 0.035161517985026 
2016-12-10 05:53:24 Valid Error = 0.68273654730946 
2016-12-10 05:53:24 Valid Loss = 0.034195635353665 
2016-12-10 05:53:47 Test Error = 0.6819 
2016-12-10 05:53:47 Test Loss = 0.034256061658672 
2016-12-10 05:53:47 -------------------LR------------------- 
2016-12-10 05:53:47 0.015625 
2016-12-10 05:53:47 Epoch 38 
2016-12-10 06:03:25 Training Error = 0.70024444444444 
2016-12-10 06:03:25 Training Loss = 0.035146615152995 
2016-12-10 06:03:36 Valid Error = 0.67013402680536 
2016-12-10 06:03:36 Valid Loss = 0.033760180294207 
2016-12-10 06:03:58 Test Error = 0.664 
2016-12-10 06:03:58 Test Loss = 0.033723750125661 
2016-12-10 06:03:58 -------------------LR------------------- 
2016-12-10 06:03:58 0.015625 
2016-12-10 06:03:58 Epoch 39 
2016-12-10 06:13:33 Training Error = 0.70028888888889 
2016-12-10 06:13:33 Training Loss = 0.035090665703668 
2016-12-10 06:13:44 Valid Error = 0.6749349869974 
2016-12-10 06:13:44 Valid Loss = 0.033749298020529 
2016-12-10 06:14:06 Test Error = 0.6649 
2016-12-10 06:14:06 Test Loss = 0.033729039091222 
2016-12-10 06:14:06 -------------------LR------------------- 
2016-12-10 06:14:06 0.015625 
2016-12-10 06:14:06 Epoch 40 
2016-12-10 06:23:55 Training Error = 0.69911111111111 
2016-12-10 06:23:55 Training Loss = 0.03504891788737 
2016-12-10 06:24:06 Valid Error = 0.66373274654931 
2016-12-10 06:24:06 Valid Loss = 0.033602254350245 
2016-12-10 06:24:28 Test Error = 0.6697 
2016-12-10 06:24:28 Test Loss = 0.033693715293735 
2016-12-10 06:24:28 -------------------LR------------------- 
2016-12-10 06:24:28 0.015625 
2016-12-10 06:24:28 Epoch 41 
2016-12-10 06:34:00 Training Error = 0.69826666666667 
2016-12-10 06:34:00 Training Loss = 0.034988617621528 
2016-12-10 06:34:11 Valid Error = 0.66433286657331 
2016-12-10 06:34:11 Valid Loss = 0.033637438854188 
2016-12-10 06:34:34 Test Error = 0.664 
2016-12-10 06:34:34 Test Loss = 0.033683896502327 
2016-12-10 06:34:34 -------------------LR------------------- 
2016-12-10 06:34:34 0.015625 
2016-12-10 06:34:34 Epoch 42 
2016-12-10 06:44:15 Training Error = 0.69193333333333 
2016-12-10 06:44:15 Training Loss = 0.034962897447374 
2016-12-10 06:44:27 Valid Error = 0.67133426685337 
2016-12-10 06:44:27 Valid Loss = 0.033650104850689 
2016-12-10 06:44:49 Test Error = 0.6667 
2016-12-10 06:44:49 Test Loss = 0.033650938595043 
2016-12-10 06:44:49 -------------------LR------------------- 
2016-12-10 06:44:49 0.015625 
2016-12-10 06:44:49 Epoch 43 
2016-12-10 06:54:32 Training Error = 0.69088888888889 
2016-12-10 06:54:32 Training Loss = 0.034913138617622 
2016-12-10 06:54:43 Valid Error = 0.67713542708542 
2016-12-10 06:54:43 Valid Loss = 0.03360981817814 
2016-12-10 06:55:06 Test Error = 0.6718 
2016-12-10 06:55:06 Test Loss = 0.033582867970186 
2016-12-10 06:55:06 -------------------LR------------------- 
2016-12-10 06:55:06 0.015625 
2016-12-10 06:55:06 Epoch 44 
2016-12-10 07:04:41 Training Error = 0.69148888888889 
2016-12-10 07:04:41 Training Loss = 0.034861942586263 
2016-12-10 07:04:52 Valid Error = 0.66873374674935 
2016-12-10 07:04:52 Valid Loss = 0.033686756445178 
2016-12-10 07:05:15 Test Error = 0.6668 
2016-12-10 07:05:15 Test Loss = 0.033691417828728 
2016-12-10 07:05:15 -------------------LR------------------- 
2016-12-10 07:05:15 0.015625 
2016-12-10 07:05:15 Epoch 45 
2016-12-10 07:14:53 Training Error = 0.68606666666667 
2016-12-10 07:14:53 Training Loss = 0.034812624226888 
2016-12-10 07:15:04 Valid Error = 0.66073214642929 
2016-12-10 07:15:04 Valid Loss = 0.033412256125791 
2016-12-10 07:15:27 Test Error = 0.6595 
2016-12-10 07:15:27 Test Loss = 0.033358830680099 
2016-12-10 07:15:27 -------------------LR------------------- 
2016-12-10 07:15:27 0.015625 
2016-12-10 07:15:27 Epoch 46 
2016-12-10 07:24:58 Training Error = 0.68762222222222 
2016-12-10 07:24:58 Training Loss = 0.034777516940647 
2016-12-10 07:25:09 Valid Error = 0.65673134626925 
2016-12-10 07:25:09 Valid Loss = 0.033300242276313 
2016-12-10 07:25:32 Test Error = 0.6536 
2016-12-10 07:25:32 Test Loss = 0.033321575449027 
2016-12-10 07:25:32 -------------------LR------------------- 
2016-12-10 07:25:32 0.015625 
2016-12-10 07:25:32 Epoch 47 
2016-12-10 07:35:12 Training Error = 0.68171111111111 
2016-12-10 07:35:12 Training Loss = 0.03473120823839 
2016-12-10 07:35:23 Valid Error = 0.64752950590118 
2016-12-10 07:35:23 Valid Loss = 0.033191525739143 
2016-12-10 07:35:45 Test Error = 0.6557 
2016-12-10 07:35:45 Test Loss = 0.033246909676346 
2016-12-10 07:35:45 -------------------LR------------------- 
2016-12-10 07:35:45 0.015625 
2016-12-10 07:35:45 Epoch 48 
2016-12-10 07:45:17 Training Error = 0.68124444444444 
2016-12-10 07:45:17 Training Loss = 0.034712504977756 
2016-12-10 07:45:28 Valid Error = 0.64652930586117 
2016-12-10 07:45:28 Valid Loss = 0.033099917381528 
2016-12-10 07:45:50 Test Error = 0.6462 
2016-12-10 07:45:50 Test Loss = 0.033100411897547 
2016-12-10 07:45:50 -------------------LR------------------- 
2016-12-10 07:45:50 0.015625 
2016-12-10 07:45:50 Epoch 49 
2016-12-10 07:55:29 Training Error = 0.68011111111111 
2016-12-10 07:55:29 Training Loss = 0.034668252143012 
2016-12-10 07:55:40 Valid Error = 0.65893178635727 
2016-12-10 07:55:40 Valid Loss = 0.033397039212776 
2016-12-10 07:56:03 Test Error = 0.6588 
2016-12-10 07:56:03 Test Loss = 0.033448815738454 
2016-12-10 07:56:03 -------------------LR------------------- 
2016-12-10 07:56:03 0.015625 
2016-12-10 07:56:03 Epoch 50 
2016-12-10 08:05:45 Training Error = 0.68177777777778 
2016-12-10 08:05:45 Training Loss = 0.034633526529948 
2016-12-10 08:05:56 Valid Error = 0.65413082616523 
2016-12-10 08:05:56 Valid Loss = 0.03338182502827 
2016-12-10 08:06:19 Test Error = 0.6573 
2016-12-10 08:06:19 Test Loss = 0.033361752827962 
2016-12-10 08:06:19 -------------------LR------------------- 
2016-12-10 08:06:19 0.0078125 
2016-12-10 08:06:19 Epoch 51 
2016-12-10 08:15:49 Training Error = 0.6694 
2016-12-10 08:15:49 Training Loss = 0.034404661960178 
2016-12-10 08:16:00 Valid Error = 0.64392878575715 
2016-12-10 08:16:00 Valid Loss = 0.032848046877406 
2016-12-10 08:16:22 Test Error = 0.6453 
2016-12-10 08:16:22 Test Loss = 0.032846296721814 
2016-12-10 08:16:22 -------------------LR------------------- 
2016-12-10 08:16:22 0.0078125 
2016-12-10 08:16:23 Epoch 52 
2016-12-10 08:26:01 Training Error = 0.66602222222222 
2016-12-10 08:26:01 Training Loss = 0.034383304456923 
2016-12-10 08:26:12 Valid Error = 0.64792958591718 
2016-12-10 08:26:12 Valid Loss = 0.032948773829029 
2016-12-10 08:26:35 Test Error = 0.6471 
2016-12-10 08:26:35 Test Loss = 0.032903984787885 
2016-12-10 08:26:35 -------------------LR------------------- 
2016-12-10 08:26:35 0.0078125 
2016-12-10 08:26:35 Epoch 53 
2016-12-10 08:36:12 Training Error = 0.66675555555556 
2016-12-10 08:36:12 Training Loss = 0.034348332967122 
2016-12-10 08:36:23 Valid Error = 0.64752950590118 
2016-12-10 08:36:23 Valid Loss = 0.032939406302513 
2016-12-10 08:36:46 Test Error = 0.6472 
2016-12-10 08:36:46 Test Loss = 0.032897726560106 
2016-12-10 08:36:46 -------------------LR------------------- 
2016-12-10 08:36:46 0.0078125 
2016-12-10 08:36:46 Epoch 54 
2016-12-10 08:46:16 Training Error = 0.66822222222222 
2016-12-10 08:46:16 Training Loss = 0.03431337113444 
2016-12-10 08:46:27 Valid Error = 0.6373274654931 
2016-12-10 08:46:27 Valid Loss = 0.032760169757238 
2016-12-10 08:46:49 Test Error = 0.6402 
2016-12-10 08:46:49 Test Loss = 0.032732271650726 
2016-12-10 08:46:49 -------------------LR------------------- 
2016-12-10 08:46:49 0.0078125 
2016-12-10 08:46:49 Epoch 55 
2016-12-10 08:56:22 Training Error = 0.66333333333333 
2016-12-10 08:56:22 Training Loss = 0.03430547648112 
2016-12-10 08:56:33 Valid Error = 0.65253050610122 
2016-12-10 08:56:33 Valid Loss = 0.032960111664086 
2016-12-10 08:56:56 Test Error = 0.6504 
2016-12-10 08:56:56 Test Loss = 0.032903773857565 
2016-12-10 08:56:56 -------------------LR------------------- 
2016-12-10 08:56:56 0.0078125 
2016-12-10 08:56:56 Epoch 56 
2016-12-10 09:06:33 Training Error = 0.66593333333333 
2016-12-10 09:06:33 Training Loss = 0.034305836249457 
2016-12-10 09:06:44 Valid Error = 0.64752950590118 
2016-12-10 09:06:44 Valid Loss = 0.032929178442501 
2016-12-10 09:07:07 Test Error = 0.647 
2016-12-10 09:07:07 Test Loss = 0.032907242389754 
2016-12-10 09:07:07 -------------------LR------------------- 
2016-12-10 09:07:07 0.0078125 
2016-12-10 09:07:07 Epoch 57 
2016-12-10 09:16:41 Training Error = 0.66444444444444 
2016-12-10 09:16:41 Training Loss = 0.034272239786784 
2016-12-10 09:16:53 Valid Error = 0.64252850570114 
2016-12-10 09:16:53 Valid Loss = 0.032706508712926 
2016-12-10 09:17:15 Test Error = 0.6418 
2016-12-10 09:17:15 Test Loss = 0.032652137038287 
2016-12-10 09:17:15 -------------------LR------------------- 
2016-12-10 09:17:15 0.0078125 
2016-12-10 09:17:15 Epoch 58 
2016-12-10 09:26:54 Training Error = 0.66166666666667 
2016-12-10 09:26:54 Training Loss = 0.034240052639431 
2016-12-10 09:27:05 Valid Error = 0.64532906581316 
2016-12-10 09:27:05 Valid Loss = 0.032876455230517 
2016-12-10 09:27:27 Test Error = 0.6471 
2016-12-10 09:27:27 Test Loss = 0.032865031552782 
2016-12-10 09:27:27 -------------------LR------------------- 
2016-12-10 09:27:27 0.0078125 
2016-12-10 09:27:27 Epoch 59 
2016-12-10 09:37:02 Training Error = 0.66231111111111 
2016-12-10 09:37:02 Training Loss = 0.034261907592773 
2016-12-10 09:37:14 Valid Error = 0.64832966593319 
2016-12-10 09:37:14 Valid Loss = 0.03294587401141 
2016-12-10 09:37:36 Test Error = 0.6465 
2016-12-10 09:37:36 Test Loss = 0.032872173683316 
2016-12-10 09:37:36 -------------------LR------------------- 
2016-12-10 09:37:36 0.0078125 
2016-12-10 09:37:36 Epoch 60 
2016-12-10 09:47:19 Training Error = 0.65906666666667 
2016-12-10 09:47:19 Training Loss = 0.034192426133898 
2016-12-10 09:47:30 Valid Error = 0.64352870574115 
2016-12-10 09:47:30 Valid Loss = 0.032690410540418 
2016-12-10 09:47:53 Test Error = 0.6432 
2016-12-10 09:47:53 Test Loss = 0.032663900008856 
2016-12-10 09:47:53 -------------------LR------------------- 
2016-12-10 09:47:53 0.0078125 
2016-12-10 09:47:53 Epoch 61 
2016-12-10 09:57:23 Training Error = 0.65862222222222 
2016-12-10 09:57:23 Training Loss = 0.034155209825304 
2016-12-10 09:57:34 Valid Error = 0.64092818563713 
2016-12-10 09:57:34 Valid Loss = 0.032701491609852 
2016-12-10 09:57:57 Test Error = 0.639 
2016-12-10 09:57:57 Test Loss = 0.032711184004241 
2016-12-10 09:57:57 -------------------LR------------------- 
2016-12-10 09:57:57 0.0078125 
2016-12-10 09:57:57 Epoch 62 
2016-12-10 10:07:38 Training Error = 0.65895555555556 
2016-12-10 10:07:38 Training Loss = 0.034135849609375 
2016-12-10 10:07:49 Valid Error = 0.63672734546909 
2016-12-10 10:07:49 Valid Loss = 0.03268794198919 
2016-12-10 10:08:12 Test Error = 0.6392 
2016-12-10 10:08:12 Test Loss = 0.032659482499665 
2016-12-10 10:08:12 -------------------LR------------------- 
2016-12-10 10:08:12 0.0078125 
2016-12-10 10:08:12 Epoch 63 
2016-12-10 10:17:44 Training Error = 0.65708888888889 
2016-12-10 10:17:44 Training Loss = 0.034132283894857 
2016-12-10 10:17:55 Valid Error = 0.64612922584517 
2016-12-10 10:17:55 Valid Loss = 0.032926865713443 
2016-12-10 10:18:17 Test Error = 0.6465 
2016-12-10 10:18:17 Test Loss = 0.032925690774357 
2016-12-10 10:18:17 -------------------LR------------------- 
2016-12-10 10:18:17 0.0078125 
2016-12-10 10:18:18 Epoch 64 
2016-12-10 10:27:54 Training Error = 0.65882222222222 
2016-12-10 10:27:54 Training Loss = 0.034105040798611 
2016-12-10 10:28:05 Valid Error = 0.63552710542108 
2016-12-10 10:28:05 Valid Loss = 0.03264208190058 
2016-12-10 10:28:28 Test Error = 0.635 
2016-12-10 10:28:28 Test Loss = 0.032527236579446 
2016-12-10 10:28:28 -------------------LR------------------- 
2016-12-10 10:28:28 0.0078125 
2016-12-10 10:28:28 Epoch 65 
2016-12-10 10:37:55 Training Error = 0.658 
2016-12-10 10:37:55 Training Loss = 0.034093981852214 
2016-12-10 10:38:06 Valid Error = 0.63192638527706 
2016-12-10 10:38:06 Valid Loss = 0.032684402408989 
2016-12-10 10:38:29 Test Error = 0.631 
2016-12-10 10:38:29 Test Loss = 0.032602894711962 
2016-12-10 10:38:29 -------------------LR------------------- 
2016-12-10 10:38:29 0.0078125 
2016-12-10 10:38:29 Epoch 66 
2016-12-10 10:48:09 Training Error = 0.65626666666667 
2016-12-10 10:48:09 Training Loss = 0.034072843356662 
2016-12-10 10:48:21 Valid Error = 0.6377275455091 
2016-12-10 10:48:21 Valid Loss = 0.032628027641438 
2016-12-10 10:48:43 Test Error = 0.6331 
2016-12-10 10:48:43 Test Loss = 0.032543491528081 
2016-12-10 10:48:43 -------------------LR------------------- 
2016-12-10 10:48:43 0.0078125 
2016-12-10 10:48:43 Epoch 67 
2016-12-10 10:58:18 Training Error = 0.65635555555556 
2016-12-10 10:58:18 Training Loss = 0.034069046210395 
2016-12-10 10:58:30 Valid Error = 0.63952790558112 
2016-12-10 10:58:30 Valid Loss = 0.032550236406137 
2016-12-10 10:58:52 Test Error = 0.6393 
2016-12-10 10:58:52 Test Loss = 0.032529573956658 
2016-12-10 10:58:52 -------------------LR------------------- 
2016-12-10 10:58:52 0.0078125 
2016-12-10 10:58:52 Epoch 68 
2016-12-10 11:08:33 Training Error = 0.65591111111111 
2016-12-10 11:08:33 Training Loss = 0.034055137152778 
2016-12-10 11:08:44 Valid Error = 0.63232646529306 
2016-12-10 11:08:44 Valid Loss = 0.032403966034865 
2016-12-10 11:09:07 Test Error = 0.6402 
2016-12-10 11:09:07 Test Loss = 0.032430764800427 
2016-12-10 11:09:07 -------------------LR------------------- 
2016-12-10 11:09:07 0.0078125 
2016-12-10 11:09:07 Epoch 69 
2016-12-10 11:18:39 Training Error = 0.65137777777778 
2016-12-10 11:18:39 Training Loss = 0.034018305216471 
2016-12-10 11:18:51 Valid Error = 0.64172834566913 
2016-12-10 11:18:51 Valid Loss = 0.032736138433099 
2016-12-10 11:19:13 Test Error = 0.6426 
2016-12-10 11:19:13 Test Loss = 0.032791519643746 
2016-12-10 11:19:13 -------------------LR------------------- 
2016-12-10 11:19:13 0.0078125 
2016-12-10 11:19:13 Epoch 70 
2016-12-10 11:28:51 Training Error = 0.65246666666667 
2016-12-10 11:28:51 Training Loss = 0.033979207451714 
2016-12-10 11:29:03 Valid Error = 0.63472694538908 
2016-12-10 11:29:03 Valid Loss = 0.032412478794959 
2016-12-10 11:29:25 Test Error = 0.633 
2016-12-10 11:29:25 Test Loss = 0.032377555936926 
2016-12-10 11:29:25 -------------------LR------------------- 
2016-12-10 11:29:25 0.0078125 
2016-12-10 11:29:25 Epoch 71 
