2016-12-10 16:54:13 [program started on Sat Dec 10 16:54:13 2016] 
2016-12-10 16:54:13 [command line arguments] 
2016-12-10 16:54:13 stcWeights false 
2016-12-10 16:54:13 LR 0.015625 
2016-12-10 16:54:13 batchSize 300 
2016-12-10 16:54:13 network ./Models/Cifar10_Custom 
2016-12-10 16:54:13 stcNeurons true 
2016-12-10 16:54:13 constBatchSize false 
2016-12-10 16:54:13 chartFileName chart1 
2016-12-10 16:54:13 dp_prepro false 
2016-12-10 16:54:13 nGPU 6 
2016-12-10 16:54:13 dataset Cifar100 
2016-12-10 16:54:13 type cuda 
2016-12-10 16:54:13 momentum 0 
2016-12-10 16:54:13 threads 8 
2016-12-10 16:54:13 weightDecay 0 
2016-12-10 16:54:13 runningVal false 
2016-12-10 16:54:13 convLayerN 10 
2016-12-10 16:54:13 LRDecay 0 
2016-12-10 16:54:13 numHid 1024 
2016-12-10 16:54:13 save /dev/shm/clone/temp/th/Results/Cifar100/model10-20 
2016-12-10 16:54:13 augment false 
2016-12-10 16:54:13 epoch -1 
2016-12-10 16:54:13 modelsFolder ./Models/ 
2016-12-10 16:54:13 format rgb 
2016-12-10 16:54:13 preProcDir /dev/shm/clone/temp/th/PreProcData/Cifar100 
2016-12-10 16:54:13 imageFileExtension svg 
2016-12-10 16:54:13 channel 2 
2016-12-10 16:54:13 devid 11 
2016-12-10 16:54:13 visualize 1 
2016-12-10 16:54:13 LRDecayPerEpoch 0.0001 
2016-12-10 16:54:13 optimization adam 
2016-12-10 16:54:13 SBN true 
2016-12-10 16:54:13 normalization simple 
2016-12-10 16:54:13 title model1 
2016-12-10 16:54:13 load  
2016-12-10 16:54:13 whiten true 
2016-12-10 16:54:13 [----------------------] 
2016-12-10 16:54:45 ==> Network 
2016-12-10 16:54:45 DataParallelTable: 6 x nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> (43) -> (44) -> (45) -> (46) -> (47) -> (48) -> (49) -> (50) -> (51) -> (52) -> (53) -> (54) -> (55) -> (56) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 256, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(512 -> 1024, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (29): SpatialBatchNormalizationShiftPow2
  (30): nn.HardTanh
  (31): BinarizedNeurons
  (32): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (33): cudnn.SpatialMaxPooling(2x2, 2,2)
  (34): SpatialBatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (38): SpatialBatchNormalizationShiftPow2
  (39): nn.HardTanh
  (40): BinarizedNeurons
  (41): cudnnBinarySpatialConvolution(1024 -> 1024, 3x3, 1,1, 1,1)
  (42): cudnn.SpatialMaxPooling(2x2, 2,2)
  (43): SpatialBatchNormalizationShiftPow2
  (44): nn.HardTanh
  (45): BinarizedNeurons
  (46): nn.View(1024)
  (47): BinaryLinear(1024 -> 1024)
  (48): BatchNormalizationShiftPow2
  (49): nn.HardTanh
  (50): BinarizedNeurons
  (51): BinaryLinear(1024 -> 1024)
  (52): BatchNormalizationShiftPow2
  (53): nn.HardTanh
  (54): BinarizedNeurons
  (55): BinaryLinear(1024 -> 100)
  (56): nn.BatchNormalization
} 
2016-12-10 16:54:45 ==>58269228 Parameters 
2016-12-10 16:54:45 ==> Loss 
2016-12-10 16:54:45 SqrtHingeEmbeddingCriterion 
2016-12-10 16:54:45 
==> Starting Training
 
2016-12-10 16:54:46 Epoch 1 
2016-12-10 17:08:06 Training Error = 0.97984444444444 
2016-12-10 17:08:06 Training Loss = 0.22742066370985 
2016-12-10 17:08:21 Valid Error = 0.97639527905581 
2016-12-10 17:08:21 Valid Loss = 0.040981541117669 
2016-12-10 17:09:00 Test Error = 0.976 
2016-12-10 17:09:00 Test Loss = 0.04094036619897 
2016-12-10 17:09:00 -------------------LR------------------- 
2016-12-10 17:09:00 0.015625 
2016-12-10 17:09:00 Epoch 2 
2016-12-10 17:22:24 Training Error = 0.9676 
2016-12-10 17:22:24 Training Loss = 0.040227469509549 
2016-12-10 17:22:38 Valid Error = 0.96619323864773 
2016-12-10 17:22:38 Valid Loss = 0.039897025931059 
2016-12-10 17:23:16 Test Error = 0.9669 
2016-12-10 17:23:16 Test Loss = 0.039873982448204 
2016-12-10 17:23:16 -------------------LR------------------- 
2016-12-10 17:23:16 0.015625 
2016-12-10 17:23:16 Epoch 3 
2016-12-10 17:36:41 Training Error = 0.9526 
2016-12-10 17:36:41 Training Loss = 0.039558393717448 
2016-12-10 17:36:55 Valid Error = 0.95759151830366 
2016-12-10 17:36:55 Valid Loss = 0.039615131146262 
2016-12-10 17:37:32 Test Error = 0.9547 
2016-12-10 17:37:32 Test Loss = 0.039649749875536 
2016-12-10 17:37:32 -------------------LR------------------- 
2016-12-10 17:37:32 0.015625 
2016-12-10 17:37:32 Epoch 4 
2016-12-10 17:50:49 Training Error = 0.93933333333333 
2016-12-10 17:50:49 Training Loss = 0.039219372748481 
2016-12-10 17:51:04 Valid Error = 0.94678935787157 
2016-12-10 17:51:04 Valid Loss = 0.039351520006926 
2016-12-10 17:51:38 Test Error = 0.9468 
2016-12-10 17:51:38 Test Loss = 0.039408686708937 
2016-12-10 17:51:38 -------------------LR------------------- 
2016-12-10 17:51:38 0.015625 
2016-12-10 17:51:38 Epoch 5 
2016-12-10 18:04:48 Training Error = 0.9272 
2016-12-10 18:04:48 Training Loss = 0.038963972927517 
2016-12-10 18:05:02 Valid Error = 0.93238647729546 
2016-12-10 18:05:02 Valid Loss = 0.039301076819164 
2016-12-10 18:05:37 Test Error = 0.9351 
2016-12-10 18:05:37 Test Loss = 0.039384685591155 
2016-12-10 18:05:37 -------------------LR------------------- 
2016-12-10 18:05:37 0.015625 
2016-12-10 18:05:37 Epoch 6 
2016-12-10 18:18:51 Training Error = 0.91184444444444 
2016-12-10 18:18:51 Training Loss = 0.038686661593967 
2016-12-10 18:19:05 Valid Error = 0.91538307661532 
2016-12-10 18:19:05 Valid Loss = 0.038906471350318 
2016-12-10 18:19:35 Test Error = 0.9229 
2016-12-10 18:19:35 Test Loss = 0.039032464061064 
2016-12-10 18:19:35 -------------------LR------------------- 
2016-12-10 18:19:35 0.015625 
2016-12-10 18:19:36 Epoch 7 
2016-12-10 18:32:59 Training Error = 0.89635555555556 
2016-12-10 18:32:59 Training Loss = 0.038427251003689 
2016-12-10 18:33:10 Valid Error = 0.90778155631126 
2016-12-10 18:33:10 Valid Loss = 0.038795354089785 
2016-12-10 18:33:50 Test Error = 0.9089 
2016-12-10 18:33:50 Test Loss = 0.038917553920372 
2016-12-10 18:33:50 -------------------LR------------------- 
2016-12-10 18:33:50 0.015625 
2016-12-10 18:33:50 Epoch 8 
2016-12-10 18:47:25 Training Error = 0.87993333333333 
2016-12-10 18:47:25 Training Loss = 0.038154817626953 
2016-12-10 18:47:37 Valid Error = 0.89837967593519 
2016-12-10 18:47:37 Valid Loss = 0.039102555319297 
2016-12-10 18:48:16 Test Error = 0.9041 
2016-12-10 18:48:16 Test Loss = 0.039257963831284 
2016-12-10 18:48:16 -------------------LR------------------- 
2016-12-10 18:48:16 0.015625 
2016-12-10 18:48:16 Epoch 9 
2016-12-10 19:01:27 Training Error = 0.86144444444444 
2016-12-10 19:01:27 Training Loss = 0.037857208116319 
2016-12-10 19:01:40 Valid Error = 0.86997399479896 
2016-12-10 19:01:40 Valid Loss = 0.038424116457027 
2016-12-10 19:02:12 Test Error = 0.8788 
2016-12-10 19:02:12 Test Loss = 0.038677892079073 
2016-12-10 19:02:12 -------------------LR------------------- 
2016-12-10 19:02:12 0.015625 
2016-12-10 19:02:12 Epoch 10 
2016-12-10 19:15:37 Training Error = 0.84517777777778 
2016-12-10 19:15:37 Training Loss = 0.037557698377821 
2016-12-10 19:15:50 Valid Error = 0.85337067413483 
2016-12-10 19:15:50 Valid Loss = 0.038036925540646 
2016-12-10 19:16:21 Test Error = 0.8526 
2016-12-10 19:16:21 Test Loss = 0.038127013950722 
2016-12-10 19:16:21 -------------------LR------------------- 
2016-12-10 19:16:21 0.015625 
2016-12-10 19:16:21 Epoch 11 
2016-12-10 19:29:42 Training Error = 0.82295555555556 
2016-12-10 19:29:42 Training Loss = 0.037176885036892 
2016-12-10 19:29:55 Valid Error = 0.84256851370274 
2016-12-10 19:29:55 Valid Loss = 0.03791314106339 
2016-12-10 19:30:26 Test Error = 0.8409 
2016-12-10 19:30:26 Test Loss = 0.038077402541217 
2016-12-10 19:30:26 -------------------LR------------------- 
2016-12-10 19:30:26 0.015625 
2016-12-10 19:30:26 Epoch 12 
2016-12-10 19:44:01 Training Error = 0.80022222222222 
2016-12-10 19:44:01 Training Loss = 0.036754443088108 
2016-12-10 19:44:14 Valid Error = 0.81676335267053 
2016-12-10 19:44:14 Valid Loss = 0.037149952308504 
2016-12-10 19:44:45 Test Error = 0.8148 
2016-12-10 19:44:45 Test Loss = 0.037280586212757 
2016-12-10 19:44:45 -------------------LR------------------- 
2016-12-10 19:44:45 0.015625 
2016-12-10 19:44:45 Epoch 13 
2016-12-10 19:58:04 Training Error = 0.7778 
2016-12-10 19:58:04 Training Loss = 0.036344594590929 
2016-12-10 19:58:17 Valid Error = 0.77955591118224 
2016-12-10 19:58:17 Valid Loss = 0.03610381501901 
2016-12-10 19:58:49 Test Error = 0.7777 
2016-12-10 19:58:49 Test Loss = 0.036151149196251 
2016-12-10 19:58:49 -------------------LR------------------- 
2016-12-10 19:58:49 0.015625 
2016-12-10 19:58:49 Epoch 14 
2016-12-10 20:12:08 Training Error = 0.75715555555556 
2016-12-10 20:12:08 Training Loss = 0.035998305338542 
2016-12-10 20:12:21 Valid Error = 0.78015603120624 
2016-12-10 20:12:21 Valid Loss = 0.036344542819557 
2016-12-10 20:12:53 Test Error = 0.7711 
2016-12-10 20:12:53 Test Loss = 0.03630516907935 
2016-12-10 20:12:53 -------------------LR------------------- 
2016-12-10 20:12:53 0.015625 
2016-12-10 20:12:53 Epoch 15 
2016-12-10 20:26:10 Training Error = 0.73675555555556 
2016-12-10 20:26:10 Training Loss = 0.035626127278646 
2016-12-10 20:26:23 Valid Error = 0.74694938987798 
2016-12-10 20:26:23 Valid Loss = 0.03544758563589 
2016-12-10 20:26:55 Test Error = 0.7435 
2016-12-10 20:26:55 Test Loss = 0.03549688541188 
2016-12-10 20:26:55 -------------------LR------------------- 
2016-12-10 20:26:55 0.015625 
2016-12-10 20:26:55 Epoch 16 
2016-12-10 20:40:15 Training Error = 0.71635555555556 
2016-12-10 20:40:15 Training Loss = 0.035265305121528 
2016-12-10 20:40:28 Valid Error = 0.74414882976595 
2016-12-10 20:40:28 Valid Loss = 0.035476614775297 
2016-12-10 20:41:00 Test Error = 0.7359 
2016-12-10 20:41:00 Test Loss = 0.035300774458343 
2016-12-10 20:41:00 -------------------LR------------------- 
2016-12-10 20:41:00 0.015625 
2016-12-10 20:41:00 Epoch 17 
2016-12-10 20:54:11 Training Error = 0.70053333333333 
2016-12-10 20:54:11 Training Loss = 0.034961128255208 
2016-12-10 20:54:24 Valid Error = 0.74074814962993 
2016-12-10 20:54:24 Valid Loss = 0.035456657592641 
2016-12-10 20:54:56 Test Error = 0.7308 
2016-12-10 20:54:56 Test Loss = 0.035335381661209 
2016-12-10 20:54:56 -------------------LR------------------- 
2016-12-10 20:54:56 0.015625 
2016-12-10 20:54:56 Epoch 18 
2016-12-10 21:08:21 Training Error = 0.68331111111111 
2016-12-10 21:08:21 Training Loss = 0.034612004611545 
2016-12-10 21:08:35 Valid Error = 0.70494098819764 
2016-12-10 21:08:35 Valid Loss = 0.034698343820146 
2016-12-10 21:09:07 Test Error = 0.7019 
2016-12-10 21:09:07 Test Loss = 0.03444165057014 
2016-12-10 21:09:07 -------------------LR------------------- 
2016-12-10 21:09:07 0.015625 
2016-12-10 21:09:07 Epoch 19 
2016-12-10 21:22:14 Training Error = 0.66644444444444 
2016-12-10 21:22:14 Training Loss = 0.034284095879449 
2016-12-10 21:22:28 Valid Error = 0.69753950790158 
2016-12-10 21:22:28 Valid Loss = 0.034178848666226 
2016-12-10 21:23:01 Test Error = 0.6883 
2016-12-10 21:23:01 Test Loss = 0.034058637521781 
2016-12-10 21:23:01 -------------------LR------------------- 
2016-12-10 21:23:01 0.015625 
2016-12-10 21:23:01 Epoch 20 
2016-12-10 21:36:22 Training Error = 0.65448888888889 
2016-12-10 21:36:22 Training Loss = 0.034026730156793 
2016-12-10 21:36:36 Valid Error = 0.68173634726945 
2016-12-10 21:36:36 Valid Loss = 0.033577273052899 
2016-12-10 21:37:09 Test Error = 0.6762 
2016-12-10 21:37:09 Test Loss = 0.033455948683795 
2016-12-10 21:37:09 -------------------LR------------------- 
2016-12-10 21:37:09 0.015625 
2016-12-10 21:37:09 Epoch 21 
2016-12-10 21:50:28 Training Error = 0.63764444444444 
2016-12-10 21:50:28 Training Loss = 0.033740703396267 
2016-12-10 21:50:42 Valid Error = 0.66893378675735 
2016-12-10 21:50:42 Valid Loss = 0.033664804820768 
2016-12-10 21:51:16 Test Error = 0.6712 
2016-12-10 21:51:16 Test Loss = 0.033682965057971 
2016-12-10 21:51:16 -------------------LR------------------- 
2016-12-10 21:51:16 0.015625 
2016-12-10 21:51:16 Epoch 22 
2016-12-10 22:04:35 Training Error = 0.62542222222222 
2016-12-10 22:04:35 Training Loss = 0.033496010091146 
2016-12-10 22:04:48 Valid Error = 0.66473294658932 
2016-12-10 22:04:48 Valid Loss = 0.033393167504861 
2016-12-10 22:05:21 Test Error = 0.6599 
2016-12-10 22:05:21 Test Loss = 0.033207990668802 
2016-12-10 22:05:21 -------------------LR------------------- 
2016-12-10 22:05:21 0.015625 
2016-12-10 22:05:21 Epoch 23 
2016-12-10 22:18:30 Training Error = 0.61933333333333 
2016-12-10 22:18:30 Training Loss = 0.033285530721029 
2016-12-10 22:18:44 Valid Error = 0.64812962592518 
2016-12-10 22:18:44 Valid Loss = 0.032547029776352 
2016-12-10 22:19:17 Test Error = 0.641 
2016-12-10 22:19:17 Test Loss = 0.032342639818379 
2016-12-10 22:19:17 -------------------LR------------------- 
2016-12-10 22:19:17 0.015625 
2016-12-10 22:19:17 Epoch 24 
2016-12-10 22:32:52 Training Error = 0.60695555555556 
2016-12-10 22:32:52 Training Loss = 0.033015788085937 
2016-12-10 22:33:05 Valid Error = 0.64012802560512 
2016-12-10 22:33:05 Valid Loss = 0.032587078310758 
2016-12-10 22:33:39 Test Error = 0.6489 
2016-12-10 22:33:39 Test Loss = 0.032562477829877 
2016-12-10 22:33:39 -------------------LR------------------- 
2016-12-10 22:33:39 0.015625 
2016-12-10 22:33:39 Epoch 25 
2016-12-10 22:46:55 Training Error = 0.59762222222222 
2016-12-10 22:46:55 Training Loss = 0.03285561960178 
2016-12-10 22:47:08 Valid Error = 0.6375275055011 
2016-12-10 22:47:08 Valid Loss = 0.032545859145028 
2016-12-10 22:47:41 Test Error = 0.6403 
2016-12-10 22:47:41 Test Loss = 0.032357325535195 
2016-12-10 22:47:41 -------------------LR------------------- 
2016-12-10 22:47:41 0.015625 
2016-12-10 22:47:41 Epoch 26 
2016-12-10 23:00:58 Training Error = 0.58755555555556 
2016-12-10 23:00:58 Training Loss = 0.032667001193576 
2016-12-10 23:01:12 Valid Error = 0.64792958591718 
2016-12-10 23:01:12 Valid Loss = 0.033015961790296 
2016-12-10 23:01:44 Test Error = 0.6482 
2016-12-10 23:01:44 Test Loss = 0.032932717117609 
2016-12-10 23:01:44 -------------------LR------------------- 
2016-12-10 23:01:44 0.015625 
2016-12-10 23:01:44 Epoch 27 
2016-12-10 23:15:02 Training Error = 0.57991111111111 
2016-12-10 23:15:02 Training Loss = 0.032478369357639 
2016-12-10 23:15:16 Valid Error = 0.61592318463693 
2016-12-10 23:15:16 Valid Loss = 0.031445554095539 
2016-12-10 23:15:48 Test Error = 0.6099 
2016-12-10 23:15:48 Test Loss = 0.031237571806066 
2016-12-10 23:15:48 -------------------LR------------------- 
2016-12-10 23:15:48 0.015625 
2016-12-10 23:15:48 Epoch 28 
2016-12-10 23:29:16 Training Error = 0.57397777777778 
2016-12-10 23:29:16 Training Loss = 0.032321487535265 
2016-12-10 23:29:30 Valid Error = 0.62372474494899 
2016-12-10 23:29:30 Valid Loss = 0.032042786135868 
2016-12-10 23:30:03 Test Error = 0.6234 
2016-12-10 23:30:03 Test Loss = 0.032005821198108 
2016-12-10 23:30:03 -------------------LR------------------- 
2016-12-10 23:30:03 0.015625 
2016-12-10 23:30:03 Epoch 29 
2016-12-10 23:43:20 Training Error = 0.56491111111111 
2016-12-10 23:43:20 Training Loss = 0.032089512315538 
2016-12-10 23:43:34 Valid Error = 0.60352070414083 
2016-12-10 23:43:34 Valid Loss = 0.031280964713417 
2016-12-10 23:44:06 Test Error = 0.608 
2016-12-10 23:44:06 Test Loss = 0.031347330878763 
2016-12-10 23:44:06 -------------------LR------------------- 
2016-12-10 23:44:06 0.015625 
2016-12-10 23:44:06 Epoch 30 
2016-12-10 23:57:32 Training Error = 0.55622222222222 
2016-12-10 23:57:32 Training Loss = 0.031968240953234 
2016-12-10 23:57:45 Valid Error = 0.60752150430086 
2016-12-10 23:57:45 Valid Loss = 0.031356477632446 
2016-12-10 23:58:17 Test Error = 0.6088 
2016-12-10 23:58:17 Test Loss = 0.03125773453058 
2016-12-10 23:58:17 -------------------LR------------------- 
2016-12-10 23:58:17 0.015625 
2016-12-10 23:58:18 Epoch 31 
2016-12-11 00:12:03 Training Error = 0.5512 
2016-12-11 00:12:03 Training Loss = 0.031805613674588 
2016-12-11 00:12:17 Valid Error = 0.59771954390878 
2016-12-11 00:12:17 Valid Loss = 0.031025632219938 
2016-12-11 00:12:50 Test Error = 0.5952 
2016-12-11 00:12:50 Test Loss = 0.031115756614535 
2016-12-11 00:12:50 -------------------LR------------------- 
2016-12-11 00:12:50 0.015625 
2016-12-11 00:12:50 Epoch 32 
2016-12-11 00:27:42 Training Error = 0.54217777777778 
2016-12-11 00:27:42 Training Loss = 0.031662005913628 
2016-12-11 00:27:56 Valid Error = 0.6123224644929 
2016-12-11 00:27:56 Valid Loss = 0.032187829034159 
2016-12-11 00:28:29 Test Error = 0.6184 
2016-12-11 00:28:29 Test Loss = 0.03220333850337 
2016-12-11 00:28:29 -------------------LR------------------- 
2016-12-11 00:28:29 0.015625 
2016-12-11 00:28:29 Epoch 33 
2016-12-11 00:43:19 Training Error = 0.5382 
2016-12-11 00:43:19 Training Loss = 0.031572377509223 
2016-12-11 00:43:33 Valid Error = 0.59011802360472 
2016-12-11 00:43:33 Valid Loss = 0.030780116228522 
2016-12-11 00:44:06 Test Error = 0.5906 
2016-12-11 00:44:06 Test Loss = 0.030898388552198 
2016-12-11 00:44:06 -------------------LR------------------- 
2016-12-11 00:44:06 0.015625 
2016-12-11 00:44:06 Epoch 34 
2016-12-11 00:58:23 Training Error = 0.53291111111111 
2016-12-11 00:58:23 Training Loss = 0.031436577663845 
2016-12-11 00:58:37 Valid Error = 0.60272054410882 
2016-12-11 00:58:37 Valid Loss = 0.031619028192577 
2016-12-11 00:59:10 Test Error = 0.6065 
2016-12-11 00:59:10 Test Loss = 0.03180713261623 
2016-12-11 00:59:10 -------------------LR------------------- 
2016-12-11 00:59:10 0.015625 
2016-12-11 00:59:10 Epoch 35 
2016-12-11 01:13:35 Training Error = 0.52662222222222 
2016-12-11 01:13:35 Training Loss = 0.031295003445095 
2016-12-11 01:13:49 Valid Error = 0.59931986397279 
2016-12-11 01:13:49 Valid Loss = 0.031669928048277 
2016-12-11 01:14:22 Test Error = 0.5918 
2016-12-11 01:14:22 Test Loss = 0.031479133037492 
2016-12-11 01:14:22 -------------------LR------------------- 
2016-12-11 01:14:22 0.015625 
2016-12-11 01:14:22 Epoch 36 
2016-12-11 01:28:49 Training Error = 0.52393333333333 
2016-12-11 01:28:49 Training Loss = 0.031191040364583 
2016-12-11 01:29:02 Valid Error = 0.58231646329266 
2016-12-11 01:29:02 Valid Loss = 0.030759326961501 
2016-12-11 01:29:35 Test Error = 0.5912 
2016-12-11 01:29:35 Test Loss = 0.031089667884976 
2016-12-11 01:29:35 -------------------LR------------------- 
2016-12-11 01:29:35 0.015625 
2016-12-11 01:29:35 Epoch 37 
2016-12-11 01:44:00 Training Error = 0.51875555555556 
2016-12-11 01:44:00 Training Loss = 0.031126335828993 
2016-12-11 01:44:14 Valid Error = 0.58851770354071 
2016-12-11 01:44:14 Valid Loss = 0.030939906221879 
2016-12-11 01:44:47 Test Error = 0.5909 
2016-12-11 01:44:47 Test Loss = 0.031091477876551 
2016-12-11 01:44:47 -------------------LR------------------- 
2016-12-11 01:44:47 0.015625 
2016-12-11 01:44:47 Epoch 38 
2016-12-11 01:59:17 Training Error = 0.51291111111111 
2016-12-11 01:59:17 Training Loss = 0.031001231540256 
2016-12-11 01:59:31 Valid Error = 0.57991598319664 
2016-12-11 01:59:31 Valid Loss = 0.030708559760593 
2016-12-11 02:00:04 Test Error = 0.5807 
2016-12-11 02:00:04 Test Loss = 0.030721093480727 
2016-12-11 02:00:04 -------------------LR------------------- 
2016-12-11 02:00:04 0.015625 
2016-12-11 02:00:04 Epoch 39 
2016-12-11 02:14:38 Training Error = 0.50757777777778 
2016-12-11 02:14:38 Training Loss = 0.030906127726237 
2016-12-11 02:14:52 Valid Error = 0.58111622324465 
2016-12-11 02:14:52 Valid Loss = 0.030388996819701 
2016-12-11 02:15:25 Test Error = 0.5873 
2016-12-11 02:15:25 Test Loss = 0.030735186887255 
2016-12-11 02:15:25 -------------------LR------------------- 
2016-12-11 02:15:25 0.015625 
2016-12-11 02:15:25 Epoch 40 
2016-12-11 02:29:45 Training Error = 0.50604444444444 
2016-12-11 02:29:45 Training Loss = 0.030844010674371 
2016-12-11 02:29:58 Valid Error = 0.57171434286857 
2016-12-11 02:29:58 Valid Loss = 0.030483513716907 
2016-12-11 02:30:32 Test Error = 0.5721 
2016-12-11 02:30:32 Test Loss = 0.030263206063065 
2016-12-11 02:30:32 -------------------LR------------------- 
2016-12-11 02:30:32 0.015625 
2016-12-11 02:30:32 Epoch 41 
2016-12-11 02:45:03 Training Error = 0.50275555555556 
2016-12-11 02:45:03 Training Loss = 0.030751113050673 
2016-12-11 02:45:16 Valid Error = 0.58831766353271 
2016-12-11 02:45:16 Valid Loss = 0.03102408120951 
2016-12-11 02:45:50 Test Error = 0.5917 
2016-12-11 02:45:50 Test Loss = 0.031132813307818 
2016-12-11 02:45:50 -------------------LR------------------- 
2016-12-11 02:45:50 0.015625 
2016-12-11 02:45:50 Epoch 42 
2016-12-11 03:00:35 Training Error = 0.50257777777778 
2016-12-11 03:00:35 Training Loss = 0.030723106743707 
2016-12-11 03:00:49 Valid Error = 0.58071614322865 
2016-12-11 03:00:49 Valid Loss = 0.031003259039193 
2016-12-11 03:01:22 Test Error = 0.5826 
2016-12-11 03:01:22 Test Loss = 0.031029970625335 
2016-12-11 03:01:22 -------------------LR------------------- 
2016-12-11 03:01:22 0.015625 
2016-12-11 03:01:22 Epoch 43 
2016-12-11 03:15:43 Training Error = 0.49582222222222 
2016-12-11 03:15:43 Training Loss = 0.030633039320204 
2016-12-11 03:15:57 Valid Error = 0.56891378275655 
2016-12-11 03:15:57 Valid Loss = 0.030556626005189 
2016-12-11 03:16:31 Test Error = 0.5706 
2016-12-11 03:16:31 Test Loss = 0.030425774368585 
2016-12-11 03:16:31 -------------------LR------------------- 
2016-12-11 03:16:31 0.015625 
2016-12-11 03:16:31 Epoch 44 
2016-12-11 03:30:57 Training Error = 0.4964 
2016-12-11 03:30:57 Training Loss = 0.030601200737847 
2016-12-11 03:31:11 Valid Error = 0.56531306261252 
2016-12-11 03:31:11 Valid Loss = 0.029990954602473 
2016-12-11 03:31:44 Test Error = 0.5623 
2016-12-11 03:31:44 Test Loss = 0.030127640249215 
2016-12-11 03:31:44 -------------------LR------------------- 
2016-12-11 03:31:44 0.015625 
2016-12-11 03:31:45 Epoch 45 
2016-12-11 03:46:15 Training Error = 0.49157777777778 
2016-12-11 03:46:15 Training Loss = 0.030495542222765 
2016-12-11 03:46:29 Valid Error = 0.56891378275655 
2016-12-11 03:46:29 Valid Loss = 0.03014944252272 
2016-12-11 03:47:02 Test Error = 0.5534 
2016-12-11 03:47:02 Test Loss = 0.02977933104272 
2016-12-11 03:47:02 -------------------LR------------------- 
2016-12-11 03:47:02 0.015625 
2016-12-11 03:47:02 Epoch 46 
2016-12-11 04:01:18 Training Error = 0.49024444444444 
2016-12-11 04:01:18 Training Loss = 0.030460607055664 
2016-12-11 04:01:32 Valid Error = 0.58671734346869 
2016-12-11 04:01:32 Valid Loss = 0.031294717028651 
2016-12-11 04:02:05 Test Error = 0.5831 
2016-12-11 04:02:05 Test Loss = 0.030991195588953 
2016-12-11 04:02:05 -------------------LR------------------- 
2016-12-11 04:02:05 0.015625 
2016-12-11 04:02:06 Epoch 47 
2016-12-11 04:16:28 Training Error = 0.48722222222222 
2016-12-11 04:16:28 Training Loss = 0.030351445787218 
2016-12-11 04:16:42 Valid Error = 0.5495099019804 
2016-12-11 04:16:42 Valid Loss = 0.029412605801488 
2016-12-11 04:17:15 Test Error = 0.5514 
2016-12-11 04:17:15 Test Loss = 0.029358203214758 
2016-12-11 04:17:15 -------------------LR------------------- 
2016-12-11 04:17:15 0.015625 
2016-12-11 04:17:15 Epoch 48 
2016-12-11 04:31:42 Training Error = 0.48502222222222 
2016-12-11 04:31:42 Training Loss = 0.030338848225911 
2016-12-11 04:31:55 Valid Error = 0.55811162232446 
2016-12-11 04:31:55 Valid Loss = 0.029931304292964 
2016-12-11 04:32:29 Test Error = 0.5506 
2016-12-11 04:32:29 Test Loss = 0.029635104788986 
2016-12-11 04:32:29 -------------------LR------------------- 
2016-12-11 04:32:29 0.015625 
2016-12-11 04:32:29 Epoch 49 
2016-12-11 04:47:02 Training Error = 0.48146666666667 
2016-12-11 04:47:02 Training Loss = 0.030302312757704 
2016-12-11 04:47:16 Valid Error = 0.54450890178036 
2016-12-11 04:47:16 Valid Loss = 0.02921980852726 
2016-12-11 04:47:50 Test Error = 0.5428 
2016-12-11 04:47:50 Test Loss = 0.029150378118777 
2016-12-11 04:47:50 -------------------LR------------------- 
2016-12-11 04:47:50 0.015625 
2016-12-11 04:47:50 Epoch 50 
2016-12-11 05:02:17 Training Error = 0.48013333333333 
2016-12-11 05:02:17 Training Loss = 0.030240457329644 
2016-12-11 05:02:31 Valid Error = 0.56731346269254 
2016-12-11 05:02:31 Valid Loss = 0.030231066543319 
2016-12-11 05:03:05 Test Error = 0.5553 
2016-12-11 05:03:05 Test Loss = 0.029942365489287 
2016-12-11 05:03:05 -------------------LR------------------- 
2016-12-11 05:03:05 0.0078125 
2016-12-11 05:03:05 Epoch 51 
2016-12-11 05:17:21 Training Error = 0.44173333333333 
2016-12-11 05:17:21 Training Loss = 0.028912131808811 
2016-12-11 05:17:35 Valid Error = 0.5375075015003 
2016-12-11 05:17:35 Valid Loss = 0.029703702175837 
2016-12-11 05:18:09 Test Error = 0.5386 
2016-12-11 05:18:09 Test Loss = 0.029434275728114 
2016-12-11 05:18:09 -------------------LR------------------- 
2016-12-11 05:18:09 0.0078125 
2016-12-11 05:18:09 Epoch 52 
2016-12-11 05:32:38 Training Error = 0.41968888888889 
2016-12-11 05:32:38 Training Loss = 0.028390750488281 
2016-12-11 05:32:52 Valid Error = 0.52010402080416 
2016-12-11 05:32:52 Valid Loss = 0.028833119356669 
2016-12-11 05:33:26 Test Error = 0.5137 
2016-12-11 05:33:26 Test Loss = 0.028594446937711 
2016-12-11 05:33:26 -------------------LR------------------- 
2016-12-11 05:33:26 0.0078125 
2016-12-11 05:33:26 Epoch 53 
2016-12-11 05:47:46 Training Error = 0.41011111111111 
2016-12-11 05:47:46 Training Loss = 0.028238448079427 
2016-12-11 05:48:00 Valid Error = 0.51150230046009 
2016-12-11 05:48:00 Valid Loss = 0.028272396619351 
2016-12-11 05:48:33 Test Error = 0.5115 
2016-12-11 05:48:33 Test Loss = 0.028072992781097 
2016-12-11 05:48:33 -------------------LR------------------- 
2016-12-11 05:48:33 0.0078125 
2016-12-11 05:48:33 Epoch 54 
2016-12-11 06:02:54 Training Error = 0.40597777777778 
2016-12-11 06:02:54 Training Loss = 0.028127139092339 
2016-12-11 06:03:08 Valid Error = 0.51650330066013 
2016-12-11 06:03:08 Valid Loss = 0.029035549993211 
2016-12-11 06:03:41 Test Error = 0.5158 
2016-12-11 06:03:41 Test Loss = 0.029095681613099 
2016-12-11 06:03:41 -------------------LR------------------- 
2016-12-11 06:03:41 0.0078125 
2016-12-11 06:03:42 Epoch 55 
2016-12-11 06:17:54 Training Error = 0.40144444444444 
2016-12-11 06:17:54 Training Loss = 0.028046566474067 
2016-12-11 06:18:08 Valid Error = 0.52710542108422 
2016-12-11 06:18:08 Valid Loss = 0.029524937923235 
2016-12-11 06:18:42 Test Error = 0.52 
2016-12-11 06:18:42 Test Loss = 0.029103585665834 
2016-12-11 06:18:42 -------------------LR------------------- 
2016-12-11 06:18:42 0.0078125 
2016-12-11 06:18:42 Epoch 56 
2016-12-11 06:33:10 Training Error = 0.39733333333333 
2016-12-11 06:33:10 Training Loss = 0.027930861043294 
2016-12-11 06:33:24 Valid Error = 0.51830366073215 
2016-12-11 06:33:24 Valid Loss = 0.029118880261857 
2016-12-11 06:33:57 Test Error = 0.5157 
2016-12-11 06:33:57 Test Loss = 0.028849974957634 
2016-12-11 06:33:57 -------------------LR------------------- 
2016-12-11 06:33:57 0.0078125 
2016-12-11 06:33:57 Epoch 57 
2016-12-11 06:48:17 Training Error = 0.39757777777778 
2016-12-11 06:48:17 Training Loss = 0.027915973849826 
2016-12-11 06:48:31 Valid Error = 0.52570514102821 
2016-12-11 06:48:31 Valid Loss = 0.029246761924089 
2016-12-11 06:49:05 Test Error = 0.5208 
2016-12-11 06:49:05 Test Loss = 0.029218453919654 
2016-12-11 06:49:05 -------------------LR------------------- 
2016-12-11 06:49:05 0.0078125 
2016-12-11 06:49:05 Epoch 58 
2016-12-11 07:03:35 Training Error = 0.39384444444444 
2016-12-11 07:03:35 Training Loss = 0.027820273573134 
2016-12-11 07:03:49 Valid Error = 0.51650330066013 
2016-12-11 07:03:49 Valid Loss = 0.029393534659381 
2016-12-11 07:04:23 Test Error = 0.5128 
2016-12-11 07:04:23 Test Loss = 0.028932175490435 
2016-12-11 07:04:23 -------------------LR------------------- 
2016-12-11 07:04:23 0.0078125 
2016-12-11 07:04:23 Epoch 59 
2016-12-11 07:18:50 Training Error = 0.39175555555556 
2016-12-11 07:18:50 Training Loss = 0.027825919921875 
2016-12-11 07:19:03 Valid Error = 0.52290458091618 
2016-12-11 07:19:03 Valid Loss = 0.029248972900222 
2016-12-11 07:19:37 Test Error = 0.5196 
2016-12-11 07:19:37 Test Loss = 0.028928265799728 
2016-12-11 07:19:37 -------------------LR------------------- 
2016-12-11 07:19:37 0.0078125 
2016-12-11 07:19:37 Epoch 60 
2016-12-11 07:34:08 Training Error = 0.39064444444444 
2016-12-11 07:34:08 Training Loss = 0.02787466277398 
2016-12-11 07:34:22 Valid Error = 0.52110422084417 
2016-12-11 07:34:22 Valid Loss = 0.029904485925819 
2016-12-11 07:34:55 Test Error = 0.519 
2016-12-11 07:34:55 Test Loss = 0.029817817747827 
2016-12-11 07:34:55 -------------------LR------------------- 
2016-12-11 07:34:55 0.0078125 
2016-12-11 07:34:55 Epoch 61 
2016-12-11 07:49:23 Training Error = 0.39 
2016-12-11 07:49:23 Training Loss = 0.027787535590278 
2016-12-11 07:49:37 Valid Error = 0.52630526105221 
2016-12-11 07:49:37 Valid Loss = 0.030495020734633 
2016-12-11 07:50:11 Test Error = 0.5335 
2016-12-11 07:50:11 Test Loss = 0.030221080196605 
2016-12-11 07:50:11 -------------------LR------------------- 
2016-12-11 07:50:11 0.0078125 
2016-12-11 07:50:11 Epoch 62 
2016-12-11 08:04:25 Training Error = 0.38633333333333 
2016-12-11 08:04:25 Training Loss = 0.027658064290365 
2016-12-11 08:04:38 Valid Error = 0.53330666133227 
2016-12-11 08:04:38 Valid Loss = 0.030191149403791 
2016-12-11 08:05:12 Test Error = 0.5367 
2016-12-11 08:05:12 Test Loss = 0.030252220692354 
2016-12-11 08:05:12 -------------------LR------------------- 
2016-12-11 08:05:12 0.0078125 
2016-12-11 08:05:12 Epoch 63 
2016-12-11 08:19:37 Training Error = 0.38495555555556 
2016-12-11 08:19:37 Training Loss = 0.027696491780599 
2016-12-11 08:19:51 Valid Error = 0.53430686137227 
2016-12-11 08:19:51 Valid Loss = 0.029725026507504 
2016-12-11 08:20:25 Test Error = 0.525 
2016-12-11 08:20:25 Test Loss = 0.029330784068388 
2016-12-11 08:20:25 -------------------LR------------------- 
2016-12-11 08:20:25 0.0078125 
2016-12-11 08:20:25 Epoch 64 
2016-12-11 08:34:44 Training Error = 0.38384444444444 
2016-12-11 08:34:44 Training Loss = 0.027678605875651 
2016-12-11 08:34:58 Valid Error = 0.51530306061212 
2016-12-11 08:34:58 Valid Loss = 0.029247742468398 
2016-12-11 08:35:31 Test Error = 0.52 
2016-12-11 08:35:31 Test Loss = 0.029171771928376 
2016-12-11 08:35:31 -------------------LR------------------- 
2016-12-11 08:35:31 0.0078125 
2016-12-11 08:35:31 Epoch 65 
2016-12-11 08:50:00 Training Error = 0.38395555555556 
2016-12-11 08:50:00 Training Loss = 0.027606540201823 
2016-12-11 08:50:13 Valid Error = 0.53110622124425 
2016-12-11 08:50:13 Valid Loss = 0.030034653439749 
2016-12-11 08:50:47 Test Error = 0.5307 
2016-12-11 08:50:47 Test Loss = 0.029899161724016 
2016-12-11 08:50:47 -------------------LR------------------- 
2016-12-11 08:50:47 0.0078125 
2016-12-11 08:50:47 Epoch 66 
2016-12-11 09:05:06 Training Error = 0.38186666666667 
2016-12-11 09:05:06 Training Loss = 0.02760833481174 
2016-12-11 09:05:20 Valid Error = 0.51050210042008 
2016-12-11 09:05:20 Valid Loss = 0.029100233972309 
2016-12-11 09:05:53 Test Error = 0.516 
2016-12-11 09:05:53 Test Loss = 0.02927438845167 
2016-12-11 09:05:53 -------------------LR------------------- 
2016-12-11 09:05:53 0.0078125 
2016-12-11 09:05:53 Epoch 67 
2016-12-11 09:20:07 Training Error = 0.3804 
2016-12-11 09:20:07 Training Loss = 0.027517189900716 
2016-12-11 09:20:20 Valid Error = 0.50830166033207 
2016-12-11 09:20:20 Valid Loss = 0.028797850664623 
2016-12-11 09:20:54 Test Error = 0.5107 
2016-12-11 09:20:54 Test Loss = 0.028879794730392 
2016-12-11 09:20:54 -------------------LR------------------- 
2016-12-11 09:20:54 0.0078125 
2016-12-11 09:20:54 Epoch 68 
2016-12-11 09:35:15 Training Error = 0.37815555555556 
2016-12-11 09:35:15 Training Loss = 0.027491799804688 
2016-12-11 09:35:29 Valid Error = 0.51690338067614 
2016-12-11 09:35:29 Valid Loss = 0.02979433941835 
2016-12-11 09:36:03 Test Error = 0.5193 
2016-12-11 09:36:03 Test Loss = 0.029925392689424 
2016-12-11 09:36:03 -------------------LR------------------- 
2016-12-11 09:36:03 0.0078125 
2016-12-11 09:36:03 Epoch 69 
2016-12-11 09:50:33 Training Error = 0.38057777777778 
2016-12-11 09:50:33 Training Loss = 0.027535129163954 
2016-12-11 09:50:46 Valid Error = 0.51970394078816 
2016-12-11 09:50:46 Valid Loss = 0.029153783983634 
2016-12-11 09:51:20 Test Error = 0.5134 
2016-12-11 09:51:20 Test Loss = 0.029004095788096 
2016-12-11 09:51:20 -------------------LR------------------- 
2016-12-11 09:51:20 0.0078125 
2016-12-11 09:51:20 Epoch 70 
2016-12-11 10:05:52 Training Error = 0.37704444444444 
2016-12-11 10:05:52 Training Loss = 0.027490106811523 
2016-12-11 10:06:05 Valid Error = 0.48869773954791 
2016-12-11 10:06:05 Valid Loss = 0.02773704739145 
2016-12-11 10:06:39 Test Error = 0.4879 
2016-12-11 10:06:39 Test Loss = 0.027748074550255 
2016-12-11 10:06:39 -------------------LR------------------- 
2016-12-11 10:06:39 0.0078125 
2016-12-11 10:06:39 Epoch 71 
2016-12-11 10:21:16 Training Error = 0.37604444444444 
2016-12-11 10:21:16 Training Loss = 0.027446893269857 
2016-12-11 10:21:29 Valid Error = 0.52230446089218 
2016-12-11 10:21:29 Valid Loss = 0.029409027230713 
2016-12-11 10:22:03 Test Error = 0.5188 
2016-12-11 10:22:03 Test Loss = 0.029672910622989 
2016-12-11 10:22:03 -------------------LR------------------- 
2016-12-11 10:22:03 0.0078125 
2016-12-11 10:22:03 Epoch 72 
2016-12-11 10:36:19 Training Error = 0.37608888888889 
2016-12-11 10:36:19 Training Loss = 0.027420668877496 
2016-12-11 10:36:32 Valid Error = 0.50130026005201 
2016-12-11 10:36:32 Valid Loss = 0.028823271481849 
2016-12-11 10:37:06 Test Error = 0.5111 
2016-12-11 10:37:06 Test Loss = 0.029000017682244 
2016-12-11 10:37:06 -------------------LR------------------- 
2016-12-11 10:37:06 0.0078125 
2016-12-11 10:37:06 Epoch 73 
2016-12-11 10:51:26 Training Error = 0.37302222222222 
2016-12-11 10:51:26 Training Loss = 0.027332170613607 
2016-12-11 10:51:40 Valid Error = 0.51090218043609 
2016-12-11 10:51:40 Valid Loss = 0.02916977711361 
2016-12-11 10:52:13 Test Error = 0.5127 
2016-12-11 10:52:13 Test Loss = 0.029441898809695 
2016-12-11 10:52:13 -------------------LR------------------- 
2016-12-11 10:52:13 0.0078125 
2016-12-11 10:52:13 Epoch 74 
2016-12-11 11:06:24 Training Error = 0.37008888888889 
2016-12-11 11:06:24 Training Loss = 0.027342104654948 
2016-12-11 11:06:37 Valid Error = 0.5125025005001 
2016-12-11 11:06:37 Valid Loss = 0.02884017930083 
2016-12-11 11:07:11 Test Error = 0.5118 
2016-12-11 11:07:11 Test Loss = 0.028938328163297 
2016-12-11 11:07:11 -------------------LR------------------- 
2016-12-11 11:07:11 0.0078125 
2016-12-11 11:07:11 Epoch 75 
