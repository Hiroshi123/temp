2016-12-07 12:10:02 [program started on Wed Dec  7 12:10:02 2016] 
2016-12-07 12:10:02 [command line arguments] 
2016-12-07 12:10:02 stcWeights false 
2016-12-07 12:10:02 LR 0.015625 
2016-12-07 12:10:02 batchSize 300 
2016-12-07 12:10:02 network ./Models/Cifar10_Custom 
2016-12-07 12:10:02 stcNeurons true 
2016-12-07 12:10:02 constBatchSize false 
2016-12-07 12:10:02 chartFileName chart1 
2016-12-07 12:10:02 dp_prepro false 
2016-12-07 12:10:02 nGPU 1 
2016-12-07 12:10:02 dataset Cifar100 
2016-12-07 12:10:02 type cuda 
2016-12-07 12:10:02 momentum 0 
2016-12-07 12:10:02 threads 8 
2016-12-07 12:10:02 weightDecay 0 
2016-12-07 12:10:02 runningVal false 
2016-12-07 12:10:02 convLayerN 7 
2016-12-07 12:10:02 LRDecay 0 
2016-12-07 12:10:02 numHid 1024 
2016-12-07 12:10:02 save /dev/shm/temp/th/Results/Cifar100/Ex2 
2016-12-07 12:10:02 augment false 
2016-12-07 12:10:02 epoch -1 
2016-12-07 12:10:02 modelsFolder ./Models/ 
2016-12-07 12:10:02 format rgb 
2016-12-07 12:10:02 preProcDir /dev/shm/temp/th/PreProcData/Cifar100 
2016-12-07 12:10:02 imageFileExtension svg 
2016-12-07 12:10:02 channel 1 
2016-12-07 12:10:02 devid 5 
2016-12-07 12:10:02 visualize 1 
2016-12-07 12:10:02 LRDecayPerEpoch 0.0001 
2016-12-07 12:10:02 optimization adam 
2016-12-07 12:10:02 SBN true 
2016-12-07 12:10:02 normalization simple 
2016-12-07 12:10:02 title model1 
2016-12-07 12:10:02 load  
2016-12-07 12:10:02 whiten true 
2016-12-07 12:10:02 [----------------------] 
2016-12-07 12:10:04 ==> Network 
2016-12-07 12:10:04 nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> output]
  (1): cudnnBinarySpatialConvolution(3 -> 128, 3x3, 1,1, 1,1)
  (2): SpatialBatchNormalizationShiftPow2
  (3): nn.HardTanh
  (4): BinarizedNeurons
  (5): cudnnBinarySpatialConvolution(128 -> 128, 3x3, 1,1, 1,1)
  (6): cudnn.SpatialMaxPooling(2x2, 2,2)
  (7): SpatialBatchNormalizationShiftPow2
  (8): nn.HardTanh
  (9): BinarizedNeurons
  (10): cudnnBinarySpatialConvolution(128 -> 256, 3x3, 1,1, 1,1)
  (11): SpatialBatchNormalizationShiftPow2
  (12): nn.HardTanh
  (13): BinarizedNeurons
  (14): cudnnBinarySpatialConvolution(256 -> 256, 3x3, 1,1, 1,1)
  (15): cudnn.SpatialMaxPooling(2x2, 2,2)
  (16): SpatialBatchNormalizationShiftPow2
  (17): nn.HardTanh
  (18): BinarizedNeurons
  (19): cudnnBinarySpatialConvolution(256 -> 512, 3x3, 1,1, 1,1)
  (20): SpatialBatchNormalizationShiftPow2
  (21): nn.HardTanh
  (22): BinarizedNeurons
  (23): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (24): cudnn.SpatialMaxPooling(2x2, 2,2)
  (25): SpatialBatchNormalizationShiftPow2
  (26): nn.HardTanh
  (27): BinarizedNeurons
  (28): cudnnBinarySpatialConvolution(512 -> 512, 3x3, 1,1, 1,1)
  (29): SpatialBatchNormalizationShiftPow2
  (30): nn.HardTanh
  (31): BinarizedNeurons
  (32): nn.View(8192)
  (33): BinaryLinear(8192 -> 1024)
  (34): BatchNormalizationShiftPow2
  (35): nn.HardTanh
  (36): BinarizedNeurons
  (37): BinaryLinear(1024 -> 1024)
  (38): BatchNormalizationShiftPow2
  (39): nn.HardTanh
  (40): BinarizedNeurons
  (41): BinaryLinear(1024 -> 100)
  (42): nn.BatchNormalization
} 
2016-12-07 12:10:04 ==>16486828 Parameters 
2016-12-07 12:10:04 ==> Loss 
2016-12-07 12:10:04 SqrtHingeEmbeddingCriterion 
2016-12-07 12:10:04 
==> Starting Training
 
2016-12-07 12:10:04 Epoch 1 
2016-12-07 12:17:16 Training Error = 0.93662222222222 
2016-12-07 12:17:16 Training Loss = 0.22771113441298 
2016-12-07 12:17:27 Valid Error = 0.93098619723945 
2016-12-07 12:17:27 Valid Loss = 0.040897469086346 
2016-12-07 12:17:51 Test Error = 0.9261 
2016-12-07 12:17:51 Test Loss = 0.040857561328364 
2016-12-07 12:17:51 -------------------LR------------------- 
2016-12-07 12:17:51 0.015625 
2016-12-07 12:17:51 Epoch 2 
2016-12-07 12:24:57 Training Error = 0.89926666666667 
2016-12-07 12:24:57 Training Loss = 0.038837233072917 
2016-12-07 12:25:09 Valid Error = 0.89517903580716 
2016-12-07 12:25:09 Valid Loss = 0.039245999857254 
2016-12-07 12:25:32 Test Error = 0.8994 
2016-12-07 12:25:32 Test Loss = 0.039337553675034 
2016-12-07 12:25:32 -------------------LR------------------- 
2016-12-07 12:25:32 0.015625 
2016-12-07 12:25:32 Epoch 3 
2016-12-07 12:32:48 Training Error = 0.86466666666667 
2016-12-07 12:32:48 Training Loss = 0.038200797281901 
2016-12-07 12:33:00 Valid Error = 0.87097419483897 
2016-12-07 12:33:00 Valid Loss = 0.038723465550072 
2016-12-07 12:33:23 Test Error = 0.8741 
2016-12-07 12:33:23 Test Loss = 0.038807867222206 
2016-12-07 12:33:23 -------------------LR------------------- 
2016-12-07 12:33:23 0.015625 
2016-12-07 12:33:23 Epoch 4 
2016-12-07 12:40:30 Training Error = 0.84233333333333 
2016-12-07 12:40:30 Training Loss = 0.037826122233073 
2016-12-07 12:40:42 Valid Error = 0.85197039407882 
2016-12-07 12:40:42 Valid Loss = 0.038391182857359 
2016-12-07 12:41:05 Test Error = 0.8581 
2016-12-07 12:41:05 Test Loss = 0.038500953195609 
2016-12-07 12:41:05 -------------------LR------------------- 
2016-12-07 12:41:05 0.015625 
2016-12-07 12:41:05 Epoch 5 
2016-12-07 12:48:18 Training Error = 0.82004444444444 
2016-12-07 12:48:18 Training Loss = 0.037503624674479 
2016-12-07 12:48:29 Valid Error = 0.82236447289458 
2016-12-07 12:48:29 Valid Loss = 0.037804012716626 
2016-12-07 12:48:52 Test Error = 0.8295 
2016-12-07 12:48:52 Test Loss = 0.037936828403847 
2016-12-07 12:48:52 -------------------LR------------------- 
2016-12-07 12:48:52 0.015625 
2016-12-07 12:48:53 Epoch 6 
2016-12-07 12:56:06 Training Error = 0.80537777777778 
2016-12-07 12:56:06 Training Loss = 0.037151094021267 
2016-12-07 12:56:18 Valid Error = 0.80496099219844 
2016-12-07 12:56:18 Valid Loss = 0.037412246085571 
2016-12-07 12:56:41 Test Error = 0.8166 
2016-12-07 12:56:41 Test Loss = 0.037595213317871 
2016-12-07 12:56:41 -------------------LR------------------- 
2016-12-07 12:56:41 0.015625 
2016-12-07 12:56:41 Epoch 7 
2016-12-07 13:03:49 Training Error = 0.78668888888889 
2016-12-07 13:03:49 Training Loss = 0.036774354329427 
2016-12-07 13:04:01 Valid Error = 0.77715543108622 
2016-12-07 13:04:01 Valid Loss = 0.03659727778392 
2016-12-07 13:04:24 Test Error = 0.7846 
2016-12-07 13:04:24 Test Loss = 0.036715879223393 
2016-12-07 13:04:24 -------------------LR------------------- 
2016-12-07 13:04:24 0.015625 
2016-12-07 13:04:24 Epoch 8 
2016-12-07 13:11:36 Training Error = 0.76702222222222 
2016-12-07 13:11:36 Training Loss = 0.036394269639757 
2016-12-07 13:11:48 Valid Error = 0.75955191038208 
2016-12-07 13:11:48 Valid Loss = 0.036176271115313 
2016-12-07 13:12:11 Test Error = 0.7627 
2016-12-07 13:12:11 Test Loss = 0.03630278709262 
2016-12-07 13:12:11 -------------------LR------------------- 
2016-12-07 13:12:11 0.015625 
2016-12-07 13:12:11 Epoch 9 
2016-12-07 13:19:16 Training Error = 0.75135555555556 
2016-12-07 13:19:16 Training Loss = 0.036028729871962 
2016-12-07 13:19:27 Valid Error = 0.749949989998 
2016-12-07 13:19:27 Valid Loss = 0.03596353317142 
2016-12-07 13:19:50 Test Error = 0.7543 
2016-12-07 13:19:50 Test Loss = 0.036098588083305 
2016-12-07 13:19:50 -------------------LR------------------- 
2016-12-07 13:19:50 0.015625 
2016-12-07 13:19:50 Epoch 10 
2016-12-07 13:27:16 Training Error = 0.73297777777778 
2016-12-07 13:27:16 Training Loss = 0.035692970513238 
2016-12-07 13:27:27 Valid Error = 0.73614722944589 
2016-12-07 13:27:27 Valid Loss = 0.035385307284498 
2016-12-07 13:27:50 Test Error = 0.7327 
2016-12-07 13:27:50 Test Loss = 0.035452343181535 
2016-12-07 13:27:50 -------------------LR------------------- 
2016-12-07 13:27:50 0.015625 
2016-12-07 13:27:50 Epoch 11 
2016-12-07 13:35:00 Training Error = 0.72022222222222 
2016-12-07 13:35:00 Training Loss = 0.035392640380859 
2016-12-07 13:35:12 Valid Error = 0.72174434886977 
2016-12-07 13:35:12 Valid Loss = 0.034975495820887 
2016-12-07 13:35:35 Test Error = 0.7196 
2016-12-07 13:35:35 Test Loss = 0.03498806735768 
2016-12-07 13:35:35 -------------------LR------------------- 
2016-12-07 13:35:35 0.015625 
2016-12-07 13:35:35 Epoch 12 
2016-12-07 13:42:48 Training Error = 0.70937777777778 
2016-12-07 13:42:48 Training Loss = 0.035111106187608 
2016-12-07 13:42:59 Valid Error = 0.70714142828566 
2016-12-07 13:42:59 Valid Loss = 0.034652752098589 
2016-12-07 13:43:22 Test Error = 0.7113 
2016-12-07 13:43:22 Test Loss = 0.034657607553519 
2016-12-07 13:43:22 -------------------LR------------------- 
2016-12-07 13:43:22 0.015625 
2016-12-07 13:43:22 Epoch 13 
2016-12-07 13:50:32 Training Error = 0.69673333333333 
2016-12-07 13:50:32 Training Loss = 0.034805556315104 
2016-12-07 13:50:44 Valid Error = 0.69753950790158 
2016-12-07 13:50:44 Valid Loss = 0.034194730621888 
2016-12-07 13:51:07 Test Error = 0.698 
2016-12-07 13:51:07 Test Loss = 0.034206348434149 
2016-12-07 13:51:07 -------------------LR------------------- 
2016-12-07 13:51:07 0.015625 
2016-12-07 13:51:07 Epoch 14 
2016-12-07 13:58:15 Training Error = 0.68617777777778 
2016-12-07 13:58:15 Training Loss = 0.034531830566406 
2016-12-07 13:58:26 Valid Error = 0.68353670734147 
2016-12-07 13:58:26 Valid Loss = 0.033967256348426 
2016-12-07 13:58:49 Test Error = 0.682 
2016-12-07 13:58:49 Test Loss = 0.033885365983552 
2016-12-07 13:58:49 -------------------LR------------------- 
2016-12-07 13:58:49 0.015625 
2016-12-07 13:58:49 Epoch 15 
2016-12-07 14:05:58 Training Error = 0.67635555555556 
2016-12-07 14:05:58 Training Loss = 0.034294249308268 
2016-12-07 14:06:10 Valid Error = 0.67653530706141 
2016-12-07 14:06:10 Valid Loss = 0.033608145769754 
2016-12-07 14:06:33 Test Error = 0.681 
2016-12-07 14:06:33 Test Loss = 0.033561766590792 
2016-12-07 14:06:33 -------------------LR------------------- 
2016-12-07 14:06:33 0.015625 
2016-12-07 14:06:33 Epoch 16 
2016-12-07 14:13:41 Training Error = 0.66644444444444 
2016-12-07 14:13:41 Training Loss = 0.034049356268989 
2016-12-07 14:13:52 Valid Error = 0.67313462692539 
2016-12-07 14:13:52 Valid Loss = 0.033851241561765 
2016-12-07 14:14:15 Test Error = 0.6773 
2016-12-07 14:14:15 Test Loss = 0.03378504411286 
2016-12-07 14:14:15 -------------------LR------------------- 
2016-12-07 14:14:15 0.015625 
2016-12-07 14:14:15 Epoch 17 
2016-12-07 14:21:36 Training Error = 0.65604444444444 
2016-12-07 14:21:36 Training Loss = 0.033824364257813 
2016-12-07 14:21:48 Valid Error = 0.66413282656531 
2016-12-07 14:21:48 Valid Loss = 0.032930169780572 
2016-12-07 14:22:11 Test Error = 0.6588 
2016-12-07 14:22:11 Test Loss = 0.032910435455921 
2016-12-07 14:22:11 -------------------LR------------------- 
2016-12-07 14:22:11 0.015625 
2016-12-07 14:22:11 Epoch 18 
2016-12-07 14:29:21 Training Error = 0.6488 
2016-12-07 14:29:21 Training Loss = 0.03356382409668 
2016-12-07 14:29:33 Valid Error = 0.65253050610122 
2016-12-07 14:29:33 Valid Loss = 0.033098126989882 
2016-12-07 14:29:56 Test Error = 0.658 
2016-12-07 14:29:56 Test Loss = 0.033003325638117 
2016-12-07 14:29:56 -------------------LR------------------- 
2016-12-07 14:29:56 0.015625 
2016-12-07 14:29:56 Epoch 19 
2016-12-07 14:37:12 Training Error = 0.64242222222222 
2016-12-07 14:37:12 Training Loss = 0.033392386461046 
2016-12-07 14:37:23 Valid Error = 0.64672934586917 
2016-12-07 14:37:23 Valid Loss = 0.032693951292731 
2016-12-07 14:37:46 Test Error = 0.6496 
2016-12-07 14:37:46 Test Loss = 0.032581881294998 
2016-12-07 14:37:46 -------------------LR------------------- 
2016-12-07 14:37:46 0.015625 
2016-12-07 14:37:46 Epoch 20 
2016-12-07 14:45:03 Training Error = 0.63482222222222 
2016-12-07 14:45:03 Training Loss = 0.033186632921007 
2016-12-07 14:45:15 Valid Error = 0.64192838567714 
2016-12-07 14:45:15 Valid Loss = 0.032319665047434 
2016-12-07 14:45:38 Test Error = 0.6376 
2016-12-07 14:45:38 Test Loss = 0.032289066688687 
2016-12-07 14:45:38 -------------------LR------------------- 
2016-12-07 14:45:38 0.0078125 
2016-12-07 14:45:38 Epoch 21 
2016-12-07 14:52:50 Training Error = 0.61184444444444 
2016-12-07 14:52:50 Training Loss = 0.032619233642578 
2016-12-07 14:53:01 Valid Error = 0.61492298459692 
2016-12-07 14:53:01 Valid Loss = 0.03152198337544 
2016-12-07 14:53:25 Test Error = 0.62 
2016-12-07 14:53:25 Test Loss = 0.031582894777784 
2016-12-07 14:53:25 -------------------LR------------------- 
2016-12-07 14:53:25 0.0078125 
2016-12-07 14:53:25 Epoch 22 
2016-12-07 15:00:37 Training Error = 0.60886666666667 
2016-12-07 15:00:37 Training Loss = 0.032462885972765 
2016-12-07 15:00:48 Valid Error = 0.6131226245249 
2016-12-07 15:00:48 Valid Loss = 0.031504217701896 
2016-12-07 15:01:12 Test Error = 0.6218 
2016-12-07 15:01:12 Test Loss = 0.031506760989918 
2016-12-07 15:01:12 -------------------LR------------------- 
2016-12-07 15:01:12 0.0078125 
2016-12-07 15:01:12 Epoch 23 
2016-12-07 15:08:20 Training Error = 0.603 
2016-12-07 15:08:20 Training Loss = 0.032370902126736 
2016-12-07 15:08:32 Valid Error = 0.62072414482897 
2016-12-07 15:08:32 Valid Loss = 0.031804668716159 
2016-12-07 15:08:55 Test Error = 0.6223 
2016-12-07 15:08:55 Test Loss = 0.031856847785501 
2016-12-07 15:08:55 -------------------LR------------------- 
2016-12-07 15:08:55 0.0078125 
2016-12-07 15:08:55 Epoch 24 
2016-12-07 15:16:09 Training Error = 0.60217777777778 
2016-12-07 15:16:09 Training Loss = 0.032273892564562 
2016-12-07 15:16:21 Valid Error = 0.60252050410082 
2016-12-07 15:16:21 Valid Loss = 0.031130110764886 
2016-12-07 15:16:44 Test Error = 0.5976 
2016-12-07 15:16:44 Test Loss = 0.031126812474868 
2016-12-07 15:16:44 -------------------LR------------------- 
2016-12-07 15:16:44 0.0078125 
2016-12-07 15:16:44 Epoch 25 
2016-12-07 15:23:51 Training Error = 0.59366666666667 
2016-12-07 15:23:51 Training Loss = 0.03213831886122 
2016-12-07 15:24:03 Valid Error = 0.61792358471694 
2016-12-07 15:24:03 Valid Loss = 0.031520666970586 
2016-12-07 15:24:26 Test Error = 0.6112 
2016-12-07 15:24:26 Test Loss = 0.031462937179266 
2016-12-07 15:24:26 -------------------LR------------------- 
2016-12-07 15:24:26 0.0078125 
2016-12-07 15:24:26 Epoch 26 
2016-12-07 15:31:40 Training Error = 0.59271111111111 
2016-12-07 15:31:40 Training Loss = 0.032077450480143 
2016-12-07 15:31:52 Valid Error = 0.61052210442088 
2016-12-07 15:31:52 Valid Loss = 0.031310981091815 
2016-12-07 15:32:15 Test Error = 0.6088 
2016-12-07 15:32:15 Test Loss = 0.031286023697199 
2016-12-07 15:32:15 -------------------LR------------------- 
2016-12-07 15:32:15 0.0078125 
2016-12-07 15:32:15 Epoch 27 
2016-12-07 15:39:22 Training Error = 0.58788888888889 
2016-12-07 15:39:22 Training Loss = 0.031900741305881 
2016-12-07 15:39:33 Valid Error = 0.59791958391678 
2016-12-07 15:39:33 Valid Loss = 0.031224228091404 
2016-12-07 15:39:57 Test Error = 0.6044 
2016-12-07 15:39:57 Test Loss = 0.031236629710478 
2016-12-07 15:39:57 -------------------LR------------------- 
2016-12-07 15:39:57 0.0078125 
2016-12-07 15:39:57 Epoch 28 
2016-12-07 15:47:07 Training Error = 0.58424444444444 
2016-12-07 15:47:07 Training Loss = 0.031848713338216 
2016-12-07 15:47:19 Valid Error = 0.60392078415683 
2016-12-07 15:47:19 Valid Loss = 0.031062663129671 
2016-12-07 15:47:42 Test Error = 0.6019 
2016-12-07 15:47:42 Test Loss = 0.03111752798043 
2016-12-07 15:47:42 -------------------LR------------------- 
2016-12-07 15:47:42 0.0078125 
2016-12-07 15:47:42 Epoch 29 
2016-12-07 15:54:50 Training Error = 0.57804444444444 
2016-12-07 15:54:50 Training Loss = 0.031701167833116 
2016-12-07 15:55:02 Valid Error = 0.6001200240048 
2016-12-07 15:55:02 Valid Loss = 0.031041261783291 
2016-12-07 15:55:25 Test Error = 0.6031 
2016-12-07 15:55:25 Test Loss = 0.03113786983116 
2016-12-07 15:55:25 -------------------LR------------------- 
2016-12-07 15:55:25 0.0078125 
2016-12-07 15:55:25 Epoch 30 
2016-12-07 16:02:40 Training Error = 0.5764 
2016-12-07 16:02:40 Training Loss = 0.031607262898763 
2016-12-07 16:02:52 Valid Error = 0.58131626325265 
2016-12-07 16:02:52 Valid Loss = 0.030511022976281 
2016-12-07 16:03:15 Test Error = 0.5872 
2016-12-07 16:03:15 Test Loss = 0.030595363691741 
2016-12-07 16:03:15 -------------------LR------------------- 
2016-12-07 16:03:15 0.0078125 
2016-12-07 16:03:15 Epoch 31 
2016-12-07 16:10:25 Training Error = 0.57344444444444 
2016-12-07 16:10:25 Training Loss = 0.031555432413737 
2016-12-07 16:10:37 Valid Error = 0.60392078415683 
2016-12-07 16:10:37 Valid Loss = 0.031318688220923 
2016-12-07 16:11:00 Test Error = 0.6046 
2016-12-07 16:11:00 Test Loss = 0.031427626247032 
2016-12-07 16:11:00 -------------------LR------------------- 
2016-12-07 16:11:00 0.0078125 
2016-12-07 16:11:00 Epoch 32 
2016-12-07 16:18:10 Training Error = 0.56995555555556 
2016-12-07 16:18:10 Training Loss = 0.031486228190104 
2016-12-07 16:18:21 Valid Error = 0.58051610322064 
2016-12-07 16:18:21 Valid Loss = 0.030809659172808 
2016-12-07 16:18:44 Test Error = 0.5905 
2016-12-07 16:18:44 Test Loss = 0.03087278621898 
2016-12-07 16:18:44 -------------------LR------------------- 
2016-12-07 16:18:44 0.0078125 
2016-12-07 16:18:44 Epoch 33 
2016-12-07 16:26:05 Training Error = 0.56777777777778 
2016-12-07 16:26:05 Training Loss = 0.031376361083984 
2016-12-07 16:26:16 Valid Error = 0.57071414282857 
2016-12-07 16:26:16 Valid Loss = 0.030485466340347 
2016-12-07 16:26:40 Test Error = 0.5844 
2016-12-07 16:26:40 Test Loss = 0.030548461824305 
2016-12-07 16:26:40 -------------------LR------------------- 
2016-12-07 16:26:40 0.0078125 
2016-12-07 16:26:40 Epoch 34 
2016-12-07 16:33:44 Training Error = 0.56391111111111 
2016-12-07 16:33:44 Training Loss = 0.031300213500977 
2016-12-07 16:33:55 Valid Error = 0.57851570314063 
2016-12-07 16:33:55 Valid Loss = 0.030410376065568 
2016-12-07 16:34:18 Test Error = 0.5822 
2016-12-07 16:34:18 Test Loss = 0.030468914675245 
2016-12-07 16:34:18 -------------------LR------------------- 
2016-12-07 16:34:18 0.0078125 
2016-12-07 16:34:18 Epoch 35 
2016-12-07 16:41:33 Training Error = 0.56093333333333 
2016-12-07 16:41:33 Training Loss = 0.03119636469184 
2016-12-07 16:41:45 Valid Error = 0.58271654330866 
2016-12-07 16:41:45 Valid Loss = 0.030714175970424 
2016-12-07 16:42:08 Test Error = 0.5826 
2016-12-07 16:42:08 Test Loss = 0.030649200828403 
2016-12-07 16:42:08 -------------------LR------------------- 
2016-12-07 16:42:08 0.0078125 
2016-12-07 16:42:08 Epoch 36 
2016-12-07 16:49:20 Training Error = 0.55806666666667 
2016-12-07 16:49:20 Training Loss = 0.031113551581489 
2016-12-07 16:49:31 Valid Error = 0.57271454290858 
2016-12-07 16:49:31 Valid Loss = 0.030387613541388 
2016-12-07 16:49:54 Test Error = 0.573 
2016-12-07 16:49:54 Test Loss = 0.03052162882487 
2016-12-07 16:49:54 -------------------LR------------------- 
2016-12-07 16:49:54 0.0078125 
2016-12-07 16:49:54 Epoch 37 
2016-12-07 16:57:05 Training Error = 0.5562 
2016-12-07 16:57:05 Training Loss = 0.031073072374132 
2016-12-07 16:57:16 Valid Error = 0.57891578315663 
2016-12-07 16:57:16 Valid Loss = 0.03069965638512 
2016-12-07 16:57:39 Test Error = 0.5791 
2016-12-07 16:57:39 Test Loss = 0.030630641473508 
2016-12-07 16:57:39 -------------------LR------------------- 
2016-12-07 16:57:39 0.0078125 
2016-12-07 16:57:39 Epoch 38 
2016-12-07 17:04:52 Training Error = 0.552 
2016-12-07 17:04:52 Training Loss = 0.030962789415148 
2016-12-07 17:05:04 Valid Error = 0.56811362272454 
2016-12-07 17:05:04 Valid Loss = 0.03017996885469 
2016-12-07 17:05:27 Test Error = 0.5645 
2016-12-07 17:05:27 Test Loss = 0.030086290755926 
2016-12-07 17:05:27 -------------------LR------------------- 
2016-12-07 17:05:27 0.0078125 
2016-12-07 17:05:27 Epoch 39 
2016-12-07 17:12:33 Training Error = 0.55053333333333 
2016-12-07 17:12:33 Training Loss = 0.03091820815701 
2016-12-07 17:12:45 Valid Error = 0.56691338267654 
2016-12-07 17:12:45 Valid Loss = 0.029850131453212 
2016-12-07 17:13:08 Test Error = 0.5626 
2016-12-07 17:13:08 Test Loss = 0.029865631103516 
2016-12-07 17:13:08 -------------------LR------------------- 
2016-12-07 17:13:08 0.0078125 
2016-12-07 17:13:08 Epoch 40 
2016-12-07 17:20:38 Training Error = 0.54744444444444 
2016-12-07 17:20:38 Training Loss = 0.030831179429796 
2016-12-07 17:20:49 Valid Error = 0.56991398279656 
2016-12-07 17:20:49 Valid Loss = 0.030211961478559 
2016-12-07 17:21:12 Test Error = 0.5692 
2016-12-07 17:21:12 Test Loss = 0.030246319280886 
2016-12-07 17:21:12 -------------------LR------------------- 
2016-12-07 17:21:12 0.00390625 
2016-12-07 17:21:12 Epoch 41 
2016-12-07 17:28:18 Training Error = 0.53513333333333 
2016-12-07 17:28:18 Training Loss = 0.030404941663954 
2016-12-07 17:28:29 Valid Error = 0.55631126225245 
2016-12-07 17:28:29 Valid Loss = 0.029746924114387 
2016-12-07 17:28:52 Test Error = 0.5501 
2016-12-07 17:28:52 Test Loss = 0.029632081963034 
2016-12-07 17:28:52 -------------------LR------------------- 
2016-12-07 17:28:52 0.00390625 
2016-12-07 17:28:52 Epoch 42 
2016-12-07 17:36:09 Training Error = 0.53095555555556 
2016-12-07 17:36:09 Training Loss = 0.03031426707628 
2016-12-07 17:36:20 Valid Error = 0.55371074214843 
2016-12-07 17:36:20 Valid Loss = 0.029799794824089 
2016-12-07 17:36:44 Test Error = 0.5577 
2016-12-07 17:36:44 Test Loss = 0.029778874475816 
2016-12-07 17:36:44 -------------------LR------------------- 
2016-12-07 17:36:44 0.00390625 
2016-12-07 17:36:44 Epoch 43 
2016-12-07 17:43:52 Training Error = 0.53235555555556 
2016-12-07 17:43:52 Training Loss = 0.030271346856011 
2016-12-07 17:44:04 Valid Error = 0.54930986197239 
2016-12-07 17:44:04 Valid Loss = 0.029401889050414 
2016-12-07 17:44:27 Test Error = 0.5439 
2016-12-07 17:44:27 Test Loss = 0.029518533833822 
2016-12-07 17:44:27 -------------------LR------------------- 
2016-12-07 17:44:27 0.00390625 
2016-12-07 17:44:27 Epoch 44 
2016-12-07 17:51:38 Training Error = 0.5256 
2016-12-07 17:51:38 Training Loss = 0.030235602457682 
2016-12-07 17:51:49 Valid Error = 0.54570914182837 
2016-12-07 17:51:49 Valid Loss = 0.029463139120296 
2016-12-07 17:52:12 Test Error = 0.5451 
2016-12-07 17:52:12 Test Loss = 0.029507811333151 
2016-12-07 17:52:12 -------------------LR------------------- 
2016-12-07 17:52:12 0.00390625 
2016-12-07 17:52:12 Epoch 45 
2016-12-07 17:59:26 Training Error = 0.52582222222222 
2016-12-07 17:59:26 Training Loss = 0.030194980414496 
2016-12-07 17:59:38 Valid Error = 0.55591118223645 
2016-12-07 17:59:38 Valid Loss = 0.029693861530938 
2016-12-07 18:00:01 Test Error = 0.5565 
2016-12-07 18:00:01 Test Loss = 0.029705388566559 
2016-12-07 18:00:01 -------------------LR------------------- 
2016-12-07 18:00:01 0.00390625 
2016-12-07 18:00:01 Epoch 46 
2016-12-07 18:07:10 Training Error = 0.5248 
2016-12-07 18:07:10 Training Loss = 0.030149222344293 
2016-12-07 18:07:22 Valid Error = 0.53590718143629 
2016-12-07 18:07:22 Valid Loss = 0.028944696967455 
2016-12-07 18:07:45 Test Error = 0.5371 
2016-12-07 18:07:45 Test Loss = 0.029062987862381 
2016-12-07 18:07:45 -------------------LR------------------- 
2016-12-07 18:07:45 0.00390625 
2016-12-07 18:07:45 Epoch 47 
2016-12-07 18:15:00 Training Error = 0.52297777777778 
2016-12-07 18:15:00 Training Loss = 0.030116186197917 
2016-12-07 18:15:12 Valid Error = 0.54710942188438 
2016-12-07 18:15:12 Valid Loss = 0.029491914173878 
2016-12-07 18:15:35 Test Error = 0.5487 
2016-12-07 18:15:35 Test Loss = 0.029585749577541 
2016-12-07 18:15:35 -------------------LR------------------- 
2016-12-07 18:15:35 0.00390625 
2016-12-07 18:15:35 Epoch 48 
2016-12-07 18:22:44 Training Error = 0.52295555555556 
2016-12-07 18:22:44 Training Loss = 0.030052091837565 
2016-12-07 18:22:55 Valid Error = 0.54750950190038 
2016-12-07 18:22:55 Valid Loss = 0.029385299107988 
2016-12-07 18:23:18 Test Error = 0.5463 
2016-12-07 18:23:18 Test Loss = 0.029381699984681 
2016-12-07 18:23:18 -------------------LR------------------- 
2016-12-07 18:23:18 0.00390625 
2016-12-07 18:23:18 Epoch 49 
2016-12-07 18:30:35 Training Error = 0.51964444444444 
2016-12-07 18:30:35 Training Loss = 0.030019220458984 
2016-12-07 18:30:46 Valid Error = 0.54550910182036 
2016-12-07 18:30:46 Valid Loss = 0.029587258679297 
2016-12-07 18:31:09 Test Error = 0.5467 
2016-12-07 18:31:09 Test Loss = 0.029464977758071 
2016-12-07 18:31:09 -------------------LR------------------- 
2016-12-07 18:31:09 0.00390625 
2016-12-07 18:31:09 Epoch 50 
2016-12-07 18:38:22 Training Error = 0.51548888888889 
2016-12-07 18:38:22 Training Loss = 0.029944520887587 
2016-12-07 18:38:33 Valid Error = 0.54630926185237 
2016-12-07 18:38:33 Valid Loss = 0.029684891589318 
2016-12-07 18:38:56 Test Error = 0.5461 
2016-12-07 18:38:56 Test Loss = 0.029576946273505 
2016-12-07 18:38:56 -------------------LR------------------- 
2016-12-07 18:38:56 0.00390625 
2016-12-07 18:38:56 Epoch 51 
2016-12-07 18:46:11 Training Error = 0.51753333333333 
2016-12-07 18:46:11 Training Loss = 0.029929763875326 
2016-12-07 18:46:22 Valid Error = 0.53630726145229 
2016-12-07 18:46:22 Valid Loss = 0.029167112324341 
2016-12-07 18:46:46 Test Error = 0.5395 
2016-12-07 18:46:46 Test Loss = 0.029088985607671 
2016-12-07 18:46:46 -------------------LR------------------- 
2016-12-07 18:46:46 0.00390625 
2016-12-07 18:46:46 Epoch 52 
2016-12-07 18:53:59 Training Error = 0.51402222222222 
2016-12-07 18:53:59 Training Loss = 0.029861601793077 
2016-12-07 18:54:10 Valid Error = 0.53290658131626 
2016-12-07 18:54:10 Valid Loss = 0.028956373128159 
2016-12-07 18:54:33 Test Error = 0.5294 
2016-12-07 18:54:33 Test Loss = 0.028896463162291 
2016-12-07 18:54:33 -------------------LR------------------- 
2016-12-07 18:54:33 0.00390625 
2016-12-07 18:54:33 Epoch 53 
2016-12-07 19:01:43 Training Error = 0.51326666666667 
2016-12-07 19:01:43 Training Loss = 0.029830742390951 
2016-12-07 19:01:54 Valid Error = 0.53530706141228 
2016-12-07 19:01:54 Valid Loss = 0.029304684681281 
2016-12-07 19:02:17 Test Error = 0.5444 
2016-12-07 19:02:17 Test Loss = 0.029520954924939 
2016-12-07 19:02:17 -------------------LR------------------- 
2016-12-07 19:02:17 0.00390625 
2016-12-07 19:02:17 Epoch 54 
2016-12-07 19:09:27 Training Error = 0.51137777777778 
2016-12-07 19:09:27 Training Loss = 0.02983525523546 
2016-12-07 19:09:38 Valid Error = 0.54190838167634 
2016-12-07 19:09:38 Valid Loss = 0.029621097428708 
2016-12-07 19:10:01 Test Error = 0.5443 
2016-12-07 19:10:01 Test Loss = 0.029649105745203 
2016-12-07 19:10:01 -------------------LR------------------- 
2016-12-07 19:10:01 0.00390625 
2016-12-07 19:10:02 Epoch 55 
2016-12-07 19:17:09 Training Error = 0.50857777777778 
2016-12-07 19:17:09 Training Loss = 0.029753170681424 
2016-12-07 19:17:20 Valid Error = 0.52910582116423 
2016-12-07 19:17:20 Valid Loss = 0.028958684757273 
2016-12-07 19:17:43 Test Error = 0.5324 
2016-12-07 19:17:43 Test Loss = 0.028990066498401 
2016-12-07 19:17:43 -------------------LR------------------- 
2016-12-07 19:17:43 0.00390625 
2016-12-07 19:17:43 Epoch 56 
2016-12-07 19:24:58 Training Error = 0.51104444444444 
2016-12-07 19:24:58 Training Loss = 0.029784314629449 
2016-12-07 19:25:10 Valid Error = 0.52610522104421 
2016-12-07 19:25:10 Valid Loss = 0.029063420134599 
2016-12-07 19:25:33 Test Error = 0.5348 
2016-12-07 19:25:33 Test Loss = 0.029200214071835 
2016-12-07 19:25:33 -------------------LR------------------- 
2016-12-07 19:25:33 0.00390625 
2016-12-07 19:25:33 Epoch 57 
2016-12-07 19:32:39 Training Error = 0.51013333333333 
2016-12-07 19:32:39 Training Loss = 0.029706206922743 
2016-12-07 19:32:51 Valid Error = 0.52750550110022 
2016-12-07 19:32:51 Valid Loss = 0.028680920229739 
2016-12-07 19:33:14 Test Error = 0.5275 
2016-12-07 19:33:14 Test Loss = 0.028773574440152 
2016-12-07 19:33:14 -------------------LR------------------- 
2016-12-07 19:33:14 0.00390625 
2016-12-07 19:33:14 Epoch 58 
2016-12-07 19:40:28 Training Error = 0.50891111111111 
2016-12-07 19:40:28 Training Loss = 0.029691966362847 
2016-12-07 19:40:39 Valid Error = 0.5381076215243 
2016-12-07 19:40:39 Valid Loss = 0.029046351863941 
2016-12-07 19:41:02 Test Error = 0.5359 
2016-12-07 19:41:02 Test Loss = 0.02908196034151 
2016-12-07 19:41:02 -------------------LR------------------- 
2016-12-07 19:41:02 0.00390625 
2016-12-07 19:41:02 Epoch 59 
2016-12-07 19:48:10 Training Error = 0.50757777777778 
2016-12-07 19:48:10 Training Loss = 0.029627233303494 
2016-12-07 19:48:21 Valid Error = 0.52890578115623 
2016-12-07 19:48:21 Valid Loss = 0.028937812424946 
2016-12-07 19:48:44 Test Error = 0.5347 
2016-12-07 19:48:44 Test Loss = 0.029083963670918 
2016-12-07 19:48:44 -------------------LR------------------- 
2016-12-07 19:48:44 0.00390625 
2016-12-07 19:48:44 Epoch 60 
2016-12-07 19:56:04 Training Error = 0.50664444444444 
2016-12-07 19:56:04 Training Loss = 0.029628965549045 
2016-12-07 19:56:16 Valid Error = 0.5255051010202 
2016-12-07 19:56:16 Valid Loss = 0.02858881814949 
2016-12-07 19:56:39 Test Error = 0.5276 
2016-12-07 19:56:39 Test Loss = 0.028846026192459 
2016-12-07 19:56:39 -------------------LR------------------- 
2016-12-07 19:56:39 0.001953125 
2016-12-07 19:56:39 Epoch 61 
2016-12-07 20:03:54 Training Error = 0.49944444444444 
2016-12-07 20:03:54 Training Loss = 0.029336564507378 
2016-12-07 20:04:05 Valid Error = 0.53230646129226 
2016-12-07 20:04:05 Valid Loss = 0.028746119808866 
2016-12-07 20:04:28 Test Error = 0.5242 
2016-12-07 20:04:28 Test Loss = 0.028734631527171 
2016-12-07 20:04:28 -------------------LR------------------- 
2016-12-07 20:04:28 0.001953125 
2016-12-07 20:04:28 Epoch 62 
2016-12-07 20:11:39 Training Error = 0.49637777777778 
2016-12-07 20:11:39 Training Loss = 0.029245021999783 
2016-12-07 20:11:51 Valid Error = 0.5249049809962 
2016-12-07 20:11:51 Valid Loss = 0.028597447315997 
2016-12-07 20:12:14 Test Error = 0.529 
2016-12-07 20:12:14 Test Loss = 0.028680025347541 
2016-12-07 20:12:14 -------------------LR------------------- 
2016-12-07 20:12:14 0.001953125 
2016-12-07 20:12:14 Epoch 63 
2016-12-07 20:19:30 Training Error = 0.49404444444444 
2016-12-07 20:19:30 Training Loss = 0.029248576687283 
2016-12-07 20:19:42 Valid Error = 0.51950390078016 
2016-12-07 20:19:42 Valid Loss = 0.028474591070467 
2016-12-07 20:20:05 Test Error = 0.5246 
2016-12-07 20:20:05 Test Loss = 0.028752484609566 
2016-12-07 20:20:05 -------------------LR------------------- 
2016-12-07 20:20:05 0.001953125 
2016-12-07 20:20:05 Epoch 64 
2016-12-07 20:27:11 Training Error = 0.49266666666667 
2016-12-07 20:27:11 Training Loss = 0.029191976657444 
2016-12-07 20:27:22 Valid Error = 0.52410482096419 
2016-12-07 20:27:22 Valid Loss = 0.028816165229391 
2016-12-07 20:27:45 Test Error = 0.5264 
2016-12-07 20:27:45 Test Loss = 0.028791289325789 
2016-12-07 20:27:45 -------------------LR------------------- 
2016-12-07 20:27:45 0.001953125 
2016-12-07 20:27:45 Epoch 65 
2016-12-07 20:35:01 Training Error = 0.49282222222222 
2016-12-07 20:35:01 Training Loss = 0.029221546034071 
2016-12-07 20:35:13 Valid Error = 0.51770354070814 
2016-12-07 20:35:13 Valid Loss = 0.028477099077144 
2016-12-07 20:35:36 Test Error = 0.5209 
2016-12-07 20:35:36 Test Loss = 0.028569349999521 
2016-12-07 20:35:36 -------------------LR------------------- 
2016-12-07 20:35:36 0.001953125 
2016-12-07 20:35:36 Epoch 66 
2016-12-07 20:42:47 Training Error = 0.49291111111111 
2016-12-07 20:42:47 Training Loss = 0.029218888590495 
2016-12-07 20:42:58 Valid Error = 0.52350470094019 
2016-12-07 20:42:58 Valid Loss = 0.028964869075771 
2016-12-07 20:43:21 Test Error = 0.5308 
2016-12-07 20:43:21 Test Loss = 0.029103337875067 
2016-12-07 20:43:21 -------------------LR------------------- 
2016-12-07 20:43:21 0.001953125 
2016-12-07 20:43:21 Epoch 67 
2016-12-07 20:50:32 Training Error = 0.4922 
2016-12-07 20:50:32 Training Loss = 0.029216285671658 
2016-12-07 20:50:43 Valid Error = 0.52170434086817 
2016-12-07 20:50:43 Valid Loss = 0.028756259360047 
2016-12-07 20:51:06 Test Error = 0.5266 
2016-12-07 20:51:06 Test Loss = 0.029025867895987 
2016-12-07 20:51:06 -------------------LR------------------- 
2016-12-07 20:51:06 0.001953125 
2016-12-07 20:51:06 Epoch 68 
2016-12-07 20:58:16 Training Error = 0.49617777777778 
2016-12-07 20:58:16 Training Loss = 0.029229905151367 
2016-12-07 20:58:28 Valid Error = 0.52290458091618 
2016-12-07 20:58:28 Valid Loss = 0.028815829493333 
2016-12-07 20:58:51 Test Error = 0.5234 
2016-12-07 20:58:51 Test Loss = 0.028927394104004 
2016-12-07 20:58:51 -------------------LR------------------- 
2016-12-07 20:58:51 0.001953125 
2016-12-07 20:58:51 Epoch 69 
2016-12-07 21:06:00 Training Error = 0.48817777777778 
2016-12-07 21:06:00 Training Loss = 0.029148531467014 
2016-12-07 21:06:11 Valid Error = 0.52130426085217 
2016-12-07 21:06:11 Valid Loss = 0.02870214313203 
2016-12-07 21:06:34 Test Error = 0.5264 
2016-12-07 21:06:34 Test Loss = 0.028910904648725 
2016-12-07 21:06:34 -------------------LR------------------- 
2016-12-07 21:06:34 0.001953125 
2016-12-07 21:06:35 Epoch 70 
2016-12-07 21:13:55 Training Error = 0.49037777777778 
2016-12-07 21:13:55 Training Loss = 0.029160008070204 
2016-12-07 21:14:06 Valid Error = 0.51850370074015 
2016-12-07 21:14:06 Valid Loss = 0.028359468797726 
2016-12-07 21:14:29 Test Error = 0.5171 
2016-12-07 21:14:29 Test Loss = 0.028472355801451 
2016-12-07 21:14:29 -------------------LR------------------- 
2016-12-07 21:14:29 0.001953125 
2016-12-07 21:14:29 Epoch 71 
2016-12-07 21:21:36 Training Error = 0.4846 
2016-12-07 21:21:36 Training Loss = 0.029081560967339 
2016-12-07 21:21:48 Valid Error = 0.52210442088418 
2016-12-07 21:21:48 Valid Loss = 0.028693344895914 
2016-12-07 21:22:11 Test Error = 0.5217 
2016-12-07 21:22:11 Test Loss = 0.028758587915757 
2016-12-07 21:22:11 -------------------LR------------------- 
2016-12-07 21:22:11 0.001953125 
2016-12-07 21:22:11 Epoch 72 
2016-12-07 21:29:29 Training Error = 0.48826666666667 
2016-12-07 21:29:29 Training Loss = 0.02911551441786 
2016-12-07 21:29:40 Valid Error = 0.51430286057211 
2016-12-07 21:29:40 Valid Loss = 0.028862480373009 
2016-12-07 21:30:04 Test Error = 0.53 
2016-12-07 21:30:04 Test Loss = 0.029210038368375 
2016-12-07 21:30:04 -------------------LR------------------- 
2016-12-07 21:30:04 0.001953125 
2016-12-07 21:30:04 Epoch 73 
2016-12-07 21:37:10 Training Error = 0.48584444444444 
2016-12-07 21:37:10 Training Loss = 0.029091041029188 
2016-12-07 21:37:22 Valid Error = 0.52130426085217 
2016-12-07 21:37:22 Valid Loss = 0.028623239927473 
2016-12-07 21:37:45 Test Error = 0.5199 
2016-12-07 21:37:45 Test Loss = 0.028728253293505 
2016-12-07 21:37:45 -------------------LR------------------- 
2016-12-07 21:37:45 0.001953125 
2016-12-07 21:37:45 Epoch 74 
2016-12-07 21:44:55 Training Error = 0.48922222222222 
2016-12-07 21:44:55 Training Loss = 0.02910054695638 
2016-12-07 21:45:06 Valid Error = 0.51490298059612 
2016-12-07 21:45:06 Valid Loss = 0.02848372278502 
2016-12-07 21:45:29 Test Error = 0.521 
2016-12-07 21:45:29 Test Loss = 0.02853486624325 
2016-12-07 21:45:29 -------------------LR------------------- 
2016-12-07 21:45:29 0.001953125 
2016-12-07 21:45:29 Epoch 75 
2016-12-07 21:52:41 Training Error = 0.48486666666667 
2016-12-07 21:52:41 Training Loss = 0.029032489461263 
2016-12-07 21:52:52 Valid Error = 0.52650530106021 
2016-12-07 21:52:52 Valid Loss = 0.028824597381463 
2016-12-07 21:53:15 Test Error = 0.5186 
2016-12-07 21:53:15 Test Loss = 0.028781830701641 
2016-12-07 21:53:15 -------------------LR------------------- 
2016-12-07 21:53:15 0.001953125 
2016-12-07 21:53:15 Epoch 76 
2016-12-07 22:00:23 Training Error = 0.48373333333333 
2016-12-07 22:00:23 Training Loss = 0.029052702745226 
2016-12-07 22:00:35 Valid Error = 0.51970394078816 
2016-12-07 22:00:35 Valid Loss = 0.028925999844745 
2016-12-07 22:00:58 Test Error = 0.5266 
2016-12-07 22:00:58 Test Loss = 0.029132832845052 
2016-12-07 22:00:58 -------------------LR------------------- 
2016-12-07 22:00:58 0.001953125 
2016-12-07 22:00:58 Epoch 77 
2016-12-07 22:08:15 Training Error = 0.48562222222222 
2016-12-07 22:08:15 Training Loss = 0.02901508871799 
2016-12-07 22:08:27 Valid Error = 0.51570314062813 
2016-12-07 22:08:27 Valid Loss = 0.02830444289029 
2016-12-07 22:08:50 Test Error = 0.5165 
2016-12-07 22:08:50 Test Loss = 0.028513577240589 
2016-12-07 22:08:50 -------------------LR------------------- 
2016-12-07 22:08:50 0.001953125 
2016-12-07 22:08:50 Epoch 78 
2016-12-07 22:15:59 Training Error = 0.48402222222222 
2016-12-07 22:15:59 Training Loss = 0.029004151652018 
2016-12-07 22:16:10 Valid Error = 0.50810162032406 
2016-12-07 22:16:10 Valid Loss = 0.028217509441355 
2016-12-07 22:16:33 Test Error = 0.5126 
2016-12-07 22:16:33 Test Loss = 0.028421564917471 
2016-12-07 22:16:33 -------------------LR------------------- 
2016-12-07 22:16:33 0.001953125 
2016-12-07 22:16:33 Epoch 79 
2016-12-07 22:23:52 Training Error = 0.48573333333333 
2016-12-07 22:23:52 Training Loss = 0.029028079427083 
2016-12-07 22:24:03 Valid Error = 0.51610322064413 
2016-12-07 22:24:03 Valid Loss = 0.02828474646108 
2016-12-07 22:24:26 Test Error = 0.5083 
2016-12-07 22:24:26 Test Loss = 0.028176019735897 
2016-12-07 22:24:26 -------------------LR------------------- 
2016-12-07 22:24:26 0.001953125 
2016-12-07 22:24:26 Epoch 80 
2016-12-07 22:31:37 Training Error = 0.4808 
2016-12-07 22:31:37 Training Loss = 0.028901268351237 
2016-12-07 22:31:48 Valid Error = 0.52070414082817 
2016-12-07 22:31:48 Valid Loss = 0.028891250312362 
2016-12-07 22:32:11 Test Error = 0.521 
2016-12-07 22:32:11 Test Loss = 0.028982327539781 
2016-12-07 22:32:11 -------------------LR------------------- 
2016-12-07 22:32:11 0.0009765625 
2016-12-07 22:32:11 Epoch 81 
2016-12-07 22:39:24 Training Error = 0.47635555555556 
2016-12-07 22:39:24 Training Loss = 0.028716153333876 
2016-12-07 22:39:36 Valid Error = 0.5123024604921 
2016-12-07 22:39:36 Valid Loss = 0.028388291256542 
2016-12-07 22:39:59 Test Error = 0.5162 
2016-12-07 22:39:59 Test Loss = 0.028552012305166 
2016-12-07 22:39:59 -------------------LR------------------- 
2016-12-07 22:39:59 0.0009765625 
2016-12-07 22:39:59 Epoch 82 
2016-12-07 22:47:03 Training Error = 0.4748 
2016-12-07 22:47:03 Training Loss = 0.028703865790473 
2016-12-07 22:47:14 Valid Error = 0.51070214042809 
2016-12-07 22:47:14 Valid Loss = 0.028308624371017 
2016-12-07 22:47:37 Test Error = 0.5134 
2016-12-07 22:47:37 Test Loss = 0.028337269203336 
2016-12-07 22:47:37 -------------------LR------------------- 
2016-12-07 22:47:37 0.0009765625 
2016-12-07 22:47:37 Epoch 83 
2016-12-07 22:54:48 Training Error = 0.47488888888889 
2016-12-07 22:54:48 Training Loss = 0.02869641792806 
2016-12-07 22:54:59 Valid Error = 0.50910182036407 
2016-12-07 22:54:59 Valid Loss = 0.028464247804154 
2016-12-07 22:55:23 Test Error = 0.5122 
2016-12-07 22:55:23 Test Loss = 0.02866597367829 
2016-12-07 22:55:23 -------------------LR------------------- 
2016-12-07 22:55:23 0.0009765625 
2016-12-07 22:55:23 Epoch 84 
2016-12-07 23:02:37 Training Error = 0.47373333333333 
2016-12-07 23:02:37 Training Loss = 0.028652792629666 
2016-12-07 23:02:49 Valid Error = 0.5125025005001 
2016-12-07 23:02:49 Valid Loss = 0.028246160582564 
2016-12-07 23:03:12 Test Error = 0.5139 
2016-12-07 23:03:12 Test Loss = 0.028486385779287 
2016-12-07 23:03:12 -------------------LR------------------- 
2016-12-07 23:03:12 0.0009765625 
2016-12-07 23:03:12 Epoch 85 
2016-12-07 23:10:18 Training Error = 0.4766 
2016-12-07 23:10:18 Training Loss = 0.02869233082411 
2016-12-07 23:10:29 Valid Error = 0.50710142028406 
2016-12-07 23:10:29 Valid Loss = 0.028009716454684 
2016-12-07 23:10:52 Test Error = 0.5107 
2016-12-07 23:10:52 Test Loss = 0.028326992528579 
2016-12-07 23:10:52 -------------------LR------------------- 
2016-12-07 23:10:52 0.0009765625 
2016-12-07 23:10:52 Epoch 86 
2016-12-07 23:18:10 Training Error = 0.47488888888889 
2016-12-07 23:18:10 Training Loss = 0.028706068386502 
2016-12-07 23:18:22 Valid Error = 0.50610122024405 
2016-12-07 23:18:22 Valid Loss = 0.02812022495313 
2016-12-07 23:18:45 Test Error = 0.5084 
2016-12-07 23:18:45 Test Loss = 0.028373371737611 
2016-12-07 23:18:45 -------------------LR------------------- 
2016-12-07 23:18:45 0.0009765625 
2016-12-07 23:18:45 Epoch 87 
2016-12-07 23:25:50 Training Error = 0.47453333333333 
2016-12-07 23:25:50 Training Loss = 0.028683083428277 
2016-12-07 23:26:02 Valid Error = 0.5123024604921 
2016-12-07 23:26:02 Valid Loss = 0.028301342732543 
2016-12-07 23:26:25 Test Error = 0.5149 
2016-12-07 23:26:25 Test Loss = 0.028500713842055 
2016-12-07 23:26:25 -------------------LR------------------- 
2016-12-07 23:26:25 0.0009765625 
2016-12-07 23:26:25 Epoch 88 
2016-12-07 23:33:40 Training Error = 0.47373333333333 
2016-12-07 23:33:40 Training Loss = 0.02865784250217 
2016-12-07 23:33:52 Valid Error = 0.5129025805161 
2016-12-07 23:33:52 Valid Loss = 0.028441058571523 
2016-12-07 23:34:15 Test Error = 0.5152 
2016-12-07 23:34:15 Test Loss = 0.028566696496103 
2016-12-07 23:34:15 -------------------LR------------------- 
2016-12-07 23:34:15 0.0009765625 
2016-12-07 23:34:15 Epoch 89 
2016-12-07 23:41:24 Training Error = 0.47344444444444 
2016-12-07 23:41:24 Training Loss = 0.028657130777995 
2016-12-07 23:41:35 Valid Error = 0.51150230046009 
2016-12-07 23:41:35 Valid Loss = 0.028288775898776 
2016-12-07 23:41:58 Test Error = 0.5149 
2016-12-07 23:41:58 Test Loss = 0.028539849135455 
2016-12-07 23:41:58 -------------------LR------------------- 
2016-12-07 23:41:58 0.0009765625 
2016-12-07 23:41:58 Epoch 90 
2016-12-07 23:49:14 Training Error = 0.47446666666667 
2016-12-07 23:49:14 Training Loss = 0.028670352145725 
2016-12-07 23:49:26 Valid Error = 0.50970194038808 
2016-12-07 23:49:26 Valid Loss = 0.028328285276071 
2016-12-07 23:49:49 Test Error = 0.5081 
2016-12-07 23:49:49 Test Loss = 0.028498017225079 
2016-12-07 23:49:49 -------------------LR------------------- 
2016-12-07 23:49:49 0.0009765625 
2016-12-07 23:49:49 Epoch 91 
2016-12-07 23:56:59 Training Error = 0.47308888888889 
2016-12-07 23:56:59 Training Loss = 0.028653513983832 
2016-12-07 23:57:11 Valid Error = 0.50630126025205 
2016-12-07 23:57:11 Valid Loss = 0.028266148397062 
2016-12-07 23:57:34 Test Error = 0.5119 
2016-12-07 23:57:34 Test Loss = 0.028402997813505 
2016-12-07 23:57:34 -------------------LR------------------- 
2016-12-07 23:57:34 0.0009765625 
2016-12-07 23:57:34 Epoch 92 
2016-12-08 00:04:42 Training Error = 0.47411111111111 
2016-12-08 00:04:42 Training Loss = 0.028662591606988 
2016-12-08 00:04:54 Valid Error = 0.51890378075615 
2016-12-08 00:04:54 Valid Loss = 0.028624348943299 
2016-12-08 00:05:17 Test Error = 0.5188 
2016-12-08 00:05:17 Test Loss = 0.028781005380668 
2016-12-08 00:05:17 -------------------LR------------------- 
2016-12-08 00:05:17 0.0009765625 
2016-12-08 00:05:17 Epoch 93 
2016-12-08 00:12:34 Training Error = 0.47284444444444 
2016-12-08 00:12:34 Training Loss = 0.028629184678819 
2016-12-08 00:12:45 Valid Error = 0.500300060012 
2016-12-08 00:12:45 Valid Loss = 0.028183184352585 
2016-12-08 00:13:08 Test Error = 0.5068 
2016-12-08 00:13:08 Test Loss = 0.028340445305319 
2016-12-08 00:13:08 -------------------LR------------------- 
2016-12-08 00:13:08 0.0009765625 
2016-12-08 00:13:09 Epoch 94 
2016-12-08 00:20:14 Training Error = 0.47244444444444 
2016-12-08 00:20:14 Training Loss = 0.028643782307943 
2016-12-08 00:20:25 Valid Error = 0.51030206041208 
2016-12-08 00:20:25 Valid Loss = 0.028106865540363 
2016-12-08 00:20:49 Test Error = 0.5044 
2016-12-08 00:20:49 Test Loss = 0.028202433717017 
2016-12-08 00:20:49 -------------------LR------------------- 
2016-12-08 00:20:49 0.0009765625 
2016-12-08 00:20:49 Epoch 95 
2016-12-08 00:28:06 Training Error = 0.47297777777778 
2016-12-08 00:28:06 Training Loss = 0.028613136786567 
2016-12-08 00:28:18 Valid Error = 0.499699939988 
2016-12-08 00:28:18 Valid Loss = 0.028014401230383 
2016-12-08 00:28:41 Test Error = 0.5063 
2016-12-08 00:28:41 Test Loss = 0.028338096409218 
2016-12-08 00:28:41 -------------------LR------------------- 
2016-12-08 00:28:41 0.0009765625 
2016-12-08 00:28:41 Epoch 96 
2016-12-08 00:35:49 Training Error = 0.47015555555556 
2016-12-08 00:35:49 Training Loss = 0.028578149536133 
2016-12-08 00:36:01 Valid Error = 0.50590118023605 
2016-12-08 00:36:01 Valid Loss = 0.028327997326529 
2016-12-08 00:36:24 Test Error = 0.51 
2016-12-08 00:36:24 Test Loss = 0.028431640385646 
2016-12-08 00:36:24 -------------------LR------------------- 
2016-12-08 00:36:24 0.0009765625 
2016-12-08 00:36:24 Epoch 97 
2016-12-08 00:43:31 Training Error = 0.4714 
2016-12-08 00:43:31 Training Loss = 0.028614018920898 
2016-12-08 00:43:42 Valid Error = 0.50370074014803 
2016-12-08 00:43:42 Valid Loss = 0.028059576347457 
2016-12-08 00:44:05 Test Error = 0.5104 
2016-12-08 00:44:05 Test Loss = 0.028290556275611 
2016-12-08 00:44:05 -------------------LR------------------- 
2016-12-08 00:44:05 0.0009765625 
2016-12-08 00:44:05 Epoch 98 
2016-12-08 00:51:19 Training Error = 0.47206666666667 
2016-12-08 00:51:19 Training Loss = 0.028581414876302 
2016-12-08 00:51:30 Valid Error = 0.50270054010802 
2016-12-08 00:51:30 Valid Loss = 0.027952261648724 
2016-12-08 00:51:54 Test Error = 0.4998 
2016-12-08 00:51:54 Test Loss = 0.028153591829188 
2016-12-08 00:51:54 -------------------LR------------------- 
2016-12-08 00:51:54 0.0009765625 
2016-12-08 00:51:54 Epoch 99 
2016-12-08 00:59:03 Training Error = 0.47357777777778 
2016-12-08 00:59:03 Training Loss = 0.028598977159288 
2016-12-08 00:59:14 Valid Error = 0.50910182036407 
2016-12-08 00:59:14 Valid Loss = 0.028163161718158 
2016-12-08 00:59:37 Test Error = 0.5064 
2016-12-08 00:59:37 Test Loss = 0.028336691882564 
2016-12-08 00:59:37 -------------------LR------------------- 
2016-12-08 00:59:37 0.0009765625 
2016-12-08 00:59:37 Epoch 100 
2016-12-08 01:07:02 Training Error = 0.47277777777778 
2016-12-08 01:07:02 Training Loss = 0.028608435465495 
2016-12-08 01:07:14 Valid Error = 0.50770154030806 
2016-12-08 01:07:14 Valid Loss = 0.028238719172585 
2016-12-08 01:07:37 Test Error = 0.5102 
2016-12-08 01:07:37 Test Loss = 0.02849370171042 
2016-12-08 01:07:37 -------------------LR------------------- 
2016-12-08 01:07:37 0.00048828125 
2016-12-08 01:07:37 Epoch 101 
2016-12-08 01:14:42 Training Error = 0.46562222222222 
2016-12-08 01:14:42 Training Loss = 0.028418251098633 
2016-12-08 01:14:54 Valid Error = 0.50270054010802 
2016-12-08 01:14:54 Valid Loss = 0.028009651307217 
2016-12-08 01:15:17 Test Error = 0.505 
2016-12-08 01:15:17 Test Loss = 0.028263366848815 
2016-12-08 01:15:17 -------------------LR------------------- 
2016-12-08 01:15:17 0.00048828125 
2016-12-08 01:15:17 Epoch 102 
2016-12-08 01:22:36 Training Error = 0.46517777777778 
2016-12-08 01:22:36 Training Loss = 0.02839373038737 
2016-12-08 01:22:48 Valid Error = 0.50610122024405 
2016-12-08 01:22:48 Valid Loss = 0.028461924577819 
2016-12-08 01:23:11 Test Error = 0.51 
2016-12-08 01:23:11 Test Loss = 0.028614528910319 
2016-12-08 01:23:11 -------------------LR------------------- 
2016-12-08 01:23:11 0.00048828125 
2016-12-08 01:23:11 Epoch 103 
2016-12-08 01:30:17 Training Error = 0.46866666666667 
2016-12-08 01:30:17 Training Loss = 0.028406685139974 
2016-12-08 01:30:29 Valid Error = 0.50090018003601 
2016-12-08 01:30:29 Valid Loss = 0.028166325156655 
2016-12-08 01:30:52 Test Error = 0.5023 
2016-12-08 01:30:52 Test Loss = 0.028194578941196 
2016-12-08 01:30:52 -------------------LR------------------- 
2016-12-08 01:30:52 0.00048828125 
2016-12-08 01:30:52 Epoch 104 
